{"id": "3shWnvRa0P", "cdate": 1650645463701, "mdate": null, "content": {"title": "Pulmonary Embolus Detection with Dual-Energy CT Data Augmentation", "abstract": "3D segmentation U-Nets are trained for pulmonary embolus detection on three different\ndata sets. We investigate the impact of the training data set on the generalization capabilities and use dual-energy CT data augmentation to increase performance."}}
{"id": "rkx5InjA1N", "cdate": 1544629330318, "mdate": null, "content": {"title": "Dynamic Pacemaker Artifact Removal (DyPAR) from CT Data using CNNs", "abstract": "Metal objects in the human heart like implanted pacemakers frequently occur in elderly patients. Due to cardiac motion, they are not static during the CT acquisition and lead to heavy artifacts in reconstructed CT image volumes. Furthermore, cardiac motion precludes the application of standard metal artifact reduction methods which assume that the object does not move. We propose a deep-learning-based approach for dynamic pacemaker artifact removal which deals with metal shadow segmentation directly in the projection domain. The data required for supervised learning is generated by introducing synthetic pacemaker leads into 14 clinical data sets without pacemakers. CNNs achieve a Dice coefficient of 0.913 on test data with synthetic metal leads. Application of the trained CNNs on eight data sets with real pacemakers and subsequent inpainting of the post-processed segmentation masks leads to significantly reduced metal artifacts in the reconstructed CT image volumes."}}
{"id": "HkBtaBjoz", "cdate": 1523436925019, "mdate": null, "content": {"title": "Motion Estimation in Coronary CT Angiography Images using Convolutional Neural Networks", "abstract": "Coronary CT angiography has become a preferred technique for the detection and diagnosis of coronary artery disease, but image artifacts due to cardiac motion frequently interfere with evaluation. Several motion compensation approaches have been developed which deal with motion estimation based on 3-D/3-D registration of multiple heart phases. The scan range required for multi-phase reconstruction is a limitation in clinical practice. In this paper, the feasibility of single-phase, image-based motion estimation by convolutional neural networks (CNNs) is investigated. First, the required data for supervised learning is generated by a forward model which introduces simulated axial motion to artifact-free CT cases. Second, regression networks are trained to estimate underlying 2D motion vectors from axial coronary cross-sections. In a phantom study with computer-simulated vessels, CNNs predict the motion direction and the motion strength with average accuracies of 1.08\u00b0 and 0.06 mm, respectively. Motivated by these results, clinical performance is evaluated based on twelve prospectively ECG-triggered clinical cases and achieves average accuracies of 20.66\u00b0 and 0.94 mm. Transferability and generalization capabilities are demonstrated by motion estimation and subsequent compensation on six clinical cases with real cardiac motion artifacts."}}
{"id": "rk-m1iW_-S", "cdate": 1514764800000, "mdate": null, "content": {"title": "State Space Gaussian Processes with Non-Gaussian Likelihood", "abstract": "We provide a comprehensive overview and tooling for GP modelling with non-Gaussian likelihoods using state space methods. The state space formulation allows for solving one-dimensonal GP models in ..."}}
{"id": "rkNbyDWu-B", "cdate": 1483228800000, "mdate": null, "content": {"title": "Scalable Log Determinants for Gaussian Process Kernel Learning", "abstract": "For applications as varied as Bayesian neural networks, determinantal point processes, elliptical graphical models, and kernel learning for Gaussian processes (GPs), one must compute a log determinant of an n by n positive definite matrix, and its derivatives---leading to prohibitive O(n^3) computations. We propose novel O(n) approaches to estimating these quantities from only fast matrix vector multiplications (MVMs). These stochastic approximations are based on Chebyshev, Lanczos, and surrogate models, and converge quickly even for kernel matrices that have challenging spectra. We leverage these approximations to develop a scalable Gaussian process approach to kernel learning. We find that Lanczos is generally superior to Chebyshev for kernel learning, and that a surrogate approach can be highly efficient and accurate with popular kernels."}}
{"id": "r1ZIijWubB", "cdate": 1420070400000, "mdate": null, "content": {"title": "Fast Kronecker Inference in Gaussian Processes with non-Gaussian Likelihoods", "abstract": "Gaussian processes (GPs) are a flexible class of methods with state of the art performance on spatial statistics applications. However, GPs require O(n^3) computations and O(n^2) storage, and popul..."}}
{"id": "ByVRQibu-S", "cdate": 1420070400000, "mdate": null, "content": {"title": "Kernel Interpolation for Scalable Structured Gaussian Processes (KISS-GP)", "abstract": "We introduce a new structured kernel interpolation (SKI) framework, which generalises and unifies inducing point methods for scalable Gaussian processes (GPs). SKI methods produce kernel approximat..."}}
{"id": "B1ZC0LbO-S", "cdate": 1293840000000, "mdate": null, "content": {"title": "Additive Gaussian Processes", "abstract": "We introduce a Gaussian process model of functions which are additive. An additive function is one which decomposes into a sum of low-dimensional functions, each depending on only a subset of the input variables. Additive GPs generalize both Generalized Additive Models, and the standard GP models which use squared-exponential kernels. Hyperparameter learning in this model can be seen as Bayesian Hierarchical Kernel Learning (HKL). We introduce an expressive but tractable parameterization of the kernel function, which allows efficient evaluation of all input interaction terms, whose number is exponential in the input dimension. The additional structure discoverable by this model results in increased interpretability, as well as state-of-the-art predictive power in regression tasks."}}
{"id": "SyWiqyGuWB", "cdate": 1230768000000, "mdate": null, "content": {"title": "Learning to detect unseen object classes by between-class attribute transfer", "abstract": "We study the problem of object classification when training and test classes are disjoint, i.e. no training examples of the target classes are available. This setup has hardly been studied in computer vision research, but it is the rule rather than the exception, because the world contains tens of thousands of different object classes and for only a very few of them image, collections have been formed and annotated with suitable class labels. In this paper, we tackle the problem by introducing attribute-based classification. It performs object detection based on a human-specified high-level description of the target objects instead of training images. The description consists of arbitrary semantic attributes, like shape, color or even geographic information. Because such properties transcend the specific learning task at hand, they can be pre-learned, e.g. from image datasets unrelated to the current task. Afterwards, new classes can be detected based on their attribute representation, without the need for a new training phase. In order to evaluate our method and to facilitate research in this area, we have assembled a new large-scale dataset, \u201cAnimals with Attributes\u201d, of over 30,000 animal images that match the 50 classes in Osherson's classic table of how strongly humans associate 85 semantic attributes with animal classes. Our experiments show that by using an attribute layer it is indeed possible to build a learning object detection system that does not require any training images of the target classes."}}
{"id": "H1EQdnW_Zr", "cdate": 1230768000000, "mdate": null, "content": {"title": "Convex variational Bayesian inference for large scale generalized linear models", "abstract": "We show how variational Bayesian inference can be implemented for very large generalized linear models. Our relaxation is proven to be a convex problem for any log-concave model. We provide a generic double loop algorithm for solving this relaxation on models with arbitrary super-Gaussian potentials. By iteratively decoupling the criterion, most of the work can be done by solving large linear systems, rendering our algorithm orders of magnitude faster than previously proposed solvers for the same problem. We evaluate our method on problems of Bayesian active learning for large binary classification models, and show how to address settings with many candidates and sequential inclusion steps."}}
