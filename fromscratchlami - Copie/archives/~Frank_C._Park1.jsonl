{"id": "ycy47ZX0Oc", "cdate": 1686324886392, "mdate": null, "content": {"title": "Leveraging 3D Reconstruction for Mechanical Search on Cluttered Shelves", "abstract": "Finding and grasping a target object on a cluttered shelf, especially when the target is occluded by other unknown objects and initially invisible, remains a significant challenge in robotic manipulation. While there have been advances in finding the target object by rearranging surrounding objects using specialized tools, developing algorithms that work with standard robot grippers remains an unresolved issue. In this paper, we introduce a novel framework for finding and grasping the target object using a standard gripper, employing pushing and pick and-place actions. To achieve this, we introduce two indicator functions: (i) an existence function, determining the potential presence of the target, and (ii) a graspability function, assessing the feasibility of grasping the identified target. We then formulate a model-based optimal control problem. The core component of our approach involves leveraging a 3D recognition model, enabling efficient estimation of the proposed indicator functions and their associated dynamics models. Our method succeeds in finding and grasping the target object using a standard robot gripper in both simulations and real-world settings. In particular, we demonstrate the adaptability and robustness of our method in the presence of noise in real-world vision sensor data. The code for our framework is available at https://github.com/seungyeon-k/Search-for-Grasp-public."}}
{"id": "psyvs5wdAV", "cdate": 1686324872637, "mdate": null, "content": {"title": "Equivariant Motion Manifold Primitives", "abstract": "Existing movement primitive models for the most part focus on representing and generating a single trajectory for a given task, limiting their adaptability to situations in which unforeseen obstacles or new constraints may arise. In this work we propose Motion Manifold Primitives (MMP), a movement primitive paradigm that encodes and generates, for a given task, a continuous manifold of trajectories each of which can achieve the given task. To address the challenge of learning each motion manifold from a limited amount of data, we exploit inherent symmetries in the robot task by constructing motion manifold primitives that are equivariant with respect to given symmetry groups. Under the assumption that each of the MMPs can be smoothly deformed into each other, an autoencoder framework is developed to encode the MMPs and also generate solution trajectories. Experiments involving synthetic and real-robot examples demonstrate that our method outperforms existing manifold primitive methods by significant margins. Code is available at https://github.com/dlsfldl/EMMP-public."}}
{"id": "Id4b5SY1Y8", "cdate": 1686324872515, "mdate": null, "content": {"title": "PairwiseNet: Pairwise Collision Distance Learning for High-dof Robot Systems", "abstract": "Motion planning for robot manipulation systems operating in complex environments remains a challenging problem. It requires the evaluation of both the collision distance and its derivative. Owing to its computational complexity, recent studies have attempted to utilize data-driven approaches to learn the collision distance. However, their performance degrades significantly for complicated high-dof systems, such as multi-arm robots. Additionally, the model must be retrained every time the environment undergoes even slight changes. In this paper, we propose PairwiseNet, a model that estimates the minimum distance between two geometric shapes and overcomes many of the limitations of current models. By dividing the problem of global collision distance learning into smaller pairwise sub-problems, PairwiseNet can be used to efficiently calculate the global collision distance. PairwiseNet can be deployed without further modifications or training for any system comprised of the same shape elements (as those in the training dataset). Experiments with multi-arm manipulation systems of various dof indicate that our model achieves significant performance improvements concerning several performance metrics, especially the false positive rate with the collision-free guaranteed threshold. Results further demonstrate that our single trained PairwiseNet model is applicable to all multi-arm systems used in the evaluation. The code is available at https://github.com/kjh6526/PairwiseNet."}}
{"id": "wrti5p4BrW", "cdate": 1683700437431, "mdate": 1683700437431, "content": {"title": "Unscented Kalman Filtering for Simultaneous Estimation of Attitude and Gyroscope Bias", "abstract": "We present an unscented Kalman filtering (UKF)\nalgorithm for simultaneously estimating attitude and gyroscope\nbias from an inertial measurement unit (IMU). The algorithm is\nformulated as a discrete-time stochastic nonlinear filter, with state\nspace given by the direct product matrix Lie group SO(3) \u00d7 R3, \nand observations in SO(3) reconstructed from IMU measurements of gravity and the earth\u2019s magnetic field. Computationally\nefficient implementations of our filter are made possible by\nformulating the state space dynamics and measurement equations\nin a way that leads to closed-form equations for covariance propagation and update. The resulting attitude estimates are invariant\nwith respect to choice of fixed and moving reference frames.\nThe performance advantages of our filter vis-a-vis existing state- `\nof-the-art IMU attitude estimation algorithms are validated via\nnumerical and hardware experiments involving both synthetic\nand real data."}}
{"id": "GYwOtBGHcRV", "cdate": 1683700231012, "mdate": 1683700231012, "content": {"title": "A Riemannian geometric framework for manifold learning of non-Euclidean data", "abstract": "A growing number of problems in data analysis and classification involve data that\nare non-Euclidean. For such problems, a naive application of vector space analysis\nalgorithms will produce results that depend on the choice of local coordinates used to\nparametrize the data. At the same time, many data analysis and classification problems\neventually reduce to an optimization, in which the criteria being minimized can be\ninterpreted as the distortion associated with a mapping between two curved spaces.\nExploiting this distortion minimizing perspective, we first show that manifold learning\nproblems involving non-Euclidean data can be naturally framed as seeking a mapping\nbetween two Riemannian manifolds that is closest to being an isometry. A family of\ncoordinate-invariant first-order distortion measures is then proposed that measure the\nproximity of the mapping to an isometry, and applied to manifold learning for non\u0002Euclidean data sets. Case studies ranging from synthetic data to human mass-shape\ndata demonstrate the many performance advantages of our Riemannian distortion\nminimization framework."}}
{"id": "_q7A0m3vXH0", "cdate": 1663850551553, "mdate": null, "content": {"title": "Geometrically regularized autoencoders for non-Euclidean data", "abstract": "Regularization is almost {\\it de rigueur} when designing autoencoders that are sparse and robust to noise. Given the recent surge of interest in machine learning problems involving non-Euclidean data, in this paper we address the regularization of autoencoders on curved spaces. We show that by ignoring the underlying geometry of the data and applying standard vector space regularization techniques, autoencoder performance can be severely degraded, or worse, training can fail to converge. Assuming that both the data space and latent space can be modeled as Riemannian manifolds, we show how to construct regularization terms in a coordinate-invariant way, and develop geometric generalizations of the denoising autoencoder and reconstruction contractive autoencoder such that the essential properties that enable the estimation of the derivative of the log-probability density are preserved. Drawing upon various non-Euclidean data sets, we show that our geometric autoencoder regularization techniques can have important performance advantages over vector-spaced methods while avoiding other breakdowns that can result from failing to account for the underlying geometry."}}
{"id": "yxj33c6NuX", "cdate": 1663850042161, "mdate": null, "content": {"title": "Minimum Curvature Manifold Learning", "abstract": "It is widely observed that vanilla autoencoders can have low manifold learning accuracy given a noisy or small training dataset. \nRecent work has discovered that it is important to regularize the decoder that explicitly parameterizes the manifold, \nwhere a neighborhood graph is employed for decoder regularization. However, one caveat of this method is that it is not always straightforward to construct a correct graph. Alternatively, one may consider naive graph-free regularization methods such as minimizing the norm of the decoder's Jacobian or Hessian, but these norms are not coordinate-invariant (i.e. reparametrization-invariant) and hence do not capture any meaningful geometric quantity of the manifold nor result in geometrically meaningful manifold regularization effects. \nAnother recent work called the isometric regularization implicitly forces the manifold to have zero intrinsic curvature, resulting in some geometrically meaningful regularization effects. But, since the intrinsic curvature does not capture how the manifold is embedded in the data space from an extrinsic perspective, the regularization effects are often limited. In this paper, we propose a {\\it minimum extrinsic curvature principle} for manifold regularization and {\\bf Minimum Curvature Autoencoder (MCAE)}, a graph-free coordinate-invariant extrinsic curvature minimization framework for autoencoder regularization. Experiments with various standard datasets demonstrate that MCAE improves manifold learning accuracy compared to existing methods, especially showing strong robustness to noise."}}
{"id": "4g3PwAp5nsX", "cdate": 1655376351123, "mdate": null, "content": {"title": "SE(2)-Equivariant Pushing Dynamics Models for Tabletop Object Manipulations", "abstract": "For tabletop object manipulation tasks, learning an accurate pushing dynamics model, which predicts the objects' motions when a robot pushes an object, is very important. In this work, we claim that an ideal pushing dynamics model should have the SE(2)-equivariance property, i.e., if tabletop objects' poses and pushing action are transformed by some same planar rigid-body transformation, then the resulting motion should also be the result of the same transformation. Existing state-of-the-art data-driven approaches do not have this equivariance property, resulting in less-than-desirable learning performances. In this paper, we propose a new neural network architecture that by construction has the above equivariance property. Through extensive empirical validations, we show that the proposed model shows significantly improved learning performances over the existing methods. Also, we verify that our pushing dynamics model can be used for various downstream pushing manipulation tasks such as the object moving, singulation, and grasping in both simulation and real robot experiments. Code is available at https://github.com/seungyeon-k/SQPDNet-public.\n\n"}}
{"id": "AVh_HTC76u", "cdate": 1652737717766, "mdate": null, "content": {"title": "A Reparametrization-Invariant Sharpness Measure Based on Information Geometry", "abstract": "It has been observed that the generalization performance of neural networks correlates with the sharpness of their loss landscape. Dinh et al. (2017) have observed that existing formulations of sharpness measures fail to be invariant with respect to scaling and reparametrization. While some scale-invariant measures have recently been proposed, reparametrization-invariant measures are still lacking. Moreover, they often do not provide any theoretical insights into generalization performance nor lead to practical use to improve the performance. Based on an information geometric analysis of the neural network parameter space, in this paper we propose a reparametrization-invariant sharpness measure that captures the change in loss with respect to changes in the probability distribution modeled by neural networks, rather than with respect to changes in the parameter values. We reveal some theoretical connections of our measure to generalization performance. In particular, experiments confirm that using our measure as a regularizer in neural network training significantly improves performance."}}
{"id": "INO8hGXD2M", "cdate": 1632875764486, "mdate": null, "content": {"title": "Adversarial Distributions Against Out-of-Distribution Detectors", "abstract": "Out-of-distribution (OOD) detection is the task of determining whether an input lies outside the training data distribution. As an outlier may deviate from the training distribution in unexpected ways, an ideal OOD detector should be able to detect all types of outliers. However, current evaluation protocols test a detector over OOD datasets that cover only a small fraction of all possible outliers, leading to overly optimistic views of OOD detector performance.  In this paper, we propose a novel evaluation framework for OOD detection that tests a detector over a larger, unexplored space of outliers.  In our framework, a detector is evaluated with samples from its adversarial distribution, which generates diverse outlier samples that are likely to be misclassified as in-distribution by the detector. Using adversarial distributions, we investigate OOD detectors with reported near-perfect performance on standard benchmarks like CIFAR-10 vs SVHN. Our methods discover a wide range of samples that are obviously outlier but recognized as in-distribution by the detectors, indicating that current state-of-the-art detectors are not as perfect as they seem on existing benchmarks."}}
