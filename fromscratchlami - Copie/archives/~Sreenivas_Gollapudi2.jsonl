{"id": "yLCCfzv_8Yx", "cdate": 1663850379718, "mdate": null, "content": {"title": "'I pick you choose': Joint human-algorithm decision making in multi-armed bandits", "abstract": "Online learning in multi-armed bandits has been a rich area of research for decades, resulting in numerous \\enquote{no-regret} algorithms that efficiently learn the arm with highest expected reward. However, in many settings the final decision of which arm to pull isn't under the control of the algorithm itself. For example, a driving app typically suggests a subset of routes (arms) to the driver, who ultimately makes the final choice about which to select. Typically, the human also wishes to learn the optimal arm based on historical reward information, but decides which arm to pull based on a potentially different objective function, such as being more or less myopic about exploiting near-term rewards. In this paper, we show when this joint human-algorithm system can achieve good performance. Specifically, we explore multiple possible frameworks for human objectives and give theoretical regret bounds for regret. Finally, we include experimental results exploring how regret varies with the human decision-maker's objective, as well as the number of arms presented. "}}
{"id": "p9zz7hLzH-4", "cdate": 1663850317510, "mdate": null, "content": {"title": "Affinity-Aware Graph Networks", "abstract": "Graph Neural Networks (GNNs) have emerged as a powerful technique for learning on relational data. Owing to the relatively limited number of message passing steps they perform\u2014and hence a smaller receptive field\u2014there has been significant interest in improving their expressivity by incorporating structural aspects of the underlying graph. In this paper, we explore the use of affinity measures as features in graph neural networks, in particular measures arising from random walks, including effective resistance, hitting and commute times. We propose message passing networks based on these features and evaluate their performance on a variety of node and graph property prediction tasks."}}
{"id": "syzTg1vyBtL", "cdate": 1632875693611, "mdate": null, "content": {"title": "Congested bandits: Optimal routing via short-term resets", "abstract": "For traffic routing platforms, the choice of which route to recommend to a user depends on the congestion on these routes -- indeed, an individual's utility depends on the number of people using the recommended route at that instance. Motivated by this, we introduce the problem of Congested Bandits where each arm's reward is allowed to depend on the number of times it was played in the past $\\Delta$ timesteps. This dependence on past history of actions leads to a dynamical system where an algorithm's present choices also affect its future pay-offs, and requires an algorithm to plan for this. We study the congestion aware formulation in the  multi-armed bandit (MAB) setup and in the  contextual bandit setup with linear rewards. For the multi-armed setup, we propose a UCB style algorithm  and show that its policy regret scales as $\\tilde{O}(\\sqrt{K \\Delta T})$. For the linear contextual bandit setup, our algorithm, based on an iterative least squares planner, achieves policy regret $\\tilde{O}(\\sqrt{dT} + \\Delta)$. From an experimental standpoint, we corroborate the no-regret properties of our algorithms via a simulation study."}}
{"id": "hVnM-ni5o5nVQ", "cdate": 1621630328932, "mdate": null, "content": {"title": "Contextual Recommendations and Low-Regret Cutting-Plane Algorithms", "abstract": "We consider the following variant of contextual linear bandits motivated by routing applications in navigational engines  and recommendation systems. We wish to learn a hidden $d$-dimensional value $w^*$. Every round, we are presented with a subset $\\mathcal{X}_t \\subseteq \\mathbb{R}^d$ of possible actions. If we choose (i.e. recommend to the user) action $x_t$, we obtain utility $\\langle x_t, w^* \\rangle$ but only learn the identity of the best action $\\arg\\max_{x \\in \\X_t} \\langle x, w^* \\rangle$.\n\nWe design algorithms for this problem which achieve regret $O(d\\log T)$ and $\\exp(O(d \\log d))$. To accomplish this, we design novel cutting-plane algorithms with low \u201cregret\u201d -- the total distance between the true point $w^*$ and the hyperplanes the separation oracle returns. \n\nWe also consider the variant where we are allowed to provide a list of several recommendations. In this variant, we give an algorithm with $O(d^2 \\log d)$ regret and list size $\\poly(d)$. Finally, we construct nearly tight algorithms for a weaker variant of this problem where the learner only learns the identity of an action that is better than the recommendation. Our results rely on new algorithmic techniques in convex geometry (including a variant of Steiner\u2019s formula for the centroid of a convex set) which may be of independent interest. "}}
{"id": "45GfBQYtYlp", "cdate": 1621630328932, "mdate": null, "content": {"title": "Contextual Recommendations and Low-Regret Cutting-Plane Algorithms", "abstract": "We consider the following variant of contextual linear bandits motivated by routing applications in navigational engines  and recommendation systems. We wish to learn a hidden $d$-dimensional value $w^*$. Every round, we are presented with a subset $\\mathcal{X}_t \\subseteq \\mathbb{R}^d$ of possible actions. If we choose (i.e. recommend to the user) action $x_t$, we obtain utility $\\langle x_t, w^* \\rangle$ but only learn the identity of the best action $\\arg\\max_{x \\in \\X_t} \\langle x, w^* \\rangle$.\n\nWe design algorithms for this problem which achieve regret $O(d\\log T)$ and $\\exp(O(d \\log d))$. To accomplish this, we design novel cutting-plane algorithms with low \u201cregret\u201d -- the total distance between the true point $w^*$ and the hyperplanes the separation oracle returns. \n\nWe also consider the variant where we are allowed to provide a list of several recommendations. In this variant, we give an algorithm with $O(d^2 \\log d)$ regret and list size $\\poly(d)$. Finally, we construct nearly tight algorithms for a weaker variant of this problem where the learner only learns the identity of an action that is better than the recommendation. Our results rely on new algorithmic techniques in convex geometry (including a variant of Steiner\u2019s formula for the centroid of a convex set) which may be of independent interest. "}}
{"id": "vCWztO0ppL", "cdate": 1621630119839, "mdate": null, "content": {"title": "A Convergence Analysis of Gradient Descent on Graph Neural Networks", "abstract": "Graph Neural Networks~(GNNs) are a powerful class of architectures for solving learning problems on graphs. While many variants of GNNs have been proposed in the literature and have achieved strong empirical performance, their theoretical properties are less well understood. In this work we study the convergence properties of the gradient descent algorithm when used to train GNNs. In particular, we consider the realizable setting where the data is generated from a network with unknown weights and our goal is to study conditions under which gradient descent on a GNN architecture can recover near optimal solutions. While such analysis has been performed in recent years for other architectures such as fully connected feed-forward networks, the message passing nature of the updates in a GNN poses a new challenge in understanding the nature of the gradient descent updates. We take a step towards overcoming this by proving that for the case of deep linear GNNs gradient descent provably recovers solutions up to error $\\epsilon$ in $O(\\text{log}(1/\\epsilon))$ iterations, under natural assumptions on the data distribution. Furthermore, for the case of one-round GNNs with ReLU activations, we show that gradient descent provably recovers solutions up to error $\\epsilon$ in $O(\\frac{1}{\\epsilon^2} \\log(\\frac{1}{\\epsilon}))$ iterations. \n"}}
{"id": "Px7xIKHjmMS", "cdate": 1601308243055, "mdate": null, "content": {"title": "Beyond GNNs: A Sample Efficient Architecture for Graph Problems", "abstract": "Despite their popularity in learning problems over graph structured data, existing Graph Neural Networks (GNNs) have inherent limitations for fundamental graph problems such as shortest paths, $k$-connectivity, minimum spanning tree and minimum cuts. In all these instances, it is known that one needs GNNs of high depth, scaling at a polynomial rate with the number of nodes $n$, to provably encode the solution space. This in turn affects their statistical efficiency thus requiring a significant amount of training data in order to obtain networks with good performance. In this work we propose a new hybrid architecture to overcome this limitation. Our proposed architecture that we call as GNNplus networks involve a combination of multiple parallel low depth GNNs along with simple pooling layers involving low depth fully connected networks. We provably demonstrate that for many graph problems, the solution space can be encoded by GNNplus networks using depth that scales only poly-logarithmically in the number of nodes. This significantly improves the amount of training data needed that we establish via improved generalization bounds. Finally, we empirically demonstrate the effectiveness of our proposed architecture for a variety of graph problems.\n"}}
{"id": "gBpYGXH9J7F", "cdate": 1601308230504, "mdate": null, "content": {"title": "Online Learning under Adversarial Corruptions", "abstract": "We study the design of efficient online learning algorithms tolerant to adversarially corrupted rewards. In particular, we study settings where an online algorithm makes a prediction at each time step, and receives a stochastic reward from the environment that can be arbitrarily corrupted with probability $\\epsilon \\in [0,\\frac 1 2)$. Here $\\epsilon$ is the noise rate the characterizes the strength of the adversary. As is standard in online learning, we study the design of algorithms with small regret over a period of time steps. However, while the algorithm observes corrupted rewards, we require its regret to be small with respect to the true uncorrupted reward distribution. We build upon recent advances in robust estimation for unsupervised learning problems to design robust online algorithms with near optimal regret in  three different scenarios: stochastic multi-armed bandits, linear contextual bandits, and Markov Decision Processes~(MDPs) with stochastic rewards and transitions. Finally, we provide empirical evidence regarding the robustness of our proposed algorithms on synthetic and real datasets."}}
{"id": "GNv-TyWu3PY", "cdate": 1601308041978, "mdate": null, "content": {"title": "Robust Learning for Congestion-Aware Routing", "abstract": "We consider the problem of routing users through a network with unknown congestion functions over an infinite time horizon. On each time step $t$, the algorithm receives a routing request and must select a valid path. For each edge $e$ in the selected path, the algorithm incurs a cost $c_e^t = f_e(x_e^t) + \\eta_e^t$, where $x_e^t$ is the flow on edge $e$ at time $t$, $f_e$ is the congestion function, and $\\eta_e^t$ is a noise sample drawn from an unknown distribution. The algorithm observes $c_e^t$, and can use this observation in future routing decisions. The routing requests are supplied adversarially. \n\nWe present an algorithm with cumulative regret $\\tilde{O}(|E| t^{2/3})$, where the regret on each time step is defined as the difference between the total cost incurred by our chosen path and the minimum cost among all valid paths. Our algorithm has space complexity $O(|E| t^{1/3})$ and time complexity $O(|E| \\log t)$. We also validate our algorithm empirically using graphs from New York City road networks."}}
{"id": "ong-9lU4cGcn", "cdate": 1577836800000, "mdate": null, "content": {"title": "On the Learnability of Random Deep Networks", "abstract": "In this paper we study the learnability of random deep networks both theoretically and experimentally. On the theoretical front, assuming the statistical query model, we show that the learnability of random deep networks with sign activation drops exponentially with their depths; under plausible conjectures, our results extend to ReLu and sigmoid activations. The core of the arguments is that even for highly correlated inputs, the outputs of deep random networks are near-orthogonal. On the experimental side, we find that the learnability of random networks drops sharply with depth even with the state-of-the-art training methods."}}
