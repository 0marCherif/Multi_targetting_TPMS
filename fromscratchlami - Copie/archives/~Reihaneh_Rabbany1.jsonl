{"id": "M84OnT0ZvDq", "cdate": 1663939410278, "mdate": null, "content": {"title": "Early Detection of Sexual Predators with Federated Learning", "abstract": "The rise in screen time and the isolation brought by the different containment measures implemented during the COVID-19 pandemic have led to an alarming increase in cases of online grooming. Online grooming is defined as all the strategies used by predators to lure children into sexual exploitation. Previous attempts made in industry and academia on the detection of grooming rely on accessing and monitoring users\u2019 private conversations through the training of a model centrally or by sending personal conversations to a global server. We introduce a first, privacy-preserving, cross-device, federated learning framework for the early detection of sexual predators, which aims to ensure a safe online environment for children while respecting their privacy. "}}
{"id": "1GVpwr2Tfdg", "cdate": 1654537377551, "mdate": null, "content": {"title": "Towards Better Evaluation for Dynamic Link Prediction", "abstract": "Despite the prevalence of recent success in learning from static graphs, learning from time-evolving graphs remains an open challenge. In this work, we design new, more stringent evaluation procedures for link prediction specific to dynamic graphs, which reflect real-world considerations, to better compare the strengths and weaknesses of methods. First, we create two visualization techniques to understand the reoccurring patterns of edges over time and show that many edges reoccur at later time steps. Based on this observation, we propose a pure memorization-based baseline called EdgeBank. EdgeBank achieves surprisingly strong performance across multiple settings which highlights that the negative edges used in the current evaluation are easy. To sample more challenging negative edges, we introduce two novel negative sampling strategies that improve robustness and better match real-world applications. Lastly, we introduce six new dynamic graph datasets from a diverse set of domains missing from current benchmarks, providing new challenges and opportunities for future research. Our code repository is accessible at https://github.com/fpour/DGB.git."}}
{"id": "3-a_IGVzXRO", "cdate": 1634343930905, "mdate": null, "content": {"title": "Curating the Twitter Election Integrity Datasets for Better Online Troll Characterization", "abstract": "In modern days, social media platforms provide accessible channels for the inter-action and immediate reflection of the most important events happening around the world. In this paper, we, firstly, present a curated set of datasets whose origin stem from the Twitter\u2019s Information Operations efforts.  More notably, these accounts, which have been already suspended, provide a notion of how state-backed human trolls operate.Secondly, we present detailed analyses of how these behaviours vary over time,and motivate its use and abstraction in the context of deep representation learning:for instance, to learn and, potentially track, troll behaviour. We present baselinesf or such tasks and highlight the differences there may exist within the literature.Finally, we utilize the representations learned for behaviour prediction to classify trolls from\"real\"users, using a sample of non-suspended active accounts."}}
{"id": "-UrA2i0liPI", "cdate": 1609459200000, "mdate": null, "content": {"title": "The Surprising Performance of Simple Baselines for Misinformation Detection", "abstract": "As social media becomes increasingly prominent in our day to day lives, it is increasingly important to detect informative content and prevent the spread of disinformation and unverified rumours. While many sophisticated and successful models have been proposed in the literature, they are often compared with older NLP baselines such as SVMs, CNNs, and LSTMs. In this paper, we examine the performance of a broad set of modern transformer-based language models and show that with basic fine-tuning, these models are competitive with and can even significantly outperform recently proposed state-of-the-art methods. We present our framework as a baseline for creating and evaluating new methods for misinformation detection. We further study a comprehensive set of benchmark datasets, and discuss potential data leakage and the need for careful design of the experiments and understanding of datasets to account for confounding variables. As an extreme case example, we show that classifying only based on the first three digits of tweet ids, which contain information on the date, gives state-of-the-art performance on a commonly used benchmark dataset for fake news detection --Twitter16. We provide a simple tool to detect this problem and suggest steps to mitigate it in future datasets."}}
{"id": "bOHykFZR9Ww", "cdate": 1599506037374, "mdate": null, "content": {"title": " Laplacian Change Point Detection for Dynamic Graphs", "abstract": "Dynamic and temporal graphs are rich data structures that are used to model complex relationships between entities over time. In particular, anomaly detection in temporal graphs is crucial for many real world applications such as intrusion identification in network systems, detection of ecosystem disturbances and detection of epidemic outbreaks. In this paper, we focus on change point detection in dynamic graphs and address two main challenges associated with this problem: I) how to compare graph snapshots across time, II) how to capture temporal dependencies. To solve the above challenges, we propose Laplacian Anomaly Detection (LAD) which uses the spectrum of the Laplacian matrix of the graph structure at each snapshot to obtain low dimensional embeddings. LAD explicitly models short term and long term dependencies by applying two sliding windows. In synthetic experiments, LAD outperforms the state-of-the-art method. We also evaluate our method on three real dynamic networks: UCI message network, US senate co-sponsorship network and Canadian bill voting network. In all three datasets, we demonstrate that our method can more effectively identify anomalous time points according to significant real world events."}}
{"id": "SkRunhIL3q", "cdate": 1577836800000, "mdate": null, "content": {"title": "Incorporating Dynamic Flight Network in SEIR to Model Mobility between Populations", "abstract": "Current efforts of modelling COVID-19 are often based on the standard compartmental models such as SEIR and their variations. As pre-symptomatic and asymptomatic cases can spread the disease between populations through travel, it is important to incorporate mobility between populations into the epidemiological modelling. In this work, we propose to modify the commonly-used SEIR model to account for the dynamic flight network, by estimating the imported cases based on the air traffic volume as well as the test positive rate at the source. This modification, called Flight-SEIR, can potentially enable 1). early detection of outbreaks due to imported pre-symptomatic and asymptomatic cases, 2). more accurate estimation of the reproduction number and 3). evaluation of the impact of travel restrictions and the implications of lifting these measures. The proposed Flight-SEIR is essential in navigating through this pandemic and the next ones, given how interconnected our world has become."}}
{"id": "BLtAykYWk0p", "cdate": 1577836800000, "mdate": null, "content": {"title": "Contact Graph Epidemic Modelling of COVID-19 for Transmission and Intervention Strategies", "abstract": "The coronavirus disease 2019 (COVID-19) pandemic has quickly become a global public health crisis unseen in recent years. It is known that the structure of the human contact network plays an important role in the spread of transmissible diseases. In this work, we study a structure aware model of COVID-19 CGEM. This model becomes similar to the classical compartment-based models in epidemiology if we assume the contact network is a Erdos-Renyi (ER) graph, i.e. everyone comes into contact with everyone else with the same probability. In contrast, CGEM is more expressive and allows for plugging in the actual contact networks, or more realistic proxies for it. Moreover, CGEM enables more precise modelling of enforcing and releasing different non-pharmaceutical intervention (NPI) strategies. Through a set of extensive experiments, we demonstrate significant differences between the epidemic curves when assuming different underlying structures. More specifically we demonstrate that the compartment-based models are overestimating the spread of the infection by a factor of 3, and under some realistic assumptions on the compliance factor, underestimating the effectiveness of some of NPIs, mischaracterizing others (e.g. predicting a later peak), and underestimating the scale of the second peak after reopening."}}
{"id": "0n8vDsaVoKi", "cdate": 1577836800000, "mdate": null, "content": {"title": "ComplexDataLab at W-NUT 2020 Task 2: Detecting Informative COVID-19 Tweets by Attending over Linked Documents", "abstract": "Given the global scale of COVID-19 and the flood of social media content related to it, how can we find informative discussions? We present Gapformer, which effectively classifies content as informative or not. It reformulates the problem as graph classification, drawing on not only the tweet but connected webpages and entities. We leverage a pre-trained language model as well as the connections between nodes to learn a pooled representation for each document network. We show it outperforms several competitive baselines and present ablation studies supporting the benefit of the linked information. Code is available on Github."}}
{"id": "dsbgoNtoTYU", "cdate": 1546300800000, "mdate": null, "content": {"title": "Anomaly Detection with Joint Representation Learning of Content and Connection", "abstract": "Social media sites are becoming a key factor in politics. These platforms are easy to manipulate for the purpose of distorting information space to confuse and distract voters. Past works to identify disruptive patterns are mostly focused on analyzing the content of tweets. In this study, we jointly embed the information from both user posted content as well as a user's follower network, to detect groups of densely connected users in an unsupervised fashion. We then investigate these dense sub-blocks of users to flag anomalous behavior. In our experiments, we study the tweets related to the upcoming 2019 Canadian Elections, and observe a set of densely-connected users engaging in local politics in different provinces, and exhibiting troll-like behavior."}}
{"id": "Q9pKSTYJetz", "cdate": 1546300800000, "mdate": null, "content": {"title": "SGP: Spotting Groups Polluting the Online Political Discourse", "abstract": "Recent events have led to a burgeoning awareness on the misuse of social media sites to affect political events, sway public opinion, and confuse the voters. Such serious, hostile mass manipulation has motivated a large body of works on bots/troll detection and fake news detection, which mostly focus on classifying at the user level based on the content generated by the users. In this study, we jointly analyze the connections among the users, as well as the content generated by them to Spot Coordinated Groups (SCG), sets of users that are likely to be organized towards impacting the general discourse. Given their tiny size (relative to the whole data), detecting these groups is computationally hard. Our proposed method detects these tiny-clusters effectively and efficiently. We deploy our SCG method to summarize and explain the coordinated groups on Twitter around the 2019 Canadian Federal Elections, by analyzing over 60 thousand user accounts with 3.4 million followership connections, and 1.3 million unique hashtags in the content of their tweets. The users in the detected coordinated groups are over 4x more likely to get suspended, whereas the hashtags which characterize their creed are linked to misinformation campaigns."}}
