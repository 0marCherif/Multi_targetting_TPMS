{"id": "LiJbL9T0T1", "cdate": 1672531200000, "mdate": 1695967560989, "content": {"title": "Proper Scoring Rules for Survival Analysis", "abstract": "Survival analysis is the problem of estimating probability distributions for future event times, which can be seen as a problem in uncertainty quantification. Although there are fundamental theorie..."}}
{"id": "5MFO7A_uR6", "cdate": 1672531200000, "mdate": 1695967560872, "content": {"title": "Proper Scoring Rules for Survival Analysis", "abstract": "Survival analysis is the problem of estimating probability distributions for future event times, which can be seen as a problem in uncertainty quantification. Although there are fundamental theories on strictly proper scoring rules for uncertainty quantification, little is known about those for survival analysis. In this paper, we investigate extensions of four major strictly proper scoring rules for survival analysis and we prove that these extensions are proper under certain conditions, which arise from the discretization of the estimation of probability distributions. We also compare the estimation performances of these extended scoring rules by using real datasets, and the extensions of the logarithmic score and the Brier score performed the best."}}
{"id": "Xj9V-stmIcO", "cdate": 1663850582185, "mdate": null, "content": {"title": "Proper Scoring Rules for Survival Analysis", "abstract": "Survival analysis is the problem of estimating probability distributions for future events, which can be seen as a problem in uncertainty quantification. Although there are fundamental theories on strictly proper scoring rules for uncertainty quantification, little is known about those for survival analysis. In this paper, we investigate extensions of four major strictly proper scoring rules for survival analysis. Through the extensions, we discuss and clarify the assumptions arising from the discretization of the estimation of probability distributions. We also discuss the relationship between the existing algorithms and extended scoring rules, and we propose new algorithms based on our extensions of the scoring rules for survival analysis.\n"}}
{"id": "zAuiZpZ478l", "cdate": 1652737651396, "mdate": null, "content": {"title": "Hierarchical Lattice Layer for Partially Monotone Neural Networks", "abstract": "Partially monotone regression is a regression analysis in which the target values are monotonically increasing with respect to a subset of input features.   The TensorFlow Lattice library is one of the standard machine learning libraries for partially monotone regression.  It consists of several neural network layers, and its core component is the lattice layer.  One of the problems of the lattice layer is that it requires the projected gradient descent algorithm with many constraints to train it.  Another problem is that it cannot receive a high-dimensional input vector due to the memory consumption.   We propose a novel neural network layer, the hierarchical lattice layer (HLL), as an extension of the lattice layer so that we can use a standard stochastic gradient descent algorithm to train HLL while satisfying monotonicity constraints and so that it can receive a high-dimensional input vector.  Our experiments demonstrate that HLL did not sacrifice its prediction performance on real datasets compared with the lattice layer."}}
{"id": "d9riPgNqDO0", "cdate": 1640995200000, "mdate": 1695967561094, "content": {"title": "Hierarchical Lattice Layer for Partially Monotone Neural Networks", "abstract": "Partially monotone regression is a regression analysis in which the target values are monotonically increasing with respect to a subset of input features. The TensorFlow Lattice library is one of the standard machine learning libraries for partially monotone regression. It consists of several neural network layers, and its core component is the lattice layer. One of the problems of the lattice layer is that it requires the projected gradient descent algorithm with many constraints to train it. Another problem is that it cannot receive a high-dimensional input vector due to the memory consumption. We propose a novel neural network layer, the hierarchical lattice layer (HLL), as an extension of the lattice layer so that we can use a standard stochastic gradient descent algorithm to train HLL while satisfying monotonicity constraints and so that it can receive a high-dimensional input vector. Our experiments demonstrate that HLL did not sacrifice its prediction performance on real datasets compared with the lattice layer."}}
{"id": "bB6YLDJewoK", "cdate": 1632875596309, "mdate": null, "content": {"title": "Simpler Calibration for Survival Analysis", "abstract": "Survival analysis, also known as time-to-event analysis, is the problem to predict the distribution of the time of the occurrence of an event.  This problem has applications in various fields such as healthcare, security, and finance.  While there have been many neural network models proposed for survival analysis, none of them are calibrated.  This means that the average of the predicted distribution is different from the actual distribution in the dataset.  Therefore, X-CAL has recently been proposed for the calibration, which is supposed to be used as a regularization term in the loss function of a neural network.  X-CAL is formulated on the basis of the widely used definition of calibration for distribution regression.  In this work, we propose new calibration definitions for distribution regression and survival analysis, and demonstrate a simpler alternative to X-CAL based on the new calibration definition for survival analysis.\n"}}
{"id": "OSyCTD8k4t", "cdate": 1609459200000, "mdate": 1681669993793, "content": {"title": "A Comparative Time-to-Event Analysis Across Health Systems", "abstract": ""}}
{"id": "9h4AYJ1j7WB", "cdate": 1546300800000, "mdate": 1681780106555, "content": {"title": "Strategy-Proof Approximation Algorithms for the Stable Marriage Problem with Ties and Incomplete Lists", "abstract": ""}}
{"id": "5Cvba_HYMTA", "cdate": 1546300800000, "mdate": 1681780106557, "content": {"title": "Strategy-Proof Approximation Algorithms for the Stable Marriage Problem with Ties and Incomplete Lists", "abstract": "In the stable marriage problem (SM), a mechanism that always outputs a stable matching is called a stable mechanism. One of the well-known stable mechanisms is the man-oriented Gale-Shapley algorithm (MGS). MGS has a good property that it is strategy-proof to the men's side, i.e., no man can obtain a better outcome by falsifying a preference list. We call such a mechanism a man-strategy-proof mechanism. Unfortunately, MGS is not a woman-strategy-proof mechanism. Roth has shown that there is no stable mechanism that is simultaneously man-strategy-proof and woman-strategy-proof, which is known as Roth's impossibility theorem. In this paper, we extend these results to the stable marriage problem with ties and incomplete lists (SMTI). Since SMTI is an extension of SM, Roth's impossibility theorem takes over to SMTI. Therefore, we focus on the one-sided-strategy-proofness. In SMTI, one instance can have stable matchings of different sizes, and it is natural to consider the problem of finding a largest stable matching, known as MAX SMTI. Thus we incorporate the notion of approximation ratio used in the theory of approximation algorithms. We say that a stable-mechanism is $c$-approximate-stable mechanism if it always returns a stable matching of size at least $1/c$ of a largest one. We also consider a restricted variant of MAX SMTI, which we call MAX SMTI-1TM, where only men's lists can contain ties. Our results are summarized as follows: (i) MAX SMTI admits both a man-strategy-proof 2-approximate-stable mechanism and a woman-strategy-proof 2-approximate-stable mechanism. (ii) MAX SMTI-1TM admits a woman-strategy-proof 2-approximate-stable mechanism. (iii) MAX SMTI-1TM admits a man-strategy-proof 1.5-approximate-stable mechanism. All these results are tight in terms of approximation ratios. Also, all these strategy-proofness results apply for strategy-proofness against coalitions."}}
{"id": "1OgAqB8dEkc", "cdate": 1546300800000, "mdate": 1681780106710, "content": {"title": "Sampler for Composition Ratio by Markov Chain Monte Carlo", "abstract": "Invention involves combination, or more precisely, ratios of composition. According to Thomas Edison, \"Genius is one percent inspiration and 99 percent perspiration\" is an example. In many situations, researchers and inventors already have a variety of data and manage to create something new by using it, but the key problem is how to select and combine knowledge. In this paper, we propose a new Markov chain Monte Carlo (MCMC) algorithm to generate composition ratios, nonnegative-integer-valued vectors with two properties: (i) the sum of the elements of each vector is constant, and (ii) only a small number of elements is nonzero. These constraints make it difficult for existing MCMC algorithms to sample composition ratios. The key points of our approach are (1) designing an appropriate target distribution by using a condition on the number of nonzero elements, and (2) changing values only between a certain pair of elements in each iteration. Through an experiment on creating a new cocktail, we show that the combination of the proposed method with supervised learning can solve a creative problem."}}
