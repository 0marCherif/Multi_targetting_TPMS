{"id": "uy1prDUVjM", "cdate": 1640995200000, "mdate": 1667380221332, "content": {"title": "Agglomerative Clustering with Threshold Optimization via Extreme Value Theory", "abstract": "Clustering is a critical part of many tasks and, in most applications, the number of clusters in the data are unknown and must be estimated. This paper presents an Extreme Value Theory-based approach to threshold selection for clustering, proving that the &ldquo;correct&rdquo; linkage distances must follow a Weibull distribution for smooth feature spaces. Deep networks and their associated deep features have transformed many aspects of learning, and this paper shows they are consistent with our extreme-linkage theory and provide Unreasonable Clusterability. We show how our novel threshold selection can be applied to both classic agglomerative clustering and the more recent FINCH (First Integer Neighbor Clustering Hierarchy) algorithm. Our evaluation utilizes over a dozen different large-scale vision datasets/subsets, including multiple face-clustering datasets and ImageNet for both in-domain and, more importantly, out-of-domain object clustering. Across multiple deep features clustering tasks with very different characteristics, our novel automated threshold selection performs well, often outperforming state-of-the-art clustering techniques even when they select parameters on the test set."}}
{"id": "uD_sHKd36q5z", "cdate": 1640995200000, "mdate": 1667380221534, "content": {"title": "Consistency and Accuracy of CelebA Attribute Values", "abstract": "We report the first analysis of the experimental foundations of facial attribute classification. An experiment with two annotators independently assigning values shows that only 12 of 40 commonly-used attributes are assigned values with >= 95% consistency, and that three (high cheekbones, pointed nose, oval face) have random consistency (50%). These results show that the binary face attributes currently used in this research area could re-focused to be more objective. We identify 5,068 duplicate face appearances in CelebA, the most widely used dataset in this research area, and find that individual attributes have contradicting values on from 10 to 860 of 5,068 duplicates. Manual audit of a subset of CelebA estimates error rates as high as 40% for (no beard=false), even though the labeling consistency experiment indicates that no beard could be assigned with >= 95% consistency. Selecting the mouth slightly open (MSO) attribute for deeper analysis, we estimate the error rate for (MSO=true) at about 20% and for (MSO=false) at about 2%. We create a corrected version of the MSO attribute values, and compare classification models created using the original versus corrected values. The corrected values enable a model that achieves higher accuracy than has been previously reported for MSO. Also, ScoreCAM visualizations show that the model created using the corrected attribute values is in fact more focused on the mouth region of the face. These results show that the error rate in the current CelebA attribute values should be reduced in order to enable learning of better models. The corrected attribute values for CelebA's MSO and the CelebA facial hair attributes will be made available upon publication."}}
{"id": "STA7X3ht66", "cdate": 1640995200000, "mdate": 1667380221326, "content": {"title": "Large-Scale Open-Set Classification Protocols for ImageNet", "abstract": "Open-Set Classification (OSC) intends to adapt closed-set classification models to real-world scenarios, where the classifier must correctly label samples of known classes while rejecting previously unseen unknown samples. Only recently, research started to investigate on algorithms that are able to handle these unknown samples correctly. Some of these approaches address OSC by including into the training set negative samples that a classifier learns to reject, expecting that these data increase the robustness of the classifier on unknown classes. Most of these approaches are evaluated on small-scale and low-resolution image datasets like MNIST, SVHN or CIFAR, which makes it difficult to assess their applicability to the real world, and to compare them among each other. We propose three open-set protocols that provide rich datasets of natural images with different levels of similarity between known and unknown classes. The protocols consist of subsets of ImageNet classes selected to provide training and testing data closer to real-world scenarios. Additionally, we propose a new validation metric that can be employed to assess whether the training of deep learning models addresses both the classification of known samples and the rejection of unknown samples. We use the protocols to compare the performance of two baseline open-set algorithms to the standard SoftMax baseline and find that the algorithms work well on negative samples that have been seen during training, and partially on out-of-distribution detection tasks, but drop performance in the presence of samples from previously unseen unknown classes."}}
{"id": "G0cbB73jgiV", "cdate": 1640995200000, "mdate": 1667380221307, "content": {"title": "Eight Years of Face Recognition Research: Reproducibility, Achievements and Open Issues", "abstract": "Automatic face recognition is a research area with high popularity. Many different face recognition algorithms have been proposed in the last thirty years of intensive research in the field. With the popularity of deep learning and its capability to solve a huge variety of different problems, face recognition researchers have concentrated effort on creating better models under this paradigm. From the year 2015, state-of-the-art face recognition has been rooted in deep learning models. Despite the availability of large-scale and diverse datasets for evaluating the performance of face recognition algorithms, many of the modern datasets just combine different factors that influence face recognition, such as face pose, occlusion, illumination, facial expression and image quality. When algorithms produce errors on these datasets, it is not clear which of the factors has caused this error and, hence, there is no guidance in which direction more research is required. This work is a followup from our previous works developed in 2014 and eventually published in 2016, showing the impact of various facial aspects on face recognition algorithms. By comparing the current state-of-the-art with the best systems from the past, we demonstrate that faces under strong occlusions, some types of illumination, and strong expressions are problems mastered by deep learning algorithms, whereas recognition with low-resolution images, extreme pose variations, and open-set recognition is still an open problem. To show this, we run a sequence of experiments using six different datasets and five different face recognition algorithms in an open-source and reproducible manner. We provide the source code to run all of our experiments, which is easily extensible so that utilizing your own deep network in our evaluation is just a few minutes away."}}
{"id": "pChGgJk1-z", "cdate": 1609459200000, "mdate": 1667380221327, "content": {"title": "ComFu: Improving Visual Clustering by Commonality Fusion", "abstract": "Clustering has a long history in the computer vision community with a myriad of applications. Clustering is a family of unsupervised machine learning techniques that group samples based on similarity. Multiple ad hoc techniques have been developed to combine or fuse clustering algorithms with dozens of different clustering techniques. This paper presents a new formalization of clustering fusion and introduces the novel Commonality Fusion (ComFu) technique to combine the advantages of different clustering algorithms by fusing their results on datasets. ComFu builds a pairwise commonality matrix of samples by computing how many clustering algorithms group each pair together. Using this matrix, ComFu builds initial clusters of points with high commonality and then assigns points with low commonality to clusters with the highest average commonality to those points with an automatic distance measure selection process. We start experiments by comparing ComFu with the prior state-of-the-art cluster fusion algorithms on eight UCI datasets. We then evaluate ComFu on practical vision clustering problems, advancing the state-of-the-art on a wide range of applications including clustering faces in the IJB-B dataset. We apply ComFu to fuse FINCH, the state-of-the-art \u201dparameter-free\u201d approach, which returns multiple partitions and can use multiple distance metrics, and show that ComFu improves their result by fusing over metrics and partitions."}}
{"id": "i0zn-IqgaS0", "cdate": 1577836800000, "mdate": 1667380221543, "content": {"title": "Enhancing Open-Set Recognition using Clustering-based Extreme Value Machine (C-EVM)", "abstract": "In real-world deployments, machine learning applications find challenges when accessing ever-increasing volumes of data - the real world is open and often presents data from classes not seen in training. Open-set recognition is a growing area of machine learning addressing such problems. This research work advances the state-of-the-art in open-set recognition, the Extreme Value Machine (EVM), with a novel clustering-based extension (C-EVM) during training to improve the end-to-end prediction performance. The C-EVM combines Density-based spatial clustering of applications with noise (DBSCAN)-based clustering with a novel Nearby Clusters (NC) algorithm during model fitting to reduce computation while improving accuracy. Our experiments show a statistically significant improvement of 5-10% in macro F1-score over the state-of-the-art EVM on open-set testing using the KDD CUP-99 data set. Past work on open set recognition often traded improved open-set robustness for a decrease in closed-set accuracy, whereas C-EVM outperforms the EVM in both closed-set and open-set recognition. Testing on subsets of ImageNet-2012 with varying numbers of classes, the C-EVM statistically significantly out performs EVM when using deep features. A parameterless Hierarchical DBSCAN (HDBSCAN)-based C-EVM variant is introduced as part of this work that scales well for large data sets. Finally, both EVM and C-EVM can operate as kernel-free incremental learners, enabling these open-set multi-class classifiers to be useful for streaming and big data applications."}}
{"id": "_Q0u2kvo0gz", "cdate": 1577836800000, "mdate": 1667380221321, "content": {"title": "The Overlooked Elephant of Object Detection: Open Set", "abstract": "Even though object detection is a popular area of research that has found considerable applications in the real world, it has some fundamental aspects that have never been formally discussed and experimented. One of the core aspects of evaluating object detectors has been the ability to avoid false detections. While major datasets like PASCAL VOC or MSCOCO extensively test the detectors on their ability to avoid false positives, they do not differentiate between their closed-set and open-set performance. Despite systems being trained to reject everything other than the classes of interest, unknown objects from the open world end up being incorrectly detected as known objects, often with very high confidence. This paper is the first to formalize the problem of open-set object detection and propose the first open-set object detection protocol. Moreover, the paper provides a new evaluation metric to analyze the performance of some state-of-the-art detectors and discusses their performance differences."}}
{"id": "9iaWFn0Jre", "cdate": 1577836800000, "mdate": 1667380221326, "content": {"title": "Watchlist Adaptation: Protecting the Innocent", "abstract": "One of the most important government applications of face recognition is the watchlist problem, where the goal is to identify a few people enlisted on a watchlist while ignoring the majority of innocent passersby. Since watchlists dynamically change and training times can be expensive, the deployed approaches use pre-trained deep networks only to provide deep features for face comparison. Since these networks never specifically trained on the operational setting or faces from the watchlist, the system will often confuse them with the faces of innocent non-watchlist subjects leading to difficult situations, e.g., being detained at the airport to resolve their identity. We develop a novel approach to take an existing pre-trained face network and use adaptation layers trained with our recently developed Objectosphere loss to provide an open-set recognition system that is rapidly adapted to the gallery while also ignoring non-watchlist faces as well as any background detections from the face detector. While our adapter network can be quickly trained without the need of re-training the entire representation network, it can also significantly improve the performance of any state-of-the-art face recognition network like VGG2. We experiment with the largest open-set face recognition dataset, the UnConstrained College Students (UCCS). It contains real surveillance camera stills including both known and unknown subjects, as well as many non-face regions from the face detector. We show that the Objectosphere approach is able to reduce the feature magnitude of unknown subjects as well as background detections, so that we can apply a specifically designed similarity function on the deep features of the Objectosphere network, which works much better than the direct prediction of the very same network. Additionally, our approach outperforms the VGG2 baseline by a large margin by rejecting the non-face data, and also outperforms prior state-of-the-art open-set recognition algorithms on the VGG2 baseline data."}}
{"id": "1vUreSy9_1", "cdate": 1577836800000, "mdate": 1667380221332, "content": {"title": "LTV-MPC Based Trajectory Planning Considering Uncertain Object Prediction Through Adaptive Potential Fields", "abstract": "In this paper a combined longitudinal and lateral trajectory planning approach is presented using an linear-time-varying model predictive control (LTV-MPC) scheme. To consider uncertain moving object state and prediction information, an adaptive potential field is modelled generating a time-varying obstacle cost-term. Approximating the nonlinear planning problem along the previous planned control and state sequence results in an LTV-MPC planning problem and ensures small approximation errors of the original nonlinear formulation. The proposed LTV-MPC planning approach is analyzed in a collision avoidance scenario with a pedestrian. The results show a more defensive maneuver integrating the uncertain object prediction information in the planning problem and the proposed approximation scheme delivers a difference of 492,18 % in the relative approximation error of the cost function in the presented scenario compared to the widely used approach, approximating the planning problem by using the current vehicle state."}}
{"id": "gWDsJmpQaMJ", "cdate": 1546300800000, "mdate": 1667380221323, "content": {"title": "Facial attributes: Accuracy and adversarial robustness", "abstract": ""}}
