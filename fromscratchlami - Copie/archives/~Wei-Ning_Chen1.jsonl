{"id": "ClgKjcje7Uk", "cdate": 1682087853592, "mdate": 1682087853592, "content": {"title": "The Fundamental Price of Secure Aggregation in Differentially Private Federated Learning.", "abstract": "We consider the problem of training a $d$ dimensional model with distributed differential privacy (DP) where secure aggregation (SecAgg) is used to ensure that the server only sees the noisy sum of $n$ model updates in every training round. Taking into account the constraints imposed by SecAgg, we characterize the fundamental communication cost required to obtain the best accuracy achievable under $\\varepsilon$ central DP (i.e. under a fully trusted server and no communication constraints). Our results show that $\\tilde{O}\\lp \\min(n^2\\varepsilon^2, d) \\rp$ bits per client are both sufficient and necessary, and this fundamental limit can be achieved by a linear scheme based on sparse random projections. This provides a significant improvement relative to state-of-the-art SecAgg distributed DP schemes which use $\\tilde{O}(d\\log(d/\\varepsilon^2))$ bits per client. \n  \nEmpirically, we evaluate our proposed scheme on real-world federated learning tasks. We find that our theoretical analysis is well matched in practice. In particular, we show that we can reduce the communication cost to under $1.78$ bits per parameter in realistic privacy settings without decreasing test-time performance. Our work hence theoretically and empirically specifies the fundamental price of using SecAgg. "}}
{"id": "Q7fNiyQWN-", "cdate": 1675209600000, "mdate": 1684216984461, "content": {"title": "Breaking the Communication-Privacy-Accuracy Trilemma", "abstract": "Two major challenges in distributed learning and estimation are 1) preserving the privacy of the local samples; and 2) communicating them efficiently to a central server, while achieving high accuracy for the end-to-end task. While there has been significant interest in addressing each of these challenges separately in the recent literature, treatments that simultaneously address both challenges are still largely missing. In this paper, we develop novel encoding and decoding mechanisms that simultaneously achieve optimal privacy and communication efficiency in various canonical settings. In particular, we consider the problems of mean estimation and frequency estimation under <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"> <tex-math notation=\"LaTeX\">$\\varepsilon $ </tex-math></inline-formula> -local differential privacy and <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"> <tex-math notation=\"LaTeX\">$b$ </tex-math></inline-formula> -bit communication constraints. For mean estimation, we propose the SQKR mechanism, a scheme based on Kashin\u2019s representation and random sampling, with order-optimal estimation error under both constraints. We further apply SQKR to distributed SGD and obtain a communication efficient and (locally) differentially private distributed SGD protocol. For frequency estimation, we present the RHR mechanism, a scheme that leverages the recursive structure of Walsh-Hadamard matrices and achieves order-optimal estimation error for all privacy levels and communication budgets. As a by-product, we also construct a distribution estimation mechanism that is rate-optimal for all privacy regimes and communication constraints, extending recent work that is limited to <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"> <tex-math notation=\"LaTeX\">$b=1$ </tex-math></inline-formula> and <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"> <tex-math notation=\"LaTeX\">$\\varepsilon =O(1)$ </tex-math></inline-formula> . Our results demonstrate that intelligent encoding under joint privacy and communication constraints can yield a performance that matches the optimal accuracy achievable under either constraint alone. In other words, the optimal performance is determined by the more stringent of the two constraints, and the less stringent constraint can be satisfied for free."}}
{"id": "vjwY7IKyN5", "cdate": 1672531200000, "mdate": 1684216984807, "content": {"title": "Privacy Amplification via Compression: Achieving the Optimal Privacy-Accuracy-Communication Trade-off in Distributed Mean Estimation", "abstract": "Privacy and communication constraints are two major bottlenecks in federated learning (FL) and analytics (FA). We study the optimal accuracy of mean and frequency estimation (canonical models for FL and FA respectively) under joint communication and $(\\varepsilon, \\delta)$-differential privacy (DP) constraints. We show that in order to achieve the optimal error under $(\\varepsilon, \\delta)$-DP, it is sufficient for each client to send $\\Theta\\left( n \\min\\left(\\varepsilon, \\varepsilon^2\\right)\\right)$ bits for FL and $\\Theta\\left(\\log\\left( n\\min\\left(\\varepsilon, \\varepsilon^2\\right) \\right)\\right)$ bits for FA to the server, where $n$ is the number of participating clients. Without compression, each client needs $O(d)$ bits and $\\log d$ bits for the mean and frequency estimation problems respectively (where $d$ corresponds to the number of trainable parameters in FL or the domain size in FA), which means that we can get significant savings in the regime $ n \\min\\left(\\varepsilon, \\varepsilon^2\\right) = o(d)$, which is often the relevant regime in practice. Our algorithms leverage compression for privacy amplification: when each client communicates only partial information about its sample, we show that privacy can be amplified by randomly selecting the part contributed by each client."}}
{"id": "pKIxxXoHEZ6", "cdate": 1640995200000, "mdate": 1684216984563, "content": {"title": "The Poisson binomial mechanism for secure and private federated learning", "abstract": "We introduce the Poisson Binomial mechanism (PBM), a discrete differential privacy mechanism for distributed mean estimation (DME) with applications to federated learning and analytics. We provide a tight analysis of its privacy guarantees, showing that it achieves the same privacy-accuracy trade-offs as the continuous Gaussian mechanism. Our analysis is based on a novel bound on the R\\'enyi divergence of two Poisson binomial distributions that may be of independent interest. Unlike previous discrete DP schemes based on additive noise, our mechanism encodes local information into a parameter of the binomial distribution, and hence the output distribution is discrete with bounded support. Moreover, the support does not increase as the privacy budget $\\varepsilon \\rightarrow 0$ as in the case of additive schemes which require the addition of more noise to achieve higher privacy; on the contrary, the support becomes smaller as $\\varepsilon \\rightarrow 0$. The bounded support enables us to combine our mechanism with secure aggregation (SecAgg), a multi-party cryptographic protocol, without the need of performing modular clipping which results in an unbiased estimator of the sum of the local vectors. This in turn allows us to apply it in the private FL setting and provide an upper bound on the convergence rate of the SGD algorithm. Moreover, since the support of the output distribution becomes smaller as $\\varepsilon \\rightarrow 0$, the communication cost of our scheme decreases with the privacy constraint $\\varepsilon$, outperforming all previous distributed DP schemes based on additive noise in the high privacy or low communication regimes."}}
{"id": "cz5kpj7VbL", "cdate": 1640995200000, "mdate": 1684216984910, "content": {"title": "The Poisson Binomial Mechanism for Unbiased Federated Learning with Secure Aggregation", "abstract": "We introduce the Poisson Binomial mechanism (PBM), a discrete differential privacy mechanism for distributed mean estimation (DME) with applications to federated learning and analytics. We provide ..."}}
{"id": "YDwtwUqriZP", "cdate": 1640995200000, "mdate": 1681673021820, "content": {"title": "The communication cost of security and privacy in federated frequency estimation", "abstract": "We consider the federated frequency estimation problem, where each user holds a private item $X_i$ from a size-$d$ domain and a server aims to estimate the empirical frequency (i.e., histogram) of $n$ items with $n \\ll d$. Without any security and privacy considerations, each user can communicate its item to the server by using $\\log d$ bits. A naive application of secure aggregation protocols would, however, require $d\\log n$ bits per user. Can we reduce the communication needed for secure aggregation, and does security come with a fundamental cost in communication? In this paper, we develop an information-theoretic model for secure aggregation that allows us to characterize the fundamental cost of security and privacy in terms of communication. We show that with security (and without privacy) $\\Omega\\left( n \\log d \\right)$ bits per user are necessary and sufficient to allow the server to compute the frequency distribution. This is significantly smaller than the $d\\log n$ bits per user needed by the naive scheme, but significantly higher than the $\\log d$ bits per user needed without security. To achieve differential privacy, we construct a linear scheme based on a noisy sketch which locally perturbs the data and does not require a trusted server (a.k.a. distributed differential privacy). We analyze this scheme under $\\ell_2$ and $\\ell_\\infty$ loss. By using our information-theoretic framework, we show that the scheme achieves the optimal accuracy-privacy trade-off with optimal communication cost, while matching the performance in the centralized case where data is stored in the central server."}}
{"id": "XCbg7_o1nk", "cdate": 1640995200000, "mdate": 1681488142105, "content": {"title": "Optimal Compression of Locally Differentially Private Mechanisms", "abstract": ""}}
{"id": "L4l8pzjzTXc", "cdate": 1640995200000, "mdate": 1683913999477, "content": {"title": "Estimating Sparse Distributions Under Joint Communication and Privacy Constraints", "abstract": "We consider the problem of estimating a d-dimensional, s-sparse discrete distribution from independent samples subject to a joint b-bit communication constraint and \u03b5-local differential privacy constraint. As an intermediate step, we introduce the Privatized Random Hashing (PRH) scheme, which concatenates a hashing-based quantization strategy with the randomized response privacy mechanism. Despite its simplicity, PRH turns out to achieve the order-optimal minimax estimation error and sample complexity in the standard (non-sparse) estimation setting, for all communication and privacy regimes. We then address the sparse case by developing a two-stage, non-interactive estimation scheme based on PRH in which the first half of samples are used to localize the unknown support of the distribution, and the remaining samples are used to obtain precise estimates of the individual probabilities. Using this scheme, we characterize the minimax sample complexity of the sparse case up to logarithmic factors, unifying existing results in the literature that considered communication and privacy constraints separately."}}
{"id": "Ig57f2RyvM", "cdate": 1640995200000, "mdate": 1675041243839, "content": {"title": "The Fundamental Price of Secure Aggregation in Differentially Private Federated Learning", "abstract": "We consider the problem of training a $d$ dimensional model with distributed differential privacy (DP) where secure aggregation (SecAgg) is used to ensure that the server only sees the noisy sum of $n$ model updates in every training round. Taking into account the constraints imposed by SecAgg, we characterize the fundamental communication cost required to obtain the best accuracy achievable under $\\varepsilon$ central DP (i.e. under a fully trusted server and no communication constraints). Our results show that $\\tilde{O}\\left( \\min(n^2\\varepsilon^2, d) \\right)$ bits per client are both sufficient and necessary, and this fundamental limit can be achieved by a linear scheme based on sparse random projections. This provides a significant improvement relative to state-of-the-art SecAgg distributed DP schemes which use $\\tilde{O}(d\\log(d/\\varepsilon^2))$ bits per client. Empirically, we evaluate our proposed scheme on real-world federated learning tasks. We find that our theoretical analysis is well matched in practice. In particular, we show that we can reduce the communication cost significantly to under $1.2$ bits per parameter in realistic privacy settings without decreasing test-time performance. Our work hence theoretically and empirically specifies the fundamental price of using SecAgg."}}
{"id": "F8yZgsmHWZy", "cdate": 1640995200000, "mdate": 1675041243832, "content": {"title": "The Fundamental Price of Secure Aggregation in Differentially Private Federated Learning", "abstract": "We consider the problem of training a $d$ dimensional model with distributed differential privacy (DP) where secure aggregation (SecAgg) is used to ensure that the server only sees the noisy sum of..."}}
