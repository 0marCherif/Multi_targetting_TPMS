{"id": "3GN0UnT6334", "cdate": 1706737211478, "mdate": 1706737211478, "content": {"title": "Beyond plain toxic: building datasets for detection of flammable topics and inappropriate statements", "abstract": "Toxicity on the Internet is an acknowledged problem. It includes a wide range of actions from the use of obscene words to offenses and hate speech toward particular users or groups of people. However, there also exist other types of inappropriate messages which are usually not viewed as toxic as they do not contain swear words or explicit offenses. Such messages can contain covert toxicity or generalizations, incite harmful actions (crime, suicide, drug use), and provoke \u201cheated\u201d discussions. These messages are often related to particular sensitive topics, e.g. politics, sexual minorities, or social injustice. Such topics tend to yield toxic emotional reactions more often than other topics, e.g. cars or computing. At the same time, not all messages within \u201cflammable\u201d topics are inappropriate. This work focuses on automatically detecting inappropriate language in natural texts. This is crucial for monitoring user-generated content and developing dialogue systems and AI assistants. While many works focus on toxicity detection, we highlight the fact that texts can be harmful without being toxic or containing obscene language. Blind censorship based on keywords is a common approach to address these issues, but it limits a system\u2019s functionality. This work proposes a safe and effective solution to serve broad user needs and develop necessary resources and tools. Thus, machinery for inappropriateness detection could be useful (i) for making communication on the Internet safer, more productive, and inclusive by flagging truly inappropriate content while not banning messages blindly by topic; (ii) for detection of inappropriate messages generated by automatic systems, e.g. neural chatbots, due to biases in training data; (iii) for debiasing training data for language models (e.g. BERT and GPT-2). Towards this end, in this work, we present two text collections labeled according to a binary notion of inappropriateness (124,597 samples) and a multinomial notion of sensitive topic (33,904 samples). Assuming that the notion of inappropriateness is common among people of the same culture, we base our approach on a human intuitive understanding of what is not acceptable and harmful. To devise an objective view of inappropriateness, we define it in a data-driven way through crowdsourcing. Namely, we run a large-scale annotation study asking workers if a given chatbot-generated utterance could harm the reputation of the company that created this chatbot. High values of inter-annotator agreement suggest that the notion of inappropriateness exists and can be uniformly understood by different people. To define the notion of a sensitive topic in an objective way we use guidelines suggested by specialists in the Legal and PR departments of a large company. We use the collected datasets to train inappropriateness and sensitive topic classifiers employing both classic and Transformer-based models."}}
{"id": "xhimDdvoOT", "cdate": 1706737141193, "mdate": 1706737141193, "content": {"title": "Don\u2019t Lose the Message While Paraphrasing: A Study on Content Preserving Style Transfer", "abstract": "Text style transfer techniques are gaining popularity in natural language processing allowing paraphrasing text in the required form: from toxic to neural, from formal to informal, from old to the modern English language, etc. Solving the task is not sufficient to generate some neural/informal/modern text, but it is important to preserve the original content unchanged. This requirement becomes even more critical in some applications such as style transfer of goal-oriented dialogues where the factual information shall be kept to preserve the original message, e.g. ordering a certain type of pizza to a certain address at a certain time. The aspect of content preservation is critical for real-world applications of style transfer studies, but it has received little attention. To bridge this gap we perform a comparison of various style transfer models on the example of the formality transfer domain. To perform a study of the content preservation abilities of various style transfer methods we create a parallel dataset of formal vs. informal task-oriented dialogues. The key difference between our dataset and the existing ones like GYAFC [17] is the presence of goal-oriented dialogues with predefined semantic slots essential to be kept during paraphrasing, e.g. named entities. This additional annotation allowed us to conduct a precise comparative study of several state-of-the-art techniques for style transfer. Another result of our study is a modification of the unsupervised method LEWIS [19] which yields a substantial improvement over the original method and all evaluated baselines on the proposed task."}}
{"id": "meAkNSWeWPy", "cdate": 1706736700381, "mdate": 1706736700381, "content": {"title": "Detecting Text Formality: A Study of Text Classification Approaches", "abstract": "Formality is one of the important characteristics of text documents. The automatic detection of the formality level of a text is potentially beneficial for various natural language processing tasks. Before, two large-scale datasets were introduced for multiple languages featuring formality annotation\u2014GYAFC and X-FORMAL. However, they were primarily used for the training of style transfer models. At the same time, the detection of text formality on its own may also be a useful application. This work proposes the first to our knowledge systematic study of formality detection methods based on statistical, neural-based, and Transformer-based machine learning methods and delivers the best-performing models for public usage. We conducted three types of experiments \u2013 monolingual, multilingual, and cross-lingual. The study shows the overcome of Char BiLSTM model over Transformer-based ones for the monolingual and multilingual formality classification task, while Transformer-based classifiers are more stable to cross-lingual knowledge transfer."}}
{"id": "c_uDQIhBP96", "cdate": 1706736621942, "mdate": 1706736621942, "content": {"title": "Error syntax aware augmentation of feedback comment generation dataset", "abstract": "This paper presents a solution to the GenChal 2022 shared task dedicated to feedback comment generation for writing learning. In terms of this task given a text with an error and a span of the error, a system generates an explanatory note that helps the writer (language learner) to improve their writing skills. Our solution is based on fine-tuning the T5 model on the initial dataset augmented according to syntactical dependencies of the words located within indicated error span. The solution of our team \u2018nigula\u2019 obtained second place according to manual evaluation by the organizers."}}
{"id": "U55GSyKUzih", "cdate": 1706736478203, "mdate": 1706736478203, "content": {"title": "Studying the role of named entities for content preservation in text style transfer", "abstract": "Text style transfer techniques are gaining popularity in Natural Language Processing, finding various applications such as text detoxification, sentiment, or formality transfer. However, the majority of the existing approaches were tested on such domains as online communications on public platforms, music, or entertainment yet none of them were applied to the domains which are typical for task-oriented production systems, such as personal plans arrangements (e.g. booking of flights or reserving a table in a restaurant). We fill this gap by studying formality transfer in this domain.\n\nWe noted that, the texts in this domain are full of named entities, which are very important for keeping the original sense of the text. Indeed, if for example, someone communicates destination city of a flight is must not be altered. Thus, we concentrate on the role of named entities in content preservation for formality text style transfer.\n\nWe collect a new dataset for the evaluation of content similarity measures in text style transfer. It is taken from a corpus of task-oriented dialogues and contains many important entities related to realistic requests that make this dataset particularly useful for testing style transfer models before using them in production. Besides, we perform an error analysis of a pre-trained formality transfer model and introduce a simple technique to use information about named entities to enhance the performance of baseline content similarity measures used in text style transfer."}}
{"id": "tYhuLJozbn9", "cdate": 1706736379438, "mdate": 1706736379438, "content": {"title": "A large-scale computational study of content preservation measures for text style transfer and paraphrase generation", "abstract": "Text style transfer and paraphrasing of texts are actively growing areas of NLP, dozens of methods for solving these tasks have been recently introduced. In both tasks, the system is supposed to generate a text which should be semantically similar to the input text. Therefore, these tasks are dependent on methods of measuring textual semantic similarity. However, it is still unclear which measures are the best to automatically evaluate content preservation between original and generated text. According to our observations, many researchers still use BLEU-like measures, while there exist more advanced measures including neural-based that significantly outperform classic approaches. The current problem is the lack of a thorough evaluation of the available measures. We close this gap by conducting a large-scale computational study by comparing 57 measures based on different principles on 19 annotated datasets. We show that measures based on cross-encoder models outperform alternative approaches in almost all cases. We also introduce the Mutual Implication Score (MIS), a measure that uses the idea of paraphrasing as a bidirectional entailment and outperforms all other measures on the paraphrase detection task and performs on par with the best measures in the text style transfer task."}}
{"id": "J0xXJ46V0a", "cdate": 1706736289490, "mdate": 1706736289490, "content": {"title": "Detecting Inappropriate Messages on Sensitive Topics that Could Harm a Company's Reputation", "abstract": "Not all topics are equally \u201cflammable\u201d in terms of toxicity: a calm discussion of turtles or fishing less often fuels inappropriate toxic dialogues than a discussion of politics or sexual minorities. We define a set of sensitive topics that can yield inappropriate and toxic messages and describe the methodology of collecting and labelling a dataset for appropriateness. While toxicity in user-generated data is well-studied, we aim at defining a more fine-grained notion of inappropriateness. The core of inappropriateness is that it can harm the reputation of a speaker. This is different from toxicity in two respects: (i) inappropriateness is topic-related, and (ii) inappropriate message is not toxic but still unacceptable. We collect and release two datasets for Russian: a topic-labelled dataset and an appropriateness-labelled dataset. We also release pre-trained classification models trained on this data."}}
{"id": "Pmy93W8QwYY", "cdate": 1697834505902, "mdate": 1697834505902, "content": {"title": "Efficient GPT Model Pre-training using Tensor Train Matrix Representation", "abstract": "Large-scale transformer models have shown remarkable\nperformance in language modelling\ntasks. However, such models feature billions\nof parameters, leading to difficulties in their\ndeployment and prohibitive training costs from\nscratch. To reduce the number of parameters in\nthe GPT-2 (Radford et al., 2019) architecture,\nwe replace the matrices of fully-connected layers\nwith the corresponding Tensor Train Matrix\n(TTM) (Oseledets, 2010) structure. Finally,\nwe customize forward and backward operations\nthrough the TTM-based layer for simplicity and\nthe stability of further training. The resulting\nGPT-2-based model stores up to 40% fewer parameters,\nshowing the perplexity comparable to\nthe original model. On the downstream tasks,\nincluding language understanding and text summarization,\nthe model performs similarly to\nthe original GPT-2 model. The proposed tensorized\nlayers can be used to efficiently pretrain\nother Transformer models."}}
{"id": "lf5Jh8xE0i", "cdate": 1697834339995, "mdate": 1697834339995, "content": {"title": "A Computational Study of Matrix Decomposition Methods for Compression of Pre-trained Transformers", "abstract": "Transformer-based models have significantly\nadvanced the field of Natural Language Processing.\nHowever, their large size and computational\ncomplexity present challenges. As a\nresult, there is considerable interest in developing\napproaches to compress these models without\ncompromising their performance on specific\ntasks. This paper presents a comparative\nstudy of low-rank matrix and tensor factorization\ntechniques for compressing Transformerbased\nmodels. Specifically, we apply Singular\nValue Decomposition (SVD) and Tensor\nTrain Matrix (TTM) decomposition to represent\nthe fully connected layers in a compressed\nform. Following Hsu et al. (2022), we extend\nthe FWSVD approach by adding Fisher information\nto the TTM decomposition and present\na novel method called FWTTM.\nOur experimental results indicate that the efficiency\nof these methods varies with the compression\nlevel. Notably, integrating Fisher information\nto align task and decomposition objectives\nenhances the performance of factorized\nwith TTM transformer-based models and\nencoder-decoders."}}
{"id": "gttCeV9_Csy", "cdate": 1609459200000, "mdate": null, "content": {"title": "How Certain is Your Transformer?", "abstract": "Artem Shelmanov, Evgenii Tsymbalov, Dmitri Puzyrev, Kirill Fedyanin, Alexander Panchenko, Maxim Panov. Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume. 2021."}}
