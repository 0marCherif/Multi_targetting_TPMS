{"id": "eVERqUmqqSV", "cdate": 1679902581421, "mdate": 1679902581421, "content": {"title": "NeRFLiX: High-Quality Neural View Synthesis by Learning a Degradation-Driven Inter-viewpoint MiXer", "abstract": "Neural radiance fields (NeRF) show great success in novel view synthesis. However, in real-world scenes, recovering high-quality details from the source images is still challenging for the existing NeRF-based approaches, due to the potential imperfect calibration information and scene representation inaccuracy. Even with high-quality training frames, the synthetic novel views produced by NeRF models still suffer from notable rendering artifacts, such as noise, blur, etc. Towards to improve the synthesis quality of NeRF-based approaches, we propose NeRFLiX, a general NeRF-agnostic restorer paradigm by learning a degradation-driven inter-viewpoint mixer. Specially, we design a NeRF-style degradation modeling approach and construct large-scale training data, enabling the possibility of effectively removing NeRF-native rendering artifacts for existing deep neural networks. Moreover, beyond the degradation removal, we propose an inter-viewpoint aggregation framework that is able to fuse highly related high-quality training images, pushing the performance of cutting-edge NeRF models to entirely new levels and producing highly photo-realistic synthetic views."}}
{"id": "2Hd3-cAL3G", "cdate": 1668137340813, "mdate": 1668137340813, "content": {"title": "HEMlets posh: learning part-centric heatmap triplets for 3D human pose and shape estimation", "abstract": "Estimating 3D human pose from a single image is a challenging task. This work attempts to address the uncertainty of lifting\nthe detected 2D joints to the 3D space by introducing an intermediate state - Part-Centric Heatmap Triplets (HEMlets), which shortens\nthe gap between the 2D observation and the 3D interpretation. The HEMlets utilize three joint-heatmaps to represent the relative depth\ninformation of the end-joints for each skeletal body part. In our approach, a Convolutional Network (ConvNet) is first trained to predict\nHEMlets from the input image, followed by a volumetric joint-heatmap regression. We leverage on the integral operation to extract the\njoint locations from the volumetric heatmaps, guaranteeing end-to-end learning. Despite the simplicity of the network design, the\nquantitative comparisons show a significant performance improvement over the best-of-grade methods (e.g., 20 percent on\nHuman3.6M). The proposed method naturally supports training with \u201cin-the-wild\u201d images, where only weakly-annotated relative depth\ninformation of skeletal joints is available. This further improves the generalization ability of our model, as validated by qualitative\ncomparisons on outdoor images. Leveraging the strength of the HEMlets pose estimation, we further design and append a shallow yet\neffective network module to regress the SMPL parameters of the body pose and shape. We term the entire HEMlets-based human\npose and shape recovery pipeline HEMlets PoSh. Extensive quantitative and qualitative experiments on the existing human body\nrecovery benchmarks justify the state-of-the-art results obtained with our HEMlets PoSh approach."}}
{"id": "jUd82qiD2j", "cdate": 1668137261732, "mdate": 1668137261732, "content": {"title": "Revisiting Temporal Alignment for Video Restoration", "abstract": "We consider the single image super-resolution (SISR) problem, where a high-resolution (HR) image is generated based on a low-resolution (LR) input. Recently, generative adversarial networks (GANs) become popular to hallucinate details. Most methods along this line rely on a predefined single-LR-single-HR mapping, which is not flexible enough for the ill-posed SISR task. Also, GAN-generated fake details may often undermine the realism of the whole image. We address these issues by proposing best-buddy GANs (Beby-GAN) for rich-detail SISR. Relaxing the rigid one-to-one constraint, we allow the estimated patches to dynamically seek trustworthy surrogates of supervision during training, which is beneficial to producing more reasonable details. Besides, we propose a region-aware adversarial learning strategy that directs our model to focus on generating details for textured areas adaptively. Extensive experiments justify the effectiveness of our method. An ultra-high-resolution 4K dataset is also constructed to facilitate future super-resolution research."}}
{"id": "wKD2YMJR2f", "cdate": 1668137199579, "mdate": 1668137199579, "content": {"title": "Best-Buddy GANs for Highly Detailed Image Super-Resolution", "abstract": "We consider the single image super-resolution (SISR) problem, where a high-resolution (HR) image is generated based on a low-resolution (LR) input. Recently, generative adversarial networks (GANs) become popular to hallucinate details. Most methods along this line rely on a predefined single-LR-single-HR mapping, which is not flexible enough for the ill-posed SISR task. Also, GAN-generated fake details may often undermine the realism of the whole image. We address these issues by proposing best-buddy GANs (Beby-GAN) for rich-detail SISR. Relaxing the rigid one-to-one constraint, we allow the estimated patches to dynamically seek trustworthy surrogates of supervision during training, which is beneficial to producing more reasonable details. Besides, we propose a region-aware adversarial learning strategy that directs our model to focus on generating details for textured areas adaptively. Extensive experiments justify the effectiveness of our method. An ultra-high-resolution 4K dataset is also constructed to facilitate future super-resolution research."}}
{"id": "Vg2w1HOwh-", "cdate": 1668136622898, "mdate": 1668136622898, "content": {"title": "MAT: Mask-Aware Transformer for Large Hole Image Inpainting", "abstract": "Recent studies have shown the importance of modeling long-range interactions in the inpainting problem. To achieve this goal, existing approaches exploit either standalone attention techniques or transformers, but usually under a low resolution in consideration of computational cost. In this paper, we present a novel transformer-based model for large hole inpainting, which unifies the merits of transformers and convolutions to efficiently process high-resolution images. We carefully design each component of our framework to guarantee the high fidelity and diversity of recovered images. Specifically, we customize an inpainting-oriented transformer block, where the attention module aggregates non-local information only from partial valid tokens, indicated by a dynamic mask. Extensive experiments demonstrate the state-of-the-art performance of the new model on multiple benchmark datasets. Code is released at https://github. com/fenglinglwb/MAT."}}
{"id": "8Sviv6TlFpk", "cdate": 1668136241523, "mdate": 1668136241523, "content": {"title": "Lapar: Linearly-assembled pixel-adaptive regression network for single image super-resolution and beyond", "abstract": "Single image super-resolution (SISR) deals with a fundamental problem of upsampling a low-resolution (LR) image to its high-resolution (HR) version. Last few years have witnessed impressive progress propelled by deep learning methods. However, one critical challenge faced by existing methods is to strike a sweet spot of deep model complexity and resulting SISR quality. This paper addresses this pain point by proposing a linearly-assembled pixel-adaptive regression network (LAPAR), which casts the direct LR to HR mapping learning into a linear coefficient regression task over a dictionary of multiple predefined filter bases. Such a parametric representation renders our model highly lightweight and easy to optimize while achieving state-of-the-art results on SISR benchmarks. Moreover, based on the same idea, LAPAR is extended to tackle other restoration tasks, eg, image denoising and JPEG image deblocking, and again, yields strong performance."}}
{"id": "n6K2EOcom9c", "cdate": 1668136022297, "mdate": 1668136022297, "content": {"title": "Hemlets pose: Learning part-centric heatmap triplets for accurate 3d human pose estimation", "abstract": "Estimating 3D human pose from a single image is a challenging task. This work attempts to address the uncertainty\nof lifting the detected 2D joints to the 3D space by introducing an intermediate state - Part-Centric Heatmap Triplets\n(HEMlets), which shortens the gap between the 2D observation and the 3D interpretation. The HEMlets utilize three\njoint heatmaps to represent the relative depth information\nof the end joints for each skeletal body part. In our approach, a Convolutional Network (ConvNet) is first trained\nto predict HEMlets from the input image, followed by a volumetric joint-heatmap regression. We leverage on the integral operation to extract the joint locations from the volumetric heatmaps, guaranteeing end-to-end learning. Despite the simplicity of the network design, the quantitative\ncomparisons show a significant performance improvement\nover the best-of-grade method (about 20% on Human3.6M).\nThe proposed method naturally supports training with \u201cin-the-wild\u201d images, where only weakly-annotated relative\ndepth information of skeletal joints is available. This further improves the generalization ability of our model, as\nvalidated by qualitative comparisons on outdoor images"}}
{"id": "m_QBSrDDCg", "cdate": 1640995200000, "mdate": 1668157869273, "content": {"title": "Best-Buddy GANs for Highly Detailed Image Super-resolution", "abstract": ""}}
{"id": "e3LoalT7-j", "cdate": 1640995200000, "mdate": 1668157869315, "content": {"title": "MAT: Mask-Aware Transformer for Large Hole Image Inpainting", "abstract": ""}}
{"id": "LGEpA-M157D", "cdate": 1640995200000, "mdate": 1668157869270, "content": {"title": "Revisiting Temporal Alignment for Video Restoration", "abstract": ""}}
