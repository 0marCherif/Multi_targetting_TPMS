{"id": "P5_MrxYJJP0", "cdate": 1675371457910, "mdate": 1675371457910, "content": {"title": "A Nasal Brush-based Classifier of Asthma Identified by Machine Learning Analysis of Nasal RNA Sequence Data", "abstract": "Asthma is a common, under-diagnosed disease affecting all ages. We sought to identify a nasal brush-based classifier of mild/moderate asthma. 190 subjects with mild/moderate asthma and controls underwent nasal brushing and RNA sequencing of nasal samples. A machine learning-based pipeline identified an asthma classifier consisting of 90 genes interpreted via an L2-regularized logistic regression classification model. This classifier performed with strong predictive value and sensitivity across eight test sets, including (1) a test set of independent asthmatic and control subjects profiled by RNA sequencing (positive and negative predictive values of 1.00 and 0.96, respectively; AUC of 0.994), (2) two independent case-control cohorts of asthma profiled by microarray, and (3) five cohorts with other respiratory conditions (allergic rhinitis, upper respiratory infection, cystic fibrosis, smoking), where the classifier had a low to zero misclassification rate. Following validation in large, prospective cohorts, this classifier could be developed into a nasal biomarker of asthma."}}
{"id": "pL3OHNL4F8o", "cdate": 1675371400033, "mdate": 1675371400033, "content": {"title": "Large-scale protein function prediction using heterogeneous ensembles", "abstract": "Heterogeneous ensembles are an effective approach in scenarios where the ideal data type and/or individual predictor are unclear for a given problem. These ensembles have shown promise for protein function prediction (PFP), but their ability to improve PFP at a large scale is unclear. The overall goal of this study is to critically assess this ability of a variety of heterogeneous ensemble methods across a multitude of functional terms, proteins and organisms. Our results show that these methods, especially Stacking using Logistic Regression, indeed produce more accurate predictions for a variety of Gene Ontology terms differing in size and specificity. To enable the application of these methods to other related problems, we have publicly shared the HPC-enabled code underlying this work as LargeGOPred (https://github.com/GauravPandeyLab/LargeGOPred)."}}
{"id": "aRmjTKaN51", "cdate": 1675371295921, "mdate": 1675371295921, "content": {"title": "Objective risk stratification of prostate cancer using machine learning and radiomics applied to multiparametric magnetic resonance images", "abstract": "Multiparametric magnetic resonance imaging (mpMRI) has become increasingly important for the clinical assessment of prostate cancer (PCa), but its interpretation is generally variable due to its relatively subjective nature. Radiomics and classification methods have shown potential for improving the accuracy and objectivity of mpMRI-based PCa assessment. However, these studies are limited to a small number of classification methods, evaluation using the AUC score only, and a non-rigorous assessment of all possible combinations of radiomics and classification methods. This paper presents a systematic and rigorous framework comprised of classification, cross-validation and statistical analyses that was developed to identify the best performing classifier for PCa risk stratification based on mpMRI-derived radiomic features derived from a sizeable cohort. This classifier performed well in an independent validation set, including performing better than PI-RADS v2 in some aspects, indicating the value of objectively interpreting mpMRI images using radiomics and classification methods for PCa risk assessment."}}
{"id": "S-kwLozb_-b", "cdate": 1675371236957, "mdate": 1675371236957, "content": {"title": "NeTFactor, a framework for identifying transcriptional regulators of gene expression-based biomarkers", "abstract": "Biological and regulatory mechanisms underlying many multi-gene expression-based disease biomarkers are often not readily evident. We describe an innovative framework, NeTFactor, that combines network analyses with gene expression data to identify transcription factors (TFs) that significantly and maximally regulate such a biomarker. NeTFactor uses a computationally-inferred context-specific gene regulatory network and applies topological, statistical, and optimization methods to identify regulator TFs. Application of NeTFactor to a multi-gene expression-based asthma biomarker identified ETS translocation variant 4 (ETV4) and peroxisome proliferator-activated receptor gamma (PPARG) as the biomarker\u2019s most significant TF regulators. siRNA-based knock down of these TFs in an airway epithelial cell line model demonstrated significant reduction of cytokine expression relevant to asthma, validating NeTFactor\u2019s top-scoring findings. While PPARG has been associated with airway inflammation, ETV4 has not yet been implicated in asthma, thus indicating the possibility of novel, disease-relevant discovery by NeTFactor. We also show that NeTFactor\u2019s results are robust when the gene regulatory network and biomarker are derived from independent data. Additionally, our application of NeTFactor to a different disease biomarker identified TF regulators of interest. These results illustrate that the application of NeTFactor to multi-gene expression-based biomarkers could yield valuable insights into regulatory mechanisms and biological processes underlying disease."}}
{"id": "moFY7Tj5G9U", "cdate": 1675371179794, "mdate": 1675371179794, "content": {"title": "Clinical features of COVID-19 mortality: development and validation of a clinical prediction model", "abstract": "Background\nThe COVID-19 pandemic has affected millions of individuals and caused hundreds of thousands of deaths worldwide. Predicting mortality among patients with COVID-19 who present with a spectrum of complications is very difficult, hindering the prognostication and management of the disease. We aimed to develop an accurate prediction model of COVID-19 mortality using unbiased computational methods, and identify the clinical features most predictive of this outcome.\n\nMethods\nIn this prediction model development and validation study, we applied machine learning techniques to clinical data from a large cohort of patients with COVID-19 treated at the Mount Sinai Health System in New York City, NY, USA, to predict mortality. We analysed patient-level data captured in the Mount Sinai Data Warehouse database for individuals with a confirmed diagnosis of COVID-19 who had a health system encounter between March 9 and April 6, 2020. For initial analyses, we used patient data from March 9 to April 5, and randomly assigned (80:20) the patients to the development dataset or test dataset 1 (retrospective). Patient data for those with encounters on April 6, 2020, were used in test dataset 2 (prospective). We designed prediction models based on clinical features and patient characteristics during health system encounters to predict mortality using the development dataset. We assessed the resultant models in terms of the area under the receiver operating characteristic curve (AUC) score in the test datasets.\n\nFindings\nUsing the development dataset (n=3841) and a systematic machine learning framework, we developed a COVID-19 mortality prediction model that showed high accuracy (AUC=0\u00b791) when applied to test datasets of retrospective (n=961) and prospective (n=249) patients. This model was based on three clinical features: patient's age, minimum oxygen saturation over the course of their medical encounter, and type of patient encounter (inpatient vs outpatient and telehealth visits).\n\nInterpretation\nAn accurate and parsimonious COVID-19 mortality prediction model based on three features might have utility in clinical settings to guide the management and prognostication of patients affected by this disease. External validation of this prediction model in other populations is needed."}}
{"id": "o-Yjwo5iYyb", "cdate": 1675371115912, "mdate": 1675371115912, "content": {"title": "MetaClean: a machine learning-based classifier for reduced false positive peak detection in untargeted LC\u2013MS metabolomics data", "abstract": "Introduction\nDespite the availability of several pre-processing software, poor peak integration remains a prevalent problem in untargeted metabolomics data generated using liquid chromatography high\u2013resolution mass spectrometry (LC\u2013MS). As a result, the output of these pre-processing software may retain incorrectly calculated metabolite abundances that can perpetuate in downstream analyses.\n\nObjectives\nTo address this problem, we propose a computational methodology that combines machine learning and peak quality metrics to filter out low quality peaks.\n\nMethods\nSpecifically, we comprehensively and systematically compared the performance of 24 different classifiers generated by combining eight classification algorithms and three sets of peak quality metrics on the task of distinguishing reliably integrated peaks from poorly integrated ones. These classifiers were compared to using a residual standard deviation (RSD) cut-off in pooled quality-control (QC) samples, which aims to remove peaks with analytical error.\n\nResults\nThe best performing classifier was found to be a combination of the AdaBoost algorithm and a set of 11 peak quality metrics previously explored in untargeted metabolomics and proteomics studies. As a complementary approach, applying our framework to peaks retained after filtering by 30% RSD across pooled QC samples was able to further distinguish poorly integrated peaks that were not removed from filtering alone. An R implementation of these classifiers and the overall computational approach is available as the MetaClean package at https://CRAN.R-project.org/package=MetaClean.\n\nConclusion\nOur work represents an important step forward in developing an automated tool for filtering out unreliable peak integrations in untargeted LC\u2013MS metabolomics data."}}
{"id": "r7x0ammwrwg", "cdate": 1675371022660, "mdate": 1675371022660, "content": {"title": "Computational performance of heterogeneous ensemble frameworks on high-performance computing platforms", "abstract": "To enable efficient computations on rapidly growing big data, a variety of high-performance computing (HPC) platforms, such as traditional multi-processor systems, Hadoop and cloud computing systems, have been developed. On the analytics side of big data, several innovative machine learning methods have been developed to enable the extraction of accurate and actionable knowledge from large datasets. In particular, heterogeneous ensemble algorithms, which are designed to aggregate an unrestricted variety and number of analytical models, have performed well for a variety of prediction problems. However, the performance of these algorithms in terms of computational metrics, such as time requirement, disk space consumption and memory usage, on these HPC platforms has not been systematically examined yet. Here, we address this gap in knowledge by implementing these algorithms and systematically assessing their computational performance on traditional HPC and Hadoop platforms. Our results show that these implementations used the resources, especially disk space and memory, consistent with the respective designs of the platforms. Furthermore, due to the iterative nature of the heterogeneous ensemble computations, the traditional HPC system executed them faster than Hadoop, since an in-memory design is better suited for them than a disk-based one. Overall, our study sheds new light on the computational performance of ensemble algorithms and software frameworks on two prominent HPC platforms, and offers a systematic methodology for conducting similar assessments for other data analytics methods as well. Basic source code of our heterogeneous ensemble implementations, as well as the HPC performance assessments, are available at https://github.com/GauravPandeyLab/HPC-Ensemble."}}
{"id": "vm6KBk0fvX", "cdate": 1675370918908, "mdate": 1675370918908, "content": {"title": "Predicting youth diabetes risk using NHANES data and machine learning", "abstract": "Prediabetes and diabetes mellitus (preDM/DM) have become alarmingly prevalent among youth in\nrecent years. However, simple questionnaire-based screening tools to reliably assess diabetes risk\nare only available for adults, not youth. As a frst step in developing such a tool, we used a large-scale\ndataset from the National Health and Nutritional Examination Survey (NHANES) to examine the\nperformance of a published pediatric clinical screening guideline in identifying youth with preDM/\nDM based on American Diabetes Association diagnostic biomarkers. We assessed the agreement\nbetween the clinical guideline and biomarker criteria using established evaluation measures\n(sensitivity, specifcity, positive/negative predictive value, F-measure for the positive/negative preDM/\nDM classes, and Kappa). We also compared the performance of the guideline to those of machine\nlearning (ML) based preDM/DM classifers derived from the NHANES dataset. Approximately 29%\nof the 2858 youth in our study population had preDM/DM based on biomarker criteria. The clinical\nguideline had a sensitivity of 43.1% and specifcity of 67.6%, positive/negative predictive values of\n35.2%/74.5%, positive/negative F-measures of 38.8%/70.9%, and Kappa of 0.1 (95%CI: 0.06\u20130.14).\nThe performance of the guideline varied across demographic subgroups. Some ML-based classifers\nperformed comparably to or better than the screening guideline, especially in identifying preDM/DM\nyouth (p = 5.23 \u00d7\u2009\u00ad10\u22125).We demonstrated that a recommended pediatric clinical screening guideline did\nnot perform well in identifying preDM/DM status among youth. Additional work is needed to develop\na simple yet accurate screener for youth diabetes risk, potentially by using advanced ML methods and\na wider range of clinical and behavioral health data."}}
{"id": "UPxp2zwp2_R", "cdate": 1675370843485, "mdate": 1675370843485, "content": {"title": "Integrating multimodal data through interpretable heterogeneous ensembles ", "abstract": "Motivation\nIntegrating multimodal data represents an effective approach to predicting biomedical characteristics, such as protein functions and disease outcomes. However, existing data integration approaches do not sufficiently address the heterogeneous semantics of multimodal data. In particular, early and intermediate approaches that rely on a uniform integrated representation reinforce the consensus among the modalities but may lose exclusive local information. The alternative late integration approach that can address this challenge has not been systematically studied for biomedical problems.\n\nResults\nWe propose Ensemble Integration (EI) as a novel systematic implementation of the late integration approach. EI infers local predictive models from the individual data modalities using appropriate algorithms and uses heterogeneous ensemble algorithms to integrate these local models into a global predictive model. We also propose a novel interpretation method for EI models. We tested EI on the problems of predicting protein function from multimodal STRING data and mortality due to coronavirus disease 2019 (COVID-19) from multimodal data in electronic health records. We found that EI accomplished its goal of producing significantly more accurate predictions than each individual modality. It also performed better than several established early integration methods for each of these problems. The interpretation of a representative EI model for COVID-19 mortality prediction identified several disease-relevant features, such as laboratory test (blood urea nitrogen and calcium) and vital sign measurements (minimum oxygen saturation) and demographics (age). These results demonstrated the effectiveness of the EI framework for biomedical data integration and predictive modeling.\n\nAvailability and implementation\nCode and data are available at https://github.com/GauravPandeyLab/ensemble_integration.\n\nSupplementary information\nSupplementary data are available at Bioinformatics Advances online."}}
{"id": "dm9mvaf9ttU", "cdate": 1675370775284, "mdate": 1675370775284, "content": {"title": "Machine learning\u2013driven identification of early-life air toxic combinations associated with childhood asthma outcomes", "abstract": "Air pollution is a well-known contributor to asthma. Air toxics are hazardous air pollutants that cause or may cause serious health effects. Although individual air toxics have been associated with asthma, only a limited number of studies have specifically examined combinations of air toxics associated with the disease. We geocoded air toxic levels from the US National Air Toxics Assessment (NATA) to residential locations for participants of our AiRway in Asthma (ARIA) study. We then applied Data-driven ExposurE Profile extraction (DEEP), a machine learning\u2013based method, to discover combinations of early-life air toxics associated with current use of daily asthma controller medication, lifetime emergency department visit for asthma, and lifetime overnight hospitalization for asthma. We discovered 20 multi\u2013air toxic combinations and 18 single air toxics associated with at least 1 outcome. The multi\u2013air toxic combinations included those containing acrylic acid, ethylidene dichloride, and hydroquinone, and they were significantly associated with asthma outcomes. Several air toxic members of the combinations would not have been identified by single air toxic analyses, supporting the use of machine learning\u2013based methods designed to detect combinatorial effects. Our findings provide knowledge about air toxic combinations associated with childhood asthma.\n\n"}}
