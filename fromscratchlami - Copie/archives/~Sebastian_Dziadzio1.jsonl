{"id": "wrah_aQ3br", "cdate": 1609459200000, "mdate": 1668215616394, "content": {"title": "Full-Body Motion from a Single Head-Mounted Device: Generating SMPL Poses from Partial Observations", "abstract": "The increased availability and maturity of head-mounted and wearable devices opens up opportunities for remote communication and collaboration. However, the signal streams provided by these devices (e.g., head pose, hand pose, and gaze direction) do not represent a whole person. One of the main open problems is therefore how to leverage these signals to build faithful representations of the user. In this paper, we propose a method based on variational autoencoders to generate articulated poses of a human skeleton based on noisy streams of head and hand pose. Our approach relies on a model of pose likelihood that is novel and theoretically well-grounded. We demonstrate on publicly available datasets that our method is effective even from very impoverished signals and investigate how pose prediction can be made more accurate and realistic."}}
{"id": "I4e5l97y7C", "cdate": 1609459200000, "mdate": 1672169388740, "content": {"title": "Fake it till you make it: face analysis in the wild using synthetic data alone", "abstract": "We demonstrate that it is possible to perform face-related computer vision in the wild using synthetic data alone. The community has long enjoyed the benefits of synthesizing training data with graphics, but the domain gap between real and synthetic data has remained a problem, especially for human faces. Researchers have tried to bridge this gap with data mixing, domain adaptation, and domain-adversarial training, but we show that it is possible to synthesize data with minimal domain gap, so that models trained on synthetic data generalize to real in-the-wild datasets. We describe how to combine a procedurally-generated parametric 3D face model with a comprehensive library of hand-crafted assets to render training images with unprecedented realism and diversity. We train machine learning systems for face-related tasks such as landmark localization and face parsing, showing that synthetic data can both match real data in accuracy as well as open up new approaches where manual labeling would be impossible."}}
{"id": "h43wMja9rmD", "cdate": 1577836800000, "mdate": 1672169388604, "content": {"title": "A high fidelity synthetic face framework for computer vision", "abstract": "Analysis of faces is one of the core applications of computer vision, with tasks ranging from landmark alignment, head pose estimation, expression recognition, and face recognition among others. However, building reliable methods requires time-consuming data collection and often even more time-consuming manual annotation, which can be unreliable. In our work we propose synthesizing such facial data, including ground truth annotations that would be almost impossible to acquire through manual annotation at the consistency and scale possible through use of synthetic data. We use a parametric face model together with hand crafted assets which enable us to generate training data with unprecedented quality and diversity (varying shape, texture, expression, pose, lighting, and hair)."}}
{"id": "F0ar5cLoFw", "cdate": 1420070400000, "mdate": 1672169388741, "content": {"title": "Understanding Context with ContextViewer - Tool for Visualization and Initial Preprocessing of Mobile Sensors Data", "abstract": ""}}
