{"id": "sze_MppYdkD", "cdate": 1640995200000, "mdate": 1664639447166, "content": {"title": "Fundamental Limits on Energy-Delay-Accuracy of In-Memory Architectures in Inference Applications", "abstract": "This article obtains fundamental limits on the computational precision of in-memory computing architectures (IMCs). An IMC noise model and associated signal-to-noise ratio (SNR) metrics are defined and their interrelationships analyzed to show that the accuracy of IMCs is fundamentally limited by the compute SNR ( <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"> <tex-math notation=\"LaTeX\">${\\mathrm {SNR}}_{a}$ </tex-math></inline-formula> ) of its analog core, and that activation, weight, and output (ADC) precision needs to be assigned appropriately for the final output SNR ( <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"> <tex-math notation=\"LaTeX\">${\\mathrm {SNR}}_{T}$ </tex-math></inline-formula> ) to approach <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"> <tex-math notation=\"LaTeX\">${\\mathrm {SNR}}_{a}$ </tex-math></inline-formula> . The minimum precision criterion (MPC) is proposed to minimize the analog-to-digital converter (ADC) precision and hence its overhead. Three in-memory compute models\u2014charge summing (QS), current summing (IS), and charge redistribution (QR)\u2014are shown to underlie most known IMCs. Noise, energy, and delay expressions for the compute models are developed and employed to derive expressions for the SNR, ADC precision, energy, and latency of IMCs. The compute SNR expressions are validated via Monte Carlo simulations in a 65 nm CMOS process. For a 512 row SRAM array, it is shown that: 1) IMCs have an upper bound on their maximum achievable <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"> <tex-math notation=\"LaTeX\">${\\mathrm {SNR}}_{a}$ </tex-math></inline-formula> due to constraints on energy, area and voltage swing, and this upper bound reduces with technology scaling for QS-based architectures; 2) MPC enables <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"> <tex-math notation=\"LaTeX\">${\\mathrm {SNR}}_{T}$ </tex-math></inline-formula> to approach <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"> <tex-math notation=\"LaTeX\">${\\mathrm {SNR}}_{a}$ </tex-math></inline-formula> to be realized with minimal ADC precision; and 3) QS-based (QR-based) architectures are preferred for low (high) compute SNR scenarios."}}
{"id": "ku2uHAt4TqL1", "cdate": 1640995200000, "mdate": 1664639447212, "content": {"title": "Optimal Clipping and Magnitude-aware Differentiation for Improved Quantization-aware Training", "abstract": "Data clipping is crucial in reducing noise in quantization operations and improving the achievable accuracy of quantization-aware training (QAT). Current practices rely on heuristics to set clippin..."}}
{"id": "0un49yQwVH5", "cdate": 1640995200000, "mdate": 1664639447212, "content": {"title": "Optimal Clipping and Magnitude-aware Differentiation for Improved Quantization-aware Training", "abstract": "Data clipping is crucial in reducing noise in quantization operations and improving the achievable accuracy of quantization-aware training (QAT). Current practices rely on heuristics to set clipping threshold scalars and cannot be shown to be optimal. We propose Optimally Clipped Tensors And Vectors (OCTAV), a recursive algorithm to determine MSE-optimal clipping scalars. Derived from the fast Newton-Raphson method, OCTAV finds optimal clipping scalars on the fly, for every tensor, at every iteration of the QAT routine. Thus, the QAT algorithm is formulated with provably minimum quantization noise at each step. In addition, we reveal limitations in common gradient estimation techniques in QAT and propose magnitude-aware differentiation as a remedy to further improve accuracy. Experimentally, OCTAV-enabled QAT achieves state-of-the-art accuracy on multiple tasks. These include training-from-scratch and retraining ResNets and MobileNets on ImageNet, and Squad fine-tuning using BERT models, where OCTAV-enabled QAT consistently preserves accuracy at low precision (4-to-6-bits). Our results require no modifications to the baseline training recipe, except for the insertion of quantization operations where appropriate."}}
{"id": "r2jr_HiWaex", "cdate": 1609459200000, "mdate": 1664639447172, "content": {"title": "A 0.44-\u03bcJ/dec, 39.9-\u03bcs/dec, Recurrent Attention In-Memory Processor for Keyword Spotting", "abstract": "This article presents a deep learning-based classifier IC for keyword spotting (KWS) in 65-nm CMOS designed using an algorithm-hardware co-design approach. First, a recurrent attention model (RAM) algorithm for the KWS task (the KeyRAM algorithm) is proposed. The KeyRAM algorithm enables accuracy versus energy scalability via a confidence-based computation (CC) scheme, leading to a 2.5\u00d7 reduction in computational complexity compared to state-of-the-art (SOTA) neural networks, and is well-suited for in-memory computing (IMC) since the bulk (89%) of its computations are 4-b matrix-vector multiplies. The KeyRAM IC comprises a multi-bit multi-bank IMC architecture with a digital co-processor. A sparsity-aware summation scheme is proposed to alleviate the challenge faced by IMCs when summing sparse activations. The digital co-processor employs diagonal major weight storage to compute without any stalls. This combination of the IMC and digital processors enables a balanced tradeoff between energy efficiency and high accuracy computation. The resultant KWS IC achieves SOTA decision latency of 39.9 \u03bcs with a decision energy <; 0.5 \u03bcJ/dec which translates to more than 24 \u00d7 savings in the energy-delay product (EDP) of decisions over existing KWS ICs."}}
{"id": "A9g-lC6EHTO", "cdate": 1609459200000, "mdate": 1664639447144, "content": {"title": "Optimizing Selective Protection for CNN Resilience", "abstract": "As CNNs are being extensively employed in high performance and safety-critical applications that demand high reliability, it is important to ensure that they are resilient to transient hardware errors. Traditional full redundancy solutions provide high error coverage, but the associated overheads are often prohibitively high for resource-constrained systems. In this work, we propose software-directed selective protection techniques to target the most vulnerable work in a CNN, providing a low-cost solution. We propose and evaluate two domain-specific selective protection techniques for CNNs that target different granularities. First, we develop a feature-map level resilience technique (FLR), which identifies and statically protects the most vulnerable feature maps in a CNN. Second, we develop an inference level resilience technique (ILR), which selectively reruns vulnerable inferences by analyzing their output. Third, we show that the combination of both techniques (FILR) is highly efficient, achieving nearly full error coverage (99.78% on average) for quantized inferences via selective protection. Our tunable approach enables developers to evaluate CNN resilience to hardware errors before deployment using MAC operations as overhead for quicker trade-off analysis. For example, targeting 100% error coverage on ResNet50 with FILR requires 20.8% additional MACs, while measurements on a Jetson Xavier GPU shows 4.6% runtime overhead."}}
{"id": "9Can3Ltvc3v", "cdate": 1609459200000, "mdate": 1664639447175, "content": {"title": "Signal Processing Methods to Enhance the Energy Efficiency of In-Memory Computing Architectures", "abstract": "This paper presents signal processing methods to enhance the energy vs. accuracy trade-off of in-memory computing (IMC) architectures. First, an optimal clipping criterion (OCC) for signal quantization is proposed in order to minimize the precision of column analog-to-digital converters (ADCs) at iso-accuracy. For a Gaussian distributed signal, the OCC is shown to reduce the column ADC precision requirements by 3 bits at a signal-to-quantization noise ratio (SQNR) of <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><tex-math notation=\"LaTeX\">$\\text{22.5}\\,dB$</tex-math></inline-formula> over the commonly used full range (FR) quantizer. Next, the input-sliced weight-parallel (ISWP) IMC architecture is presented as a generalization of the popular bit-serial bit-parallel (BSBP) architecture. Quantization noise analysis of the ISWP indicates that its accuracy is comparable to BSBP while providing an order-of-magnitude reduction in energy consumption due to fewer array invocations and smaller ADC precision. Combining OCC and ISWP noise analysis, we map popular DNNs such as VGG-9 (CIFAR-10), ResNet-18 (CIFAR-10), and AlexNet (ImageNet) on a OCC-enabled ISWP architecture and show a reduction in energy consumption by an order-of-magnitude at iso-accuracy over the BSBP architecture that employs FR-based ADCs."}}
{"id": "jg8WZFmgsvK", "cdate": 1577836800000, "mdate": 1664639447197, "content": {"title": "Fundamental Limits on the Precision of In-memory Architectures", "abstract": "This paper obtains the fundamental limits on the computational precision of in-memory computing architectures (IMCs). Various compute SNR metrics for IMCs are defined and their interrelationships analyzed to show that the accuracy of IMCs is fundamentally limited by the compute SNR (SNRa) of its analog core, and that activation, weight and output precision needs to be assigned appropriately for the final output SNR SNRT \u2192 SNRa. The minimum precision criterion (MPC) is proposed to minimize the output and hence the column analog-to-digital converter (ADC) precision. The charge summing (QS) compute model and its associated IMC QS-Arch are studied to obtain analytical models for its compute SNR, minimum ADC precision, energy and latency. Compute SNR models of QS-Arch are validated via Monte Carlo simulations in a 65 nm CMOS process. Employing these models, upper bounds on SNRa of a QS-Arch-based IMC employing a 512 row SRAM array are obtained and it is shown that QS-Arch's energy cost reduces by 3.3\u00d7 for every 6 dB drop in SNRa, and that the maximum achievable SNRa reduces with technology scaling while the energy cost at the same SNRa increases. These models also indicate the existence of an upper bound on the dot product dimension N due to voltage headroom clipping, and this bound can be doubled for every 3 dB drop in SNRa."}}
{"id": "hq78EDj1yvvJ", "cdate": 1577836800000, "mdate": 1664639447177, "content": {"title": "HarDNN: Feature Map Vulnerability Evaluation in CNNs", "abstract": "As Convolutional Neural Networks (CNNs) are increasingly being employed in safety-critical applications, it is important that they behave reliably in the face of hardware errors. Transient hardware errors may percolate undesirable state during execution, resulting in software-manifested errors which can adversely affect high-level decision making. This paper presents HarDNN, a software-directed approach to identify vulnerable computations during a CNN inference and selectively protect them based on their propensity towards corrupting the inference output in the presence of a hardware error. We show that HarDNN can accurately estimate relative vulnerability of a feature map (fmap) in CNNs using a statistical error injection campaign, and explore heuristics for fast vulnerability assessment. Based on these results, we analyze the tradeoff between error coverage and computational overhead that the system designers can use to employ selective protection. Results show that the improvement in resilience for the added computation is superlinear with HarDNN. For example, HarDNN improves SqueezeNet's resilience by 10x with just 30% additional computations."}}
{"id": "8OZZa47RrQ5", "cdate": 1577836800000, "mdate": 1664639447188, "content": {"title": "Fundamental Limits on Energy-Delay-Accuracy of In-memory Architectures in Inference Applications", "abstract": "This paper obtains fundamental limits on the computational precision of in-memory computing architectures (IMCs). An IMC noise model and associated SNR metrics are defined and their interrelationships analyzed to show that the accuracy of IMCs is fundamentally limited by the compute SNR ($\\text{SNR}_{\\text{a}}$) of its analog core, and that activation, weight and output precision needs to be assigned appropriately for the final output SNR $\\text{SNR}_{\\text{T}} \\rightarrow \\text{SNR}_{\\text{a}}$. The minimum precision criterion (MPC) is proposed to minimize the ADC precision. Three in-memory compute models - charge summing (QS), current summing (IS) and charge redistribution (QR) - are shown to underlie most known IMCs. Noise, energy and delay expressions for the compute models are developed and employed to derive expressions for the SNR, ADC precision, energy, and latency of IMCs. The compute SNR expressions are validated via Monte Carlo simulations in a 65 nm CMOS process. For a 512 row SRAM array, it is shown that: 1) IMCs have an upper bound on their maximum achievable $\\text{SNR}_{\\text{a}}$ due to constraints on energy, area and voltage swing, and this upper bound reduces with technology scaling for QS-based architectures; 2) MPC enables $\\text{SNR}_{\\text{T}} \\rightarrow \\text{SNR}_{\\text{a}}$ to be realized with minimal ADC precision; 3) QS-based (QR-based) architectures are preferred for low (high) compute SNR scenarios."}}
{"id": "1yh3_AA41Rij", "cdate": 1577836800000, "mdate": 1664639447249, "content": {"title": "KeyRAM: A 0.34 uJ/decision 18 k decisions/s Recurrent Attention In-memory Processor for Keyword Spotting", "abstract": "This paper presents a 0.34 uJ/decision deep learning-based classifier for keyword spotting (KWS) in 65 nm CMOS with all weights stored on-chip. This work adapts a Recurrent Attention Model (RAM) algorithm for the KWS task, and employs an in-memory computing (IMC) architecture to achieve up to 9\u00d7 savings in energy/decision and more than 23\u00d7 savings in EDP of decisions over a state-of-the art IMC IC for KWS using the Google Speech dataset while achieving the highest reported decision throughput of 18.32 k decisions/s."}}
