{"id": "xBeGd7sAND", "cdate": 1663850019903, "mdate": null, "content": {"title": "Spotting Expressivity Bottlenecks and Fixing Them Optimally ", "abstract": "Machine learning tasks are generally formulated as optimization problems, where one searches for an optimal function within a certain functional space. In practice, parameterized functional spaces are considered, in order to be able to perform gradient descent. Typically, a neural network architecture is chosen and fixed, and its parameters (connection weights) are optimized, yielding an architecture-dependent result. This way of proceeding however forces the evolution of the function during training to lie within the realm of what is expressible with the chosen architecture, and prevents any optimization across possible architectures. Costly architectural hyper-parameter optimization is often performed to compensate for this. Instead, we propose to adapt the architecture on the fly during training. We show that the information about desirable architectural changes, due to expressivity bottlenecks when attempting to follow the functional gradient, can be extracted from the back-propagation.  To do this, we propose a new mathematically well-grounded method to detect expressivity bottlenecks on the fly and solve them by adding suitable neurons when and where needed. Thus, while the standard approach requires large networks, in terms of number of neurons per layer, for expressivity and optimization reasons, we are able to start with  very small neural networks and let them grow appropriately.  As a proof of concept, we show convincing results on the MNIST dataset, matching large neural network accuracy, with competitive training time, while removing the need for standard architectural hyper-parameter optimization.\n"}}
{"id": "6GUIv9eYnD7", "cdate": 1598877956540, "mdate": null, "content": {"title": "Asymmetrical Scaling Layers for Stable Network Pruning", "abstract": "We propose a new training setup, called ScaLa, and a new pruning algorithm based on it, called ScaLP. \nThe new training setup ScaLa is designed to make standard Stochastic Gradient Descent resilient to layer width changes. It consists in adding a fixed well-chosen scaling layer before each linear or convolutional layer. This results in an overall learning behavior that is more independent of the layer widths, especially with respect to optimal learning rates, which stay close to 1. \nBeyond the usual choice of scaling each input by the factor 1/fan-in, we also propose a family of asymmetric scaling factors: this promotes learning some neurons faster than others. The pruning algorithm ScaLP is a combination of ScaLa with asymmetrical scaling, and weight penalties. With ScaLP, the final pruned architecture is roughly independent of the layer widths in the initial network."}}
{"id": "B1lCtNreLr", "cdate": 1567802502022, "mdate": null, "content": {"title": "Input Similarity from the Neural Network Perspective", "abstract": " We first exhibit a multimodal image registration task, for which a neural network trained on a dataset with noisy labels reaches almost perfect accuracy, far beyond noise variance. This surprising auto-denoising phenomenon can be explained as a noise averaging effect over the labels of similar input examples. This effect theoretically grows with the number of similar examples; the question is then to define and estimate the similarity of examples.  We express a proper definition of similarity, from the neural network perspective, ie we quantify how undissociable two inputs A and B are, taking a machine learning viewpoint: how much a parameter variation designed to change the output for A would impact the output for B?  We study the mathematical properties of this similarity measure, and show how to use it on a trained network to estimate sample density, in low complexity, enabling new types of statistical analysis for neural networks. We also propose to use it during training, to enforce that examples known to be similar should also be seen as similar by the network, and notice speed-up training effects for certain datasets."}}
{"id": "rkMdBSdRKm", "cdate": 1538323776188, "mdate": null, "content": {"title": "Deep Learning for Hurricane Track Forecasting from Aligned Spatio-temporal Climate Datasets", "abstract": "  The forecast of hurricane trajectories is crucial for the protection of people and property, but machine learning techniques have been scarce for this so far.\n  We propose a neural network fusing past trajectory data and reanalysis atmospheric images (wind and pressure 3D fields). We used a moving frame of reference that follows the storm center for the 24h tracking forecast. The network is trained to estimate the longitude and latitude displacement of hurricanes and depressions from a large database from both hemispheres (more than 3000 storms since 1979,  sampled at a 6 hour frequency). The advantage of the fusion network is demonstrated and a comparison with current forecast models shows that deep methods could provide a valuable and complementary prediction."}}
{"id": "SJLr5bOWH", "cdate": 1514764800000, "mdate": null, "content": {"title": "Multimodal Image Alignment Through a Multiscale Chain of Neural Networks with Application to Remote Sensing", "abstract": "We tackle here the problem of multimodal image non-rigid registration, which is of prime importance in remote sensing and medical imaging. The difficulties encountered by classical registration approaches include feature design and slow optimization by gradient descent. By analyzing these methods, we note the significance of the notion of scale. We design easy-to-train, fully-convolutional neural networks able to learn scale-specific features. Once chained appropriately, they perform global registration in linear time, getting rid of gradient descent schemes by predicting directly the deformation. We show their performance in terms of quality and speed through various tasks of remote sensing multimodal image alignment. In particular, we are able to register correctly cadastral maps of buildings as well as road polylines onto RGB images, and outperform current keypoint matching methods."}}
{"id": "By--DKWObr", "cdate": 1325376000000, "mdate": null, "content": {"title": "Learning to Match Appearances by Correlations in a Covariance Metric Space", "abstract": "This paper addresses the problem of appearance matching across disjoint camera views. Significant appearance changes, caused by variations in view angle, illumination and object pose, make the problem challenging. We propose to formulate the appearance matching problem as the task of learning a model that selects the most descriptive features for a specific class of objects. Learning is performed in a covariance metric space using an entropy-driven criterion. Our main idea is that different regions of the object appearance ought to be matched using various strategies to obtain a distinctive representation. The proposed technique has been successfully applied to the person re-identification problem, in which a human appearance has to be matched across non-overlapping cameras. We demonstrate that our approach improves state of the art performance in the context of pedestrian recognition."}}
{"id": "HJWCfxGO-S", "cdate": 1293840000000, "mdate": null, "content": {"title": "Exhaustive family of energies minimizable exactly by a graph cut", "abstract": "Graph cuts are widely used in many fields of computer vision in order to minimize in small polynomial time complexity certain classes of energies. These specific classes depend on the way chosen to build the graphs representing the problems to solve. We study here all possible ways of building graphs and the associated energies minimized, leading to the exhaustive family of energies minimizable exactly by a graph cut. To do this, we consider the issue of coding pixel labels as states of the graph, i.e. the choice of state interpretations. The family obtained comprises many new classes, in particular energies that do not satisfy the submodularity condition, including energies that are even not permuted-submodular. A generating subfamily is studied in details, in particular we propose a canonical form to represent Markov random fields, which proves useful to recognize energies in this subfamily in linear complexity almost surely, and then to build the associated graph in quasilinear time. A few experiments are performed, to illustrate the new possibilities offered."}}
{"id": "Hy-Lj9-ubr", "cdate": 1262304000000, "mdate": null, "content": {"title": "Converting Level Set Gradients to Shape Gradients", "abstract": "The level set representation of shapes is useful for shape evolution and is widely used for the minimization of energies with respect to shapes. Many algorithms consider energies depending explicitly on the signed distance function (SDF) associated with a shape, and differentiate these energies with respect to the SDF directly in order to make the level set representation evolve. This framework is known as the \u201cvariational level set method\u201d. We show that this gradient computation is actually mathematically incorrect, and can lead to undesirable performance in practice. Instead, we derive the expression of the gradient with respect to the shape, and show that it can be easily computed from the gradient of the energy with respect to the SDF. We discuss some problematic gradients from the literature, show how they can easily be fixed, and provide experimental comparisons illustrating the improvement."}}
{"id": "S1WI4KWuWS", "cdate": 1199145600000, "mdate": null, "content": {"title": "Automatic Image Colorization Via Multimodal Predictions", "abstract": "We aim to color greyscale images automatically, without any manual intervention. The color proposition could then be interactively corrected by user-provided color landmarks if necessary. Automatic colorization is nontrivial since there is usually no one-to-one correspondence between color and local texture. The contribution of our framework is that we deal directly with multimodality and estimate, for each pixel of the image to be colored, the probability distribution of all possible colors, instead of choosing the most probable color at the local level. We also predict the expected variation of color at each pixel, thus defining a non-uniform spatial coherency criterion. We then use graph cuts to maximize the probability of the whole colored image at the global level. We work in the L-a-b color space in order to approximate the human perception of distances between colors, and we use machine learning tools to extract as much information as possible from a dataset of colored examples. The resulting algorithm is fast, designed to be more robust to texture noise, and is above all able to deal with ambiguity, in contrary to previous approaches."}}
{"id": "rkbx7gGObH", "cdate": 1167609600000, "mdate": null, "content": {"title": "Shape Statistics for Image Segmentation with Prior", "abstract": "We propose a new approach to compute non-linear, intrinsic shape statistics and to incorporate them into a shape prior for an image segmentation task. Given a sample set of contours, we first define their mean shape as the one which is simultaneously closest to all samples up to rigid motions, and compute it in a gradient descent framework. We consider here a differentiable approximation of the Hausdorff distance between shapes. Statistics on the instantaneous deformation fields that the mean shape should undergo to move towards each sample lead to sensible characteristic modes of deformation that convey the shape variability. Contour statistics are turned into a shape prior which is rigid-motion invariant. Image segmentation results show the improvement gained by the shape prior."}}
