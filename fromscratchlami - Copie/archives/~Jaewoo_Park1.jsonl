{"id": "lAFDMV1qkq", "cdate": 1672531200000, "mdate": 1676666013404, "content": {"title": "Open-Set Face Identification on Few-Shot Gallery by Fine-Tuning", "abstract": "In this paper, we focus on addressing the open-set face identification problem on a few-shot gallery by fine-tuning. The problem assumes a realistic scenario for face identification, where only a small number of face images is given for enrollment and any unknown identity must be rejected during identification. We observe that face recognition models pretrained on a large dataset and naively fine-tuned models perform poorly for this task. Motivated by this issue, we propose an effective fine-tuning scheme with classifier weight imprinting and exclusive BatchNorm layer tuning. For further improvement of rejection accuracy on unknown identities, we propose a novel matcher called Neighborhood Aware Cosine (NAC) that computes similarity based on neighborhood information. We validate the effectiveness of the proposed schemes thoroughly on large-scale face benchmarks across different convolutional neural network architectures. The source code for this project is available at: https://github.com/1ho0jin1/OSFI-by-FineTuning"}}
{"id": "tqUyuZjlNOR", "cdate": 1640995200000, "mdate": 1668021604449, "content": {"title": "Understanding Open-Set Recognition by Jacobian Norm of Representation", "abstract": "In contrast to conventional closed-set recognition, open-set recognition (OSR) assumes the presence of an unknown class, which is not seen to a model during training. One predominant approach in OSR is metric learning, where a model is trained to separate the inter-class representations of known class data. Numerous works in OSR reported that, even though the models are trained only with the known class data, the models become aware of the unknown, and learn to separate the unknown class representations from the known class representations. This paper analyzes this emergent phenomenon by observing the Jacobian norm of representation. We theoretically show that minimizing the intra-class distances within the known set reduces the Jacobian norm of known class representations while maximizing the inter-class distances within the known set increases the Jacobian norm of the unknown class. The closed-set metric learning thus separates the unknown from the known by forcing their Jacobian norm values to differ. We empirically validate our theoretical framework with ample pieces of evidence using standard OSR datasets. Moreover, under our theoretical framework, we explain how the standard deep learning techniques can be helpful for OSR and use the framework as a guiding principle to develop an effective OSR model."}}
{"id": "j412oQtxAS", "cdate": 1640995200000, "mdate": 1676666013411, "content": {"title": "Open-Set Face Identification on Few-Shot Gallery by Fine-Tuning", "abstract": "In this paper, we focus on addressing the open-set face identification problem on a few-shot gallery by finetuning. The problem assumes a realistic scenario for face identification, where only a small number of face images is given for enrollment and any unknown identity must be rejected during identification. We observe that face recognition models pretrained on a large dataset and naively fine-tuned models perform poorly for this task. Motivated by this issue, we propose an effective fine-tuning scheme with classifier weight imprinting and exclusive BatchNorm layer tuning. For further improvement of rejection accuracy on unknown identities, we propose a novel matcher called Neighborhood Aware Cosine (NAC) that computes similarity based on neighborhood information. We validate the effectiveness of the proposed schemes thoroughly on large-scale face benchmarks across different convolutional neural network architectures. The source code for this project is available at: https://github.com/1ho0jin1/OSFI-by-FineTuning"}}
{"id": "-XRv5unYMoL", "cdate": 1640995200000, "mdate": 1652598459866, "content": {"title": "Divergent Angular Representation for Open Set Image Recognition", "abstract": "Open set recognition (OSR) models need not only discriminate between known classes but also detect unknown class samples unavailable during training. One promising approach is to learn discriminative representations over known classes with strong intra-class similarity and inter-class discrepancy. Then, the powerful class discrimination learned from the known classes can be extended to known and unknown classes. Without appropriate regularization, however, the model may learn representations trivially, collapsing unknown class representations to the known class ones. To resolve this problem, we propose Divergent Angular Representation (DivAR) based on two approaches. Firstly, DivAR maximizes its representational discrimination between known classes via a highly discriminative loss. Secondly, to ensure separation between known and unknown classes in the representation space, DivAR boosts the directional variation of representations over global samples. In addition, self-supervision is leveraged to improve the representation\u2019s robustness and extend DivAR to one-class classification. Moreover, unlike other OSR methods that require an extra machinery for inference, DivAR learns and infers in a single module. Extensive experiments on generic image datasets demonstrate the plausibility and effectiveness of DivAR for both OSR and One-Class Classification (OCC) problems."}}
{"id": "-4q8Nv0gxJw", "cdate": 1609459200000, "mdate": 1652598459834, "content": {"title": "MIND-Net: A Deep Mutual Information Distillation Network for Realistic Low-Resolution Face Recognition", "abstract": "Realistic low-resolution (LR) face images refer to those captured by the real-world surveillance cameras at extreme standoff distances, thereby LR and poor in quality essentially. Owing to severe scarcity of labeled data, a high-capacity deep convolution neural networks (CNN) is hardly trained to confront the realistic LR face recognition (LRFR) challenge. We introduce in this letter a dual-stream mutual information distillation network (MIND-Net), whereby the non-identity specific mutual information (MI) characterized by generic face features coexistent on realistic and synthetic LR face images are distilled to render a resolution-invariant embedding space for LRFR. For a thorough analysis, we quantify the degree of MI distillation in terms normalized MI index. Our experimental results on the realistic LR face datasets substantiate that the MIND-Net instances assembled from the pre-learned CNNs stand out from the baselines and other state of the arts by a notable margin."}}
{"id": "v_o-UEWM46g", "cdate": 1577836800000, "mdate": 1652598459673, "content": {"title": "Revisiting ImprovedGAN with Metric Learning for Semi-Supervised Learning", "abstract": "Semi-supervised Learning (SSL) is a classical problem where a model needs to solve classification as it is trained on a partially labeled train data. After the introduction of generative adversarial network (GAN) and its success, the model has been modified to be applicable to SSL. ImprovedGAN as a representative model for GAN-based SSL, it showed promising performance on the SSL problem. However, the inner mechanism of this model has been only partially revealed. In this work, we revisit ImprovedGAN with a fresh look on it based on metric learning. In particular, we interpret ImprovedGAN by general pair weighting, a recent framework in metric learning. Based on this interpretation, we derive two theoretical properties of ImprovedGAN: (i) its discriminator learns to make confident predictions over real samples, (ii) the adversarial interaction in ImprovedGAN constrains the discriminator to decrease the angles between the features of real samples and class weight vectors. The two properties suggest that the adversarial interaction induces the class-wise cluster separation of the features as experimentally verified. Motivated by the findings, we propose a variant of ImprovedGAN, called Intensified ImprovedGAN, where its cluster separation characteristic is improved by two proposed techniques: (a) the unsupervised discriminator loss is scaled up and (b) the generated batch size is enlarged. As a result, I2GAN produces better class-wise cluster separation and, hence, generalization. Extensive experiments on the widely known benchmark data sets verify the effectiveness of our proposed method, showing that its performance is better than or comparable to other GAN based SSL models."}}
{"id": "vIE8Ku9iWXI", "cdate": 1577836800000, "mdate": 1652598459706, "content": {"title": "Compact Surjective Encoding Autoencoder for Unsupervised Novelty Detection", "abstract": "In one-class novelty detection, a model learns solely on the in-class data to single out out-class instances. Autoencoder (AE) variants aim to compactly model the in-class data to reconstruct it exclusively, thus differentiating the in-class from out-class by the reconstruction error. However, compact modeling in an improper way might collapse the latent representations of the in-class data and thus their reconstruction, which would lead to performance deterioration. Moreover, to properly measure the reconstruction error of high-dimensional data, a metric is required that captures high-level semantics of the data. To this end, we propose Discriminative Compact AE (DCAE) that learns both compact and collapse-free latent representations of the in-class data, thereby reconstructing them both finely and exclusively. In DCAE, (a) we force a compact latent space to bijectively represent the in-class data by reconstructing them through internal discriminative layers of generative adversarial nets. (b) Based on the deep encoder's vulnerability to open set risk, out-class instances are encoded into the same compact latent space and reconstructed poorly without sacrificing the quality of in-class data reconstruction. (c) In inference, the reconstruction error is measured by a novel metric that computes the dissimilarity between a query and its reconstruction based on the class semantics captured by the internal discriminator. Extensive experiments on public image datasets validate the effectiveness of our proposed model on both novelty and adversarial example detection, delivering state-of-the-art performance."}}
{"id": "fN87AxuKSo4", "cdate": 1577836800000, "mdate": 1652598459834, "content": {"title": "Periocular Recognition in the Wild With Generalized Label Smoothing Regularization", "abstract": "Periocular biometric covering the immediate vicinity of human eye is a synergistic alternative to face particularly when the face is masked or occluded. Most present work for periocular recognition in the wild are mainly convolutional neural networks learned based on cross-entropy loss. However, periocular images only capture the least salient face features, and thus suffering from severe intra-class compactness and inter-class dispersion issues for discriminative deep feature learning. Recently, label smoothing regularization (LSR) is discerned capable of diminishing the intra-class variation by minimizing the Kullback-Liebler divergence of a uniform distribution and a network prediction distribution. In this letter, we extend LSR to that of Generalized LSR (GLSR) by learning a pre-task network prediction, in place of the predefined uniform distribution. Extensive experiments on four periocular in the wild datasets disclose that the GSLR-trained networks prevail over the LSR-based counterpart and other most recent the state of the arts. This is supported by our empirical analyses that the embedding periocular features rendered by GLSR results in better class-wise cluster separation than the conventional LSR."}}
{"id": "_rqfEhn0QX", "cdate": 1577836800000, "mdate": 1652598459834, "content": {"title": "Discriminative Multi -level Reconstruction under Compact Latent Space for One-Class Novelty Detection", "abstract": "In one-class novelty detection, a model learns solely on the in-class data to single out out-class instances. Autoencoder (AE) variants aim to compactly model the in-class data to reconstruct it exclusively, thus differentiating the in-class from out-class by the reconstruction error. However, compact modeling in an improper way might collapse the latent representations of the in-class data and thus their reconstruction, which would lead to performance deterioration. Moreover, to properly measure the reconstruction error of high-dimensional data, a metric is required that captures high-level semantics of the data. To this end, we propose Discriminative Compact AE (DCAE) that learns both compact and collapse-free latent representations of the in-class data, thereby reconstructing them both finely and exclusively. In DCAE, (a) we force a compact latent space to bijectively represent the in-class data by reconstructing them through internal discriminative layers of generative adversarial nets. (b) Based on the deep encoder's vulnerability to open set risk, out-class instances are encoded into the same compact latent space and reconstructed poorly without sacrificing the quality of in-class data reconstruction. (c) In inference, the reconstruction error is measured by a novel metric that computes the dissimilarity between a query and its reconstruction based on the class semantics captured by the internal discriminator. Extensive experiments on public image datasets validate the effectiveness of our proposed model on both novelty and adversarial example detection, delivering state-of-the-art performance."}}
{"id": "PZoHrTGRyzt", "cdate": 1577836800000, "mdate": 1652598459705, "content": {"title": "Stacking-Based Deep Neural Network: Deep Analytic Network for Pattern Classification", "abstract": "Stacking-based deep neural network (S-DNN) is aggregated with pluralities of basic learning modules, one after another, to synthesize a deep neural network (DNN) alternative for pattern classification. Contrary to the DNNs trained from end to end by backpropagation (BP), each S-DNN layer, that is, a self-learnable module, is to be trained decisively and independently without BP intervention. In this paper, a ridge regression-based S-DNN, dubbed deep analytic network (DAN), along with its kernelization (K-DAN), are devised for multilayer feature relearning from the pre-extracted baseline features and the structured features. Our theoretical formulation demonstrates that DAN/K-DAN relearn by perturbing the intra/interclass variations, apart from diminishing the prediction errors. We scrutinize the DAN/K-DAN performance for pattern classification on datasets of varying domains-faces, handwritten digits, generic objects, to name a few. Unlike the typical BP-optimized DNNs to be trained from gigantic datasets by GPU, we reveal that DAN/K-DAN are trainable using only CPU even for small-scale training sets. Our experimental results show that DAN/K-DAN outperform the present S-DNNs and also the BP-trained DNNs, including multiplayer perceptron, deep belief network, etc., without data augmentation applied."}}
