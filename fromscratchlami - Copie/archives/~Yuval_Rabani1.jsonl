{"id": "GeounBDhT7S", "cdate": 1667393653395, "mdate": null, "content": {"title": "Causal Inference Despite Limited Global Confounding via Mixture Models", "abstract": "A Bayesian Network is a directed acyclic graph (DAG) on a set of $n$ random variables (the vertices); a Bayesian Network Distribution (BND) is a probability distribution on the random variables that is Markovian on the graph. A finite $k$-mixture of such models is graphically represented by a larger graph which has an additional ``hidden'' (or ``latent'') random variable $U$, ranging in $\\{1,\\ldots,k\\}$, and a directed edge from $U$ to every other vertex. Models of this type are fundamental to causal inference, where $U$ models an unobserved confounding effect of multiple populations, obscuring the causal relationships in the observable DAG. By solving the mixture problem and recovering the joint probability distribution with $U$, traditionally unidentifiable causal relationships become identifiable. Using a reduction to the more well-studied ``product'' case on empty graphs, we give the first algorithm to learn mixtures of non-empty DAGs. "}}
{"id": "nqJiNuMdKjp", "cdate": 1577836800000, "mdate": null, "content": {"title": "Online Multiserver Convex Chasing and Optimization", "abstract": "We introduce the problem of $k$-chasing of convex functions, a simultaneous generalization of both the famous k-server problem in $R^d$, and of the problem of chasing convex bodies and functions. Aside from fundamental interest in this general form, it has natural applications to online $k$-clustering problems with objectives such as $k$-median or $k$-means. We show that this problem exhibits a rich landscape of behavior. In general, if both $k > 1$ and $d > 1$ there does not exist any online algorithm with bounded competitiveness. By contrast, we exhibit a class of nicely behaved functions (which include in particular the above-mentioned clustering problems), for which we show that competitive online algorithms exist, and moreover with dimension-free competitive ratio. We also introduce a parallel question of top-$k$ action regret minimization in the realm of online convex optimization. There, too, a much rougher landscape emerges for $k > 1$. While it is possible to achieve vanishing regret, unlike the top-one action case the rate of vanishing does not speed up for strongly convex functions. Moreover, vanishing regret necessitates both intractable computations and randomness. Finally we leave open whether almost dimension-free regret is achievable for $k > 1$ and general convex losses. As evidence that it might be possible, we prove dimension-free regret for linear losses via an information-theoretic argument."}}
{"id": "zY11YM_zP3K", "cdate": 1546300800000, "mdate": null, "content": {"title": "Proportional Dynamics in Exchange Economies", "abstract": "We study the Proportional Response dynamic in exchange economies, where each player starts with some amount of money and a good. Every day, the players bring one unit of their good and submit bids on goods they like, each good gets allocated in proportion to the bid amounts, and each seller collects the bids received. Then every player updates the bids proportionally to the contribution of each good in their utility. This dynamic models a process of learning how to bid and has been studied in a series of papers on Fisher and production markets, but not in exchange economies. Our main results are as follows: - For linear utilities, the dynamic converges to market equilibrium utilities and allocations, while the bids and prices may cycle. We give a combinatorial characterization of limit cycles for prices and bids. - We introduce a lazy version of the dynamic, where players may save money for later, and show this converges in everything: utilities, allocations, and prices. - For CES utilities in the substitute range $[0,1)$, the dynamic converges for all parameters. This answers an open question about exchange economies with linear utilities, where tatonnement does not converge to market equilibria, and no natural process leading to equilibria was known. We also note that proportional response is a process where the players exchange goods throughout time (in out-of-equilibrium states), while tatonnement only explains how exchange happens in the limit."}}
{"id": "eVgihLJ8oy", "cdate": 1546300800000, "mdate": null, "content": {"title": "Parametrized Metrical Task Systems", "abstract": "We consider parametrized versions of metrical task systems and metrical service systems, two fundamental models of online computing, where the constrained parameter is the number of possible distinct requests $m$. Such parametrization occurs naturally in a wide range of applications. Striking examples are certain power management problems, which are modeled as metrical task systems with $m=2$. We characterize the competitive ratio in terms of the parameter $m$ for both deterministic and randomized algorithms on hierarchically separated trees. Our findings uncover a rich and unexpected picture that differs substantially from what is known or conjectured about the unparametrized versions of these problems. For metrical task systems, we show that deterministic algorithms do not exhibit any asymptotic gain beyond one-level trees (namely, uniform metric spaces), whereas randomized algorithms do not exhibit any asymptotic gain even for one-level trees. In contrast, the special case of metrical service systems (subset chasing) behaves very differently. Both deterministic and randomized algorithms exhibit gain, for $m$ sufficiently small compared to $n$, for any number of levels. Most significantly, they exhibit a large gain for uniform metric spaces and a smaller gain for two-level trees. Moreover, it turns out that in these cases (as well as in the case of metrical task systems for uniform metric spaces with $m$ being an absolute constant), deterministic algorithms are essentially as powerful as randomized algorithms. This is surprising and runs counter to the ubiquitous intuition/conjecture that, for most problems that can be modeled as metrical task systems, the randomized competitive ratio is polylogarithmic in the deterministic competitive ratio."}}
{"id": "dRPDfp62kTt", "cdate": 1514764800000, "mdate": null, "content": {"title": "Strictly Balancing Matrices in Polynomial Time Using Osborne's Iteration", "abstract": "Osborne's iteration is a method for balancing n x n matrices which is widely used in linear algebra packages, as balancing preserves eigenvalues and stabilizes their numeral computation. The iteration can be implemented in any norm over R^n, but it is normally used in the L_2 norm. The choice of norm not only affects the desired balance condition, but also defines the iterated balancing step itself. In this paper we focus on Osborne's iteration in any L_p norm, where p < infty. We design a specific implementation of Osborne's iteration in any L_p norm that converges to a strictly epsilon-balanced matrix in O~(epsilon^{-2}n^{9} K) iterations, where K measures, roughly, the number of bits required to represent the entries of the input matrix. This is the first result that proves a variant of Osborne's iteration in the L_2 norm (or any L_p norm, p < infty) strictly balances matrices in polynomial time. This is a substantial improvement over our recent result (in SODA 2017) that showed weak balancing in L_p norms. Previously, Schulman and Sinclair (STOC 2015) showed strict balancing of another variant of Osborne's iteration in the L_infty norm. Their result does not imply any bounds on strict balancing in other norms."}}
{"id": "zOYG6df8mdc", "cdate": 1483228800000, "mdate": null, "content": {"title": "Convergence of Incentive-Driven Dynamics in Fisher Markets", "abstract": "In both general equilibrium theory and game theory, the dominant mathematical models rest on a fully rational solution concept in which every player's action is a best-response to the actions of the other players. In both theories there is less agreement on suitable out- of-equilibrium modeling, but one attractive approach is the level k model in which a level 0 player adopts a very simple response to current conditions, a level 1 player best-responds to a model in which others take level 0 actions, and so forth. (This is analogous to k-ply exploration of game trees in AI, and to receding-horizon control in control theory.) If players have deterministic mental models with this kind of finite-level response, there is obviously no way their mental models can all be consistent. Nevertheless, there is experimental evidence that people act this way in many situations, motivating the question of what the dynamics of such interactions lead to. We address the problem of out-of-equilibrium price dynamics in the setting of Fisher markets. We develop a general framework in which sellers have (a) a set of atomic price update rules which are simple responses to a price vector; (b) a belief-formation procedure that simulates actions of other sellers (themselves using the atomic price updates) to some finite horizon in the future. In this framework, sellers use an atomic price update rule to respond to a price vector they generate with the belief formation procedure. The framework is general and allows sellers to have inconsistent and time- varying beliefs about each other. Under certain assumptions on the atomic update rules, we show that despite the inconsistent and time-varying nature of beliefs, the market converges to a unique equilibrium. (If the price updates are driven by weak-gross substitutes demands, this is the same equilibrium point predicted by those demands.) This result holds for both synchronous and asynchronous discrete-time updates. Moreover, the result is computationally feasible in the sense that the convergence rate is linear, i.e., the distance to equilibrium decays exponentially fast. To the best of our knowledge, this is the first result that demonstrates, in Fisher markets, convergence at any rate for dynamics driven by a plausible model of seller incentives. We then specialize our results to Fisher markets with elastic demands (a further special case corresponds to demand generated by buyers with constant elasticity of substitution (CES) utilities, in the weak gross substitutes (WGS) regime) and show that the atomic update rule in which a seller uses the best-response (=profit- maximizing) update given the prices of all other sellers, satisfies the assumptions required on atomic price update rules in our framework. We can even characterize the convergence rate (as a function of elasticity parameters of the demand function). Our results apply also to settings where, to the best of our knowledge, there exists no previous demonstration of efficient convergence of any discrete dynamic of price updates. Even for the simple case of (level 0) best- response dynamics, our result is the first to demonstrate a linear rate of convergence."}}
{"id": "h0mxiyRC_jm", "cdate": 1483228800000, "mdate": null, "content": {"title": "Matrix Balancing in Lp Norms: Bounding the Convergence Rate of Osborne's Iteration", "abstract": "We study an iterative matrix conditioning algorithm due to Osborne (1960). The goal of the algorithm is to convert a square matrix into a balanced matrix where every row and corresponding column have the same norm. The original algorithm was proposed for balancing rows and columns in the L2 norm, and it works by iterating over balancing a row-column pair in fixed round-robin order. Variants of the algorithm for other norms have been heavily studied and are implemented as standard preconditioners in many numerical linear algebra packages. Recently, Schulman and Sinclair (2015), in a first result of its kind for any norm, analyzed the rate of convergence of a variant of Osborne's algorithm that uses the L\u221e norm and a different order of choosing row-column pairs. In this paper we study matrix balancing in the L1 norm and other Lp norms. We show the following results for any matrix , resolving in particular a main open problem mentioned by Schulman and Sinclair. 1. We analyze the iteration for the L1 norm under a greedy order of balancing. We show that it converges to an \u220a-balanced matrix in K = O(min{ \u220a\u22122 log w, \u220a\u22121n3/2 log(w / \u220a)}) iterations that cost a total of O(m + Kn log n) arithmetic operations over O(n log(w/\u220a))-bit numbers. Here m is the number of non-zero entries of A, and w =\u2211i,j |aij|/amin with amin = min{|aij| : aj \u2260 0}. 2. We show that the original round-robin implementation converges to an \u220a -balanced matrix in O(\u220a\u22122n2 log w) iterations totaling O(\u220a\u22122mn log w) arithmetic operations over O(nlog(w/\u220a))-bit numbers. 3. We show that a random implementation of the iteration converges to an \u220a -balanced matrix in O(\u220a\u22122 log w) iterations using O(m + \u220a\u22122n log w) arithmetic operations over O(log(wn/\u220a))-bit numbers. 4. We demonstrate a lower bound of on the convergence rate of any implementation of the iteration. 5. We observe, through a known trivial reduction, that our results for L1 balancing apply to any Lp norm for all finite p, at the cost of increasing the number of iterations by only a factor of p. We note that our techniques are very different from those used by Schulman and Sinclair."}}
{"id": "bft0HUlgMCz", "cdate": 1483228800000, "mdate": null, "content": {"title": "Approximating Sparsest Cut in Low Rank Graphs via Embeddings from Approximately Low-Dimensional Spaces", "abstract": "We consider the problem of embedding a finite set of points $\\{x_1, \\ldots, x_n\\} \\in \\mathbb{R}^d$ that satisfy $\\ell_2^2$ triangle inequalities into $\\ell_1$, when the points are approximately low-dimensional. Goemans (unpublished, appears in a work of [Magen and Moharammi, 2008]) showed that such points residing in \\emph{exactly} $d$ dimensions can be embedded into $\\ell_1$ with distortion at most $\\sqrt{d}$. We prove the following robust analogue of this statement: if there exists a $r$-dimensional subspace $\\Pi$ such that the projections onto this subspace satisfy $\\sum_{i,j \\in [n]}\\Vert \\Pi x_i - \\Pi x_j \\Vert _2^2 \\geq \\Omega(1) \\sum_{i,j \\in [n]}\\Vert x_i - x_j \\Vert _2^2$, then there is an embedding of the points into $\\ell_1$ with $O(\\sqrt{r})$ average distortion. A consequence of this result is that the integrality gap of the well-known Goemans-Linial SDP relaxation for the Uniform Sparsest Cut problem is $O(\\sqrt{r})$ on graphs $G$ whose $r$-th smallest normalized eigenvalue of the Laplacian satisfies $\\lambda_r(G)/n \\geq \\Omega(1)\\Phi_{SDP} (G)$. Our result improves upon the previously known bound of $O(r)$ on the average distortion, and the integrality gap of the Goemans-Linial SDP under the same preconditions, proven in the previous works of [Deshpande and Venkat, 2014] and [Deshpande, Harsha and Venkat, 2016]."}}
{"id": "YGILRCuoL_K", "cdate": 1483228800000, "mdate": null, "content": {"title": "Approximating Sparsest Cut in Low Rank Graphs via Embeddings from Approximately Low Dimensional Spaces", "abstract": "We consider the problem of embedding a finite set of points x_1, ... , x_n in R^d that satisfy l_2^2 triangle inequalities into l_1, when the points are approximately low-dimensional. Goemans (unpublished, appears in a work of Magen and Moharammi (2008) ) showed that such points residing in exactly d dimensions can be embedded into l_1 with distortion at most sqrt{d}. We prove the following robust analogue of this statement: if there exists a r-dimensional subspace Pi such that the projections onto this subspace satisfy sum_{i,j in [n]} norm{Pi x_i - Pi x_j}_2^2 >= Omega(1) * sum_{i,j \\in [n]} norm{x_i - x_j}_2^2, then there is an embedding of the points into l_1 with O(sqrt{r}) average distortion. A consequence of this result is that the integrality gap of the well-known Goemans-Linial SDP relaxation for the Uniform Sparsest Cut problem is O(sqrt{r}) on graphs G whose r-th smallest normalized eigenvalue of the Laplacian satisfies lambda_r(G)/n >= Omega(1)*Phi_{SDP}(G). Our result improves upon the previously known bound of O(r) on the average distortion, and the integrality gap of the Goemans-Linial SDP under the same preconditions, proven in [Deshpande and Venkat, 2014], and [Deshpande, Harsha and Venkat 2016]."}}
{"id": "98QNzT2eRL", "cdate": 1483228800000, "mdate": null, "content": {"title": "Strictly Balancing Matrices in Polynomial Time Using Osborne's Iteration", "abstract": "Osborne's iteration is a method for balancing $n\\times n$ matrices which is widely used in linear algebra packages, as balancing preserves eigenvalues and stabilizes their numeral computation. The iteration can be implemented in any norm over $\\mathbb{R}^n$, but it is normally used in the $L_2$ norm. The choice of norm not only affects the desired balance condition, but also defines the iterated balancing step itself. In this paper we focus on Osborne's iteration in any $L_p$ norm, where $p < \\infty$. We design a specific implementation of Osborne's iteration in any $L_p$ norm that converges to a strictly $\\epsilon$-balanced matrix in $\\tilde{O}(\\epsilon^{-2}n^{9} K)$ iterations, where $K$ measures, roughly, the {\\em number of bits} required to represent the entries of the input matrix. This is the first result that proves that Osborne's iteration in the $L_2$ norm (or any $L_p$ norm, $p < \\infty$) strictly balances matrices in polynomial time. This is a substantial improvement over our recent result (in SODA 2017) that showed weak balancing in $L_p$ norms. Previously, Schulman and Sinclair (STOC 2015) showed strong balancing of Osborne's iteration in the $L_\\infty$ norm. Their result does not imply any bounds on strict balancing in other norms."}}
