{"id": "80CaEGusR3", "cdate": 1695618576149, "mdate": 1695618576149, "content": {"title": "High-dimensional Contextual Bandit Problem without Sparsity", "abstract": "In this research, we investigate the high-dimensional linear contextual bandit problem where the number of features p is greater than the budget T, or it may even be infinite. Differing from the majority of previous works in this field, we do not impose sparsity on the regression coefficients. Instead, we rely on recent findings on overparameterized models, which enables us to analyze the performance the minimum-norm interpolating estimator when data distributions have small effective ranks. We propose an explore-then-commit (EtC) algorithm to address this problem and examine its performance. Through our analysis, we derive the optimal rate of the ETC algorithm in terms of T and show that this rate can be achieved by balancing exploration and exploitation. Moreover, we introduce an adaptive explore-then-commit (AEtC) algorithm that adaptively finds the optimal balance. We assess the performance of the proposed algorithms through a series of simulations."}}
{"id": "btJFlb6C54m", "cdate": 1672531200000, "mdate": 1695953772888, "content": {"title": "High-dimensional Contextual Bandit Problem without Sparsity", "abstract": "In this research, we investigate the high-dimensional linear contextual bandit problem where the number of features $p$ is greater than the budget $T$, or it may even be infinite. Differing from the majority of previous works in this field, we do not impose sparsity on the regression coefficients. Instead, we rely on recent findings on overparameterized models, which enables us to analyze the performance the minimum-norm interpolating estimator when data distributions have small effective ranks. We propose an explore-then-commit (EtC) algorithm to address this problem and examine its performance. Through our analysis, we derive the optimal rate of the ETC algorithm in terms of $T$ and show that this rate can be achieved by balancing exploration and exploitation. Moreover, we introduce an adaptive explore-then-commit (AEtC) algorithm that adaptively finds the optimal balance. We assess the performance of the proposed algorithms through a series of simulations."}}
{"id": "Qnz_TMm6DKv", "cdate": 1672531200000, "mdate": 1695953772883, "content": {"title": "Posterior Tracking Algorithm for Classification Bandits", "abstract": "The classification bandit problem aims to determine whether a set of given $K$ arms contains at least $L$ good arms or not. Here, an arm is said to be good if its expected reward is no less than a ..."}}
{"id": "9dFOx_0CnjD", "cdate": 1672531200000, "mdate": 1695953772876, "content": {"title": "Thresholded linear bandits", "abstract": "We introduce the thresholded linear bandit problem, a novel sequential decision making problem at the interface of structured stochastic multi-armed bandits and learning halfspaces. The set of arms..."}}
{"id": "TIQfmR7IF6H", "cdate": 1652737616447, "mdate": null, "content": {"title": "Minimax Optimal Algorithms for Fixed-Budget Best Arm Identification", "abstract": "We consider the fixed-budget best arm identification problem where the goal is to find the arm of the largest mean with a fixed number of samples. It is known that the probability of misidentifying the best arm is exponentially small to the number of rounds. However, limited characterizations have been discussed on the rate (exponent) of this value. In this paper, we characterize the minimax optimal rate as a result of an optimization over all possible parameters. We introduce two rates, $R^{\\mathrm{go}}$ and $R^{\\mathrm{go}}_{\\infty}$, corresponding to lower bounds on the probability of misidentification, each of which is associated with a proposed algorithm. The rate $R^{\\mathrm{go}}$ is associated with $R^{\\mathrm{go}}$-tracking, which can be efficiently implemented by a neural network and is shown to outperform existing algorithms. However, this rate requires a nontrivial condition to be achievable. To address this issue, we introduce the second rate $R^{\\mathrm{go}}_\\infty$. We show that this rate is indeed achievable by introducing a conceptual algorithm called delayed optimal tracking (DOT)."}}
{"id": "--_UZUq9EnFG", "cdate": 1652725944694, "mdate": 1652725944694, "content": {"title": "Policy Choice and Best Arm Identification: Asymptotic Analysis of Exploration Sampling", "abstract": "We consider the \u201cpolicy choice\u201d problem\u2013 otherwise known as best arm identification in the bandit literature\u2013 proposed by Kasy and Sautmann (2021) for adaptive experimental design. Theorem 1 of Kasy and Sautmann (2021) provides three asymptotic results that give theoretical guarantees for exploration sampling developed for this setting. We first show that the proof of Theorem 1 (1) has technical issues, and the proof and statement of Theorem 1 (2) are incorrect. We then show, through a counterexample, that Theorem 1 (3) is false. For the former two, we correct the statements and provide rigorous proofs. For Theorem 1 (3), we propose an alternative objective function, which we call posterior weighted policy regret, and derive the asymptotic optimality of exploration sampling."}}
{"id": "rIOGmTprYcK", "cdate": 1652725657231, "mdate": null, "content": {"title": "Optimal Simple Regret in Bayesian Best Arm Identification", "abstract": "We consider Bayesian best arm identification in the multi-armed bandit problem. Assuming certain continuity conditions of the prior, we characterize the rate of the Bayesian simple regret. Differing from Bayesian regret minimization (Lai, 1987), the leading factor in Bayesian simple regret derives from the region where the gap between optimal and sub-optimal arms is smaller than $\\sqrt{\\frac{\\log T}{T}}$. We propose a simple and easy-to-compute algorithm with its leading factor matches with the lower bound up to a constant factor; simulation results support our theoretical findings."}}
{"id": "aLcj5qPy0sx", "cdate": 1640995200000, "mdate": 1683896064372, "content": {"title": "Strategic Choices of Migrants and Smugglers in the Central Mediterranean Sea", "abstract": "The sea crossing from Libya to Italy is one of the world's most dangerous and politically contentious migration routes, and yet over half a million people have attempted the crossing since 2014. Leveraging data on aggregate migration flows and individual migration incidents, we estimate how migrants and smugglers have reacted to changes in border enforcement, namely the rise in interceptions by the Libyan Coast Guard starting in 2017 and the corresponding decrease in the probability of rescue at sea. We find support for a deterrence effect in which attempted crossings along the Central Mediterranean route declined, and a diversion effect in which some migrants substituted to the Western Mediterranean route. At the same time, smugglers adapted their tactics. Using a strategic model of the smuggler's choice of boat size, we estimate how smugglers trade off between the short-run payoffs to launching overcrowded boats and the long-run costs of making less successful crossing attempts under different levels of enforcement. Taken together, these analyses shed light on how the integration of incident- and flow-level datasets can inform ongoing migration policy debates and identify potential consequences of changing enforcement regimes."}}
{"id": "Xe-0fDL4ne", "cdate": 1640995200000, "mdate": 1683896063972, "content": {"title": "Globally Optimal Algorithms for Fixed-Budget Best Arm Identification", "abstract": "We consider the fixed-budget best arm identification problem where the goal is to find the arm of the largest mean with a fixed number of samples. It is known that the probability of misidentifying the best arm is exponentially small to the number of rounds. However, limited characterizations have been discussed on the rate (exponent) of this value. In this paper, we characterize the minimax optimal rate as a result of an optimization over all possible parameters. We introduce two rates, $R^{\\mathrm{go}}$ and $R^{\\mathrm{go}}_{\\infty}$, corresponding to lower bounds on the probability of misidentification, each of which is associated with a proposed algorithm. The rate $R^{\\mathrm{go}}$ is associated with $R^{\\mathrm{go}}$-tracking, which can be efficiently implemented by a neural network and is shown to outperform existing algorithms. However, this rate requires a nontrivial condition to be achievable. To address this issue, we introduce the second rate $R^{\\mathrm{go}}_\\infty$. We show that this rate is indeed achievable by introducing a conceptual algorithm called delayed optimal tracking (DOT)."}}
{"id": "X5XvHnE_1M", "cdate": 1640995200000, "mdate": 1683896064451, "content": {"title": "Bayes Optimal Algorithm is Suboptimal in Frequentist Best Arm Identification", "abstract": "We consider the fixed-budget best-arm identification problem with Normal reward distributions. In this problem, the forecaster is given $K$ arms (or treatments) and $T$ time steps. The forecaster attempts to find the best arm, defined by the largest mean, via an adaptive experiment conducted using an algorithm. The algorithm's performance is measured by the simple regret, that is, the quality of the estimated best arm. The frequentist simple regret can be exponentially small to $T$, whereas the Bayesian simple regret is polynomially small to $T$. This paper demonstrates that Bayes optimal algorithm, which minimizes the Bayesian simple regret, does not produce an exponential simple regret for some parameters, a finding that contrasts with the many results indicating the asymptotic equivalence of Bayesian and frequentist algorithms in the context of fixed sampling regimes. While the Bayes optimal algorithm is described in terms of a recursive equation that is virtually impossible to compute exactly, we establish the foundations for further analysis by introducing a key quantity that we call the expected Bellman improvement."}}
