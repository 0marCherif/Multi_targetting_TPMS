{"id": "gEyrgahyXpf", "cdate": 1680532676878, "mdate": 1680532676878, "content": {"title": "AgileAvatar: Stylized 3D Avatar Creation via Cascaded Domain Bridging", "abstract": "Stylized 3D avatars have become increasingly prominent in our modern life. Creating these avatars manually usually involves laborious selection and adjustment of continuous and discrete parameters and is time-consuming for average users. Self-supervised approaches to automatically create 3D avatars from user selfies promise high quality with little annotation cost but fall short in application to stylized avatars due to a large style domain gap. We propose a novel self-supervised learning framework to create high-quality stylized 3D avatars with a mix of continuous and discrete parameters. Our cascaded domain bridging framework first leverages a modified portrait stylization approach to translate input selfies into stylized avatar renderings as the targets for desired 3D avatars. Next, we find the best parameters of the avatars to match the stylized avatar renderings through a differentiable imitator we train to mimic the avatar graphics engine. To ensure we can effectively optimize the discrete parameters, we adopt a cascaded relaxation-and-search pipeline. We use a human preference study to evaluate how well our method preserves user identity compared to previous work as well as manual creation. Our results achieve much higher preference scores than previous work and close to those of manual creation. We also provide an ablation study to justify the design choices in our pipeline."}}
{"id": "knQ6_Jd_1X-", "cdate": 1640995200000, "mdate": 1668701876372, "content": {"title": "DuelGAN: A Duel Between Two Discriminators Stabilizes the GAN Training", "abstract": "In this paper, we introduce DuelGAN, a generative adversarial network (GAN) solution to improve the stability of the generated samples and to mitigate mode collapse. Built upon the Vanilla GAN\u2019s two-player game between the discriminator $$D_1$$ and the generator G, we introduce a peer discriminator $$D_2$$ to the min-max game. Similar to previous work using two discriminators, the first role of both $$D_1$$ , $$D_2$$ is to distinguish between generated samples and real ones, while the generator tries to generate high-quality samples which are able to fool both discriminators. Different from existing methods, we introduce a duel between $$D_1$$ and $$D_2$$ to discourage their agreement and therefore increase the level of diversity of the generated samples. This property alleviates the issue of early mode collapse by preventing $$D_1$$ and $$D_2$$ from converging too fast. We provide theoretical analysis for the equilibrium of the min-max game formed among $$G,D_1,D_2$$ . We offer convergence behavior of DuelGAN as well as stability of the min-max game. It\u2019s worth mentioning that DuelGAN operates in the unsupervised setting, and the duel between $$D_1$$ and $$D_2$$ does not need any label supervision. Experiments results on a synthetic dataset and on real-world image datasets (MNIST, Fashion MNIST, CIFAR-10, STL-10, CelebA, VGG) demonstrate that DuelGAN outperforms competitive baseline work in generating diverse and high-quality samples, while only introduces negligible computation cost. Our code is publicly available at https://github.com/UCSC-REAL/DuelGAN ."}}
{"id": "DdKiiLB81ge", "cdate": 1640995200000, "mdate": 1668701876373, "content": {"title": "How much does input data type impact final face model accuracy?", "abstract": "Face models are widely used in image processing and other domains. The input data to create a 3D face model ranges from accurate laser scans to simple 2D RGB photographs. These input data types are typically deficient either due to missing regions, or because they are underconstrained. As a result, reconstruction methods include embedded priors encoding the valid domain of faces. System designers must choose a source of input data and then choose a reconstruction method to obtain a usable 3D face. If a particular application domain requires accuracy X, which kinds of input data are suitable? Does the input data need to be 3D, or will 2D data suffice? This paper takes a step toward answering these questions using synthetic data. A ground truth dataset is used to analyze accuracy obtainable from 2D landmarks, 3D landmarks, low quality 3D, high quality 3D, texture color, normals, dense 2D image data, and when regions of the face are missing. Since the data is synthetic it can be analyzed both with and without measurement error. This idealized synthetic analysis is then compared to real results from several methods for constructing 3D faces from 2D photographs. The experimental results suggest that accuracy is severely limited when only 2D raw input data exists."}}
