{"id": "GH2R4Ezsq4X", "cdate": 1672531200000, "mdate": 1693253988408, "content": {"title": "Searching for Optimal Per-Coordinate Step-sizes with Multidimensional Backtracking", "abstract": "The backtracking line-search is an effective technique to automatically tune the step-size in smooth optimization. It guarantees similar performance to using the theoretically optimal step-size. Many approaches have been developed to instead tune per-coordinate step-sizes, also known as diagonal preconditioners, but none of the existing methods are provably competitive with the optimal per-coordinate stepsizes. We propose multidimensional backtracking, an extension of the backtracking line-search to find good diagonal preconditioners for smooth convex problems. Our key insight is that the gradient with respect to the step-sizes, also known as hypergradients, yields separating hyperplanes that let us search for good preconditioners using cutting-plane methods. As black-box cutting-plane approaches like the ellipsoid method are computationally prohibitive, we develop an efficient algorithm tailored to our setting. Multidimensional backtracking is provably competitive with the best diagonal preconditioner and requires no manual tuning."}}
{"id": "JvkqFiNTVx", "cdate": 1640995200000, "mdate": 1672081098771, "content": {"title": "Continuous Prediction with Experts' Advice", "abstract": "Prediction with experts' advice is one of the most fundamental problems in online learning and captures many of its technical challenges. A recent line of work has looked at online learning through the lens of differential equations and continuous-time analysis. This viewpoint has yielded optimal results for several problems in online learning. In this paper, we employ continuous-time stochastic calculus in order to study the discrete-time experts' problem. We use these tools to design a continuous-time, parameter-free algorithm with improved guarantees for the quantile regret. We then develop an analogous discrete-time algorithm with a very similar analysis and identical quantile regret bounds. Finally, we design an anytime continuous-time algorithm with regret matching the optimal fixed-time rate when the gains are independent Brownian Motions; in many settings, this is the most difficult case. This gives some evidence that, even with adversarial gains, the optimal anytime and fixed-time regrets may coincide."}}
{"id": "JdBM8l2rUum", "cdate": 1640995200000, "mdate": 1693254009614, "content": {"title": "Online Mirror Descent and Dual Averaging: Keeping Pace in the Dynamic Case", "abstract": "Online mirror descent (OMD) and dual averaging (DA)---two fundamental algorithms for online convex optimization---are known to have very similar (and sometimes identical) performance guarantees when used with a fixed learning rate. Under dynamic learning rates, however, OMD is provably inferior to DA and suffers linear regret, even in common settings such as prediction with expert advice. We modify the OMD algorithm through a simple technique that we call stabilization. We give essentially the same abstract regret bound for OMD with stabilization and for DA by modifying the classical OMD convergence analysis in a careful and modular way that allows for straightforward and flexible proofs. Simple corollaries of these bounds show that OMD with stabilization and DA enjoy the same performance guarantees in many applications---even under dynamic learning rates. We also shed light on the similarities between OMD and DA and show simple conditions under which stabilized-OMD and DA generate the same iterates. Finally, we show how to effectively use dual-stabilization with composite cost functions with simple adaptations to both the algorithm and its analysis."}}
{"id": "6l6_NpHxqv", "cdate": 1640995200000, "mdate": 1672081098751, "content": {"title": "Efficient and Optimal Fixed-Time Regret with Two Experts", "abstract": "Prediction with expert advice is a foundational problem in online learning. In instances with \\(T\\) rounds and \\(n\\) experts, the classical Multiplicative Weights Update method suffers at most \\(\\s..."}}
{"id": "k3mJ8_74Kh", "cdate": 1577836800000, "mdate": null, "content": {"title": "Online mirror descent and dual averaging: keeping pace in the dynamic case", "abstract": "Online mirror descent (OMD) and dual averaging (DA)\u2014two fundamental algorithms for online convex optimization\u2014are known to have very similar (and sometimes identical) performance guarantees when us..."}}
{"id": "OIXiRvZpBS", "cdate": 1577836800000, "mdate": 1684352343279, "content": {"title": "Regret Bounds without Lipschitz Continuity: Online Learning with Relative-Lipschitz Losses", "abstract": "In online convex optimization (OCO), Lipschitz continuity of the functions is commonly assumed in order to obtain sublinear regret. Moreover, many algorithms have only logarithmic regret when these functions are also strongly convex. Recently, researchers from convex optimization proposed the notions of <code>relative Lipschitz continuity'' and</code>relative strong convexity''. Both of the notions are generalizations of their classical counterparts. It has been shown that subgradient methods in the relative setting have performance analogous to their performance in the classical setting. In this work, we consider OCO for relative Lipschitz and relative strongly convex functions. We extend the known regret bounds for classical OCO algorithms to the relative setting. Specifically, we show regret bounds for the follow the regularized leader algorithms and a variant of online mirror descent. Due to the generality of these methods, these results yield regret bounds for a wide variety of OCO algorithms. Furthermore, we further extend the results to algorithms with extra regularization such as regularized dual averaging."}}
{"id": "Akx9Ao652jL", "cdate": 1577836800000, "mdate": null, "content": {"title": "Regret Bounds without Lipschitz Continuity: Online Learning with Relative-Lipschitz Losses", "abstract": "In online convex optimization (OCO), Lipschitz continuity of the functions is commonly assumed in order to obtain sublinear regret. Moreover, many algorithms have only logarithmic regret when these functions are also strongly convex. Recently, researchers from convex optimization proposed the notions of \"relative Lipschitz continuity\" and \"relative strong convexity\". Both of the notions are generalizations of their classical counterparts. It has been shown that subgradient methods in the relative setting have performance analogous to their performance in the classical setting. In this work, we consider OCO for relative Lipschitz and relative strongly convex functions. We extend the known regret bounds for classical OCO algorithms to the relative setting. Specifically, we show regret bounds for the follow the regularized leader algorithms and a variant of online mirror descent. Due to the generality of these methods, these results yield regret bounds for a wide variety of OCO algorithms. Furthermore, we further extend the results to algorithms with extra regularization such as regularized dual averaging."}}
