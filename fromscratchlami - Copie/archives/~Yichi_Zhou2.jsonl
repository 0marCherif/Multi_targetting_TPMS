{"id": "oJZ8bPtCar", "cdate": 1663850153544, "mdate": null, "content": {"title": "Stochastic No-regret Learning for General Games with Variance Reduction", "abstract": "We show that a stochastic version of optimistic mirror descent (OMD), a variant of mirror descent with recency bias, converges fast in general games. More specifically, with our algorithm, the individual regret of each player vanishes at a speed of $O(1/T^{3/4})$ and the sum of all players' regret vanishes at a speed of $O(1/T)$, which is an improvement upon the $O(1/\\sqrt{T})$ convergence rate of prior stochastic algorithms, where $T$ is the number of interaction rounds. Due to the advantage of stochastic methods in the computational cost, we significantly improve the time complexity over the deterministic algorithms to approximate coarse correlated equilibrium. To achieve lower time complexity, we equip the stochastic version of OMD in \\cite{alacaoglu2021stochastic} with a novel low-variance Monte-Carlo estimator. Our algorithm extends previous works \\cite{alacaoglu2021stochastic,carmon2019variance} from two-player zero-sum games to general games. "}}
{"id": "yXBb-0cPSKO", "cdate": 1632875667158, "mdate": null, "content": {"title": "Regularized-OFU: an efficient algorithm for general contextual bandit with optimization oracles", "abstract": "In contextual bandit, one major challenge is to develop theoretically solid and empirically efficient  algorithms for general function classes. We present a novel algorithm called \\emph{regularized optimism in face of uncertainty (ROFU)} for general contextual bandit problems. It exploits an optimization oracle to calculate the well-founded upper confidence bound (UCB).  Theoretically, for general function classes under very mild assumptions, it achieves a near-optimal regret bound $\\Tilde{O}(\\sqrt{T})$. Practically, one great advantage of ROFU is that the optimization oracle can be efficiently implemented with low computational cost. Thus, we can easily extend ROFU for  contextual bandits with deep neural networks as the function class, which outperforms strong baselines including the UCB and Thompson sampling variants. "}}
{"id": "SJNGSy-OWH", "cdate": 1514764800000, "mdate": null, "content": {"title": "Selective Verification Strategy for Learning From Crowds", "abstract": "To deal with the low qualities of web workers in crowdsourcing, many unsupervised label aggregation methods have been investigated but most of them provide inconsistent performance. In this paper, we explore the learning from crowds with selective verification problem. In addition to the noisy responses from the crowds, it also collects the ground truths for a well-chosen subset of tasks as the reference, then aggregates the redundant responses based on the patterns provided by both the supervised and unsupervised signal. To improve the labeling efficiency, we propose the EBM selecting strategy for choosing the verification subset, which is based on the loss error minimization. Specifically, we first establish the expected loss error given the semi-supervised learning estimate, then find the subset that minimizes this selecting criterion. We do extensive empirical comparisons on both synthetic and real-world datasets to show the benefits of this new learning setting as well as our proposal."}}
{"id": "S1b_3o-dZH", "cdate": 1514764800000, "mdate": null, "content": {"title": "Racing Thompson: an Efficient Algorithm for Thompson Sampling with Non-conjugate Priors", "abstract": "Thompson sampling has impressive empirical performance for many multi-armed bandit problems. But current algorithms for Thompson sampling only work for the case of conjugate priors since they requi..."}}
{"id": "rkZ1esbOWS", "cdate": 1483228800000, "mdate": null, "content": {"title": "Identify the Nash Equilibrium in Static Games with Random Payoffs", "abstract": "We study the problem on how to learn the pure Nash Equilibrium of a two-player zero-sum static game with random payoffs under unknown distributions via efficient payoff queries. We introduce a mult..."}}
