{"id": "iTCGGSc91p", "cdate": 1687827765158, "mdate": 1687827765158, "content": {"title": "Penguins Don't Fly: Reasoning about Generics through Instantiations and Exceptions", "abstract": "Generics express generalizations about the\nworld (e.g., birds can fly) that are not universally true (e.g., newborn birds and penguins\ncannot fly). Commonsense knowledge bases,\nused extensively in NLP, encode some generic\nknowledge but rarely enumerate such exceptions and knowing when a generic statement\nholds or does not hold true is crucial for developing a comprehensive understanding of\ngenerics. We present a novel framework informed by linguistic theory to generate EXEMPLARS\u2014specific cases when a generic holds\ntrue or false. We generate \u223c19k exemplars for\n\u223c650 generics and show that our framework\noutperforms a strong GPT-3 baseline by 12.8\nprecision points. Our analysis highlights the\nimportance of linguistic theory-based controllability for generating exemplars, the insufficiency of knowledge bases as a source of exemplars, and the challenges exemplars pose\nfor the task of natural language inference."}}
{"id": "CJgmD_DqYZ0", "cdate": 1634236321588, "mdate": 1634236321588, "content": {"title": "Natural Language Rationales with Full-Stack Visual Reasoning: From Pixels to Semantic Frames to Commonsense Graphs", "abstract": "Natural language rationales could provide intuitive, higher-level explanations that are easily understandable by humans, complementing the more broadly studied lower-level explanations based on gradients or attention weights. We present the first study focused on generating natural language rationales across several complex visual reasoning tasks: visual commonsense reasoning, visual-textual entailment, and visual question answering. The key challenge of accurate rationalization is comprehensive image understanding at all levels: not just their explicit content at the pixel level, but their contextual contents at the semantic and pragmatic levels. We present Rationale^VT Transformer, an integrated model that learns to generate free-text rationales by combining pretrained language models with object recognition, grounded visual semantic frames, and visual commonsense graphs. Our experiments show that the base pretrained language model benefits from visual adaptation and that free-text rationalization is a promising research direction to complement model interpretability for complex visual-textual reasoning tasks.\n"}}
{"id": "qF7FlUT5dxa", "cdate": 1623081048955, "mdate": null, "content": {"title": "CommonsenseQA 2.0: Exposing the Limits of AI through Gamification", "abstract": "Constructing benchmarks that test the abilities of modern natural language understanding models is difficult - pre-trained language models exploit artifacts in benchmarks to achieve human parity, but still fail on adversarial examples and make errors that demonstrate a lack of common sense. In this work, we propose gamification as a framework for data construction. \nThe goal of players in the game is to compose questions that mislead a rival AI while using specific phrases for extra points. The game environment leads to enhanced user engagement and simultaneously gives the game designer control over the collected data, allowing us to collect high-quality data at scale. Using our method we create CommonsenseQA 2.0, which includes 14,343 yes/no questions, and demonstrate its difficulty for models that are orders-of-magnitude larger than the AI used in the game itself.\nOur best baseline, the T5-based Unicorn with 11B parameters achieves an accuracy of 70.2%, substantially higher than GPT-3 (52.9%) in a few-shot inference setup.  Both score well below human performance which is at 94.1%."}}
{"id": "x0TstPCQfa5", "cdate": 1609459200000, "mdate": 1637789272565, "content": {"title": "proScript: Partially Ordered Scripts Generation", "abstract": "Keisuke Sakaguchi, Chandra Bhagavatula, Ronan Le Bras, Niket Tandon, Peter Clark, Yejin Choi. Findings of the Association for Computational Linguistics: EMNLP 2021. 2021."}}
{"id": "vDD4-oV14-Q", "cdate": 1609459200000, "mdate": 1634320327454, "content": {"title": "NeuroLogic Decoding: (Un)supervised Neural Text Generation with Predicate Logic Constraints", "abstract": "Ximing Lu, Peter West, Rowan Zellers, Ronan Le Bras, Chandra Bhagavatula, Yejin Choi. Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. 2021."}}
{"id": "qXezptOpHkh", "cdate": 1609459200000, "mdate": null, "content": {"title": "\"I'm Not Mad\": Commonsense Implications of Negation and Contradiction", "abstract": "Natural language inference requires reasoning about contradictions, negations, and their commonsense implications. Given a simple premise (e.g., \"I'm mad at you\"), humans can reason about the varying shades of contradictory statements ranging from straightforward negations (\"I'm not mad at you\") to commonsense contradictions (\"I'm happy\"). Moreover, these negated or contradictory statements shift the commonsense implications of the original premise in nontrivial ways. For example, while \"I'm mad\" implies \"I'm unhappy about something,\" negating the premise (i.e., \"I'm not mad\") does not necessarily negate the corresponding commonsense implications. In this paper, we present the first comprehensive study focusing on commonsense implications of negated statements and contradictions. We introduce ANION1, a new commonsense knowledge graph with 624K if-then rules focusing on negated and contradictory events. We then present joint generative and discriminative inference models for this new resource, providing novel empirical insights on how logical negations and commonsense contradictions reshape the commonsense implications of their original premises."}}
{"id": "qE83w4KQw6L", "cdate": 1609459200000, "mdate": 1631128870211, "content": {"title": "Reflective Decoding: Beyond Unidirectional Generation with Off-the-Shelf Language Models", "abstract": "Peter West, Ximing Lu, Ari Holtzman, Chandra Bhagavatula, Jena D. Hwang, Yejin Choi. Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers). 2021."}}
{"id": "mgs9v1kHArR", "cdate": 1609459200000, "mdate": null, "content": {"title": "UNICORN on RAINBOW: A Universal Commonsense Reasoning Model on a New Multitask Benchmark", "abstract": "Commonsense AI has long been seen as a near impossible goal -- until recently. Now, research interest has sharply increased with an influx of new benchmarks and models. We propose two new ways to evaluate commonsense models, emphasizing their generality on new tasks and building on diverse, recently introduced benchmarks. First, we propose a new multitask benchmark, RAINBOW, to promote research on commonsense models that generalize well over multiple tasks and datasets. Second, we propose a novel evaluation, the cost equivalent curve, that sheds new insight on how the choice of source datasets, pretrained language models, and transfer learning methods impacts performance and data efficiency. We perform extensive experiments -- over 200 experiments encompassing 4800 models -- and report multiple valuable and sometimes surprising findings, e.g., that transfer almost always leads to better or equivalent performance if following a particular recipe, that QA-based commonsense datasets transfer well with each other, while commonsense knowledge graphs do not, and that perhaps counter-intuitively, larger models benefit more from transfer than smaller ones. Last but not least, we introduce a new universal commonsense reasoning model, UNICORN, that establishes new state-of-the-art performance across 8 popular commonsense benchmarks, aNLI (87.3%), CosmosQA (91.8%), HellaSWAG (93.9%), PIQA (90.1%), SocialIQa (83.2%), WinoGrande (86.6%), CycIC (94.0%) and CommonsenseQA (79.3%)."}}
{"id": "lLHpItNi83t", "cdate": 1609459200000, "mdate": 1637090901900, "content": {"title": "Paragraph-level Commonsense Transformers with Recurrent Memory", "abstract": "Human understanding of narrative texts requires making commonsense inferences beyond what is stated in the text explicitly. A recent model, COMET, can generate such inferences along several dimensions such as pre- and post-conditions, motivations, and mental states of the participants. However, COMET was trained on short phrases, and is therefore discourse-agnostic. When presented with each sentence of a multi-sentence narrative, it might generate inferences that are inconsistent with the rest of the narrative. We present the task of discourse-aware commonsense inference. Given a sentence within a narrative, the goal is to generate commonsense inferences along predefined dimensions, while maintaining coherence with the rest of the narrative. Such large-scale paragraph-level annotation is hard to get and costly, so we use available sentence-level annotations to efficiently and automatically construct a distantly supervised corpus. Using this corpus, we train PARA-COMET, a discourse-aware model that incorporates paragraph-level information to generate coherent commonsense inferences from narratives. PARA-COMET captures both semantic knowledge pertaining to prior world knowledge, and episodic knowledge involving how current events relate to prior and future events in a narrative. Our results confirm that PARA-COMET outperforms the sentence-level baselines, particularly in generating inferences that are both coherent and novel."}}
{"id": "e4Oxtu6fUN", "cdate": 1609459200000, "mdate": 1637789272042, "content": {"title": "Symbolic Knowledge Distillation: from General Language Models to Commonsense Models", "abstract": "The common practice for training commonsense models has gone from-human-to-corpus-to-machine: humans author commonsense knowledge graphs in order to train commonsense models. In this work, we investigate an alternative, from-machine-to-corpus-to-machine: general language models author these commonsense knowledge graphs to train commonsense models. Our study leads to a new framework, Symbolic Knowledge Distillation. As with prior art in Knowledge Distillation (Hinton et al., 2015), our approach uses larger models to teach smaller models. A key difference is that we distill knowledge symbolically-as text-in addition to the neural model. We also distill only one aspect-the commonsense of a general language model teacher, allowing the student to be a different type, a commonsense model. Altogether, we show that careful prompt engineering and a separately trained critic model allow us to selectively distill high-quality causal commonsense from GPT-3, a general language model. Empirical results demonstrate that, for the first time, a human-authored commonsense knowledge graph is surpassed by our automatically distilled variant in all three criteria: quantity, quality, and diversity. In addition, it results in a neural commonsense model that surpasses the teacher model's commonsense capabilities despite its 100x smaller size. We apply this to the ATOMIC resource, and share our new symbolic knowledge graph and commonsense models."}}
