{"id": "wzlWiO_WY4", "cdate": 1663850228074, "mdate": null, "content": {"title": "Calibration Matters: Tackling Maximization Bias in Large-scale Advertising Recommendation Systems", "abstract": "Calibration is defined as the ratio of the average predicted click rate to the true click rate. The optimization of calibration is essential to many online advertising recommendation systems because it directly affects the downstream bids in ads auctions and the amount of money charged to advertisers. Despite its importance, calibration often suffers from a problem called \u201cmaximization bias\u201d. Maximization bias refers to the phenomenon that the maximum of predicted values overestimates the true maximum. The problem is introduced because the calibration is computed on the set selected by the prediction model itself. It persists even if unbiased predictions are achieved on every datapoint and worsens when covariate shifts exist between the training and test sets. To mitigate this problem, we quantify maximization bias and propose a variance-adjusting debiasing (VAD) meta-algorithm in this paper. The algorithm is efficient, robust, and practical as it is able to mitigate maximization bias problem under covariate shifts, without incurring additional online serving costs or compromising the ranking performance. We demonstrate the effectiveness of the proposed algorithm  using a state-of-the-art recommendation neural network model on a large-scale real-world dataset."}}
{"id": "w09h18VeZv", "cdate": 1577836800000, "mdate": null, "content": {"title": "Robust Bayesian Classification Using an Optimistic Score Ratio", "abstract": "We build a Bayesian contextual classification model using an optimistic score ratio for robust binary classification when there is limited information on the class-conditional, or contextual, distribution. The optimistic score searches for the distribution that is most plausible to explain the observed outcomes in the testing sample among all distributions belonging to the contextual ambiguity set which is prescribed using a limited structural constraint on the mean vector and the covariance matrix of the underlying contextual distribution. We show that the Bayesian classifier using the optimistic score ratio is conceptually attractive, delivers solid statistical guarantees and is computationally tractable. We showcase the power of the proposed optimistic score ratio classifier on both synthetic and empirical data."}}
{"id": "tACV7On7Lit", "cdate": 1577836800000, "mdate": null, "content": {"title": "Quantifying the Empirical Wasserstein Distance to a Set of Measures: Beating the Curse of Dimensionality", "abstract": "We consider the problem of estimating the Wasserstein distance between the empirical measure and a set of probability measures whose expectations over a class of functions (hypothesis class) are constrained. If this class is sufficiently rich to characterize a particular distribution (e.g., all Lipschitz functions), then our formulation recovers the Wasserstein distance to such a distribution. We establish a strong duality result that generalizes the celebrated Kantorovich-Rubinstein duality. We also show that our formulation can be used to beat the curse of dimensionality, which is well known to affect the rates of statistical convergence of the empirical Wasserstein distance. In particular, examples of infinite-dimensional hypothesis classes are presented, informed by a complex correlation structure, for which it is shown that the empirical Wasserstein distance to such classes converges to zero at the standard parametric rate. Our formulation provides insights that help clarify why, despite the curse of dimensionality, the Wasserstein distance enjoys favorable empirical performance across a wide range of statistical applications."}}
{"id": "Bdbn96x7xFe", "cdate": 1577836800000, "mdate": null, "content": {"title": "Robust Bayesian Classification Using An Optimistic Score Ratio", "abstract": "We build a Bayesian contextual classification model using an optimistic score ratio for robust binary classification when there is limited information on the class-conditional, or contextual, distr..."}}
{"id": "6ho3ObsYYOY", "cdate": 1577836800000, "mdate": null, "content": {"title": "Distributionally Robust Policy Evaluation and Learning in Offline Contextual Bandits", "abstract": "Policy learning using historical observational data is an important problem that has found widespread applications. However, existing literature rests on the crucial assumption that the future envi..."}}
{"id": "0s7WVXR7KsQ", "cdate": 1577836800000, "mdate": null, "content": {"title": "Distributional Robust Batch Contextual Bandits", "abstract": "Policy learning using historical observational data is an important problem that has found widespread applications. Examples include selecting offers, prices, advertisements to send to customers, as well as selecting which medication to prescribe to a patient. However, existing literature rests on the crucial assumption that the future environment where the learned policy will be deployed is the same as the past environment that has generated the data -- an assumption that is often false or too coarse an approximation. In this paper, we lift this assumption and aim to learn a distributionally robust policy with incomplete observational data. We first present a policy evaluation procedure that allows us to assess how well the policy does under the worst-case environment shift. We then establish a central limit theorem type guarantee for this proposed policy evaluation scheme. Leveraging this evaluation scheme, we further propose a novel learning algorithm that is able to learn a policy that is robust to adversarial perturbations and unknown covariate shifts with a performance guarantee based on the theory of uniform convergence. Finally, we empirically test the effectiveness of our proposed algorithm in synthetic datasets and demonstrate that it provides the robustness that is missing using standard policy learning algorithms. We conclude the paper by providing a comprehensive application of our methods in the context of a real-world voting dataset."}}
{"id": "UgKYuEfFajE", "cdate": 1546300800000, "mdate": null, "content": {"title": "Optimal uncertainty size in distributionally robust inverse covariance estimation", "abstract": "In a recent paper, Nguyen et\u00a0al. (2018) built a distributionally robust estimator for the precision matrix of the Gaussian distribution. The distributional uncertainty size is a key ingredient in the construction of this estimator. We develop a statistical theory which shows how to optimally choose the uncertainty size to minimize the associated Stein loss. Surprisingly, rather than the expected canonical square-root scaling rate, the optimal uncertainty size scales linearly with the sample size."}}
