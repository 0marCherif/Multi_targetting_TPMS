{"id": "C0kuQYU7RJ", "cdate": 1693526400000, "mdate": 1695961943600, "content": {"title": "Fast sharpness-aware training for periodic time series classification and forecasting", "abstract": ""}}
{"id": "Kcmh8ym11V", "cdate": 1684063983971, "mdate": 1684063983971, "content": {"title": "Joint Transfer of Model Knowledge and Fairness Over Domains Using Wasserstein Distance", "abstract": "Owing to the increasing use of machine learning in our daily lives, the problem of fairness has recently become an important topic in machine learning societies. Recent studies regarding fairness in machine learning have been conducted to attempt to ensure statistical independence between individual model predictions and designated sensitive attributes. However, in reality, cases exist in which the sensitive variables of data used for learning models differ from the data upon which the model is applied. In this paper, we investigate a methodology for developing a fair classification model for data with limited or no labels, by transferring knowledge from another data domain where information is fully available. This is done by controlling the Wasserstein distances between relevant distributions. Subsequently, we obtain a fair model that could be successfully applied to two datasets with different sensitive attributes. We present theoretical results validating that our approach provably transfers both classification performance and fairness over domains. Experimental results show that our method does indeed promote fairness for the target domain, while retaining reasonable classification accuracy, and that it often outperforms comparative models in terms of joint fairness."}}
{"id": "kXo5TKXgBBz", "cdate": 1683880307468, "mdate": 1683880307468, "content": {"title": "Graddiv: Adversarial robustness of randomized neural networks via gradient diversity regularization", "abstract": "Deep learning is vulnerable to adversarial examples. Many defenses based on randomized neural networks have been proposed to solve the problem, but fail to achieve robustness against attacks using proxy gradients such as the Expectation over Transformation (EOT) attack. We investigate the effect of the adversarial attacks using proxy gradients on randomized neural networks and demonstrate that it highly relies on the directional distribution of the loss gradients of the randomized neural network. We show in particular that proxy gradients are less effective when the gradients are more scattered. To this end, we propose Gradient Diversity (GradDiv) regularizations that minimize the concentration of the gradients to build a robust randomized neural network. Our experiments on MNIST, CIFAR10, and STL10 show that our proposed GradDiv regularizations improve the adversarial robustness of randomized neural networks against a variety of state-of-the-art attack methods. Moreover, our method efficiently reduces the transferability among sample models of randomized neural networks."}}
{"id": "X55oS5kccN", "cdate": 1683880212650, "mdate": null, "content": {"title": "Lipschitz-certifiable training with a tight outer bound", "abstract": "Verifiable training is a promising research direction for training a robust network. However, most verifiable training methods are slow or lack scalability. In this study, we propose a fast and scalable certifiable training algorithm based on Lipschitz analysis and interval arithmetic. Our certifiable training algorithm provides a tight propagated outer bound by introducing the box constraint propagation (BCP), and it efficiently computes the worst logit over the outer bound. In the experiments, we show that BCP achieves a tighter outer bound than the global Lipschitz-based outer bound. Moreover, our certifiable training algorithm is over 12 times faster than the state-of-the-art dual relaxation-based method; however, it achieves comparable or better verification performance, improving natural accuracy. Our fast certifiable training algorithm with the tight outer bound can scale to Tiny ImageNet with verification accuracy of 20.1\\%(l2-perturbation of 36/255). Our code is available at \\url {https://github. com/sungyoon-lee/bcp}."}}
{"id": "OraNUPqfQff", "cdate": 1682899200000, "mdate": 1695962012310, "content": {"title": "Efficient homomorphic encryption framework for privacy-preserving regression", "abstract": "Homomorphic encryption (HE) has recently attracted considerable attention as a key solution for privacy-preserving machine learning because HE can apply to various areas that require to delegate outsourcing computations of user\u2019s data. Nevertheless, its computational inefficiency still hinders its wider application. In this study, we propose an alternative to bridge the gap between the privacy and efficiency of HE by encrypting only a small amount of private information. We first derive an exact solution to HE-friendly ridge regression with multiple private variables, while linearly reducing the computational complexity of this algorithm over the number of variables. The proposed method has the advantage that it can be implemented using any HE scheme. Moreover, we propose an adversarial perturbation method that can prevent potential attacks on private variables, which have rarely been explored in HE-based machine learning studies. An extensive experiment on real-world benchmarking datasets supports the effectiveness of our method."}}
{"id": "3romVtF37lz", "cdate": 1682899200000, "mdate": 1683962241220, "content": {"title": "Generating Transferable Adversarial Examples for Speech Classification", "abstract": ""}}
{"id": "uebhA5xHb1", "cdate": 1672531200000, "mdate": 1695961943617, "content": {"title": "Implicit Jacobian regularization weighted with impurity of probability output", "abstract": "The success of deep learning is greatly attributed to stochastic gradient descent (SGD), yet it remains unclear how SGD finds well-generalized models. We demonstrate that SGD has an implicit regula..."}}
{"id": "tMYNYW0jug", "cdate": 1672531200000, "mdate": 1679965814812, "content": {"title": "Stability Analysis of Sharpness-Aware Minimization", "abstract": ""}}
{"id": "tKtZqNK2mV", "cdate": 1672531200000, "mdate": 1695962012322, "content": {"title": "Unraveling the MEV Enigma: ABI-Free Detection Model using Graph Neural Networks", "abstract": "The detection of Maximal Extractable Value (MEV) in blockchain is crucial for enhancing blockchain security, as it enables the evaluation of potential consensus layer risks, the effectiveness of anti-centralization solutions, and the assessment of user exploitation. However, existing MEV detection methods face limitations due to their low recall rate, reliance on pre-registered Application Binary Interfaces (ABIs) and the need for continuous monitoring of new DeFi services. In this paper, we propose ArbiNet, a novel GNN-based detection model that offers a low-overhead and accurate solution for MEV detection without requiring knowledge of smart contract code or ABIs. We collected an extensive MEV dataset, surpassing currently available public datasets, to train ArbiNet. Our implemented model and open dataset enhance the understanding of the MEV landscape, serving as a foundation for MEV quantification and improved blockchain security."}}
{"id": "oYWInODzDT", "cdate": 1672531200000, "mdate": 1683962240598, "content": {"title": "Improving the Utility of Differentially Private Clustering through Dynamical Processing", "abstract": "This study aims to alleviate the trade-off between utility and privacy in the task of differentially private clustering. Existing works focus on simple clustering methods, which show poor clustering performance for non-convex clusters. By utilizing Morse theory, we hierarchically connect the Gaussian sub-clusters to fit complex cluster distributions. Because differentially private sub-clusters are obtained through the existing methods, the proposed method causes little or no additional privacy loss. We provide a theoretical background that implies that the proposed method is inductive and can achieve any desired number of clusters. Experiments on various datasets show that our framework achieves better clustering performance at the same privacy level, compared to the existing methods."}}
