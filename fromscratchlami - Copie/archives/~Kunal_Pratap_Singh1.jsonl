{"id": "xMnFw-ALjh", "cdate": 1695989143147, "mdate": 1695989143147, "content": {"title": "Agent with the Big Picture: Perceiving Surroundings for Interactive Instruction Following", "abstract": "We address the interactive instruction following task which requires an agent to navigate through an environment, interact with objects, and complete long-horizon tasks, following natural language instructions with egocentric vision. To successfully achieve a goal in the interactive instruction following task, the agent should infer a sequence of actions and object interactions. When performing actions, a small field of view often limits the agent\u2019s understanding of an environment, leading to poor performance. Here, we propose to exploit surrounding views by additional observations from navigable directions to enlarge the field of view of the agent."}}
{"id": "5wV2_58VrzO", "cdate": 1680535403356, "mdate": 1680535403356, "content": {"title": "A General Purpose Supervisory Signal for Embodied Agents", "abstract": "Training effective embodied AI agents often involves manual reward engineering, expert imitation, specialized components such as maps, or leveraging additional sensors for depth and localization. Another approach is to use neural architectures alongside self-supervised objectives which encourage better representation learning. In practice, there are few guarantees that these self-supervised\nobjectives encode task relevant information. We propose the Scene Graph Contrastive (SGC) loss, which uses scene\ngraphs as general-purpose, training-only, supervisory signals. The SGC loss does away with explicit graph decoding and instead uses contrastive learning to align an agent\u2019s representation with a rich graphical encoding of its environment. The SGC loss is generally applicable, simple to implement, and encourages representations that encode objects\u2019 semantics, relationships, and history. By using the\nSGC loss, we attain large gains on three embodied tasks: Object Navigation, Multi-Object Navigation, and Arm Point\nNavigation. Finally, we present studies and analyses which demonstrate the ability of our trained representation to encode semantic cues about the environment."}}
{"id": "_bqtjfpj8h", "cdate": 1652737389721, "mdate": null, "content": {"title": "Ask4Help: Learning to Leverage an Expert for Embodied Tasks", "abstract": "Embodied AI agents continue to become more capable every year with the advent of new models, environments, and benchmarks, but are still far away from being performant and reliable enough to be deployed in real, user-facing, applications. In this paper, we ask: can we bridge this gap by enabling agents to ask for assistance from an expert such as a human being? To this end, we propose the Ask4Help policy that augments agents with the ability to request, and then use expert assistance. Ask4Help policies can be efficiently trained without modifying the original agent's parameters and learn a desirable trade-off between task performance and the amount of requested help, thereby reducing the cost of querying the expert. We evaluate Ask4Help on two different tasks -- object goal navigation and room rearrangement and see substantial improvements in performance using minimal help. On object navigation, an agent that achieves a $52\\%$ success rate is raised to $86\\%$ with $13\\%$ help and for rearrangement, the state-of-the-art model with a $7\\%$ success rate is dramatically improved to $90.4\\%$ using $39\\%$ help. Human trials with Ask4Help demonstrate the efficacy of our approach in practical scenarios."}}
{"id": "moYWND8PiD", "cdate": 1640995200000, "mdate": 1682368466373, "content": {"title": "A General Purpose Supervisory Signal for Embodied Agents", "abstract": "Training effective embodied AI agents often involves manual reward engineering, expert imitation, specialized components such as maps, or leveraging additional sensors for depth and localization. Another approach is to use neural architectures alongside self-supervised objectives which encourage better representation learning. In practice, there are few guarantees that these self-supervised objectives encode task-relevant information. We propose the Scene Graph Contrastive (SGC) loss, which uses scene graphs as general-purpose, training-only, supervisory signals. The SGC loss does away with explicit graph decoding and instead uses contrastive learning to align an agent's representation with a rich graphical encoding of its environment. The SGC loss is generally applicable, simple to implement, and encourages representations that encode objects' semantics, relationships, and history. Using the SGC loss, we attain significant gains on three embodied tasks: Object Navigation, Multi-Object Navigation, and Arm Point Navigation. Finally, we present studies and analyses which demonstrate the ability of our trained representation to encode semantic cues about the environment."}}
{"id": "7Md0780y5qR", "cdate": 1640995200000, "mdate": 1695391888549, "content": {"title": "Ask4Help: Learning to Leverage an Expert for Embodied Tasks", "abstract": "Embodied AI agents continue to become more capable every year with the advent of new models, environments, and benchmarks, but are still far away from being performant and reliable enough to be deployed in real, user-facing, applications. In this paper, we ask: can we bridge this gap by enabling agents to ask for assistance from an expert such as a human being? To this end, we propose the Ask4Help policy that augments agents with the ability to request, and then use expert assistance. Ask4Help policies can be efficiently trained without modifying the original agent's parameters and learn a desirable trade-off between task performance and the amount of requested help, thereby reducing the cost of querying the expert. We evaluate Ask4Help on two different tasks -- object goal navigation and room rearrangement and see substantial improvements in performance using minimal help. On object navigation, an agent that achieves a $52\\%$ success rate is raised to $86\\%$ with $13\\%$ help and for rearrangement, the state-of-the-art model with a $7\\%$ success rate is dramatically improved to $90.4\\%$ using $39\\%$ help. Human trials with Ask4Help demonstrate the efficacy of our approach in practical scenarios."}}
{"id": "U-9B7LgpCn", "cdate": 1609459200000, "mdate": 1667408440663, "content": {"title": "BNAS v2: Learning Architectures for Binary Networks with Empirical Improvements", "abstract": "Backbone architectures of most binary networks are well-known floating point (FP) architectures such as the ResNet family. Questioning that the architectures designed for FP networks might not be the best for binary networks, we propose to search architectures for binary networks (BNAS) by defining a new search space for binary architectures and a novel search objective. Specifically, based on the cell based search method, we define the new search space of binary layer types, design a new cell template, and rediscover the utility of and propose to use the Zeroise layer instead of using it as a placeholder. The novel search objective diversifies early search to learn better performing binary architectures. We show that our method searches architectures with stable training curves despite the quantization error inherent in binary networks. Quantitative analyses demonstrate that our searched architectures outperform the architectures used in state-of-the-art binary networks and outperform or perform on par with state-of-the-art binary networks that employ various techniques other than architectural changes. In addition, we further propose improvements to the training scheme of our searched architectures. With the new training scheme for our searched architectures, we achieve the state-of-the-art performance by binary networks by outperforming all previous methods by non-trivial margins."}}
{"id": "H-vyNotNZP", "cdate": 1609459200000, "mdate": 1667408440662, "content": {"title": "Factorizing Perception and Policy for Interactive Instruction Following", "abstract": "Performing simple household tasks based on language directives is very natural to humans, yet it remains an open challenge for AI agents. The \u2018interactive instruction following\u2019 task attempts to make progress towards building agents that jointly navigate, interact, and reason in the environment at every step. To address the multifaceted problem, we propose a model that factorizes the task into interactive perception and action policy streams with enhanced components and name it as MOCA, a Modular Object-Centric Approach. We empirically validate that MOCA outperforms prior arts by significant margins on the ALFRED benchmark with improved generalization."}}
{"id": "r40DfCeEex", "cdate": 1577836800000, "mdate": 1667408440662, "content": {"title": "Learning Architectures for Binary Networks", "abstract": "Backbone architectures of most binary networks are well-known floating point (FP) architectures such as the ResNet family. Questioning that the architectures designed for FP networks might not be the best for binary networks, we propose to search architectures for binary networks (BNAS) by defining a new search space for binary architectures and a novel search objective. Specifically, based on the cell based search method, we define the new search space of binary layer types, design a new cell template, and rediscover the utility of and propose to use the Zeroise layer instead of using it as a placeholder. The novel search objective diversifies early search to learn better performing binary architectures. We show that our method searches architectures with stable training curves despite the quantization error inherent in binary networks. Quantitative analyses demonstrate that our searched architectures outperform the architectures used in state-of-the-art binary networks and outperform or perform on par with state-of-the-art binary networks that employ various techniques other than architectural changes."}}
{"id": "0c_irBwcDLB", "cdate": 1546300800000, "mdate": 1667408440660, "content": {"title": "A Fast, Scalable, and Reliable Deghosting Method for Extreme Exposure Fusion", "abstract": "HDR fusion of extreme exposure images with complex camera and object motion is a challenging task. Existing patch-based optimization techniques generate noisy and/or blurry results with undesirable artifacts for difficult scenarios. Additionally, they are computationally intensive and have high execution times. Recently proposed CNN-based methods offer fast alternatives, but still fail to generate artifact-free results for extreme exposure images. Furthermore, they do not scale to an arbitrary number of input images. To address these issues, we propose a simple, yet effective CNN-based multi-exposure image fusion method that produces artifact-free HDR images. Our method is fast, and scales to an arbitrary number of input images. Additionally, we prepare a large dataset of 582 varying exposure images with corresponding deghosted HDR images to train our model. We test the efficacy of our algorithm on publicly available datasets, and achieve significant improvements over existing state-of-the-art methods. Through experimental results, we demonstrate that our method produces artifact-free results, and offers a speed-up of around 54\u00d7 over existing state-of-the-art HDR fusion methods."}}
