{"id": "9916eknWHOr", "cdate": 1663939405618, "mdate": null, "content": {"title": "Find Your Friends: Personalized Federated Learning with the Right Collaborators", "abstract": "In the traditional federated learning setting, a central server coordinates a network of clients to train one global model. However, the global model may serve many clients poorly due to data heterogeneity. Moreover, there may not exist a trusted central party that can coordinate the clients to ensure that each of them can benefit from others. To address these concerns, we present a novel decentralized framework, FedeRiCo, where each client can learn as much or as little from other clients as is optimal for its local data distribution. Based on expectation-maximization, FedeRiCo estimates the utilities of other participants\u2019 models on each client\u2019s data so that everyone can select the right collaborators for learning. As a result, our algorithm outperforms other federated, personalized, and/or decentralized approaches on several benchmark datasets, being the only approach that consistently performs better than training with local data only."}}
{"id": "5g4FC-SHkaV", "cdate": 1663850032054, "mdate": null, "content": {"title": "Find Your Friends: Personalized Federated Learning with the Right Collaborators", "abstract": "In the traditional federated learning setting, a central server coordinates a network of clients to train one global model. However, the global model may serve many clients poorly due to data heterogeneity. Moreover, there may not exist a trusted central party that can coordinate the clients to ensure that each of them can benefit from others. To address these concerns, we present a novel decentralized framework, FedeRiCo, where each client can learn as much or as little from other clients as is optimal for its local data distribution. Based on expectation-maximization, FedeRiCo estimates the utilities of other participants\u2019 models on each client\u2019s data so that everyone can select the right collaborators for learning. As a result, our algorithm outperforms other federated, personalized, and/or decentralized approaches on several benchmark datasets, being the only approach that consistently performs better than training with local data only."}}
{"id": "TQUiK5qImnl", "cdate": 1640995200000, "mdate": 1664933057165, "content": {"title": "A Parametric Class of Approximate Gradient Updates for Policy Optimization", "abstract": "Approaches to policy optimization have been motivated from diverse principles, based on how the parametric model is interpreted (e.g. value versus policy representation) or how the learning objecti..."}}
{"id": "mHM-vzH2Ozf", "cdate": 1609459200000, "mdate": 1631812198237, "content": {"title": "Characterizing the Gap Between Actor-Critic and Policy Gradient", "abstract": "Actor-critic (AC) methods are ubiquitous in reinforcement learning. Although it is understood that AC methods are closely related to policy gradient (PG), their precise connection has not been full..."}}
{"id": "ybBVZCw4bxt", "cdate": 1577836800000, "mdate": 1664933057110, "content": {"title": "Batch Stationary Distribution Estimation", "abstract": "We consider the problem of approximating the stationary distribution of an ergodic Markov chain given a set of sampled transitions. Classical simulation-based approaches assume access to the underl..."}}
{"id": "E3OLJo08zvk", "cdate": 1577836800000, "mdate": 1664933057094, "content": {"title": "Domain Aggregation Networks for Multi-Source Domain Adaptation", "abstract": "In many real-world applications, we want to exploit multiple source datasets to build a model for a different but related target dataset. Despite the recent empirical success, most existing researc..."}}
{"id": "ByljMaNKwB", "cdate": 1569438995159, "mdate": null, "content": {"title": "Domain Aggregation Networks for Multi-Source Domain Adaptation", "abstract": "In many real-world applications, we want to exploit multiple source datasets of similar tasks to learn a model for a different but related target dataset -- e.g.,  recognizing characters of a new font using a set of different fonts. While most recent research has considered ad-hoc combination rules to address this problem, we extend previous work on domain discrepancy minimization to develop a finite-sample generalization bound, and accordingly propose a theoretically justified optimization procedure. The algorithm we develop, Domain AggRegation Network (DARN), is able to effectively adjust the weight of each source domain during training to ensure relevant domains are given more importance for adaptation. We evaluate the proposed method on real-world sentiment analysis and digit recognition datasets and show that DARN can significantly outperform the state-of-the-art alternatives."}}
{"id": "ByxHb3R5tX", "cdate": 1538087933163, "mdate": null, "content": {"title": "Universal Successor Features for Transfer Reinforcement Learning", "abstract": "Transfer in Reinforcement Learning (RL) refers to the idea of applying knowledge gained from previous tasks to solving related tasks. Learning a universal value function (Schaul et al., 2015), which generalizes over goals and states, has previously been shown to be useful for transfer. However, successor features are believed to be more suitable than values for transfer (Dayan, 1993; Barreto et al.,2017), even though they cannot directly generalize to new goals. In this paper, we propose (1) Universal Successor Features (USFs) to capture the underlying dynamics of the environment while allowing generalization to unseen goals and (2) a flexible end-to-end model of USFs that can be trained by interacting with the environment. We show that learning USFs is compatible with any RL algorithm that learns state values using a temporal difference method. Our experiments in a simple gridworld and with two MuJoCo environments show that USFs can greatly accelerate training when learning multiple tasks and can effectively transfer knowledge to new tasks."}}
{"id": "HJ_CpYyDz", "cdate": 1518472656157, "mdate": null, "content": {"title": "Universal Successor Representations for Transfer Reinforcement Learning", "abstract": "The objective of transfer reinforcement learning is to generalize from a set of previous tasks to unseen new tasks. In this work, we focus on the transfer scenario where the dynamics among tasks are the same, but their goals differ. Although general value function (Sutton et al., 2011) has been shown to be useful for knowledge transfer, learning a universal value function can be challenging in practice. To attack this, we propose (1) to use universal successor representations (USR) to represent the transferable knowledge and (2) a USR approximator (USRA) that can be trained by interacting with the environment. Our experiments show that USR can be effectively applied to new tasks, and the agent initialized by the trained USRA can achieve the goal considerably faster than random initialization."}}
{"id": "EowXicToPV9", "cdate": 1514764800000, "mdate": 1664933057167, "content": {"title": "Universal Successor Representations for Transfer Reinforcement Learning", "abstract": "The objective of transfer reinforcement learning is to generalize from a set of previous tasks to unseen new tasks. In this work, we focus on the transfer scenario where the dynamics among tasks are the same, but their goals differ. Although general value function (Sutton et al., 2011) has been shown to be useful for knowledge transfer, learning a universal value function can be challenging in practice. To attack this, we propose (1) to use universal successor representations (USR) to represent the transferable knowledge and (2) a USR approximator (USRA) that can be trained by interacting with the environment. Our experiments show that USR can be effectively applied to new tasks, and the agent initialized by the trained USRA can achieve the goal considerably faster than random initialization."}}
