{"id": "s8rr9Q8U3s", "cdate": 1667375320364, "mdate": 1667375320364, "content": {"title": "GLASS: Global to Local Attention for Scene-Text Spotting", "abstract": "In recent years, the dominant paradigm for text spotting is\nto combine the tasks of text detection and recognition into a single endto-end framework. Under this paradigm, both tasks are accomplished\nby operating over a shared global feature map extracted from the input\nimage. Among the main challenges that end-to-end approaches face is\nthe performance degradation when recognizing text across scale variations (smaller or larger text), and arbitrary word rotation angles. In this\nwork, we address these challenges by proposing a novel global-to-local\nattention mechanism for text spotting, termed GLASS, that fuses together global and local features. The global features are extracted from\nthe shared backbone, preserving contextual information from the entire\nimage, while the local features are computed individually on resized, high\nresolution rotated word crops. The information extracted from the local\ncrops alleviates much of the inherent difficulties with scale and word\nrotation. We show a performance analysis across scales and angles, highlighting improvement over scale and angle extremities. In addition, we\nintroduce an orientation-aware loss term supervising the detection task,\nand show its contribution to both detection and recognition performance\nacross all angles. Finally, we show that GLASS is general by incorporating it into other leading text spotting architectures, improving their text\nspotting performance. Our method achieves state-of-the-art results on\nmultiple benchmarks, including the newly released TextOCR."}}
{"id": "njMn4vkNjN8", "cdate": 1609459200000, "mdate": 1628683548617, "content": {"title": "Learning Multimodal Affinities for Textual Editing in Images", "abstract": "Nowadays, as cameras are rapidly adopted in our daily routine, images of documents are becoming both abundant and prevalent. Unlike natural images that capture physical objects, document-images contain a significant amount of text with critical semantics and complicated layouts. In this work, we devise a generic unsupervised technique to learn multimodal affinities between textual entities in a document-image, considering their visual style, the content of their underlying text and their geometric context within the image. We then use these learned affinities to automatically cluster the textual entities in the image into different semantic groups. The core of our approach is a deep optimization scheme dedicated for an image provided by the user that detects and leverages reliable pairwise connections in the multimodal representation of the textual elements in order to properly learn the affinities. We show that our technique can operate on highly varying images spanning a wide range of documents and demonstrate its applicability for various editing operations manipulating the content, appearance and geometry of the image."}}
{"id": "kyY61XOZ6D", "cdate": 1577836800000, "mdate": 1628683548572, "content": {"title": "Sequence-to-Sequence Contrastive Learning for Text Recognition", "abstract": "We propose a framework for sequence-to-sequence contrastive learning (SeqCLR) of visual representations, which we apply to text recognition. To account for the sequence-to-sequence structure, each feature map is divided into different instances over which the contrastive loss is computed. This operation enables us to contrast in a sub-word level, where from each image we extract several positive pairs and multiple negative examples. To yield effective visual representations for text recognition, we further suggest novel augmentation heuristics, different encoder architectures and custom projection heads. Experiments on handwritten text and on scene text show that when a text decoder is trained on the learned representations, our method outperforms non-sequential contrastive methods. In addition, when the amount of supervision is reduced, SeqCLR significantly improves performance compared with supervised training, and when fine-tuned with 100% of the labels, our method achieves state-of-the-art results on standard handwritten text recognition benchmarks."}}
{"id": "jMo_aEYiefO", "cdate": 1577836800000, "mdate": null, "content": {"title": "SCATTER: Selective Context Attentional Scene Text Recognizer", "abstract": "Scene Text Recognition (STR), the task of recognizing text against complex image backgrounds, is an active area of research. Current state-of-the-art (SOTA) methods still struggle to recognize text written in arbitrary shapes. In this paper, we introduce a novel architecture for STR, named Selective Context ATtentional Text Recognizer (SCATTER). SCATTER utilizes a stacked block architecture with intermediate supervision during training, that paves the way to successfully train a deep BiLSTM encoder, thus improving the encoding of contextual dependencies. Decoding is done using a two-step 1D attention mechanism. The first attention step re-weights visual features from a CNN backbone together with contextual features computed by a BiLSTM layer. The second attention step, similar to previous papers, treats the features as a sequence and attends to the intra-sequence relationships. Experiments show that the proposed approach surpasses SOTA performance on irregular text recognition benchmarks by 3.7\\% on average."}}
{"id": "fE88u9TdH2-", "cdate": 1577836800000, "mdate": 1628683548619, "content": {"title": "On Calibration of Scene-Text Recognition Models", "abstract": "In this work, we study the problem of word-level confidence calibration for scene-text recognition (STR). Although the topic of confidence calibration has been an active research area for the last several decades, the case of structured and sequence prediction calibration has been scarcely explored. We analyze several recent STR methods and show that they are consistently overconfident. We then focus on the calibration of STR models on the word rather than the character level. In particular, we demonstrate that for attention based decoders, calibration of individual character predictions increases word-level calibration error compared to an uncalibrated model. In addition, we apply existing calibration methodologies as well as new sequence-based extensions to numerous STR models, demonstrating reduced calibration error by up to a factor of nearly 7. Finally, we show consistently improved accuracy results by applying our proposed sequence calibration method as a preprocessing step to beam-search."}}
{"id": "Syetja4KPH", "cdate": 1569439137112, "mdate": null, "content": {"title": "Deep Randomized Least Squares Value Iteration", "abstract": "Exploration while learning representations is one of the main challenges Deep\nReinforcement Learning (DRL) faces today. As the learned representation is dependant in the observed data, the exploration strategy has a crucial role. The popular DQN algorithm has improved significantly the capabilities of Reinforcement\nLearning (RL) algorithms to learn state representations from raw data, yet, it uses\na naive exploration strategy which is statistically inefficient. The Randomized\nLeast Squares Value Iteration (RLSVI) algorithm (Osband et al., 2016), on the\nother hand, explores and generalizes efficiently via linearly parameterized value\nfunctions. However, it is based on hand-designed state representation that requires\nprior engineering work for every environment. In this paper, we propose a Deep\nLearning adaptation for RLSVI. Rather than using hand-design state representation, we use a state representation that is being learned directly from the data by a\nDQN agent. As the representation is being optimized during the learning process,\na key component for the suggested method is a likelihood matching mechanism,\nwhich adapts to the changing representations. We demonstrate the importance of\nthe various properties of our algorithm on a toy problem and show that our method\noutperforms DQN in five Atari benchmarks, reaching competitive results with the\nRainbow algorithm."}}
{"id": "kka6W_o0B9Q", "cdate": 1483228800000, "mdate": null, "content": {"title": "End-to-End Differentiable Adversarial Imitation Learning", "abstract": "Generative Adversarial Networks (GANs) have been successfully applied to the problem of <em>policy imitation</em> in a model-free setup. However, the computation graph of GANs, that include a stoch..."}}
{"id": "VcESB_IFWGy", "cdate": 1483228800000, "mdate": null, "content": {"title": "Averaged-DQN: Variance Reduction and Stabilization for Deep Reinforcement Learning", "abstract": "Instability and variability of Deep Reinforcement Learning (DRL) algorithms tend to adversely affect their performance. Averaged-DQN is a simple extension to the DQN algorithm, based on averaging p..."}}
{"id": "aDGtVy2RH_A", "cdate": 1451606400000, "mdate": null, "content": {"title": "Model-based Adversarial Imitation Learning", "abstract": "Generative adversarial learning is a popular new approach to training generative models which has been proven successful for other related problems as well. The general idea is to maintain an oracle $D$ that discriminates between the expert's data distribution and that of the generative model $G$. The generative model is trained to capture the expert's distribution by maximizing the probability of $D$ misclassifying the data it generates. Overall, the system is \\emph{differentiable} end-to-end and is trained using basic backpropagation. This type of learning was successfully applied to the problem of policy imitation in a model-free setup. However, a model-free approach does not allow the system to be differentiable, which requires the use of high-variance gradient estimations. In this paper we introduce the Model based Adversarial Imitation Learning (MAIL) algorithm. A model-based approach for the problem of adversarial imitation learning. We show how to use a forward model to make the system fully differentiable, which enables us to train policies using the (stochastic) gradient of $D$. Moreover, our approach requires relatively few environment interactions, and fewer hyper-parameters to tune. We test our method on the MuJoCo physics simulator and report initial results that surpass the current state-of-the-art."}}
{"id": "3gZGGIaFdmN", "cdate": 1451606400000, "mdate": null, "content": {"title": "Deep Reinforcement Learning with Averaged Target DQN", "abstract": "Instability and variability of Deep Reinforcement Learning (DRL) algorithms tend to adversely affect their performance. Averaged-DQN is a simple extension to the DQN algorithm, based on averaging previously learned Q-values estimates, which leads to a more stable training procedure and improved performance by reducing approximation error variance in the target values. To understand the effect of the algorithm, we examine the source of value function estimation errors and provide an analytical comparison within a simplified model. We further present experiments on the Arcade Learning Environment benchmark that demonstrate significantly improved stability and performance due to the proposed extension."}}
