{"id": "rLj5jTcCUpp", "cdate": 1601308105182, "mdate": null, "content": {"title": "Distribution Embedding Network for Meta-Learning with Variable-Length Input", "abstract": "We propose Distribution Embedding Network (DEN) for meta-learning, which is designed for applications where both the distribution and the number of features could vary across tasks. DEN first transforms features using a learned piecewise linear function, then learns an embedding of the underlying data distribution after the transformation, and finally classifies examples based on the distribution embedding. We show that the parameters of the distribution embedding and the classification modules can be shared across tasks. We propose a novel methodology to mass-simulate binary classification training tasks, and demonstrate that DEN outperforms existing methods in a number of test tasks in numerical studies."}}
{"id": "Lzf1kFw4zye", "cdate": 1598050243597, "mdate": null, "content": {"title": "Multidimensional Shape Constraints", "abstract": "We propose new multi-input shape constraints across four intuitive categories: complements, diminishers, dominance, and unimodality constraints. We show these shape constraints can be checked and even enforced when training machine-learned models for linear models, generalized additive models, and the nonlinear function class of multi-layer lattice models. Real-world experiments illustrate how the different shape constraints can be used to increase explainability and improve regularization, especially for non-IID train-test distribution shift."}}
{"id": "S1-L0jW_-B", "cdate": 1546300800000, "mdate": null, "content": {"title": "Metric-Optimized Example Weights", "abstract": "Real-world machine learning applications often have complex test metrics, and may have training and test data that are not identically distributed. Motivated by known connections between complex te..."}}
{"id": "SklgHoRqt7", "cdate": 1538087735645, "mdate": null, "content": {"title": "Metric-Optimized Example Weights", "abstract": "Real-world machine learning applications often have complex test metrics, and may have training and test data that follow different distributions.  We propose addressing these issues by using a weighted loss function with a standard convex loss, but with weights on the training examples that are learned to optimize the test metric of interest on the validation set. These metric-optimized example weights can be learned for any test metric, including black box losses and customized metrics for specific applications.  We illustrate the performance of our proposal with public benchmark datasets and real-world applications with domain shift and custom loss functions that balance multiple objectives, impose fairness policies, and are non-convex and non-decomposable."}}
