{"id": "n8oWh81sdd", "cdate": 1683699523159, "mdate": 1683699523159, "content": {"title": "Towards Fair Representation Learning in Knowledge Graph with Stable Adversarial Debiasing", "abstract": "With graph-structured tremendous information, Knowledge Graphs (KG) aroused increasing interest in academic research and industrial applications. Recent studies have shown demographic bias, in terms of sensitive attributes (e.g., gender and race), exist in the learned representations of KG entities. Such bias negatively affects specific populations, especially minorities and underrepresented groups, and exacerbates machine learning-based human inequality. Adversarial learning is regarded as an effective way to alleviate bias in the representation learning model by simultaneously training a task-specific predictor and a sensitive attribute-specific discriminator. However, due to the unique challenge caused by topological structure and the comprehensive relationship between knowledge entities, adversarial learning-based debiasing is rarely studied in representation learning in knowledge graphs. In this paper, we propose a framework to learn unbiased representations for nodes and edges in knowledge graph mining. Specifically, we integrate a simple-but-effective normalization technique with Graph Neural Networks (GNNs) to constrain the weights updating process. Moreover, as a work-in-progress paper, we also find that the introduced weights normalization technique can mitigate the pitfalls of instability in adversarial debasing towards fair-and-stable machine learning. We evaluate the proposed framework on a benchmarking graph with multiple edge types and node types. The experimental results show that our model achieves comparable or better gender fairness over three competitive baselines on Equality of Odds. Importantly, our superiority in the fair model does not scarify the performance in the knowledge graph task (i.e., multi-class edge classification)."}}
{"id": "OJ4mMfGKLN", "cdate": 1652737839328, "mdate": null, "content": {"title": "Self-Supervised Contrastive Pre-Training For Time Series via Time-Frequency Consistency", "abstract": "Pre-training on time series poses a unique challenge due to the potential mismatch between pre-training and target domains, such as shifts in temporal dynamics, fast-evolving trends, and long-range and short-cyclic effects, which can lead to poor downstream performance. While domain adaptation methods can mitigate these shifts, most methods need examples directly from the target domain, making them suboptimal for pre-training. To address this challenge, methods need to accommodate target domains with different temporal dynamics and be capable of doing so without seeing any target examples during pre-training. Relative to other modalities, in time series, we expect that time-based and frequency-based representations of the same example are located close together in the time-frequency space. To this end, we posit that time-frequency consistency (TF-C) --- embedding a time-based neighborhood of an example close to its frequency-based neighborhood --- is desirable for pre-training. Motivated by TF-C, we define a decomposable pre-training model, where the self-supervised signal is provided by the distance between time and frequency components, each individually trained by contrastive estimation. We evaluate the new method on eight datasets, including electrodiagnostic testing, human activity recognition, mechanical fault detection, and physical status monitoring.  Experiments against eight state-of-the-art methods show that TF-C outperforms baselines by 15.4% (F1 score) on average in one-to-one settings (e.g., fine-tuning an EEG-pretrained model on EMG data) and by 8.4% (precision) in challenging one-to-many settings (e.g., fine-tuning an EEG-pretrained model for either hand-gesture recognition or mechanical fault prediction), reflecting the breadth of scenarios that arise in real-world applications. The source code and datasets are available at https://github.com/mims-harvard/TFC-pretraining."}}
{"id": "Kwm8I7dU-l5", "cdate": 1632875544741, "mdate": null, "content": {"title": "Graph-Guided Network for Irregularly Sampled Multivariate Time Series", "abstract": "In many domains, including healthcare, biology, and climate science, time series are irregularly sampled with varying time intervals between successive readouts and different subsets of variables (sensors) observed at different time points. Here, we introduce RAINDROP, a graph neural network that embeds irregularly sampled and multivariate time series while also learning the dynamics of sensors purely from observational data. RAINDROP represents every sample as a separate sensor graph and models time-varying dependencies between sensors with a novel message passing operator. It estimates the latent sensor graph structure and leverages the structure together with nearby observations to predict misaligned readouts. This model can be interpreted as a graph neural network that sends messages over graphs that are optimized for capturing time-varying dependencies among sensors. We use RAINDROP to classify time series and interpret temporal dynamics on three healthcare and human activity datasets. RAINDROP outperforms state-of-the-art methods by up to 11.4% (absolute F1-score points), including techniques that deal with irregular sampling using fixed discretization and set functions. RAINDROP shows superiority in diverse setups, including challenging leave-sensor-out settings. "}}
{"id": "zVoJ633tSQ", "cdate": 1577836800000, "mdate": null, "content": {"title": "Data-Efficient Deep Representation Learning for Brain-Computer Interface and Its Applications.", "abstract": "Author Summary Whole-cell models promise to enable rational bioengineering by predicting how cells behave. Even for simple bacteria, whole-cell models require thousands of parameters, many of which are poorly characterized or unknown. New approaches are needed to estimate these parameters. We organized the Dialogue for Reverse Engineering Assessments and Methods (DREAM) 8 Whole-Cell Parameter Estimation Challenge to develop new approaches for whole-cell model parameter identification. Here we describe the challenge, the best performing methods, new insights into the identifiability of whole-cell models, and several lessons we learned for improving future challenges. Going forward, we believe that collaborative efforts have the potential to produce powerful tools for identifying whole-cell models."}}
{"id": "zIo-HmVxRPT", "cdate": 1577836800000, "mdate": null, "content": {"title": "A multi-view CNN-based acoustic classification system for automatic animal species identification.", "abstract": "Automatic identification of animal species by their vocalization is an important and challenging task. Although many kinds of audio monitoring system have been proposed in the literature, they suffer from several disadvantages such as non-trivial feature selection, accuracy degradation because of environmental noise or intensive local computation. In this paper, we propose a deep learning based acoustic classification framework for Wireless Acoustic Sensor Network (WASN). The proposed framework is based on cloud architecture which relaxes the computational burden on the wireless sensor node. To improve the recognition accuracy, we design a multi-view Convolution Neural Network (CNN) to extract the short-, middle-, and long-term dependencies in parallel. The evaluation on two real datasets shows that the proposed architecture can achieve high accuracy and outperforms traditional classification systems significantly when the environmental noise dominate the audio signal (low SNR). Moreover, we implement and deploy the proposed system on a testbed and analyse the system performance in real-world environments. Both simulation and real-world evaluation demonstrate the accuracy and robustness of the proposed acoustic classification system in distinguishing species of animals. Previous article in issue Next article in issue"}}
{"id": "ZIBOPF_0Xeco", "cdate": 1577836800000, "mdate": null, "content": {"title": "A Multi-view CNN-based Acoustic Classification System for Automatic Animal Species Identification.", "abstract": "Automatic identification of animal species by their vocalization is an important and challenging task. Although many kinds of audio monitoring system have been proposed in the literature, they suffer from several disadvantages such as non-trivial feature selection, accuracy degradation because of environmental noise or intensive local computation. In this paper, we propose a deep learning based acoustic classification framework for Wireless Acoustic Sensor Network (WASN). The proposed framework is based on cloud architecture which relaxes the computational burden on the wireless sensor node. To improve the recognition accuracy, we design a multi-view Convolution Neural Network (CNN) to extract the short-, middle-, and long-term dependencies in parallel. The evaluation on two real datasets shows that the proposed architecture can achieve high accuracy and outperforms traditional classification systems significantly when the environmental noise dominate the audio signal (low SNR). Moreover, we implement and deploy the proposed system on a testbed and analyse the system performance in real-world environments. Both simulation and real-world evaluation demonstrate the accuracy and robustness of the proposed acoustic classification system in distinguishing species of animals."}}
{"id": "LYK3ZYZVUCL", "cdate": 1577836800000, "mdate": null, "content": {"title": "Unraveling Metric Vector Spaces With Factorization for Recommendation.", "abstract": "Unlike all prior work, in this article, we investigate the notion of \u201cunraveling metric vector spaces,\u201d i.e., deriving meaning and low-rank structure from distance or metric space. Our new model bridges two commonly adopted paradigms for recommendations-metric learning approaches and factorization-based models, distinguishing itself accordingly. More concretely, we show that factorizing a metric vector space can be surprisingly efficacious. All in all, our proposed method, factorized metric learning, is highly effective for two classic recommendation tasks, possessing the potential of displacing many popular choices as an extremely strong baseline. We have done experiments on a number of real-world datasets, which show that our model performs better than recent state of the art largely on the rating prediction and item ranking tasks."}}
{"id": "89MrJ_5q8_C", "cdate": 1577836800000, "mdate": null, "content": {"title": "Software expert discovery via knowledge domain embeddings in a collaborative network.", "abstract": "Highlights \u2022 We take advantage of recent distributed word representation technology to help summarize text chunks. \u2022 The word embeddings in this research are utilized both in semantically and numerically. \u2022 We explore the relationships between natural language phrases in semantic view to extract latent knowledge domains. \u2022 Users\u2019 expertise is determined on historical performance, and data sparseness is alleviated by matrix factorization. \u2022 Evaluation is conducted on large scale dataset by comprehensive experiments, where preferable output is generated. Abstract Community Question Answering (CQA) websites can be claimed as the most major venues for knowledge sharing, and the most effective way of exchanging knowledge at present. Considering that massive amount of users are participating online and generating huge amount data, management of knowledge here systematically can be challenging. Expert recommendation is one of the major challenges, as it highlights users in CQA with potential expertise, which may help match unresolved questions with existing high quality answers while at the same time may help external services like human resource systems as another reference to evaluate their candidates. In this paper, we in this work we propose to exploring experts in CQA websites. We take advantage of recent distributed word representation technology to help summarize text chunks, and in a semantic view exploiting the relationships between natural language phrases to extract latent knowledge domains. By domains, the users\u2019 expertise is determined on their historical performance, and a rank can be compute to given recommendation accordingly. In particular, Stack Overflow is chosen as our dataset to test and evaluate our work, where inclusive experiment shows our competence. Previous article in issue Next article in issue"}}
{"id": "nId9Iygyrt", "cdate": 1546300800000, "mdate": null, "content": {"title": "A Survey on Deep Learning based Brain Computer Interface: Recent Advances and New Frontiers.", "abstract": "Brain-Computer Interface (BCI) bridges the human's neural world and the outer physical world by decoding individuals' brain signals into commands recognizable by computer devices. Deep learning has lifted the performance of brain-computer interface systems significantly in recent years. In this article, we systematically investigate brain signal types for BCI and related deep learning concepts for brain signal analysis. We then present a comprehensive survey of deep learning techniques used for BCI, by summarizing over 230 contributions most published in the past five years. Finally, we discuss the applied areas, opening challenges, and future directions for deep learning-based BCI."}}
{"id": "jJm0_FSQ8zF", "cdate": 1546300800000, "mdate": null, "content": {"title": "Deep Neural Network Hyperparameter Optimization with Orthogonal Array Tuning.", "abstract": "Deep learning algorithms have achieved excellent performance lately in a wide range of fields (e.g., computer version). However, a severe challenge faced by deep learning is the high dependency on hyper-parameters. The algorithm results may fluctuate dramatically under the different configuration of hyper-parameters. Addressing the above issue, this paper presents an efficient Orthogonal Array Tuning Method (OATM) for deep learning hyper-parameter tuning. We describe the OATM approach in five detailed steps and elaborate on it using two widely used deep neural network structures (Recurrent Neural Networks and Convolutional Neural Networks). The proposed method is compared to the state-of-the-art hyper-parameter tuning methods including manually (e.g., grid search and random search) and automatically (e.g., Bayesian Optimization) ones. The experiment results state that OATM can significantly save the tuning time compared to the state-of-the-art methods while preserving the satisfying performance."}}
