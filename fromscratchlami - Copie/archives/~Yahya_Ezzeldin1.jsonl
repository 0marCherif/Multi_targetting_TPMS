{"id": "mmSBe9xTneS", "cdate": 1672531200000, "mdate": 1682683020291, "content": {"title": "How Much Privacy Does Federated Learning with Secure Aggregation Guarantee?", "abstract": ""}}
{"id": "lHLcfkpN_E", "cdate": 1672531200000, "mdate": 1682683020498, "content": {"title": "The Resource Problem of Using Linear Layer Leakage Attack in Federated Learning", "abstract": "Secure aggregation promises a heightened level of privacy in federated learning, maintaining that a server only has access to a decrypted aggregate update. Within this setting, linear layer leakage methods are the only data reconstruction attacks able to scale and achieve a high leakage rate regardless of the number of clients or batch size. This is done through increasing the size of an injected fully-connected (FC) layer. However, this results in a resource overhead which grows larger with an increasing number of clients. We show that this resource overhead is caused by an incorrect perspective in all prior work that treats an attack on an aggregate update in the same way as an individual update with a larger batch size. Instead, by attacking the update from the perspective that aggregation is combining multiple individual updates, this allows the application of sparsity to alleviate resource overhead. We show that the use of sparsity can decrease the model size overhead by over 327$\\times$ and the computation time by 3.34$\\times$ compared to SOTA while maintaining equivalent total leakage rate, 77% even with $1000$ clients in aggregation."}}
{"id": "DsnYttl9Kj", "cdate": 1672531200000, "mdate": 1682683020303, "content": {"title": "Federated Analytics: A survey", "abstract": "Federated analytics (FA) is a privacy-preserving framework for computing data analytics over multiple remote parties (e.g., mobile devices) or silo-ed institutional entities (e.g., hospitals, banks) without sharing the data among parties. Motivated by the practical use cases of federated analytics, we follow a systematic discussion on federated analytics in this article. In particular, we discuss the unique characteristics of federated analytics and how it differs from federated learning. We also explore a wide range of FA queries and discuss various existing solutions and potential use case applications for different FA queries."}}
{"id": "0Zq4sO5aFM1", "cdate": 1672531200000, "mdate": 1682683020527, "content": {"title": "Secure Aggregation in Federated Learning is not Private: Leaking User Data at Large Scale through Model Modification", "abstract": "Security and privacy are important concerns in machine learning. End user devices often contain a wealth of data and this information is sensitive and should not be shared with servers or enterprises. As a result, federated learning was introduced to enable machine learning over large decentralized datasets while promising privacy by eliminating the need for data sharing. However, prior work has shown that shared gradients often contain private information and attackers can gain knowledge either through malicious modification of the architecture and parameters or by using optimization to approximate user data from the shared gradients. Despite this, most attacks have so far been limited in scale of number of clients, especially failing when client gradients are aggregated together using secure model aggregation. The attacks that still function are strongly limited in the number of clients attacked, amount of training samples they leak, or number of iterations they take to be trained. In this work, we introduce MANDRAKE, an attack that overcomes previous limitations to directly leak large amounts of client data even under secure aggregation across large numbers of clients. Furthermore, we break the anonymity of aggregation as the leaked data is identifiable and directly tied back to the clients they come from. We show that by sending clients customized convolutional parameters, the weight gradients of data points between clients will remain separate through aggregation. With an aggregation across many clients, prior work could only leak less than 1% of images. With the same number of non-zero parameters, and using only a single training iteration, MANDRAKE leaks 70-80% of data samples."}}
{"id": "bPpPgrzqoyM", "cdate": 1640995200000, "mdate": 1682683020723, "content": {"title": "How Much Privacy Does Federated Learning with Secure Aggregation Guarantee?", "abstract": "Federated learning (FL) has attracted growing interest for enabling privacy-preserving machine learning on data stored at multiple users while avoiding moving the data off-device. However, while data never leaves users' devices, privacy still cannot be guaranteed since significant computations on users' training data are shared in the form of trained local models. These local models have recently been shown to pose a substantial privacy threat through different privacy attacks such as model inversion attacks. As a remedy, Secure Aggregation (SA) has been developed as a framework to preserve privacy in FL, by guaranteeing the server can only learn the global aggregated model update but not the individual model updates. While SA ensures no additional information is leaked about the individual model update beyond the aggregated model update, there are no formal guarantees on how much privacy FL with SA can actually offer; as information about the individual dataset can still potentially leak through the aggregated model computed at the server. In this work, we perform a first analysis of the formal privacy guarantees for FL with SA. Specifically, we use Mutual Information (MI) as a quantification metric and derive upper bounds on how much information about each user's dataset can leak through the aggregated model update. When using the FedSGD aggregation algorithm, our theoretical bounds show that the amount of privacy leakage reduces linearly with the number of users participating in FL with SA. To validate our theoretical bounds, we use an MI Neural Estimator to empirically evaluate the privacy leakage under different FL setups on both the MNIST and CIFAR10 datasets. Our experiments verify our theoretical bounds for FedSGD, which show a reduction in privacy leakage as the number of users and local batch size grow, and an increase in privacy leakage with the number of training rounds."}}
{"id": "KrDNEzupFH", "cdate": 1640995200000, "mdate": 1682683020290, "content": {"title": "Gomory-Hu Trees Over Wireless", "abstract": "The Gomory-Hu tree is a popular optimization algorithm that enables to efficiently find a min-cut (or equivalently, max-flow) for every pair of nodes in a graph. However, graphs cannot capture broadcasting and interference in wireless: over wireless networks we need to resort to the information-theoretical cut-set to bound the max-flow. Leveraging the submodularity of mutual information, we show that the Gomory-Hu algorithm can be used to efficiently find information-theoretic rate characterizations such as the capacity or an approximation to the capacity, over a number of network scenarios including wireless Gaussian networks and deterministic relay networks."}}
{"id": "5ZmVvpc6Iw", "cdate": 1640995200000, "mdate": 1682683020732, "content": {"title": "Federated K-Private Set Intersection", "abstract": "Private set intersection (PSI) is a popular protocol that allows multiple parties to evaluate the intersection of their sets without revealing them to each other. PSI has numerous practical applications, including privacy preserving data mining and location-based services. In this work, we develop a new approach for the PSI problem within the federated analytics framework. In particular, we consider a setting where a server wants to determine (query) which among its local set of data identifiers appears coupled with the same value in at least K of the N parties. Applications for this framework include but are not limited to: double-filing insurance verification, credit scoring and password checkup on an institutional level. To address the proposed setting, we propose a new protocol Fed-K-PSI that allows the server to answer this query while being oblivious to the data of identifiers that do not satisfy the distributed query at the parties. In addition, Fed-K-PSI also maintains the anonymity of the parties by hiding which K parties satisfied the query, or which value associated with the identifier which caused the query to be successful. Our proposed setting does not lend itself directly to state-of-the-art approaches in PSI based on Oblivious Transfer, since the server does not have a complete representation of a datapoint (only the identifier, but no value). Our proposed approach tackles this problem by constructing a distributed function at the parties, which encodes the datapoints and returns a deterministic known property if and only if the value for a given identifier is the same in at least K of the N parties. We show that Fed-K-PSI achieves a strong information-theoretic privacy guarantee and is resilient to collusion scenarios among honest-but-curious parties. We also evaluate Fed-K-PSI via extensive experiments to study the effect of the different system parameters."}}
{"id": "vwuePnwLJE", "cdate": 1609459200000, "mdate": 1682683020754, "content": {"title": "A Reinforcement Learning Approach for Scheduling in mmWave Networks", "abstract": "We consider a source that wishes to communicate with a destination at a desired rate, over a mmWave network where links are subject to blockage and nodes to failure (e.g., in a hostile military environment). To achieve resilience to link and node failures, we here explore a state-of-the-art Soft Actor-Critic (SAC) deep reinforcement learning algorithm, that adapts the information flow through the network, without using knowledge of the link capacities or network topology. Numerical evaluations show that our algorithm can achieve the desired rate even in dynamic environments and it is robust against blockage."}}
{"id": "v44DVutQAp", "cdate": 1609459200000, "mdate": 1682683020506, "content": {"title": "Efficient Beam Scheduling for Half-Duplex mmWave Relay Networks", "abstract": "Millimeter wave (mmWave) communication is expected to play a central role in next generation mobile systems (5G) and beyond, by providing multi-Gbps data rates. However, the severe pathloss and sensitivity to blockages at mmWave frequencies significantly challenge practical implementations. One effective way to mitigate these effects and to increase the communication range is beamforming in combination with relaying. In this paper, we study the beam scheduling problem for mmWave half-duplex (HD) relay networks, where the relay topology can be arbitrary. Based on theoretically optimal scheduling results, we first implement a network simplification procedure to reduce the network topology complexity, and then propose two practically relevant beam scheduling schemes: the deterministic edge coloring (EC) scheduler and the adaptive backpressure (BP) scheduler. The former consists of a very simple one-time computation of the sequence of scheduling states, which is then repeated periodically. The one-time computation depends on the underlying network topology, and therefore it must be repeated when such topology changes. As such, this approach is more suited to quasi-static scenarios. The latter is an \u201conline\u201d approach which updates scheduling weights and solves at each time slots a weighted sum rate maximization. Hence, it's computational complexity may be significantly higher than that of EC, but it is better suited to dynamic time-varying scenarios. With the aid of computer simulations, we show that both the proposed schedulers guarantee network stability within the network capacity. Particularly, in comparison with two baseline schemes, the proposed schedulers achieve much smaller queuing backlogs, much smaller backlog fluctuations, and much lower packet end-to-end delays."}}
{"id": "t1_YaZEUpf", "cdate": 1609459200000, "mdate": 1682683020530, "content": {"title": "A Reinforcement Learning Approach for Scheduling in mmWave Networks", "abstract": "We consider a source that wishes to communicate with a destination at a desired rate, over a mmWave network where links are subject to blockage and nodes to failure (e.g., in a hostile military environment). To achieve resilience to link and node failures, we here explore a state-of-the-art Soft Actor-Critic (SAC) deep reinforcement learning algorithm, that adapts the information flow through the network, without using knowledge of the link capacities or network topology. Numerical evaluations show that our algorithm can achieve the desired rate even in dynamic environments and it is robust against blockage."}}
