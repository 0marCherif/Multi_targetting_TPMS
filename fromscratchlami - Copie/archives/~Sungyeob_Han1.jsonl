{"id": "HaFRdl9A5Y", "cdate": 1676827099429, "mdate": null, "content": {"title": "On the Convergence of Continual Learning with Adaptive Methods", "abstract": "One of the objectives of continual learning is to prevent catastrophic forgetting in learning multiple tasks sequentially, and the existing solutions have been driven by the conceptualization of the plasticity-stability dilemma. However, the convergence of continual learning for each sequential task is less studied so far. In this paper, we provide a convergence analysis of memory-based continual learning with stochastic gradient descent and empirical evidence that training current tasks causes the cumulative degradation of previous tasks.\nWe propose an adaptive method for nonconvex continual learning (NCCL), which adjusts step sizes of both previous and current tasks with the gradients. The proposed method can achieve the same convergence rate as the SGD method when the catastrophic forgetting term which we define in the paper is suppressed at each iteration. Further, we demonstrate that the proposed algorithm improves the performance of continual learning over existing methods for several image classification tasks."}}
{"id": "O1GVJECGhN", "cdate": 1672531200000, "mdate": 1685092575438, "content": {"title": "Learning to Learn Unlearned Feature for Brain Tumor Segmentation", "abstract": "We propose a fine-tuning algorithm for brain tumor segmentation that needs only a few data samples and helps networks not to forget the original tasks. Our approach is based on active learning and meta-learning. One of the difficulties in medical image segmentation is the lack of datasets with proper annotations, because it requires doctors to tag reliable annotation and there are many variants of a disease, such as glioma and brain metastasis, which are the different types of brain tumor and have different structural features in MR images. Therefore, it is impossible to produce the large-scale medical image datasets for all types of diseases. In this paper, we show a transfer learning method from high grade glioma to brain metastasis, and demonstrate that the proposed algorithm achieves balanced parameters for both glioma and brain metastasis domains within a few steps."}}
{"id": "-WXCYvc5E-P", "cdate": 1665251222885, "mdate": null, "content": {"title": "Perturbed Quantile Regression for Distributional Reinforcement Learning", "abstract": "Distributional reinforcement learning aims to learn distribution of return under stochastic environments. Since the learned distribution of return contains rich information about the stochasticity of the environment, previous studies have relied on descriptive statistics, such as standard deviation, for optimism in the face of uncertainty. However, using the uncertainty from an empirical distribution can hinder convergence and performance when exploring with the certain criterion that has an one-sided tendency on risk in these methods. In this paper, we propose a novel distributional reinforcement learning that explores by randomizing risk criterion to reach a risk-neutral optimal policy. First, we provide a perturbed distributional Bellman optimality operator by distorting the risk measure in action selection. Second, we prove the convergence and optimality of the proposed method by using the weaker contraction property. Our theoretical results support that the proposed method does not fall into biased exploration and is guaranteed to converge to an optimal return distribution. Finally, we empirically show that our method outperforms other existing distribution-based algorithms in various environments including 55 Atari games."}}
{"id": "j9Na6QMTCE4", "cdate": 1664731443804, "mdate": null, "content": {"title": "Adaptive Methods for Nonconvex Continual Learning", "abstract": "One of the objectives of continual learning is to prevent catastrophic forgetting in learning multiple tasks sequentially,\nand the existing solutions have been driven by the conceptualization of the plasticity-stability dilemma.\nHowever, the convergence of continual learning for each sequential task is less studied so far.\nIn this paper, we provide a convergence analysis of memory-based continual learning with stochastic gradient descent\nand empirical evidence that training current tasks causes the cumulative degradation of previous tasks.\nWe propose an adaptive method for nonconvex continual learning (NCCL), which adjusts step sizes of both previous and current tasks with the gradients.\nThe proposed method can achieve the same convergence rate as the SGD method when the catastrophic forgetting term which we define in the paper is suppressed at each iteration.\nFurther, we demonstrate that the proposed algorithm improves the performance of continual learning over existing methods for several image classification tasks. "}}
{"id": "CTOJRqLMsl", "cdate": 1632875662509, "mdate": null, "content": {"title": "On the Convergence of Nonconvex Continual Learning with Adaptive Learning Rate", "abstract": "One of the objectives of continual learning is to prevent catastrophic forgetting in learning multiple tasks sequentially.\nThe memory based continual learning stores a small subset of the data for previous tasks and applies various methods such as quadratic programming and sample selection.\nSome memory-based approaches are formulated as a constrained optimization problem and rephrase constraints on the objective for memory as the inequalities on gradients.\nHowever, there have been little theoretical results on the convergence of continual learning.\nIn this paper, we propose a theoretical convergence analysis of memory-based continual learning with stochastic gradient descent.\nThe proposed method called nonconvex continual learning (NCCL) adapts the learning rates of both previous and current tasks with the gradients.\nThe proposed method can achieve the same convergence rate as the SGD method for a single task when the catastrophic forgetting term which we define in the paper is suppressed at each iteration.\nIt is also shown that memory-based approaches inherently overfit to memory, which degrades the performance on previously learned tasks. Experiments show that the proposed algorithm improves the performance of continual learning over existing methods for several image classification tasks. "}}
{"id": "gD0KBsQcGKg", "cdate": 1632875654569, "mdate": null, "content": {"title": "Distribution-Driven Disjoint Prediction Intervals for Deep Learning", "abstract": "This paper redefines prediction intervals (PIs) as the form of a union of disjoint intervals. PIs represent predictive uncertainty in the regression problem. Since previous PI methods assumed a single continuous PI (one lower and upper bound), it suffers from performance degradation in the uncertainty estimation when the conditional density function has multiple modes. This paper demonstrates that multimodality should be considered in regression uncertainty estimation. To address the issue, we propose a novel method that generates a union of disjoint PIs. Throughout UCI benchmark experiments, our method improves over current state-of-the-art uncertainty quantification methods, reducing an average PI width by over 27$\\%$. Through qualitative experiments, we visualized that the multi-mode often exists in real-world datasets and why our method produces high-quality PIs compared to the previous PI. "}}
{"id": "2cpsEstmH1", "cdate": 1632875653833, "mdate": null, "content": {"title": "Beyond Examples: Constructing Explanation Space for Explaining Prototypes", "abstract": "As deep learning has been successfully deployed in diverse applications, there is ever increasing need for explaining its decision. Most of the existing methods produced explanations with a second model that explains the first black-box model, but we propose an inherently interpretable model for more faithful explanations. Our method constructs an explanation space in which similarities in terms of human-interpretable features at images share similar latent representations by using a variational autoencoder. This explanation space provides additional explanations of the relationships, going beyond previous classification networks that provide explanations by distances and learned prototypes. In addition, our distance has more intrinsic meaning by VAE training techniques that regulate the latent space. With user study, we validate the quality of explanation space and additional explanations."}}
{"id": "rGg-Qcyplgq", "cdate": 1632875617605, "mdate": null, "content": {"title": "Distributional Perturbation for Efficient Exploration in Distributional Reinforcement Learning", "abstract": "Distributional reinforcement learning aims to learn distribution of return under stochastic environments. Since the learned distribution of return contains rich information about the stochasticity of the environment, previous studies have relied on descriptive statistics, such as standard deviation, for optimism in face of uncertainty. These prior works are divided into risk-seeking or averse methods, which can be considered as having a one-sided tendency on risk. Unexpectedly, such approaches hinder convergence. In this paper, we propose a novel distributional reinforcement learning that explores by randomizing the risk criterion to reach a risk-neutral optimal policy. First, we provide a perturbed distributional Bellman optimality operator by distorting the risk measure in action selection. Second, we prove the convergence and optimality of the proposed method by using weaker contraction property. Our theoretical results support that the proposed method does not fall into biased exploration and converges to an optimal return distribution. Finally, we empirically show that our method outperforms other existing distribution-based algorithms in various environments including Atari games."}}
{"id": "rUVFU1oyAoy", "cdate": 1601308292215, "mdate": null, "content": {"title": "Nonconvex Continual Learning with Episodic Memory", "abstract": "Continual learning aims to prevent catastrophic forgetting while learning a new task without accessing data of previously learned tasks. \nThe memory for such learning scenarios build a small subset of the data for previous tasks and is used in various ways such as quadratic programming and sample selection. \nCurrent memory-based continual learning algorithms are formulated as a constrained optimization problem and rephrase constraints as a gradient-based approach.\nHowever, previous works have not provided the theoretical proof on convergence to previously learned tasks.\nIn this paper, we propose a theoretical convergence analysis of continual learning based on stochastic gradient descent method.\nOur method, nonconvex continual learning (NCCL), can achieve the same convergence rate when the proposed catastrophic forgetting term is suppressed at each iteration.\nWe also show that memory-based approaches have an inherent problem of overfitting to memory, which degrades the performance on previously learned tasks, namely catastrophic forgetting.\nWe empirically demonstrate that NCCL successfully performs continual learning with episodic memory by scaling learning rates adaptive to mini-batches on several image classification tasks.  "}}
{"id": "S1xXiREKDB", "cdate": 1569439386992, "mdate": null, "content": {"title": "Adversarial training with perturbation generator networks", "abstract": "Despite the remarkable development of recent deep learning techniques, neural networks are still vulnerable to adversarial attacks, i.e., methods that fool the neural networks with perturbations that are too small for human eyes to perceive. Many adversarial training methods were introduced as to solve this problem, using adversarial examples as a training data. However, these adversarial attack methods used in these techniques are fixed, making the model stronger only to attacks used in training, which is widely known as an overfitting problem. In this paper, we suggest a novel adversarial training approach. In addition to the classifier, our method adds another neural network that generates the most effective adversarial perturbation by finding the weakness of the classifier. This perturbation generator network is trained to produce perturbations that maximize the loss function of the classifier, and these adversarial examples train the classifier with a true label. In short, the two networks compete with each other, performing a minimax game. In this scenario, attack patterns created by the generator network are adaptively altered to the classifier, mitigating the overfitting problem mentioned above. We theoretically proved that our minimax optimization problem is equivalent to minimizing the adversarial loss after all. Beyond this, we proposed an evaluation method that could accurately compare a wide-range of adversarial algorithms. Experiments with various datasets show that our method outperforms conventional adversarial algorithms. "}}
