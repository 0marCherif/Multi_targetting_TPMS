{"id": "1Xy14nkcZEd", "cdate": 1696525375658, "mdate": 1696525375658, "content": {"title": "Riding out DOMsday: Toward Detecting and Preventing DOM Cross-Site Scripting", "abstract": "Cross-site scripting (XSS) vulnerabilities are the most frequently reported web application vulnerability. As com- plex JavaScript applications become more widespread, DOM (Document Object Model) XSS vulnerabilities\u2014a type of XSS vulnerability where the vulnerability is located in client-side JavaScript, rather than server-side code\u2014are becoming more common. As the first contribution of this work, we empirically assess the impact of DOM XSS on the web using a browser with taint tracking embedded in the JavaScript engine. Building on the methodology used in a previous study that crawled popular websites, we collect a current dataset of potential DOM XSS vulnerabilities. We improve on the methodology for confirming XSS vulnerabilities, and using this improved methodology, we find 83% more vulnerabilities than previous methodology applied to the same dataset. As a second contribution, we identify the causes of and discuss how to prevent DOM XSS vulnerabilities. One example of our findings is that custom HTML templating designs\u2014a design pattern that could prevent DOM XSS vul- nerabilities analogous to parameterized SQL\u2014can be buggy in practice, allowing DOM XSS attacks. As our third contribution, we evaluate the error rates of three static-analysis tools to detect DOM XSS vulnerabilities found with dynamic analysis techniques using in-the-wild examples. We find static-analysis tools to miss 90% of bugs found by our dynamic analysis, though some tools can have very few false positives and at the same time find vulnerabilities not found using the dynamic analysis."}}
{"id": "UGpedYLeGwF", "cdate": 1696524634016, "mdate": 1696524634016, "content": {"title": "(Do Not) Track Me Sometimes: Users\u2019 Contextual Preferences for Web Tracking", "abstract": "Online trackers compile profiles on users for targeting ads, customizing websites, and selling users\u2019 information. In this paper, we report on the first de- tailed study of the perceived benefits and risks of tracking\u2014and the reasons behind them\u2014conducted in the context of users\u2019 own browsing histories. Prior work has studied this in the abstract; in contrast, we collected browsing histories from and interviewed 35 people about the perceived benefits and risks of online tracking in the context of their own browsing behavior. We find that many users want more control over tracking and think that controlled tracking has benefits, but are unwilling to put in the effort to control tracking or distrust current tools. We confirm previous findings that users\u2019 general attitudes about tracking are often at odds with their comfort in specific situations. We also identify specific situational factors that contribute to users\u2019 preferences about online tracking and explore how and why. Finally, we examine a sample of popular tools for controlling tracking and show that they only partially address the situational factors driving users\u2019 preferences. We suggest opportunities to improve such tools, and explore the use of a classifier to automatically determine whether a user would be comfortable with tracking on a particular page visit; our results suggest this is a promising direction for future work."}}
{"id": "6yaLHYv5L91", "cdate": 1663850407900, "mdate": null, "content": {"title": "The Ultimate Combo: Boosting Adversarial Example Transferability by Composing Data Augmentations", "abstract": "Transferring adversarial examples from surrogate (ML) models to evade target models is a common method for evaluating adversarial robustness in black-box settings. Researchers have invested substantial efforts to enhance transferability. Chiefly, attacks leveraging data augmentation have been found to help adversarial examples generalize better from surrogate to target models. Still, prior work has explored a limited set of augmentation techniques and their composition. To fill the gap, we conducted a systematic, comprehensive study of how data augmentation affects transferability. Particularly, we explored ten augmentation techniques of six categories originally proposed to help ML models generalize to unseen benign samples, and assessed how they influence transferability, both when applied individually and when composed. Our extensive experiments with the ImageNet dataset showed that simple color-space augmentations (e.g., color to greyscale) outperform the state of the art when combined with standard augmentations, such as translation and scaling. Additionally, except for two methods that may harm transferability, we found that composing augmentation methods impacts transferability monotonically (i.e., more methods composed $\\rightarrow$ $\\ge$transferability)---the best composition we found significantly outperformed the state of the art (e.g., 95.6% vs. 90.9% average transferability from normally trained surrogates to other normally trained models). We provide intuitive, empirically supported explanations for why certain augmentations fail to improve transferability."}}
