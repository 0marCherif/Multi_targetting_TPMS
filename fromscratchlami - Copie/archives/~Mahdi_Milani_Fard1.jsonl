{"id": "7nLRv4zSPSZ", "cdate": 1621838142515, "mdate": null, "content": {"title": "Optimizing Black-box Metrics with Adaptive Surrogates", "abstract": "We address the problem of training models with\nblack-box and hard-to-optimize metrics by expressing the metric as a monotonic function of a\nsmall number of easy-to-optimize surrogates. We\npose the training problem as an optimization over\na relaxed surrogate space, which we solve by estimating local gradients for the metric and performing inexact convex projections. We analyze gradient estimates based on finite differences and local\nlinear interpolations, and show convergence of\nour approach under smoothness assumptions with\nrespect to the surrogates. Experimental results\non classification and ranking problems verify the\nproposal performs on par with methods that know\nthe mathematical formulation, and adds notable\nvalue when the form of the metric is unknown."}}
{"id": "9OHI8a0yimN", "cdate": 1618413639357, "mdate": null, "content": {"title": "Optimizing Black-box Metrics with Iterative Example Weighting", "abstract": "We consider learning to optimize a classification metric defined by a black-box function of\nthe confusion matrix. Such black-box learning settings are ubiquitous, for example, when the\nlearner only has query access to the metric of interest, or in noisy-label and domain adaptation\napplications where the learner must evaluate the metric via performance evaluation using a\nsmall validation sample. Our approach is to adaptively learn example weights on the training\ndataset such that the resulting weighted objective best approximates the metric on the validation\nsample. We show how to model and estimate the example weights and use them to iteratively\npost-shift a pre-trained class probability estimator to construct a classifier. We also analyze the\nresulting procedure\u2019s statistical properties. Experiments on various label noise, domain shift, and\nfair classification setups confirm that our proposal is better than the individual state-of-the-art\nbaselines for each application."}}
{"id": "rLj5jTcCUpp", "cdate": 1601308105182, "mdate": null, "content": {"title": "Distribution Embedding Network for Meta-Learning with Variable-Length Input", "abstract": "We propose Distribution Embedding Network (DEN) for meta-learning, which is designed for applications where both the distribution and the number of features could vary across tasks. DEN first transforms features using a learned piecewise linear function, then learns an embedding of the underlying data distribution after the transformation, and finally classifies examples based on the distribution embedding. We show that the parameters of the distribution embedding and the classification modules can be shared across tasks. We propose a novel methodology to mass-simulate binary classification training tasks, and demonstrate that DEN outperforms existing methods in a number of test tasks in numerical studies."}}
{"id": "SklgHoRqt7", "cdate": 1538087735645, "mdate": null, "content": {"title": "Metric-Optimized Example Weights", "abstract": "Real-world machine learning applications often have complex test metrics, and may have training and test data that follow different distributions.  We propose addressing these issues by using a weighted loss function with a standard convex loss, but with weights on the training examples that are learned to optimize the test metric of interest on the validation set. These metric-optimized example weights can be learned for any test metric, including black box losses and customized metrics for specific applications.  We illustrate the performance of our proposal with public benchmark datasets and real-world applications with domain shift and custom loss functions that balance multiple objectives, impose fairness policies, and are non-convex and non-decomposable."}}
