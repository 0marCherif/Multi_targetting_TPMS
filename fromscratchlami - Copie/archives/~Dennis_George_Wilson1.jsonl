{"id": "2fFCR_jvjl", "cdate": 1680307200000, "mdate": 1682441047623, "content": {"title": "Satellite derived bathymetry using deep learning", "abstract": "Coastal development and urban planning are facing different issues including natural disasters and extreme storm events. The ability to track and forecast the evolution of the physical characteristics of coastal areas over time is an important factor in coastal development, risk mitigation and overall coastal zone management. Traditional bathymetry measurements are obtained using echo-sounding techniques which are considered expensive and not always possible due to various complexities. Remote sensing tools such as satellite imagery can be used to estimate bathymetry using incident wave signatures and inversion models such as physical models of waves. In this work, we present two novel approaches to bathymetry estimation using deep learning and we compare the two proposed methods in terms of accuracy, computational costs, and applicability to real data. We show that deep learning is capable of accurately estimating ocean depth in a variety of simulated cases which offers a new approach for bathymetry estimation and a novel application for deep learning."}}
{"id": "o8f8MBOf6w", "cdate": 1672531200000, "mdate": 1682441047738, "content": {"title": "Kartezio: Evolutionary Design of Explainable Pipelines for Biomedical Image Analysis", "abstract": "An unresolved issue in contemporary biomedicine is the overwhelming number and diversity of complex images that require annotation, analysis and interpretation. Recent advances in Deep Learning have revolutionized the field of computer vision, creating algorithms that compete with human experts in image segmentation tasks. Crucially however, these frameworks require large human-annotated datasets for training and the resulting models are difficult to interpret. In this study, we introduce Kartezio, a modular Cartesian Genetic Programming based computational strategy that generates transparent and easily interpretable image processing pipelines by iteratively assembling and parameterizing computer vision functions. The pipelines thus generated exhibit comparable precision to state-of-the-art Deep Learning approaches on instance segmentation tasks, while requiring drastically smaller training datasets, a feature which confers tremendous flexibility, speed, and functionality to this approach. We also deployed Kartezio to solve semantic and instance segmentation problems in four real-world Use Cases, and showcase its utility in imaging contexts ranging from high-resolution microscopy to clinical pathology. By successfully implementing Kartezio on a portfolio of images ranging from subcellular structures to tumoral tissue, we demonstrated the flexibility, robustness and practical utility of this fully explicable evolutionary designer for semantic and instance segmentation."}}
{"id": "KJFpArxWe-g", "cdate": 1664194167338, "mdate": null, "content": {"title": "Towards Architectural Optimization of Equivariant Neural Networks over Subgroups", "abstract": "Incorporating equivariance to symmetry groups in artificial neural networks (ANNs) can improve performance on tasks exhibiting those symmetries, but such symmetries are often only approximate and not explicitly known. This motivates algorithmically optimizing the architectural constraints imposed by equivariance. We propose the equivariance relaxation morphism, which preserves functionality while reparameterizing a group equivariant layer to operate with equivariance constraints on a subgroup, and the $[G]$-mixed equivariant layer, which mixes operations constrained to equivariance to different groups to enable within-layer equivariance optimization. These two architectural tools can be used within neural architecture search (NAS) algorithms for equivariance-aware architectural optimization."}}
{"id": "a6rCdfABJXg", "cdate": 1663850364078, "mdate": null, "content": {"title": "Equivariance-aware Architectural Optimization of Neural Networks", "abstract": "Incorporating equivariance to symmetry groups as a constraint during neural network training can improve performance and generalization for tasks exhibiting those symmetries, but such symmetries are often not perfectly nor explicitly present. This motivates algorithmically optimizing the architectural constraints imposed by equivariance. We propose the equivariance relaxation morphism, which preserves functionality while reparameterizing a group equivariant layer to operate with equivariance constraints on a subgroup, as well as the $[G]$-mixed equivariant layer, which mixes layers constrained to different groups to enable within-layer equivariance optimization. We further present evolutionary and differentiable neural architecture search (NAS) algorithms that utilize these mechanisms respectively for equivariance-aware architectural optimization. Experiments across a variety of datasets show the benefit of dynamically constrained equivariance to find effective architectures with approximate equivariance."}}
{"id": "lxpXEuDTdw", "cdate": 1660643204134, "mdate": 1660643204134, "content": {"title": "Structural Learning in Artificial Neural Networks: A Neural Operator Perspective", "abstract": "Over the history of Artificial Neural Networks (ANNs), only a minority of algorithms integrate structural changes of the network architecture into the learning process. Modern neuroscience has demonstrated that structural change is an important part of biological learning, with mechanisms such as synaptogenesis and neurogenesis present even in adult brains. Despite this history of artificial methods and biological inspiration, and furthermore the recent resurgence of neural methods in deep learning, relatively few current ANN methods include structural changes in learning compared to those that only adjust synaptic weights during the training process. We aim to draw connections between different approaches of structural learning that have similar abstractions in order to encourage collaboration and development. In this review, we provide a survey on structural learning methods in deep ANNs, including a new neural operator framework from a cellular neuroscience context and perspective, aimed at motivating research on this challenging topic. We then provide an overview of ANN methods which include structural changes within the neural operator framework in the learning process, characterizing each neural operator in detail and drawing connections to their biological counterparts. Finally, we present overarching trends in how these operators are implemented and discuss the open challenges in structural learning in ANNs."}}
{"id": "SWOg-arIg9", "cdate": 1645792504309, "mdate": null, "content": {"title": "When, where, and how to add new neurons to ANNs", "abstract": "Neurogenesis in ANNs is an understudied and difficult problem, even compared to other forms of structural learning like pruning. By decomposing it into triggers and initializations, we introduce a framework for studying the various facets of neurogenesis: when, where, and how to add neurons during the learning process. We present the Neural Orthogonality (NORTH*) suite of neurogenesis strategies, combining layer-wise triggers and initializations based on the orthogonality of activations or weights to dynamically grow performant networks that converge to an efficient size. We evaluate our contributions against other recent neurogenesis works across a variety of supervised learning tasks."}}
{"id": "yAZ-DfaeEB", "cdate": 1640995200000, "mdate": 1682441047820, "content": {"title": "Curiosity creates Diversity in Policy Search", "abstract": "When searching for policies, reward-sparse environments often lack sufficient information about which behaviors to improve upon or avoid. In such environments, the policy search process is bound to blindly search for reward-yielding transitions and no early reward can bias this search in one direction or another. A way to overcome this is to use intrinsic motivation in order to explore new transitions until a reward is found. In this work, we use a recently proposed definition of intrinsic motivation, Curiosity, in an evolutionary policy search method. We propose Curiosity-ES, an evolutionary strategy adapted to use Curiosity as a fitness metric. We compare Curiosity with Novelty, a commonly used diversity metric, and find that Curiosity can generate higher diversity over full episodes without the need for an explicit diversity criterion and lead to multiple policies which find reward."}}
{"id": "qtKSy6XpgtO", "cdate": 1640995200000, "mdate": 1682441047695, "content": {"title": "Coastal Bathymetry Estimation from Sentinel-2 Satellite Imagery: Comparing Deep Learning and Physics-Based Approaches", "abstract": "The ability to monitor the evolution of the coastal zone over time is an important factor in coastal knowledge, development, planning, risk mitigation, and overall coastal zone management. While traditional bathymetry surveys using echo-sounding techniques are expensive and time consuming, remote sensing tools have recently emerged as reliable and inexpensive data sources that can be used to estimate bathymetry using depth inversion models. Deep learning is a growing field of artificial intelligence that allows for the automatic construction of models from data and has been successfully used for various Earth observation and model inversion applications. In this work, we make use of publicly available Sentinel-2 satellite imagery and multiple bathymetry surveys to train a deep learning-based bathymetry estimation model. We explore for the first time two complementary approaches, based on color information but also wave kinematics, as inputs to the deep learning model. This offers the possibility to derive bathymetry not only in clear waters as previously done with deep learning models but also at common turbid coastal zones. We show competitive results with a state-of-the-art physical inversion method for satellite-derived bathymetry, Satellite to Shores (S2Shores), demonstrating a promising direction for worldwide applicability of deep learning models to inverse bathymetry from satellite imagery and a novel use of deep learning models in Earth observation."}}
{"id": "mvP19PLpX2", "cdate": 1640995200000, "mdate": 1682441047854, "content": {"title": "Coevolution of neural networks for agents and environments", "abstract": "Evolutionary strategies have recently shown great results in the field of policy search. Compared to some classical artificial neural networks used in reinforcement learning, evolutionary strategies generate populations of agents which are evaluated on a specific task. The algorithm detailed here demonstrates how artificial neural networks can be evolved in a process of neuroevolution and used as agents in the 2D-game Zelda, producing relevant behaviors. Moreover, to increase the diversity and quantity of available maps, this paper shows how it is possible to generate environments using evolutionary strategies and neuroevolution, as well as neural cellular automata. Finally, to evolve populations of environments and agents cohesively, a coevolution algorithm was developed. Results demonstrate the potential of coevolution in the field of videogames by creating a wide range of diverse environments, and by creating agent strategies to solve these levels. However, these results also highlight the complexity of continuously generating novelty as agents and maps tend to converge quickly on similar patterns."}}
{"id": "lS9VAdkG9lf", "cdate": 1640995200000, "mdate": 1682441047792, "content": {"title": "Architectural Optimization over Subgroups for Equivariant Neural Networks", "abstract": "Incorporating equivariance to symmetry groups as a constraint during neural network training can improve performance and generalization for tasks exhibiting those symmetries, but such symmetries are often not perfectly nor explicitly present. This motivates algorithmically optimizing the architectural constraints imposed by equivariance. We propose the equivariance relaxation morphism, which preserves functionality while reparameterizing a group equivariant layer to operate with equivariance constraints on a subgroup, as well as the [G]-mixed equivariant layer, which mixes layers constrained to different groups to enable within-layer equivariance optimization. We further present evolutionary and differentiable neural architecture search (NAS) algorithms that utilize these mechanisms respectively for equivariance-aware architectural optimization. Experiments across a variety of datasets show the benefit of dynamically constrained equivariance to find effective architectures with approximate equivariance."}}
