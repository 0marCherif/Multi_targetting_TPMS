{"id": "BJFuFTVYT2", "cdate": 1683879465707, "mdate": 1683879465707, "content": {"title": "Topology Preserving Maps as Aggregations for Graph Convolutional Neural Networks ", "abstract": "In Graph Convolutional Neural Networks, the capability of learning\nthe representation of graph nodes comes at hand when dealing\nwith one of the many graph analysis tasks, namely the prediction of\nnode properties. Furthermore, node-level representations can be aggregated\nto obtain a single graph-level representation and predictor.\nSuch aggregator functions are essential to retain the most information\nabout graph topology. This work explores an alternative\nroute for the definition of the aggregation function compared to\nexisting approaches. We propose a graph aggregator that exploits\nGenerative Topographic Mapping (GTM) to transform a set of nodelevel\nrepresentations into a single graph-level one. The integration\nof GTM in a GCNN pipeline allows to estimate node representation\nprobability densities and project them in a low-dimensional\nspace, while retaining the information about their mutual similarity.\nA novel dedicated training procedure is specifically designed to\nlearn from these reduced representations instead of the complete\ninitial data. Experimental results on several graph classification\nbenchmark datasets show that this approach achieves competitive\npredictive performances with respect to the commonly adopted\naggregation architectures present in the literature, while retaining\na well-grounded theoretical framework."}}
{"id": "bv6M2Ckoh5A", "cdate": 1656000772488, "mdate": null, "content": {"title": "Generative Topographic Mapping Based Aggregation Function for GCNN", "abstract": "In Graph Convolutional Neural Networks, the capability of learning the representation of graph nodes comes at hand when dealing with one of the many graph analysis tasks, namely the prediction of node properties. Furthermore, node-level representations can be aggregated to obtain a single graph-level representation and predictor. Such aggregator functions are essential to retaining the most information about graph topology. This work explores an alternative route for the definition of the aggregation function compared to existing approaches. We propose a graph aggregator that exploits Generative Topographic Mapping (GTM) to transform a set of node-level representations into a single graph-level one. The integration of GTM in a GCNN pipeline allows to estimate node representation probability densities and project them in a low-dimensional space, while retaining the information about their mutual similarity. A novel dedicated training procedure is specifically designed to learn from these reduced representations instead of the complete initial data. Experimental results on several graph classification benchmark datasets show that this approach achieves competitive predictive performances with respect to the commonly adopted aggregation architectures present in the literature while retaining a well-grounded theoretical framework."}}
{"id": "nEKJfPPlhnn", "cdate": 1655981254323, "mdate": null, "content": {"title": "On Backpropagation-Free Graph Convolutions", "abstract": "In this paper, we present neural models for graphs that do not rely on backpropagation for training. This makes learning more biologically plausible and amenable to parallel implementation in hardware.\nThe base component of our architecture is a generalization of Gated Linear Networks which allows the adoption of multiple graph convolutions. Every neuron is a \\emph{set} of graph convolution filters (weight vectors) and a gating mechanism that selects the weight vector to use for processing based on the node and its topological context.\nWe focus on a message-passing aggregation scheme where the gating mechanism is embedded directly into the graph convolution. We compare the effectiveness of different definitions of node contexts (depending on input or hidden features) and of gating functions (based on hyper-planes or on prototypes). \nWe evaluate the proposed convolutions on several node classification benchmark datasets.\nThe experimental results show that our backpropagation-free graph convolutions are competitive with backpropagation-based counterparts.  Moreover, we present a theoretical result on the expressiveness of the proposed models."}}
{"id": "mW4cWrAJGCL", "cdate": 1640995200000, "mdate": 1683880884503, "content": {"title": "Compact graph neural network models for node classification", "abstract": "Recent research on graph convolutional networks tend to increase the complexity and non-linearity of graph convolution operators. Many of these operators result in models exploiting a huge number of learnable parameters, that have to be tuned during the training phase. This aspect makes the application of these approaches on huge datasets challenging due to the considerable computational time required by the training phase. On the other hand, having a huge number of parameters limits the applicability of the models in many node classification problems, in particular in the semi-supervised setting where the number of samples for which the target is known is limited to a few dozen nodes. In this paper, we propose a simple and efficient operator dubbed Compact Multi-head Exponential Graph Convolution (CM-EGC). To limit the number of learnable parameters, the proposed model exploits a compact and structurally meaningful representation of the input node features resorting to truncated SVD matrix decomposition, while the expressiveness of the model is ensured by adopting a multi-head attention-based gating mechanism. We evaluated the CM-EGC on semi-supervised and fully-supervised node classification tasks considering 3 well-known benchmark datasets. The results show that even using an extremely compact model, the classification performance of the proposed approach is comparable and sometimes better than the state of the art."}}
{"id": "mHkwUZZH01C", "cdate": 1640995200000, "mdate": 1683880884404, "content": {"title": "Polynomial-based graph convolutional neural networks for graph classification", "abstract": "Graph convolutional neural networks exploit convolution operators, based on some neighborhood aggregating scheme, to compute representations of graphs. The most common convolution operators only exploit local topological information. To consider wider topological receptive fields, the mainstream approach is to non-linearly stack multiple graph convolutional (GC) layers. In this way, however, interactions among GC parameters at different levels pose a bias on the flow of topological information. In this paper, we propose a different strategy, considering a single graph convolution layer that independently exploits neighbouring nodes at different topological distances, generating decoupled representations for each of them. These representations are then processed by subsequent readout layers. We implement this strategy introducing the polynomial graph convolution (PGC) layer, that we prove being more expressive than the most common convolution operators and their linear stacking. Our contribution is not limited to the definition of a convolution operator with a larger receptive field, but we prove both theoretically and experimentally that the common way multiple non-linear graph convolutions are stacked limits the neural network expressiveness. Specifically, we show that a graph neural network architecture with a single PGC layer achieves state of the art performance on many commonly adopted graph classification benchmarks."}}
{"id": "FplXdKGrOK", "cdate": 1640995200000, "mdate": 1683880884411, "content": {"title": "SOM-based aggregation for graph convolutional neural networks", "abstract": "Graph property prediction is becoming more and more popular due to the increasing availability of scientific and social data naturally represented in a graph form. Because of that, many researchers are focusing on the development of improved graph neural network models. One of the main components of a graph neural network is the aggregation operator, needed to generate a graph-level representation from a set of node-level embeddings. The aggregation operator is critical since it should, in principle, provide a representation of the graph that is isomorphism invariant, i.e. the graph representation should be a function of graph nodes treated as a set. DeepSets (in: Advances in neural information processing systems, pp 3391\u20133401, 2017) provides a framework to construct a set-aggregation operator with universal approximation properties. In this paper, we propose a DeepSets aggregation operator, based on Self-Organizing Maps (SOM), to transform a set of node-level representations into a single graph-level one. The adoption of SOMs allows to compute node representations that embed the information about their mutual similarity. Experimental results on several real-world datasets show that our proposed approach achieves improved predictive performance compared to the commonly adopted sum aggregation and many state-of-the-art graph neural network architectures in the literature."}}
{"id": "BrV7SSrSO97", "cdate": 1640995200000, "mdate": 1683880884559, "content": {"title": "Multiresolution Reservoir Graph Neural Network", "abstract": "Graph neural networks are receiving increasing attention as state-of-the-art methods to process graph-structured data. However, similar to other neural networks, they tend to suffer from a high computational cost to perform training. Reservoir computing (RC) is an effective way to define neural networks that are very efficient to train, often obtaining comparable predictive performance with respect to the fully trained counterparts. Different proposals of reservoir graph neural networks have been proposed in the literature. However, their predictive performances are still slightly below the ones of fully trained graph neural networks on many benchmark datasets, arguably because of the oversmoothing problem that arises when iterating over the graph structure in the reservoir computation. In this work, we aim to reduce this gap defining a multiresolution reservoir graph neural network (MRGNN) inspired by graph spectral filtering. Instead of iterating on the nonlinearity in the reservoir and using a shallow readout function, we aim to generate an explicit <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"> <tex-math notation=\"LaTeX\">$k$ </tex-math></inline-formula> -hop unsupervised graph representation amenable for further, possibly nonlinear, processing. Experiments on several datasets from various application areas show that our approach is extremely fast and it achieves in most of the cases comparable or even higher results with respect to state-of-the-art approaches."}}
{"id": "B87soRRyTJ", "cdate": 1640995200000, "mdate": 1682154526647, "content": {"title": "Understanding Catastrophic Forgetting of Gated Linear Networks in Continual Learning", "abstract": "In this paper, we consider the recently proposed family of continual learning models, called Gated Linear Networks (GLNs), and study two crucial aspects impacting on the amount of catastrophic forgetting affecting gated linear networks, namely, data standardization and gating mechanism. Data standardization is particularly challenging in the online/continual learning setting because data from future tasks is not available beforehand. The results obtained using an online standardization method show a considerably higher amount of forgetting compared to an offline -static- standardization. Interestingly, with the latter standardization, we observe that GLNs show almost no forgetting on the considered benchmark datasets. Secondly, for an effective GLNs, it is essential to tailor the hyperparameters of the gating mechanism to the data distribution. In this paper, we propose a gating strategy based on a set of prototypes and the resulting Voronoi tessellation. The experimental assessment shows that the proposed approach is more robust to different data standardizations compared to the original one, based on a halfspace gating mechanism, and shows improved predictive performance."}}
{"id": "-whRs3JREr", "cdate": 1640995200000, "mdate": 1683880884388, "content": {"title": "Backpropagation-free Graph Neural Networks", "abstract": "We propose a class of neural models for graphs that do not rely on backpropagation for training, thus making learning more biologically plausible and amenable to parallel implementation in hardware. The base component of our architecture is a generalization of Gated Linear Networks which allows the adoption of multiple graph convolutions. Specifically, each neuron is defined as a set of graph convolution filters (weight vectors) and a gating mechanism that, given a node and its topological context, selects the weight vector to use for processing the node\u2019s attributes. Two different graph processing schemes are studied, i.e., a message-passing aggregation scheme where the gating mechanism is embedded directly into the graph convolution, and a multi-resolution one where neighbouring nodes at different topological distances are jointly processed by a single graph convolution layer. We also compare the effectiveness of different alternatives for defining the context function of a node, i.e., based on hyper-planes or on prototypes. A theoretical result on the expressiveness of the proposed models is also reported. We experimented our backpropagation-free graph convolutional neural architectures on commonly adopted node classification datasets, and show competitive performances compared to the backpropagation-based counterparts."}}
{"id": "gA1zA-b2sz", "cdate": 1609459200000, "mdate": 1684136509189, "content": {"title": "Audio-Visual Target Speaker Enhancement on Multi-Talker Environment Using Event-Driven Cameras", "abstract": "We propose a method to address audio-visual target speaker enhancement in multi-talker environments using eventdriven cameras. State of the art audio-visual speech separation methods shows that crucial information is the movement of the facial landmarks related to speech production. However, all approaches proposed so far work offline, using frame-based video input, making it difficult to process an audio-visual signal with low latency, for online applications. In order to overcome this limitation, we propose the use of event-driven cameras and exploit compression, high temporal resolution and low latency, for low cost and low latency motion feature extraction, going towards online embedded audio-visual speech processing. We use the event-driven optical flow estimation of the facial landmarks as input to a stacked Bidirectional LSTM trained to predict an Ideal Amplitude Mask that is then used to filter the noisy audio, to obtain the audio signal of the target speaker. The presented approach performs almost on pair with the frame- based approach, with very low latency and computational cost."}}
