{"id": "2EBn01PJh17", "cdate": 1652737394049, "mdate": null, "content": {"title": "Adaptive Cholesky Gaussian Processes", "abstract": "We present a method to fit exact Gaussian process models to large datasets by considering only a subset of the data. Our approach is novel in that the size of the subset is selected on the fly during exact inference with little computational overhead. From an empirical observation that the log-marginal likelihood often exhibits a linear trend once a sufficient subset of a dataset has been observed, we conclude that many large datasets contain redundant information that only slightly affects the posterior. Based on this, we provide probabilistic bounds on the full model evidence that can identify such subsets. Remarkably, these bounds are largely composed of terms that appear in intermediate steps of the standard Cholesky decomposition, allowing us to modify the algorithm to adaptively stop the decomposition once enough data have been observed. Empirically, we show that our method can be directly plugged into well-known inference schemes to fit exact Gaussian process models to large datasets. "}}
{"id": "fzMsayyn0NF", "cdate": 1640995200000, "mdate": 1681721108641, "content": {"title": "Adaptive Cholesky Gaussian Processes", "abstract": "We present a method to approximate Gaussian process regression models for large datasets by considering only a subset of the data. Our approach is novel in that the size of the subset is selected on the fly during exact inference with little computational overhead. From an empirical observation that the log-marginal likelihood often exhibits a linear trend once a sufficient subset of a dataset has been observed, we conclude that many large datasets contain redundant information that only slightly affects the posterior. Based on this, we provide probabilistic bounds on the full model evidence that can identify such subsets. Remarkably, these bounds are largely composed of terms that appear in intermediate steps of the standard Cholesky decomposition, allowing us to modify the algorithm to adaptively stop the decomposition once enough data have been observed."}}
{"id": "DhvauaRia4x", "cdate": 1483228800000, "mdate": null, "content": {"title": "Big Universe, Big Data: Machine Learning and Image Analysis for Astronomy", "abstract": "Astrophysics and cosmology are rich with data. The advent of wide-area digital cameras on large aperture telescopes has led to ever more ambitious surveys of the sky. Data volumes of entire surveys a decade ago can now be acquired in a single night and real-time analysis is often desired. Thus, modern astronomy requires big data know-how, in particular it demands highly efficient machine learning and image analysis algorithms. But scalability is not the only challenge: Astronomy applications touch several current machine learning research questions, such as learning from biased data and dealing with label and measurement noise. We argue that this makes astronomy a great domain for computer science research, as it pushes the boundaries of data analysis. In the following, we will present this exciting application area for data scientists. We will focus on exemplary results, discuss main challenges, and highlight some recent methodological advancements in machine learning and image analysis triggered by astronomical applications."}}
{"id": "kcBKl-dGEcr", "cdate": 1356998400000, "mdate": null, "content": {"title": "Nearest neighbour regression outperforms model-based prediction of specific star formation rate", "abstract": "Data in astronomy is rapidly growing with upcoming surveys producing 30 TB of images per night. Highly informative spectra are too expensive to measure for each detected object, hence ways of reliably estimating physical properties from images alone are paramount. The objective of this work is to test whether a \u201cbig data ready\u201d k-nearest neighbour regression can successfully estimate the specific star formation rate (sSFR) from colours of low-redshift galaxies. The nearest neighbour algorithm achieves a root mean square error (RMSE) of 0.30, outperforming the state-of-the-art astronomical model achieving a RMSE of 0.36."}}
{"id": "Sybdv-fu-H", "cdate": 1356998400000, "mdate": null, "content": {"title": "Shape Index Descriptors Applied to Texture-Based Galaxy Analysis", "abstract": "A texture descriptor based on the shape index and the accompanying curvedness measure is proposed, and it is evaluated for the automated analysis of astronomical image data. A representative sample of images of low-red shift galaxies from the Sloan Digital Sky Survey (SDSS) serves as a test bed. The goal of applying texture descriptors to these data is to extract novel information about galaxies, information which is often lost in more traditional analysis. In this study, we build a regression model for predicting a spectroscopic quantity, the specific star-formation rate (sSFR). As texture features we consider multi-scale gradient orientation histograms as well as multi-scale shape index histograms, which lead to a new descriptor. Our results show that we can successfully predict spectroscopic quantities from the texture in optical multi-band images. We successfully recover the observed bi-modal distribution of galaxies into quiescent and star-forming. The state-of-the-art for predicting the sSFR is a color-based physical model. We significantly improve its accuracy by augmenting the model with texture information. This study is the first step towards enabling the quantification of physical galaxy properties from imaging data alone."}}
