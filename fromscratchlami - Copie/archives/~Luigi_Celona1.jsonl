{"id": "QVDpZpiWq_d", "cdate": 1681549781599, "mdate": 1681549781599, "content": {"title": "An Efficient Method for No-Reference Video Quality Assessment", "abstract": "Methods for No-Reference Video Quality Assessment (NR-VQA) of consumer-produced video content are largely investigated due to the spread of databases containing videos affected by natural distortions. In this work, we design an effective and efficient method for NR-VQA. The proposed method exploits a novel sampling module capable of selecting a predetermined number of frames from the whole video sequence on which to base the quality assessment. It encodes both the quality attributes and semantic content of video frames using two lightweight Convolutional Neural Networks (CNNs). Then, it estimates the quality score of the entire video using a Support Vector Regressor (SVR). We compare the proposed method against several relevant state-of-the-art methods using four benchmark databases containing user generated videos (CVD2014, KoNViD-1k, LIVE-Qualcomm, and LIVE-VQC). The results show that the proposed method at a substantially lower computational cost predicts subjective video quality in line with the state of the art methods on individual databases and generalizes better than existing methods in cross-database setup."}}
{"id": "E40KioMinb", "cdate": 1681116451727, "mdate": 1681116451727, "content": {"title": "Blind quality assessment of authentically distorted images", "abstract": "Blind image quality assessment (BIQA) of authentically distorted images is a challenging problem due to the lack of a reference image and the coexistence of blends of distortions with unknown characteristics. In this article, we present a convolutional neural network based BIQA model. It encodes the input image into multi-level features to estimate the perceptual quality score. The proposed model is designed to predict the image quality score but is trained for jointly treating the image quality assessment as a classification, regression, and pairwise ranking problem. Experimental results on three different datasets of authentically distorted images show that the proposed method achieves comparable results with state-of-the-art methods in intra-dataset experiments and is more effective in cross-dataset experiments."}}
{"id": "-VyJim9UBxQ", "cdate": 1654536356226, "mdate": null, "content": {"title": "Understanding Aesthetics with Language: A Photo Critique Dataset for Aesthetic Assessment", "abstract": "Computational inference of aesthetics is an ill-defined task due to its subjective nature. Many datasets have been proposed to tackle the problem by providing pairs of images and aesthetic scores based on human ratings. However, humans are better at expressing their opinion, taste, and emotions by means of language rather than summarizing them in a single number. In fact, photo critiques provide much richer information as they reveal how and why users rate the aesthetics of visual stimuli. In this regard, we propose the Reddit Photo Critique Dataset (RPCD), which contains tuples of image and photo critiques. RPCD consists of 74K images and 220K comments and is collected from a Reddit community used by hobbyists and professional photographers to improve their photography skills by leveraging constructive community feedback. The proposed dataset differs from previous aesthetics datasets mainly in three aspects, namely (i) the large scale of the dataset and the extension of the comments criticizing different aspects of the image, (ii) it contains mostly UltraHD images, and (iii) it can easily be extended to new data as it is collected through an automatic pipeline. To the best of our knowledge, in this work, we propose the first attempt to estimate the aesthetic quality of visual stimuli from the critiques. To this end, we exploit the polarity of the sentiment of criticism as an indicator of aesthetic judgment. We demonstrate how sentiment polarity correlates positively with the aesthetic judgment available for two aesthetic assessment benchmarks. Finally, we experiment with several models by using the sentiment scores as a target for ranking images. Dataset and baselines are available https://github.com/mediatechnologycenter/aestheval."}}
{"id": "iNggjNpfk_x", "cdate": 1640995200000, "mdate": 1668204249129, "content": {"title": "Composition and Style Attributes Guided Image Aesthetic Assessment", "abstract": ""}}
{"id": "2l0lI_j1yI", "cdate": 1640995200000, "mdate": 1681550285209, "content": {"title": "Fast-n-Squeeze: towards real-time spectral reconstruction from RGB images", "abstract": ""}}
{"id": "vnvVh74Uwt7", "cdate": 1609459200000, "mdate": 1668204249195, "content": {"title": "A grid anchor based cropping approach exploiting image aesthetics, geometric composition, and semantics", "abstract": ""}}
{"id": "ZbjW8qe6Ktp", "cdate": 1609459200000, "mdate": 1668204249217, "content": {"title": "A Smart Mirror for Emotion Monitoring in Home Environments", "abstract": ""}}
{"id": "Mz5A5qFk1rB", "cdate": 1609459200000, "mdate": 1681550285209, "content": {"title": "A Genetic Algorithm to Combine Deep Features for the Aesthetic Assessment of Images Containing Faces", "abstract": ""}}
{"id": "GDvdKLVPBQ0", "cdate": 1609459200000, "mdate": 1681550285210, "content": {"title": "An Efficient Method for No-Reference Video Quality Assessment", "abstract": ""}}
{"id": "6fWazy_uEh", "cdate": 1609459200000, "mdate": 1668204249112, "content": {"title": "Disentangling Image distortions in deep feature space", "abstract": ""}}
