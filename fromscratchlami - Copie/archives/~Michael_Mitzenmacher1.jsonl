{"id": "04OL67rm6ok", "cdate": 1663850297127, "mdate": null, "content": {"title": "QUIC-FL: : Quick Unbiased Compression for Federated Learning", "abstract": "Distributed Mean Estimation (DME) is a fundamental building block in communication efficient federated learning. In DME, clients communicate their lossily compressed gradients to the parameter server, which estimates the average and updates the model. \nState of the art DME techniques apply either unbiased quantization methods, resulting in large estimation errors, or biased quantization methods, where unbiasing the result requires that the server decodes each gradient individually, which markedly slows the aggregation time.\nIn this paper, we propose QUIC-FL, a DME algorithm that achieves the best of all worlds. QUIC-FL is unbiased, offers fast aggregation time, and is competitive with the most accurate (slow aggregation) DME techniques. To achieve this, we formalize the problem in a novel way that allows us to use standard solvers to design near-optimal unbiased quantization schemes."}}
{"id": "l5HdwFu2Ttp", "cdate": 1632875436524, "mdate": null, "content": {"title": "Tabula: Efficiently Computing Nonlinear Activation Functions for Private Neural Network Inference", "abstract": "Multiparty computation approaches to private neural network inference require significant communication between server and client, incur tremendous runtime penalties, and cost massive storage overheads. The primary source of these expenses is garbled circuits operations for nonlinear activation functions (typically ReLU), which require on the order of kilobytes of data transfer for each individual operation and tens of kilobytes of preprocessing storage per operation per inference. We propose a replacement for garbled circuits: Tabula, an algorithm to securely and efficiently perform single operand nonlinear functions for private neural network inference. Tabula performs a one time client initialization procedure with the help of a trusted third party (or via using fully homomorphic encryption), operates over smaller finite fields whose elements are representable with less than 16 bits, and employs a lookup table which stores the encrypted results of nonlinear operations over secretly shared values. We show Tabula is secure under a semi-honest threat model, allowing it to be used as a replacement for garbled circuits operations. Our results show that for private neural network inference, Tabula eliminates communication  by a factor of more than $50 \\times$, enables speedups over $10 \\times$, and reduces storage costs from $O(n)$ to $O(1)$. "}}
{"id": "KXRTmcv3dQ8", "cdate": 1621629929205, "mdate": null, "content": {"title": "DRIVE: One-bit Distributed Mean Estimation", "abstract": "We consider the problem where $n$ clients transmit $d$-dimensional real-valued vectors using $d(1+o(1))$ bits each, in a manner that allows the receiver to approximately reconstruct their mean. Such compression problems naturally arise in distributed and federated learning. We provide novel mathematical results and derive computationally efficient algorithms that are more accurate than previous compression techniques.  We evaluate our methods on a collection of distributed and federated learning tasks, using a variety of datasets, and show a consistent improvement over the state of the art."}}
{"id": "pBPd1J2AcNI", "cdate": 1609459200000, "mdate": null, "content": {"title": "SALSA: Self-Adjusting Lean Streaming Analytics", "abstract": "Counters are the fundamental building block of many data sketching schemes, which hash items to a small number of counters and account for collisions to provide good approximations for frequencies and other measures. Most existing methods rely on fixed-size counters, which may be wasteful in terms of space, as counters must be large enough to eliminate any risk of overflow. Instead, some solutions use small, fixed-size counters that may overflow into secondary structures. This paper takes a different approach. We propose a simple and general method called SALSA for dynamic re-sizing of counters and show its effectiveness. SALSA starts with small counters, and overflowing counters simply merge with their neighbors. SALSA can thereby allow more counters for a given space, expanding them as necessary to represent large numbers. Our evaluation demonstrates that, at the cost of a small overhead for its merging logic, SALSA significantly improves the accuracy of popular schemes (such as Count-Min Sketch and Count Sketch) over a variety of tasks. Our code is released as open-source [1]."}}
{"id": "hfNu7ateOwK", "cdate": 1609459200000, "mdate": null, "content": {"title": "Dynamic Longest Increasing Subsequence and the Erd\u00f6s-Szekeres Partitioning Problem", "abstract": "In this paper, we provide new approximation algorithms for dynamic variations of the longest increasing subsequence (\\textsf{LIS}) problem, and the complementary distance to monotonicity (\\textsf{DTM}) problem. In this setting, operations of the following form arrive sequentially: (i) add an element, (ii) remove an element, or (iii) substitute an element for another. At every point in time, the algorithm has an approximation to the longest increasing subsequence (or distance to monotonicity). We present a $(1+\\epsilon)$-approximation algorithm for \\textsf{DTM} with polylogarithmic worst-case update time and a constant factor approximation algorithm for \\textsf{LIS} with worst-case update time $\\tilde O(n^\\epsilon)$ for any constant $\\epsilon > 0$.% $n$ in the runtime denotes the size of the array at the time the operation arrives. Our dynamic algorithm for \\textsf{LIS} leads to an almost optimal algorithm for the Erd\\\"{o}s-Szekeres partitioning problem. Erd\\\"{o}s-Szekeres partitioning problem was introduced by Erd\\\"{o}s and Szekeres in 1935 and was known to be solvable in time $O(n^{1.5}\\log n)$. Subsequent work improve the runtime to $O(n^{1.5})$ only in 1998. Our dynamic \\textsf{LIS} algorithm leads to a solution for Erd\\\"{o}s-Szekeres partitioning problem with runtime $\\tilde O_{\\epsilon}(n^{1+\\epsilon})$ for any constant $\\epsilon > 0$."}}
{"id": "F-TS6C59gIy", "cdate": 1609459200000, "mdate": null, "content": {"title": "Improved Sublinear Time Algorithm for Longest Increasing Subsequence", "abstract": "We present a novel sublinear time algorithm for approximating LIS. If we denote the ratio of the solution size over the input size by \u03bb, our approach yields an algorithm with an approximation factor of \u03a9(\u03bb\u220a) for any constant \u220a > 0, and a truly sublinear runtime. This improves over for example the recent work of Rubinstein et al. [RSSS19] that approximates LIS within a factor \u03a9(\u03bb3) in truly sublinear time. Our work makes use of a grid packing technique recently introduced by Mitzenmacher and Seddighin to approximate LIS in the dynamic setting [MS20], providing another application for this technique."}}
{"id": "6BRLOfrMhW", "cdate": 1601308082278, "mdate": null, "content": {"title": "Partitioned Learned Bloom Filters", "abstract": "Bloom filters are space-efficient probabilistic data structures that are used to test whether an element is a member of a set, and may return false positives.  Recently, variations referred to as learned Bloom filters were developed that can provide improved performance in terms of the rate of false positives, by using a learned model for the represented set.  However, previous methods for learned Bloom filters do not take full advantage of the learned model.  Here we show how to frame the problem of optimal model utilization as an optimization problem, and using our framework derive algorithms that can achieve near-optimal performance in many cases."}}
{"id": "xH8fJ4XuuU", "cdate": 1577836800000, "mdate": null, "content": {"title": "DISCOvering the heavy hitters with disaggregated sketches", "abstract": "We propose DISCO - a lightweight approach to flow monitoring in the data plane. The idea is to disaggregate the computation of a single (logically) centralized sketch into multiple small \"sketch fragments\" that are distributed across the flows' paths. This allows use less resources at switches without trading on telemetry capabilities."}}
{"id": "wlz5BxnG9d7", "cdate": 1577836800000, "mdate": null, "content": {"title": "Detecting routing loops in the data plane", "abstract": "Routing loops can harm network operation. Existing loop detection mechanisms, including mirroring packets, storing state on switches, or encoding the path onto packets, impose significant overheads on either the switches or the network.\n                                                    \n                                                    \n                                                        We present Unroller, a solution that enables real-time identification of routing loops in the data plane with minimal overheads. Our algorithms encode a varying fixed-size subset of the traversed path on each packet. That way, our overhead is independent of the path length, while we can detect the loop once the packet returns to some encoded switch. We implemented Unroller in P4 and compiled into three different FPGA targets. We then compared it against state-of-the-art solutions on real WAN and data center topologies and show that it requires from 6x to 100x fewer bits added to packets than existing methods."}}
{"id": "sMic_GC8WLW", "cdate": 1577836800000, "mdate": null, "content": {"title": "PINT: Probabilistic In-band Network Telemetry", "abstract": "Commodity network devices support adding in-band telemetry measurements into data packets, enabling a wide range of applications, including network troubleshooting, congestion control, and path tracing. However, including such information on packets adds significant overhead that impacts both flow completion times and application-level performance. We introduce PINT, an in-band network telemetry framework that bounds the amount of information added to each packet. PINT encodes the requested data on multiple packets, allowing per-packet overhead limits that can be as low as one bit. We analyze PINT and prove performance bounds, including cases when multiple queries are running simultaneously. PINT is implemented in P4 and can be deployed on network devices.Using real topologies and traffic characteristics, we show that PINT concurrently enables applications such as congestion control, path tracing, and computing tail latencies, using only sixteen bits per packet, with performance comparable to the state of the art."}}
