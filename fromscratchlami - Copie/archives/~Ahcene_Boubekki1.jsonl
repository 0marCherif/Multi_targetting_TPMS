{"id": "rm8DY1J8Wz", "cdate": 1685577600000, "mdate": 1683890934602, "content": {"title": "RELAX: Representation Learning Explainability", "abstract": "Despite the significant improvements that self-supervised representation learning has led to when learning from unlabeled data, no methods have been developed that explain what influences the learned representation. We address this need through our proposed approach, RELAX, which is the first approach for attribution-based explanations of representations. Our approach can also model the uncertainty in its explanations, which is essential to produce trustworthy explanations. RELAX explains representations by measuring similarities in the representation space between an input and masked out versions of itself, providing intuitive explanations that significantly outperform the gradient-based baselines. We provide theoretical interpretations of RELAX and conduct a novel analysis of feature extractors trained using supervised and unsupervised learning, providing insights into different learning strategies. Moreover, we conduct a user study to assess how well the proposed approach aligns with human intuition and show that the proposed method outperforms the baselines in both the quantitative and human evaluation studies. Finally, we illustrate the usability of RELAX in several use cases and highlight that incorporating uncertainty can be essential for providing faithful explanations, taking a crucial step towards explaining representations."}}
{"id": "QqhbWZNRu_", "cdate": 1672531200000, "mdate": 1702046348794, "content": {"title": "Supercm: Revisiting Clustering for Semi-Supervised Learning", "abstract": "The development of semi-supervised learning (SSL) has in recent years largely focused on the development of new consistency regularization or entropy minimization approaches, often resulting in models with complex training strategies to obtain the desired results. In this work, we instead propose a novel approach that explicitly incorporates the underlying clustering assumption in SSL through extending a recently proposed differentiable clustering module. Leveraging annotated data to guide the cluster centroids results in a simple end-to-end trainable deep SSL approach. We demonstrate that the proposed model improves the performance over the supervised-only baseline and show that our framework can be used in conjunction with other SSL methods to further boost their performance."}}
{"id": "L8pZq2eRWvX", "cdate": 1652737808489, "mdate": null, "content": {"title": "ProtoVAE: A Trustworthy Self-Explainable Prototypical Variational Model", "abstract": "The need for interpretable models has fostered the development of self-explainable classifiers. Prior approaches are either based on multi-stage optimization schemes, impacting the predictive performance of the model, or produce explanations that are not transparent, trustworthy or do not capture the diversity of the data. To address these shortcomings, we propose ProtoVAE, a variational autoencoder-based framework that learns class-specific prototypes in an end-to-end manner and enforces trustworthiness and diversity by regularizing the representation space and introducing an orthonormality constraint. Finally, the model is designed to be transparent by directly incorporating the prototypes into the decision process. Extensive comparisons with previous self-explainable approaches demonstrate the superiority of ProtoVAE, highlighting its ability to generate trustworthy and diverse explanations, while not degrading predictive performance."}}
{"id": "XieGPEaYT8", "cdate": 1640995200000, "mdate": 1682317830340, "content": {"title": "Clinically Relevant Features for Predicting the Severity of Surgical Site Infections", "abstract": "Surgical site infections are hospital-acquired infections resulting in severe risk for patients and significantly increased costs for healthcare providers. In this work, we show how to leverage irregularly sampled preoperative blood tests to predict, on the day of surgery, a future surgical site infection and its severity. Our dataset is extracted from the electronic health records of patients who underwent gastrointestinal surgery and developed either deep, shallow or no infection. We represent the patients using the concentrations of fourteen common blood components collected over the four weeks preceding the surgery partitioned into six time windows. A gradient boosting based classifier trained on our new set of features reports an AUROC of 0.991 for predicting a postoperative infection and and AUROC of 0.937 for classifying the severity of the infection. Further analyses support the clinical relevance of our approach as the most important features describe the nutritional status and the liver function over the two weeks prior to surgery."}}
{"id": "WLJewLm6Atv1", "cdate": 1640995200000, "mdate": 1682317829419, "content": {"title": "ProtoVAE: A Trustworthy Self-Explainable Prototypical Variational Model", "abstract": "The need for interpretable models has fostered the development of self-explainable classifiers. Prior approaches are either based on multi-stage optimization schemes, impacting the predictive performance of the model, or produce explanations that are not transparent, trustworthy or do not capture the diversity of the data. To address these shortcomings, we propose ProtoVAE, a variational autoencoder-based framework that learns class-specific prototypes in an end-to-end manner and enforces trustworthiness and diversity by regularizing the representation space and introducing an orthonormality constraint. Finally, the model is designed to be transparent by directly incorporating the prototypes into the decision process. Extensive comparisons with previous self-explainable approaches demonstrate the superiority of ProtoVAE, highlighting its ability to generate trustworthy and diverse explanations, while not degrading predictive performance."}}
{"id": "SXQ22gDm8iJ", "cdate": 1640995200000, "mdate": 1683890934594, "content": {"title": "ProtoVAE: A Trustworthy Self-Explainable Prototypical Variational Model", "abstract": "The need for interpretable models has fostered the development of self-explainable classifiers. Prior approaches are either based on multi-stage optimization schemes, impacting the predictive performance of the model, or produce explanations that are not transparent, trustworthy or do not capture the diversity of the data. To address these shortcomings, we propose ProtoVAE, a variational autoencoder-based framework that learns class-specific prototypes in an end-to-end manner and enforces trustworthiness and diversity by regularizing the representation space and introducing an orthonormality constraint. Finally, the model is designed to be transparent by directly incorporating the prototypes into the decision process. Extensive comparisons with previous self-explainable approaches demonstrate the superiority of ProtoVAE, highlighting its ability to generate trustworthy and diverse explanations, while not degrading predictive performance."}}
{"id": "l1YSMqSSCe9", "cdate": 1609459200000, "mdate": 1631190185749, "content": {"title": "Joint optimization of an autoencoder for clustering and embedding", "abstract": "Deep embedded clustering has become a dominating approach to unsupervised categorization of objects with deep neural networks. The optimization of the most popular methods alternates between the training of a deep autoencoder and a k-means clustering of the autoencoder\u2019s embedding. The diachronic setting, however, prevents the former to benefit from valuable information acquired by the latter. In this paper, we present an alternative where the autoencoder and the clustering are learned simultaneously. This is achieved by providing novel theoretical insight, where we show that the objective function of a certain class of Gaussian mixture models (GMM\u2019s) can naturally be rephrased as the loss function of a one-hidden layer autoencoder thus inheriting the built-in clustering capabilities of the GMM. That simple neural network, referred to as the clustering module, can be integrated into a deep autoencoder resulting in a deep clustering model able to jointly learn a clustering and an embedding. Experiments confirm the equivalence between the clustering module and Gaussian mixture models. Further evaluations affirm the empirical relevance of our deep architecture as it outperforms related baselines on several data sets."}}
{"id": "Og9uJvK7NDv", "cdate": 1598865189527, "mdate": null, "content": {"title": "Toward Data-Driven Analyses of Electronic Text Books", "abstract": "We present data-driven log file analyses of an electronic text\nbook for history, called the mBook, to support teachers in\npreparing lessons for their students. We represent user ses-\nsions as contextualised Markov processes of user sessions and\npropose a probabilistic clustering using expectation maximi-\nsation to detect groups of similar (i) sessions and (ii) users."}}
{"id": "_lxJN02SXKQ", "cdate": 1598865012775, "mdate": null, "content": {"title": "Infinite Mixtures of Markov Chains", "abstract": "Facilitating a satisfying user experience requires a detailed\nunderstanding of user behavior and intentions. The key is to leverage\nobservations of activities, usually the clicks performed on Web pages.\nA common approach is to transform user sessions into Markov chains\nand analyze them using mixture models. However, model selection and\ninterpretability of the results are often limiting factors. As a remedy, we\npresent a Bayesian nonparametric approach to group user sessions and\ndevise behavioral patterns. Empirical results on a social network and an\nelectronic text book show that our approach reliably identifies underlying\nbehavioral patterns and proves more robust than baseline competitors."}}
{"id": "Cma6MajuMos", "cdate": 1598864820680, "mdate": null, "content": {"title": "Frame-based Data Factorizations", "abstract": "Archetypal Analysis is the method of choice\nto compute interpretable matrix factorizations.\nEvery data point is represented as a convex\ncombination of factors, i.e., points on the\nboundary of the convex hull of the data. This\nrenders computation inefficient. In this paper, we\nshow that the set of vertices of a convex hull, the\nso-called frame, can be efficiently computed by\na quadratic program. We provide theoretical and\nempirical results for our proposed approach and\nmake use of the frame to accelerate Archetypal\nAnalysis. The novel method yields similar\nreconstruction errors as baseline competitors but\nis much faster to compute."}}
