{"id": "ZW-ZsleMIWk", "cdate": 1621629856346, "mdate": null, "content": {"title": "Fast Approximate Dynamic Programming for Infinite-Horizon Markov Decision Processes", "abstract": "In this study, we consider the infinite-horizon, discounted cost, optimal control of stochastic nonlinear systems with separable cost and constraints in the state and input variables. Using the linear-time Legendre transform, we propose a novel numerical scheme for implementation of the corresponding value iteration (VI) algorithm in the conjugate domain. Detailed analyses of the convergence, time complexity, and error of the proposed algorithm are provided. In particular, with a discretization of size $X$ and $U$ for the state and input spaces, respectively, the proposed approach reduces the time complexity of each iteration in the VI algorithm from $O(XU)$ to $O(X+U)$, by replacing the minimization operation in the primal domain with a simple addition in the conjugate domain."}}
{"id": "niMlACxOOk", "cdate": 1577836800000, "mdate": null, "content": {"title": "Data-Assisted Model-Based Anomaly Detection for High-Fidelity Simulators of Power Systems", "abstract": "The main objective of this article is to develop scalable dynamic anomaly detectors when high-fidelity simulators of power systems are at our disposal. On the one hand, mathematical models of these high-fidelity simulators are typically \"intractable\" to apply existing model-based approaches. On the other hand, pure data-driven methods developed primarily in the machine learning literature neglect our knowledge about the underlying dynamics of the systems. In this study, we combine tools from these two mainstream approaches to develop a diagnosis filter that utilizes the knowledge of both the dynamical system as well as the simulation data of the high-fidelity simulators. The proposed diagnosis filter aims to achieve two desired features: (i) performance robustness with respect to model mismatch; (ii) high scalability. To this end, we propose a tractable (convex) optimization-based reformulation in which decisions are the filter parameters, the model-based information introduces feasible sets, and the data from the simulator forms the objective function to-be-minimized regarding the effect of model mismatch on the filter performance. To validate the theoretical results, we implement the developed diagnosis filter in DIgSILENT PowerFactory to detect false data injection attacks on the Automatic Generation Control measurements in the three-area IEEE 39-bus system."}}
{"id": "F4m3-GmAvp7", "cdate": 1577836800000, "mdate": null, "content": {"title": "Robust Dynamic Controllers for Output Regulation: Optimization-Based Synthesis and Event-Triggered Implementation", "abstract": "We investigate the problem of practical output regulation, i.e., to design a controller that brings the system output in the vicinity of a desired target value while keeping the other variables bounded. We consider uncertain systems that are possibly nonlinear and the uncertainty of their linear parts is modeled element-wise through a parametric family of matrix boxes. An optimization-based design procedure is proposed that delivers a continuous-time control and estimates the maximal regulation error. We also analyze an event-triggered emulation of this controller, which can be implemented on a digital platform, along with an explicit estimates of the regulation error."}}
{"id": "n3owJ4-Eey9", "cdate": 1546300800000, "mdate": null, "content": {"title": "Learning robust control for LQR systems with multiplicative noise via policy gradient", "abstract": "The linear quadratic regulator (LQR) problem has reemerged as an important theoretical benchmark for reinforcement learning-based control of complex dynamical systems with continuous state and action spaces. In contrast with nearly all recent work in this area, we consider multiplicative noise models, which are increasingly relevant because they explicitly incorporate inherent uncertainty and variation in the system dynamics and thereby improve robustness properties of the controller. Robustness is a critical and poorly understood issue in reinforcement learning; existing methods which do not account for uncertainty can converge to fragile policies or fail to converge at all. Additionally, intentional injection of multiplicative noise into learning algorithms can enhance robustness of policies, as observed in ad hoc work on domain randomization. Although policy gradient algorithms require optimization of a non-convex cost function, we show that the multiplicative noise LQR cost has a special property called gradient domination, which is exploited to prove global convergence of policy gradient algorithms to the globally optimum control policy with polynomial dependence on problem parameters. Results are provided both in the model-known and model-unknown settings where samples of system trajectories are used to estimate policy gradients."}}
{"id": "W8GFCke5oEZG", "cdate": 1546300800000, "mdate": null, "content": {"title": "Wasserstein Distributionally Robust Optimization: Theory and Applications in Machine Learning", "abstract": "Many decision problems in science, engineering and economics are affected by uncertain parameters whose distribution is only indirectly observable through samples. The goal of data-driven decision-making is to learn a decision from finitely many training samples that will perform well on unseen test samples. This learning task is difficult even if all training and test samples are drawn from the same distribution---especially if the dimension of the uncertainty is large relative to the training sample size. Wasserstein distributionally robust optimization seeks data-driven decisions that perform well under the most adverse distribution within a certain Wasserstein distance from a nominal distribution constructed from the training samples. In this tutorial we will argue that this approach has many conceptual and computational benefits. Most prominently, the optimal decisions can often be computed by solving tractable convex optimization problems, and they enjoy rigorous out-of-sample and asymptotic consistency guarantees. We will also show that Wasserstein distributionally robust optimization has interesting ramifications for statistical learning and motivates new approaches for fundamental learning tasks such as classification, regression, maximum likelihood estimation or minimum mean square error estimation, among others."}}
{"id": "SRzFY5mPvGr", "cdate": 1546300800000, "mdate": null, "content": {"title": "UWB orthogonal pulse design using Sturm-Liouville boundary value problem", "abstract": "Highlights \u2022 New orthogonal UWB pulses. \u2022 Sturm\u2013Liouville theory. \u2022 High utilization efficiency. Abstract The problem of designing UWB pulses which meet specific spectrum requirements is usually treated by filtering common pulses such as Gaussian doublets, modified Hermite polynomials and wavelets. When there is the need to have a number of orthogonal pulses ( e.g. , in a multiuser scenario), a naive approach is to filter all the members of an orthogonal set, which is likely to destroy their orthogonality property. In this paper, we study the design of a set of pulses that simultaneously satisfy the orthogonality property and spectrum requirements. Our design is based on the eigenfunctions of Sturm\u2013Liouville boundary value problems. Indeed, we introduce Sturm\u2013Liouville differential equations for which the eigenfunctions meet the FCC mask constraints. Computer simulation results show that all such waveforms occupy almost 55% of the allowed spectrum (utilization efficiency). A comparison of the proposed method with some conventional techniques of orthogonal UWB pulse generation will demonstrate the advantages of the new proposal. Previous article in issue Next article in issue"}}
{"id": "D9_PKXerWXZQ", "cdate": 1546300800000, "mdate": null, "content": {"title": "Bridging Bayesian and Minimax Mean Square Error Estimation via Wasserstein Distributionally Robust Optimization", "abstract": "We introduce a distributionally robust minimium mean square error estimation model with a Wasserstein ambiguity set to recover an unknown signal from a noisy observation. The proposed model can be viewed as a zero-sum game between a statistician choosing an estimator -- that is, a measurable function of the observation -- and a fictitious adversary choosing a prior -- that is, a pair of signal and noise distributions ranging over independent Wasserstein balls -- with the goal to minimize and maximize the expected squared estimation error, respectively. We show that if the Wasserstein balls are centered at normal distributions, then the zero-sum game admits a Nash equilibrium, where the players' optimal strategies are given by an {\\em affine} estimator and a {\\em normal} prior, respectively. We further prove that this Nash equilibrium can be computed by solving a tractable convex program. Finally, we develop a Frank-Wolfe algorithm that can solve this convex program orders of magnitude faster than state-of-the-art general purpose solvers. We show that this algorithm enjoys a linear convergence rate and that its direction-finding subproblems can be solved in quasi-closed form."}}
{"id": "40I2nuly7F8", "cdate": 1546300800000, "mdate": null, "content": {"title": "Robust Linear Quadratic Regulator: Exact Tractable Reformulation", "abstract": "We consider the problem of controlling an unknown stochastic linear dynamical system subject to an infinitehorizon discounted quadratic cost. Existing approaches for handling the corresponding robust optimal control problem resort to either conservative uncertainty sets or various approximations schemes, and to our best knowledge, the current literature lacks an exact, yet tractable, solution. We propose a class of novel uncertainty sets for the system matrices of the linear system. We show that the resulting robust linear quadratic regulator problem enjoys a closed-form solution described through a generalized algebraic Riccati equation arising from dynamic game theory."}}
{"id": "xiGN52GclKF", "cdate": 1514764800000, "mdate": null, "content": {"title": "A Hybrid Control Framework for Fast Methods Under Invexity: Non-Zeno Trajectories with Exponential Rate", "abstract": "In this paper, we propose a framework to design a class of fast gradient-based methods in continuous-time that, in comparison with the existing literature including Nesterov's fast-gradient method, features a state-dependent, time-invariant damping term that acts as a feedback control input. The proposed design scheme allows for a user-defined, exponential rate of convergence for a class of nonconvex, unconstrained optimization problems in which the objective function satisfies the so-called Polyak-\u0141ojasiewicz inequality. Formulating the optimization algorithm as a hybrid control system, a state-feedback input is synthesized such that a desired rate of convergence is guaranteed. Furthermore, we establish that the solution trajectories of the hybrid control system are Zeno-free."}}
{"id": "o65Yt1ygThR", "cdate": 1514764800000, "mdate": null, "content": {"title": "Data-driven inverse optimization with imperfect information", "abstract": "In data-driven inverse optimization an observer aims to learn the preferences of an agent who solves a parametric optimization problem depending on an exogenous signal. Thus, the observer seeks the agent\u2019s objective function that best explains a historical sequence of signals and corresponding optimal actions. We focus here on situations where the observer has imperfect information, that is, where the agent\u2019s true objective function is not contained in the search space of candidate objectives, where the agent suffers from bounded rationality or implementation errors, or where the observed signal-response pairs are corrupted by measurement noise. We formalize this inverse optimization problem as a distributionally robust program minimizing the worst-case risk that the predicted decision (i.e., the decision implied by a particular candidate objective) differs from the agent\u2019s actual response to a random signal. We show that our framework offers rigorous out-of-sample guarantees for different loss functions used to measure prediction errors and that the emerging inverse optimization problems can be exactly reformulated as (or safely approximated by) tractable convex programs when a new suboptimality loss function is used. We show through extensive numerical tests that the proposed distributionally robust approach to inverse optimization attains often better out-of-sample performance than the state-of-the-art approaches."}}
