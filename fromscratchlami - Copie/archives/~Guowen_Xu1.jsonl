{"id": "NxKHi7ymG27", "cdate": 1696118400000, "mdate": 1699609434546, "content": {"title": "Hercules: Boosting the Performance of Privacy-Preserving Federated Learning", "abstract": "In this paper, we address the problem of privacy-preserving federated neural network training with <inline-formula><tex-math notation=\"LaTeX\">$N$</tex-math></inline-formula> users. We present <b>Hercules</b> , an efficient and high-precision training framework that can tolerate collusion of up to <inline-formula><tex-math notation=\"LaTeX\">$N-1$</tex-math></inline-formula> users. <b>Hercules</b> follows the POSEIDON framework proposed by Sav et al. (NDSS\u201921), but makes a qualitative leap in performance with the following contributions: (i) we design a novel parallel homomorphic computation method for matrix operations, which enables fast Single Instruction and Multiple Data (SIMD) operations over ciphertexts. For the multiplication of two <inline-formula><tex-math notation=\"LaTeX\">$h\\times h$</tex-math></inline-formula> dimensional matrices, our method reduces the computation complexity from <inline-formula><tex-math notation=\"LaTeX\">$O(h^{3})$</tex-math></inline-formula> to <inline-formula><tex-math notation=\"LaTeX\">$O(h)$</tex-math></inline-formula> . This greatly improves the training efficiency of the neural network since the ciphertext computation is dominated by the convolution operations; (ii) we present an efficient approximation on the sign function based on the composite polynomial approximation. It is used to approximate non-polynomial functions (i.e., <monospace>ReLU</monospace> and <monospace>max</monospace> ), with the optimal asymptotic complexity. Extensive experiments on various benchmark datasets (BCW, ESR, CREDIT, MNIST, SVHN, CIFAR-10 and CIFAR-100) show that compared with POSEIDON, <b>Hercules</b> obtains up to 4% increase in model accuracy, and up to <inline-formula><tex-math notation=\"LaTeX\">$60\\times$</tex-math></inline-formula> reduction in the computation and communication cost."}}
{"id": "FgBGLKVB2fZ", "cdate": 1690848000000, "mdate": 1699609434596, "content": {"title": "Secure Updatable Storage Access Control System for EHRs in the Cloud", "abstract": "With an increasing number of IoT devices being deployed in healthcare, massive amounts of electronic health records (EHRs) are generated and shared in the cloud. To preserve data privacy, one promising data-sharing tool named attribute-based encryption (ABE) has been widely employed. However, it is a challenge to achieve flexible data sharing without loss of confidentiality when authorized users are dynamic. Another challenge is how to guarantee fleet data access time when resource-limited devices are used. In this article, a dynamic access policy ABE (DAP-ABE) system for EHRs in the cloud is proposed. The cloud server can update the access policy without sensitive information, while decryption keys of authorized users do not need to be updated. Authorized users enjoy approximately 0.07 ms data access by outsourcing the majority of the decryption overhead to the cloud server. Furthermore, a verification procedure is embedded in DAP-ABE to check the identities of patients in the data sharing stage, which ensures that no malicious user can upload invalid EHRs. Extensive experiments demonstrate the feasibility and efficiency of the DAP-ABE system."}}
{"id": "ryOI67LJ3A", "cdate": 1688169600000, "mdate": 1699609434546, "content": {"title": "Secure Decentralized Image Classification With Multiparty Homomorphic Encryption", "abstract": "Decentralized image classification plays a key role in various scenarios due to its attractive properties, including tolerating high network latency and less prone to single-point failures. Unfortunately, training such a decentralized image classification model is more vulnerable to data privacy leaks compared to other distributed training frameworks. Existing efforts exclusively use differential privacy as the cornerstone to alleviate the threat to data privacy. However, differential privacy is implemented at the expense of accuracy, which goes against our motivation for designing an image classification model without loss of accuracy. To address this problem, we propose D <sup xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">2</sup> -MHE, the <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">first</i> secure and efficient decentralized training framework with lossless precision. Inspired by the latest developments in the homomorphic encryption technology, we design a multiparty version of Brakerski-Fan-Vercauteren (BFV), one of the most advanced cryptosystems, and use it to implement private gradient updates of users\u2019 local models. D <sup xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">2</sup> -MHE can reduce the communication complexity of general Secure Multiparty Computation (MPC) tasks from quadratic to linear in the number of users, making it very suitable and scalable for large-scale decentralized learning systems. Moreover, D <sup xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">2</sup> -MHE provides strict semantic security protection even if the majority of users are dishonest with collusion. We conduct extensive experiments on MNIST, CIFAR-10, and ImageNet to demonstrate the superiority of D <sup xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">2</sup> -MHE. Experimental results show that D <sup xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">2</sup> -MHE achieves up to <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"> <tex-math notation=\"LaTeX\">$5.5\\times $ </tex-math></inline-formula> reduction in computation overhead, and at least <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"> <tex-math notation=\"LaTeX\">$12\\times $ </tex-math></inline-formula> reduction in communication overhead compared to existing schemes."}}
{"id": "ulMZfqv4-r", "cdate": 1685577600000, "mdate": 1699609434552, "content": {"title": "Physical Black-Box Adversarial Attacks Through Transformations", "abstract": "Deep learning has shown impressive performance in numerous applications. However, recent studies have found that deep learning models are vulnerable to adversarial attacks, where the attacker adds imperceptible perturbations into benign samples to induce misclassifications. Adversarial attacks in the digital domain focus on constructing imperceptible perturbations. However, they are always less effective in the physical world because the perturbations may be destroyed when captured by the camera. Most physical adversarial attacks require adding invisible adversarial features (e.g., a sticker or a laser) to the target object, which may be noticed by human eyes. In this work, we propose to employ image transformation to generate more natural adversarial samples in the physical world. Concretely, we propose two attack algorithms to satisfy different attack goals: <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">Efficient-AATR</i> employs a greedy strategy to generate adversarial samples with fewer queries; <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">Effective-AATR</i> employs an adaptive particle swarm optimization algorithm to search for the most effective adversarial samples within the given the number of queries. Extensive experiments demonstrate the superiority of our attacks compared with state-of-the-art adversarial attacks under mainstream defenses."}}
{"id": "angga-bjat", "cdate": 1685577600000, "mdate": 1699609434506, "content": {"title": "Physical Black-Box Adversarial Attacks Through Transformations", "abstract": "Deep learning has shown impressive performance in numerous applications. However, recent studies have found that deep learning models are vulnerable to adversarial attacks, where the attacker adds imperceptible perturbations into benign samples to induce misclassifications. Adversarial attacks in the digital domain focus on constructing imperceptible perturbations. However, they are always less effective in the physical world because the perturbations may be destroyed when captured by the camera. Most physical adversarial attacks require adding invisible adversarial features (e.g., a sticker or a laser) to the target object, which may be noticed by human eyes. In this work, we propose to employ image transformation to generate more natural adversarial samples in the physical world. Concretely, we propose two attack algorithms to satisfy different attack goals: <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">Efficient-AATR</i> employs a greedy strategy to generate adversarial samples with fewer queries; <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">Effective-AATR</i> employs an adaptive particle swarm optimization algorithm to search for the most effective adversarial samples within the given the number of queries. Extensive experiments demonstrate the superiority of our attacks compared with state-of-the-art adversarial attacks under mainstream defenses."}}
{"id": "PMI4Y0MJsDw", "cdate": 1677628800000, "mdate": 1684306478592, "content": {"title": "Share Your Data Carefree: An Efficient, Scalable and Privacy-Preserving Data Sharing Service in Cloud Computing", "abstract": "Benefiting from the powerful computing and storage capabilities of cloud services, data sharing in the cloud has been permeated across various applications including social networks, e-health and crowdsourcing transportation system. Intuitively, outsourcing data to untrusted cloud commonly raises concerns about data privacy breaches. To combat this, one approach is exploiting Broadcast Based Searchable Encryption (BBSE) for secure data sharing. Nevertheless, the latest proposed BBSE is still defective in either security or efficiency. In this article, we propose ESPD, an Efficient, Scalable and Privacy-preserving Data sharing framework over encrypted cloud dataset. Different from previous works, ESPD supports sharing target data to multiple users with distinct secret keys, and keeps a constant ciphertext length with the changes of the amount of system users. This feature significantly improves search efficiency and makes ESPD scalable in real-world scenarios. We show a formal analysis to prove the security of ESPD in terms of file privacy, keyword privacy and trapdoor privacy. Also, extensive experiments on real-world dataset are conducted to indicate the desirable performance of ESPD compared to other similar schemes."}}
{"id": "38F9v6Q-Fde", "cdate": 1677628800000, "mdate": 1684306478543, "content": {"title": "Enabling Simultaneous Content Regulation and Privacy Protection for Cloud Storage Image", "abstract": "The population of cloud computing greatly facilitates the sharing of explosively generated image today. While benefiting from the convenient of cloud, the privacy protection mechanism that commonly applied in cloud service makes the spreading of illegal and harmful data very hard to be detected or controlled. Such a realistic threat should be seriously treated, yet is largely overlooked in the literature. To address this issue, we propose the first cloud service framework that can simultaneously provide privacy protection and content regulation for the cloud storage image. In specific, we design a secure multi-party computation (MPC) protocol to protect the data privacy via random projection. By leveraging the distance preserving properties residing in random projection, we propose a privacy-preserving principal component analysis (PCA)-based recognition approach over the random projection domain to achieve content matching while respecting the data privacy. To facilitate the efficiency, we implement our system under the compressive sensing (CS) framework. Due to the compression effect of CS, the proposed cloud service can achieve remarkable reduction on the computation and communication complexity of the content matching process. Theoretical analysis and experimental results both show that our system can achieve privacy assurance and acceptable recognition performance, while with high efficiency."}}
{"id": "wWG4gpA6Fn", "cdate": 1672531200000, "mdate": 1699609434535, "content": {"title": "Extracting Robust Models with Uncertain Examples", "abstract": ""}}
{"id": "wOm3rSA8ra", "cdate": 1672531200000, "mdate": 1699609434551, "content": {"title": "An Adaptively Secure and Efficient Data Sharing System for Dynamic User Groups in Cloud", "abstract": "Cloud computing has been widely accepted as a computing paradigm to offer high-quality data services on demand. However, it suffers from various attacks as the cloud service provider and data owners are not in the same trusted domain. To support data confidentiality, existing cloud-based systems apply cryptographic tools to issue the decryption key to data users to share data in a controlled way. However, fine-grained cloud data sharing still faces many challenges, especially when dealing with dynamic user groups. In this paper, we introduce a secure and efficient cloud-based data-sharing system with fine-grained access control and dynamic user groups. Our system enjoys 1) adaptive security in prime-order groups, 2) forward secrecy against revoked user fetches data generated before being revoked, and 3) decryption key exposure resistance against the compromise of the frequently used decryption key, where the previous solutions only concentrate on one or two above-mentioned properties. More specifically, we introduce two timestamp management mechanisms that manage the timestamp in each ciphertext to support dynamic user groups with forward secrecy. By applying the proposed timestamp management mechanisms, we introduce two novel designs of attribute-based encryption schemes with formal definition and security analyses. The proposed schemes are adaptively secure in prime-order groups under a standard assumption and support decryption key exposure resistance. We conduct theoretical analysis and experimental simulation to demonstrate the outperformance of our solutions."}}
{"id": "tAiIifvxckx", "cdate": 1672531200000, "mdate": 1699609434539, "content": {"title": "Mercury: An Automated Remote Side-channel Attack to Nvidia Deep Learning Accelerator", "abstract": "DNN accelerators have been widely deployed in many scenarios to speed up the inference process and reduce the energy consumption. One big concern about the usage of the accelerators is the confidentiality of the deployed models: model inference execution on the accelerators could leak side-channel information, which enables an adversary to preciously recover the model details. Such model extraction attacks can not only compromise the intellectual property of DNN models, but also facilitate some adversarial attacks. Although previous works have demonstrated a number of side-channel techniques to extract models from DNN accelerators, they are not practical for two reasons. (1) They only target simplified accelerator implementations, which have limited practicality in the real world. (2) They require heavy human analysis and domain knowledge. To overcome these limitations, this paper presents Mercury, the first automated remote side-channel attack against the off-the-shelf Nvidia DNN accelerator. The key insight of Mercury is to model the side-channel extraction process as a sequence-to-sequence problem. The adversary can leverage a time-to-digital converter (TDC) to remotely collect the power trace of the target model's inference. Then he uses a learning model to automatically recover the architecture details of the victim model from the power trace without any prior knowledge. The adversary can further use the attention mechanism to localize the leakage points that contribute most to the attack. Evaluation results indicate that Mercury can keep the error rate of model extraction below 1%."}}
