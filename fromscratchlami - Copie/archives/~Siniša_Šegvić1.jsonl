{"id": "hmKtMjs4Fu", "cdate": 1672531200000, "mdate": 1675686470056, "content": {"title": "Hybrid Open-set Segmentation with Synthetic Negative Data", "abstract": "Open-set segmentation is often conceived by complementing closed-set classification with anomaly detection. Existing dense anomaly detectors operate either through generative modelling of regular training data or by discriminating with respect to negative training data. These two approaches optimize different objectives and therefore exhibit different failure modes. Consequently, we propose the first dense hybrid anomaly score that fuses generative and discriminative cues. The proposed score can be efficiently implemented by upgrading any semantic segmentation model with dense estimates of data likelihood and dataset posterior. Our design is a remarkably good fit for efficient inference on large images due to negligible computational overhead over the closed-set baseline. The resulting dense hybrid open-set models require negative training images that can be sampled from an auxiliary negative dataset, from a jointly trained generative model, or from a mixture of both sources. We evaluate our contributions on benchmarks for dense anomaly detection and open-set segmentation. The experiments reveal strong open-set performance in spite of negligible computational overhead."}}
{"id": "deAMj9f9-EJ", "cdate": 1672531200000, "mdate": 1679902408881, "content": {"title": "Revisiting Consistency for Semi-Supervised Semantic Segmentation", "abstract": ""}}
{"id": "ckxkKT8p2O", "cdate": 1672531200000, "mdate": 1675686470080, "content": {"title": "On advantages of Mask-level Recognition for Open-set Segmentation in the Wild", "abstract": "Most dense recognition approaches bring a separate decision in each particular pixel. These approaches deliver competitive performance in usual closed-set setups. However, important applications in the wild typically require strong performance in presence of outliers. We show that this demanding setup greatly benefit from mask-level predictions, even in the case of non-finetuned baseline models. Moreover, we propose an alternative formulation of dense recognition uncertainty that effectively reduces false positive responses at semantic borders. The proposed formulation produces a further improvement over a very strong baseline and sets the new state of the art in outlier-aware semantic segmentation with and without training on negative data. Our contributions also lead to performance improvement in a recent panoptic setup. In-depth experiments confirm that our approach succeeds due to implicit aggregation of pixel-level cues into mask-level predictions."}}
{"id": "UyZt2ueC130", "cdate": 1672531200000, "mdate": 1679902408740, "content": {"title": "Normalizing Flow based Feature Synthesis for Outlier-Aware Object Detection", "abstract": ""}}
{"id": "45JwgIq46ze", "cdate": 1672531200000, "mdate": 1679902408767, "content": {"title": "Identifying Label Errors in Object Detection Datasets by Loss Inspection", "abstract": ""}}
{"id": "wmfPS8rlc6J", "cdate": 1640995200000, "mdate": 1667338009070, "content": {"title": "DenseHybrid: Hybrid Anomaly Detection for Dense Open-set Recognition", "abstract": "Anomaly detection can be conceived either through generative modelling of regular training data or by discriminating with respect to negative training data. These two approaches exhibit different failure modes. Consequently, hybrid algorithms present an attractive research goal. Unfortunately, dense anomaly detection requires translational equivariance and very large input resolutions. These requirements disqualify all previous hybrid approaches to the best of our knowledge. We therefore design a novel hybrid algorithm based on reinterpreting discriminative logits as a logarithm of the unnormalized joint distribution $\\hat{p}(\\mathbf{x}, \\mathbf{y})$. Our model builds on a shared convolutional representation from which we recover three dense predictions: i) the closed-set class posterior $P(\\mathbf{y}|\\mathbf{x})$, ii) the dataset posterior $P(d_{in}|\\mathbf{x})$, iii) unnormalized data likelihood $\\hat{p}(\\mathbf{x})$. The latter two predictions are trained both on the standard training data and on a generic negative dataset. We blend these two predictions into a hybrid anomaly score which allows dense open-set recognition on large natural images. We carefully design a custom loss for the data likelihood in order to avoid backpropagation through the untractable normalizing constant $Z(\\theta)$. Experiments evaluate our contributions on standard dense anomaly detection benchmarks as well as in terms of open-mIoU - a novel metric for dense open-set performance. Our submissions achieve state-of-the-art performance despite neglectable computational overhead over the standard semantic segmentation baseline."}}
{"id": "uUjh6WksHIl", "cdate": 1640995200000, "mdate": 1667338009086, "content": {"title": "Automatic universal taxonomies for multi-domain semantic segmentation", "abstract": "Training semantic segmentation models on multiple datasets has sparked a lot of recent interest in the computer vision community. This interest has been motivated by expensive annotations and a desire to achieve proficiency across multiple visual domains. However, established datasets have mutually incompatible labels which disrupt principled inference in the wild. We address this issue by automatic construction of universal taxonomies through iterative dataset integration. Our method detects subset-superset relationships between dataset-specific labels, and supports learning of sub-class logits by treating super-classes as partial labels. We present experiments on collections of standard datasets and demonstrate competitive generalization performance with respect to previous work."}}
{"id": "q7i8P1ijy6", "cdate": 1640995200000, "mdate": 1672869119453, "content": {"title": "Dynamic loss balancing and sequential enhancement for road-safety assessment and traffic scene classification", "abstract": ""}}
{"id": "pfv61UBD9D7", "cdate": 1640995200000, "mdate": 1672869119459, "content": {"title": "Weakly supervised training of universal visual concepts for multi-domain semantic segmentation", "abstract": ""}}
{"id": "eyxG1DsFPrP", "cdate": 1640995200000, "mdate": 1667338009078, "content": {"title": "DenseHybrid: Hybrid Anomaly Detection for Dense Open-Set Recognition", "abstract": "Anomaly detection can be conceived either through generative modelling of regular training data or by discriminating with respect to negative training data. These two approaches exhibit different failure modes. Consequently, hybrid algorithms present an attractive research goal. Unfortunately, dense anomaly detection requires translational equivariance and very large input resolutions. These requirements disqualify all previous hybrid approaches to the best of our knowledge. We therefore design a novel hybrid algorithm based on reinterpreting discriminative logits as a logarithm of the unnormalized joint distribution $$\\hat{p}(\\textbf{x},\\textbf{y})$$ . Our model builds on a shared convolutional representation from which we recover three dense predictions: i) the closed-set class posterior $$P(\\textbf{y}|\\textbf{x})$$ , ii) the dataset posterior $$P(d_{in}|\\textbf{x})$$ , iii) unnormalized data likelihood $$\\hat{p}(\\textbf{x})$$ . The latter two predictions are trained both on the standard training data and on a generic negative dataset. We blend these two predictions into a hybrid anomaly score which allows dense open-set recognition on large natural images. We carefully design a custom loss for the data likelihood in order to avoid backpropagation through the untractable normalizing constant $$Z(\\theta )$$ . Experiments evaluate our contributions on standard dense anomaly detection benchmarks as well as in terms of open-mIoU - a novel metric for dense open-set performance. Our submissions achieve state-of-the-art performance despite neglectable computational overhead over the standard semantic segmentation baseline. Official implementation: https://github.com/matejgrcic/DenseHybrid"}}
