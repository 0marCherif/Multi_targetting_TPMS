{"id": "t2X4JfAfQZJ", "cdate": 1672531200000, "mdate": 1695951956303, "content": {"title": "Run-off Election: Improved Provable Defense against Data Poisoning Attacks", "abstract": "In data poisoning attacks, an adversary tries to change a model\u2019s prediction by adding, modifying, or removing samples in the training data. Recently, <em>ensemble-based</em> approaches for obtaini..."}}
{"id": "jlIq7Lpkf3", "cdate": 1672531200000, "mdate": 1695951956308, "content": {"title": "Text2Concept: Concept Activation Vectors Directly from Text", "abstract": "Concept activation vectors (CAVs) enable interpretability of a model with respect to human concepts, though CAV generation requires the costly step of curating positive and negative examples for each concept one wishes to encode. To alleviate this bottleneck, we present Text2Concept, an efficient method for obtaining CAVs directly from text. Text2Concept extends the multi-modal accessibility of a CLIP model\u2019s feature space to that of an arbitrary off-the-shelf vision model, with only the small extra step of training a linear layer on existing data to map the feature spaces to one another. We validate our method qualitatively, by sorting images by similarity to embedded concepts, and quantitatively, by showing surprisingly strong zero-shot classification (enabled via Text2Concept) performance for off-the-shelf vision encoders. Finally, we demonstrate two new interpretability applications of Text2Concept CAVs: building concept bottleneck models with no concept supervision, and diagnosing distribution shifts in terms of human concepts."}}
{"id": "T97W0MssAS", "cdate": 1672531200000, "mdate": 1695951956302, "content": {"title": "Text-To-Concept (and Back) via Cross-Model Alignment", "abstract": "We observe that the mapping between an image\u2019s representation in one model to its representation in another can be learned surprisingly well with just a linear layer, even across diverse models. Bu..."}}
{"id": "HjMnztLGfj", "cdate": 1672531200000, "mdate": 1695951956308, "content": {"title": "Delegating to Multiple Agents", "abstract": "We consider a multi-agent delegation mechanism without money. In our model, given a set of agents, each agent has a fixed number of solutions which is exogenous to the mechanism, and privately sends a signal, e.g., a subset of solutions, to the principal. Then, the principal selects a final solution based on the agents' signals. In stark contrast to single-agent setting by Kleinberg and Kleinberg [2018] with an approximate Bayesian mechanism, we show that there exists efficient approximate prior-independent mechanisms with both information and performance gain, thanks to the competitive tension between the agents. Interestingly however, the amount of such a compelling power significantly varies with respect to the information available to the agents, and the degree of correlation between the principal's and the agent's utility. Technically, we conduct a comprehensive study on the multi-agent delegation problem and derive several results on the approximation factors of Bayesian/prior-independent mechanisms in complete/incomplete information settings. As a special case of independent interest, we obtain comparative statics regarding the number of agents which implies the dominance of the multi-agent setting (n \u2265 2) over the single-agent setting (n = 1) in terms of the principal's utility. We further extend our problem by considering an examination cost of the mechanism and derive some analogous results in the complete information setting."}}
