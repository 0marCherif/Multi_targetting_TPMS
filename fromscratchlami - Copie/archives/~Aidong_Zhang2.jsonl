{"id": "YR-s5leIvh", "cdate": 1652737397671, "mdate": null, "content": {"title": "CLEAR: Generative Counterfactual Explanations on Graphs", "abstract": "Counterfactual explanations promote explainability in machine learning models by answering the question \u201chow should the input instance be altered to obtain a desired predicted label?\". The comparison of this instance before and after perturbation can enhance human interpretation. Most existing studies on counterfactual explanations are limited in tabular data or image data. In this paper, we study the problem of counterfactual explanation generation on graphs. A few studies have explored to generate counterfactual explanations on graphs, but many challenges of this problem are still not well-addressed: 1) optimizing in the discrete and disorganized space of graphs; 2) generalizing on unseen graphs; 3) maintaining the causality\u00a0in the generated counterfactuals without prior knowledge of the causal model. To tackle these challenges, we propose a novel framework CLEAR which aims to generate counterfactual explanations on graphs for graph-level prediction models. Specifically, CLEAR leverages a graph variational autoencoder based mechanism to facilitate its optimization and generalization, and promotes causality by leveraging an auxiliary variable to better identify the causal model. Extensive experiments on both synthetic and real-world graphs validate the superiority of CLEAR over state-of-the-art counterfactual explanation methods on graphs in different aspects. \u2028"}}
{"id": "gBRhD54Pd_", "cdate": 1642649805083, "mdate": null, "content": {"title": "A Survey on Causal Inference", "abstract": "Causal inference is a critical research topic across many domains, such as statistics, computer science, education, public policy, and economics, for decades. Nowadays, estimating causal effect from observational data has become an appealing research direction owing to the large amount of available data and low budget requirement, compared with randomized controlled trials. Embraced with the rapidly developed machine learning area, various causal effect estimation methods for observational data have sprung up. In this survey, we provide a comprehensive review of causal inference methods under the potential outcome framework, one of the well-known causal inference frameworks. The methods are divided into two categories depending on whether they require all three assumptions of the potential outcome framework or not. For each category, both the traditional statistical methods and the recent machine learning enhanced methods are discussed and compared. The plausible applications of these methods are also presented, including the applications in advertising, recommendation, medicine, and so on. Moreover, the commonly used benchmark datasets as well as the open-source codes are also summarized, which facilitate researchers and practitioners to explore, evaluate and apply the causal inference methods."}}
{"id": "vqm3oqFY6LpZ", "cdate": 1577836800000, "mdate": null, "content": {"title": "Deep Learning Aided Signal Detection for SPAD-Based Underwater Optical Wireless Communications.", "abstract": "In underwater optical wireless communication (UOWC) systems, using single photon avalanche photondiode (SPAD) as the detector can improve the transmission distance. However, the signal detection for SPAD-based systems is greatly challenged by the complex optical channel characteristics and SPAD nonlinear distortion. To address this issue, a novel deep learning aided signal detection scheme is proposed in this paper. By exploiting the physical mechanism and prior expert knowledge of the signal processing, a two-connected multilayer perception (MLP) network is integrated into the receiver. The first subnetwork is regarded as a channel compensation block while the second one works as a demodulator. With sophisticated numerical optical channel model and SPAD non-Poisson model, large amounts of training data are utilized to train the proposed model offline. Afterwards, the online data are recovered with the trained network. Simulation results verify that significant bit error ratio (BER) improvement can be achieved with the proposed scheme."}}
{"id": "kiLUlPSkJbqx", "cdate": 1577836800000, "mdate": null, "content": {"title": "Cooperative Moving-Target Enclosing of Networked Vehicles With Constant Linear Velocities.", "abstract": "This paper investigates the cooperative movingtarget enclosing control problem of networked unicycle-type nonholonomic vehicles with constant linear velocities. The information of the target is only known to some of the vehicles, and the topology of the vehicle network is described by a directed graph. A dynamic control law is proposed to steer the vehicles, such that they can get close to orbiting around the target while the target is moving with a time-vary velocity. Besides, the constraint of bounded angular velocity for the vehicles can always be satisfied. The proposed control law is distributed in the sense that each vehicle only uses its own information and the information of its neighbors in the network. Finally, simulation results of an example validate the effectiveness of the proposed control law."}}
{"id": "kPsSgOKtClrj", "cdate": 1577836800000, "mdate": null, "content": {"title": "Secure Inter-Domain Forwarding Loop Test in Software Defined Networks.", "abstract": "Debugging a traditional network is notoriously difficult due to network devices' heterogeneity and protocols' decentralized nature, but Software-Defined Networking (SDN) is changing this predicament. Recent works have provided very nice approaches for an administrator to perform several fundamental network tests in a single-domain SDN network. However, how to perform these tests securely in multi-domain networks still remains open. In this paper, we study the highly challenging problem of inter-domain forwarding loop test in a SDN environment. We present two novel testing protocols that can be used for inter-domain loop tests. Both protocols are secure in the sense that they protect each domain's private information about its topology and configuration. The first protocol, based on random sampling, is highly efficient with a small error probability diminishing exponentially in the sample size. The second protocol, based on secure set intersection test, guarantees 100 percent accuracy of the result, although not as efficient as the first one. We provide rigorous proofs for the security and accuracy guarantees, and show our protocols have very good efficiency by testing them with real-world network data."}}
{"id": "LFUCqByqpo1", "cdate": 1577836800000, "mdate": null, "content": {"title": "A Survey on Causal Inference.", "abstract": "Causal inference is a critical research topic across many domains, such as statistics, computer science, education, public policy and economics, for decades. Nowadays, estimating causal effect from observational data has become an appealing research direction owing to the large amount of available data and low budget requirement, compared with randomized controlled trials. Embraced with the rapidly developed machine learning area, various causal effect estimation methods for observational data have sprung up. In this survey, we provide a comprehensive review of causal inference methods under the potential outcome framework, one of the well known causal inference framework. The methods are divided into two categories depending on whether they require all three assumptions of the potential outcome framework or not. For each category, both the traditional statistical methods and the recent machine learning enhanced methods are discussed and compared. The plausible applications of these methods are also presented, including the applications in advertising, recommendation, medicine and so on. Moreover, the commonly used benchmark datasets as well as the open-source codes are also summarized, which facilitate researchers and practitioners to explore, evaluate and apply the causal inference methods."}}
{"id": "Asu-fiECotuF", "cdate": 1577836800000, "mdate": null, "content": {"title": "DeepMV: Multi-View Deep Learning for Device-Free Human Activity Recognition.", "abstract": "Recently, significant efforts are made to explore device-free human activity recognition techniques that utilize the information collected by existing indoor wireless infrastructures without the need for the monitored subject to carry a dedicated device. Most of the existing work, however, focuses their attention on the analysis of the signal received by a single device. In practice, there are usually multiple devices \"observing\" the same subject. Each of these devices can be regarded as an information source and provides us an unique \"view\" of the observed subject. Intuitively, if we can combine the complementary information carried by the multiple views, we will be able to improve the activity recognition accuracy. Towards this end, we propose DeepMV, a unified multi-view deep learning framework, to learn informative representations of heterogeneous device-free data. DeepMV can combine different views' information weighted by the quality of their data and extract commonness shared across different environments to improve the recognition performance. To evaluate the proposed DeepMV model, we set up a testbed using commercialized WiFi and acoustic devices. Experiment results show that DeepMV can effectively recognize activities and outperform the state-of-the-art human activity recognition methods."}}
{"id": "yfC1HgPIOEJH", "cdate": 1546300800000, "mdate": null, "content": {"title": "Recurrent Imputation for Multivariate Time Series with Missing Values.", "abstract": "Multivariate time series data are ubiquitous in real-world healthcare systems. It is a common issue that the data contain missing values due to various reasons, such as sensor damage, data corruption, patient dropout. There have been various works on filling the missing values in multivariate time series. Classical imputation methods include KNN-based, Matrix Factorization based, and Expectation-Maximization (EM) based imputation and so on. These methods are developed for general imputation purpose and rarely utilize the temporal relations between observations. Classical statistical time series models such as autoregressive (AR) models and dynamic linear models (DLM) (e.g. [1]) can capture the temporal information, but they are essentially linear and may not be suitable for modern complex large-scale data. ImputeTS [2] employs time dependencies on univariate time series imputation, which ignores feature correlations. Recent works [3, 4] develop the imputation framework that can take advantages of the traditional methods and resolve their drawbacks. Another trend of models is based on recurrent neural network (RNN) [5-10], utilizing RNN to capture temporal dependencies and further considering various aspects of the data characteristics, such as time decay, feature correlation, residual link, and temporal belief gate. In this paper, we propose an RNN-based imputation method for filling the missing values in multivariate time series. RNN is used to capture the temporal information of time series. We use a global RNN and variable-specific RNNs to perform imputation based on historical information, and a fusion gate to combine them. At each timestamp, we use a regression layer to impute the value of a certain variable using other variables, by utilizing the relationship of variables. Bi-directional imputation is adopted to improve the ability of long-term memory and performance of starting timestamps."}}
{"id": "yJyhzDCjtYUx", "cdate": 1546300800000, "mdate": null, "content": {"title": "Bionic Architecture Design and Robust Rough-Terrain Locomotion for a High-Payload Quadrupedal Robot.", "abstract": "In this work, an electrically actuated quadrupedal robot with bionic architecture, Pegasus, is reported. With investigating the anatomical skeleton of medium-sized dog, its movement mechanism, and dog\u2019s joints, we conclude that the architecture design of quadrupedal robots can benefit from bionics research. There is an optimization for structural parameters, geometrical relationship, and motion range of each joint according to the findings in bionics. The bionic structure design is verified by analyzing mechanical performance and motion ability of the robot. The bionic architecture allows COG trajectory not to follow the terrain profile and COG fluctuations are significantly suppressed when going through rough terrains. In order to generate a stable COG trajectory with fewer pose fluctuations, the step sequence and four footholds in each step follow the typical biological gait pattern for dynamic walking over rough terrains while the robot can keep robust postures in efficient workspace for each leg. Moreover, \"Virtual Muscle\" model is realized for each leg\u2019s compliance control with two sets of virtual spring and damper, in order to absorb feet impacts on the ground."}}
{"id": "xxksdEQVmPD", "cdate": 1546300800000, "mdate": null, "content": {"title": "A survey on literature based discovery approaches in biomedical domain.", "abstract": "Literature Based Discovery (LBD) refers to the problem of inferring new and interesting knowledge by logically connecting independent fragments of information units through explicit or implicit means. This area of research, which incorporates techniques from Natural Language Processing (NLP), Information Retrieval and Artificial Intelligence, has significant potential to reduce discovery time in biomedical research fields. Formally introduced in 1986, LBD has grown to be a significant and a core task for text mining practitioners in the biomedical domain. Together with its inter-disciplinary nature, this has led researchers across domains to contribute in advancing this field of study. This survey attempts to consolidate and present the evolution of techniques in this area. We cover a variety of techniques and provide a detailed description of the problem setting, the intuition, the advantages and limitations of various influential papers. We also list the current bottlenecks in this field and provide a general direction of research activities for the future. In an effort to be comprehensive and for ease of reference for off-the-shelf users, we also list many publicly available tools for LBD. We hope this survey will act as a guide to both academic and industry (bio)-informaticians, introduce the various methodologies currently employed and also the challenges yet to be tackled."}}
