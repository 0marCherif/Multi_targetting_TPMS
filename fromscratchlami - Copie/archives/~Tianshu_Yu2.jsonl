{"id": "RHsOd1Aineq", "cdate": 1663850248755, "mdate": null, "content": {"title": "Learning to Boost Resilience of Complex Networks via Neural Edge Rewiring", "abstract": "The resilience of complex networks, a critical structural characteristic in network science, measures the network's ability to withstand noise corruption and structural changes. Improving resilience typically resorts to minimal modifications of the network structure via degree-preserving edge rewiring-based methods. Despite their effectiveness, existing methods are learning-free, sharing the limitation of transduction: a learned edge rewiring strategy from one graph cannot be generalized to another. Such a limitation cannot be trivially addressed by existing graph neural networks (GNNs)-based approaches since there is no rich initial node features for GNNs to learn meaningful representations. However, neural edge rewiring relies on GNNs for obtaining meaningful representations from pure graph topologies to select edges. We found existing GNNs degenerate remarkably with only pure topologies on the resilience task, leading to the undesired infinite action backtracking. In this work, inspired by persistent homology, we specifically design a variant of GNN called FireGNN for learning inductive edge rewiring strategies. Based on meaningful representations from FireGNN, we develop the first end-to-end inductive method, ResiNet, to discover $\\textbf{resi}$lient $\\textbf{net}$work topologies while balancing network utility. ResiNet reformulates network resilience optimization as a Markov decision process equipped with edge rewiring action space and learns to select correct edges successively.  Extensive experiments demonstrate that ResiNet achieves a near-optimal resilience gain on various graphs while balancing the utility and outperforms existing approaches by a large margin."}}
{"id": "tsPXEkMzPjB", "cdate": 1663850235447, "mdate": null, "content": {"title": "Learning to Decouple Complex System for Sequential Data", "abstract": "A complex system with cluttered observations may be a coupled mixture of multiple simple sub-systems corresponding to \\emph{latent entities}. Such sub-systems may hold distinct dynamics in the continuous-time domain, therein complicated interactions between sub-systems also evolve over time.  This setting is fairly common in the real world, but has been less considered. In this paper, we propose a sequential learning approach under this setting by decoupling a complex system for handling irregularly sampled and cluttered sequential observations. Such decoupling brings about not only subsystems describing the dynamics of each latent entity, but also a meta-system capturing the interaction between entities over time. Specifically, we argue that the meta-system of interactions is governed by a smoothed version of \\emph{projected differential equations}. Experimental results on synthetic and real-world datasets show the advantages of our approach when facing complex and cluttered sequential data compared to the state-of-the-art."}}
{"id": "wjJ3pR-ZQD", "cdate": 1601308027845, "mdate": null, "content": {"title": "Learning Latent Topology for Graph Matching", "abstract": "Graph matching (GM) has been traditionally modeled as a deterministic optimization problem characterized by an affinity matrix under pre-defined graph topology. Though there have been several attempts on learning more effective node-level affinity/representation for matching, they still heavily rely on the initial graph structure/topology which is typically obtained through heuristic ways (e.g. Delauney or $k$-nearest) and will not be adjusted during the learning process to adapt to problem-specific patterns. We argue that a standalone graph representation learning is insufficient for GM task, whereby a GM solver may favor some latent topology other than pre-defined one. Motivated by this hypothesis, we propose to learn latent graph topology in replacement of the fixed topology as input. To this end, we devise two types of latent graph generation procedures in deterministic and generative fashion, respectively. Particularly, the generative procedure emphasizes the across-graph consistency and thus can be viewed as a \\textbf{co-generative} model. Our methods show superior performance over previous state-of-the-arts on several benchmarks, thus strongly supporting our hypothesis."}}
{"id": "SFUeU3vZ1AS", "cdate": 1576109998498, "mdate": null, "content": {"title": "Generalizing graph matching beyond quadratic assignment model", "abstract": "Graph matching has received persistent attention over several decades, which can\nbe formulated as a quadratic assignment problem (QAP). We show that a large\nfamily of functions, which we define as Separable Functions, can approximate\ndiscrete graph matching in the continuous domain asymptotically by varying the\napproximation controlling parameters. We also study the properties of global\noptimality and devise convex/concave-preserving extensions to the widely used\nLawler\u2019s QAP form. Our theoretical findings show the potential for deriving new\nalgorithms and techniques for graph matching. We deliver solvers based on two\nspecific instances of Separable Functions, and the state-of-the-art performance of\nour method is verified on popular benchmarks."}}
{"id": "HAGgwSw-J0H", "cdate": 1576109886967, "mdate": null, "content": {"title": "Incremental multi-graph matching via diversity and randomness based graph clustering", "abstract": "Multi-graph matching refers to finding correspondences across\ngraphs, which are traditionally solved by matching all the graphs in a single batch. However in real-world applications, graphs are often collected\nincrementally, rather than once for all. In this paper, we present an incremental multi-graph matching approach, which deals with the arriving\ngraph utilizing the previous matching results under the global consistency constraint. When a new graph arrives, rather than re-optimizing\nover all graphs, we propose to partition graphs into subsets with certain\ntopological structure and conduct optimization within each subset. The\npartitioning procedure is guided by the diversity within partitions and\nrandomness over iterations, and we present an interpretation showing\nwhy these two factors are essential. The final matching results are calculated over all subsets via an intersection graph. Extensive experimental\nresults on synthetic and real image datasets show that our algorithm\nnotably improves the efficiency without sacrificing the accuracy."}}
{"id": "B42gsC8ZJCH", "cdate": 1576109778969, "mdate": null, "content": {"title": "Joint Cuts and Matching of Partitions in One Graph", "abstract": "\nAs two fundamental problems, graph cuts and graph\nmatching have been intensively investigated over the\ndecades, resulting in vast literature in these two topics respectively. However the way of jointly applying and solving\ngraph cuts and matching receives few attention. In this paper, we first formalize the problem of simultaneously cutting\na graph into two partitions i.e. graph cuts and establishing their correspondence i.e. graph matching. Then we\ndevelop an optimization algorithm by updating matching\nand cutting alternatively, provided with theoretical analysis. The efficacy of our algorithm is verified on both synthetic dataset and real-world images containing similar regions or structures."}}
{"id": "rkeIq2VYPr", "cdate": 1569438862414, "mdate": null, "content": {"title": "Deep Learning of Determinantal Point Processes via Proper Spectral Sub-gradient", "abstract": "Determinantal point processes (DPPs) is an effective tool to deliver diversity on multiple machine learning and computer vision tasks. Under deep learning framework, DPP is typically optimized via approximation, which is not straightforward and has some conflict with diversity requirement. We note, however, there has been no deep learning paradigms to optimize DPP directly since it involves matrix inversion which may result in highly computational instability. This fact greatly hinders the wide use of DPP on some specific objectives where DPP serves as a term to measure the feature diversity. In this paper, we devise a simple but effective algorithm to address this issue to optimize DPP term directly expressed with L-ensemble in spectral domain over gram matrix, which is more flexible than learning on parametric kernels. By further taking into account some geometric constraints, our algorithm seeks to generate valid sub-gradients of DPP term in case when the DPP gram matrix is not invertible (no gradients exist in this case). In this sense, our algorithm can be easily incorporated with multiple deep learning tasks. Experiments show the effectiveness of our algorithm, indicating promising performance for practical learning problems. "}}
{"id": "rJgBd2NYPH", "cdate": 1569438829123, "mdate": null, "content": {"title": "Learning deep graph matching with channel-independent embedding and Hungarian attention", "abstract": "Graph matching aims to establishing node-wise correspondence between two graphs, which is a classic combinatorial problem and in general NP-complete. Until very recently, deep graph matching methods start to resort to deep networks to achieve unprecedented matching accuracy. Along this direction, this paper makes two complementary contributions which can also be reused as plugin in existing works: i) a novel node and edge embedding strategy which stimulates the multi-head strategy in attention models and allows the information in each channel to be merged independently. In contrast, only node embedding is accounted in previous works; ii) a general masking mechanism over the loss function is devised to improve the smoothness of objective learning for graph matching. Using Hungarian algorithm, it dynamically constructs a structured and sparsely connected layer, taking into account the most contributing matching pairs as hard attention. Our approach performs competitively, and can also improve state-of-the-art methods as plugin, regarding with matching accuracy on three public benchmarks."}}
