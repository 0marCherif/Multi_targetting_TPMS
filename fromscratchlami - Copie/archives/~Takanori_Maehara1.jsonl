{"id": "GnZfV5Hplq", "cdate": 1695617823077, "mdate": 1695617823077, "content": {"title": "Statistically Efficient Estimation for Non-Smooth Probability Densities", "abstract": "We investigate statistical efficiency of estimators for non-smooth density functions. The density estimation problem appears in various situations, and it is intensively used in statistics and machine learning. The statistical efficiencies of estimators, i.e., their convergence rates, play a central role in advanced statistical analysis. Although estimators and their convergence rates for smooth density functions are well investigated in the literature, those for non-smooth density functions remain elusive despite their importance in application fields. In this paper, we propose new estimators for non-smooth density functions by employing the notion of Szemeredi partitions from graph theory. We derive convergence rates of the proposed estimators. One of them has the optimal convergence rate in minimax sense, and the other has slightly worse convergence rate but runs in polynomial time. Experimental results support the theoretical performance of our estimators."}}
{"id": "DzKPXXr-CLK", "cdate": 1632875517299, "mdate": null, "content": {"title": "Abelian Neural Networks", "abstract": "In several domains such as natural language processing, it has been empirically reported that simple addition and subtraction in a somehow learned embedding space capture analogical relations. However, there is no guarantee that such relation holds for a new embedding space acquired by some training strategies. To tackle this issue, we propose to explicitly model analogical structure with an Abelian group. We construct an Abelian group network using invertible neural networks and show its universal approximation property. In experiments, our model successfully learns to capture word analogies from word2vec representations and shows better performance than other learning-based strategies. As a byproduct of modeling Abelian group operations, we furthermore obtain its natural extension to permutation invariant models with theoretical size-generalization capability."}}
{"id": "Tbq5fYViJzm", "cdate": 1621629980549, "mdate": null, "content": {"title": "Learning on Random Balls is Sufficient for Estimating (Some) Graph Parameters", "abstract": "Theoretical analyses for graph learning methods often assume a complete observation of the input graph. Such an assumption might not be useful for handling any-size graphs due to the scalability issues in practice. In this work, we develop a theoretical framework for graph classification problems in the partial observation setting (i.e., subgraph samplings). Equipped with insights from graph limit theory, we propose a new graph classification model that works on a randomly sampled subgraph and a novel topology to characterize the representability of the model. Our theoretical framework contributes a theoretical validation of mini-batch learning on graphs and leads to new learning-theoretic results on generalization bounds as well as size-generalizability without assumptions on the input."}}
{"id": "1pn5ydv5X8c", "cdate": 1609459200000, "mdate": null, "content": {"title": "Abelian Neural Networks", "abstract": "We study the problem of modeling a binary operation that satisfies some algebraic requirements. We first construct a neural network architecture for Abelian group operations and derive a universal approximation property. Then, we extend it to Abelian semigroup operations using the characterization of associative symmetric polynomials. Both models take advantage of the analytic invertibility of invertible neural networks. For each case, by repeating the binary operations, we can represent a function for multiset input thanks to the algebraic structure. Naturally, our multiset architecture has size-generalization ability, which has not been obtained in existing methods. Further, we present modeling the Abelian group operation itself is useful in a word analogy task. We train our models over fixed word embeddings and demonstrate improved performance over the original word2vec and another naive learning method."}}
{"id": "1lf_YZAyvle", "cdate": 1609459200000, "mdate": null, "content": {"title": "r-Gathering Problems on Spiders: Hardness, FPT Algorithms, and PTASes", "abstract": "We consider the min-max r-gathering problem described as follows: We are given a set of users and facilities in a metric space. We open some of the facilities and assign each user to an opened facility such that each facility has at least r users. The goal is to minimize the maximum distance between the users and the assigned facility. We also consider the min-max r-gather clustering problem, which is a special case of the r-gathering problem in which the facilities are located everywhere. In this paper, we study the tractability and the hardness when the underlying metric space is a spider, which answers the open question posed by Ahmed et al. [WALCOM\u201919]. First, we show that the problems are NP-hard even if the underlying space is a spider. Then, we propose FPT algorithms parameterized by the degree d of the center. This improves the previous algorithms because they are parameterized by both r and d. Finally, we propose PTASes to the problems. These are best possible because there are no FPTASes unless P = NP."}}
{"id": "6VPl9khIMz", "cdate": 1601308085502, "mdate": null, "content": {"title": "Adaptive Stacked Graph Filter", "abstract": "We study Graph Convolutional Networks (GCN) from the graph signal processing viewpoint by addressing a difference between learning graph filters with fully-connected weights versus trainable polynomial coefficients. We find that by stacking graph filters with learnable polynomial parameters, we can build a highly adaptive and robust vertex classification model. Our treatment here relaxes the low-frequency (or equivalently, high homophily) assumptions in existing vertex classification models, resulting a more ubiquitous solution in terms of spectral properties. Empirically, by using only one hyper-parameter setting, our model achieves strong results on most benchmark datasets across the frequency spectrum."}}
{"id": "zBTG9WM1zpc", "cdate": 1577836800000, "mdate": null, "content": {"title": "Solving Weighted Abduction via Max-SAT Solvers", "abstract": ""}}
{"id": "xtaIfgz45x", "cdate": 1577836800000, "mdate": null, "content": {"title": "State-Space Network Topology Identification From Partial Observations", "abstract": "In this article, we explore the state-space formulation of a network process to recover from partial observations the network topology that drives its dynamics. To do so, we employ subspace techniques borrowed from system identification literature and extend them to the network topology identification problem. This approach provides a unified view of network control and signal processing on graphs. In addition, we provide theoretical guarantees for the recovery of the topological structure of a deterministic continuous-time linear dynamical system from input-output observations even when the input and state interaction networks are different. Our mathematical analysis is accompanied by an algorithm for identifying from data,a network topology consistent with the system dynamics and conforms to the prior information about the underlying structure. The proposed algorithm relies on alternating projections and is provably convergent. Numerical results corroborate the theoretical findings and the applicability of the proposed algorithm."}}
{"id": "v-Cj4dYr7PI", "cdate": 1577836800000, "mdate": null, "content": {"title": "Graph Homomorphism Convolution", "abstract": "In this paper, we study the graph classification problem from the graph homomorphism perspective. We consider the homomorphisms from $F$ to $G$, where $G$ is a graph of interest (e.g. molecules or social networks) and $F$ belongs to some family of graphs (e.g. paths or non-isomorphic trees). We show that graph homomorphism numbers provide a natural invariant (isomorphism invariant and $\\mathcal{F}$-invariant) embedding maps which can be used for graph classification. Viewing the expressive power of a graph classifier by the $\\mathcal{F}$-indistinguishable concept, we prove the universality property of graph homomorphism vectors in approximating $\\mathcal{F}$-invariant functions. In practice, by choosing $\\mathcal{F}$ whose elements have bounded tree-width, we show that the homomorphism method is efficient compared with other methods."}}
{"id": "uXIwZh4ccmQ", "cdate": 1577836800000, "mdate": null, "content": {"title": "Stacked Graph Filter", "abstract": "We study Graph Convolutional Networks (GCN) from the graph signal processing viewpoint by addressing a difference between learning graph filters with fully connected weights versus trainable polynomial coefficients. We find that by stacking graph filters with learnable polynomial parameters, we can build a highly adaptive and robust vertex classification model. Our treatment here relaxes the low-frequency (or equivalently, high homophily) assumptions in existing vertex classification models, resulting a more ubiquitous solution in terms of spectral properties. Empirically, by using only one hyper-parameter setting, our model achieves strong results on most benchmark datasets across the frequency spectrum."}}
