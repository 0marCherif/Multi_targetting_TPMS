{"id": "6bRKHpeZi7", "cdate": 1663850248285, "mdate": null, "content": {"title": "Visual Expertise and the Log-Polar Transform Explain Image Inversion Effects", "abstract": "Visual expertise can be defined as the ability to discriminate among subordinate-level objects in homogeneous classes, such as identities  of faces within the class \"face\". Despite being able to discriminate many faces, subjects perform poorly at recognizing even familiar faces once inverted. This face-inversion effect is in contrast to subjects\u2019 performance identifying inverted objects for which their experience is at a basic level, which results in less impairment.  Experimental results have suggested that when identifying mono-oriented objects, such as cars, car novices' performance is between that of faces and other objects. We build an anatomically-inspired neurocomputational model to explore this effect. Our model includes a foveated retina and the log-polar mapping from the visual field to V1. This transformation causes changes in scale to appear as horizontal translations, leading to scale equivariance. Rotation is similarly equivariant, leading to vertical translations. When fed into a standard convolutional network, this provides rotation and scale invariance. It may be surprising that a rotation-invariant network shows any inversion effect at all. This is because there is a crucial topological difference between scale and rotation: Rotational invariance is discontinuous, with V1 ranging from 90 degrees (vertically up) to 270 degrees (vertically down). Hence when a face is inverted, the configural information in the face is disrupted while feature information is relatively unaffected. We show that the inversion effect arises as a result of visual expertise, where configural information becomes relevant as more identities are learned at the subordinate level. Our model matches the classic result: faces suffer more from inversion than mono-oriented objects, which are more disrupted than non-mono-oriented objects when objects are only familiar at a basic level."}}
{"id": "xDXzffycmQw", "cdate": 1640995200000, "mdate": 1684102331869, "content": {"title": "Automated Skin Biopsy Analysis with Limited Data", "abstract": "In patients with diabetic and other peripheral neuropathies, the number of nerve fibers that originate in the dermis and cross the dermal-epidermal boundary is an important metric for diagnosis of early small fiber neuropathy and determination of the efficacy of interventions that promote nerve regeneration. To aid in the time-consuming and often variable process of manually counting these measurements, we propose an end-to-end fully automated method to count dermal-epidermal boundary nerve crossings. Working with images of skin biopsies immunostained to identify peripheral nerves using current standard operating procedures, we used image segmentation neural networks to distinguish between the dermis and epidermis and an edge detection neural network to identify nerves. We then applied an unsupervised clustering algorithm to identify nerve crossings, producing an automated count. Since our dataset is very small\u2014containing less than one hundred images\u2014we use pretrained models in combination with several image augmentation methods to improve performance on training and inference. The model learns from a human expert\u2019s training data better than a human trained by the same expert."}}
{"id": "w3HCxyGgf-", "cdate": 1640995200000, "mdate": 1683583756284, "content": {"title": "Debiasing Image-to-Image Translation Models", "abstract": ""}}
{"id": "v7E-HvILWR", "cdate": 1640995200000, "mdate": 1684102331943, "content": {"title": "FIgLib & SmokeyNet: Dataset and Deep Learning Model for Real-Time Wildland Fire Smoke Detection", "abstract": "The size and frequency of wildland fires in the western United States have dramatically increased in recent years. On high-fire-risk days, a small fire ignition can rapidly grow and become out of control. Early detection of fire ignitions from initial smoke can assist the response to such fires before they become difficult to manage. Past deep learning approaches for wildfire smoke detection have suffered from small or unreliable datasets that make it difficult to extrapolate performance to real-world scenarios. In this work, we present the Fire Ignition Library (FIgLib), a publicly available dataset of nearly 25,000 labeled wildfire smoke images as seen from fixed-view cameras deployed in Southern California. We also introduce SmokeyNet, a novel deep learning architecture using spatiotemporal information from camera imagery for real-time wildfire smoke detection. When trained on the FIgLib dataset, SmokeyNet outperforms comparable baselines and rivals human performance. We hope that the availability of the FIgLib dataset and the SmokeyNet architecture will inspire further research into deep learning methods for wildfire smoke detection, leading to automated notification systems that reduce the time to wildfire response."}}
{"id": "j3dyQK21u46", "cdate": 1640995200000, "mdate": 1684102331828, "content": {"title": "Multimodal Wildland Fire Smoke Detection", "abstract": "Research has shown that climate change creates warmer temperatures and drier conditions, leading to longer wildfire seasons and increased wildfire risks in the United States. These factors have in turn led to increases in the frequency, extent, and severity of wildfires in recent years. Given the danger posed by wildland fires to people, property, wildlife, and the environment, there is an urgency to provide tools for effective wildfire management. Early detection of wildfires is essential to minimizing potentially catastrophic destruction. In this paper, we present our work on integrating multiple data sources in SmokeyNet, a deep learning model using spatio-temporal information to detect smoke from wildland fires. Camera image data is integrated with weather sensor measurements and processed by SmokeyNet to create a multimodal wildland fire smoke detection system. We present our results comparing performance in terms of both accuracy and time-to-detection for multimodal data vs. a single data source. With a time-to-detection of only a few minutes, SmokeyNet can serve as an automated early notification system, providing a useful tool in the fight against destructive wildfires."}}
{"id": "2CBLL96U_AG", "cdate": 1640995200000, "mdate": 1667476411546, "content": {"title": "Generating and Controlling Diversity in Image Search", "abstract": "In our society, generations of systemic biases have led to some professions being more common among certain genders and races. This bias is also reflected in image search on stock image repositories and search engines, e.g., a query like \u201cmale Asian administrative assistant\u201d may produce limited results. The pursuit of a utopian world demands providing content users with an opportunity to present any profession with diverse racial and gender characteristics. The limited choice of existing content for certain combinations of profession, race, and gender presents a challenge to content providers. Current research dealing with bias in search mostly focuses on re-ranking algorithms. However, these methods cannot create new content or change the overall distribution of protected attributes in photos. To remedy these problems, we propose a new task of high-fidelity image generation conditioning on multiple attributes from imbalanced datasets. Our proposed task poses new sets of challenges for the state-of-the-art Generative Adversarial Networks (GANs). In this paper, we also propose a new training framework to better address the challenges. We evaluate our framework rigorously on a real-world dataset and perform user studies that show our model is preferable to the alternatives."}}
{"id": "XKelfif46yu", "cdate": 1621435483769, "mdate": null, "content": {"title": "The face inversion effect and the anatomical mapping from the visual field to the primary visual cortex", "abstract": "The face-inversion effect, or the drastic decrease in accuracy\nseen when a participant is asked to identify inverted faces when\ncompared to upright faces, is an effect that is not found in object\ninversion. Here we suggest a new explanation of this effect using\ncomputational models to show that the phenomenon can be\nexplained by the anatomical mapping from the visual field to\nprimary visual cortex. We propose that the way inverted faces are\nmapped onto the cortex is fundamentally different from the way\nupright faces are mapped. Our work first shows the advantages of\nthis mapping due to its scale and rotation invariance when used as\ninput to a convolutional neural network. We train the network to\nperform recognition tasks and show it exhibits scale and\nrealistically constrained rotation invariance. We then confirm that\nthe decline in accuracy seen when a participant is asked to identify\ninverted faces is not seen in the network with inverted object\nrecognition tasks. With the support of these two findings, we test\nthe face-inversion effect on our network and are able to show the\nunique decline in accuracy, suggesting that the way the visual field\nis mapped onto the primary visual cortex is a key facet in the\nmanifestation of this effect."}}
{"id": "V3isJXNLzxB", "cdate": 1621435320372, "mdate": null, "content": {"title": "Do you see what I see? A Cross-cultural Comparison of Social Impressions of Faces.", "abstract": "Research has suggested that social impressions of faces made\nby Western and Eastern people have different underlying dimensionalities. However, the individual level consistency, the\ngroup-level agreement of rater groups, and the interactions\nbetween face ethnicity, rater ethnicity, and social impression\ntraits remain largely unknown. In this paper, we perform a\nlarge-scale data-driven cross-cultural study of facial impressions, and illustrate the idiosyncrasies and similarities behind\nCaucasian and Asian participants in their social impressions of\nfaces from both ethnicity groups. Our study illustrates multiple interesting findings: (1) Asians rate faces lower on most\npositive traits, compared with Caucasian raters, and they have\nmore diverse opinions than Caucasians. (2) Caucasian faces receive higher average ratings on social impression traits related\nto warmth due to the preponderance of smiles in Caucasian\nimages, but similar mean scores on traits related to capability,\ncompared to Asian faces. (3) Caucasians and Asians disagree\nmost on capability related traits, especially on \u201cresponsible\u201d\nand \u201csuccessful.\u201d Opinions on these two traits diverge more\non Asian than on Caucasian faces. Our findings provide new\ninsights on the nuances of cross-cultural differences in social\nimpressions of faces."}}
{"id": "410s3idVu17", "cdate": 1621434914879, "mdate": null, "content": {"title": "ReZero is all you need: Fast convergence at large depth", "abstract": "Deep networks often suffer from vanishing or exploding gradients due to inefficient signal propagation, leading to long training times or convergence difficulties. Various architecture designs, sophisticated residual-style networks, and initialization schemes have been shown to improve deep signal propagation. Recently, Pennington et al. used free probability theory to show that dynamical isometry plays an integral role in efficient deep learning. We show that the simplest architecture change of gating each residual connection using a single zero-initialized parameter satisfies initial dynamical isometry and outperforms more complex approaches. Although much simpler than its predecessors, this gate enables training thousands of fully connected layers with fast convergence and better test performance for ResNets trained on CIFAR-10. We apply this technique to language modeling and find that we can easily train 120-layer Transformers. When applied to 12 layer Transformers, it converges 56% faster on enwiki8."}}
{"id": "BP_W-rVVBmU", "cdate": 1609459200000, "mdate": 1684102331856, "content": {"title": "FIgLib & SmokeyNet: Dataset and Deep Learning Model for Real-Time Wildland Fire Smoke Detection", "abstract": "The size and frequency of wildland fires in the western United States have dramatically increased in recent years. On high-fire-risk days, a small fire ignition can rapidly grow and become out of control. Early detection of fire ignitions from initial smoke can assist the response to such fires before they become difficult to manage. Past deep learning approaches for wildfire smoke detection have suffered from small or unreliable datasets that make it difficult to extrapolate performance to real-world scenarios. In this work, we present the Fire Ignition Library (FIgLib), a publicly available dataset of nearly 25,000 labeled wildfire smoke images as seen from fixed-view cameras deployed in Southern California. We also introduce SmokeyNet, a novel deep learning architecture using spatiotemporal information from camera imagery for real-time wildfire smoke detection. When trained on the FIgLib dataset, SmokeyNet outperforms comparable baselines and rivals human performance. We hope that the availability of the FIgLib dataset and the SmokeyNet architecture will inspire further research into deep learning methods for wildfire smoke detection, leading to automated notification systems that reduce the time to wildfire response."}}
