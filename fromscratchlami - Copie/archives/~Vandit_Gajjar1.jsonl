{"id": "ahU36TWoAzr", "cdate": 1620626692112, "mdate": null, "content": {"title": "PeR-ViS: Person Retrieval in Video Surveillance using Semantic Description", "abstract": "A person is usually characterized by descriptors like age, gender, height, cloth type, pattern, color, etc. Such descriptors are known as attributes and/or soft-biometrics. They link the semantic gap between a person\u2019s description and retrieval in video surveillance. Retrieving a specific person with the query of semantic description has an important application in video surveillance. Using computer vision to fully automate the person retrieval task has been gathering interest within the research community. How\u0002ever, the Current, trend mainly focuses on retrieving per\u0002sons with image-based queries, which have major limitations for practical usage. Instead of using an image query, in this paper, we study the problem of person retrieval in video surveillance with a semantic description. To solve this problem, we develop a deep learning-based cascade filtering approach (PeR-ViS), which uses Mask R\u0002CNN [14] (person detection and instance segmentation) and DenseNet-161 [16] (soft-biometric classification). On the standard person retrieval dataset of SoftBioSearch [6], we achieve 0.566 Average IoU and 0.792 %w IoU > 0.4, surpassing the current state-of-the-art by a large margin. We hope our simple, reproducible, and effective approach\nwill help ease future research in the domain of person retrieval in video surveillance. The source code will be released after the paper is accepted for publication with baseline and pretrained weights. The source code and pre-trained weights available at https://parshwa1999.github.io/PeR-ViS/."}}
{"id": "jpeHIuwSb0", "cdate": 1580561190304, "mdate": null, "content": {"title": "Human Detection for Night Surveillance using Adaptive Background Subtracted Image", "abstract": "Surveillance based on Computer Vision has become a major necessity in current era. Most of the surveillance systems operate on visible light imaging, but performance based on visible light imaging is limited due to some factors like variation in light intensity during the daytime. The matter of concern lies in the need for processing images in low light, such as in the need of nighttime surveillance. In this paper, we have proposed a novel approach for human detection using FLIR (Forward Looking Infrared) camera. As the principle involves sensing based on thermal radiation in the Near IR Region, it is possible to detect Humans from an image captured using a FLIR camera even in low light. The proposed method for human detection involves processing of Thermal images by using HOG (Histogram of Oriented Gradients) feature extraction technique along with some enhancements. The principle of the proposed technique lies in an adaptive background subtraction algorithm, which works in association with the HOG technique. By means of this method, we are able to reduce execution time, precision and some other parameters, which result in improvement of overall accuracy of the human detection system."}}
{"id": "yu0VKGNMcF", "cdate": 1580561137777, "mdate": null, "content": {"title": "Hand Gesture Real Time Paint Tool-Box", "abstract": "With current development universally in computing, now a days user interaction approaches with mouse, keyboard, touch-pens etc. are not sufficient. Directly using of hands or hand gestures as an input device is a method to attract people with providing the applications, through Machine Learning and Computer Vision. Human-computer interaction application in which you can simply draw different shapes, fill the colors, moving the folder from one place to another place and rotating your image with rotating your hand gesture all this will be without touching your device only. In this paper Machine Learning based hand gestures recognition is presented, with the use of Computer Vision different types of gesture applications have been created."}}
{"id": "TDFtl8ZPYT", "cdate": 1580561048948, "mdate": null, "content": {"title": "SAF- BAGE: Salient Approach for Facial Soft-Biometric Classification - Age, Gender, and Facial Expression", "abstract": "How can we improve the facial soft-biometric classification with help of the human visual system? This paper explores the use of saliency which is equivalent to the human visual system to classify Age, Gender and Facial Expression soft-biometric for facial images. Using the Deep Multi-level Network (ML-Net) [1] and off-the-shelf face detector [2], we propose our approach - SAF-BAGE, which first detects the face in the test image, increases the Bounding Box (B-Box) margin by 30%, finds the saliency map using ML-Net, with 30% reweighted ratio of saliency map, it multiplies with the input cropped face and extracts the Convolutional Neural Networks (CNN) predictions on the multiplied reweighted salient face. Our CNN uses the model AlexNet [3], which is pre-trained on ImageNet. The proposed approach surpasses the performance of other approaches, increasing the state-of-the-art by approximately 0.8% on the widely-used Adience [28] dataset for Age and Gender classification and by nearly 3% on the recent AffectNet [36] dataset for Facial Expression classification. We hope our simple, reproducible and effective approach will help ease future research in facial soft-biometric classification using saliency."}}
{"id": "fYvROcN6_s", "cdate": 1580560960653, "mdate": null, "content": {"title": "Person Retrieval in Surveillance Video using Height, Color and Gender", "abstract": "A person is commonly described by attributes like height, build, cloth color, cloth type, and gender. Such attributes are known as soft biometrics. They bridge the semantic gap between human description and person retrieval in surveillance video. The paper proposes a deep learning-based linear filtering approach for person retrieval using height, cloth color, and gender. The proposed approach uses Mask R-CNN for pixel-wise person segmentation. It removes background clutter and provides precise boundary around the person. Color and gender models are fine-tuned using AlexNet and the algorithm is tested on SoftBioSearch dataset. It achieves good accuracy for person retrieval using the semantic query in challenging conditions."}}
{"id": "zCzpVlz9UC", "cdate": 1580560899578, "mdate": null, "content": {"title": "Flower Categorization using Deep Convolutional Neural Networks", "abstract": "We have developed a deep learning network for the classification of different flowers. For this, we have used Visual Geometry Group's 102 category flower dataset having 8189 images of 102 different flowers from the University of Oxford. The method is basically divided into two parts; Image segmentation and classification. We have compared the performance of two different Convolutional Neural Network architectures GoogLeNet and AlexNet for classification purposes. By keeping the hyperparameters the same for both architectures, we have found that the top 1 and top 5 accuracies of GoogLeNet are 47.15% and 69.17% respectively whereas the top 1 and top 5 accuracies of AlexNet are 43.39% and 68.68% respectively. These results are extremely good when compared to a random classification accuracy of 0.98%. This method for classification of flowers can be implemented in real-time applications and can be used to help botanists for their research as well as camping enthusiasts."}}
{"id": "qPfKKsM8tt", "cdate": 1579965798779, "mdate": null, "content": {"title": "Human Detection and Tracking for Video Surveillance A Cognitive Science Approach", "abstract": "With crimes on the rise all around the world, video surveillance is becoming more important day by day. Due to the lack of human resources to monitor this increasing number of cameras manually, new computer vision algorithms to perform lower and higher level tasks are being developed. We have developed a new method incorporating the most acclaimed Histograms of Oriented Gradients, the theory of Visual Saliency and the saliency prediction model Deep Multi-Level Network to detect human beings in video sequences. Furthermore, we implemented the k-Means algorithm to cluster the HOG feature vectors of the positively detected windows and determined the path followed by a person in the video. We achieved a detection precision of 83.11% and a recall of 41.27%. We obtained these results 76.866 times faster than classification on normal images."}}
{"id": "SkNUzyfdbr", "cdate": 1514764800000, "mdate": null, "content": {"title": "ViS-HuD: Using Visual Saliency to Improve Human Detection With Convolutional Neural Networks", "abstract": "The paper presents a technique to improve human detection in still images using deep learning. Our novel method, ViS-HuD, computes visual saliency map from the image. Then the input image is multiplied by the map and product is fed to the Convolutional Neural Network (CNN) which detects humans in the image. A visual saliency map is generated using ML-Net and human detection is carried out using DetectNet. ML-Net is pre-trained on SALICON while, DetectNet is pre-trained on ImageNet database for visual saliency detection and image classification respectively. The CNNs of ViS-HuD were trained on two challenging databases - Penn Fudan and TUD-Brussels Benchmark. Experimental results demonstrate that the proposed method achieves state-of-the-art performance on Penn Fudan Dataset with 91.4% human detection accuracy and it achieves average miss-rate of 53% on the TUD-Brussels benchmark."}}
