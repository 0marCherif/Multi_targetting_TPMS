{"id": "cF05wEwD2Qu", "cdate": 1653595784670, "mdate": null, "content": {"title": "On Combining Global and Localized Self-Supervised Models of Speech", "abstract": "Self supervised learning involves learning general-purpose representations that can be useful in a variety of downstream tasks.\nIn this work, we study the application of speech-embeddings derived from popular self-supervised learning frameworks such as wav2vec-2.0 and HuBERT over four different speech-classification tasks such as sentiment classification, command detection, emotion classification and depression detection. We distinguish between and discuss self-supervised training tasks that induce localized and global features of speech based on their temporal granularity: noting that self-supervised representation learning frameworks based on the masked language-modeling objective -- such as wav2vec-2.0 and HuBERT -- induce localized embeddings, we define a self-supervised learning framework based on SimSiam for learning global features of speech. Through our evaluations, we find that these global representations are better suited for tasks such as depression detection and emotion classification while the localized embeddings of speech can be very useful in tasks such as speech-command detection; we also find that our proposed model outperforms TRILL -- a popular model for learning global representations. Finally, we also propose and confirm empirically that combining the global and localized representations of speech helps obtain better performance across a range of downstream tasks than each of the individual embedding methods. "}}
{"id": "wYF7LPpCcjH", "cdate": 1640995200000, "mdate": 1664891509096, "content": {"title": "Efficient CDF Approximations for Normalizing Flows", "abstract": "Normalizing flows model a complex target distribution in terms of a bijective transform operating on a simple base distribution. As such, they enable tractable computation of a number of important statistical quantities, particularly likelihoods and samples. Despite these appealing properties, the computation of more complex inference tasks, such as the cumulative distribution function (CDF) over a complex region (e.g., a polytope) remains challenging. Traditional CDF approximations using Monte-Carlo techniques are unbiased but have unbounded variance and low sample efficiency. Instead, we build upon the diffeomorphic properties of normalizing flows and leverage the divergence theorem to estimate the CDF over a closed region in target space in terms of the flux across its \\emph{boundary}, as induced by the normalizing flow. We describe both deterministic and stochastic instances of this estimator: while the deterministic variant iteratively improves the estimate by strategically subdividing the boundary, the stochastic variant provides unbiased estimates. Our experiments on popular flow architectures and UCI benchmark datasets show a marked improvement in sample efficiency as compared to traditional estimators."}}
{"id": "SgcQKOcOZ3", "cdate": 1640995200000, "mdate": 1682395554412, "content": {"title": "On Combining Global and Localized Self-Supervised Models of Speech", "abstract": "Self supervised learning involves learning general-purpose representations that can be useful in a variety of downstream tasks. In this work, we study the application of speech-embeddings derived from popular self-supervised learning frameworks such as wav2vec-2.0 and HuBERT over four different speech classification tasks such as sentiment classification, command detection, emotion classification and depression detection. We distinguish between and discuss self-supervised training tasks that induce localized and global features of speech based on their temporal granularity: noting that self-supervised representation learning frameworks based on the masked language modeling objective \u2013 such as wav2vec-2.0 and HuBERT \u2013 induce localized embeddings, we define a self-supervised learning framework based on SimSiam for learning global features of speech. Through our evaluations, we find that these global representations are better suited for tasks such as depression detection and emotion classification while the localized embeddings of speech can be very useful in tasks such as speech-command detection; we also find that our proposed model outperforms TRILL \u2013 a popular model for learning global representations. Finally, we also propose and confirm empirically that combining the global and localized representations of speech helps obtain better performance across a range of downstream tasks than each of the individual embedding methods."}}
{"id": "W4J-JBJp3P1", "cdate": 1609459200000, "mdate": 1682395554418, "content": {"title": "Controlling BigGAN Image Generation with a Segmentation Network", "abstract": "GANS have been used for a variety of unconditional and conditional generation tasks; while class-conditional generation can be directly integrated into the training process, integrating more sophisticated conditioning signals within the training is not as straightforward. In this work, we consider the task of sampling from P(X) such that the silhouette of (the subject of) X matches the silhouette of (the subject of) a given image; that is, we not only specify what to generate, but we also control where to put it: more generally, we allow a mask (this is actually another image) to control the silhouette of the object to be generated. The mask is itself the result of a segmentation system applied to a user-provided image. To achieve this, we use pre-trained BigGAN and State-of-the-art segmentation models (e.g. DeepLabV3 and FCN) as follows: we first sample a random latent vector z from the Gaussian Prior of BigGAN and then iteratively modify the latent vector until the silhouettes of $$X=G(z)$$ and the reference image match. While the BigGAN is a class-conditional generative model trained on the 1000 classes of ImageNet, the segmentation models are trained on the 20 classes of the PASCAL VOC dataset; we choose the \u201cDog\u201d and the \u201cCat\u201d classes to demonstrate our controlled generation model."}}
{"id": "7obPRRhIBZO", "cdate": 1609459200000, "mdate": 1682395554419, "content": {"title": "Musical Speech: A Transformer-based Composition Tool", "abstract": "In this paper, we propose a new compositional tool that will generate a musical outline of speech recorded/provided by the user for use as a musical building block in their compositions. The tool allows any user to use their own speech to generate musical material, while still being able to hear the direct connection between their recorded speech and the resulting music. The tool is built on our proposed pipeline. This pipeline begins with speech-based signal processing, after which some simple musical heuristics are applied, and finally these pre-processed signals are passed through Transformer models trained on new musical tasks. We illustrate the effectiveness of our pipeline -- which does not require a paired dataset for training -- through examples of music created by musicians making use of our tool."}}
{"id": "q8gq95fHes4", "cdate": 1577836800000, "mdate": 1682395554419, "content": {"title": "Active neural learners for text with dual supervision", "abstract": "Dual supervision for text classification and information retrieval, which involves training the machine with class labels augmented with text annotations that are indicative of the class, has been shown to provide significant improvements, both in and beyond active learning (AL) settings. Annotations in the simplest form are highlighted portions of the text that are indicative of the class. In this work, we aim to identify and realize the full potential of unsupervised pretrained word embeddings for text-related tasks in AL settings by training neural nets\u2014specifically, convolutional and recurrent neural nets\u2014through dual supervision. We propose an architecture-independent algorithm for training neural networks with human rationales for class assignments and show how unsupervised embeddings can be better leveraged in active learning settings using the said algorithm. The proposed solution involves the use of gradient-based feature attributions for constraining the machine to follow the user annotations; further, we discuss methods for overcoming the architecture-specific challenges in the optimization. Our results on the sentiment classification task show that one annotated and labeled document can be worth up to seven labeled documents, giving accuracies of up to 70% for as few as ten labeled and annotated documents, and shows promise in significantly reducing user effort for total-recall information retrieval task in systematic literature reviews."}}
{"id": "iOTdx_LDga", "cdate": 1577836800000, "mdate": 1682395554418, "content": {"title": "Detecting Out-of-Distribution Examples with Gram Matrices", "abstract": "When presented with Out-of-Distribution (OOD) examples, deep neural networks yield confident, incorrect predictions; detecting OOD examples is challenging, and the potential risks are high. In this..."}}
{"id": "_6yBwH5PgFz", "cdate": 1577836800000, "mdate": 1682395554420, "content": {"title": "Musical Speech: A Transformer-based Composition Tool", "abstract": "In this paper, we propose a new compositional tool that will generate a musical outline of speech recorded/provided by the user for use as a musical building block in their compositions. The tool a..."}}
{"id": "3izxCjFqSJw", "cdate": 1577836800000, "mdate": 1682395554418, "content": {"title": "On Out-of-Distribution Detection Algorithms with Deep Neural Skin Cancer Classifiers", "abstract": "Computer-aided skin cancer detection systems built with deep neural networks yield overconfident predictions on out-of-distribution examples. Motivated by the importance of out-of-distribution detection in these systems and the lack of relevant benchmarks targeted for skin cancer classification, we introduce a rich collection of out-of-distribution datasets -- designed to comprehensively evaluate state-of-the-art out-of-distribution algorithms with skin cancer classifiers. In addition, we propose an adaptation in the Gram-Matrix algorithm for out-of-distribution detection that generally performs better and faster than the original algorithm for the considered skin cancer classification task. We also include a detailed discussion comparing the various state-of-the-art out-of-distribution detection algorithms and identify avenues for future research."}}
{"id": "r1g6MCEtwr", "cdate": 1569439252819, "mdate": null, "content": {"title": "Zero-Shot Out-of-Distribution Detection with Feature Correlations", "abstract": "When presented with Out-of-Distribution (OOD) examples, deep neural networks yield confident, incorrect predictions. Detecting OOD examples is challenging, and the potential risks are high. In this paper, we propose to detect OOD examples by identifying inconsistencies between activity patterns and class predicted. We find that characterizing activity patterns by feature correlations and identifying anomalies in pairwise feature correlation values can yield high OOD detection rates. We identify anomalies in the pairwise feature correlations by simply comparing each pairwise correlation value with its respective range observed over the training data. Unlike many approaches, this can be used with any pre-trained softmax classifier and does not require access to OOD data for fine-tuning hyperparameters, nor does it require OOD access for inferring parameters. The method is applicable across a variety of architectures and vision datasets and generally performs better than or equal to state-of-the-art OOD detection methods, including those that do assume access to OOD examples."}}
