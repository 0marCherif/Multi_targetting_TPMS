{"id": "17n8l_hV5w4", "cdate": 1683930034818, "mdate": 1683930034818, "content": {"title": "An Accelerated Asynchronous Distributed Method for Convex Constrained Optimization Problems", "abstract": "We consider a class of multi-agent cooperative consensus optimization problems with local nonlinear convex constraints where only those agents connected by an edge can directly communicate, hence, the optimal consensus decision lies in the intersection of these private sets. We develop an asynchronous distributed accelerated primal-dual algorithm to solve \nthe considered problem. The proposed scheme is the first asynchronous method with an optimal convergence guarantee for this class of problems, to the best of our knowledge. In particular, we provide an optimal convergence rate of $\\mathcal{O}(1/K)$ for suboptimality, infeasibility, and consensus violation."}}
{"id": "I4Lpdm_Znex", "cdate": 1683929832600, "mdate": 1683929832600, "content": {"title": "A conditional gradient-based method for simple bilevel optimization with convex lower-level problem", "abstract": "In this paper, we study a class of bilevel optimization problems, also known as simple bilevel optimization, where we minimize a smooth objective function over the optimal solution set of another convex constrained optimization problem. Several iterative methods have been developed for tackling this class of problems. Alas, their convergence guarantees are either asymptotic for the upper-level objective, or the convergence rates are slow and sub-optimal. To address this issue,\nin this paper, we introduce a novel bilevel optimization method that locally approximates the solution set of the lower-level problem via a cutting plane and then runs a conditional gradient update to decrease the upper-level objective.  When the upper-level objective is convex, we show that our method requires ${\\mathcal{O}}(\\max\\{1/\\epsilon_f,1/\\epsilon_g\\})$ iterations to find a solution that is $\\epsilon_f$-optimal for the upper-level objective and  $\\epsilon_g$-optimal for the lower-level objective. Moreover, when the upper-level objective is non-convex, our method requires ${\\mathcal{O}}(\\max\\{1/\\epsilon_f^2,1/(\\epsilon_f\\epsilon_g)\\})$ iterations to find an $(\\epsilon_f,\\epsilon_g)$-optimal solution. We also prove stronger convergence guarantees under the H\\\"olderian error bound assumption on the lower-level problem.\nTo the best of our knowledge, our method achieves the best-known iteration complexity for the considered class of bilevel problems"}}
{"id": "2lKGRn-gi5", "cdate": 1664731449231, "mdate": null, "content": {"title": "Conditional gradient-based method for bilevel optimization with convex lower-level problem", "abstract": "In this paper, we study simple bilevel optimization problems, where we minimize a smooth objective function over the optimal solution set of another convex constrained optimization problem. Several iterative methods have been developed for tackling this class of problems. Alas, their convergence guarantees are not satisfactory as they are either asymptotic for the upper-level objective, or the convergence rates  are slow and sub-optimal. To address this issue, in this paper, we introduce a conditional gradient-based (CG-based) method to solve the considered problem. The main idea is to locally approximate the solution set of the lower-level problem via a cutting plane, and then run a CG-type update to decrease the upper-level objective. When the upper-level objective is convex, we show that our method requires ${\\mathcal{O}}(\\max\\{1/\\epsilon_f,1/\\epsilon_g\\})$ iterations to find a solution that is $\\epsilon_f$-optimal for the upper-level objective and  $\\epsilon_g$-optimal for the lower-level objective. Moreover, when the upper-level objective is non-convex, our method requires ${\\mathcal{O}}(\\max\\{1/\\epsilon_f^2,1/(\\epsilon_f\\epsilon_g)\\})$ iterations to find an $(\\epsilon_f,\\epsilon_g)$-optimal solution. To the best of our knowledge, our method achieves the best-known iteration complexity for the considered bilevel problem. "}}
{"id": "r1E5Jd-_-B", "cdate": 1451606400000, "mdate": null, "content": {"title": "A primal-dual method for conic constrained distributed optimization problems", "abstract": "We consider cooperative multi-agent consensus optimization problems over an undirected network of agents, where only those agents connected by an edge can directly communicate. The objective is to minimize the sum of agent-specific composite convex functions over agent-specific private conic constraint sets; hence, the optimal consensus decision should lie in the intersection of these private sets. We provide convergence rates in sub-optimality, infeasibility and consensus violation; examine the effect of underlying network topology on the convergence rates of the proposed decentralized algorithms; and show how to extend these methods to handle time-varying communication networks."}}
