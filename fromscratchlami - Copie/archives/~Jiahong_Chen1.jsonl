{"id": "gnfIbpA5KE", "cdate": 1694027545311, "mdate": 1694027545311, "content": {"title": "Training Feedforward Neural Nets in Hopfield-Energy-Based Configuration: A Two-Step Approach", "abstract": "We introduce Hopfield-Energy-Based Learning, a general learning framework that is inspired by energy-based models, to train feedforward neural nets. Our approach includes two training phases applied iteratively: first, the minimization of the internal energy, that captures dependencies between input samples and network parameters, is carried out in an unsupervised manner; second, the problem-dependent supervised external energy (e.g., cross-entropy loss) combined with partially reversed internal energy gradients are back-propagated in a standard manner. The intuition is that the first stage helps parameters to settle into the state that simply partitions data into clusters; while in the second stage, the network is allowed to deviate from that clustering a bit (hence gradient reversal) in order to converge to parameters that ultimately perform well on the task at hand. Notably, the data used for the two steps might not be one and the same (e.g., can come from different domains) and the approach naturally tailors itself to solve unsupervised domain adaptation problems without adopting any distribution alignment techniques. We also show that the proposed training strategy substantially improves the performance of several ConvNets on standard supervised classification tasks; showing improvements of at least 1.2% (2.64% on CIFAR-10, 4.5% on CIFAR-100, and 1.35% on ImageNet). Our formulation is general, performs well in practice, and holds promise for scenarios where labeled data is limited."}}
{"id": "lJhpOBgRWD", "cdate": 1682899200000, "mdate": 1681693340052, "content": {"title": "Ensemble diverse hypotheses and knowledge distillation for unsupervised cross-subject adaptation", "abstract": ""}}
{"id": "psNHHIc8Ei", "cdate": 1680047954578, "mdate": 1680047954578, "content": {"title": "Ensemble diverse hypotheses and knowledge distillation for unsupervised cross-subject adaptation", "abstract": "Recognizing human locomotion intent and activities is important for controlling wearable robots while walking in complex environments. However, human-robot interface signals are usually user-dependent, which causes the classifier trained on source subjects to perform poorly on new subjects. To address this issue, this paper designs the ensemble diverse hypotheses and knowledge distillation (EDHKD) method to realize unsupervised cross-subject adaptation. EDH mitigates the divergence between labeled data of source subjects and unlabeled data of target subjects to accurately classify the locomotion modes of target subjects without labeling data. Compared to previous domain adaptation methods based on the single learner, which may only learn a subset of features from input signals, EDH can learn diverse features by incorporating multiple diverse feature generators and thus increases the accuracy and decreases the variance of classifying target data, but it sacrifices the efficiency. To solve this problem, EDHKD (student) distills the knowledge from the EDH (teacher) to a single network to re- main efficient and accurate. The performance of the EDHKD is theoretically proved and experimentally validated on a 2D moon dataset and two public human locomotion datasets. Experimental results show that the EDHKD outperforms all other methods. The EDHKD can classify target data with 96.9%, 94.4%, and 97.4% average accuracy on the above three datasets with a short computing time (1 ms). Compared to a benchmark (BM) method, the EDHKD increases by 1.3% and 7.1% average accuracy for classifying the locomotion modes of target subjects. The EDHKD also stabilizes the learning curves. Therefore, the EDHKD is significant for increasing the generalization ability and efficiency of the human intent prediction and human activity recognition system, which will improve human-robot interactions."}}
{"id": "rnMlcS8EG79", "cdate": 1648670274453, "mdate": 1648670274453, "content": {"title": "Unsupervised cross-domain fault diagnosis using feature representation alignment networks for rotating machinery", "abstract": "In this article, the problem of the cross-domain fault diagnosis of rotating machinery is considered. In a practical setting of this approach, the operating platform of the machine may have a different setup and conditions compared to the experimental platform that is used to collect the training data. This can lead to significant data variations, specifically domain shifts. Conventional data-driven approaches are known to adapt poorly to these domain shifts, resulting in a significant drop in the diagnosis accuracy when the pretrained model is applied in the actual operating situation. In this article, an unsupervised domain adaptation approach is developed to mitigate the domain shifts between the data gathered from the experimental platform (the source domain) and the operating platform (the target domain) by aligning the features extracted from the two data domains. The mutual information between the target feature space and the entire feature space is maximized to improve the knowledge transferability of the labeled data in the source domain. Furthermore, the feature-level discrepancy between the two domains is minimized to further improve diagnosis accuracy. The experiments using public datasets and real-world adaptation scenarios demonstrate the feasibility and the superior performance of the proposed method."}}
{"id": "BhNxowN4f7c", "cdate": 1648669794912, "mdate": 1648669794912, "content": {"title": "WSN optimization for sampling-based signal estimation using semi-binarized variational autoencoder", "abstract": "This study focuses on optimizing the sampling strategies for WSNs to estimate spatiotemporal signals. Existing deep-learning-based approaches for signal estimation tend to collect samples from pre-determined sensing locations, due to which the performance of signal estimation relies heavily on selected handcrafted features. Instead of fixing sensing locations, we propose a semi-binarized variational autoencoder to simultaneously optimize the sampling strategy and evaluate the signal estimated from the sampled sensing locations. The proposed framework is composed of a backpropagatable binarized encoding layer to optimize sensing locations and a generative model to estimate the complete signal from these sparse samples. Moreover, a feature-level discrepancy was proposed to further optimize the sampling locations with respect to the estimation error. The experiments were conducted using four publicly available datasets with three evaluation metrics (mean square error, standard deviation, and peak signal-to-noise ratio). The 10-fold cross-validation and two-sample t-test were utilized to analyze the experimental results, which demonstrate the significant improvement achieved by the proposed method."}}
{"id": "B6MgReN4fmc", "cdate": 1648669686035, "mdate": 1648669686035, "content": {"title": "Gaussian-guided feature alignment for unsupervised cross-subject adaptation", "abstract": "Human activities recognition (HAR) and human intent recognition (HIR) are important for medical diagnosis and human-robot interaction. HAR and HIR usually rely on the signals of some wearable sensors, such as inertial measurement unit (IMU), but these signals may be user-dependent, which degrades the performance of the recognition algorithm on new subjects. Traditional supervised learning methods require labeling signals and training specific classifiers for each new subject, which is burdensome. To deal with this problem, this paper proposes a novel non-adversarial cross-subject adaptation method called Gaussian-guided feature alignment (GFA). The proposed GFA metric quantifies the discrepancy between the labeled features of source subjects and the unlabeled features of target subjects so that minimizing the GFA metric leads to the alignment of the source and target features. The GFA metric is estimated by calculating the divergence between the feature distribution and Gaussian distribution, as well as the mean squared error of the mean and variance between source and target features. This paper analytically proves the effect of the GFA metric and validates its performance using three public human activity datasets. Experimental results show that the proposed GFA achieves 1% higher target classification accuracy and 0.5% lower variance than state-of-the-art methods in case of cross-subject validation. These results indicate that the proposed GFA is feasible for improving the generalization of the HAR and HIR."}}
{"id": "SAMx1wmVGQ5", "cdate": 1648669527277, "mdate": 1648669527277, "content": {"title": "Mutual Variational Inference: An Indirect Variational Inference Approach for Unsupervised Domain Adaptation", "abstract": "In this article, the unsupervised domain adaptation problem, where an approximate inference model is to be learned from a labeled dataset and expected to generalize well on an unlabeled dataset, is considered. Unlike the existing work, we explicitly unveil the importance of the latent variables produced by the feature extractor, that is, encoder, where contains the most representative information about their input samples, for the knowledge transfer. We argue that an estimator of the representation of the two datasets can be used as an agent for knowledge transfer. To be specific, a novel variational inference approach is proposed to approximate a latent distribution from the unlabeled dataset that can be used to accurately predict its input samples. It is demonstrated that the discriminative knowledge of the latent distribution that is learned from the labeled dataset can be progressively transferred to that is learned from the unlabeled dataset by simultaneously optimizing the estimator via the variational inference and our proposed regularization for shifting the mean of the estimator. The experiments on several benchmark datasets demonstrate that the proposed method consistently outperforms state-of-the-art methods for both object classification and digit classification."}}
{"id": "BcUBDxmEG75", "cdate": 1648669423507, "mdate": 1648669423507, "content": {"title": "Discriminative feature alignment: Improving transferability of unsupervised domain adaptation by Gaussian-guided latent alignment", "abstract": "In this paper, we focus on the unsupervised domain adaptation problem where an approximate inference model is to be learned from a labeled data domain and expected to generalize well to an unlabeled domain. The success of unsupervised domain adaptation largely relies on the cross-domain feature alignment. Previous work has attempted to directly align features by classifier-induced discrepancies. Nevertheless, a common feature space cannot always be learned via this direct feature alignment especially when large domain gaps exist. To solve this problem, we introduce a Gaussian-guided latent alignment approach to align the latent feature distributions of the two domains under the guidance of a prior. In such an indirect way, the distributions over the samples from the two domains will be constructed on a common feature space, i.e., the space of the prior, which promotes better feature alignment. To effectively align the target latent distribution with this prior distribution, we also propose a novel unpaired L1-distance by taking advantage of the formulation of the encoder-decoder. The extensive evaluations on nine benchmark datasets validate the superior knowledge transferability through outperforming state-of-the-art methods and the versatility of the proposed method by improving the existing work significantly."}}
{"id": "ojuY7U4vQ3I", "cdate": 1640995200000, "mdate": 1681693340054, "content": {"title": "Ensemble diverse hypotheses and knowledge distillation for unsupervised cross-subject adaptation", "abstract": "Recognizing human locomotion intent and activities is important for controlling the wearable robots while walking in complex environments. However, human-robot interface signals are usually user-dependent, which causes that the classifier trained on source subjects performs poorly on new subjects. To address this issue, this paper designs the ensemble diverse hypotheses and knowledge distillation (EDHKD) method to realize unsupervised cross-subject adaptation. EDH mitigates the divergence between labeled data of source subjects and unlabeled data of target subjects to accurately classify the locomotion modes of target subjects without labeling data. Compared to previous domain adaptation methods based on the single learner, which may only learn a subset of features from input signals, EDH can learn diverse features by incorporating multiple diverse feature generators and thus increases the accuracy and decreases the variance of classifying target data, but it sacrifices the efficiency. To solve this problem, EDHKD (student) distills the knowledge from the EDH (teacher) to a single network to remain efficient and accurate. The performance of the EDHKD is theoretically proved and experimentally validated on a 2D moon dataset and two public human locomotion datasets. Experimental results show that the EDHKD outperforms all other methods. The EDHKD can classify target data with 96.9%, 94.4%, and 97.4% average accuracy on the above three datasets with a short computing time (1 ms). Compared to a benchmark (BM) method, the EDHKD increases 1.3% and 7.1% average accuracy for classifying the locomotion modes of target subjects. The EDHKD also stabilizes the learning curves. Therefore, the EDHKD is significant for increasing the generalization ability and efficiency of the human intent prediction and human activity recognition system, which will improve human-robot interactions."}}
{"id": "acYpVTuwi2L", "cdate": 1640995200000, "mdate": 1682317858987, "content": {"title": "Mutual Variational Inference: An Indirect Variational Inference Approach for Unsupervised Domain Adaptation", "abstract": "In this article, the unsupervised domain adaptation problem, where an approximate inference model is to be learned from a labeled dataset and expected to generalize well on an unlabeled dataset, is considered. Unlike the existing work, we explicitly unveil the importance of the latent variables produced by the feature extractor, that is, encoder, where contains the most representative information about their input samples, for the knowledge transfer. We argue that an estimator of the representation of the two datasets can be used as an agent for knowledge transfer. To be specific, a novel variational inference approach is proposed to approximate a latent distribution from the unlabeled dataset that can be used to accurately predict its input samples. It is demonstrated that the discriminative knowledge of the latent distribution that is learned from the labeled dataset can be progressively transferred to that is learned from the unlabeled dataset by simultaneously optimizing the estimator via the variational inference and our proposed regularization for shifting the mean of the estimator. The experiments on several benchmark datasets demonstrate that the proposed method consistently outperforms state-of-the-art methods for both object classification and digit classification."}}
