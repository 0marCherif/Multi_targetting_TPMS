{"id": "NxWUnvwFV4", "cdate": 1629469414330, "mdate": null, "content": {"title": "Graph Robustness Benchmark: Benchmarking the Adversarial Robustness of Graph Machine Learning", "abstract": "Adversarial attacks on graphs have posed a major threat to the robustness of graph machine learning (GML) models. Naturally, there is an ever-escalating arms race between attackers and defenders. However, the strategies behind both sides are often not fairly compared under the same and realistic conditions. To bridge this gap, we present the Graph Robustness Benchmark (GRB) with the goal of providing a scalable, unified, modular, and reproducible evaluation for the adversarial robustness of GML models. GRB standardizes the process of attacks and defenses by 1) developing scalable and diverse datasets, 2) modularizing the attack and defense implementations, and 3) unifying the evaluation protocol in refined scenarios. By leveraging the modular GRB pipeline,  the end-users can focus on the development of robust GML models with automated data processing and experimental evaluations. To support open and reproducible research on graph adversarial learning, GRB also hosts public leaderboards for different scenarios. \nAs a starting point, we provide various baseline experiments to benchmark the state-of-the-art techniques. GRB is an open-source benchmark and all datasets, code, and leaderboards are available at https://cogdl.ai/grb/home. "}}
{"id": "pBwQ82pYha", "cdate": 1623127611009, "mdate": null, "content": {"title": "Graph Robustness Benchmark: Rethinking and Benchmarking Adversarial Robustness of Graph Neural Networks", "abstract": "Recent studies have shown that Graph Neural Networks (GNNs) are vulnerable to adversarial attacks. Previous attacks and defenses on GNNs face common problems like scalability or generality, which hinder the progress of this domain. By rethinking limitations in previous works, we propose Graph Robustness Benchmark (GRB), the first benchmark that aims to provide scalable, general, unified, and reproducible evaluation on adversarial robustness of GNNs. GRB includes (1) scalable datasets processed by a novel splitting scheme; (2) diverse set of baseline methods covering GNNs, attacks, and defenses; (3) unified evaluation pipeline that permits a fair comparison; (4) modular coding framework that facilitates implementation of various methods and ensures reproducibility; (5) leaderboards that track the progress of the field. Besides, we propose two strong baseline defenses that significantly outperform previous ones. With extensive experiments, we can fairly compare all methods and investigate their pros and cons. GRB is open-source and maintains all datasets, codes, leaderboards at https://cogdl.ai/grb/home, which will be continuously updated to promote future research in this field."}}
{"id": "cnWSyJNmeCE", "cdate": 1621629847846, "mdate": null, "content": {"title": "CogView: Mastering Text-to-Image Generation via Transformers", "abstract": "Text-to-Image generation in the general domain has long been an open problem, which requires both a powerful generative model and cross-modal understanding. We propose CogView, a 4-billion-parameter Transformer with VQ-VAE tokenizer to advance this problem. We also demonstrate the finetuning strategies for various downstream tasks, e.g. style learning, super-resolution, text-image ranking and fashion design, and methods to stabilize pretraining, e.g. eliminating NaN losses. CogView achieves the state-of-the-art FID on the blurred MS COCO dataset, outperforming previous GAN-based models and a recent similar work DALL-E.\n"}}
{"id": "SJeLO34KwS", "cdate": 1569438830406, "mdate": null, "content": {"title": "Dimensional Reweighting Graph Convolution Networks", "abstract": "In this paper, we propose a method named Dimensional reweighting Graph Convolutional Networks (DrGCNs), to tackle the problem of variance between dimensional information in the node representations of GCNs. We prove that DrGCNs can reduce the variance of the node representations by connecting our problem to the theory of the mean field. However, practically, we find that the degrees DrGCNs help vary severely on different datasets. We revisit the problem and develop a new measure K to quantify the effect. This measure guides when we should use dimensional reweighting in GCNs and how much it can help. Moreover, it offers insights to explain the improvement obtained by the proposed DrGCNs. The dimensional reweighting block is light-weighted and highly flexible to be built on most of the GCN variants. Carefully designed experiments, including several fixes on duplicates, information leaks, and wrong labels of the well-known node classification benchmark datasets, demonstrate the superior performances of DrGCNs over the existing state-of-the-art approaches. Significant improvements can also be observed on a large scale industrial dataset."}}
