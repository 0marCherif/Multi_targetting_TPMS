{"id": "zFJZXaDzdd", "cdate": 1640995200000, "mdate": 1681662163777, "content": {"title": "Impact of Parameter Sparsity on Stochastic Gradient MCMC Methods for Bayesian Deep Learning", "abstract": "Bayesian methods hold significant promise for improving the uncertainty quantification ability and robustness of deep neural network models. Recent research has seen the investigation of a number of approximate Bayesian inference methods for deep neural networks, building on both the variational Bayesian and Markov chain Monte Carlo (MCMC) frameworks. A fundamental issue with MCMC methods is that the improvements they enable are obtained at the expense of increased computation time and model storage costs. In this paper, we investigate the potential of sparse network structures to flexibly trade-off model storage costs and inference run time against predictive performance and uncertainty quantification ability. We use stochastic gradient MCMC methods as the core Bayesian inference method and consider a variety of approaches for selecting sparse network structures. Surprisingly, our results show that certain classes of randomly selected substructures can perform as well as substructures derived from state-of-the-art iterative pruning methods while drastically reducing model training times."}}
{"id": "SUntWoooc6", "cdate": 1640995200000, "mdate": 1681662163717, "content": {"title": "Uncertainty Quantification Using Query-Based Object Detectors", "abstract": "Recently, a new paradigm of query-based object detection has gained popularity. In this paper, we study the problem of quantifying the uncertainty in the predictions of these models that derive from model uncertainty. Such uncertainty quantification is vital for many high-stakes applications that need to avoid making overconfident errors. We focus on quantifying multiple aspects of detection uncertainty based on a deep ensembles representation. We perform extensive experiments on two representative models in this space: DETR and AdaMixer. We show that deep ensembles of these query-based detectors result in improved performance with respect to three types of uncertainty: location uncertainty, class uncertainty, and objectness uncertainty (Code available at: https://github.com/colinski/uq-query-object-detectors )."}}
{"id": "--ydeqEHGl", "cdate": 1640995200000, "mdate": 1681662163711, "content": {"title": "URSABench: A System for Comprehensive Benchmarking of Bayesian Deep Neural Network Models and Inference methods", "abstract": ""}}
{"id": "o3zg4BzH1sd", "cdate": 1609459200000, "mdate": 1640120964764, "content": {"title": "Post-hoc loss-calibration for Bayesian neural networks", "abstract": "Bayesian decision theory provides an elegant framework for acting optimally under uncertainty when tractable posterior distributions are available. Modern Bayesian models, however, typically involve intractable posteriors that are approximated with, potentially crude, surrogates. This difficulty has engendered loss-calibrated techniques that aim to learn posterior approximations that favor high-utility decisions. In this paper, focusing on Bayesian neural networks, we develop methods for correcting approximate posterior predictive distributions encouraging them to prefer high-utility decisions. In contrast to previous work, our approach is agnostic to the choice of the approximate inference algorithm, allows for efficient test time decision making through amortization, and empirically produces higher quality decisions. We demonstrate the effectiveness of our approach through controlled experiments spanning a diversity of tasks and datasets."}}
{"id": "cPCksd2MOdO", "cdate": 1609459200000, "mdate": 1640120964746, "content": {"title": "Challenges and Opportunities in Approximate Bayesian Deep Learning for Intelligent IoT Systems", "abstract": "Approximate Bayesian deep learning methods hold significant promise for addressing several issues that occur when deploying deep learning components in intelligent systems, including mitigating the occurrence of over-confident errors and providing enhanced robustness to out of distribution examples. However, the computational requirements of existing approximate Bayesian inference methods can make them ill-suited for deployment in intelligent IoT systems that include lower-powered edge devices. In this paper, we present a range of approximate Bayesian inference methods for supervised deep learning and highlight the challenges and opportunities when applying these methods on current edge hardware. We highlight several potential solutions to decreasing model storage requirements and improving computational scalability, including model pruning and distillation methods."}}
{"id": "GdwCFdU6_Kx", "cdate": 1609459200000, "mdate": 1640120964763, "content": {"title": "Post-hoc loss-calibration for Bayesian neural networks", "abstract": "Bayesian decision theory provides an elegant framework for acting optimally under uncertainty when tractable posterior distributions are available. Modern Bayesian models, however, typically involv..."}}
{"id": "5FA9f99V1iS", "cdate": 1609459200000, "mdate": 1681662163716, "content": {"title": "Challenges and Opportunities in Approximate Bayesian Deep Learning for Intelligent IoT Systems", "abstract": "Approximate Bayesian deep learning methods hold significant promise for addressing several issues that occur when deploying deep learning components in intelligent systems, including mitigating the occurrence of over-confident errors and providing enhanced robustness to out of distribution examples. However, the computational requirements of existing approxi-mate Bayesian inference methods can make them ill-suited for deployment in intelligent IoT systems that include lower-powered edge devices. In this paper, we present a range of approximate Bayesian inference methods for supervised deep learning and highlight the challenges and opportunities when applying these methods on current edge hardware. We highlight several potential solutions to decreasing model storage requirements and improving computational scalability, including model pruning and distillation methods."}}
{"id": "r1xtIVCDXHb", "cdate": 1577836800000, "mdate": null, "content": {"title": "Assessing the Adversarial Robustness of Monte Carlo and Distillation Methods for Deep Bayesian Neural Network Classification", "abstract": "In this paper, we consider the problem of assessing the adversarial robustness of deep neural network models under both Markov chain Monte Carlo (MCMC) and Bayesian Dark Knowledge (BDK) inference approximations. We characterize the robustness of each method to two types of adversarial attacks: the fast gradient sign method (FGSM) and projected gradient descent (PGD). We show that full MCMC-based inference has excellent robustness, significantly outperforming standard point estimation-based learning. On the other hand, BDK provides marginal improvements. As an additional contribution, we present a storage-efficient approach to computing adversarial examples for large Monte Carlo ensembles using both the FGSM and PGD attacks."}}
{"id": "gxnPvKVqkFx", "cdate": 1577836800000, "mdate": null, "content": {"title": "On Uncertainty and Robustness in Large-Scale Intelligent Data Fusion Systems", "abstract": "The resurgence of AI in the recent decade dramatically changes the design of modern sensor data fusion systems, leading to new challenges, opportunities, and research directions. One of these challenges is the management of uncertainty. This paper develops a framework to reason about sources of uncertainty, develops representations of uncertainty, and investigates uncertainty mitigation strategies in modern intelligent data processing systems. Insights are developed into workflow composition that maximizes efficacy at accomplishing mission goals despite the sources of uncertainty, while leveraging a collaboration of humans, algorithms, and machine learning components."}}
{"id": "MY8JJU8eFg0", "cdate": 1577836800000, "mdate": 1640120964741, "content": {"title": "Generalized Bayesian Posterior Expectation Distillation for Deep Neural Networks", "abstract": "In this paper, we present a general framework for distilling expectations with respect to the Bayesian posterior distribution of a deep neural network classifier, extending prior work on the Bayesi..."}}
