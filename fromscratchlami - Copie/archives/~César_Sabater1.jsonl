{"id": "dKJBCMamTbj", "cdate": 1680307200000, "mdate": 1693157110295, "content": {"title": "Private Sampling with Identifiable Cheaters", "abstract": ""}}
{"id": "y-Hnf1ae9XQ", "cdate": 1640995200000, "mdate": 1681484529586, "content": {"title": "An accurate, scalable and verifiable protocol for federated differentially private averaging", "abstract": ""}}
{"id": "rqk8TSU6aG5", "cdate": 1640995200000, "mdate": 1681484529566, "content": {"title": "Efficient and Robust Protocols for Privacy-Preserving Semi-Decentralized Machine Learning. (Protocoles Efficaces et Robustes pour l'Apprentissage Automatique Semi-D\u00e9centralis\u00e9 Pr\u00e9servant la Confidentialit\u00e9)", "abstract": ""}}
{"id": "YS47RZFtKm", "cdate": 1631722296596, "mdate": null, "content": {"title": "Zero Knowledge Arguments for Verifiable Sampling", "abstract": "In privacy-preserving machine learning, it is less obvious to verify correct behavior of participants because they are not supposed to reveal their inputs in cleartext to other participants. It is hence important to make federated machine learning robust against data poisoning and related attacks.  While input data can be related to a distributed ledger (blockchain), a less studied input is formed by the random sampling parties perform. In this paper, we describe strategies based on zero knowledge proofs to allow parties to prove they perform sampling (and other computations) correctly.  We sketch a number of alternative ways to implement our idea and provide some preliminary experimental results."}}
{"id": "UErJ348uyNp_", "cdate": 1577836800000, "mdate": null, "content": {"title": "Distributed Differentially Private Averaging with Improved Utility and Robustness to Malicious Parties", "abstract": "Learning from data owned by several parties, as in federated learning, raises challenges regarding the privacy guarantees provided to participants and the correctness of the computation in the presence of malicious parties. We tackle these challenges in the context of distributed averaging, an essential building block of federated learning algorithms. Our first contribution is a scalable protocol in which participants exchange correlated Gaussian noise along the edges of a network graph, complemented by independent noise added by each party. We analyze the differential privacy guarantees of our protocol and the impact of the graph topology under colluding malicious parties, showing that we can nearly match the utility of the trusted curator model even when each honest party communicates with only a logarithmic number of other parties chosen at random. This is in contrast with protocols in the local model of privacy (with lower utility) or based on secure aggregation (where all pairs of users need to exchange messages). Our second contribution enables users to prove the correctness of their computations without compromising the efficiency and privacy guarantees of the protocol. Our verification protocol relies on standard cryptographic primitives like commitment schemes and zero knowledge proofs."}}
