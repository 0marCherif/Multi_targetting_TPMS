{"id": "LwL7zze2rle", "cdate": 1685532020774, "mdate": null, "content": {"title": "Coherent Soft Imitation Learning", "abstract": "Imitation learning methods seek to learn from an expert either through behavioral cloning (BC) of the policy or inverse reinforcement learning (IRL) of the reward.\nSuch methods enable agents to learn complex tasks from humans that are difficult to capture with hand-designed reward functions. \nChoosing BC or IRL for imitation depends on the quality and state-action coverage of the demonstrations, as well as additional access to the Markov decision process. \nHybrid strategies that combine BC and IRL are not common, as initial policy optimization against inaccurate rewards diminishes the benefit of pretraining the policy with BC.\nThis work derives an imitation method that captures the strengths of both BC and IRL.\nIn the entropy-regularized (`soft') reinforcement learning setting, we show that the behaviour-cloned policy can be used as both a shaped reward and a critic hypothesis space by inverting the regularized policy update. \nThis coherency facilities fine-tuning cloned policies using the reward estimate and additional interactions with the environment.\nThis approach conveniently achieves imitation learning through initial behaviour cloning, followed by refinement via RL with online or offline data sources.\nThe simplicity of the approach enables graceful scaling to high-dimensional and vision-based tasks, with stable learning and minimal hyperparameter tuning, in contrast to adversarial approaches."}}
{"id": "hQtq698TTWx", "cdate": 1683882158933, "mdate": 1683882158933, "content": {"title": "Neural Linear Models with Functional Gaussian Process Priors", "abstract": "Neural linear models (NLM) and Gaussian processes (GP) are both examples of Bayesian linear regression on rich feature spaces. In contrast to the widespread use of nonparametric GPs for probabilistic nonlinear regression, NLMs remain an underused parametric alternative because standard type II maximum likelihood (ML) training leads to overconfidence outside of the data distribution. Therefore, we propose to augment this training procedure through functional variational inference (fVI) proposed by Sun et. al. (2019), which is particularly well suited for NLMs due to their closed-form predictive distribution. Additionally, we investigate whether an appropriate functional prior can guide parametric NLMs to attain nonparametric GP performance, despite using fewer parameters. Results show that functional priors do improve performance of NLM over ML training, and that the NLM performs on par with weight space BNNs in this setting.\n"}}
{"id": "w6itykwbOJ_", "cdate": 1681833043817, "mdate": null, "content": {"title": "Function-Space Regularization for Deep Bayesian Classification", "abstract": "Bayesian deep learning approaches assume model parameters to be latent random variables and infer posterior distributions to quantify uncertainty, increase safety and trust, and prevent overconfident and unpredictable behavior. However, weight-space priors are model- specific, can be difficult to interpret and are hard to specify. Instead, we apply a Dirichlet prior in predictive space and perform approximate function-space variational inference. To this end, we interpret conventional categorical predictions from stochastic neural network classifiers as samples from an implicit Dirichlet distribution. By adapting the inference, the same function-space prior can be combined with different models without affecting model architecture or size. We illustrate the flexibility and efficacy of such a prior with toy experiments and demonstrate scalability, improved uncertainty quantification and adversarial robustness with large-scale image classification experiments.\n"}}
{"id": "HbGgF93Ppoy", "cdate": 1655376324789, "mdate": null, "content": {"title": "Inferring Smooth Control: Monte Carlo Posterior Policy Iteration with Gaussian Processes", "abstract": "Monte Carlo methods have become increasingly relevant for control of non-differentiable systems, approximate dynamics models, and learning from data.\nThese methods scale to high-dimensional spaces and are effective at the non-convex optimization often seen in robot learning. We look at sample-based methods from the perspective of inference-based control, specifically posterior policy iteration.\nFrom this perspective, we highlight how Gaussian noise priors produce rough control actions that are unsuitable for physical robot deployment.\nConsidering smoother Gaussian process priors, as used in episodic reinforcement learning and motion planning, we demonstrate how smoother model predictive control can be achieved using online sequential inference.\nThis inference is realized through an efficient factorization of the action distribution, and novel means of optimizing the likelihood temperature for to improve importance sampling accuracy.\nWe evaluate this approach on several high-dimensional robot control tasks, matching the sample efficiency of prior heuristic methods while also ensuring smoothness.\nSimulation results can be seen at monte-carlo-ppi.github.io."}}
{"id": "SqWjORXre5", "cdate": 1640995200000, "mdate": 1645719154526, "content": {"title": "Benchmarking Structured Policies and Policy Optimization for Real-World Dexterous Object Manipulation", "abstract": "Dexterous manipulation is a challenging and important problem in robotics. While data-driven methods are a promising approach, current benchmarks require simulation or extensive engineering support due to the sample inefficiency of popular methods. We present benchmarks for the TriFinger system, an open-source robotic platform for dexterous manipulation and the focus of the 2020 Real Robot Challenge. The benchmarked methods, which were successful in the challenge, can be generally described as <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">structured policies</i> , as they combine elements of classical robotics and modern policy optimization. This inclusion of inductive biases facilitates sample efficiency, interpretability, reliability and high performance. The key aspects of this benchmarking is validation of the baselines across both simulation and the real system, thorough ablation study over the core features of each solution, and a retrospective analysis of the challenge as a manipulation benchmark."}}
{"id": "0cU9FZT_h54", "cdate": 1640995200000, "mdate": 1682852831286, "content": {"title": "Inferring Smooth Control: Monte Carlo Posterior Policy Iteration with Gaussian Processes", "abstract": "Monte Carlo methods have become increasingly relevant for control of non-differentiable systems, approximate dynamics models, and learning from data.These methods scale to high-dimensional spaces a..."}}
{"id": "5o7lEUYRvM", "cdate": 1632875625887, "mdate": null, "content": {"title": "Function-Space Variational Inference for Deep Bayesian Classification", "abstract": "Bayesian deep learning approaches assume model parameters to be latent random variables and infer posterior predictive distributions to quantify uncertainty, increase safety and trust, and prevent overconfident and unpredictable behavior. However, weight-space priors are model-specific, can be difficult to interpret and hard to choose. Instead of weight-space priors, we leverage function-space variational inference to apply a Dirichlet predictive prior in function space, resulting in a variational Dirichlet posterior which facilitates easier specification of epistemic uncertainty.  This is achieved through the perspective of stochastic neural network classifiers as variational implicit processes, which can be trained using function-space variational inference by devising a novel Dirichlet KL estimator. Experiments on small- and large-scale image classification tasks demonstrate that our function-space inference scales to large-scale tasks and models, improves adversarial robustness and boosts uncertainty quantification across models, without influencing the in-distribution performances, architecture or model size."}}
{"id": "g7XqhGwoUn0", "cdate": 1609459200000, "mdate": 1624045261850, "content": {"title": "Advancing Trajectory Optimization with Approximate Inference: Exploration, Covariance Control and Adaptive Risk", "abstract": "Discrete-time stochastic optimal control remains a challenging problem for general, nonlinear systems under significant uncertainty, with practical solvers typically relying on the certainty equivalence assumption, replanning and/or extensive regularization. Control as inference is an approach that frames stochastic control as an equivalent inference problem, and has demonstrated desirable qualities over existing methods, namely in exploration and regularization. We look specifically at the input inference for control (i2c) algorithm, and derive three key characteristics that enable advanced trajectory optimization: An `expert' linear Gaussian controller that combines the benefits of open-loop optima and closed-loop variance reduction when optimizing for nonlinear systems, inherent adaptive risk sensitivity from the inference formulation, and covariance control functionality with only a minor algorithmic adjustment."}}
{"id": "_3fps7rAWY", "cdate": 1609459200000, "mdate": 1624045260743, "content": {"title": "Latent Derivative Bayesian Last Layer Networks", "abstract": "Bayesian neural networks (BNN) are powerful parametric models for nonlinear regression with uncertainty quantification. However, the approximate inference techniques for weight space priors suffer from several drawbacks. The \u2018Bayesian last layer\u2019 (BLL) is an alternative BNN approach that learns the feature space for an exact Bayesian linear model with explicit predictive distributions. However, its predictions outside of the data distribution (OOD) are typically overconfident, as the marginal likelihood objective results in a learned feature space that overfits to the data. We overcome this weakness by introducing a functional prior on the model\u2019s derivatives w.r.t. the inputs. Treating these Jacobians as latent variables, we incorporate the prior into the objective to influence the smoothness and diversity of the features, which enables greater predictive uncertainty. For the BLL, the Jacobians can be computed directly using forward mode automatic differentiation, and the distribution over Jacobians may be obtained in closed-form. We demonstrate this method enhances the BLL to Gaussian process-like performance on tasks where calibrated uncertainty is critical: OOD regression, Bayesian optimization and active learning, which include high-dimensional real-world datasets."}}
{"id": "Slj1pXm0rkc", "cdate": 1609459200000, "mdate": 1633453327171, "content": {"title": "Advancing Trajectory Optimization with Approximate Inference: Exploration, Covariance Control and Adaptive Risk", "abstract": "Discrete-time stochastic optimal control remains a challenging problem for general, nonlinear systems under significant uncertainty, with practical solvers typically relying on the certainty equivalence assumption, replanning and/or extensive regularization. Control-as-inference is an approach that frames stochastic control as an equivalent inference problem, and has demonstrated desirable qualities over existing methods, namely in exploration and regularization. We look specifically at the input inference for control (I2C) algorithm, and derive three key characteristics that enable advanced trajectory optimization: An `expert' linear Gaussian controller that combines the benefits of open-loop optima and closed-loop variance reduction when optimizing for nonlinear systems, adaptive risk sensitivity for regularized exploration, and performing covariance control through specifying the terminal state distribution."}}
