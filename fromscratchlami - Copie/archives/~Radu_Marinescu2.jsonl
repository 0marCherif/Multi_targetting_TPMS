{"id": "FrtkfqD4bCc-", "cdate": 1676827111024, "mdate": null, "content": {"title": "Boosting AND/OR-Based Computational Protein Design: Dynamic Heuristics and Generalizable UFO", "abstract": "Scientific computing has experienced a surge empowered by advancements in technologies such as neural networks.  However, certain important tasks are less amenable to these technologies, benefiting from innovations to traditional inference schemes.  One such task is protein re-design.  Recently a new re-design algorithm, AOBB-K*, was introduced and was competitive with state-of-the-art BBK* on small protein re-design problems. However, AOBB-K* did not scale well.  In this work, we focus on scaling up AOBB-K* and introduce three new versions: AOBB-K*-b (boosted), AOBB-K*-DH (with dynamic heuristics), and AOBB-K*-UFO (with underflow optimization) that significantly enhance scalability."}}
{"id": "JJkB5xAZTHU", "cdate": 1655100065229, "mdate": null, "content": {"title": "AND/OR Branch-and-Bound for Computational Protein Design Optimizing K*", "abstract": "The importance of designing proteins, such as high affinity antibodies, has become ever more apparent.  Computational Protein Design can cast such design problems as optimization tasks with the objective of maximizing K*, an approximation of binding affinity.  Here we lay out a graphical model framework for K* optimization that enables use of compact AND/OR search spaces. We introduce two distinct graphical model formulations, a new K* heuristic, AOBB-K* - an efficient depth-first branch-and-bound algorithm, and modifications that improve performance with theoretical guarantees.  As AOBB-K* is inspired by algorithms from the well studied task of Marginal MAP, this work provides a foundation for adaptation of state-of-the-art mixed inference schemes to protein design."}}
{"id": "MbBTrAvee-N", "cdate": 1652737599027, "mdate": null, "content": {"title": "Hedging as Reward Augmentation in Probabilistic Graphical Models", "abstract": "Most people associate the term `hedging' exclusively with financial applications, particularly the use of financial derivatives. We argue that hedging is an activity that human and machine agents should engage in more broadly, even when the agent's value is not necessarily in monetary units. In this paper, we propose a decision-theoretic view of hedging based on augmenting a probabilistic graphical model -- specifically a Bayesian network or an influence diagram -- with a reward. Hedging is therefore posed as a particular kind of graph manipulation, and can be viewed as analogous to control/intervention and information gathering related analysis. Effective hedging occurs when a risk-averse agent finds opportunity to balance uncertain rewards in their current situation. We illustrate the concepts with examples and counter-examples, and conduct experiments to demonstrate the properties and applicability of the proposed computational tools that enable agents to proactively identify potential hedging opportunities in real-world situations."}}
{"id": "wiGXs_kS_X", "cdate": 1652737519069, "mdate": null, "content": {"title": "Logical Credal Networks", "abstract": "We introduce Logical Credal Networks (or LCNs for short) -- an expressive probabilistic logic that generalizes prior formalisms that combine logic and probability. Given imprecise information represented by probability bounds and conditional probability bounds on logic formulas, an LCN specifies a set of probability distributions over all its interpretations. Our approach allows propositional and first-order logic formulas with few restrictions, e.g., without requiring acyclicity. We also define a generalized Markov condition that allows us to identify implicit independence relations between atomic formulas. We evaluate our method on benchmark problems such as random networks, Mastermind games with uncertainty and credit card fraud detection. Our results show that the LCN outperforms existing approaches; its advantage lies in aggregating multiple sources of imprecise information."}}
{"id": "HpPejZv2oZ5", "cdate": 1647195907428, "mdate": null, "content": {"title": "Finding Sub-task Structure with Natural Language Instruction", "abstract": "When mapping a natural language instruction to a sequence of actions, it is often useful to\nidentify sub-tasks in the instruction. \nSuch sub-task segmentation, however, is not necessarily provided in the training data. \nWe present the A2LCTC (Action-to-Language Connectionist Temporal Classification) algorithm to automatically discover a sub-task segmentation of an action sequence.\nA2LCTC does not require annotations of correct sub-task segments and learns to find them from pairs of instruction and action sequence in a weakly-supervised manner.\nWe experiment with the ALFRED dataset and show that A2LCTC accurately finds the sub-task structures.\nWith the discovered sub-tasks segments, we also train agents that work on the downstream task and empirically show that our algorithm improves the performance. "}}
{"id": "BKbcdPUs9ec", "cdate": 1646077536425, "mdate": null, "content": {"title": "AND/OR Branch-and-Bound for Computational Protein Design Optimizing K*", "abstract": "The importance of designing proteins, such as high affinity antibodies, has become ever more apparent.  Computational Protein Design can cast such design problems as optimization tasks with the objective of maximizing K*, an approximation of binding affinity.  Here we lay out a graphical model framework for K* optimization that enables use of compact AND/OR search algorithms. We designed an AND/OR branch-and-bound algorithm, AOBB-K*, for optimizing K* that is guided by a new K* heuristic and can incorporate specialized performance improvements with theoretical guarantees. As AOBB-K* is inspired by algorithms from the well studied task of Marginal MAP, this work provides a foundation for harnessing advancements in state-of-the-art mixed inference schemes and adapting them to protein design."}}
{"id": "RZai7UKX7Oo", "cdate": 1621522019343, "mdate": null, "content": {"title": "Bandit Limited Discrepancy Search and Application to Machine Learning Pipeline Optimization", "abstract": "Optimizing a machine learning (ML) pipeline has been an important topic of AI and ML.  Despite recent progress, this topic remains a challenging problem, due to potentially many combinations to consider as well as slow training and validation.  We present the BLDS algorithm for optimized algorithm selection (ML operations) in a fixed ML pipeline structure.  BLDS performs multi-fidelity optimization for selecting ML algorithms trained with smaller computational overhead, while controlling its pipeline search based on multi-armed bandit and limited discrepancy search.  Our experiments on well-known benchmarks show that BLDS is superior to competing algorithms.\n"}}
{"id": "S1xCKSBlUS", "cdate": 1567802758087, "mdate": null, "content": {"title": "Counting the Optimal Solutions in Graphical Models", "abstract": "We introduce #opt, a new inference task for graphical models which calls for counting the number of optimal solutions of the model. We describe a novel variable elimination based approach for solving this task, as well as a depth-first  branch and bound algorithm that traverses the AND/OR search space of the model. The key feature of the proposed algorithms is that their complexity is exponential in the induced width of the model only. It does not depend on the actual number of optimal solutions. Our empirical evaluation on various benchmarks demonstrates the effectiveness of the proposed algorithms compared with existing depth-first and best-first search based approaches that enumerate explicitly the optimal solutions."}}
{"id": "Hs8PfR-gdaB", "cdate": 1546300800000, "mdate": null, "content": {"title": "Anytime Recursive Best-First Search for Bounding Marginal MAP.", "abstract": "Marginal MAP is a difficult mixed inference task for graphical models. Existing state-of-the-art solvers for this task are based on a hybrid best-first and depth-first search scheme that allows them to compute upper and lower bounds on the optimal solution value in an anytime fashion. These methods however are memory intensive schemes (via the best-first component) and do not have an efficient memory management mechanism. For this reason, they are often less effective in practice, especially on difficult problem instances with very large search spaces. In this paper, we introduce a new recursive best-first search based bounding scheme that operates efficiently within limited memory and computes anytime upper and lower bounds that improve over time. An empirical evaluation demonstrates the effectiveness of our proposed approach against current solvers."}}
{"id": "SJWcsdZd-r", "cdate": 1514764800000, "mdate": null, "content": {"title": "From Stochastic Planning to Marginal MAP", "abstract": "It is well known that the problems of stochastic planning and probabilistic inference are closely related. This paper makes two contributions in this context. The first is to provide an analysis of the recently developed SOGBOFA heuristic planning algorithm that was shown to be effective for problems with large factored state and action spaces. It is shown that SOGBOFA can be seen as a specialized inference algorithm that computes its solutions through a combination of a symbolic variant of belief propagation and gradient ascent. The second contribution is a new solver for Marginal MAP (MMAP) inference. We introduce a new reduction from MMAP to maximum expected utility problems which are suitable for the symbolic computation in SOGBOFA. This yields a novel algebraic gradient-based solver (AGS) for MMAP. An experimental evaluation illustrates the potential of AGS in solving difficult MMAP problems."}}
