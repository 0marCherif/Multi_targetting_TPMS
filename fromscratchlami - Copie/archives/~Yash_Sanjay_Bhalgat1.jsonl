{"id": "78gtW7cahU", "cdate": 1698935460087, "mdate": 1698935460087, "content": {"title": "Contrastive Lift: 3D Object Instance Segmentation by Slow-Fast Contrastive Fusion", "abstract": "Instance segmentation in 3D is a challenging task due to the lack of large-scale annotated datasets. In this paper, we show that this task can be addressed effectively by leveraging instead 2D pre-trained models for instance segmentation. We propose a novel approach to lift 2D segments to 3D and fuse them by means of a neural field representation, which encourages multi-view consistency across frames. The core of our approach is a slow-fast clustering objective function, which is scalable and well-suited for scenes with a large number of objects. Unlike previous approaches, our method does not require an upper bound on the number of objects or object tracking across frames. To demonstrate the scalability of the slow-fast clustering, we create a new semi-realistic dataset called the Messy Rooms dataset, which features scenes with up to 500 objects per scene. Our approach outperforms the state-of-the-art on challenging scenes from the ScanNet, Hypersim, and Replica datasets, as well as on our newly created Messy Rooms dataset, demonstrating the effectiveness and scalability of our slow-fast clustering method."}}
{"id": "oZBx2jPTuPz", "cdate": 1683883043587, "mdate": 1683883043587, "content": {"title": "A Prompt Array Keeps the Bias Away: Debiasing Vision-Language Models with Adversarial Learning", "abstract": "Vision-language models can encode societalv biases and stereotypes, but there are challenges to measuring and mitigating these multimodal harms due to lacking measurement robustness and feature degradation. To address these challenges, we investigate bias measures and apply ranking metrics for image-text representations. We then investigate debiasing methods and show that prepending learned embeddings to text queries that are jointly trained with adversarial debiasing and a contrastive loss reduces various bias measures with minimal degradation to the image-text representation."}}
{"id": "BLFKU56VnnU", "cdate": 1672531200000, "mdate": 1695974727403, "content": {"title": "Contrastive Lift: 3D Object Instance Segmentation by Slow-Fast Contrastive Fusion", "abstract": "Instance segmentation in 3D is a challenging task due to the lack of large-scale annotated datasets. In this paper, we show that this task can be addressed effectively by leveraging instead 2D pre-trained models for instance segmentation. We propose a novel approach to lift 2D segments to 3D and fuse them by means of a neural field representation, which encourages multi-view consistency across frames. The core of our approach is a slow-fast clustering objective function, which is scalable and well-suited for scenes with a large number of objects. Unlike previous approaches, our method does not require an upper bound on the number of objects or object tracking across frames. To demonstrate the scalability of the slow-fast clustering, we create a new semi-realistic dataset called the Messy Rooms dataset, which features scenes with up to 500 objects per scene. Our approach outperforms the state-of-the-art on challenging scenes from the ScanNet, Hypersim, and Replica datasets, as well as on our newly created Messy Rooms dataset, demonstrating the effectiveness and scalability of our slow-fast clustering method."}}
{"id": "6tXnKkQgThS", "cdate": 1672531200000, "mdate": 1681511926191, "content": {"title": "Refinement for Absolute Pose Regression with Neural Feature Synthesis", "abstract": ""}}
{"id": "wIUTqSjmH9", "cdate": 1640995200000, "mdate": 1666125256539, "content": {"title": "A Prompt Array Keeps the Bias Away: Debiasing Vision-Language Models with Adversarial Learning", "abstract": "Vision-language models can encode societal biases and stereotypes, but there are challenges to measuring and mitigating these multimodal harms due to lacking measurement robustness and feature degradation. To address these challenges, we investigate bias measures and apply ranking metrics for image-text representations. We then investigate debiasing methods and show that prepending learned embeddings to text queries that are jointly trained with adversarial debiasing and a contrastive loss reduces various bias measures with minimal degradation to the image-text representation."}}
{"id": "rdShAmXAXE", "cdate": 1640995200000, "mdate": 1681511926191, "content": {"title": "A Light Touch Approach to Teaching Transformers Multi-view Geometry", "abstract": ""}}
{"id": "Pe4hVhPw6QC", "cdate": 1640995200000, "mdate": 1681511926192, "content": {"title": "A Prompt Array Keeps the Bias Away: Debiasing Vision-Language Models with Adversarial Learning", "abstract": ""}}
{"id": "Bn0hyJTtB6", "cdate": 1640995200000, "mdate": 1666125256530, "content": {"title": "Dynamic Iterative Refinement for Efficient 3D Hand Pose Estimation", "abstract": "While hand pose estimation is a critical component of most interactive extended reality and gesture recognition systems, contemporary approaches are not optimized for computational and memory efficiency. In this paper, we propose a tiny deep neural network of which partial layers are recursively exploited for refining its previous estimations. During its iterative refinements, we employ learned gating criteria to decide whether to exit from the weight-sharing loop, allowing per-sample adaptation in our model. Our network is trained to be aware of the uncertainty in its current predictions to efficiently gate at each iteration, estimating variances after each loop for its keypoint estimates. Additionally, we investigate the effectiveness of end-to-end and progressive training protocols for our recursive structure on maximizing the model capacity. With the proposed setting, our method consistently outperforms state-of-the-art 2D/3D hand pose estimation approaches in terms of both accuracy and efficiency for widely used benchmarks."}}
{"id": "mdviS-fgjxQ", "cdate": 1609459200000, "mdate": 1666125256554, "content": {"title": "Dynamic Iterative Refinement for Efficient 3D Hand Pose Estimation", "abstract": "While hand pose estimation is a critical component of most interactive extended reality and gesture recognition systems, contemporary approaches are not optimized for computational and memory efficiency. In this paper, we propose a tiny deep neural network of which partial layers are recursively exploited for refining its previous estimations. During its iterative refinements, we employ learned gating criteria to decide whether to exit from the weight-sharing loop, allowing per-sample adaptation in our model. Our network is trained to be aware of the uncertainty in its current predictions to efficiently gate at each iteration, estimating variances after each loop for its keypoint estimates. Additionally, we investigate the effectiveness of end-to-end and progressive training protocols for our recursive structure on maximizing the model capacity. With the proposed setting, our method consistently outperforms state-of-the-art 2D/3D hand pose estimation approaches in terms of both accuracy and efficiency for widely used benchmarks."}}
{"id": "Ni0HaGUJN86", "cdate": 1609459200000, "mdate": 1666125256532, "content": {"title": "Data-driven Weight Initialization with Sylvester Solvers", "abstract": "In this work, we propose a data-driven scheme to initialize the parameters of a deep neural network. This is in contrast to traditional approaches which randomly initialize parameters by sampling from transformed standard distributions. Such methods do not use the training data to produce a more informed initialization. Our method uses a sequential layer-wise approach where each layer is initialized using its input activations. The initialization is cast as an optimization problem where we minimize a combination of encoding and decoding losses of the input activations, which is further constrained by a user-defined latent code. The optimization problem is then restructured into the well-known Sylvester equation, which has fast and efficient gradient-free solutions. Our data-driven method achieves a boost in performance compared to random initialization methods, both before start of training and after training is over. We show that our proposed method is especially effective in few-shot and fine-tuning settings. We conclude this paper with analyses on time complexity and the effect of different latent codes on the recognition performance."}}
