{"id": "z9SIj-IM7tn", "cdate": 1663850458623, "mdate": null, "content": {"title": "Competitive Physics Informed Networks ", "abstract": "Neural networks can be trained to solve partial differential equations (PDEs) by using the PDE residual as the loss function. This strategy is called \"physics-informed neural networks\" (PINNs), but it currently cannot produce high-accuracy solutions, typically attaining about $0.1\\%$ relative error. We present an adversarial approach that overcomes this limitation, which we call competitive PINNs (CPINNs). CPINNs train a discriminator that is rewarded for predicting mistakes the PINN makes. The discriminator and PINN participate in a zero-sum game with the exact PDE solution as an optimal strategy. This approach avoids squaring the large condition numbers of PDE discretizations, which is the likely reason for failures of previous attempts to decrease PINN errors even on benign problems. Numerical experiments on a Poisson problem show that CPINNs achieve errors four orders of magnitude smaller than the best-performing PINN. We observe relative errors on the order of single-precision accuracy, consistently decreasing with each epoch. To the authors' knowledge, this is the first time this level of accuracy and convergence behavior has been achieved. Additional experiments on the nonlinear Schr{\\\"o}dinger, Burgers', and Allen--Cahn equation show that the benefits of CPINNs are not limited to linear problems."}}
{"id": "rMz_scJ6lc", "cdate": 1646226080035, "mdate": null, "content": {"title": "Competitive Physics Informed Networks", "abstract": "Physics Informed Neural Networks (PINNs) solve partial differential equations (PDEs) by representing them as neural networks.\nThe original PINN implementation does not provide high accuracy, typically attaining about $10^{-3}$ $L_2$ relative error.\nWe formulate and test an adversarial approach called competitive PINNs (CPINNs) to overcome this limitation.\nCPINNs train a discriminator that is rewarded for predicting PINN mistakes. \nThe discriminator and PINN participate in a zero-sum game with the exact PDE solution as an optimal strategy.\nThis approach avoids the issue of squaring the large condition numbers of PDE discretizations. \nNumerical experiments show that a CPINN trained with competitive gradient descent can achieve errors two orders of magnitude smaller than that of a PINN trained with Adam or stochastic gradient descent."}}
{"id": "EYCm0AFjaSS", "cdate": 1632875611488, "mdate": null, "content": {"title": "ZerO Initialization: Initializing Residual Networks with only Zeros and Ones", "abstract": "Deep neural networks are usually initialized with random weights, with adequately selected initial variance to ensure stable signal propagation during training. However, there is no consensus on how to select the variance, and this becomes challenging especially as the number of layers grows. In this work, we replace the widely used random weight initialization with a fully deterministic initialization scheme ZerO, which initializes residual networks with only zeros and ones. By augmenting the standard ResNet architectures with a few extra skip connections and Hadamard transforms, ZerO allows us to start the training from zeros and ones entirely. This has many benefits such as improving reproducibility (by reducing the variance over different experimental runs) and allowing network training without batch normalization. Surprisingly, we find that ZerO achieves state-of-the-art performance over various image classification datasets, including ImageNet, which suggests random weights may be unnecessary for modern network initialization."}}
{"id": "SkxaueHFPB", "cdate": 1569439861433, "mdate": null, "content": {"title": "Implicit competitive regularization in GANs", "abstract": "Generative adversarial networks (GANs) are capable of producing high quality samples, but they suffer from numerous issues such as instability and mode collapse during training. To combat this, we propose to model the generator and discriminator as agents acting under local information, uncertainty, and awareness of their opponent. By doing so we achieve stable convergence, even when the underlying game has no  Nash equilibria. We call this mechanism \\emph{implicit competitive regularization} (ICR) and show that it is present in the recently proposed \\emph{competitive gradient descent} (CGD).\nWhen comparing CGD to Adam using a variety of loss functions and regularizers on CIFAR10, CGD shows a much more consistent performance, which we attribute to ICR.\nIn our experiments, we achieve the highest inception score when using the WGAN loss (without gradient penalty or weight clipping) together with CGD. This can be interpreted as minimizing a form of integral probability metric based on ICR."}}
{"id": "HJechEHeLr", "cdate": 1567802545982, "mdate": null, "content": {"title": "Competitive Gradient Descent", "abstract": " We introduce a new algorithm for the numerical computation of Nash equilibria of competitive two-player games.     Our method is a natural generalization of gradient descent to the two-player setting where the update is given by the Nash equilibrium of a regularized bilinear local approximation of the underlying game.  It avoids   oscillatory and divergent behaviors seen in alternating gradient descent. Using numerical experiments and rigorous analysis, we provide a detailed comparison to methods based on \\emph{optimism} and \\emph{consensus}  and show that our method avoids making any unnecessary changes to the gradient dynamics while achieving exponential (local) convergence for (locally) convex-concave zero sum games.     Convergence and stability properties of our method are robust to strong interactions between the players, without adapting the stepsize, which is not the case with previous methods.      In our numerical experiments on non-convex-concave problems, existing methods are prone to divergence and instability due to their sensitivity to interactions among the players, whereas we never observe divergence of our algorithm.     The ability to choose larger stepsizes furthermore allows our algorithm to achieve faster convergence, as measured by the number of model evaluations."}}
