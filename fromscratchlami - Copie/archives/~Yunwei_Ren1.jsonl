{"id": "uTQqiVTrEpR", "cdate": 1672531200000, "mdate": 1682358022285, "content": {"title": "Depth Separation with Multilayer Mean-Field Networks", "abstract": "Depth separation -- why a deeper network is more powerful than a shallower one -- has been a major problem in deep learning theory. Previous results often focus on representation power. For example, arXiv:1904.06984 constructed a function that is easy to approximate using a 3-layer network but not approximable by any 2-layer network. In this paper, we show that this separation is in fact algorithmic: one can learn the function constructed by arXiv:1904.06984 using an overparameterized network with polynomially many neurons efficiently. Our result relies on a new way of extending the mean-field limit to multilayer networks, and a decomposition of loss that factors out the error introduced by the discretization of infinite-width mean-field networks."}}
{"id": "r5tODmUk01M", "cdate": 1672531200000, "mdate": 1682358022295, "content": {"title": "On the Importance of Contrastive Loss in Multimodal Learning", "abstract": "Recently, contrastive learning approaches (e.g., CLIP (Radford et al., 2021)) have received huge success in multimodal learning, where the model tries to minimize the distance between the representations of different views (e.g., image and its caption) of the same data point while keeping the representations of different data points away from each other. However, from a theoretical perspective, it is unclear how contrastive learning can learn the representations from different views efficiently, especially when the data is not isotropic. In this work, we analyze the training dynamics of a simple multimodal contrastive learning model and show that contrastive pairs are important for the model to efficiently balance the learned representations. In particular, we show that the positive pairs will drive the model to align the representations at the cost of increasing the condition number, while the negative pairs will reduce the condition number, keeping the learned representations balanced."}}
{"id": "wfU0emciOcM", "cdate": 1663850404479, "mdate": null, "content": {"title": "On the Importance of Contrastive Loss in Multimodal Learning", "abstract": "Recently, contrastive learning approaches (e.g., CLIP (Radford et al., 2021)) have received huge success in multimodal learning, where the model tries to minimize the distance between the representations of di\ufb00erent views (e.g., image and its caption) of the same data point, while keep the representations of di\ufb00erent data points away from each other. However, from a theoretical perspective, it is unclear how contrastive learning can learn to align the representations from di\ufb00erent views e\ufb03ciently, especially in cases where the data is not isotropic. In this work, we analyze the training dynamics of a simple multimodal contrastive learning model, and show that contrastive pairs are important for the model to e\ufb03ciently balance the learned representations. In particular, we reveal a stage-wise behavior of the learning process: In the \ufb01rst stage, the model aligns the feature representations using positive pairs and the condition number grows in this stage. Then, in the second stage, the model reduces the condition number of the learned representations using negative pairs."}}
{"id": "uzFQpkEzOo", "cdate": 1663850400702, "mdate": null, "content": {"title": "Depth Separation with Multilayer Mean-Field Networks", "abstract": "Depth separation\u2014why a deeper network is more powerful than a shallow one\u2014has been a major problem in deep learning theory. Previous results often focus on representation power, for example, Safran et al. (2019) constructed a function that is easy to approximate using a 3-layer network but not approximable by any 2-layer network. In this paper, we show that this separation is in fact algorithmic: one can learn the function constructed by Safran et al. (2019) using an overparametrized network with polynomially many neurons ef\ufb01ciently. Our result relies on a new way of extending the mean-\ufb01eld limit to multilayer networks, and a decomposition of loss that factors out the error introduced by the discretization of in\ufb01nite-width mean-\ufb01eld networks."}}
{"id": "lLP77dROaJ", "cdate": 1621630250767, "mdate": null, "content": {"title": "Understanding Deflation Process in Over-parametrized Tensor Decomposition", "abstract": "In this paper we study the training dynamics for gradient flow on over-parametrized tensor decomposition problems. Empirically, such training process often first fits larger components and then discovers smaller components, which is similar to a tensor deflation process that is commonly used in tensor decomposition algorithms. We prove that for orthogonally decomposable tensor, a slightly modified version of gradient flow would follow a tensor deflation process and recover all the tensor components. Our proof suggests that for orthogonal tensors, gradient flow dynamics works similarly as greedy low-rank learning in the matrix setting, which is a first step towards understanding the implicit regularization effect of over-parametrized models for low-rank tensors."}}
{"id": "wJJ56hG9OGy", "cdate": 1609459200000, "mdate": 1682358022310, "content": {"title": "Understanding Deflation Process in Over-parametrized Tensor Decomposition", "abstract": "In this paper we study the training dynamics for gradient flow on over-parametrized tensor decomposition problems. Empirically, such training process often first fits larger components and then discovers smaller components, which is similar to a tensor deflation process that is commonly used in tensor decomposition algorithms. We prove that for orthogonally decomposable tensor, a slightly modified version of gradient flow would follow a tensor deflation process and recover all the tensor components. Our proof suggests that for orthogonal tensors, gradient flow dynamics works similarly as greedy low-rank learning in the matrix setting, which is a first step towards understanding the implicit regularization effect of over-parametrized models for low-rank tensors."}}
{"id": "CoifZqQR8B", "cdate": 1609459200000, "mdate": 1682358022312, "content": {"title": "Understanding Deflation Process in Over-parametrized Tensor Decomposition", "abstract": "In this paper we study the training dynamics for gradient flow on over-parametrized tensor decomposition problems. Empirically, such training process often first fits larger components and then discovers smaller components, which is similar to a tensor deflation process that is commonly used in tensor decomposition algorithms. We prove that for orthogonally decomposable tensor, a slightly modified version of gradient flow would follow a tensor deflation process and recover all the tensor components. Our proof suggests that for orthogonal tensors, gradient flow dynamics works similarly as greedy low-rank learning in the matrix setting, which is a first step towards understanding the implicit regularization effect of over-parametrized models for low-rank tensors."}}
