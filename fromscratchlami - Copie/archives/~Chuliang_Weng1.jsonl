{"id": "atx8Y8-E9qq", "cdate": 1683705382304, "mdate": 1683705382304, "content": {"title": "ShadowVM: accelerating data plane for data analytics with bare metal CPUs and GPUs", "abstract": "Authors: Zhifang Li, Mingcong Han, Shangwei Wu, Chuliang Weng\n\nWith the development of the big data ecosystem, large-scale data analytics has become more prevalent in the past few years. Apache Spark, etc., provide a flexible approach for scalable processing upon massive data. However, they are not designed for handling computing-intensive workloads due to the restrictions of JVM runtime. In contrast, GPU has been the de facto accelerator for graphics rendering and deep learning in recent years. Nevertheless, the current architecture makes it difficult to take advantage of GPUs and other accelerators in the big data world.\nNow, it is time to break down this obstacle by changing the fundamental architecture. To integrate accelerators efficiently, we decouple the control plane and the data plane within big data systems via action shadowing. The control plane keeps logic information to fit well with the host systems like Spark, while the data plane holds data and performs execution upon bare metal CPUs and GPUs. Under this decoupled architecture, both the control plane and the data plane could leverage the appropriate approaches without breaking existing mechanisms. Based on this idea, we implement an accelerated data plane, namely ShadowVM. In our experiments on the SSB benchmark, ShadowVM lifts the JVM-based Spark with up to 14.7\u00d7 speedup. Furthermore, ShadowVM could also outperform the GPU-only fashion by adopting mixed CPU-GPU execution."}}
{"id": "6t-nguFFKtV", "cdate": 1683705241127, "mdate": null, "content": {"title": "Dynamic depth-width optimization for capsule graph convolutional network", "abstract": "\nAuthors: Shangwei WU , Yingtong XIONG , Chuliang WENG\n\nEncouraged by the success of Convolutional Neural Networks (CNNs), many studies [1], known as Graph Convolutional Networks (GCNs), borrowed the idea of convolution and redefined it for graph data. In graph-level classification tasks, Classic GCN methods [2,3] generate graph embeddings based on the learned node embeddings which consider each node\u2019s representation as multiple independent scalar features. However, they neglect the detailed mutual relations among different node features such as position, direction, and connection. Inspired by CapsNet [4] which encodes each feature of an image as a vector (a capsule), CapsGNN [5] extracts multi-scale node features from different convolutional layers in the form of capsules. However, CapsGNN uses a static model structure to conduct training, which inherently restricts its representation ability on different datasets.\nIn this paper, we propose Dynamic Depth-Width Optimization for Capsule Graph Convolutional Network (DynaCGCN) to explore the optimal depth-width setting on each dataset. Specifically, we leverage Reinforcement Learning (RL) to design an efficient online assistant module for evaluating different changes to depth (number of convolutional layers, denoted by D) and width (number of capsule channels in each layer, denoted by W). Differing from a typical RL-based Neural Architecture Search (NAS) task that evaluates different model structures separately, we move the RL procedure into only one full training and choose one action (i.e., one alteration to D and W) at one time in a sliding epoch window, according to not only the accuracy results on the validation set but also the reduction rate of training loss."}}
{"id": "6Zywb_RSWlj", "cdate": 1683704996992, "mdate": null, "content": {"title": "CBA-Detector: A Self-Feedback Detector Against Cache-Based Attacks", "abstract": "\nAuthors: Beilei Zheng; Jianan Gu; Jialun Wang; Chuliang Weng\n\nCloud computing is convenient to provide adequate resources for tenants. However, since multiple tenants share the underlying hardware resources, malicious tenants can use the shared processor to launch cache-based attacks. Such attacks can help malicious tenants steal private data of other tenants bypassing isolation mechanisms provided by the system, resulting in information leakage. Moreover, Spectre and Meltdown vulnerabilities can even extract memory contents arbitrarily with the help of cache attacks. Therefore, cache-based attacks pose a serious threat to the security of cloud platforms. To defeat such attacks, many detection methods have been proposed. However, most methods induce high false positives because they completely rely on the hardware performance counters (HPCs) and detect attacks with static criteria. To solve this problem, this article proposes a self-feedback detector named CBA-Detector to detect cache-based attacks in real time. Specifically, CBA-Detector first uses machine learning technologies to create models for identifying suspicious programs with abnormal hardware behaviors, then analyzes suspicious programs from the instruction level to identify real attacks and provide feedback. Based on the feedback, the models can be updated to further improve their detection accuracy. As our experiments show, CBA-Detector can accurately identify cache-based attacks in real time and introduces a little overhead. Besides, the misjudgment rate decreases with the running time."}}
{"id": "o2UwRc8fbXI", "cdate": 1632875642677, "mdate": null, "content": {"title": "Adaptive Graph Capsule Convolutional Networks", "abstract": "In recent years, many studies utilize Convolutional Neural Networks (CNNs) to deal with non-grid graph data, known as Graph Convolutional Networks (GCNs). However, there exist two main restrictions of the prevalent GCNs. First, GCNs have a latent information loss problem since they use scalar-valued neurons rather than vector-valued ones to iterate through graph convolutions. Second, GCNs are presented statically with fixed architectures during training, which would limit their representation power. To tackle these two issues, based on a GNN model (CapsGNN) which encodes node embeddings as vectors, we propose Adaptive Graph Capsule Convolutional Networks (AdaGCCN) to adaptively adjust the model architecture at runtime. Specifically, we leverage Reinforcement Learning (RL) to design an assistant module for continuously selecting the optimal modification to the model structure through the whole training process. Moreover, we determine the architecture search space through analyzing the impacts of model's depth and width. To mitigate the computation overhead brought by the assistant module, we then deploy multiple workers to compute in parallel on GPU. Evaluations show that AdaGCCN achieves SOTA accuracy results and outperforms CapsGNN almost on all datasets in both bioinformatics and social fields. We also conduct experiments to indicate the efficiency of the paralleling strategy."}}
