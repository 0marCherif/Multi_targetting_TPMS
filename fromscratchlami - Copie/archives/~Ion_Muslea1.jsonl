{"id": "hX3OCgroK2", "cdate": 1696356009362, "mdate": 1696356009362, "content": {"title": "Improving the Exploration/Exploitation Trade-Of in Web Content Discovery", "abstract": "New web content is published constantly, and although protocols such as RSS can notify subscribers of new pages, they are not always implemented or actively maintained. A more reliable way to discover new content is to periodically re-crawl the target sites. Designing such \u201ccontent discovery crawlers\u201d has important applications, for example, in web search, digital assistants, business, humanitarian aid, and law enforcement. Existing approaches assume that each site of interest has a relatively small set of unknown \u201csource pages\u201d that, when refreshed, frequently provide hyperlinks to the majority of new content. The state of the art (SOTA) uses ideas from the multi-armed bandit literature to explore candidate sources while simultaneously exploiting known good sources. We observe, however, that the SOTA uses a sub-optimal algorithm for balancing exploration and exploitation. We trace this back to a mismatch between the space of actionsthat the SOTA algorithm models and the space of actions that the crawler must actually choose from. Our proposed approach, the Thompson crawler (named after the Thompson sampler that drives its refresh decisions), addresses this shortcoming by more faithfully modeling the action space. On a dataset of 4,070 source pages drawn from 53 news domains over a period of 7 weeks, we show that, on average, the Thompson crawler discovers 20% more new pages, fnds pages 6 hours earlier, and uses 14 fewer refreshes per 100 pages discovered than the SOTA."}}
{"id": "SkZR5Agd-S", "cdate": 1104537600000, "mdate": null, "content": {"title": "Online Query Relaxation via Bayesian Causal Structures Discovery", "abstract": "We introduce a novel algorithm, TOQR, for relaxing failed queries over databases, that is, over-constrained DNF queries that return an empty result. TOQR uses a small dataset to discover the implicit relationships among the domain attributes, and then it exploits this domain knowledge to relax the failed query. TOQR starts with a relaxed query that does not include any constraint, and it tries to add to it as many as possible of the original constraints or their relaxations. The order in which the constraints are added is derived from the domain's causal structure, which is learned by applying the TAN algorithm to the small training dataset. Our experiments show that TOQR clearly outperforms other approaches: even when trained on a handful of examples, it successfully relaxes more that 97% of the failed queries; furthermore, TOQR'S relaxed queries are highly similar to the original failed query."}}
{"id": "r1ZvYEbO-H", "cdate": 1072915200000, "mdate": null, "content": {"title": "Machine learning for online query relaxation", "abstract": "In this paper we provide a fast, data-driven solution to the failing query problem: given a query that returns an empty answer, how can one relax the query's constraints so that it returns a non-empty set of tuples? We introduce a novel algorithm, loqr, which is designed to relax queries that are in the disjunctive normal form and contain a mixture of discrete and continuous attributes. loqr discovers the implicit relationships that exist among the various domain attributes and then uses this knowledge to relax the constraints from the failing query.In a first step, loqr uses a small, randomly-chosen subset of the target database to learn a set of decision rules that predict whether an attribute's value satisfies the constraints in the failing query; this query-driven operation is performed online for each failing query. In the second step, loqr uses nearest-neighbor techniques to find the learned rule that is the most similar to the failing query; then it uses the attributes' values from this rule to relax the failing query's constraints. Our experiments on six application domains show that loqr is both robust and fast: it successfully relaxes more than 95% of the failing queries, and it takes under a second for processing queries that consist of up to 20 attributes (larger queries of up to 93 attributes are processed in several seconds)."}}
{"id": "SkERaXGO-B", "cdate": 1041379200000, "mdate": null, "content": {"title": "Active Learning with Strong and Weak Views: A Case Study on Wrapper Induction", "abstract": "Multi-view learners reduce the need for labeled data by exploiting disjoint sub-sets of features (views), each of which is sufficient for learning. Such algorithms assume that each view is a strong view (i.e., perfect learning is possible in each view). We extend the multi-view framework by introducing a novel algorithm, Aggressive Co-Testing, that exploits both strong and weak views; in a weak view, one can learn a concept that is strictly more general or specific than the target concept. Aggressive Co-Testing uses the weak views both for detecting the most informative examples in the domain and for improving the accuracy of the predictions. In a case study on 33 wrapper induction tasks, our algorithm requires significantly fewer labeled examples than existing state-of-the-art approaches."}}
{"id": "ByWycobdWB", "cdate": 1009843200000, "mdate": null, "content": {"title": "Active + Semi-supervised Learning = Robust Multi-View Learning", "abstract": "In a multi-view problem, the features of the domain can be partitioned into disjoint subsets (views) that are sufficient to learn the target concept. Semi-supervised, multi-view algorithms, which reduce the amount of labeled data required for learning, rely on the assumptions that the views are compatible and uncorrelated (i.e., every example is identically labeled by the target concepts in each view; and, given the label of any example, its descriptions in each view are independent). As these assumptions are unlikely to hold in practice, it is crucial to understand the behavior of multi-view algorithms on problems with incompatible, correlated views. We address this issue by studying several algorithms on a parameterized family of text classification problems in which we control both view correlation and incompatibility. We first show that existing semi-supervised algorithms are not robust over the whole spectrum of parameterized problems. Then we introduce a new multi-view algorithm, Co-EMT, which combines semi-supervised and active learning. Co-EMT outperforms the other algorithms both on the parameterized problems and on two additional real world domains. Our experiments suggest that Co-EMT\u2019s robustness comes from active learning compensating for the correlation of the views."}}
{"id": "ByEoy2-u-H", "cdate": 1009843200000, "mdate": null, "content": {"title": "Adaptive View Validation: A First Step Towards Automatic View Detection", "abstract": "Multi-view algorithms reduce the amount of required training data by partitioning the domain features into separate subsets or views that are sufficient to learn the target concept. Such algorithms rely on the assumption that the views are sufficiently compatible for multi-view learning (i.e., most examples are labeled identically in all views). In practice, it is unclear whether or not two views are sufficiently compatible for solving a new, unseen learning task. In order to cope with this problem, we introduce a view validation algorithm: given a learning task, the algorithm predicts whether or not the views are sufficiently compatible for solving that particular task. We use information acquired while solving several exemplar learning tasks to train a classifier that discriminates between the tasks for which the views are sufficiently and insufficiently compatible for multi-view learning. Our experiments on wrapper induction and text classification show that view validation requires only a modest amount of training data to make high accuracy predictions."}}
{"id": "SyZ1LxZ_bS", "cdate": 946684800000, "mdate": null, "content": {"title": "Selective Sampling with Redundant Views", "abstract": "Selective sampling, a form of active learning, reduces the cost of labeling training data by asking only for the labels of the most informative unlabeled examples. We introduce a novel approach to selective sampling which we call co-testing. Co-testing can be applied to problems with redundant views (i.e., problems with multiple disjoint sets of attributes that can be used for learning). We analyze the most general algorithm in the cotesting family, naive co-testing, which can be used with virtually any type of learner. Naive co-testing simply selects at random an example on which the existing views disagree. We applied our algorithm to a variety of domains, including three real-world problems: wrapper induction, Web page classification, and discourse trees parsing. The empirical results show that besides reducing the number of labeled examples, naive co-testing may also boost the classification accuracy."}}
{"id": "BkW-Iy-ObB", "cdate": 946684800000, "mdate": null, "content": {"title": "Selective Sampling with Co-Testing: Preliminary Results", "abstract": "We present a novel approach to selective sampling, cotesting, which can be applied to problems with redundant views (i.e., problems with multiple disjoint sets of attributes that can be used for learning). The main idea behind co-testing consists of selecting the queries among the unlabeled examples on which the existing views disagree. Selective sampling (Seung, Opper, & Sompolinski 1972), a form of active learning, reduces the number of training examples that need to be labeled by examining unlabeled examples and selecting the most informative ones for the human to label. We introduce co-testing, which is a novel approach to selective sampling for domains with redundant views. A domain has redundant views if there are at least two mutually exclusive sets of features that can be used to learn the target concept. Our work was inspired by (Blum & Mitchell 1998), who noted that there are many real world domains with multiple views. For example, in Web page classification, one can identify faculty home pages either based on the words on the page or based on the words in HTML anchors pointing to the page. Active learning algorithms ask the user to label an example that maximizes the information conveyed to the learner (we refer to such selected examples as ). In a standard, single-view learning scenario, this generally translates into finding an example that splits the version space in half, i.e., eliminating half of the hypotheses consistent with the training set. With redundant views, we can do much better. Co-testing simultaneously trains a separate classifier for each redundant view. Each classifier is applied to a pool of unlabeled examples, and the system selects a query based on the degree of disagreement among the learners. As the target hypotheses in each view must agree, co-testing can reduce the hypothesis space faster than would otherwise be possible. To illustrate this, consider a learning problem where we have two views, A and B. For illustrative purposes, imagine an extreme case where there is an unlabeled example that is classified as positive by a single hypothesis from the A version space; furthermore, assume that is classified as positive by all but one of the hypotheses from the B version space. If the"}}
{"id": "SyEDZ1WdWH", "cdate": 915148800000, "mdate": null, "content": {"title": "Active Learning for Hierarchical Wrapper Induction", "abstract": "Information mediators that allow users to integrate data from several Web sources rely on wrappers that extract the relevant data from the Web documents. Wrappers turn collections of Web pages into database-like tables by applying a set of extraction rules to each individual document. Even though the extraction rules can be written by humans, this is undesirable because the process is tedious, time consuming, and requires a high level of expertise. As an alternative to manually writing extraction rules, we created STALKER (Muslea, Minton, & Knoblock 1999), which is a wrapper induction algorithm that learns highaccuracy extraction rules. The major novelty introduced by STALKER is the concept of hierarchical wrapper induction: the extraction of the relevant data is performed in a hierarchical manner based on the embedded catalog tree (ECT), which is a user-provided description of the information to be extracted. Consider the sample document html Name: Joe\u2019s p br Cuisine: American p Menu: Salad 2, Soup 1.5, Steak 4.25. /html It is easy to see that the document above has a hierarchical structure: at the top level, the whole page can be seen as a 3-tuple that contains the name, cuisine, and menu. The name and cuisine are atomic items (i.e., strings), while the menu is an embedded listof 2-tuples that contain the course name and the price. Consequently, the relevant data in the document can be seen as the leaves of a tree-like structure in which the root represents the whole page, and all internal nodes are embedded lists. STALKER generates one extraction rule for each node in the tree, together with an additional list iteration rule for each internal node. Given the learned rules and the ECT of the documents, the extraction is performed in a hierarchical manner. A straightforward example would be to extract the restaurant name from the page above: we can use the rule SkipTo(Name:) to ignore everything until \u201cName:\u201d, which immediately precedes the restaurant name; then we can apply SkipUntil( p ) to extract all characters until we find \u201c p \u201d. In order to perform a more complicated task, say to extract the names of all the courses in the menu, STALKER first extracts the whole menu, and then it applies the corresponding list iteration rule to obtain the individual 2-tuples"}}
{"id": "H1WjPHG_WS", "cdate": 915148800000, "mdate": null, "content": {"title": "Two Fielded Teams and Two Experts: A RoboCup Challenge Response from the Trenches", "abstract": "The RoboCup (robot world-cup soccer) effort, initiated to stimulate research in multi-agents and robotics, has blossomed into a significant effort of international proportions. RoboCup is simultaneously a fundamental research effort and a set of competitions for testing research ideas. At IJCAI'97, a broad research challenge was issued for the RoboCup synthetic agents, covering areas of multi-agent learning, teamwork and agent modeling. This paper outlines our attack on the entire breadth of the RoboCup research challenge, on all of its categories, in the form of two fielded, contrasting RoboCup teams, and two off-line soccer analysis agents. We compare the teams and the agents to generalize the lessons learned in learning, teamwork and agent modeling."}}
