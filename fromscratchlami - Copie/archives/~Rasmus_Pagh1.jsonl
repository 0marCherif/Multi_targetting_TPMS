{"id": "K4JetICumF", "cdate": 1674142930378, "mdate": null, "content": {"title": "Fair Near Neighbor Search: Independent Range Sampling in High Dimensions", "abstract": "Similarity search is a fundamental algorithmic primitive, widely used in many computer science disciplines. There are several variants of the similarity search problem, and one of the most relevant is the r-near neighbor (r-NN) problem: given a radius r>0 and a set of points S, construct a data structure that, for any given query point q, returns a point p within distance at most r from q. In this paper, we study the r-NN problem in the light of fairness. We consider fairness in the sense of equal opportunity: all points that are within distance r from the query should have the same probability to be returned. In the low-dimensional case, this problem was first studied by Hu, Qiao, and Tao (PODS 2014). Locality sensitive hashing (LSH), the theoretically strongest approach to similarity search in high dimensions, does not provide such a fairness guarantee. To address this, we propose efficient data structures for r-NN where all points in S that are near q have the same probability to be selected and returned by the query. Specifically, we first propose a black-box approach that, given any LSH scheme, constructs a data structure for uniformly sampling points in the neighborhood of a query. Then, we develop a data structure for fair similarity search under inner product that requires nearly-linear space and exploits locality sensitive filters. The paper concludes with an experimental evaluation that highlights (un)fairness in a recommendation setting on real-world datasets and discusses the inherent unfairness introduced by solving other variants of the problem."}}
{"id": "8wnWvrEn2jm", "cdate": 1672531200000, "mdate": 1681653088237, "content": {"title": "Simple Set Sketching", "abstract": ""}}
{"id": "XFCirHGr4Cs", "cdate": 1652737450249, "mdate": null, "content": {"title": "Improved Utility Analysis of Private CountSketch", "abstract": "Sketching is an important tool for dealing with high-dimensional vectors that are sparse (or well-approximated by a sparse vector), especially useful in distributed, parallel, and streaming settings.\nIt is known that sketches can be made differentially private by adding noise according to the sensitivity of the sketch, and this has been used in private analytics and federated learning settings.\nThe post-processing property of differential privacy implies that \\emph{all} estimates computed from the sketch can be released within the given privacy budget.\n\nIn this paper we consider the classical CountSketch, made differentially private with the Gaussian mechanism, and give an improved analysis of its estimation error.\nPerhaps surprisingly, the privacy-utility trade-off is essentially the best one could hope for, independent of the number of repetitions in CountSketch:\nThe error is almost identical to the error from non-private CountSketch plus the noise needed to make the vector private in the original, high-dimensional domain.\n"}}
{"id": "w8_RiR9HGTO", "cdate": 1640995200000, "mdate": 1681653088565, "content": {"title": "HyperLogLogLog: Cardinality Estimation With One Log More", "abstract": ""}}
{"id": "r_cCM40h8m", "cdate": 1640995200000, "mdate": 1681653088370, "content": {"title": "Improved Utility Analysis of Private CountSketch", "abstract": ""}}
{"id": "nRlZwpiJmy", "cdate": 1640995200000, "mdate": 1681653088498, "content": {"title": "Representing Sparse Vectors with Differential Privacy, Low Error, Optimal Space, and Fast Access", "abstract": ""}}
{"id": "fl4_CC5r_x", "cdate": 1640995200000, "mdate": 1681653090575, "content": {"title": "Infinitely Divisible Noise in the Low Privacy Regime", "abstract": ""}}
{"id": "Ukgdt15-Z3B", "cdate": 1640995200000, "mdate": 1681653088622, "content": {"title": "Sampling a Near Neighbor in High Dimensions - Who is the Fairest of Them All?", "abstract": ""}}
{"id": "UY_ju9RwT6Z", "cdate": 1640995200000, "mdate": 1681653088573, "content": {"title": "Sampling near neighbors in search for fairness", "abstract": ""}}
{"id": "RlAjfvJBR-", "cdate": 1640995200000, "mdate": 1681653090783, "content": {"title": "DEANN: Speeding up Kernel-Density Estimation using Approximate Nearest Neighbor Search", "abstract": ""}}
