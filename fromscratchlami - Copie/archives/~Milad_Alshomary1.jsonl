{"id": "o8_-QvbWGgM", "cdate": 1687866158230, "mdate": 1687866158230, "content": {"title": "Argument Novelty and Validity Assessment via Multitask and Transfer Learning", "abstract": "An argument is a constellation of premises reasoning towards a certain conclusion. The automatic generation of conclusions is becoming a very prominent task, raising the need for automatic measures to assess the quality of these generated conclusions. The SharedTask at the 9th Workshop on Argument Mining proposes a new task to assess the novelty and validity of a conclusion given a set of premises. In this paper, we present a multitask learning approach that transfers the knowledge learned from the natural language inference task to the tasks at hand. Evaluation results indicate the importance of both knowledge transfer and joint learning, placing our approach in the fifth place with strong results compared to baselines."}}
{"id": "loodGsl6KYL", "cdate": 1609459200000, "mdate": 1634124379849, "content": {"title": "Counter-Argument Generation by Attacking Weak Premises", "abstract": "Milad Alshomary, Shahbaz Syed, Arkajit Dhar, Martin Potthast, Henning Wachsmuth. Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021. 2021."}}
{"id": "htJl0nyaehL", "cdate": 1609459200000, "mdate": 1634124379778, "content": {"title": "Key Point Analysis via Contrastive Learning and Extractive Argument Summarization", "abstract": "Key point analysis is the task of extracting a set of concise and high-level statements from a given collection of arguments, representing the gist of these arguments. This paper presents our proposed approach to the Key Point Analysis shared task, collocated with the 8th Workshop on Argument Mining. The approach integrates two complementary components. One component employs contrastive learning via a siamese neural network for matching arguments to key points; the other is a graph-based extractive summarization model for generating key points. In both automatic and manual evaluation, our approach was ranked best among all submissions to the shared task."}}
{"id": "OGCAJRsxMHN", "cdate": 1609459200000, "mdate": 1634124379859, "content": {"title": "Belief-based Generation of Argumentative Claims", "abstract": "When engaging in argumentative discourse, skilled human debaters tailor claims to the beliefs of the audience, to construct effective arguments. Recently, the field of computational argumentation witnessed extensive effort to address the automatic generation of arguments. However, existing approaches do not perform any audience-specific adaptation. In this work, we aim to bridge this gap by studying the task of belief-based claim generation: Given a controversial topic and a set of beliefs, generate an argumentative claim tailored to the beliefs. To tackle this task, we model the people's prior beliefs through their stances on controversial topics and extend state-of-the-art text generation models to generate claims conditioned on the beliefs. Our automatic evaluation confirms the ability of our approach to adapt claims to a set of given beliefs. In a manual study, we additionally evaluate the generated claims in terms of informativeness and their likelihood to be uttered by someone with a respective belief. Our results reveal the limitations of modeling users' beliefs based on their stances, but demonstrate the potential of encoding beliefs into argumentative texts, laying the ground for future exploration of audience reach."}}
{"id": "IQxXglrgx0z", "cdate": 1609459200000, "mdate": 1634124379849, "content": {"title": "Toward audience-aware argument generation", "abstract": "The maturity of the computational argumentation field, demonstrated with the first live debate between a machine and a human,1 triggers a demanding question: how can we build argumentation technologies that bring people together? We believe that an important part of the answer is to include the audience\u2019s beliefs into the process."}}
{"id": "DyU4DtC46tD", "cdate": 1609459200000, "mdate": 1635850286816, "content": {"title": "Assessing the Sufficiency of Arguments through Conclusion Generation", "abstract": "The premises of an argument give evidence or other reasons to support a conclusion. However, the amount of support required depends on the generality of a conclusion, the nature of the individual premises, and similar. An argument whose premises make its conclusion rationally worthy to be drawn is called sufficient in argument quality research. Previous work tackled sufficiency assessment as a standard text classification problem, not modeling the inherent relation of premises and conclusion. In this paper, we hypothesize that the conclusion of a sufficient argument can be generated from its premises. To study this hypothesis, we explore the potential of assessing sufficiency based on the output of large-scale pre-trained language models. Our best model variant achieves an F1-score of .885, outperforming the previous state-of-the-art and being on par with human experts. While manual evaluation reveals the quality of the generated conclusions, their impact remains low ultimately."}}
{"id": "BUzlH1Edagr", "cdate": 1609459200000, "mdate": 1634124379966, "content": {"title": "Generating Informative Conclusions for Argumentative Texts", "abstract": "The purpose of an argumentative text is to support a certain conclusion. Yet, they are often omitted, expecting readers to infer them rather. While appropriate when reading an individual text, this rhetorical device limits accessibility when browsing many texts (e.g., on a search engine or on social media). In these scenarios, an explicit conclusion makes for a good candidate summary of an argumentative text. This is especially true if the conclusion is informative, emphasizing specific concepts from the text. With this paper we introduce the task of generating informative conclusions: First, Webis-ConcluGen-21 is compiled, a large-scale corpus of 136,996 samples of argumentative texts and their conclusions. Second, two paradigms for conclusion generation are investigated; one extractive, the other abstractive in nature. The latter exploits argumentative knowledge that augment the data via control codes and finetuning the BART model on several subsets of the corpus. Third, insights are provided into the suitability of our corpus for the task, the differences between the two generation paradigms, the trade-off between informativeness and conciseness, and the impact of encoding argumentative knowledge. The corpus, code, and the trained models are publicly available."}}
{"id": "8k4vg8lOV9I", "cdate": 1609459200000, "mdate": 1634124379849, "content": {"title": "Argument Undermining: Counter-Argument Generation by Attacking Weak Premises", "abstract": "Text generation has received a lot of attention in computational argumentation research as of recent. A particularly challenging task is the generation of counter-arguments. So far, approaches primarily focus on rebutting a given conclusion, yet other ways to counter an argument exist. In this work, we go beyond previous research by exploring argument undermining, that is, countering an argument by attacking one of its premises. We hypothesize that identifying the argument's weak premises is key to effective countering. Accordingly, we propose a pipeline approach that first assesses the premises' strength and then generates a counter-argument targeting the weak ones. On the one hand, both manual and automatic evaluation proves the importance of identifying weak premises in counter-argument generation. On the other hand, when considering correctness and content richness, human annotators favored our approach over state-of-the-art counter-argument generation."}}
{"id": "7tertXFrc-J", "cdate": 1609459200000, "mdate": 1634124379850, "content": {"title": "Generating Informative Conclusions for Argumentative Texts", "abstract": "Shahbaz Syed, Khalid Al Khatib, Milad Alshomary, Henning Wachsmuth, Martin Potthast. Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021. 2021."}}
{"id": "4zHEbnln5Ua", "cdate": 1609459200000, "mdate": 1634124379931, "content": {"title": "Belief-based Generation of Argumentative Claims", "abstract": "Milad Alshomary, Wei-Fan Chen, Timon Gurcke, Henning Wachsmuth. Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume. 2021."}}
