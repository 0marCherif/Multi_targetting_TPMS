{"id": "WgJhsOJ_cL", "cdate": 1609459200000, "mdate": 1682341772308, "content": {"title": "Fast Posterior Estimation of Cardiac Electrophysiological Model Parameters via Bayesian Active Learning", "abstract": ""}}
{"id": "ojSA_lerRuw", "cdate": 1577836800000, "mdate": null, "content": {"title": "Semi-supervised Medical Image Classification with Global Latent Mixing", "abstract": "Computer-aided diagnosis via deep learning relies on large-scale annotated data sets, which can be costly when involving expert knowledge. Semi-supervised learning (SSL) mitigates this challenge by leveraging unlabeled data. One effective SSL approach is to regularize the local smoothness of neural functions via perturbations around single data points. In this work, we argue that regularizing the global smoothness of neural functions by filling the void in between data points can further improve SSL. We present a novel SSL approach that trains the neural network on linear mixing of labeled and unlabeled data, at both the input and latent space in order to regularize different portions of the network. We evaluated the presented model on two distinct medical image data sets for semi-supervised classification of thoracic disease and skin lesion, demonstrating its improved performance over SSL with local perturbations and SSL with global mixing but at the input space only. Our code is available at https://github.com/Prasanna1991/LatentMixing ."}}
{"id": "MrkFyrAczqb", "cdate": 1577836800000, "mdate": null, "content": {"title": "Semi-supervised Medical Image Classification with Global Latent Mixing", "abstract": "Computer-aided diagnosis via deep learning relies on large-scale annotated data sets, which can be costly when involving expert knowledge. Semi-supervised learning (SSL) mitigates this challenge by leveraging unlabeled data. One effective SSL approach is to regularize the local smoothness of neural functions via perturbations around single data points. In this work, we argue that regularizing the global smoothness of neural functions by filling the void in between data points can further improve SSL. We present a novel SSL approach that trains the neural network on linear mixing of labeled and unlabeled data, at both the input and latent space in order to regularize different portions of the network. We evaluated the presented model on two distinct medical image data sets for semi-supervised classification of thoracic disease and skin lesion, demonstrating its improved performance over SSL with local perturbations and SSL with global mixing but at the input space only. Our code is available at https://github.com/Prasanna1991/LatentMixing."}}
{"id": "H9UPyBrLK8", "cdate": 1577836800000, "mdate": 1682341770527, "content": {"title": "Embedding high-dimensional Bayesian optimization via generative modeling: Parameter personalization of cardiac electrophysiological models", "abstract": ""}}
