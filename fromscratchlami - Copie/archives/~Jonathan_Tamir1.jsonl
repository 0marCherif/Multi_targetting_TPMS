{"id": "501viugsidI", "cdate": 1684298878843, "mdate": 1684298878843, "content": {"title": "Federated End-to-End Unrolled Models for Magnetic Resonance Image Reconstruction", "abstract": "Image reconstruction is the process of recovering an image from raw, under-sampled signal measurements, and is a critical step in diagnostic medical imaging, such as magnetic resonance imaging (MRI). Recently, data-driven methods have led to improved image quality in MRI reconstruction using a limited number of measurements, but these methods typically rely on the existence of a large, centralized database of fully sampled scans for training. In this work, we investigate federated learning for MRI reconstruction using end-to-end unrolled deep learning models as a means of training global models across multiple clients (data sites), while keeping individual scans local. We empirically identify a low-data regime across a large number of heterogeneous scans, where a small number of training samples per client are available and non-collaborative models lead to performance drops. In this regime, we investigate the performance of adaptive federated optimization algorithms as a function of client data distribution and communication budget. Experimental results show that adaptive optimization algorithms are well suited for the federated learning of unrolled models, even in a limited-data regime (50 slices per data site), and that client-sided personalization can improve reconstruction quality for clients that did not participate in training."}}
{"id": "P-9OcO2qFn", "cdate": 1684298760717, "mdate": 1684298760717, "content": {"title": "FSE Compensated Motion Correction for MRI Using Data Driven Methods", "abstract": "Magnetic Resonance Imaging (MRI) is a powerful medical imaging modality, but unfortunately suffers from long scan times which, aside from increasing operational costs, can lead to image artifacts due to patient motion. Motion during the acquisition leads to inconsistencies in measured data that manifest as blurring and ghosting if unaccounted for in the image reconstruction process. Various deep learning based reconstruction techniques have been proposed which decrease scan time by reducing the number of measurements needed for a high fidelity reconstructed image. Additionally, deep learning has been used to correct motion using end-to-end techniques. This, however, increases susceptibility to distribution shifts at test time (sampling pattern, motion level). In this work we propose a framework for jointly reconstructing highly sub-sampled MRI data while estimating patient motion using score-based generative models. Our method does not make specific assumptions on the sampling trajectory or motion pattern at training time and thus can be flexibly applied to various types of measurement models and patient motion. We demonstrate our framework on retrospectively accelerated 2D brain MRI corrupted by rigid motion."}}
{"id": "0jXTqlhcmj", "cdate": 1684298514030, "mdate": 1684298514030, "content": {"title": "Conditional Score-Based Reconstructions for Multi-contrast MRI", "abstract": "Magnetic resonance imaging (MRI) exam protocols consist of multiple contrast-weighted images of\nthe same anatomy to emphasize different tissue properties. Due to the long acquisition times required to\ncollect fully sampled k-space measurements, it is common to only collect a fraction of k-space for some,\nor all, of the scans and subsequently solve an inverse problem for each contrast to recover the desired\nimage from sub-sampled measurements. Recently, there has been a push to further accelerate MRI exams\nusing data-driven priors, and generative models in particular, to regularize the ill-posed inverse problem\nof image reconstruction. These methods have shown promising improvements over classical methods.\nHowever, many of the approaches neglect the multi-contrast nature of clinical MRI exams and treat each\nscan as an independent reconstruction. In this work we show that by learning a joint Bayesian prior over\nmulti-contrast data with a score-based generative model we are able to leverage the underlying structure\nbetween multi-contrast images and thus improve image reconstruction fidelity over generative models\nthat only reconstruct images of a single contrast."}}
{"id": "wPGvczhRBRS", "cdate": 1684295425428, "mdate": 1684295425428, "content": {"title": "Accelerated Motion Correction for MRI using Score-Based Generative Models", "abstract": "Magnetic Resonance Imaging (MRI) is a powerful medical imaging modality, but unfortunately suffers\nfrom long scan times which, aside from increasing operational costs, can lead to image artifacts due to\npatient motion. Motion during the acquisition leads to inconsistencies in measured data that manifest\nas blurring and ghosting if unaccounted for in the image reconstruction process. Various deep learning\nbased reconstruction techniques have been proposed which decrease scan time by reducing the number of\nmeasurements needed for a high fidelity reconstructed image. Additionally, deep learning has been used\nto correct motion using end-to-end techniques. This, however, increases susceptibility to distribution\nshifts at test time (sampling pattern, motion level). In this work we propose a framework for jointly reconstructing highly sub-sampled MRI data while estimating patient motion using score-based generative\nmodels. Our method does not make specific assumptions on the sampling trajectory or motion pattern\nat training time and thus can be flexibly applied to various types of measurement models and patient\nmotion. We demonstrate our framework on retrospectively accelerated 2D brain MRI corrupted by rigid\nmotion"}}
{"id": "Zf8YONn69J-", "cdate": 1681707885636, "mdate": 1681707885636, "content": {"title": "High Fidelity Deep Learning-based MRI Reconstruction with Instance-wise Discriminative Feature Matching Loss", "abstract": "Purpose: To improve reconstruction fidelity of fine structures and textures in deep learning (DL) based reconstructions.\nMethods: A novel patch-based Unsupervised Feature Loss (UFLoss) is proposed and incorporated into the training of DL-based reconstruction frameworks in order to preserve perceptual similarity and high-order statistics. The UFLoss provides instance-level discrimination by mapping similar instances to similar low-dimensional feature vectors and is trained without any human annotation. By adding an additional loss function on the low-dimensional feature space during training, the reconstruction frameworks from under-sampled or corrupted data can reproduce more realistic images that are closer to the original with finer textures, sharper edges, and improved overall image quality. The performance of the proposed UFLoss is demonstrated on unrolled networks for accelerated 2D and 3D knee MRI reconstruction with retrospective under-sampling. Quantitative metrics including NRMSE, SSIM, and our proposed UFLoss were used to evaluate the performance of the proposed method and compare it with others.\nResults: In-vivo experiments indicate that adding the UFLoss encourages sharper edges and more faithful contrasts compared to traditional and learning-based methods with pure l2 loss. More detailed textures can be seen in both 2D and 3D knee MR images. Quantitative results indicate that reconstruction with UFLoss can provide comparable NRMSE and a higher SSIM while achieving a much lower UFLoss value.\nConclusion: We present UFLoss, a patch-based unsupervised learned feature loss, which allows the training of DL-based reconstruction to obtain more detailed texture, finer features, and sharper edges with higher overall image quality under DL-based reconstruction frameworks."}}
{"id": "dguP0S3s5Gp", "cdate": 1681707658591, "mdate": 1681707658591, "content": {"title": "Implicit data crimes: Machine learning bias arising from misuse of public data", "abstract": "Although open databases are an important resource in the current deep learning (DL) era, they are sometimes used \u201coff label\u201d: Data published for one task are used to train algorithms for a different one. This work aims to highlight that this common practice may lead to biased, overly optimistic results. We demonstrate this phenomenon for inverse problem solvers and show how their biased performance stems from hidden data-processing pipelines. We describe two processing pipelines typical of open-access databases and study their effects on three well-established algorithms developed for MRI reconstruction: compressed sensing, dictionary learning, and DL. Our results demonstrate that all these algorithms yield systematically biased results when they are naively trained on seemingly appropriate data: The normalized RMS error improves consistently with the extent of data processing, showing an artificial improvement of 25 to 48% in some cases. Because this phenomenon is not widely known, biased results sometimes are published as state-of-the-art; we refer to that as implicit \u201cdata crimes.\u201dThis work hence aims to raise awareness regarding naive off-label usage of big data and reveal the vulnerability of modern inverse problem solvers to the resulting bias."}}
{"id": "dxTivou2h-", "cdate": 1681707459339, "mdate": 1681707459339, "content": {"title": "High-fidelity Direct Contrast Synthesis from Magnetic Resonance Fingerprinting", "abstract": "Magnetic Resonance Fingerprinting (MRF) is an efficient quantitative MRI technique that can extract important tissue and system parameters such as T1, T2, B0, and B1 from a single scan. This property also makes it attractive for retrospectively synthesizing contrast-weighted images. In general, contrast-weighted images like T1-weighted, T2-weighted, etc., can be synthesized directly from parameter maps through spin-dynamics simulation (i.e., Bloch or Extended Phase Graph models). However, these approaches often exhibit artifacts due to imperfections in the mapping, the sequence modeling, and the data acquisition. Here we propose a supervised learning-based method that directly synthesizes contrast-weighted images from the MRF data without going through the quantitative mapping and spin-dynamics simulation. To implement our direct contrast synthesis (DCS) method, we deploy a conditional Generative Adversarial Network (GAN) framework and propose a multi-branch U-Net as the generator. The input MRF data are used to directly synthesize T1-weighted, T2-weighted, and fluid-attenuated inversion recovery (FLAIR) images through supervised training on paired MRF and target spin echo-based contrast-weighted scans. In-vivo experiments demonstrate excellent image quality compared to simulation-based contrast synthesis and previous DCS methods, both visually as well as by quantitative metrics. We also demonstrate cases where our trained model is able to mitigate in-flow and spiral off-resonance artifacts that are typically seen in MRF reconstructions and thus more faithfully represent conventional spin echo-based contrast-weighted images."}}
{"id": "c7r_8FBm4Ck", "cdate": 1681706732063, "mdate": 1681706732063, "content": {"title": "Memory-efficient Learning for High-Dimensional MRI Reconstruction", "abstract": "Deep learning (DL) based unrolled reconstructions have shown state-of-the-art performance for under-sampled magnetic resonance imaging (MRI). Similar to compressed sensing, DL can leverage high-dimensional data (e.g. 3D, 2D+time, 3D+time) to further improve performance. However, network size and depth are currently limited by the GPU memory required for backpropagation. Here we use a memory-efficient learning (MEL) framework which favorably trades off storage with a manageable increase in computation during training. Using MEL with multi-dimensional data, we demonstrate improved image reconstruction performance for in-vivo 3D MRI and 2D+time cardiac cine MRI. MEL uses far less GPU memory while marginally increasing the training time, which enables new applications of DL to high-dimensional MRI."}}
{"id": "SNeLAhVuDZ9", "cdate": 1646916790369, "mdate": null, "content": {"title": "Score-Based Generative Models for Wireless Channel Modeling and Estimation", "abstract": "In this work, we investigate score-based models for learning the distribution of multiple-input multiple-output (MIMO) wireless channels in structured stochastic environments, using either clean or corrupted (noisy) data for training. We find that score-based models are capable of generating high-quality synthetic channels, and have robust downstream estimation performance, sometimes surpassing strong baselines by up to $10$ dB in estimation error, when the inverse problem is ill-posed. Our preliminary results on training with corrupted data show improved performance against simple baselines, and introduce a very promising future research direction. Code will be made publicly available upon paper acceptance."}}
{"id": "xgo5Tq1Y89v", "cdate": 1640995200000, "mdate": 1680541287526, "content": {"title": "MIMO Channel Estimation using Score-Based Generative Models", "abstract": ""}}
