{"id": "MIeLXW6nbU", "cdate": 1668518821270, "mdate": 1668518821270, "content": {"title": "MVOR: A multi-view RGB-D operating room dataset for 2D and 3D human pose estimation", "abstract": "Person detection and pose estimation is a key requirement to develop intelligent context-aware assistance systems. To foster the development of human pose estimation methods and their applications in the Operating Room (OR), we release the Multi-View Operating Room (MVOR) dataset, the first public dataset recorded during real clinical interventions. It consists of 732 synchronized multi-view frames recorded by three RGB-D cameras in a hybrid OR. It also includes the visual challenges present in such environments, such as occlusions and clutter. We provide camera calibration parameters, color and depth frames, human bounding boxes, and 2D/3D pose annotations. In this paper, we present the dataset, its annotations, as well as baseline results from several recent person detection and 2D/3D pose estimation methods. Since we need to blur some parts of the images to hide identity and nudity in the released dataset, we also present a comparative study of how the baselines have been impacted by the blurring. Results show a large margin for improvement and suggest that the MVOR dataset can be useful to compare the performance of the different methods."}}
{"id": "CwdCf8jafg3", "cdate": 1668518735027, "mdate": 1668518735027, "content": {"title": "Face detection in the operating room: Comparison of state-of-the-art methods and a self-supervised approach", "abstract": "Purpose: Face detection is a needed component for the automatic\nanalysis and assistance of human activities during surgical procedures. Efficient\nface detection algorithms can indeed help to detect and identify the persons\npresent in the room, and also be used to automatically anonymize the data.\nHowever, current algorithms trained on natural images do not generalize well\nto the operating room (OR) images. In this work, we provide a comparison\nof state-of-the-art face detectors on OR data and also present an approach to\ntrain a face detector for the OR by exploiting non-annotated OR images.\nMethods: We propose a comparison of 6 state-of-the-art face detectors on clinical\ndata using Multi-View Operating Room Faces (MVOR-Faces), a dataset of\noperating room images capturing real surgical activities. We then propose to\nuse self-supervision, a domain adaptation method, for the task of face detection\nin the OR. The approach makes use of non-annotated images to fine-tune a\nstate-of-the-art detector for the OR without using any human supervision.\nResults: The results show that the best model, namely the tiny face detector,\nyields an average precision of 0.556 at Intersection over Union (IoU) of 0.5.\nOur self-supervised model using non-annotated clinical data outperforms this\nresult by 9.2%.\nConclusion: We present the first comparison of state-of-the-art face detectors\non operating room images and show that results can be significantly improved\nby using self-supervision on non-annotated data"}}
{"id": "qOV5REmPOM", "cdate": 1663849989038, "mdate": null, "content": {"title": "On the optimal precision of GANs", "abstract": "Generative adversarial networks (GANs) are known to face model misspecification when learning disconnected distributions. Indeed, continuous mapping from a unimodal latent distribution to a disconnected one is impossible, so GANs necessarily generate samples outside of the support of the target distribution. In this paper, we make the connection between the performance of GANs and their latent space configuration. In particular, we raise the following question: what is the latent space partition that minimizes the measure of out-of-manifold samples? Building on a recent result of geometric measure theory, we prove there exist optimal GANs when the dimension of the latent space is larger than the number of modes. In particular, we show that these generators structure their latent space as a `simplicial cluster' - a Voronoi partition where centers are equally distant.  We derive both an upper and a lower bound on the optimal precision of GANs learning disconnected manifolds. Interestingly, these two bounds have the same order of decrease: $\\sqrt{\\log m}$, $m$ being the number of modes. Finally, we perform several experiments to exhibit the geometry of the latent space and experimentally show that GANs have a geometry with similar properties to the theoretical one."}}
{"id": "HbTsJRaphE", "cdate": 1640995200000, "mdate": 1672737430042, "content": {"title": "Optimal precision for GANs", "abstract": ""}}
{"id": "0wqVwk2y_jB", "cdate": 1640995200000, "mdate": 1668072149006, "content": {"title": "Latent reweighting, an almost free improvement for GANs", "abstract": "Standard formulations of GANs, where a continuous function deforms a connected latent space, have been shown to be misspecified when fitting different classes of images. In particular, the generator will necessarily sample some low-quality images in between the classes. Rather than modifying the architecture, a line of works aims at improving the sampling quality from pre-trained generators at the expense of increased computational cost. Building on this, we introduce an additional network to predict latent importance weights and two associated sampling methods to avoid the poorest samples. This idea has several advantages: 1) it provides a way to inject disconnectedness into any GAN architecture, 2) since the rejection happens in the latent space, it avoids going through both the generator and the discriminator, saving computation time, 3) this importance weights formulation provides a principled way to reduce the Wasserstein\u2019s distance to the target distribution. We demonstrate the effectiveness of our method on several datasets, both synthetic and high-dimensional."}}
{"id": "Iyr8yvU-Jt", "cdate": 1609459200000, "mdate": 1672737430029, "content": {"title": "EdiBERT, a generative model for image editing", "abstract": ""}}
{"id": "EaqecFCYRkl", "cdate": 1609459200000, "mdate": 1672737430087, "content": {"title": "Latent reweighting, an almost free improvement for GANs", "abstract": ""}}
{"id": "nxJ8ugF24q2", "cdate": 1601308062473, "mdate": null, "content": {"title": "Learning Disconnected Manifolds: Avoiding The No Gan's Land by Latent Rejection", "abstract": "Standard formulations of GANs, where a continuous function deforms a connected latent space, have been shown to be misspecified when fitting disconnected manifolds. In particular, when covering different classes of images, the generator will necessarily sample some low quality images in between the modes. Rather than modify the learning procedure, a line of works aims at improving the sampling quality from trained generators. Thus, it is now common to introduce a rejection step within the generation procedure.\nBuilding on this, we propose to train an additional network and transform the latent space via an adversarial learning of importance weights. This idea has several advantages: 1) it provides a way to inject disconnectedness on any GAN architecture, 2) the rejection avoids going through both the generator and the discriminator saving computation time, 3) this importance weights formulation provides a principled way to estimate the Wasserstein's distance to the true distribution, enabling its minimization. We demonstrate the effectiveness of our method on different datasets, both synthetic and high dimensional, and stress its superiority on highly disconnected data."}}
{"id": "sxsaMoMHdG", "cdate": 1577836800000, "mdate": 1672737430061, "content": {"title": "Learning disconnected manifolds: a no GAN's land", "abstract": ""}}
{"id": "krt0W9M3Rtu", "cdate": 1577836800000, "mdate": 1649229135776, "content": {"title": "Do Not Mask What You Do Not Need to Mask: A Parser-Free Virtual Try-On", "abstract": "The 2D virtual try-on task has recently attracted a great interest from the research community, for its direct potential applications in online shopping as well as for its inherent and non-addressed scientific challenges. This task requires fitting an in-shop cloth image on the image of a person, which is highly challenging because it involves cloth warping, image compositing, and synthesizing. Casting virtual try-on into a supervised task faces a difficulty: available datasets are composed of pairs of pictures (cloth, person wearing the cloth). Thus, we have no access to ground-truth when the cloth on the person changes. State-of-the-art models solve this by masking the cloth information on the person with both a human parser and a pose estimator. Then, image synthesis modules are trained to reconstruct the person image from the masked person image and the cloth image. This procedure has several caveats: firstly, human parsers are prone to errors; secondly, it is a costly pre-processing step, which also has to be applied at inference time; finally, it makes the task harder than it is since the mask covers information that should be kept such as hands or accessories. In this paper, we propose a novel student-teacher paradigm where the teacher is trained in the standard way (reconstruction) before guiding the student to focus on the initial task (changing the cloth). The student additionally learns from an adversarial loss, which pushes it to follow the distribution of the real images. Consequently, the student exploits information that is masked to the teacher. A student trained without the adversarial loss would not use this information. Also, getting rid of both human parser and pose estimator at inference time allows obtaining a real-time virtual try-on."}}
