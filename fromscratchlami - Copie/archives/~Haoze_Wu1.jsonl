{"id": "hVAK0cgiWrU", "cdate": 1661329137220, "mdate": null, "content": {"title": "Toward Certified Robustness Against Real-World Distribution Shifts", "abstract": "We consider the problem of certifying the robustness of deep neural networks against real-world distribution shifts.  To do so, we bridge the gap between hand-crafted specifications and realistic deployment settings by considering a neural-symbolic verification framework in which generative models are trained to learn perturbations from data and specifications are defined with respect to the output of these learned models.  A pervasive challenge arising from this setting is that although S-shaped activations (e.g., sigmoid, tanh) are common in the last layer of deep generative models, existing verifiers cannot tightly approximate S-shaped activations.  To address this challenge, we propose a general meta-algorithm for handling S-shaped activations which leverages classical notions of counter-example-guided abstraction refinement. The key idea is to ``lazily'' refine the abstraction of S-shaped functions to exclude spurious counter-examples found in the previous abstraction, thus guaranteeing progress in the verification process while keeping the state-space small.  For networks with sigmoid activations, we show that our technique outperforms state-of-the-art verifiers on certifying robustness against both canonical adversarial perturbations and numerous real-world distribution shifts.  Furthermore, experiments on the MNIST and CIFAR-10 datasets show that distribution-shift-aware algorithms have significantly higher certified robustness against distribution shifts."}}
{"id": "x2nYcpb8rkB", "cdate": 1609459200000, "mdate": null, "content": {"title": "An SMT-Based Approach for Verifying Binarized Neural Networks", "abstract": "Deep learning has emerged as an effective approach for creating modern software systems, with neural networks often surpassing hand-crafted systems. Unfortunately, neural networks are known to suffer from various safety and security issues. Formal verification is a promising avenue for tackling this difficulty, by formally certifying that networks are correct. We propose an SMT-based technique for verifying binarized neural networks \u2014 a popular kind of neural network, where some weights have been binarized in order to render the neural network more memory and energy efficient, and quicker to evaluate. One novelty of our technique is that it allows the verification of neural networks that include both binarized and non-binarized components. Neural network verification is computationally very difficult, and so we propose here various optimizations, integrated into our SMT procedure as deduction steps, as well as an approach for parallelizing verification queries. We implement our technique as an extension to the Marabou framework, and use it to evaluate the approach on popular binarized neural network architectures."}}
{"id": "ivtFR-wAiiG", "cdate": 1609459200000, "mdate": null, "content": {"title": "DeepCert: Verification of Contextually Relevant Robustness for Neural Network Image Classifiers", "abstract": "We introduce DeepCert, a tool-supported method for verifying the robustness of deep neural network (DNN) image classifiers to contextually relevant perturbations such as blur, haze, and changes in image contrast. While the robustness of DNN classifiers has been the subject of intense research in recent years, the solutions delivered by this research focus on verifying DNN robustness to small perturbations in the images being classified, with perturbation magnitude measured using established Lp norms. This is useful for identifying potential adversarial attacks on DNN image classifiers, but cannot verify DNN robustness to contextually relevant image perturbations, which are typically not small when expressed with Lp norms. DeepCert addresses this underexplored verification problem by supporting:(1) the encoding of real-world image perturbations; (2) the systematic evaluation of contextually relevant DNN robustness, using both testing and formal verification; (3) the generation of contextually relevant counterexamples; and, through these, (4) the selection of DNN image classifiers suitable for the operational context (i)envisaged when a potentially safety-critical system is designed, or (ii)observed by a deployed system. We demonstrate the effectiveness of DeepCert by showing how it can be used to verify the robustness of DNN image classifiers build for two benchmark datasets (`German Traffic Sign' and `CIFAR-10') to multiple contextually relevant perturbations."}}
{"id": "nqloLaxjwk", "cdate": 1577836800000, "mdate": null, "content": {"title": "Global Optimization of Objective Functions Represented by ReLU Networks", "abstract": "Neural networks can learn complex, non-convex functions, and it is challenging to guarantee their correct behavior in safety-critical contexts. Many approaches exist to find failures in networks (e.g., adversarial examples), but these cannot guarantee the absence of failures. Verification algorithms address this need and provide formal guarantees about a neural network by answering \"yes or no\" questions. For example, they can answer whether a violation exists within certain bounds. However, individual \"yes or no\" questions cannot answer qualitative questions such as \"what is the largest error within these bounds\"; the answers to these lie in the domain of optimization. Therefore, we propose strategies to extend existing verifiers to perform optimization and find: (i) the most extreme failure in a given input region and (ii) the minimum input perturbation required to cause a failure. A naive approach using a bisection search with an off-the-shelf verifier results in many expensive and overlapping calls to the verifier. Instead, we propose an approach that tightly integrates the optimization process into the verification procedure, achieving better runtime performance than the naive approach. We evaluate our approach implemented as an extension of Marabou, a state-of-the-art neural network verifier, and compare its performance with the bisection approach and MIPVerify, an optimization-based verifier. We observe complementary performance between our extension of Marabou and MIPVerify."}}
{"id": "c4BSCGy5Sj", "cdate": 1577836800000, "mdate": null, "content": {"title": "Parallelization Techniques for Verifying Neural Networks", "abstract": "128"}}
{"id": "_CYsktPnFZH", "cdate": 1577836800000, "mdate": null, "content": {"title": "An SMT-Based Approach for Verifying Binarized Neural Networks", "abstract": "Deep learning has emerged as an effective approach for creating modern software systems, with neural networks often surpassing hand-crafted systems. Unfortunately, neural networks are known to suffer from various safety and security issues. Formal verification is a promising avenue for tackling this difficulty, by formally certifying that networks are correct. We propose an SMT-based technique for verifying Binarized Neural Networks - a popular kind of neural network, where some weights have been binarized in order to render the neural network more memory and energy efficient, and quicker to evaluate. One novelty of our technique is that it allows the verification of neural networks that include both binarized and non-binarized components. Neural network verification is computationally very difficult, and so we propose here various optimizations, integrated into our SMT procedure as deduction steps, as well as an approach for parallelizing verification queries. We implement our technique as an extension to the Marabou framework, and use it to evaluate the approach on popular binarized neural network architectures."}}
{"id": "YzkR65Bj6u4", "cdate": 1577836800000, "mdate": null, "content": {"title": "Parallelization Techniques for Verifying Neural Networks", "abstract": "Inspired by recent successes with parallel optimization techniques for solving Boolean satisfiability, we investigate a set of strategies and heuristics that aim to leverage parallel computing to improve the scalability of neural network verification. We introduce an algorithm based on partitioning the verification problem in an iterative manner and explore two partitioning strategies, that work by partitioning the input space or by case splitting on the phases of the neuron activations, respectively. We also introduce a highly parallelizable pre-processing algorithm that uses the neuron activation phases to simplify the neural network verification problems. An extensive experimental evaluation shows the benefit of these techniques on both existing benchmarks and new benchmarks from the aviation domain. A preliminary experiment with ultra-scaling our algorithm using a large distributed cloud-based platform also shows promising results."}}
{"id": "ByeZlBBeUB", "cdate": 1567802601314, "mdate": null, "content": {"title": "G2SAT: Learning to Generate SAT Formulas", "abstract": "The Boolean Satisfiability (SAT) problem is the canonical NP-complete problem that is fundamental to Computer Science, with a wide array of applications in planning, verification, and theorem proving. Developing and evaluating practical SAT solvers relies on extensive empirical testing on a set of real-world benchmark formulas. However, the number of such real-world SAT formulas is limited, and while augmenting benchmark formulas via synthetic SAT formulas is possible, existing approaches are heavily hand-crafted and cannot simultaneously capture a wide range of characteristics of real-world SAT formulas. Here we present G2SAT, the first deep generative framework that learns to generate SAT formulas from a given set of input formulas. Our key insight is that SAT formulas can be transformed into latent bipartite graph representations which can be modeled using specialized deep generative models for graphs. The core of G2SAT is a novel deep generative model for bipartite graphs, which generates graphs via iterative node merging operations. We show that G2SAT can generate SAT formulas that closely resemble given industrial SAT formulas, as measured by both graph metrics and SAT solver behavior. Furthermore, we show that our synthetic SAT formulas can be used to improve SAT-solver performance on real-world benchmarks, which opens up new opportunities for the continued development of SAT-solvers and a deeper understanding of their performance."}}
{"id": "wUSmEBttLmO", "cdate": 1546300800000, "mdate": null, "content": {"title": "The Marabou Framework for Verification and Analysis of Deep Neural Networks", "abstract": "Deep neural networks are revolutionizing the way complex systems are designed. Consequently, there is a pressing need for tools and techniques for network analysis and certification. To help in addressing that need, we present Marabou, a framework for verifying deep neural networks. Marabou is an SMT-based tool that can answer queries about a network\u2019s properties by transforming these queries into constraint satisfaction problems. It can accommodate networks with different activation functions and topologies, and it performs high-level reasoning on the network that can curtail the search space and improve performance. It also supports parallel execution to further enhance scalability. Marabou accepts multiple input formats, including protocol buffer files generated by the popular TensorFlow framework for neural networks. We describe the system architecture and main components, evaluate the technique and discuss ongoing work."}}
{"id": "d1lcqp0LKLw", "cdate": 1546300800000, "mdate": null, "content": {"title": "Learning to Generate Industrial SAT Instances", "abstract": "In this paper, we present Satgen, the first implicit generative model of real-world Boolean Satisfiability (SAT) formulas. Our approach uses unsupervised machine learning techniques to generate new formulas by mimicking the structural properties of a given input formula Phi. We proceed in two phases: first, we construct the Literal-Incidence Graph (LIG) of Phi. This is used by a Generative Adversarial Network (GAN) to generate new LIGs that exhibit graph-theoretic properties similar to those of the LIG of Phi. In the second phase, we extract a formula whose LIG would correspond to the generated graph. We show that generating such a formula is equivalent to finding a minimal clique edge cover of the given graph, which we tackle efficiently using a greedy hill-climbing algorithm. We verify experimentally that our approach generates formulas that closely resemble a given real-world SAT instance, as measured by a range of different metrics."}}
