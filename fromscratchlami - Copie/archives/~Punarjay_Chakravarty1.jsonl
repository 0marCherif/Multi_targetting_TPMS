{"id": "yp9B8mV2RBy", "cdate": 1696005368174, "mdate": 1696005368174, "content": {"title": "Look Both Ways: Bidirectional Visual Sensing for Automatic Multi-Camera Registration", "abstract": "This work describes the automatic registration of\na large network (\u2248 40) of fixed, ceiling-mounted environment\ncameras spread over a large area (\u2248 800 m2) using a mobile\ncalibration robot equipped with a single upward-facing fisheye\ncamera and a backlit ArUco marker for easy detection. The\nfisheye camera is used to do visual odometry (VO), and the\nArUco marker facilitates easy detection of the calibration robot\nin the environment cameras. In addition, the fisheye camera is\nalso able to detect the environment cameras. This two-way,\nbidirectional detection constrains the pose of the environment\ncameras to solve an optimization problem. Such an approach\ncan be used to automatically register a large-scale multi-camera\nsystem used for surveillance, automated parking, or robotic\napplications. This VO based multi-camera registration method\nhas been extensively validated using real-world experiments,\nand also compared against a similar approach which uses a\nLiDAR - an expensive, heavier and power hungry sensor."}}
{"id": "3Df4Bt6rpyc", "cdate": 1680307200000, "mdate": 1695368606769, "content": {"title": "Kinematics Design of a MacPherson Suspension Architecture Based on Bayesian Optimization", "abstract": "Engineering design is traditionally performed by hand: an expert makes design proposals based on past experience, and these proposals are then tested for compliance with certain target specifications. Testing for compliance is performed first by computer simulation using what is called a discipline model. Such a model can be implemented by finite element analysis, multibody systems approach, etc. Designs passing this simulation are then considered for physical prototyping. The overall process may take months and is a significant cost in practice. We have developed a Bayesian optimization (BO) system for partially automating this process by directly optimizing compliance with the target specification with respect to the design parameters. The proposed method is a general framework for computing the generalized inverse of a high-dimensional nonlinear function that does not require, for example, gradient information, which is often unavailable from discipline models. We furthermore develop a three-tier convergence criterion based on: 1) convergence to a solution optimally satisfying all specified design criteria; 2) detection that a design satisfying all criteria is infeasible; or 3) convergence to a probably approximately correct (PAC) solution. We demonstrate the proposed approach on benchmark functions and a vehicle chassis design problem motivated by an industry setting using a state-of-the-art commercial discipline model. We show that the proposed approach is general, scalable, and efficient and that the novel convergence criteria can be implemented straightforwardly based on the existing concepts and subroutines in popular BO software packages."}}
{"id": "v6ar0_B4iQ_Z", "cdate": 1672531200000, "mdate": 1696005460328, "content": {"title": "Ref-DVGO: Reflection-Aware Direct Voxel Grid Optimization for an Improved Quality-Efficiency Trade-Off in Reflective Scene Reconstruction", "abstract": "Neural Radiance Fields (NeRFs) have revolutionized the field of novel view synthesis, demonstrating remarkable performance. However, the modeling and rendering of reflective objects remain challenging problems. Recent methods have shown significant improvements over the baselines in handling reflective scenes, albeit at the expense of efficiency. In this work, we aim to strike a balance between efficiency and quality. To this end, we investigate an implicit-explicit approach based on conventional volume rendering to enhance the reconstruction quality and accelerate the training and rendering processes. We adopt an efficient density-based grid representation and reparameterize the reflected radiance in our pipeline. Our proposed reflection-aware approach achieves a competitive quality efficiency trade-off compared to competing methods. Based on our experimental results, we propose and discuss hypotheses regarding the factors influencing the results of density-based methods for reconstructing reflective objects. The source code is available at https://github.com/gkouros/ref-dvgo."}}
{"id": "v5163ohWuK1", "cdate": 1672531200000, "mdate": 1696005460206, "content": {"title": "Locking On: Leveraging Dynamic Vehicle-Imposed Motion Constraints to Improve Visual Localization", "abstract": "Most 6-DoF localization and SLAM systems use static landmarks but ignore dynamic objects because they cannot be usefully incorporated into a typical pipeline. Where dynamic objects have been incorporated, typical approaches have attempted relatively sophisticated identification and localization of these objects, limiting their robustness or general utility. In this research, we propose a middle ground, demonstrated in the context of autonomous vehicles, using dynamic vehicles to provide limited pose constraint information in a 6-DoF frame-by-frame PnP-RANSAC localization pipeline. We refine initial pose estimates with a motion model and propose a method for calculating the predicted quality of future pose estimates, triggered based on whether or not the autonomous vehicle's motion is constrained by the relative frame-to-frame location of dynamic vehicles in the environment. Our approach detects and identifies suitable dynamic vehicles to define these pose constraints to modify a pose filter, resulting in improved recall across a range of localization tolerances from $0.25m$ to $5m$, compared to a state-of-the-art baseline single image PnP method and its vanilla pose filtering. Our constraint detection system is active for approximately $35\\%$ of the time on the Ford AV dataset and localization is particularly improved when the constraint detection is active."}}
{"id": "_fkQxsl4VE", "cdate": 1672531200000, "mdate": 1696005460279, "content": {"title": "RADIANT: Radar-Image Association Network for 3D Object Detection", "abstract": "As a direct depth sensor, radar holds promise as a tool to improve monocular 3D object detection, which suffers from depth errors, due in part to the depth-scale ambiguity. On the other hand, leveraging radar depths is hampered by difficulties in precisely associating radar returns with 3D estimates from monocular methods, effectively erasing its benefits. This paper proposes a fusion network that addresses this radar-camera association challenge. We train our network to predict the 3D offsets between radar returns and object centers, enabling radar depths to enhance the accuracy of 3D monocular detection. By using parallel radar and camera backbones, our network fuses information at both the feature level and detection level, while at the same time leveraging a state-of-the-art monocular detection technique without retraining it. Experimental results show significant improvement in mean average precision and translation error on the nuScenes dataset over monocular counterparts. Our source code is available at https://github.com/longyunf/radiant."}}
{"id": "L58jSjpsO9A", "cdate": 1672531200000, "mdate": 1696005460331, "content": {"title": "DisPlacing Objects: Improving Dynamic Vehicle Detection via Visual Place Recognition under Adverse Conditions", "abstract": "Can knowing where you are assist in perceiving objects in your surroundings, especially under adverse weather and lighting conditions? In this work we investigate whether a prior map can be leveraged to aid in the detection of dynamic objects in a scene without the need for a 3D map or pixel-level map-query correspondences. We contribute an algorithm which refines an initial set of candidate object detections and produces a refined subset of highly accurate detections using a prior map. We begin by using visual place recognition (VPR) to retrieve a reference map image for a given query image, then use a binary classification neural network that compares the query and mapping image regions to validate the query detection. Once our classification network is trained, on approximately 1000 query-map image pairs, it is able to improve the performance of vehicle detection when combined with an existing off-the-shelf vehicle detector. We demonstrate our approach using standard datasets across two cities (Oxford and Zurich) under different settings of train-test separation of map-query traverse pairs. We further emphasize the performance gains of our approach against alternative design choices and show that VPR suffices for the task, eliminating the need for precise ground truth localization."}}
{"id": "baPSNvcWUm", "cdate": 1668644247880, "mdate": 1668644247880, "content": {"title": "Deflating dataset bias using synthetic data augmentation", "abstract": "DeepLearning has seen an unprecedented increase in vision applications since the publication of large-scale object recognition datasets and introduction of scalable compute hardware. State-of-the-art methods for most vision tasks for Autonomous Vehicles (AVs) rely on supervised learning and often fail to generalize to domain shifts and/or outliers. Dataset diversity is thus key to successful real-world deployment. No matter how big the size of the dataset, capturing long tails of the distribution pertaining to task-specific environmental factors is impractical. The goal of this paper is to investigate the use of targeted synthetic data augmentation- combining the benefits of gaming engine simulations and sim2real style transfer techniques- for filling gaps in real datasets for vision tasks. Empirical studies on three different computer vision tasks of practical use to AVsparking slot detection, lane detection and monocular depth estimation consistently show that having synthetic data in the training mix provides a significant boost in cross-dataset generalization performance as compared to training on real data only, for the same size of the training set"}}
{"id": "SWeaMNSSlc", "cdate": 1645724692593, "mdate": 1645724692593, "content": {"title": "Full-Velocity Radar Returns by Radar-Camera Fusion", "abstract": "A distinctive feature of Doppler radar is the measurement of velocity in the radial direction for radar points. However, the missing tangential velocity component hampers object velocity estimation as well as temporal integration of radar sweeps in dynamic scenes. Recognizing that\nfusing camera with radar provides complementary information to radar, in this paper we present a closed-form solution for the point-wise, full-velocity estimate of Doppler returns using the corresponding optical flow from camera images. Additionally, we address the association problem between radar returns and camera images with a neural network that is trained to estimate radar-camera correspondences. Experimental results on the nuScenes dataset verify the validity of the method and show significant improvements over the state-of-the-art in velocity estimation and accumulation of radar points."}}
{"id": "v49_x3KV0tc", "cdate": 1640995200000, "mdate": 1663769133422, "content": {"title": "Designing MacPherson Suspension Architectures using Bayesian Optimization", "abstract": "Engineering design is traditionally performed by hand: an expert makes design proposals based on past experience, and these proposals are then tested for compliance with certain target specifications. Testing for compliance is performed first by computer simulation using what is called a discipline model. Such a model can be implemented by a finite element analysis, multibody systems approach, etc. Designs passing this simulation are then considered for physical prototyping. The overall process may take months, and is a significant cost in practice. We have developed a Bayesian optimization system for partially automating this process by directly optimizing compliance with the target specification with respect to the design parameters. The proposed method is a general framework for computing a generalized inverse of a high-dimensional non-linear function that does not require e.g. gradient information, which is often unavailable from discipline models. We furthermore develop a two-tier convergence criterion based on (i) convergence to a solution optimally satisfying all specified design criteria, or (ii) convergence to a minimum-norm solution. We demonstrate the proposed approach on a vehicle chassis design problem motivated by an industry setting using a state-of-the-art commercial discipline model. We show that the proposed approach is general, scalable, and efficient, and that the novel convergence criteria can be implemented straightforwardly based on existing concepts and subroutines in popular Bayesian optimization software packages."}}
{"id": "qdPnNjLf3e8", "cdate": 1640995200000, "mdate": 1696005460299, "content": {"title": "Localization of a Smart Infrastructure Fisheye Camera in a Prior Map for Autonomous Vehicles", "abstract": "This work presents a technique for localization of a smart infrastructure node, consisting of a fisheye camera, in a prior map. These cameras can detect objects that are outside the line of sight of the autonomous vehicles (AV) and send that information to AVs using V2X technology. However, in order for this information to be of any use to the AV, the detected objects should be provided in the reference frame of the prior map that the AV uses for its own navigation. Therefore, it is important to know the accurate pose of the infrastructure camera with respect to the prior map. Here we propose to solve this localization problem in two steps, (i) we perform feature matching between perspective projection of fisheye image and bird's eye view (BEV) satellite imagery from the prior map to estimate an initial camera pose, (ii) we refine the initialization by maximizing the Mutual Information (MI) between intensity of pixel values of fisheye image and reflectivity of 3D LiDAR points in the map data. We validate our method on simulated data and also present results with real world data."}}
