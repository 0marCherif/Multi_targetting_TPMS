{"id": "UxX8OpSYcac", "cdate": 1693828094809, "mdate": 1693828094809, "content": {"title": "Unsupervised Abstract Reasoning for Raven's Problem Matrices", "abstract": "Raven's Progressive Matrices (RPM) is highly correlated with human intelligence, and it has been widely used to measure the abstract reasoning ability of humans. In this paper, to study the abstract reasoning capability of deep neural networks, we propose the first unsupervised learning method for solving RPM problems. \nSince the ground truth labels are not allowed, we design a pseudo target based on the prior constraints of the RPM formulation to approximate the ground-truth label, which effectively converts the unsupervised learning strategy into a supervised one. \nHowever, the correct answer is wrongly labelled by the pseudo target, and thus the noisy contrast will lead to inaccurate model training. To alleviate this issue, we propose to improve the model performance with negative answers.\nMoreover, we develop a decentralization method to adapt the feature representation to different RPM problems. Extensive experiments on three datasets demonstrate that our method even outperforms some of the supervised approaches. Our code is available at {\\color{magenta} https://github.com/visiontao/ncd}."}}
{"id": "EkkQHecJ9zl", "cdate": 1693827943497, "mdate": 1693827943497, "content": {"title": "DIOT: Detecting Implicit Obstacles from Trajectories", "abstract": "In this paper, we study a new data mining problem of obstacle detection from trajectory data. \nIntuitively, given two kinds of trajectories, i.e., reference and query trajectories, the obstacle is a region such that most query trajectories need to bypass this region, whereas the reference trajectories can go through as usual. \nWe introduce a density-based definition for the obstacle based on a new normalized Dynamic Time Warping (nDTW) distance and the density functions tailored for the sub-trajectories to estimate the density variations. \nWith this definition, we introduce a novel framework \\textsf{DIOT} that utilizes the depth-first search method to detect implicit obstacles. \nWe conduct extensive experiments over two real-life data sets. The experimental results show that \\textsf{DIOT} can capture the nature of obstacles yet detect the implicit obstacles efficiently and effectively. Code is available at \\url{https://github.com/1flei/obstacle}."}}
{"id": "lwF24D31tWy", "cdate": 1693827716938, "mdate": 1693827716938, "content": {"title": "A Stitch in Time Saves Nine: Enabling Early Anomaly Detection with Correlation Analysis", "abstract": "Early detection of anomalies from sensor-based Multivariate Time Series (MTS) is vital for timely response to the signs of operation failures and errors. \nWhile many interesting works have been done toward solving this problem, existing methods typically detect such anomalies as outliers by making certain assumptions that allow efficient and easily understandable solutions to be used but might not be applicable to time series. \nMeanwhile, unsupervised deep learning-based methods might be highly accurate but often lead to challenges for real-time industrial scenarios, e.g., requiring a large amount of training data and producing unstable output.\n\nIn this paper, we propose a new approach, \\textsf{CAD}, to detect anomalies from sensor-based MTS. We aim to leverage the latent correlations between sensors by first converting the MTS into a sequence of Time-Series Graphs (TSGs) that connect sensors to their highly correlated neighbors within a certain time period. Then, we track the unusual correlation variations between sensors on the sequence of TSGs. \nBy analyzing the correlation variations with a theoretical guarantee, \\textsf{CAD} can detect the time of occurrence for the anomalies simultaneously with the sensors that are affected as early as possible.\n\nExtensive experiments over eight real-world datasets show that \\textsf{CAD} is effective, scalable, yet stable compared to nine state-of-the-art methods while keeping comparable efficiency. \nMoreover, it maintains above 85\\% accuracy on large-scale datasets with over 1,000 sensors. Notably, \\textsf{CAD} can determine relevant sensors in a very early stage of the anomaly so that timely predictive maintenance can be done. The code is available at \\url{https://github.com/YihaoAng/CAD}."}}
{"id": "nTrnHnvIQVO", "cdate": 1693827529955, "mdate": 1693827529955, "content": {"title": "A New Sparse Data Clustering Method Based on Frequent Items", "abstract": "Large, sparse categorical data is a natural way to represent complex data like sequences, trees, and graphs. Such data is prevalent in many applications, e.g., Criteo released a terabyte size click log data of 4 billion records with millions of dimensions. While most existing clustering algorithms like $k$-Means work well on dense, numerical data, there exist relatively few algorithms that can cluster sets of sparse categorical features. \n\nIn this paper, we propose a new method called $k$-FreqItems that performs scalable clustering over high-dimensional, sparse data. To make clustering results easily interpretable, $k$-FreqItems is built upon a novel sparse center representation called FreqItem which will choose a set of high-frequency, non-zero dimensions to represent the cluster. Unlike most existing clustering algorithms, which adopt Euclidean distance as the similarity measure, $k$-FreqItems uses the popular Jaccard distance for comparing sets. \n\nSince the efficiency and effectiveness of $k$-FreqItems are highly dependent on an initial set of representative seeds, we introduce a new randomized initialization method, SILK, to deal with the seeding problem of $k$-FreqItems. SILK uses locality-sensitive hash (LSH) functions for oversampling and identifies frequently co-occurred data in LSH buckets to determine a set of promising seeds, allowing $k$-FreqItems to converge swiftly in an iterative process. Experimental results over seven real-world sparse data sets show that the SILK seeding is around 1.1$\\sim$3.2$\\times$ faster yet more effective than the state-of-the-art seeding methods. Notably, SILK scales up well to a billion data objects on a commodity machine with 4 GPUs. The code is available at \\url{https://github.com/HuangQiang/k-FreqItems}."}}
{"id": "7Uz0sEs63Cj", "cdate": 1681441740424, "mdate": 1681441740424, "content": {"title": "Lightweight-Yet-Efficient: Revitalizing Ball-Tree for Point-to-Hyperplane Nearest Neighbor Search", "abstract": "Finding the nearest neighbor to a hyperplane (or Point-to-Hyperplane Nearest Neighbor Search, simply P2HNNS) is a new and challenging problem with applications in many research domains. While existing state-of-the-art hashing schemes (e.g., NH and FH) are able to achieve sublinear time complexity without the assumption of the data being in a unit hypersphere, they require an asymmetric transformation, which increases the data dimension from $d$ to $\\Omega(d^2)$. This leads to considerable overhead for indexing and incurs significant distortion errors.\n\nIn this paper, we investigate a tree-based approach for solving P2HNNS using the classical Ball-Tree index. Compared to hashing-based methods, tree-based methods usually require roughly linear costs for construction, and they provide different kinds of approximations with excellent flexibility. A simple branch-and-bound algorithm with a novel lower bound is first developed on Ball-Tree for performing P2HNNS. Then, a new tree structure named BC-Tree, which maintains the Ball and Cone structures in the leaf nodes of Ball-Tree, is described together with two effective strategies, i.e., point-level pruning and collaborative inner product computing. BC-Tree inherits both the low construction cost and lightweight property of Ball-Tree while providing a similar or more efficient search. Experimental results over 16 real-world data sets show that Ball-Tree and BC-Tree are around 1.1$\\sim$10$\\times$ faster than NH and FH, and they can reduce the index size and indexing time by about 1$\\sim$3 orders of magnitudes on average. The code is available at \\url{https://github.com/HuangQiang/BC-Tree}."}}
{"id": "paItCnUke7", "cdate": 1671806787798, "mdate": 1671806787798, "content": {"title": "SAH: Shifting-aware Asymmetric Hashing for Reverse k-Maximum Inner Product Search", "abstract": "This paper investigates a new yet challenging problem called Reverse k-Maximum Inner Product Search (RkMIPS). Given a query (item) vector, a set of item vectors, and a set of user vectors, the problem of RkMIPS aims to find a set of user vectors whose inner products with the query vector are one of the k largest among the query and item vectors. We propose the first subquadratic-time algorithm, i.e., Shifting-aware Asymmetric Hashing (SAH), to tackle the RkMIPS problem. To speed up the Maximum Inner Product Search (MIPS) on item vectors, we design a shifting-invariant asymmetric transformation and develop a novel sublinear-time Shifting-Aware Asymmetric Locality Sensitive Hashing (SA-ALSH) scheme. Furthermore, we devise a new blocking strategy based on the Cone-Tree to effectively prune user vectors (in a batch). We prove that SAH achieves a theoretical guarantee for solving the RMIPS problem. Experimental results on five real-world datasets show that SAH runs 4\u223c8\u00d7 faster than the state-of-the-art methods for RkMIPS while achieving F1-scores of over 90\\%. The code is available at https://github.com/HuangQiang/SAH."}}
{"id": "DI3B2BVD_wM", "cdate": 1617689908071, "mdate": null, "content": {"title": "Point-to-Hyperplane Nearest Neighbor Search Beyond the Unit Hypersphere", "abstract": "Point-to-Hyperplane Nearest Neighbor Search (P2HNNS) is a fundamental yet challenging problem, and it has plenty of applications in various fields. Existing hyperplane hashing schemes enjoy sub-linear query time and achieve excellent performance on applications such as large-scale active learning with Support Vector Machines (SVMs). However, they only conditionally deal with this problem with a strong assumption that all of the data objects are normalized, located at the unit hypersphere. Those hyperplane hashing schemes may be arbitrarily bad without this assumption.\n\nIn this paper, we introduce a new asymmetric transformation and develop the first two provable hyperplane hashing schemes, Nearest Hyperplane hashing (NH) and Furthest Hyperplane hashing (FH), for high-dimensional P2HNNS beyond the unit hypersphere. With this asymmetric transformation, we demonstrate that the hash functions of NH and FH are locality-sensitive to the hyperplane queries, and both of them enjoy quality guarantee on query results. Moreover, we propose a data-dependent multi-partition strategy to boost the search performance of FH. NH can perform the hyperplane queries in sub-linear time, while FH enjoys a better practical performance. We evaluate NH and FH over five real-life datasets and show that we are around $3 \\sim 100 \\times$ faster than the best competitor in four out of five datasets, especially for the recall in $[20\\%, 80\\%]$. Code is available at \\url{https://github.com/HuangQiang/P2HNNS}."}}
{"id": "nbsd1UmgJdF", "cdate": 1617689667819, "mdate": null, "content": {"title": "Query-aware locality-sensitive hashing for approximate nearest neighbor search", "abstract": "Locality-Sensitive Hashing (LSH) and its variants are the well-known indexing schemes for the $c$-Approximate Nearest Neighbor ($c$-ANN) search problem in high-dimensional Euclidean space. Traditionally, LSH functions are constructed in a \\emph{query-oblivious} manner in the sense that buckets are partitioned before any query arrives. However, objects closer to a query may be partitioned into different buckets, which is undesirable. Due to the use of \\emph{query-oblivious} bucket partition, the state-of-the-art LSH schemes for external memory, namely C2LSH and LSB-Forest, only work with approximation ratio of integer $c \\geq 2$. \n\nIn this paper, we introduce a novel concept of \\emph{query-aware} bucket partition which uses a given query as the ``anchor\" for bucket partition. Accordingly, a \\emph{query-aware} LSH function is a random projection coupled with \\emph{query-aware} bucket partition, which removes random shift required by traditional \\emph{query-oblivious} LSH functions. Notably, \\emph{query-aware} bucket partition can be easily implemented so that query performance is guaranteed. We propose a novel \\emph{query-aware} LSH scheme named QALSH for $c$-ANN search over external memory. Our theoretical studies show that QALSH enjoys a guarantee on query quality. The use of \\emph{query-aware} LSH function enables QALSH to work with any approximation ratio $c > 1$. Extensive experiments show that QALSH outperforms C2LSH and LSB-Forest, especially in high-dimensional space. Specifically, by using a ratio $c < 2$, QALSH can achieve much better query quality. "}}
{"id": "jAWhmqChhC3", "cdate": 1617681118763, "mdate": null, "content": {"title": "Reverse Query-Aware Locality-Sensitive Hashing for High-Dimensional Furthest Neighbor Search", "abstract": "The $c$-Approximate Furthest Neighbor ($c$-AFN) search is a fundamental problem in many applications. However, existing hashing schemes are designed for internal memory. The old techniques for external memory, such as furthest point Voronoi diagram and the tree-based methods, are only suitable for the low-dimensional case. In this paper, we introduce a novel concept of Reverse Locality-Sensitive Hashing (RLSH) family which is directly designed for $c$-AFN search. Accordingly, we propose two novel hashing schemes RQALSH and RQALSH$^*$ for high-dimensional $c$-AFN search over external memory. Experimental results validate the efficiency and effectiveness of RQALSH and RQALSH$^*$."}}
{"id": "bd5XT8gue5", "cdate": 1617680931750, "mdate": null, "content": {"title": "Two Efficient Hashing Schemes for High-Dimensional Furthest Neighbor Search", "abstract": "The $c$-Approximate Furthest Neighbor ($c$-AFN) search is a fundamental problem in many applications. However, existing hashing schemes for $c$-AFN search are designed for internal memory. The old techniques for external memory, such as furthest point Voronoi diagram and the tree-based methods, are only suitable for the low-dimensional case. In this paper, we introduce a novel concept of Reverse Locality-Sensitive Hashing (RLSH) family which is directly designed for $c$-AFN search. Accordingly, we propose a new reverse query-aware LSH function, which is a random projection coupled with query-aware interval identification. Based on the reverse query-aware LSH functions, we introduce a novel Reverse Query-Aware LSH scheme named RQALSH for high-dimensional $c$-AFN search over external memory. Our theoretical studies show that RQALSH enjoys a guarantee on query quality. In addition, in order to further speed up RQALSH, we propose a heuristic variant named RQALSH$^*$ which applies a data-dependent objects selection to largely reduce the number of data objects. In the experiment, we compare with two state-of-the-art hashing schemes QDAFN and DrusillaSelect which have been adapted for external memory. Extensive experiments on four real datasets show that our proposed RQALSH and RQALSH$^*$ schemes significantly outperform these two methods."}}
