{"id": "qYLp6nNU7m-", "cdate": 1664294262826, "mdate": null, "content": {"title": "The emergence of visual simulation in task-optimized recurrent neural networks", "abstract": "Primates display remarkable prowess in making rapid visual inferences even when sensory inputs are impoverished. One hypothesis about how they accomplish this is through a process called visual simulation, in which they imagine future states of their environment using a constructed mental model. Though a growing body of behavioral findings, in both humans and non-human primates, provides credence to this hypothesis, the computational mechanisms underlying this ability remain poorly understood. In this study, we probe the capability of feedforward and recurrent neural network models to solve the Planko task, parameterized to systematically control task variability. We demonstrate that visual simulation emerges as the optimal computational strategy in deep neural networks only when task variability is high. Moreover, we provide some of the first evidence that information about imaginary future states can be decoded from the model latent representations, despite no explicit supervision. Taken together, our work suggests that the optimality of visual simulation is task-specific and provides a framework to test its mechanistic basis."}}
{"id": "ElI9znK_eUz", "cdate": 1663850022084, "mdate": null, "content": {"title": "Diagnosing and exploiting the computational demands of videos games for deep reinforcement learning", "abstract": "Humans learn by interacting with their environments and perceiving the outcomes of their actions. A landmark in artificial intelligence has been the development of deep reinforcement learning (dRL) algorithms capable of doing the same in video games, on par with or better than humans. However, it remains unclear whether the successes of dRL models reflect advances in visual representation learning, the effectiveness of reinforcement learning algorithms at discovering better policies, or both. To address this question, we introduce the Learning Challenge Diagnosticator (LCD), a tool that separately measures the perceptual and reinforcement learning demands of a task. We use LCD to discover a novel taxonomy of challenges in the Procgen benchmark, and demonstrate that these predictions are both highly reliable and can instruct algorithmic development. More broadly, the LCD reveals multiple failure cases that can occur when optimizing dRL algorithms over entire video game benchmarks like Procgen, and provides a pathway towards more efficient progress."}}
{"id": "GlvB-Hu-YlT", "cdate": 1577836800000, "mdate": 1682573321039, "content": {"title": "Recurrent neural circuits for contour detection", "abstract": "We introduce a deep recurrent neural network architecture that approximates visual cortical circuits (M\u00e9ly et al., 2018). We show that this architecture, which we refer to as the \ud835\udf38-net, learns to solve contour detection tasks with better sample efficiency than state-of-the-art feedforward networks, while also exhibiting a classic perceptual illusion, known as the orientation-tilt illusion. Correcting this illusion significantly reduces \\gnetw contour detection accuracy by driving it to prefer low-level edges over high-level object boundary contours. Overall, our study suggests that the orientation-tilt illusion is a byproduct of neural circuits that help biological visual systems achieve robust and efficient contour detection, and that incorporating these circuits in artificial neural networks can improve computer vision."}}
{"id": "BjBeX3FkjZ", "cdate": 1577836800000, "mdate": 1668021731735, "content": {"title": "Stable and expressive recurrent vision models", "abstract": "Primate vision depends on recurrent processing for reliable perception. A growing body of literature also suggests that recurrent connections improve the learning efficiency and generalization of vision models on classic computer vision challenges. Why then, are current large-scale challenges dominated by feedforward networks? We posit that the effectiveness of recurrent vision models is bottlenecked by the standard algorithm used for training them, \"back-propagation through time\" (BPTT), which has O(N) memory-complexity for training an N step model. Thus, recurrent vision model design is bounded by memory constraints, forcing a choice between rivaling the enormous capacity of leading feedforward models or trying to compensate for this deficit through granular and complex dynamics. Here, we develop a new learning algorithm, \"contractor recurrent back-propagation\" (C-RBP), which alleviates these issues by achieving constant O(1) memory-complexity with steps of recurrent processing. We demonstrate that recurrent vision models trained with C-RBP can detect long-range spatial dependencies in a synthetic contour tracing task that BPTT-trained models cannot. We further show that recurrent vision models trained with C-RBP to solve the large-scale Panoptic Segmentation MS-COCO challenge outperform the leading feedforward approach, with fewer free parameters. C-RBP is a general-purpose learning algorithm for any application that can benefit from expansive recurrent dynamics. Code and data are available at https://github.com/c-rbp."}}
{"id": "A_raRDfa03", "cdate": 1577836800000, "mdate": 1682573321050, "content": {"title": "Recurrent neural circuits for contour detection", "abstract": "We introduce a deep recurrent neural network architecture that approximates visual cortical circuits. We show that this architecture, which we refer to as the gamma-net, learns to solve contour detection tasks with better sample efficiency than state-of-the-art feedforward networks, while also exhibiting a classic perceptual illusion, known as the orientation-tilt illusion. Correcting this illusion significantly reduces gamma-net contour detection accuracy by driving it to prefer low-level edges over high-level object boundary contours. Overall, our study suggests that the orientation-tilt illusion is a byproduct of neural circuits that help biological visual systems achieve robust and efficient contour detection, and that incorporating these circuits in artificial neural networks can improve computer vision."}}
{"id": "0Ma7QuSKQQF", "cdate": 1577836800000, "mdate": 1668021731735, "content": {"title": "Stable and expressive recurrent vision models", "abstract": "Primate vision depends on recurrent processing for reliable perception. A growing body of literature also suggests that recurrent connections improve the learning efficiency and generalization of vision models on classic computer vision challenges. Why then, are current large-scale challenges dominated by feedforward networks? We posit that the effectiveness of recurrent vision models is bottlenecked by the standard algorithm used for training them, \"back-propagation through time\" (BPTT), which has O(N) memory-complexity for training an N step model. Thus, recurrent vision model design is bounded by memory constraints, forcing a choice between rivaling the enormous capacity of leading feedforward models or trying to compensate for this deficit through granular and complex dynamics. Here, we develop a new learning algorithm, \"contractor recurrent back-propagation\" (C-RBP), which alleviates these issues by achieving constant O(1) memory-complexity with steps of recurrent processing. We demonstrate that recurrent vision models trained with C-RBP can detect long-range spatial dependencies in a synthetic contour tracing task that BPTT-trained models cannot. We further show that recurrent vision models trained with C-RBP to solve the large-scale Panoptic Segmentation MS-COCO challenge outperform the leading feedforward approach, with fewer free parameters. C-RBP is a general-purpose learning algorithm for any application that can benefit from expansive recurrent dynamics. Code and data are available at https://github.com/c-rbp."}}
{"id": "H1gB4RVKvB", "cdate": 1569439277139, "mdate": null, "content": {"title": "Recurrent neural circuits for contour detection", "abstract": "We introduce a deep recurrent neural network architecture that approximates visual cortical circuits (M\u00e9ly et al., 2018). We show that this architecture, which we refer to as the \ud835\udf38-net, learns to solve contour detection tasks with better sample efficiency than state-of-the-art feedforward networks, while also exhibiting a classic perceptual illusion, known as the orientation-tilt illusion. Correcting this illusion significantly reduces \\gnetw contour detection accuracy by driving it to prefer low-level edges over high-level object boundary contours. Overall, our study suggests that the orientation-tilt illusion is a byproduct of neural circuits that help biological visual systems achieve robust and efficient contour detection, and that incorporating these circuits in artificial neural networks can improve computer vision."}}
{"id": "P-yGDdwFrIf", "cdate": 1546300800000, "mdate": 1682573321084, "content": {"title": "Automatic Inspection of Utility Scale Solar Power Plants using Deep Learning", "abstract": "Solar energy has the potential to become the backbone energy source for the world. Utility scale solar power plants (more than 50 MW) could have more than 100K individual solar modules and be spread over more than 200 acres of land. Traditionally methods of monitoring each module become too costly in the utility scale. We demonstrate an alternative using the recent advances in deep learning to automatically analyze drone footage. We show that this can be a quick and reliable alternative. We show that it can save huge amounts of power and the impact the developing world hugely."}}
{"id": "H1-zYRb_bB", "cdate": 1514764800000, "mdate": null, "content": {"title": "Autoencoders with Variable Sized Latent Vector for Image Compression", "abstract": "Learning to compress images is an interesting and challenging task. Autoencoders have long been used to compress images into a code of small but fixed size. As different images need different sized code based on their complexity, we propose an autoencoder architecture with a variable sized latent vector. We propose an attention based model which attends over the image and summarizes it into a small code. This summarization is repeated many times depending on the complexity of the image, producing a new code each time to encode new information so as to get a better reconstruction. These small codes then form sub-units of the final code. Our approach is quality progressive and has flexible quality setting which are desirable properties in compression. We show that the proposed model shows better performance compared to JPEG."}}
