{"id": "wd0XOnNcagQ", "cdate": 1577836800000, "mdate": null, "content": {"title": "A unified survey on treatment effect heterogeneity modeling and uplift modeling", "abstract": "A central question in many fields of scientific research is to determine how an outcome would be affected by an action, or to measure the effect of an action (a.k.a treatment effect). In recent years, a need for estimating the heterogeneous treatment effects conditioning on the different characteristics of individuals has emerged from research fields such as personalized healthcare, social science, and online marketing. To meet the need, researchers and practitioners from different communities have developed algorithms by taking the treatment effect heterogeneity modeling approach and the uplift modeling approach, respectively. In this paper, we provide a unified survey of these two seemingly disconnected yet closely related approaches under the potential outcome framework. We then provide a structured survey of existing methods by emphasizing on their inherent connections with a set of unified notations to make comparisons of the different methods easy. We then review the main applications of the surveyed methods in personalized marketing, personalized medicine, and social studies. Finally, we summarize the existing software packages and present discussions based on the use of methods on synthetic, semi-synthetic and real world data sets and provide some general guidelines for choosing methods."}}
{"id": "wIthoSOIAMd", "cdate": 1577836800000, "mdate": null, "content": {"title": "Detecting potential signals of adverse drug events from prescription data", "abstract": "Highlights \u2022 Detecting Adverse drug events purely from prescription data containing no additional information. \u2022 Adapting the case-crossover study to extract samples from constructed case and control time windows. \u2022 Using a logistic regression model to automatically evaluate multiple medicines and select the medicines with the most significant associations with the ADE via Lasso regularisation. \u2022 Proposing improvements to take temporal effect, frequency of prescription and individual effect into account. \u2022 As a complement to other signal detection methods for ADEs, our work can potentially strengthen global pharmacosurveillance. Abstract Adverse drug events (ADEs) may occur and lead to severe consequences for the public, even though clinical trials are conducted in the stage of pre-market. Computational methods are still needed to fulfil the task of pharmacosurveillance. In post-market surveillance, the spontaneous reporting system (SRS) has been widely used to detect suspicious associations between medicines and ADEs. However, the passive mechanism of SRS leads to the hysteresis in ADE detection by SRS based methods, not mentioning the acknowledged problem of under-reporting and duplicate reporting in SRS. Therefore, there is a growing demand for other complementary methods utilising different types of healthcare data to assist with global pharmacosurveillance. Among those data sources, prescription data is of proved usefulness for pharmacosurveillance. However, few works have used prescription data for signalling ADEs. In this paper, we propose a data-driven method to discover medicines that are responsible for a given ADE purely from prescription data. Our method uses a logistic regression model to evaluate the associations between up to hundreds of suspected medicines and an ADE spontaneously and selects the medicines possessing the most significant associations via Lasso regularisation. To prepare data for training the logistic regression model, we adapt the design of the case-crossover study to construct case time and control time windows for the extraction of medicine use information. While the case time window can be readily determined, we propose several criteria to select the suitable control time windows providing the maximum power of comparisons. In order to address confounding situations, we have considered diverse factors in medicine utilisation in terms of the temporal effect of medicine and the frequency of prescription, as well as the individual effect of patients on the occurrence of an ADE. To assess the performance of the proposed method, we conducted a case study with a real-world prescription dataset. Validated by the existing domain knowledge, our method successfully traced a wide range of medicines that are potentially responsible for the ADE. Further experiments were also carried out according to a recognised gold standard, our method achieved a sensitivity of 65.9% and specificity of 96.2%."}}
{"id": "tT4zMSvZU7z", "cdate": 1577836800000, "mdate": null, "content": {"title": "Evidence Weighted Tree Ensembles for Text Classification", "abstract": "Text documents are often mapped to vectors of binary values where 1 indicates the presence of a word and 0 indicates the absence. The vectors are then used to train predictive models. In tree-based ensemble models, predictions from some decision trees may be made purely from absent words. This type of predictions should be trusted less as absent words can be interpreted in multiple ways. In this work, we propose to improve the comprehensibility and accuracy of ensemble models by distinguishing word presence and absence. The presented method weights predictions based on word presence. Experimental results on 35 real text datasets indicate that our method outperforms state-of-the-art ensemble methods on various text classification tasks."}}
{"id": "tKaVE_OiI9U", "cdate": 1577836800000, "mdate": null, "content": {"title": "Correction to: Identifying miRNA synergism using multiple-intervention causal inference", "abstract": "After publication of this supplement article [1], it was brought to our attention that the Fig.\u00a03 was incorrect. The correct Fig.\u00a03 is as below:"}}
{"id": "s2g6M7vEtt9", "cdate": 1577836800000, "mdate": null, "content": {"title": "Sufficient Dimension Reduction for Average Causal Effect Estimation", "abstract": "Having a large number of covariates can have a negative impact on the quality of causal effect estimation since confounding adjustment becomes unreliable when the number of covariates is large relative to the samples available. Propensity score is a common way to deal with a large covariate set, but the accuracy of propensity score estimation (normally done by logistic regression) is also challenged by large number of covariates. In this paper, we prove that a large covariate set can be reduced to a lower dimensional representation which captures the complete information for adjustment in causal effect estimation. The theoretical result enables effective data-driven algorithms for causal effect estimation. We develop an algorithm which employs a supervised kernel dimension reduction method to search for a lower dimensional representation for the original covariates, and then utilizes nearest neighbor matching in the reduced covariate space to impute the counterfactual outcomes to avoid large-sized covariate set problem. The proposed algorithm is evaluated on two semi-synthetic and three real-world datasets and the results have demonstrated the effectiveness of the algorithm."}}
{"id": "fYZsD8rKMaN", "cdate": 1577836800000, "mdate": null, "content": {"title": "A general framework for causal classification", "abstract": "In many applications, there is a need to predict the effect of an intervention on different individuals from data. For example, which customers are persuadable by a product promotion? which patients should be treated with a certain type of treatment? These are typical causal questions involving the effect or the change in outcomes made by an intervention. The questions cannot be answered with traditional classification methods as they only use associations to predict outcomes. For personalised marketing, these questions are often answered with uplift modelling. The objective of uplift modelling is to estimate causal effect, but its literature does not discuss when the uplift represents causal effect. Causal heterogeneity modelling can solve the problem, but its assumption of unconfoundedness is untestable in data. So practitioners need guidelines in their applications when using the methods. In this paper, we use causal classification for a set of personalised decision making problems, and differentiate it from classification. We discuss the conditions when causal classification can be resolved by uplift (and causal heterogeneity) modelling methods. We also propose a general framework for causal classification, by using off-the-shelf supervised methods for flexible implementations. Experiments have shown two instantiations of the framework work for causal classification and for uplift (causal heterogeneity) modelling, and are competitive with the other uplift (causal heterogeneity) modelling methods."}}
{"id": "_FemScbCVdP", "cdate": 1577836800000, "mdate": null, "content": {"title": "Robust Multi-Instance Learning with Stable Instances", "abstract": "Multi-instance learning (MIL) deals with tasks where data is represented by a set of bags and each bag is described by a set of instances. Unlike standard supervised learning, only the bag labels are observed whereas the label for each instance is not available to the learner. Previous MIL studies typically follow the i.i.d. assumption, that the training and test samples are independently drawn from the same distribution. However, such assumption is often violated in real-world applications. Efforts have been made towards addressing distribution changes by importance weighting the training data with the density ratio between the training and test samples. Unfortunately, models often need to be trained without seeing the test distributions. In this paper we propose possibly the first framework for addressing distribution change in MIL without requiring access to the unlabeled test data. Our framework builds upon identifying a novel connection between MIL and the potential outcome framework in causal effect estimation. Experimental results on synthetic distribution change datasets, real-world datasets with synthetic distribution biases and real distributional biased image classification datasets validate the effectiveness of our approach."}}
{"id": "Y9WBI-GL5FR", "cdate": 1577836800000, "mdate": null, "content": {"title": "LoPAD: A Local Prediction Approach to Anomaly Detection", "abstract": "Dependency-based anomaly detection methods detect anomalies by looking at the deviations from the normal probabilistic dependency among variables and are able to discover more subtle and meaningful anomalies. However, with high dimensional data, they face two key challenges. One is how to find the right set of relevant variables for a given variable from the large search space to assess dependency deviation. The other is how to use the dependency to estimate the expected value of a variable accurately. In this paper, we propose the Local Prediction approach to Anomaly Detection (LoPAD) framework to deal with the two challenges simultaneously. Through introducing Markov Blanket into dependency-based anomaly detection, LoPAD decomposes the high dimensional unsupervised anomaly detection problem into local feature selection and prediction problems while achieving better performance and interpretability. The framework enables instantiations with off-the-shelf predictive models for anomaly detection. Comprehensive experiments have been done on both synthetic and real-world data. The results show that LoPAD outperforms state-of-the-art anomaly detection methods."}}
{"id": "X_5vbJrsIis", "cdate": 1577836800000, "mdate": null, "content": {"title": "Assessing the Fairness of Classifiers with Collider Bias", "abstract": "The increasing application of machine learning techniques in everyday decision-making processes has brought concerns about the fairness of algorithmic decision-making. This paper concerns the problem of collider bias which produces spurious associations in fairness assessment and develops theorems to guide fairness assessment avoiding the collider bias. We consider a real-world application of auditing a trained classifier by an audit agency. We propose an unbiased assessment algorithm by utilising the developed theorems to reduce collider biases in the assessment. Experiments and simulations show the proposed algorithm reduces collider biases significantly in the assessment and is promising in auditing trained classifiers."}}
{"id": "SXoXo7sG77G", "cdate": 1577836800000, "mdate": null, "content": {"title": "Detecting high-quality signals of adverse drug-drug interactions from spontaneous reporting data", "abstract": "Highlights \u2022 A novel method for signal detection of adverse drug-drug interactions (ADDIs). \u2022 Adaption of the framework of Bayesian network ensures high-quality signals. \u2022 An efficient level-wise algorithm with pruning strategy to search for ADDI signals. \u2022 A case study on the FAERS dataset with a comprehensive evaluation of results. Abstract As a medicine safety issue, Drug-Drug Interaction (DDI) may become an unexpected threat for causing Adverse Drug Events (ADEs). There is a growing demand for computational methods to efficiently and effectively analyse large-scale data to detect signals of Adverse Drug-drug Interactions (ADDIs). In this paper, we aim to detect high-quality signals of ADDIs which are non-spurious and non-redundant. We propose a new method which employs the framework of Bayesian network to infer the direct associations between the target ADE and medicines, and uses domain knowledge to facilitate the learning of Bayesian network structures. To improve efficiency and avoid redundancy, we design a level-wise algorithm with pruning strategy to search for high-quality ADDI signals. We have applied the proposed method to the United States Food and Drug Administration\u2019s (FDA) Adverse Event Reporting System (FAERS) data. The result shows that 54.45% of detected signals are verified as known DDIs and 10.89% were evaluated as high-quality ADDI signals, demonstrating that the proposed method could be a promising tool for ADDI signal detection."}}
