{"id": "zJdpwOkrO_G", "cdate": 1672531200000, "mdate": 1695962412504, "content": {"title": "Correcting for Interference in Experiments: A Case Study at Douyin", "abstract": "Interference is a ubiquitous problem in experiments conducted on two-sided content marketplaces, such as Douyin (China\u2019s analog of TikTok). In many cases, creators are the natural unit of experimentation, but creators interfere with each other through competition for viewers\u2019 limited time and attention. \u201cNaive\u201d estimators currently used in practice simply ignore the interference, but in doing so incur bias on the order of the treatment effect. We formalize the problem of inference in such experiments as one of policy evaluation. Off-policy estimators, while unbiased, are impractically high variance. We introduce a novel Monte-Carlo estimator, based on \u201cDifferences-in-Qs\u201d (DQ) techniques, which achieves bias that is second-order in the treatment effect, while remaining sample-efficient to estimate. On the theoretical side, our contribution is to develop a generalized theory of Taylor expansions for policy evaluation, which extends DQ theory to all major MDP formulations. On the practical side, we implement our estimator on Douyin\u2019s experimentation platform, and in the process develop DQ into a truly \u201cplug-and-play\u201d estimator for interference in real-world settings: one which provides robust, low-bias, low-variance treatment effect estimates; admits computationally cheap, asymptotically exact uncertainty quantification; and reduces MSE by 99% compared to the best existing alternatives in our applications."}}
{"id": "VaWcKptIlR", "cdate": 1672531200000, "mdate": 1695962412518, "content": {"title": "Correcting for Interference in Experiments: A Case Study at Douyin", "abstract": "Interference is a ubiquitous problem in experiments conducted on two-sided content marketplaces, such as Douyin (China's analog of TikTok). In many cases, creators are the natural unit of experimentation, but creators interfere with each other through competition for viewers' limited time and attention. \"Naive\" estimators currently used in practice simply ignore the interference, but in doing so incur bias on the order of the treatment effect. We formalize the problem of inference in such experiments as one of policy evaluation. Off-policy estimators, while unbiased, are impractically high variance. We introduce a novel Monte-Carlo estimator, based on \"Differences-in-Qs\" (DQ) techniques, which achieves bias that is second-order in the treatment effect, while remaining sample-efficient to estimate. On the theoretical side, our contribution is to develop a generalized theory of Taylor expansions for policy evaluation, which extends DQ theory to all major MDP formulations. On the practical side, we implement our estimator on Douyin's experimentation platform, and in the process develop DQ into a truly \"plug-and-play\" estimator for interference in real-world settings: one which provides robust, low-bias, low-variance treatment effect estimates; admits computationally cheap, asymptotically exact uncertainty quantification; and reduces MSE by 99\\% compared to the best existing alternatives in our applications."}}
{"id": "AOSIbSmQJr", "cdate": 1652737471946, "mdate": null, "content": {"title": "Markovian Interference in Experiments", "abstract": "We consider experiments in dynamical systems where interventions on some experimental units impact other units through a limiting constraint (such as a limited supply of products). Despite outsize practical importance, the best estimators for this `Markovian' interference problem are largely heuristic in nature, and their bias is not well understood. We formalize the problem of inference in such experiments as one of policy evaluation. Off-policy estimators, while unbiased, apparently incur a large penalty in variance relative to state-of-the-art heuristics. We introduce an on-policy estimator: the Differences-In-Q's (DQ) estimator. We show that the DQ estimator can in general have exponentially smaller variance than off-policy evaluation. At the same time, its bias is second order in the impact of the intervention. This yields a striking bias-variance tradeoff so that the DQ estimator effectively dominates state-of-the-art alternatives. From a theoretical perspective, we introduce three separate novel techniques that are of independent interest in the theory of Reinforcement Learning (RL). Our empirical evaluation includes a set of experiments on a city-scale ride-hailing simulator.  "}}
{"id": "oZYFC1_1tQ", "cdate": 1640995200000, "mdate": 1695962412516, "content": {"title": "Markovian Interference in Experiments", "abstract": "We consider experiments in dynamical systems where interventions on some experimental units impact other units through a limiting constraint (such as a limited supply of products). Despite outsize practical importance, the best estimators for this `Markovian' interference problem are largely heuristic in nature, and their bias is not well understood. We formalize the problem of inference in such experiments as one of policy evaluation. Off-policy estimators, while unbiased, apparently incur a large penalty in variance relative to state-of-the-art heuristics. We introduce an on-policy estimator: the Differences-In-Q's (DQ) estimator. We show that the DQ estimator can in general have exponentially smaller variance than off-policy evaluation. At the same time, its bias is second order in the impact of the intervention. This yields a striking bias-variance tradeoff so that the DQ estimator effectively dominates state-of-the-art alternatives. From a theoretical perspective, we introduce three separate novel techniques that are of independent interest in the theory of Reinforcement Learning (RL). Our empirical evaluation includes a set of experiments on a city-scale ride-hailing simulator."}}
{"id": "iAc9N_1Qj3", "cdate": 1640995200000, "mdate": 1681874609548, "content": {"title": "Uncertainty Quantification for Low-Rank Matrix Completion with Heterogeneous and Sub-Exponential Noise", "abstract": "The problem of low-rank matrix completion with heterogeneous and sub-exponential (as opposed to homogeneous Gaussian) noise is particularly relevant to a number of applications in modern commerce. Examples include panel sales data and data collected from web-commerce systems such as recommendation engines. An important unresolved question for this problem is characterizing the distribution of estimated matrix entries under common low-rank estimators. Such a characterization is essential to any application that requires quantification of uncertainty in these estimates and has heretofore only been available under the assumption of homogenous Gaussian noise. Here we characterize the distribution of estimated matrix entries when the observation noise is heterogeneous sub-Exponential and provide, as an application, explicit formulas for this distribution when observed entries are Poisson or Binary distributed."}}
{"id": "_kRdNx5OjOq", "cdate": 1640995200000, "mdate": 1681874609549, "content": {"title": "Synthetically Controlled Bandits", "abstract": "This paper presents a new dynamic approach to experiment design in settings where, due to interference or other concerns, experimental units are coarse. `Region-split' experiments on online platforms are one example of such a setting. The cost, or regret, of experimentation is a natural concern here. Our new design, dubbed Synthetically Controlled Thompson Sampling (SCTS), minimizes the regret associated with experimentation at no practically meaningful loss to inferential ability. We provide theoretical guarantees characterizing the near-optimal regret of our approach, and the error rates achieved by the corresponding treatment effect estimator. Experiments on synthetic and real world data highlight the merits of our approach relative to both fixed and `switchback' designs common to such experimental settings."}}
{"id": "BH43PaYYsJ9", "cdate": 1640995200000, "mdate": 1681874609546, "content": {"title": "Markovian Interference in Experiments", "abstract": "We consider experiments in dynamical systems where interventions on some experimental units impact other units through a limiting constraint (such as a limited inventory). Despite outsize practical importance, the best estimators for this `Markovian' interference problem are largely heuristic in nature, and their bias is not well understood. We formalize the problem of inference in such experiments as one of policy evaluation. Off-policy estimators, while unbiased, apparently incur a large penalty in variance relative to state-of-the-art heuristics. We introduce an on-policy estimator: the Differences-In-Q's (DQ) estimator. We show that the DQ estimator can in general have exponentially smaller variance than off-policy evaluation. At the same time, its bias is second order in the impact of the intervention. This yields a striking bias-variance tradeoff so that the DQ estimator effectively dominates state-of-the-art alternatives. From a theoretical perspective, we introduce three separate novel techniques that are of independent interest in the theory of Reinforcement Learning (RL). Our empirical evaluation includes a set of experiments on a city-scale ride-hailing simulator."}}
{"id": "gEXbJVhVK5_", "cdate": 1621629713684, "mdate": null, "content": {"title": "Learning Treatment Effects in Panels with General Intervention Patterns", "abstract": "The problem of causal inference with panel data is a central econometric question. The following is a fundamental version of this problem: Let $M^*$ be a low rank matrix and $E$ be a zero-mean noise matrix. For a `treatment' matrix $Z$ with entries in $\\{0,1\\}$ we observe the matrix $O$ with entries $O_{ij} := M^*_{ij} + E_{ij} + \\mathcal{T}_{ij} Z_{ij}$ where $\\mathcal{T}_{ij} $ are unknown, heterogenous treatment effects. The problem requires we estimate the average treatment effect $\\tau^* := \\sum_{ij} \\mathcal{T}_{ij} Z_{ij} / \\sum_{ij} Z_{ij}$. The synthetic control paradigm provides an approach to estimating $\\tau^*$ when $Z$ places support on a single row. This paper extends that framework to allow rate-optimal recovery of $\\tau^*$ for general $Z$, thus broadly expanding its applicability. Our guarantees are the first of their type in this general setting. Computational experiments on synthetic and real-world data show a substantial advantage over competing estimators. "}}
{"id": "zKhGkFh5KEw", "cdate": 1609459200000, "mdate": 1681874609547, "content": {"title": "Near-Optimal Entrywise Anomaly Detection for Low-Rank Matrices with Sub-Exponential Noise", "abstract": "We study the problem of identifying anomalies in a low-rank matrix observed with sub-exponential noise, motivated by applications in retail and inventory management. State of the art approaches to ..."}}
{"id": "vfLe2DP5-Z", "cdate": 1609459200000, "mdate": 1681874609548, "content": {"title": "Uncertainty Quantification For Low-Rank Matrix Completion With Heterogeneous and Sub-Exponential Noise", "abstract": "The problem of low-rank matrix completion with heterogeneous and sub-exponential (as opposed to homogeneous and Gaussian) noise is particularly relevant to a number of applications in modern commerce. Examples include panel sales data and data collected from web-commerce systems such as recommendation engines. An important unresolved question for this problem is characterizing the distribution of estimated matrix entries under common low-rank estimators. Such a characterization is essential to any application that requires quantification of uncertainty in these estimates and has heretofore only been available under the assumption of homogenous Gaussian noise. Here we characterize the distribution of estimated matrix entries when the observation noise is heterogeneous sub-exponential and provide, as an application, explicit formulas for this distribution when observed entries are Poisson or Binary distributed."}}
