{"id": "RwfHI3-qda", "cdate": 1672531200000, "mdate": 1682344972598, "content": {"title": "NeuroBench: Advancing Neuromorphic Computing through Collaborative, Fair and Representative Benchmarking", "abstract": "The field of neuromorphic computing holds great promise in terms of advancing computing efficiency and capabilities by following brain-inspired principles. However, the rich diversity of techniques employed in neuromorphic research has resulted in a lack of clear standards for benchmarking, hindering effective evaluation of the advantages and strengths of neuromorphic methods compared to traditional deep-learning-based methods. This paper presents a collaborative effort, bringing together members from academia and the industry, to define benchmarks for neuromorphic computing: NeuroBench. The goals of NeuroBench are to be a collaborative, fair, and representative benchmark suite developed by the community, for the community. In this paper, we discuss the challenges associated with benchmarking neuromorphic solutions, and outline the key features of NeuroBench. We believe that NeuroBench will be a significant step towards defining standards that can unify the goals of neuromorphic computing and drive its technological progress. Please visit neurobench.ai for the latest updates on the benchmark tasks and metrics."}}
{"id": "Oe0VRt2EBol", "cdate": 1621197668954, "mdate": null, "content": {"title": "Dynamical learning of dynamics", "abstract": "The ability of humans and animals to quickly adapt to novel tasks is difficult to reconcile with the\nstandard paradigm of learning by slow synaptic weight modification. Here we show that fixed-weight\nneural networks can learn to generate required dynamics by imitation. After appropriate weight\npretraining, the networks quickly and dynamically adapt to learn new tasks and thereafter continue\nto achieve them without further teacher feedback. We explain this ability and illustrate it with a\nvariety of target dynamics, ranging from oscillatory trajectories to driven and chaotic dynamical\nsystems.\n"}}
{"id": "pBzyOcUVXIu", "cdate": 1621197367278, "mdate": null, "content": {"title": "Thalamic regulation of switching between cortical representations enables cognitive flexibility", "abstract": "Interactions between the prefrontal cortex (PFC) and mediodorsal thalamus are critical for cognitive flexibility, yet the underly-\ning computations are unknown. To investigate frontothalamic substrates of cognitive flexibility, we developed a behavioral task\nin which mice switched between different sets of learned cues that guided attention toward either visual or auditory targets.\nWe found that PFC responses reflected both the individual cues and their meaning as task rules, indicating a hierarchical cue-\nto-rule transformation. Conversely, mediodorsal thalamus responses reflected the statistical regularity of cue presentation\nand were required for switching between such experimentally specified cueing contexts. A subset of these thalamic responses\nsustained context-relevant PFC representations, while another suppressed the context-irrelevant ones. Through modeling and\nexperimental validation, we find that thalamic-mediated suppression may not only reduce PFC representational interference\nbut could also preserve unused cortical traces for future use. Overall, our study provides a computational foundation for tha-\nlamic engagement in cognitive flexibility.\n"}}
{"id": "ZtsYXpJ2fDI", "cdate": 1514764800000, "mdate": 1682350595765, "content": {"title": "Multi-Timescale Memory Dynamics Extend Task Repertoire in a Reinforcement Learning Network With Attention-Gated Memory", "abstract": "The interplay of reinforcement learning and memory is at the core of several recent neural network models, such as the Attention-Gated MEmory Tagging (AuGMEnT) model. While successful at various animal learning tasks, we find that the AuGMEnT network is unable to cope with some hierarchical tasks, where higher-level stimuli have to be maintained over a long time, while lower-level stimuli need to be remembered and forgotten over a shorter timescale. To overcome this limitation, we introduce a hybrid AuGMEnT, with leaky (or short-timescale) and non-leaky (or long-timescale) memory units, that allows the exchange of low-level information while maintaining high-level one. We test the performance of the hybrid AuGMEnT network on two cognitive reference tasks, sequence prediction and 12AX."}}
{"id": "HJb6lo-dZr", "cdate": 1514764800000, "mdate": null, "content": {"title": "Non-Linear Motor Control by Local Learning in Spiking Neural Networks", "abstract": "Learning weights in a spiking neural network with hidden neurons, using local, stable and online rules, to control non-linear body dynamics is an open problem. Here, we employ a supervised scheme, ..."}}
