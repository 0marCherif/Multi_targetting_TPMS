{"id": "nX7jYfHsUo", "cdate": 1673821748317, "mdate": 1673821748317, "content": {"title": "Comment: Diagnostics and Kernel-based Extensions for Linear Mixed Effects Models with Endogenous Covariates", "abstract": "We discuss \u201cLinear mixed models with endogenous covariates: modeling sequential treatment effects with application to a mobile health study\u201d by Qian, Klasnja and Murphy. In this discussion, we study when the linear mixed effects models with endogenous covariates are feasible to use by providing examples and diagnostic tools as well as discussing potential extensions. This includes evaluating feasibility of partial likelihood-based inference, checking the conditional independence assumption, estimation of marginal effects, and kernel extensions of the model."}}
{"id": "ZoIWJvy8cv7", "cdate": 1673407474776, "mdate": 1673407474776, "content": {"title": "The Association Between Serum Chloride Levels and Chronic Kidney Disease Progression: A Cohort Study", "abstract": "Background Limited data suggest serum chloride levels associate with mortality in heart failure, chronic kidney disease (CKD), and pulmonary arterial hypertension. Randomized trials have also shown that administration of crystalloid intravenous fluids with lower chloride concentration may have better renal outcomes. However, chloride has not been studied longitudinally for CKD progression. Methods We used a prospective cohort of subjects with stage 3 and 4 CKD recruited from a nephrology clinic at a single medical center. Linear regression, linear regression with generalized estimating equations, and Cox proportional hazards models were created for outcomes of overall change in estimated glomerular filtration rate (eGFR), longitudinal changes in eGFR, and time to >\u200930% decline in eGFR, respectively. Baseline chloride was modeled continuously and categorically, and models were adjusted for potential confounders. Results Median follow-up was 1.7\u2009years. Baseline median age was 72\u2009years and median eGFR was 35.7\u2009mL/min/1.73m 2 . In multivariable analysis, higher serum chloride associated with worsened eGFR decline. Every 1\u2009mEq/L increase in chloride associated with an overall eGFR decline of 0.32\u2009mL/min/1.73m 2 ( p \u2009=\u20090.003), while the difference in eGFR decline in the highest quartile of chloride was 3.4\u2009mL/min/1.73m 2 compared to the lowest quartile ( p \u2009=\u20090.004). No association between serum chloride and time to 30% decline in eGFR was observed in multivariable analysis (hazard ratio 1.05 per 1\u2009mEq/L increase in serum chloride, p \u2009=\u20090.103). Conclusions In CKD patients, higher serum chloride associated with a modestly steeper rate of eGFR decline, and may be a useful biomarker to predict CKD progression. Further studies are needed to determine causality"}}
{"id": "pZFAMnl_H3", "cdate": 1673406696635, "mdate": 1673406696635, "content": {"title": "Fast Effect Size Shrinkage Software for Beta-Binomial Models of Allelic Imbalance", "abstract": "Allelic imbalance occurs when the two alleles of a gene are differentially expressed within a diploid organism and can indicate important differences in cis-regulation and epigenetic state across the two chromosomes. Because of this, the ability to accurately quantify the proportion at which each allele of a gene is expressed is of great interest to researchers. This becomes challenging in the presence of small read counts and/or sample sizes, which can cause estimators for allelic expression proportions to have high variance. Investigators have traditionally dealt with this problem by filtering out genes with small counts and samples. However, this may inadvertently remove important genes that have truly large allelic imbalances. Another option is to use pseudocounts or Bayesian estimators to reduce the variance. To this end, we evaluated the accuracy of four different estimators, the latter two of which are Bayesian shrinkage estimators: maximum likelihood, adding a pseudocount to each allele, approximate posterior estimation of GLM coefficients (apeglm) and adaptive shrinkage (ash). We also wrote C++ code to quickly calculate ML and apeglm estimates and integrated it into the apeglm package. The four methods were evaluated on two simulations and one real data set. Apeglm consistently performed better than ML according to a variety of criteria, and generally outperformed use of pseudocounts as well. Ash also performed better than ML in one of the simulations, but in the other performance was more mixed. Finally, when compared to five other packages that also fit beta-binomial models, the apeglm package was substantially faster and more numerically reliable, making our package useful for quick and reliable analyses of allelic imbalance. Apeglm is available as an R/Bioconductor package at http://bioconductor.org/packages/apeglm."}}
{"id": "VCz-MAH5_ej", "cdate": 1672531200000, "mdate": 1682443637383, "content": {"title": "Revisiting Bellman Errors for Offline Model Selection", "abstract": "Offline model selection (OMS), that is, choosing the best policy from a set of many policies given only logged data, is crucial for applying offline RL in real-world settings. One idea that has been extensively explored is to select policies based on the mean squared Bellman error (MSBE) of the associated Q-functions. However, previous work has struggled to obtain adequate OMS performance with Bellman errors, leading many researchers to abandon the idea. To this end, we elucidate why previous work has seen pessimistic results with Bellman errors and identify conditions under which OMS algorithms based on Bellman errors will perform well. Moreover, we develop a new estimator of the MSBE that is more accurate than prior methods. Our estimator obtains impressive OMS performance on diverse discrete control tasks, including Atari games."}}
{"id": "NfpUUn6DNv1", "cdate": 1665251236634, "mdate": null, "content": {"title": "Revisiting Bellman Errors for Offline Model Selection", "abstract": "It is well-known that the empirical Bellman errors are poor predictors of value function estimation accuracy and policy performance. This has led researchers to abandon offline model selection procedures based on Bellman errors and instead focus on directly estimating the expected return under different policies of interest. The problem with this approach is that it can be very difficult to use an offline dataset generated by one policy to estimate the expected returns of a different policy. In contrast, we argue that Bellman errors can be useful for offline model selection, and that the discouraging results in past literature has been due to estimating and utilizing them incorrectly. We propose a new algorithm, $\\textit{Supervised Bellman Validation}$, that estimates the expected squared Bellman error better than the empirical Bellman errors. We demonstrate the relative merits of our method over competing methods through both theoretical results and empirical results on offline datasets from the Atari benchmark. We hope that our results will challenge current attitudes and spur future research into Bellman errors and their utility in offline model selection."}}
{"id": "bmB3nlZbQd", "cdate": 1664994279289, "mdate": null, "content": {"title": "Revisiting Bellman Errors for Offline Model Selection", "abstract": "Applying offline reinforcement learning in real-world settings necessitates the ability to tune hyperparameters offline, a task known as $\\textit{offline model selection}$. It is well-known that the empirical Bellman errors are poor predictors of value function estimation accuracy and policy performance. This has led researchers to abandon model selection procedures based on Bellman errors and instead focus on evaluating the expected return under policies of interest. The problem with this approach is that it can be very difficult to use an offline dataset generated by one policy to estimate the expected returns of a different policy. In contrast, we argue that Bellman errors can be useful for offline model selection, and that the discouraging results in past literature has been due to estimating and utilizing them incorrectly. We propose a new algorithm, $\\textit{Supervised Bellman Validation}$, that estimates the expected squared Bellman error better than the empirical Bellman errors. We demonstrate the relative merits of our method over competing methods through both theoretical results and empirical results on datasets from the Atari benchmark. We hope that our results will challenge current attitudes and spur future research into Bellman errors and their utility in offline model selection."}}
{"id": "_25dqenu_i", "cdate": 1514764800000, "mdate": 1682443629828, "content": {"title": "Models for Early Identification of Struggling Novice Programmers", "abstract": "There is much interest in predicting student performance in computer programming courses early in the semester to identify weak students who might benefit from targeted support. To this end, we analyzed detailed keystroke transcripts and outputs of compilation attempts during programming activities, both in and out of class. In linear regression models predicting grades, we identified multiple behavioral indicators and performance indicators that explained a significant portion of the variation in final grades using only the data collected within the first three weeks. Because the indicators identify specific behaviors and are generated automatically, they may be used as the basis for interventions instructors may use when counseling weaker students concerning their performance early in the course before they fall too far behind. Furthermore, in contrast with some other automated struggling-student detection models, our predictors are based on generic behaviors and generic performance metrics that can be extended to a wide range of introductory programming contexts. Our models also predict performance on a continuous scale rather than a binary \"weak\"/\"not weak\" classification, which would allow instructors to offer interventions to marginal students who want to improve, or to promising students who want to excel."}}
