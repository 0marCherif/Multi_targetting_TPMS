{"id": "wR3DcZeB3h", "cdate": 1696113461842, "mdate": null, "content": {"title": "Graph Neural Prompting with Large Language Models", "abstract": "Large Language Models (LLMs) have shown remarkable generalization capability with exceptional performance in various language modeling tasks. However, they still exhibit inherent limitations in precisely capturing and returning grounded knowledge. While existing work has explored utilizing knowledge graphs to enhance language modeling via joint training and customized model architectures, applying this to LLMs is problematic owing to their large number of parameters and high computational cost. In addition, how to leverage the pre-trained LLMs and avoid training a customized model from scratch remains an open question. In this work, we propose Graph Neural Prompting (GNP), a novel plug-and-play method to assist pre-trained LLMs in learning beneficial knowledge from KGs. GNP encompasses various designs, including a standard graph neural network encoder, a cross-modality pooling module, a domain projector, and a self-supervised link prediction objective. Extensive experiments on multiple datasets demonstrate the superiority of GNP on both commonsense and biomedical reasoning tasks across different LLM sizes and settings."}}
{"id": "wuWBHb-y_87", "cdate": 1648673110847, "mdate": 1648673110847, "content": {"title": "Surface plasmon polariton laser based on a metallic trench Fabry-Perot resonator", "abstract": "Recent years have witnessed a growing interest in the development of small-footprint lasers for potential applications in small-volume sensing and on-chip optical communications. Surface plasmons\u2014electromagnetic modes evanescently confined to metal-dielectric interfaces\u2014offer an effective route to achieving lasing at nanometer-scale dimensions when resonantly amplified in contact with a gain medium. We achieve narrow-linewidth visible-frequency lasing at room temperature by leveraging surface plasmons propagating in an open Fabry-Perot cavity formed by a flat metal surface coated with a subwavelength-thick layer of optically pumped gain medium and orthogonally bound by a pair of flat metal sidewalls. We show how the lasing threshold and linewidth can be lowered by incorporating a low-profile tapered grating on the cavity floor to couple the excitation beam into a pump surface plasmon polariton providing a strong modal overlap with the gain medium. Low-perturbation transmission-configuration sampling of the lasing plasmon mode is achieved via an evanescently coupled recessed nanoslit, opening the way to high\u2013figure of merit refractive index sensing of analytes interacting with the open metallic trench."}}
{"id": "ZNgw93LdPpV", "cdate": 1648673046056, "mdate": 1648673046056, "content": {"title": "Single-photon imager based on a superconducting nanowire delay line", "abstract": "Detecting spatial and temporal information of individual photons is critical to applications in spectroscopy, communication, biological imaging, astronomical observation and quantum-information processing. Here we demonstrate a scalable single-photon imager using a single continuous superconducting nanowire that is not only a single-photon detector but also functions as an efficient microwave delay line. In this context, photon-detection pulses are guided in the nanowire and enable the readout of the position and time of photon-absorption events from the arrival times of the detection pulses at the nanowire's two ends. Experimentally, we slowed down the velocity of pulse propagation to \u223c2% of the speed of light in free space. In a 19.7\u2005mm long nanowire that meandered across an area of 286\u2009\u00d7\u2009193\u2005\u03bcm2, we were able to resolve \u223c590 effective pixels with a temporal resolution of 50\u2005ps (full width at half maximum). The nanowire imager presents a scalable approach for high-resolution photon imaging in space and time."}}
{"id": "8seh8FR1ajU", "cdate": 1648672992004, "mdate": 1648672992004, "content": {"title": "An Analytical Method for Evaluating the Robustness of Photonic Integrated Circuits", "abstract": "We propose an efficient analytical method to evaluate the robustness of integrated photonic devices and circuits in the presence of independently-distributed random variations in the device parameters. By approximating the output of a photonic system in terms of a first or second-order Taylor series, we derive closed-form expressions for the mean and variance of the system output, which allow us to compute the one-standard-deviation (1-sigma) bounds on the expected system performance. Compared to other approaches for evaluating robustness, our method does not require computationally-intensive numerical simulations of the system output and can apply to any statistical distribution of parameter variations, including uniform and normal distributions. We demonstrate the method by analyzing the robustness of two coupled resonator systems: a fifth-order microring filter, and optical delay lines based on 1D Coupled Resonator Optical Waveguides and 2D Floquet topological microring lattice. Our method could provide a useful tool in the design and analysis of robust optical devices and circuits."}}
{"id": "-AhS-EiFLVC", "cdate": 1648672934899, "mdate": 1648672934899, "content": {"title": "Neutron: Neural Particle Swarm Optimization for Material-Aware Inverse Design of Structural Color", "abstract": "Designing optical structures for generating structural colors is challenging due to the complex relationship between the optical structures and the color perceived by human eyes. Machine learning-based inverse approaches have been applied to expedite the structural color design process due to their exceptional ability to learn complex relationships from data. However, existing methods often assume that the materials for the optical structures are fixed, which could lead to sub-optimal performance of color generation due to the inability to search for and include the best materials. To address this issue, a hybrid approach termed Neural Particle Swarm Optimization is proposed in this paper. The proposed method combines a multitask mixture density network that predicts the materials and associated design parameter values and particle swarm optimization to finetune the predicted design parameter values. The proposed method demonstrates exceptional design accuracy and efficiency on two practical tasks of designing environmental-friendly alternatives to chrome coatings and reconstructing pictures with structural colors based on multilayer optical thin films. With the proposed method, several designs that could be used to replace the chrome coating have been discovered; pictures with more than 200,000 pixels can be reconstructed within 2 to 3 hours with an almost unnoticeable difference from the original picture."}}
{"id": "gjEnEcJkZcC", "cdate": 1648672873487, "mdate": 1648672873487, "content": {"title": "Benchmarking deep learning-based models on nanophotonic inverse design problems", "abstract": "Photonic inverse design concerns the problem of finding photonic structures with target optical properties. However, traditional methods based on optimization algorithms are time-consuming and computationally expensive. Recently, deep learning-based approaches have been developed to tackle the problem of inverse design efficiently. Although most of these neural network models have demonstrated high accuracy in different inverse design problems, no previous study has examined the potential effects under given constraints in nanomanufacturing. Additionally, the relative strength of different deep learning-based inverse design approaches has not been fully investigated. Here, we benchmark three commonly used deep learning models in inverse design: Tandem networks, Variational Auto-Encoders, and Generative Adversarial Networks. We provide detailed comparisons in terms of their accuracy, diversity, and robustness. We find that tandem networks and Variational Auto-Encoders give the best accuracy, while Generative Adversarial Networks lead to the most diverse predictions. Our findings could serve as a guideline for researchers to select the model that can best suit their design criteria and fabrication considerations. In addition, our code and data are publicly available, which could be used for future inverse design model development and benchmarking."}}
{"id": "oj1BJmfF2qO", "cdate": 1640995200000, "mdate": 1675450657038, "content": {"title": "Dynamic prediction of work status for workers with occupational injuries: assessing the value of longitudinal observations", "abstract": "Occupational injuries (OIs) cause an immense burden on the US population. Prediction models help focus resources on those at greatest risk of a delayed return to work (RTW). RTW depends on factors that develop over time; however, existing methods only utilize information collected at the time of injury. We investigate the performance benefits of dynamically estimating RTW, using longitudinal observations of diagnoses and treatments collected beyond the time of initial injury."}}
{"id": "35BuRJ6dpIK", "cdate": 1609459200000, "mdate": 1675450656985, "content": {"title": "Automated multi-layer optical design via deep reinforcement learning", "abstract": ""}}
{"id": "rypT3fb0b", "cdate": 1518730159672, "mdate": null, "content": {"title": "LEARNING TO SHARE: SIMULTANEOUS PARAMETER TYING AND SPARSIFICATION IN DEEP LEARNING", "abstract": "Deep neural networks (DNNs) usually contain millions, maybe billions, of parameters/weights, making both storage and computation very expensive. This has motivated a large body of work to reduce the complexity of the neural network by using sparsity-inducing regularizers.  Another well-known approach for controlling the complexity of DNNs is parameter sharing/tying, where certain sets of weights are forced to share a common value. Some forms of weight sharing are hard-wired to express certain in- variances, with a notable example being the shift-invariance of convolutional layers. However, there may be other groups of weights that may be tied together during the learning process, thus further re- ducing the complexity of the network. In this paper, we adopt a recently proposed sparsity-inducing regularizer, named GrOWL (group ordered weighted l1), which encourages sparsity and, simulta- neously, learns which groups of parameters should share a common value. GrOWL has been proven effective in linear regression, being able to identify and cope with strongly correlated covariates. Unlike standard sparsity-inducing regularizers (e.g., l1 a.k.a. Lasso), GrOWL not only eliminates unimportant neurons by setting all the corresponding weights to zero, but also explicitly identifies strongly correlated neurons by tying the corresponding weights to a common value. This ability of GrOWL motivates the following two-stage procedure: (i) use GrOWL regularization in the training process to simultaneously identify significant neurons and groups of parameter that should be tied together; (ii) retrain the network, enforcing the structure that was unveiled in the previous phase, i.e., keeping only the significant neurons and enforcing the learned tying structure. We evaluate the proposed approach on several benchmark datasets, showing that it can dramatically compress the network with slight or even no loss on generalization performance.\n"}}
{"id": "Hkb3lEbO-S", "cdate": 1514764800000, "mdate": null, "content": {"title": "Learning Credible Models", "abstract": "In many settings, it is important that a model be capable of providing reasons for its predictions (\u0131e, the model must be interpretable). However, the model's reasoning may not conform with well-established knowledge. In such cases, while interpretable, the model lacks credibility. In this work, we formally define credibility in the linear setting and focus on techniques for learning models that are both accurate and credible. In particular, we propose a regularization penalty, expert yielded estimates (EYE), that incorporates expert knowledge about well-known relationships among covariates and the outcome of interest. We give both theoretical and empirical results comparing our proposed method to several other regularization techniques. Across a range of settings, experiments on both synthetic and real data show that models learned using the EYE penalty are significantly more credible than those learned using other penalties. Applied to two large-scale patient risk stratification task, our proposed technique results in a model whose top features overlap significantly with known clinical risk factors, while still achieving good predictive performance."}}
