{"id": "blCYlB5rzIK", "cdate": 1672531200000, "mdate": 1682385314729, "content": {"title": "Non-stationary Contextual Bandits and Universal Learning", "abstract": "We study the fundamental limits of learning in contextual bandits, where a learner's rewards depend on their actions and a known context, which extends the canonical multi-armed bandit to the case where side-information is available. We are interested in universally consistent algorithms, which achieve sublinear regret compared to any measurable fixed policy, without any function class restriction. For stationary contextual bandits, when the underlying reward mechanism is time-invariant, Blanchard et. al (2022) characterized learnable context processes for which universal consistency is achievable; and further gave algorithms ensuring universal consistency whenever this is achievable, a property known as optimistic universal consistency. It is well understood, however, that reward mechanisms can evolve over time, possibly adversarially, and depending on the learner's actions. We show that optimistic universal learning for contextual bandits with adversarial rewards is impossible in general, contrary to all previously studied settings in online learning -- including standard supervised learning. We also give necessary and sufficient conditions for universal learning under various adversarial reward models, and an exact characterization for online rewards. In particular, the set of learnable processes for these reward models is still extremely general -- larger than i.i.d., stationary or ergodic -- but in general strictly smaller than that for supervised learning or stationary contextual bandits, shedding light on new adversarial phenomena."}}
{"id": "bQoDHT4VY8", "cdate": 1672531200000, "mdate": 1682385314750, "content": {"title": "Quadratic Memory is Necessary for Optimal Query Complexity in Convex Optimization: Center-of-Mass is Pareto-Optimal", "abstract": "We give query complexity lower bounds for convex optimization and the related feasibility problem. We show that quadratic memory is necessary to achieve the optimal oracle complexity for first-order convex optimization. In particular, this shows that center-of-mass cutting-planes algorithms in dimension $d$ which use $\\tilde O(d^2)$ memory and $\\tilde O(d)$ queries are Pareto-optimal for both convex optimization and the feasibility problem, up to logarithmic factors. Precisely, we prove that to minimize $1$-Lipschitz convex functions over the unit ball to $1/d^4$ accuracy, any deterministic first-order algorithms using at most $d^{2-\\delta}$ bits of memory must make $\\tilde\\Omega(d^{1+\\delta/3})$ queries, for any $\\delta\\in[0,1]$. For the feasibility problem, in which an algorithm only has access to a separation oracle, we show a stronger trade-off: for at most $d^{2-\\delta}$ memory, the number of queries required is $\\tilde\\Omega(d^{1+\\delta})$. This resolves a COLT 2019 open problem of Woodworth and Srebro."}}
{"id": "Zk3FHLRiIMx", "cdate": 1672531200000, "mdate": 1682385314704, "content": {"title": "Contextual Bandits and Optimistically Universal Learning", "abstract": "We consider the contextual bandit problem on general action and context spaces, where the learner's rewards depend on their selected actions and an observable context. This generalizes the standard multi-armed bandit to the case where side information is available, e.g., patients' records or customers' history, which allows for personalized treatment. We focus on consistency -- vanishing regret compared to the optimal policy -- and show that for large classes of non-i.i.d. contexts, consistency can be achieved regardless of the time-invariant reward mechanism, a property known as universal consistency. Precisely, we first give necessary and sufficient conditions on the context-generating process for universal consistency to be possible. Second, we show that there always exists an algorithm that guarantees universal consistency whenever this is achievable, called an optimistically universal learning rule. Interestingly, for finite action spaces, learnable processes for universal learning are exactly the same as in the full-feedback setting of supervised learning, previously studied in the literature. In other words, learning can be performed with partial feedback without any generalization cost. The algorithms balance a trade-off between generalization (similar to structural risk minimization) and personalization (tailoring actions to specific contexts). Lastly, we consider the case of added continuity assumptions on rewards and show that these lead to universal consistency for significantly larger classes of data-generating processes."}}
{"id": "r2MjjvAcfb", "cdate": 1640995200000, "mdate": 1682385314678, "content": {"title": "Universal Online Learning with Bounded Loss: Reduction to Binary Classification", "abstract": "We study universal consistency of non-i.i.d. processes in the context of online learning. A stochastic process is said to admit universal consistency if there exists a learner that achieves vanishi..."}}
{"id": "jU7LnhCB6Sa", "cdate": 1640995200000, "mdate": 1682385314656, "content": {"title": "Universal Online Learning with Unbounded Losses: Memory Is All You Need", "abstract": "We resolve an open problem of Hanneke (2021) on the subject of universally consistent online learning with non-i.i.d. processes and unbounded losses. The notion of an optimistically universal learn..."}}
{"id": "hXOeizrjg-U", "cdate": 1640995200000, "mdate": 1682385314754, "content": {"title": "Universal Regression with Adversarial Responses", "abstract": "We provide algorithms for regression with adversarial responses under large classes of non-i.i.d. instance sequences, on general separable metric spaces, with provably minimal assumptions. We also give characterizations of learnability in this regression context. We consider universal consistency which asks for strong consistency of a learner without restrictions on the value responses. Our analysis shows that such an objective is achievable for a significantly larger class of instance sequences than stationary processes, and unveils a fundamental dichotomy between value spaces: whether finite-horizon mean estimation is achievable or not. We further provide optimistically universal learning rules, i.e., such that if they fail to achieve universal consistency, any other algorithms will fail as well. For unbounded losses, we propose a mild integrability condition under which there exist algorithms for adversarial regression under large classes of non-i.i.d. instance sequences. In addition, our analysis also provides a learning rule for mean estimation in general metric spaces that is consistent under adversarial responses without any moment conditions on the sequence, a result of independent interest."}}
{"id": "cO3Zif7yIqE", "cdate": 1640995200000, "mdate": 1682385314656, "content": {"title": "Universal Online Learning: an Optimistically Universal Learning Rule", "abstract": "We study the subject of universal online learning with non-i.i.d. processes for bounded losses. The notion of universally consistent learning was defined by Hanneke in an effort to study learning t..."}}
{"id": "W0NqKv89xkZ", "cdate": 1640995200000, "mdate": 1682385314721, "content": {"title": "Universal Online Learning with Unbounded Losses: Memory Is All You Need", "abstract": "We resolve an open problem of Hanneke on the subject of universally consistent online learning with non-i.i.d. processes and unbounded losses. The notion of an optimistically universal learning rule was defined by Hanneke in an effort to study learning theory under minimal assumptions. A given learning rule is said to be optimistically universal if it achieves a low long-run average loss whenever the data generating process makes this goal achievable by some learning rule. Hanneke posed as an open problem whether, for every unbounded loss, the family of processes admitting universal learning are precisely those having a finite number of distinct values almost surely. In this paper, we completely resolve this problem, showing that this is indeed the case. As a consequence, this also offers a dramatically simpler formulation of an optimistically universal learning rule for any unbounded loss: namely, the simple memorization rule already suffices. Our proof relies on constructing random measurable partitions of the instance space and could be of independent interest for solving other open questions. We extend the results to the non-realizable setting thereby providing an optimistically universal Bayes consistent learning rule."}}
{"id": "UIda2UKAWu", "cdate": 1640995200000, "mdate": 1682385314700, "content": {"title": "Additional Results and Extensions for the paper \"Probabilistic bounds on the k-Traveling Salesman Problem and the Traveling Repairman Problem\"", "abstract": "This technical report provides additional results for the main paper ``Probabilistic bounds on the $k-$Traveling Salesman Problem ($k-$TSP) and the Traveling Repairman Problem (TRP)''. For the $k-$TSP, we extend the probabilistic bounds derived in the main paper to the case of distributions with general densities. For the TRP, we propose a utility-based notion of fairness and derive constant-factor probabilistic bounds for this objective, thus extending the TRP bounds from the main paper to non-linear utilities."}}
{"id": "EwuHzI9ORC", "cdate": 1640995200000, "mdate": 1682385314746, "content": {"title": "Shallow and Deep Networks are Near-Optimal Approximators of Korobov Functions", "abstract": "In this paper, we analyze the number of neurons and training parameters that a neural network needs to approximate multivariate functions of bounded second mixed derivatives --- Korobov functions. We prove upper bounds on these quantities for shallow and deep neural networks, drastically lessening the curse of dimensionality. Our bounds hold for general activation functions, including ReLU. We further prove that these bounds nearly match the minimal number of parameters any continuous function approximator needs to approximate Korobov functions, showing that neural networks are near-optimal function approximators."}}
