{"id": "ptjHThVtqLS", "cdate": 1640995200000, "mdate": 1667400228654, "content": {"title": "Variational Autoencoders for Localized Mesh Deformation Component Analysis", "abstract": "Spatially localized deformation components are very useful for shape analysis and synthesis in 3D geometry processing. Several methods have recently been developed, with an aim to extract intuitive and interpretable deformation components. However, these techniques suffer from fundamental limitations especially for meshes with noise or large-scale nonlinear deformations, and may not always be able to identify important deformation components. In this paper we propose a mesh-based variational autoencoder architecture that is able to cope with meshes with irregular connectivity and nonlinear deformations, assuming that the analyzed dataset contains meshes with the same vertex connectivity, which is common for deformation analysis. To help localize deformations, we introduce sparse regularization in this framework, along with spectral graph convolutional operations. Through modifying the regularization formulation and allowing dynamic change of sparsity ranges, we improve the visual quality and reconstruction ability of the extracted deformation components. Our system also provides a nonlinear approach to reconstruction of meshes using the extracted basis, which is more effective than the current linear combination approach. As an important application of localized deformation components and a novel approach on its own, we further develop a neural shape editing method, achieving shape editing and deformation component extraction in a unified framework, and ensuring plausibility of the edited shapes. Extensive experiments show that our method outperforms state-of-the-art methods in both qualitative and quantitative evaluations. We also demonstrate the effectiveness of our method for neural shape editing."}}
{"id": "hn3G9OqT48I", "cdate": 1640995200000, "mdate": 1667400228653, "content": {"title": "A Repulsive Force Unit for Garment Collision Handling in Neural Networks", "abstract": "Despite recent success, deep learning-based methods for predicting 3D garment deformation under body motion suffer from interpenetration problems between the garment and the body. To address this problem, we propose a novel collision handling neural network layer called Repulsive Force Unit (ReFU). Based on the signed distance function (SDF) of the underlying body and the current garment vertex positions, ReFU predicts the per-vertex offsets that push any interpenetrating vertex to a collision-free configuration while preserving the fine geometric details. We show that ReFU is differentiable with trainable parameters and can be integrated into different network backbones that predict 3D garment deformations. Our experiments show that ReFU significantly reduces the number of collisions between the body and the garment and better preserves geometric details compared to prior methods based on collision loss or post-processing optimization."}}
{"id": "bUG4id9oSt_", "cdate": 1640995200000, "mdate": 1667400228785, "content": {"title": "N-Penetrate: Active Learning of Neural Collision Handler for Complex 3D Mesh Deformations", "abstract": "We present a robust learning algorithm to detect and handle collisions in 3D deforming meshes. We first train a neural network to detect collisions and then use a numerical optimization algorithm t..."}}
{"id": "JxwAI44YX5d", "cdate": 1609459200000, "mdate": 1667400228692, "content": {"title": "LCollision: Fast Generation of Collision-Free Human Poses using Learned Non-Penetration Constraints", "abstract": "We present LCollision, a learning-based method that synthesizes collision-free 3D human poses. At the crux of our approach is a novel deep architecture that simultaneously decodes new human poses from the latent space and predicts colliding body parts. These two components of our architecture are used as the objective function and surrogate hard constraints in a constrained optimization for collision-free human pose generation. A novel aspect of our approach is the use of a bilevel autoencoder that decomposes whole-body collisions into groups of collisions between localized body parts. By solving the constrained optimizations, we show that a significant amount of collision artifacts can be resolved. Furthermore, in a large test set of 2.5 \u00d7 10 6 randomized poses from SCAPE, our architecture achieves a collision-prediction accuracy of 94.1% with 80\u00d7 speedup over exact collision detection algorithms. To the best of our knowledge, LCollision is the \ufb01rst approach that accelerates collision detection and resolves penetrations using a neural network."}}
{"id": "DY27Avc9anq", "cdate": 1577836800000, "mdate": 1667400228815, "content": {"title": "Multiscale Mesh Deformation Component Analysis with Attention-based Autoencoders", "abstract": "Deformation component analysis is a fundamental problem in geometry processing and shape understanding. Existing approaches mainly extract deformation components in local regions at a similar scale while deformations of real-world objects are usually distributed in a multi-scale manner. In this paper, we propose a novel method to exact multiscale deformation components automatically with a stacked attention-based autoencoder. The attention mechanism is designed to learn to softly weight multi-scale deformation components in active deformation regions, and the stacked attention-based autoencoder is learned to represent the deformation components at different scales. Quantitative and qualitative evaluations show that our method outperforms state-of-the-art methods. Furthermore, with the multiscale deformation components extracted by our method, the user can edit shapes in a coarse-to-fine fashion which facilitates effective modeling of new shapes."}}
{"id": "BefK9xggm4", "cdate": 1577836800000, "mdate": 1667400228786, "content": {"title": "Realtime Simulation of Thin-Shell Deformable Materials Using CNN-Based Mesh Embedding", "abstract": "We address the problem of accelerating thin-shell deformable object simulations by dimension reduction. We present a new algorithm to embed a high-dimensional configuration space of deformable objects in a low-dimensional feature space, where the configurations of objects and feature points have approximate one-to-one mapping. Our key technique is a graph-based convolutional neural network (CNN) defined on meshes with arbitrary topologies and a new mesh embedding approach based on physics-inspired loss term. We have applied our approach to accelerate high-resolution thin shell simulations corresponding to cloth-like materials, where the configuration space has tens of thousands of degrees of freedom. We show that our physics-inspired embedding approach leads to higher accuracy compared with prior mesh embedding methods. Finally, we show that the temporal evolution of the mesh in the feature space can also be learned using a recurrent neural network (RNN) leading to fully learnable physics simulators. After training our learned simulator runs 500-10000\u00d7 faster and the accuracy is high enough for robot manipulation tasks."}}
{"id": "-XDXUOdl4L", "cdate": 1577836800000, "mdate": 1667400228645, "content": {"title": "DeepMNavigate: Deep Reinforced Multi-Robot Navigation Unifying Local & Global Collision Avoidance", "abstract": "We present a novel algorithm (DeepMNavigate) for global multi-agent navigation in dense scenarios using deep reinforcement learning (DRL). Our approach uses local and global information for each robot from motion information maps. We use a three-layer CNN that takes these maps as input to generate a suitable action to drive each robot to its goal position. Our approach is general, learns an optimal policy using a multi-scenario, multi-state training algorithm, and can directly handle raw sensor measurements for local observations. We demonstrate the performance on dense, complex benchmarks with narrow passages and environments with tens of agents. We highlight the algorithm\u2019s benefits over prior learning methods and geometric decentralized algorithms in complex scenarios."}}
{"id": "rkZjXxMu-r", "cdate": 1514764800000, "mdate": null, "content": {"title": "Variational Autoencoders for Deforming 3D Mesh Models", "abstract": "3D geometric contents are becoming increasingly popular. In this paper, we study the problem of analyzing deforming 3D meshes using deep neural networks. Deforming 3D meshes are \ufb02exible to represent 3D animation sequences as well as collections of objects of the same category, allowing diverse shapes with large-scale non-linear deformations. We propose a novel framework which we call mesh variational autoencoders (mesh VAE), to explore the probabilistic latent space of 3D surfaces. The framework is easy to train, and requires very few training examples. We also propose an extended model which allows \ufb02exibly adjusting the signi\ufb01cance of different latent variables by altering the prior distribution. Extensive experiments demonstrate that our general framework is able to learn a reasonable representation for a collection of deformable shapes, and produce competitive results for a variety of applications, including shape generation, shape interpolation, shape space embedding and shape exploration, outperforming state-of-the-art methods."}}
{"id": "HybI7RgO-r", "cdate": 1514764800000, "mdate": null, "content": {"title": "Mesh-Based Autoencoders for Localized Deformation Component Analysis", "abstract": "Spatially localized deformation components are very useful\r\nfor shape analysis and synthesis in 3D geometry processing.\r\nSeveral methods have recently been developed, with an aim to\r\nextract intuitive and interpretable deformation components.\r\nHowever, these techniques suffer from fundamental limitations\r\nespecially for meshes with noise or large-scale deformations,\r\nand may not always be able to identify important\r\ndeformation components. In this paper we propose a novel\r\nmesh-based autoencoder architecture that is able to cope with\r\nmeshes with irregular topology. We introduce sparse regularization\r\nin this framework, which along with convolutional operations,\r\nhelps localize deformations. Our framework is capable\r\nof extracting localized deformation components from\r\nmesh data sets with large-scale deformations and is robust to\r\nnoise. It also provides a nonlinear approach to reconstruction\r\nof meshes using the extracted basis, which is more effective\r\nthan the current linear combination approach. Extensive experiments\r\nshow that our method outperforms state-of-the-art\r\nmethods in both qualitative and quantitative evaluations."}}
{"id": "193QGSTrtUs", "cdate": 1483228800000, "mdate": 1667400228773, "content": {"title": "Mesh-based Autoencoders for Localized Deformation Component Analysis", "abstract": "Spatially localized deformation components are very useful for shape analysis and synthesis in 3D geometry processing. Several methods have recently been developed, with an aim to extract intuitive and interpretable deformation components. However, these techniques suffer from fundamental limitations especially for meshes with noise or large-scale deformations, and may not always be able to identify important deformation components. In this paper we propose a novel mesh-based autoencoder architecture that is able to cope with meshes with irregular topology. We introduce sparse regularization in this framework, which along with convolutional operations, helps localize deformations. Our framework is capable of extracting localized deformation components from mesh data sets with large-scale deformations and is robust to noise. It also provides a nonlinear approach to reconstruction of meshes using the extracted basis, which is more effective than the current linear combination approach. Extensive experiments show that our method outperforms state-of-the-art methods in both qualitative and quantitative evaluations."}}
