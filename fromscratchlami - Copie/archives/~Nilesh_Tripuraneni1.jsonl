{"id": "PxMfDdPnTfV", "cdate": 1621629859962, "mdate": null, "content": {"title": "Overparameterization Improves Robustness to Covariate Shift in High Dimensions", "abstract": "A significant obstacle in the development of robust machine learning models is \\emph{covariate shift}, a form of distribution shift that occurs when the input distributions of the training and test sets differ while the conditional label distributions remain the same. Despite the prevalence of covariate shift in real-world applications, a theoretical understanding in the context of modern machine learning has remained lacking. In this work, we examine the exact high-dimensional asymptotics of random feature regression under covariate shift and present a precise characterization of the limiting test error, bias, and variance in this setting. Our results motivate a natural partial order over covariate shifts that provides a sufficient condition for determining when the shift will harm (or even help) test performance. We find that overparameterized models exhibit enhanced robustness to covariate shift, providing one of the first theoretical explanations for this ubiquitous empirical phenomenon. Additionally, our analysis reveals an exact linear relationship between the in-distribution and out-of-distribution generalization performance, offering an explanation for this surprising recent observation."}}
{"id": "By--0iZuZH", "cdate": 1546300800000, "mdate": null, "content": {"title": "Rao-Blackwellized Stochastic Gradients for Discrete Distributions", "abstract": "We wish to compute the gradient of an expectation over a finite or countably infinite sample space having K $\\leq$ $\\infty$ categories. When K is indeed infinite, or finite but very large, the rele..."}}
{"id": "ryVGsuWdZB", "cdate": 1514764800000, "mdate": null, "content": {"title": "Stochastic Cubic Regularization for Fast Nonconvex Optimization", "abstract": "This paper proposes a stochastic variant of a classic algorithm---the cubic-regularized Newton method [Nesterov and Polyak]. The proposed algorithm efficiently escapes saddle points and finds approximate local minima for general smooth, nonconvex functions in only $\\mathcal{\\tilde{O}}(\\epsilon^{-3.5})$ stochastic gradient and stochastic Hessian-vector product evaluations. The latter can be computed as efficiently as stochastic gradients. This improves upon the $\\mathcal{\\tilde{O}}(\\epsilon^{-4})$ rate of stochastic gradient descent. Our rate matches the best-known result for finding local minima without requiring any delicate acceleration or variance-reduction techniques."}}
{"id": "SJ-Vio-OZS", "cdate": 1483228800000, "mdate": null, "content": {"title": "Lost Relatives of the Gumbel Trick", "abstract": "The Gumbel trick is a method to sample from a discrete probability distribution, or to estimate its normalizing partition function. The method relies on repeatedly applying a random perturbation to..."}}
{"id": "BybTMhWubS", "cdate": 1483228800000, "mdate": null, "content": {"title": "Magnetic Hamiltonian Monte Carlo", "abstract": "Hamiltonian Monte Carlo (HMC) exploits Hamiltonian dynamics to construct efficient proposals for Markov chain Monte Carlo (MCMC). In this paper, we present a generalization of HMC which exploits no..."}}
{"id": "rkZfUD-OZB", "cdate": 1420070400000, "mdate": null, "content": {"title": "Particle Gibbs for Infinite Hidden Markov Models", "abstract": "Infinite Hidden Markov Models (iHMM's) are an attractive, nonparametric generalization of the classical Hidden Markov Model which can automatically infer the number of hidden states in the system. However, due to the infinite-dimensional nature of the transition dynamics, performing inference in the iHMM is difficult. In this paper, we present an infinite-state Particle Gibbs (PG) algorithm to resample state trajectories for the iHMM. The proposed algorithm uses an efficient proposal optimized for iHMMs, and leverages ancestor sampling to improve the mixing of the standard PG algorithm. Our algorithm demonstrates significant convergence improvements on synthetic and real world data sets."}}
