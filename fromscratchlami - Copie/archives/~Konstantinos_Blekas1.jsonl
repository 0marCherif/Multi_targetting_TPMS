{"id": "KiOoY96N1x3", "cdate": 1672531200000, "mdate": 1682326085371, "content": {"title": "Hierarchical multiagent reinforcement learning schemes for air traffic management", "abstract": "In this work we investigate the use of hierarchical multiagent reinforcement learning methods for the computation of policies to resolve congestion problems in the air traffic management domain. To address cases where the demand of airspace use exceeds capacity, we consider agents representing flights, who need to decide on ground delays at the pre-tactical stage of operations, towards executing their trajectories while adhering to airspace capacity constraints. Hierarchical reinforcement learning manages to handle real-world problems with high complexity, by partitioning the task into hierarchies of states and/or actions. This provides an efficient way of exploring the state\u2013action space and constructing an advantageous decision-making mechanism. We first establish a general framework of hierarchical multiagent reinforcement learning, and then, we further formulate four alternative schemes of abstractions, on states, actions, or both. To quantitatively assess the quality of solutions of the proposed approaches and show the potential of the hierarchical methods in resolving the demand\u2013capacity balance problem, we provide experimental results on real-world evaluation cases, where we measure the average delay per flight and the number of flights with delays."}}
{"id": "bNp2bChmxps", "cdate": 1640995200000, "mdate": 1682326085402, "content": {"title": "Multi-label sampling based on local label imbalance", "abstract": ""}}
{"id": "yWBTreJY7G0", "cdate": 1577836800000, "mdate": 1682326085361, "content": {"title": "Multiple mini-robots navigation using a collaborative multiagent reinforcement learning framework", "abstract": "In this work we investigate the use of a reinforcement learning (RL) framework for the autonomous navigation of a group of mini-robots in a multi-agent collaborative environment. Each mini-robot is..."}}
{"id": "QRijkezB8X", "cdate": 1577836800000, "mdate": 1682326085366, "content": {"title": "Identification of Brain Functional Networks Using a Model-Based Approach", "abstract": "Functional MRI (fMRI) is a valuable brain imaging technique. A significant problem, when analyzing fMRI time series, is the finding of functional brain networks when the brain is at rest, i.e. no e..."}}
{"id": "P1dk3E8ieMj", "cdate": 1577836800000, "mdate": 1682326085365, "content": {"title": "Double deep multiagent reinforcement learning for autonomous driving in traffic maps with road segments and unsignaled intersections", "abstract": "In this work we present an advanced deep multiagent reinforcement learning scheme for autonomous driving of multiple vehicles in traffic networks with road segments and unsignaled intersections. The key aspect of the proposed method lies on the definition of the possible routes one vehicle can follow as agents, called route-agents, that allows the transfer learning and the reuse of their learned policies. An informative state space is constructed by introducing a collision matrix that \u201cdisplays\u201d a predictive traffic map of the intersections that the vehicles traverse. Also, an efficient reward function is designed that aims at providing optimal driving policies in order to navigate vehicles safely and rapidly to their destinations, avoiding collisions. A combined scheme of a Deep Q-Network (DQN) and a feedforward neural network along with the Double Q-leaning technique is employed that offers more stable solutions. Several experiments were made in simulated road traffic maps that empirically illustrate the efficiency of the proposed deep multiagent framework."}}
{"id": "OfegG-PT5Kd", "cdate": 1577836800000, "mdate": 1636556948155, "content": {"title": "Multi-Label Sampling based on Local Label Imbalance", "abstract": "Class imbalance is an inherent characteristic of multi-label data that hinders most multi-label learning methods. One efficient and flexible strategy to deal with this problem is to employ sampling techniques before training a multi-label learning model. Although existing multi-label sampling approaches alleviate the global imbalance of multi-label datasets, it is actually the imbalance level within the local neighbourhood of minority class examples that plays a key role in performance degradation. To address this issue, we propose a novel measure to assess the local label imbalance of multi-label datasets, as well as two multi-label sampling approaches based on the local label imbalance, namely MLSOL and MLUL. By considering all informative labels, MLSOL creates more diverse and better labeled synthetic instances for difficult examples, while MLUL eliminates instances that are harmful to their local region. Experimental results on 13 multi-label datasets demonstrate the effectiveness of the proposed measure and sampling approaches for a variety of evaluation metrics, particularly in the case of an ensemble of classifiers trained on repeated samples of the original data."}}
{"id": "FYYanDPbF4w", "cdate": 1577836800000, "mdate": 1682326085544, "content": {"title": "Apprenticeship learning of flight trajectories prediction with inverse reinforcement learning", "abstract": "One of the primary goals of Artificial Intelligence research is to develop machines with human-like intelligence, perception and reasoning. In this direction teaching apprentice agents by observing demonstrations delivered by experts is a framework of imitation learning that can provide improved solutions and it is possible to significantly outperform the demonstrator. Inverse reinforcement learning (IRL) is a paradigm relying on Markov Decision Processes (MDPs) that has a twofold target: to learn optimum policies of autonomous agents for solving complex tasks from successful demonstrations, and also to discover the unknown reward function that could explain the expert behavior. In this article we are addressing the trajectory prediction problem in the aviation domain by using an IRL approach. The proposed learning scheme provides an imitation process where the algorithm tries to imitate demonstrated trajectories, exploiting raw trajectory data enriched with contextual features and learn an efficient reward model that is learned during imitation and has generalization capabilities to unknown cases. We show several experimental results using real trajectory data from the Spanish FIR that confirms the effectiveness of our approach in automatically predicting trajectories."}}
{"id": "hwxcSZd3T-y", "cdate": 1546300800000, "mdate": 1682326085379, "content": {"title": "Collaborative multiagent reinforcement learning schemes for air traffic management", "abstract": "In this work we investigate the use of hierarchical collaborative reinforcement learning methods (H-CMARL) for the computation of joint policies to resolve congestion problems in the Air Traffic Management (ATM) domain. In particular, to address cases where the demand of airspace use exceeds capacity, we consider agents representing flights, who need to decide jointly on ground delays at the pre-tactical stage of operations, towards executing their trajectories while adhering to airspace capacity constraints. In doing so, agents collaborate, applying collaborative multi-agent reinforcement learning methods. Specifically, starting from a multiagent Markov Decision Process problem formulation, we introduce a flat and a hierarchical collaborative multiagent reinforcement learning method at two levels (the ground and an abstract one). To quantitatively assess the quality of solutions of the proposed approaches and show the potential of the hierarchical method in resolving the demand-capacity balance problems, we provide experimental results on real-world evaluation cases, where we measure the average delay of flights and the number of flights with delays."}}
{"id": "8QXC-ihBKE", "cdate": 1546300800000, "mdate": 1682326085368, "content": {"title": "Resolving Congestions in the Air Traffic Management Domain via Multiagent Reinforcement Learning Methods", "abstract": "In this article, we report on the efficiency and effectiveness of multiagent reinforcement learning methods (MARL) for the computation of flight delays to resolve congestion problems in the Air Traffic Management (ATM) domain. Specifically, we aim to resolve cases where demand of airspace use exceeds capacity (demand-capacity problems), via imposing ground delays to flights at the pre-tactical stage of operations (i.e. few days to few hours before operation). Casting this into the multiagent domain, agents, representing flights, need to decide on own delays w.r.t. own preferences, having no information about others' payoffs, preferences and constraints, while they plan to execute their trajectories jointly with others, adhering to operational constraints. Specifically, we formalize the problem as a multiagent Markov Decision Process (MA-MDP) and we show that it can be considered as a Markov game in which interacting agents need to reach an equilibrium: What makes the problem more interesting is the dynamic setting in which agents operate, which is also due to the unforeseen, emergent effects of their decisions in the whole system. We propose collaborative multiagent reinforcement learning methods to resolve demand-capacity imbalances: Extensive experimental study on real-world cases, shows the potential of the proposed approaches in resolving problems, while advanced visualizations provide detailed views towards understanding the quality of solutions provided."}}
{"id": "6Y9-VZEArj7", "cdate": 1546300800000, "mdate": 1682326085548, "content": {"title": "Navigation of inertial forces driven mini-robots using reinforcement learning", "abstract": "In this paper we propose a reinforcement learning (RL) framework for the autonomous navigation of a pair of mini-robots that are driven by inertial forces. The inertial forces are provided by two vibration motors on each mini-robot which are controlled by a simple and efficient low-level speed controller. The action of the RL agent is the direction of the velocity of each mini-robot, and it based on the position of each mini-robot, the distance between the mini-robots, and the sign of the distance gradient. Each mini-robot is considered as a moving obstacle to the other that must by avoided. We have introduced a suitable reward function that results into an efficient collaborative RL approach. A simulation environment is created using the ROS framework, that include the dynamic model of the mini-robot and of the vibration motors. Several application scenarios are simulated, and the presented results demonstrate the performance of the proposed framework."}}
