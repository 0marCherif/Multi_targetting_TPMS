{"id": "4rXMRuoJlai", "cdate": 1663850248405, "mdate": null, "content": {"title": "Mind's Eye: Grounded Language Model Reasoning through Simulation", "abstract": "Successful and effective communication between humans and AI relies on a shared experience of the world. By training solely on written text, current language models (LMs) miss the grounded experience of humans in the real-world---their failure to relate language to the physical world causes knowledge to be misrepresented and obvious mistakes in their reasoning. We present Mind's Eye, a paradigm to ground language model reasoning in the physical world. Given a physical reasoning question, we use a computational physics engine (DeepMind's MuJoCo) to simulate the possible outcomes, and then use the simulation results as part of the input, which enables language models to perform reasoning. Experiments on 39 tasks in a physics alignment benchmark demonstrate that Mind's Eye can improve reasoning ability by a large margin (27.9% zero-shot, and 46.0% few-shot absolute accuracy improvement on average). Smaller language models armed with Mind's Eye can obtain similar performance to models that are 100x larger. Finally, we confirm the robustness of Mind's Eye through ablation studies."}}
{"id": "u6OfmaGIya1", "cdate": 1652737614856, "mdate": null, "content": {"title": "Second Thoughts are Best: Learning to Re-Align With Human Values from Text Edits", "abstract": "We present Second Thoughts, a new learning paradigm that enables language models (LMs) to re-align with human values. By modeling the chain-of-edits between value-unaligned and value-aligned text, with LM fine-tuning and additional refinement through reinforcement learning, Second Thoughts not only achieves superior performance in three value alignment benchmark datasets but also shows strong human-value transfer learning ability in few-shot scenarios. The generated editing steps also offer better interpretability and ease for interactive error correction. Extensive human evaluations further confirm its effectiveness."}}
{"id": "m_XGQz_LO36", "cdate": 1640995200000, "mdate": 1672645691915, "content": {"title": "Aligning Generative Language Models with Human Values", "abstract": ""}}
{"id": "jp-Xglj2_m", "cdate": 1640995200000, "mdate": 1671856884343, "content": {"title": "Non-Parallel Text Style Transfer with Self-Parallel Supervision", "abstract": "The performance of existing text style transfer models is severely limited by the non-parallel datasets on which the models are trained. In non-parallel datasets, no direct mapping exists between sentences of the source and target style; the style transfer models thus only receive weak supervision of the target sentences during training, which often leads the model to discard too much style-independent information, or utterly fail to transfer the style. In this work, we propose LaMer, a novel text style transfer framework based on large-scale language models. LaMer first mines the roughly parallel expressions in the non-parallel datasets with scene graphs, and then employs MLE training, followed by imitation learning refinement, to leverage the intrinsic parallelism within the data. On two benchmark tasks (sentiment & formality transfer) and a newly proposed challenging task (political stance transfer), our model achieves qualitative advances in transfer accuracy, content preservation, and fluency. Further empirical and human evaluations demonstrate that our model not only makes training more efficient, but also generates more readable and diverse expressions than previous models."}}
{"id": "g0wPRwanTuk", "cdate": 1640995200000, "mdate": 1671856884342, "content": {"title": "Knowledge Infused Decoding", "abstract": "Pre-trained language models (LMs) have been shown to memorize a substantial amount of knowledge from the pre-training corpora; however, they are still limited in recalling factually correct knowledge given a certain context. Hence. they tend to suffer from counterfactual or hallucinatory generation when used in knowledge-intensive natural language generation (NLG) tasks. Recent remedies to this problem focus on modifying either the pre-training or task fine-tuning objectives to incorporate knowledge, which normally require additional costly training or architecture modification of LMs for practical applications. We present Knowledge Infused Decoding (KID)---a novel decoding algorithm for generative LMs, which dynamically infuses external knowledge into each step of the LM decoding. Specifically, we maintain a local knowledge memory based on the current context, interacting with a dynamically created external knowledge trie, and continuously update the local memory as a knowledge-aware constraint to guide decoding via reinforcement learning. On six diverse knowledge-intensive NLG tasks, task-agnostic LMs (e.g., GPT-2 and BART) armed with KID outperform many task-optimized state-of-the-art models, and show particularly strong performance in few-shot scenarios over seven related knowledge-infusion techniques. Human evaluation confirms KID's ability to generate more relevant and factual language for the input context when compared with multiple baselines. Finally, KID also alleviates exposure bias and provides stable generation quality when generating longer sequences."}}
{"id": "RVBDOr5BXN2", "cdate": 1640995200000, "mdate": 1672645692777, "content": {"title": "Quantifying and alleviating political bias in language models", "abstract": ""}}
{"id": "OjstuSCnEX", "cdate": 1640995200000, "mdate": 1672645692771, "content": {"title": "Dynamic Structural Role Node Embedding for User Modeling in Evolving Networks", "abstract": ""}}
{"id": "JPergJtlS35", "cdate": 1640995200000, "mdate": 1682369043205, "content": {"title": "EnDex: Evaluation of Dialogue Engagingness at Scale", "abstract": ""}}
{"id": "Fwebonq_z6", "cdate": 1640995200000, "mdate": 1683746182427, "content": {"title": "Second Thoughts are Best: Learning to Re-Align With Human Values from Text Edits", "abstract": "We present Second Thoughts, a new learning paradigm that enables language models (LMs) to re-align with human values. By modeling the chain-of-edits between value-unaligned and value-aligned text, with LM fine-tuning and additional refinement through reinforcement learning, Second Thoughts not only achieves superior performance in three value alignment benchmark datasets but also shows strong human-value transfer learning ability in few-shot scenarios. The generated editing steps also offer better interpretability and ease for interactive error correction. Extensive human evaluations further confirm its effectiveness."}}
{"id": "-TSe5o7STVR", "cdate": 1632875748125, "mdate": null, "content": {"title": "Non-Parallel Text Style Transfer with Self-Parallel Supervision", "abstract": "The performance of existing text style transfer models is severely limited by the non-parallel datasets on which the models are trained. In non-parallel datasets, no direct mapping exists between sentences of the source and target style; the style transfer models thus only receive weak supervision of the target sentences during training, which often leads the model to discard too much style-independent information, or utterly fail to transfer the style.\n\nIn this work, we propose LaMer, a novel text style transfer framework based on large-scale language models. LaMer first mines the roughly parallel expressions in the non-parallel datasets with scene graphs, and then employs MLE training, followed by imitation learning refinement, to leverage the intrinsic parallelism within the data. On two benchmark tasks (sentiment & formality transfer) and a newly proposed challenging task (political stance transfer), our model achieves qualitative advances in transfer accuracy, content preservation, and fluency. Further empirical and human evaluations demonstrate that our model not only makes training more efficient, but also generates more readable and diverse expressions than previous models."}}
