{"id": "EArll-Jmhpz", "cdate": 1674014433265, "mdate": 1674014433265, "content": {"title": "Interpretable AI in Healthcare: Enhancing Fairness, Safety, and Trust", "abstract": "The value and future potentials of AI in healthcare are becoming self-evident, presenting an escalating body of evidence. However, the adoption into clinical practice is still significantly impacted by the lack of transparency, stemming from inadequate focus on human-comprehensive information from AI, i.e. Interpretable AI. AI interpretations of uncertainty, significance, and causality translate to a more fair, safe, and reliable AI. This is especially pertinent to safer clinical decision making and for minimising any risk to the patient. In this chapter we aim to elucidate what interpretability means and why most machine learning (i.e. AI) models fail to satisfy these definitions. We lay this phenomenon out through what we believe to be its canonical components: predictions, uncertainty, significance, and causality; explaining how these different types of interpretations can support various explanations and how overcoming this barrier can permit the adoption of AI into healthcare."}}
{"id": "dbZELM6v43s", "cdate": 1674007826209, "mdate": 1674007826209, "content": {"title": "Generalising uncertainty improves accuracy and safety of deep learning analytics applied to oncology", "abstract": "Trust and transparency are critical for deploying deep learning (DL) models into the clinic. DL application poses generalisation obstacles since training/development datasets often have different data distributions to clinical/production datasets that can lead to incorrect predictions with underestimated uncertainty. To investigate this pitfall, we benchmarked one pointwise and three approximate Bayesian DL models used to predict cancer of unknown primary with three independent RNA-seq datasets covering 10,968 samples across 57 primary cancer types. Our results highlight simple and scalable Bayesian DL significantly improves the generalisation of uncertainty estimation (e.g., p-value\u2009=\u20090.0013 for calibration). Moreover, we demonstrate Bayesian DL substantially improves accuracy under data distributional shifts when utilising \u2018uncertainty thresholding\u2019 by designing a prototypical metric that evaluates the expected (accuracy) loss when deploying models from development to production, which we call the Area between Development and Production curve (ADP). In summary, Bayesian DL is a hopeful avenue of research for generalising uncertainty, which improves performance, transparency, and therefore safety of DL models for deployment in real-world."}}
