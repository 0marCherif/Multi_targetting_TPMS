{"id": "LLM_kOyn4X", "cdate": 1648686354946, "mdate": null, "content": {"title": "Learning to Align Sequential Actions in the Wild", "abstract": "State-of-the-art methods for self-supervised sequential action alignment rely on deep networks that find correspondences across videos in time. They either learn frame-toframe mapping across sequences, which does not leverage temporal information, or assume monotonic alignment between each video pair, which ignores variations in the order of actions. As such, these methods are not able to deal with common real-world scenarios that involve background frames or videos that contain non-monotonic sequence of actions.\n\nIn this paper, we propose an approach to align sequential actions in the wild that involve diverse temporal variations. To this end, we propose an approach to enforce temporal priors on the optimal transport matrix, which leverages temporal consistency, while allowing for variations in the order of actions. Our model accounts for both monotonic and non-monotonic sequences and handles background frames that should not be aligned. We demonstrate that our approach consistently outperforms the stateof-the-art in self-supervised sequential action representation learning on four different benchmark datasets.\n"}}
{"id": "603pNbPklFX", "cdate": 1648686168796, "mdate": null, "content": {"title": "Leveraging Self-Supervision for Cross-Domain Crowd Counting", "abstract": "State-of-the-art methods for counting people in crowded scenes rely on deep networks to estimate crowd density. While effective, these data-driven approaches rely on large amount of data annotation to achieve good performance, which stops these models from being deployed in emergencies during which data annotation is either too costly or cannot be obtained fast enough.\n\n One popular solution is to use synthetic data for training. Unfortunately, due to domain shift, the resulting models generalize poorly on real imagery. We remedy this shortcoming by training with both synthetic images, along with their associated labels, and unlabeled real images. To this end, we force our network to learn perspective-aware features by training it to recognize upside-down real images from regular ones and incorporate into it the ability to predict its own uncertainty so that it can generate useful pseudo labels for fine-tuning purposes. This yields an algorithm that consistently outperforms state-of-the-art cross-domain crowd counting ones without any extra computation at inference time.\n"}}
{"id": "QXXkis8TBH4", "cdate": 1648686083424, "mdate": null, "content": {"title": "Counting People by Estimating People Flows", "abstract": "Modern methods for counting people in crowded scenes rely on deep networks to estimate people densities in individual\nimages. As such, only very few take advantage of temporal consistency in video sequences, and those that do only impose weak\nsmoothness constraints across consecutive frames. In this paper, we advocate estimating people flows across image locations\nbetween consecutive images and inferring the people densities from these flows instead of directly regressing them. This enables us to\nimpose much stronger constraints encoding the conservation of the number of people. As a result, it significantly boosts performance\nwithout requiring a more complex architecture. Furthermore, it allows us to exploit the correlation between people flow and optical flow\nto further improve the results. We also show that leveraging people conservation constraints in both a spatial and temporal manner\nmakes it possible to train a deep crowd counting model in an active learning setting with much fewer annotations. This significantly\nreduces the annotation cost while still leading to similar performance to the full supervision case.\n"}}
{"id": "VXiIX74059", "cdate": 1579510842204, "mdate": null, "content": {"title": "Geometric and Physical Constraints for Drone-Based Head Plane Crowd Density Estimation", "abstract": "State-of-the-art methods for counting people in crowded scenes rely on deep networks to estimate crowd density in the image plane. While useful for this purpose, this image plane density has no immediate physical meaning because it is\nsubject to perspective distortion. This is a concern in sequences acquired by drones because the viewpoint changes often. This distortion is usually handled implicitly by either learning scale-invariant features or estimating density in patches of different sizes, neither of which accounts for the fact that scale changes must be consistent over the whole scene.\n\nIn this paper, we explicitly model the scale changes and reason in terms of people per square-meter. We show that feeding the perspective model to the network allows us to enforce global scale consistency and that this model can be obtained on the fly from the drone sensors. In addition, it also enables us to enforce physically-inspired temporal consistency constraints that do not have to be learned. This yields an algorithm that outperforms state-of-the-art methods in inferring crowd density from a moving drone camera especially when perspective effects are strong."}}
{"id": "rjee5_RMeupB", "cdate": 1546300800000, "mdate": null, "content": {"title": "Context-Aware Crowd Counting.", "abstract": "State-of-the-art methods for counting people in crowded scenes rely on deep networks to estimate crowd density. They typically use the same filters over the whole image or over large image patches. Only then do they estimate local scale to compensate for perspective distortion. This is typically achieved by training an auxiliary classifier to select, for predefined image patches, the best kernel size among a limited set of choices. As such, these methods are not end-to-end trainable and restricted in the scope of context they can leverage. In this paper, we introduce an end-to-end trainable deep architecture that combines features obtained using multiple receptive field sizes and learns the importance of each such feature at each image location. In other words, our approach adaptively encodes the scale of the contextual information required to accurately predict crowd density. This yields an algorithm that outperforms state-of-the-art crowd counting methods, especially when perspective effects are strong."}}
