{"id": "e7Niyz2jQDJ", "cdate": 1685982299933, "mdate": null, "content": {"title": "On Imitation in Mean-field Games", "abstract": "We explore the problem of imitation learning (IL) in the context of mean-field games (MFGs), where the goal is to imitate the behavior of a population of agents following a Nash equilibrium policy according to some unknown payoff function. IL in MFGs presents new challenges compared to single-agent IL, particularly when both the reward function and the transition kernel depend on the population distribution. In this paper, departing from the existing literature on IL for MFGs, we introduce a new solution concept called the Nash imitation gap. Then we show that when only the reward depends on the population distribution, IL in MFGs can be reduced to single-agent IL with similar guarantees. However, when the dynamics is population-dependent, we provide a novel upper-bound that suggests IL is harder in this setting. To address this issue, we propose a new adversarial formulation where the reinforcement learning problem is replaced by a mean-field control (MFC) problem, suggesting progress in IL within MFGs may have to build upon MFC."}}
{"id": "JdEkjes56Q", "cdate": 1683898621042, "mdate": 1683898621042, "content": {"title": "DeepSets and their derivative networks for solving symmetric PDEs", "abstract": "Machine learning methods for solving nonlinear partial differential equations (PDEs) are hot topical issues, and different algorithms proposed in the literature show efficient numerical approximation in high dimension. In this paper, we introduce a class of PDEs that are invariant to permutations, and called symmetric PDEs. Such pro- blems are widespread, ranging from cosmology to quantum mechanics, and option pricing/hedging in multi-asset market with exchangeable payoff. Our main applica- tion comes actually from the particles approximation of mean-field control problems. We design deep learning algorithms based on certain types of neural networks, named PointNet and DeepSet (and their associated derivative networks), for computing simul- taneously an approximation of the solution and its gradient to symmetric PDEs. We illustrate the performance and accuracy of the PointNet/DeepSet networks compared to classical feedforward ones, and provide several numerical results of our algorithm for the examples of a mean-field systemic risk, mean-variance problem and a min/max linear quadratic McKean-Vlasov control problem"}}
{"id": "v-wrIWIlsHr", "cdate": 1672531200000, "mdate": 1681728700788, "content": {"title": "Recent Developments in Machine Learning Methods for Stochastic Control and Games", "abstract": "Stochastic optimal control and games have found a wide range of applications, from finance and economics to social sciences, robotics and energy management. Many real-world applications involve complex models which have driven the development of sophisticated numerical methods. Recently, computational methods based on machine learning have been developed for stochastic control problems and games. We review such methods, with a focus on deep learning algorithms that have unlocked the possibility to solve such problems even when the dimension is high or when the structure is very complex, beyond what is feasible with traditional numerical methods. Here, we consider mostly the continuous time and continuous space setting. Many of the new approaches build on recent neural-network based methods for high-dimensional partial differential equations or backward stochastic differential equations, or on model-free reinforcement learning for Markov decision processes that have led to breakthrough results. In this paper we provide an introduction to these methods and summarize state-of-the-art works on machine learning for stochastic control and games."}}
{"id": "DQUlOzidJB", "cdate": 1672531200000, "mdate": 1681728701199, "content": {"title": "Deep Learning for Mean Field Optimal Transport", "abstract": "Mean field control (MFC) problems have been introduced to study social optima in very large populations of strategic agents. The main idea is to consider an infinite population and to simplify the analysis by using a mean field approximation. These problems can also be viewed as optimal control problems for McKean-Vlasov dynamics. They have found applications in a wide range of fields, from economics and finance to social sciences and engineering. Usually, the goal for the agents is to minimize a total cost which consists in the integral of a running cost plus a terminal cost. In this work, we consider MFC problems in which there is no terminal cost but, instead, the terminal distribution is prescribed. We call such problems mean field optimal transport problems since they can be viewed as a generalization of classical optimal transport problems when mean field interactions occur in the dynamics or the running cost function. We propose three numerical methods based on neural networks. The first one is based on directly learning an optimal control. The second one amounts to solve a forward-backward PDE system characterizing the solution. The third one relies on a primal-dual approach. We illustrate these methods with numerical experiments conducted on two families of examples."}}
{"id": "z5qhU8SHMi", "cdate": 1640995200000, "mdate": 1681728701144, "content": {"title": "Learning Mean Field Games: A Survey", "abstract": "Non-cooperative and cooperative games with a very large number of players have many applications but remain generally intractable when the number of players increases. Introduced by Lasry and Lions, and Huang, Caines and Malham\\'e, Mean Field Games (MFGs) rely on a mean-field approximation to allow the number of players to grow to infinity. Traditional methods for solving these games generally rely on solving partial or stochastic differential equations with a full knowledge of the model. Recently, Reinforcement Learning (RL) has appeared promising to solve complex problems. By combining MFGs and RL, we hope to solve games at a very large scale both in terms of population size and environment complexity. In this survey, we review the quickly growing recent literature on RL methods to learn Nash equilibria in MFGs. We first identify the most common settings (static, stationary, and evolutive). We then present a general framework for classical iterative methods (based on best-response computation or policy evaluation) to solve MFGs in an exact way. Building on these algorithms and the connection with Markov Decision Processes, we explain how RL can be used to learn MFG solutions in a model-free way. Last, we present numerical illustrations on a benchmark problem, and conclude with some perspectives."}}
{"id": "z1GVGutMTN", "cdate": 1640995200000, "mdate": 1681728701112, "content": {"title": "Concave Utility Reinforcement Learning: The Mean-field Game Viewpoint", "abstract": ""}}
{"id": "ukMciag96a", "cdate": 1640995200000, "mdate": 1681728700958, "content": {"title": "DeepSets and Their Derivative Networks for Solving Symmetric PDEs", "abstract": "Machine learning methods for solving nonlinear partial differential equations (PDEs) are hot topical issues, and different algorithms proposed in the literature show efficient numerical approximation in high dimension. In this paper, we introduce a class of PDEs that are invariant to permutations, and called symmetric PDEs. Such problems are widespread, ranging from cosmology to quantum mechanics, and option pricing/hedging in multi-asset market with exchangeable payoff. Our main application comes actually from the particles approximation of mean-field control problems. We design deep learning algorithms based on certain types of neural networks, named PointNet and DeepSet (and their associated derivative networks), for computing simultaneously an approximation of the solution and its gradient to symmetric PDEs. We illustrate the performance and accuracy of the PointNet/DeepSet networks compared to classical feedforward ones, and provide several numerical results of our algorithm for the examples of a mean-field systemic risk, mean-variance problem and a min/max linear quadratic McKean-Vlasov control problem."}}
{"id": "tacBnHFNtZK", "cdate": 1640995200000, "mdate": 1681728701112, "content": {"title": "Solving N-Player Dynamic Routing Games with Congestion: A Mean-Field Approach", "abstract": ""}}
{"id": "rDFW8-fVNf6", "cdate": 1640995200000, "mdate": 1681728701064, "content": {"title": "Optimal Incentives to Mitigate Epidemics: A Stackelberg Mean Field Game Approach", "abstract": "Motivated by the models of epidemic control in large populations, we consider a Stackelberg mean field game model between a principal and a mean field of agents whose states evolve in a finite state space. The agents play a noncooperative game in which they control their rates of transition between states to minimize an individual cost. The principal influences the nature of the resulting Nash equilibrium through incentives to optimize its own objective. We analyze this game using a probabilistic approach. We then propose an application to an epidemic model of SIR type in which the agents control the intensities of their interactions, and the principal is a regulator acting with nonpharmaceutical interventions. To compute the solutions, we propose an innovative numerical approach based on Monte Carlo simulations and machine learning tools for stochastic optimization. We conclude with numerical experiments illustrating the impact of the agents' and the regulator's optimal decisions in two specific models: a basic SIR model with semiexplicit solutions and a more complex model with a larger state space."}}
{"id": "nVU1asQW6ZZ", "cdate": 1640995200000, "mdate": 1681728701158, "content": {"title": "Learning Correlated Equilibria in Mean-Field Games", "abstract": "The designs of many large-scale systems today, from traffic routing environments to smart grids, rely on game-theoretic equilibrium concepts. However, as the size of an $N$-player game typically grows exponentially with $N$, standard game theoretic analysis becomes effectively infeasible beyond a low number of players. Recent approaches have gone around this limitation by instead considering Mean-Field games, an approximation of anonymous $N$-player games, where the number of players is infinite and the population's state distribution, instead of every individual player's state, is the object of interest. The practical computability of Mean-Field Nash equilibria, the most studied Mean-Field equilibrium to date, however, typically depends on beneficial non-generic structural properties such as monotonicity or contraction properties, which are required for known algorithms to converge. In this work, we provide an alternative route for studying Mean-Field games, by developing the concepts of Mean-Field correlated and coarse-correlated equilibria. We show that they can be efficiently learnt in \\emph{all games}, without requiring any additional assumption on the structure of the game, using three classical algorithms. Furthermore, we establish correspondences between our notions and those already present in the literature, derive optimality bounds for the Mean-Field - $N$-player transition, and empirically demonstrate the convergence of these algorithms on simple games."}}
