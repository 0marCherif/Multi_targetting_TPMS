{"id": "uKAjVYSt1eK", "cdate": 1640995200000, "mdate": 1675601784958, "content": {"title": "Contextual Pandora's Box", "abstract": "Pandora's Box is a fundamental stochastic optimization problem, where the decision-maker must find a good alternative while minimizing the search cost of exploring the value of each alternative. In the original formulation, it is assumed that accurate distributions are given for the values of all the alternatives, while recent work studies the online variant of Pandora's Box where the distributions are originally unknown. In this work, we study Pandora's Box in the online setting, while incorporating context. At every round, we are presented with a number of alternatives each having a context, an exploration cost and an unknown value drawn from an unknown distribution that may change at every round. Our main result is a no-regret algorithm that performs comparably well to the optimal algorithm which knows all prior distributions exactly. Our algorithm works even in the bandit setting where the algorithm never learns the values of the alternatives that were not explored. The key technique that enables our result is a novel modification of the realizability condition in contextual bandits that connects a context to a sufficient statistic of each alternative's distribution (its \"reservation value\") rather than its mean."}}
{"id": "OEwjG1m2eP9", "cdate": 1640995200000, "mdate": 1675601784832, "content": {"title": "Parallel model exploration for tumor treatment simulations", "abstract": "Computational systems and methods are often being used in biological research, including the understanding of cancer and the development of treatments. Simulations of tumor growth and its response to..."}}
{"id": "LNGiQlRlI-k", "cdate": 1640995200000, "mdate": 1675601784759, "content": {"title": "Asymptotically-Optimal Gaussian Bandits with Side Observations", "abstract": "We study the problem of Gaussian bandits with general side information, as first introduced by Wu, Szepesv\u00e1ri, and Gy\u00f6rgy. In this setting, the play of an arm reveals information about other arms, ..."}}
{"id": "E6F_0gKyEB", "cdate": 1640995200000, "mdate": 1675601784788, "content": {"title": "Towards Statistical and Computational Complexities of Polyak Step Size Gradient Descent", "abstract": "We study the statistical and computational complexities of the Polyak step size gradient descent algorithm under generalized smoothness and {\u0141}ojasiewicz conditions of the population loss function, namely, the limit of the empirical loss function when the sample size goes to infinity, and the stability between the gradients of the empirical and population loss functions, namely, the polynomial growth on the concentration bound between the gradients of sample and population loss functions. We demonstrate that the Polyak step size gradient descent iterates reach a final statistical radius of convergence around the true parameter after logarithmic number of iterations in terms of the sample size. It is computationally cheaper than the polynomial number of iterations on the sample size of the fixed-step size gradient descent algorithm to reach the same final statistical radius when the population loss function is not locally strongly convex. Finally, we illustrate our general theory under three statistical examples: generalized linear model, mixture model, and mixed linear regression model."}}
{"id": "2Sgd657Hosd", "cdate": 1640995200000, "mdate": 1675601784840, "content": {"title": "Bayesian Fixed-Budget Best-Arm Identification", "abstract": "Fixed-budget best-arm identification (BAI) is a bandit problem where the agent maximizes the probability of identifying the optimal arm within a fixed budget of observations. In this work, we study this problem in the Bayesian setting. We propose a Bayesian elimination algorithm and derive an upper bound on its probability of misidentifying the optimal arm. The bound reflects the quality of the prior and is the first distribution-dependent bound in this setting. We prove it using a frequentist-like argument, where we carry the prior through, and then integrate out the bandit instance at the end. We also provide a lower bound on the probability of misidentification in a $2$-armed Bayesian bandit and show that our upper bound (almost) matches it for any budget. Our experiments show that Bayesian elimination is superior to frequentist methods and competitive with the state-of-the-art Bayesian algorithms that have no guarantees in our setting."}}
{"id": "EyuuodvOFPW", "cdate": 1609459200000, "mdate": 1675601784856, "content": {"title": "Combinatorial Blocking Bandits with Stochastic Delays", "abstract": "Recent work has considered natural variations of the {\\em multi-armed bandit} problem, where the reward distribution of each arm is a special function of the time passed since its last pulling. In ..."}}
