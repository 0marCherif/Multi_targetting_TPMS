{"id": "TvKKqWn_-6", "cdate": 1668480873353, "mdate": null, "content": {"title": "Plant Geometry Reconstruction From Field Data Using Neural Radiance Fields", "abstract": "Real-time simulations of large-scale farming operations would provide farmers with data-driven and physics-consistent decision support. These real-time farming simulations could be accomplished using predictive digital twins. Predictive digital twins of biological entities allow for a virtual simulation of real-life processes for various environmental conditions, thus paving the way for a comprehensive understanding of various biological responses. One of the first steps in constructing a predictive digital twin is the 3D reconstruction of plant geometry. While traditional approaches for the reconstruction of plant geometry exist, they require a very expensive setup using a LIDAR or destructive imaging of the plant in a controlled environment. Neural approaches for 3D scene reconstruction have alleviated the data collection burden associated with traditional 3D reconstruction methods. In this work, we demonstrate the ability to generate a 3D reconstruction (mesh) of a maize plant by leveraging a recent work in 3D computer vision, Neural Radiance Fields (NeRFs), which uses data collected from a mobile phone camera. Our approach aims to generate high-resolution geometric models for several downstream tasks, such as developing a predictive digital twin.\n"}}
{"id": "kPM87uCwFq", "cdate": 1668480873287, "mdate": null, "content": {"title": "Optimized Class-specific Data Augmentation for Plant Stress Classification", "abstract": "Data augmentation has the potential to significantly improve the performance of deep learning-based image classifiers. However, a key challenge in applying data augmentation is choosing an effective set of augmentations from a large pool of candidates. Recently, automated augmentation strategies have produced state-of-the-art results for image classification. Most results have focused on improving the total accuracy of the classifier, often at the cost of reduced performance of a finite number of classes. We explore a Genetic Algorithm-based optimization to identify the ideal class-specific augmentations that maximize the mean-per-class accuracy, starting from a well-trained classifier (which serves as our baseline). We illustrate the utility of this strategy on a well-studied problem (and\nassociated dataset) of classifying soybean leaf stresses. Our (preliminary) work indicated improvements over our baseline model and showed improvement in the mean-per-class accuracy from 90.68% to 93.11% across generations. Identifying class-specific augmentations can provide contextual information to end users. This approach is computationally less expensive than traditional Network-Architecture-Search (NAS), as we only seek to fine-tune the baseline classifier."}}
{"id": "39Eh1ifhsj", "cdate": 1668480873089, "mdate": null, "content": {"title": "Out-of-distribution algorithms for robust insect classification", "abstract": "Plants are exposed to various useful and harmful insect pests during their growth cycle. Accurate identification of these pests is critical for deciding on a timely and appropriate mitigation strategy with significant economic and environmental implications. Recent progress in deep learning-based approaches has resulted in insects exhibiting good accuracy. However, deploying them in the wild is still problematic since input images that are wildly out of the distribution (e.g., non-insect images like vehicles, animals, or a blurred image of an insect or insect class that is not yet trained on) can still produce insect classification. To counter this, methods that ensure that a model abstains from making predictions are needed. To address this issue, we leverage the out-of-distribution detection concept that showed promising results in detecting out-of-distribution data in dermatology tasks (Roy et al., 2022).\nIn our work, we evaluate the performance of state-of-the-art out-of-distribution (OOD) \nalgorithms on insect detection classifiers. These algorithms represent a diversity of methods of approaching an OOD problem. Additionally, we focus on extrusive algorithms -- i.e., algorithms that wrap around a pre-trained classifier without the need for additional co-training. We choose three OOD detection algorithms: (i) Maximum Softmax Probability (MSP), commonly referred to as the baseline algorithms, (ii) Mahalanobis distance-based algorithm, which solves the problem using a generative classification approach; and (iii) Energy-Based Model OOD detection algorithm, which exhibits SOTA for OOD detection. We perform an extensive series of evaluations of these OOD algorithms across two performance axes: (a) how the accuracy of the classifier impacts OOD performance and (b) how the degree of out-of-domain impacts OOD performance. Our analysis shows OOD detection algorithms can significantly improve from abstaining classification across different settings of models\u2019 structures and datasets. Thus, our OOD-robust classifier improves user trust in using the application for insect-pests classification."}}
{"id": "VPDKe672pv", "cdate": 1668480872564, "mdate": null, "content": {"title": "Zero-Shot Insect Detection via Weak Language Supervision", "abstract": "Open source image datasets collected via citizen science platforms (such as iNaturalist) can pave the way for the development of powerful AI models for insect detection and classification. However, traditional supervised learning methods require labeled data, and manual annotation of these raw datasets with useful labels (such as bounding boxes) can be extremely laborious, expensive, and error-prone. In this paper, we show that recent advances in vision-language models enable highly accurate zero-shot detection of insects in a variety of challenging environs. Our contributions are twofold: a) We curate the Insecta rank class of iNaturalist to form a new benchmark dataset of approximately 6M images consisting of 2526 agriculturally important species (both pests and beneficial insects). b) Using a vision-language object detection method coupled with weak language supervision, we are able to automatically annotate images in this dataset with bounding box information localizing the insect within each image. Our method succeeds in detection of diverse insect species present in a wide variety of backgrounds, producing high-quality bounding boxes in a zero-shot manner with no additional training cost. "}}
{"id": "f9Lk1G9q-G-", "cdate": 1664314537199, "mdate": null, "content": {"title": "Generative Design of Material Microstructures for Organic Solar Cells using Diffusion Models", "abstract": "Score-based methods, particularly denoising diffusion probabilistic models (DDPMs), have demonstrated impressive improvements to state-of-the-art generative modeling. Due to their impressive ability to sample from complex distributions, DDPM models and related variants, all broadly categorized under diffusion models, apply to various applications. In this work, we compare the performance of a diffusion model with a Wasserstein Generative Adversarial Network in generating two-phase microstructures of photovoltaic cells. We demonstrate the diffusion model's performance improvements in generating realistic-looking microstructures and its ability to cover several modes of the target distribution."}}
{"id": "F4eTwol9qne", "cdate": 1637383722199, "mdate": null, "content": {"title": "Deep implicit surface reconstruction of 3D plant geometry from point cloud", "abstract": "Reconstructing the geometry of crops from 3D point cloud data is useful for a variety of plant phenotyping applications. Due to very thin and slender segments, obtaining accurate surface geometry representations from the 3D point cloud data is challenging. Further, defects (noise) and holes (sparsity or occlusion) in the point cloud data might be errors in the reconstructed plant structures. While the reconstruction of a surface from an input point cloud has been studied for decades, recent work on deep learning frameworks that learn neural implicit representations have shown significant promise in accurately reconstructing 3D data, especially under noisy and sparse sampling conditions. However, these approaches have not yet been deployed for slender members. In this work, we explore neural implicit representations to reconstruct the surfaces of fully developed maize plants using data acquired from Terrestrial Laser Scanners (TLS). We compare several neural implicit approaches with more traditional methods of surface reconstruction. We also analyze the robustness of these neural implicit methods for 3D plant data reconstruction. We finally utilize the predicted surface to infer structural features from the data. This approach paves the way for detailed flow/transport simulations of agricultural domains from 3D point cloud data."}}
{"id": "BJSHAXe-XZz", "cdate": 1637368063949, "mdate": null, "content": {"title": "Multigrid Distributed Deep CNNs for Structural Topology Optimization", "abstract": "Structural topology optimization with traditional approaches is compute-intensive, mainly due to multiple finite element analysis iterations required to evaluate the component's performance during the optimization process. This computation cost scales up when performed on 3D high-resolution geometries. Researchers have developed deep learning (DL) based approaches, but these methods were demonstrated mainly using low-resolution 3D geometries (with a typical resolution of 32 X 32 X 32). We propose a DL-based method trained with a convolutional neural network (CNN) on high-resolution 3D geometries 128 X 128 X 128. With the initial strain energy (objective function of structural topology optimization) and target volume fraction (% material to be preserved after optimization) as the only inputs to the CNN, we predict the final optimized topology while maintaining the volume fraction constraint. To train the CNN at a high resolution is again a computational challenge. Therefore, we propose multi-resolution CNN, where we train the network at a lower resolution and then transfer the learned network to continue training at a higher resolution. Further, we significantly speed up the training time by 4.77X using distributed deep learning framework on GPU clusters (PSC Bridges-2)."}}
{"id": "r7-mkF0QOCr", "cdate": 1637361803336, "mdate": null, "content": {"title": "Fast Unsupervised Generative Design for Structural Topology Optimization", "abstract": "Exploring the intersection of generative design and structural topology optimization has been a popular research area recently. Existing structural optimization methods have been shown to generate high-performance and aesthetically pleasing structures but at a tremendous computational cost. The rapidly advancing field of deep learning, particularly generative modeling, has substantial potential to tackle the structural generative design problem. Previous works have utilized deep generative models for highly specific cases, ranging from a small set of loading conditions to heavily relying on supervised loss functions for training. We propose a new method targeted at generating near-optimal structures over a wide variety of initial conditions in a completely unsupervised manner. We accomplish this by implementing a novel Generative Adversarial Network (GAN) framework to generate densities that match our given target distribution and encode extremely efficient latent representations of the initial physical conditions of the sample. The target distribution used in this work comes from data generated via the solid isotropic material condition with penalization (SIMP) topology optimization algorithm. Our results show that the proposed framework can generate similar structures to those found using the SIMP optimization algorithm, which consequently demonstrates the potential variability in solution spaces for arbitrary problems in generative design."}}
{"id": "5ThX8_KgZwQ", "cdate": 1637338090011, "mdate": null, "content": {"title": "Inverse Design of Microstructures via Generative Networks for Organic Solar Cells", "abstract": "We consider the inverse problem of efficiently designing material microstructures that exhibit desired electrical properties in an organic solar cell design. We leverage data-driven generative models to learn the underlying data distribution and generate novel microstructures during test time. We focus on a recent framework, specifically generative invariance networks (InvNets), which simultaneously learns from a dataset of microstructures while constraining the output of the generative model to conform to constraints such as generating microstructure designs with a targeted short circuit current density, J values. While previous works in this area have focused on the model training and data efficiency aspects, the applicability and success of Generative Invariance Networks to different material systems (i.e., the donor material and the acceptor material chemistry) and device thickness remain unexplored. In this paper, we demonstrate that we can successfully adapt the same InvNet framework to different material systems and device thicknesses with minimal computational effort."}}
{"id": "jTEGbvLjgp", "cdate": 1621630267391, "mdate": null, "content": {"title": "Differentiable Spline Approximations", "abstract": "The paradigm of differentiable programming has significantly enhanced the scope of machine learning via the judicious use of gradient-based optimization. However, standard differentiable programming methods (such as autodiff) typically require that the machine learning models be differentiable, limiting their applicability. Our goal in this paper is to use a new, principled approach to extend gradient-based optimization to functions well modeled by splines, which encompass a large family of piecewise polynomial models. We derive the form of the (weak) Jacobian of such functions and show that it exhibits a block-sparse structure that can be computed implicitly and efficiently. Overall, we show that leveraging this redesigned Jacobian in the form of a differentiable \"layer'' in predictive models leads to improved performance in diverse applications such as image segmentation, 3D point cloud reconstruction, and finite element analysis. We also open-source the code at \\url{https://github.com/idealab-isu/DSA}."}}
