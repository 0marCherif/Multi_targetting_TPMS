{"id": "b9XVzM80iO", "cdate": 1672531200000, "mdate": 1686550190215, "content": {"title": "LLM-Pruner: On the Structural Pruning of Large Language Models", "abstract": "Large language models (LLMs) have shown remarkable capabilities in language understanding and generation. However, such impressive capability typically comes with a substantial model size, which presents significant challenges in both the deployment, inference, and training stages. With LLM being a general-purpose task solver, we explore its compression in a task-agnostic manner, which aims to preserve the multi-task solving and language generation ability of the original LLM. One challenge to achieving this is the enormous size of the training corpus of LLM, which makes both data transfer and model post-training over-burdensome. Thus, we tackle the compression of LLMs within the bound of two constraints: being task-agnostic and minimizing the reliance on the original training dataset. Our method, named LLM-Pruner, adopts structural pruning that selectively removes non-critical coupled structures based on gradient information, maximally preserving the majority of the LLM's functionality. To this end, the performance of pruned models can be efficiently recovered through tuning techniques, LoRA, in merely 3 hours, requiring only 50K data. We validate the LLM-Pruner on three LLMs, including LLaMA, Vicuna, and ChatGLM, and demonstrate that the compressed models still exhibit satisfactory capabilities in zero-shot classification and generation. The code is available at: https://github.com/horseee/LLM-Pruner"}}
{"id": "ZHio_i7saF", "cdate": 1672531200000, "mdate": 1686550190378, "content": {"title": "DepGraph: Towards Any Structural Pruning", "abstract": "Structural pruning enables model acceleration by removing structurally-grouped parameters from neural networks. However, the parameter-grouping patterns vary widely across different models, making architecture-specific pruners, which rely on manually-designed grouping schemes, non-generalizable to new architectures. In this work, we study a highly-challenging yet barely-explored task, any structural pruning, to tackle general structural pruning of arbitrary architecture like CNNs, RNNs, GNNs and Transformers. The most prominent obstacle towards this goal lies in the structural coupling, which not only forces different layers to be pruned simultaneously, but also expects all removed parameters to be consistently unimportant, thereby avoiding structural issues and significant performance degradation after pruning. To address this problem, we propose a general and {fully automatic} method, \\emph{Dependency Graph} (DepGraph), to explicitly model the dependency between layers and comprehensively group coupled parameters for pruning. In this work, we extensively evaluate our method on several architectures and tasks, including ResNe(X)t, DenseNet, MobileNet and Vision transformer for images, GAT for graph, DGCNN for 3D point cloud, alongside LSTM for language, and demonstrate that, even with a simple norm-based criterion, the proposed method consistently yields gratifying performances."}}
{"id": "FZwdARj8Uri", "cdate": 1672531200000, "mdate": 1686550190272, "content": {"title": "Structural Pruning for Diffusion Models", "abstract": "Generative modeling has recently undergone remarkable advancements, primarily propelled by the transformative implications of Diffusion Probabilistic Models (DPMs). The impressive capability of these models, however, often entails significant computational overhead during both training and inference. To tackle this challenge, we present Diff-Pruning, an efficient compression method tailored for learning lightweight diffusion models from pre-existing ones, without the need for extensive re-training. The essence of Diff-Pruning is encapsulated in a Taylor expansion over pruned timesteps, a process that disregards non-contributory diffusion steps and ensembles informative gradients to identify important weights. Our empirical assessment, undertaken across four diverse datasets highlights two primary benefits of our proposed method: 1) Efficiency: it enables approximately a 50% reduction in FLOPs at a mere 10% to 20% of the original training expenditure; 2) Consistency: the pruned diffusion models inherently preserve generative behavior congruent with their pre-trained progenitors. Code is available at \\url{https://github.com/VainF/Diff-Pruning}."}}
{"id": "wZ9CXUt6dT", "cdate": 1640995200000, "mdate": 1686550190312, "content": {"title": "Prompting to Distill: Boosting Data-Free Knowledge Distillation via Reinforced Prompt", "abstract": "Data-free knowledge distillation (DFKD) conducts knowledge distillation via eliminating the dependence of original training data, and has recently achieved impressive results in accelerating pre-trained language models. At the heart of DFKD is to reconstruct a synthetic dataset by inverting the parameters of the uncompressed model. Prior DFKD approaches, however, have largely relied on hand-crafted priors of the target data distribution for the reconstruction, which can be inevitably biased and often incompetent to capture the intrinsic distributions. To address this problem, we propose a prompt-based method, termed as PromptDFD, that allows us to take advantage of learned language priors, which effectively harmonizes the synthetic sentences to be semantically and grammatically correct. Specifically, PromptDFD leverages a pre-trained generative model to provide language priors and introduces a reinforced topic prompter to control data synthesis, making the generated samples thematically relevant and semantically plausible, and thus friendly to downstream tasks. As shown in our experiments, the proposed method substantially improves the synthesis quality and achieves considerable improvements on distillation performance. In some cases, PromptDFD even gives rise to results on par with those from the data-driven knowledge distillation with access to the original training data."}}
{"id": "zZ0g348TLCI", "cdate": 1609459200000, "mdate": 1639412393776, "content": {"title": "MuVER: Improving First-Stage Entity Retrieval with Multi-View Entity Representations", "abstract": "Xinyin Ma, Yong Jiang, Nguyen Bach, Tao Wang, Zhongqiang Huang, Fei Huang, Weiming Lu. Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing. 2021."}}
{"id": "n9LPSn8cm2U", "cdate": 1609459200000, "mdate": 1639412393066, "content": {"title": "A Trigger-Sense Memory Flow Framework for Joint Entity and Relation Extraction", "abstract": "Joint entity and relation extraction framework constructs a unified model to perform entity recognition and relation extraction simultaneously, which can exploit the dependency between the two tasks to mitigate the error propagation problem suffered by the pipeline model. Current efforts on joint entity and relation extraction focus on enhancing the interaction between entity recognition and relation extraction through parameter sharing, joint decoding, or other ad-hoc tricks (e.g., modeled as a semi-Markov decision process, cast as a multi-round reading comprehension task). However, there are still two issues on the table. First, the interaction utilized by most methods is still weak and uni-directional, which is unable to model the mutual dependency between the two tasks. Second, relation triggers are ignored by most methods, which can help explain why humans would extract a relation in the sentence. They\u2019re essential for relation extraction but overlooked. To this end, we present a Trigger-Sense Memory Flow Framework (TriMF) for joint entity and relation extraction. We build a memory module to remember category representations learned in entity recognition and relation extraction tasks. And based on it, we design a multi-level memory flow attention mechanism to enhance the bi-directional interaction between entity recognition and relation extraction. Moreover, without any human annotations, our model can enhance relation trigger information in a sentence through a trigger sensor module, which improves the model performance and makes model predictions with better interpretation. Experiment results show that our proposed framework achieves state-of-the-art results by improves the relation F1 to 52.44% (+3.2%) on SciERC, 66.49% (+4.9%) on ACE05, 72.35% (+0.6%) on CoNLL04 and 80.66% (+2.3%) on ADE."}}
{"id": "leJXniS-T9j", "cdate": 1609459200000, "mdate": 1635913190213, "content": {"title": "Locate and Label: A Two-stage Identifier for Nested Named Entity Recognition", "abstract": "Yongliang Shen, Xinyin Ma, Zeqi Tan, Shuai Zhang, Wen Wang, Weiming Lu. Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers). 2021."}}
{"id": "tn-86CajmJQ", "cdate": 1577836800000, "mdate": 1639412394089, "content": {"title": "Adversarial Self-Supervised Data-Free Distillation for Text Classification", "abstract": "Xinyin Ma, Yongliang Shen, Gongfan Fang, Chen Chen, Chenghao Jia, Weiming Lu. Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP). 2020."}}
{"id": "rBxOXDpb5rG", "cdate": 1577836800000, "mdate": 1639412393022, "content": {"title": "SynET: Synonym Expansion using Transitivity", "abstract": "Jiale Yu, Yongliang Shen, Xinyin Ma, Chenghao Jia, Chen Chen, Weiming Lu. Findings of the Association for Computational Linguistics: EMNLP 2020. 2020."}}
{"id": "OQnk8eBQpQD", "cdate": 1577836800000, "mdate": 1639412393464, "content": {"title": "Enrich cross-lingual entity links for online wikis via multi-modal semantic matching", "abstract": "Highlights \u2022 This paper investigated the task of enriching cross-lingual links for online wikis, which is a significant step and a pretty good starting point for cross-lingual knowledge graph construction. \u2022 we propose two end-to-end neural matching models for matching entity descriptions and images, and then jointly train them with handcraft features. To the best of our knowledge, it is the first to utilize multi-modal information to enrich cross-lingual entity links. \u2022 Three datasets C E M Z H \u2212 E N E a s y , C E M Z H \u2212 E N C h a l l e n g e and C E M F R \u2212 E N E a s y with different languages and difficulties were created, and our approach gets the best performance compared with other baseline approaches. Abstract The task of enriching cross-lingual links is to find articles in different languages but representing the same real-world object between multilingual Wikis. In this paper, we propose a novel Multi-Modal Semantic Matching approach, called MMSM, to enrich cross-lingual links for online Wikis. Specifically, MMSM jointly trains two novel end-to-end neural matching models, Entity Description Matching Model and Entity Image Matching Model, which can utilize entity description and images for the cross-lingual entity matching. To the best of our knowledge, it is the first work to utilize multi-modal information to enrich cross-lingual entity links. In the experiments on three datasets C E M Z H \u2212 E N E a s y , C E M Z H \u2212 E N C h a l l e n g e and C E M F R \u2212 E N E a s y , our approach gets the best performance compared with other baseline approaches."}}
