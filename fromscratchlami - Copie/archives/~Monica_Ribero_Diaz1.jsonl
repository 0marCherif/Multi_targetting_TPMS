{"id": "rSUCajhLsQ", "cdate": 1663849867555, "mdate": null, "content": {"title": "Easy Differentially Private Linear Regression", "abstract": "Linear regression is a fundamental tool for statistical analysis. This has motivated the development of linear regression methods that also satisfy differential privacy and thus guarantee that the learned model reveals little about any one data point used to construct it. However, existing differentially private solutions assume that the end user can easily specify good data bounds and hyperparameters. Both present significant practical obstacles. In this paper, we study an algorithm which uses the exponential mechanism to select a model with high Tukey depth from a collection of non-private regression models. Given $n$ samples of $d$-dimensional data used to train $m$ models, we construct an efficient analogue using an approximate Tukey depth that runs in time $O(d^2n + dm\\log(m))$. We find that this algorithm obtains strong empirical performance in the data-rich setting with no data bounds or hyperparameter selection required."}}
{"id": "BjBeRB3NqG", "cdate": 1631911157880, "mdate": null, "content": {"title": "A Joint Exponential Mechanism for Differentially Private Top-k Set", "abstract": "We present a novel differentially private algorithm for releasing the set of k elements with the highest counts from a data domain of d elements. We define a ``joint'' instance of the exponential mechanism (EM) whose output space consists of all O(d^k) size-k subsets; yet, we are able to show how to sample from this EM in only time O(dk^3). Experiments suggest that this joint approach can yield utility improvements over the existing state of the art for small problem sizes."}}
{"id": "pAXQRimHKJ6", "cdate": 1577836800000, "mdate": null, "content": {"title": "Federating Recommendations Using Differentially Private Prototypes.", "abstract": "Machine learning methods allow us to make recommendations to users in applications across fields including entertainment, dating, and commerce, by exploiting similarities in users' interaction patterns. However, in domains that demand protection of personally sensitive data, such as medicine or banking, how can we learn such a model without accessing the sensitive data, and without inadvertently leaking private information? We propose a new federated approach to learning global and local private models for recommendation without collecting raw data, user statistics, or information about personal preferences. Our method produces a set of prototypes that allows us to infer global behavioral patterns, while providing differential privacy guarantees for users in any database of the system. By requiring only two rounds of communication, we both reduce the communication costs and avoid the excessive privacy loss associated with iterative procedures. We test our framework on synthetic data as well as real federated medical data and Movielens ratings data. We show local adaptation of the global model allows our method to outperform centralized matrix-factorization-based recommender system models, both in terms of accuracy of matrix reconstruction and in terms of relevance of the recommendations, while maintaining provable privacy guarantees. We also show that our method is more robust and is characterized by smaller variance than individual models learned by independent entities."}}
{"id": "GeHDLHU4_ZW", "cdate": 1577836800000, "mdate": null, "content": {"title": "Communication-Efficient Federated Learning via Optimal Client Sampling", "abstract": "Federated learning (FL) ameliorates privacy concerns in settings where a central server coordinates learning from data distributed across many clients. The clients train locally and communicate the models they learn to the server; aggregation of local models requires frequent communication of large amounts of information between the clients and the central server. We propose a novel, simple and efficient way of updating the central model in communication-constrained settings based on collecting models from clients with informative updates and estimating local updates that were not communicated. In particular, modeling the progression of model's weights by an Ornstein-Uhlenbeck process allows us to derive an optimal sampling strategy for selecting a subset of clients with significant weight updates. The central server collects updated local models from only the selected clients and combines them with estimated model updates of the clients that were not selected for communication. We test this policy on a synthetic dataset for logistic regression and two FL benchmarks, namely, a classification task on EMNIST and a realistic language modeling task using the Shakespeare dataset. The results demonstrate that the proposed framework provides significant reduction in communication while maintaining competitive or achieving superior performance compared to a baseline. Our method represents a new line of strategies for communication-efficient FL that is orthogonal to the existing user-local methods such as quantization or sparsification, thus complementing rather than aiming to replace those existing methods."}}
{"id": "3lIbPMrpFrU", "cdate": 1577836800000, "mdate": null, "content": {"title": "Dimension Independence in Unconstrained Private ERM via Adaptive Preconditioning", "abstract": "We revisit the problem of empirical risk minimziation (ERM) with differential privacy. We show that noisy AdaGrad, given appropriate knowledge and conditions on the subspace from which gradients can be drawn, achieves a regret comparable to traditional AdaGrad plus a well-controlled term due to noise. We show a convergence rate of $O(\\text{Tr}(G_T)/T)$, where $G_T$ captures the geometry of the gradient subspace. Since $\\text{Tr}(G_T)=O(\\sqrt{T})$ we can obtain faster rates for convex and Lipschitz functions, compared to the $O(1/\\sqrt{T})$ rate achieved by known versions of noisy (stochastic) gradient descent with comparable noise variance. In particular, we show that if the gradients lie in a known constant rank subspace, and assuming algorithmic access to an envelope which bounds decaying sensitivity, one can achieve faster convergence to an excess empirical risk of $\\tilde O(1/\\epsilon n)$, where $\\epsilon$ is the privacy budget and $n$ the number of samples. Letting $p$ be the problem dimension, this result implies that, by running noisy Adagrad, we can bypass the DP-SGD bound $\\tilde O(\\sqrt{p}/\\epsilon n)$ in $T=(\\epsilon n)^{2/(1+2\\alpha)}$ iterations, where $\\alpha \\geq 0$ is a parameter controlling gradient norm decay, instead of the rate achieved by SGD of $T=\\epsilon^2n^2$. Our results operate with general convex functions in both constrained and unconstrained minimization. Along the way, we do a perturbation analysis of noisy AdaGrad of independent interest. Our utility guarantee for the private ERM problem follows as a corollary to the regret guarantee of noisy AdaGrad."}}
{"id": "cLBx9tCjvnE", "cdate": 1546300800000, "mdate": null, "content": {"title": "Deep Learning Propagation Models over Irregular Terrain.", "abstract": "Accurate path gain models are critical for coverage prediction and radio frequency (RF) planning in wireless communications. In many settings irregular terrain induces blockages and scattering making it difficult to predict the path gain. Current solutions are either computationally expensive or slope-intercept fits that do not capture local deviations due to terrain variation, leading to large prediction errors. We propose to use machine learning to learn path gain based on terrain elevation as features. We implement different neural network architectures with dense and convolutional layers that could include effects difficult to describe with traditional models (e.g. back scatter). We test our framework on an extensive set of measured path gain data and consistently predict with 5 dB Root Mean Squared Error, an 8 dB improvement over traditional slope-intercept solutions."}}
{"id": "RppaXi5c43S", "cdate": 1546300800000, "mdate": null, "content": {"title": "MmWave Vehicular Beam Selection With Situational Awareness Using Machine Learning.", "abstract": "Establishing and tracking beams in millimeter-wave (mmWave) vehicular communication is a challenging task. Large antenna arrays and narrow beams introduce significant system overhead configuring the beams using exhaustive beam search. In this paper, we propose to learn the optimal beam pair index by exploiting the locations and types of the receiver vehicle and its neighboring vehicles (situational awareness), leveraging machine learning classification and past beam training data. We formulate the mmWave beam selection as a multi-class classification problem based on hand-crafted features that capture the situational awareness in different coordinates. We then provide a comprehensive comparison of the different classification models and various levels of situational awareness. Furthermore, we examine several practical issues in the implementation: localization is susceptible to inaccuracy; situational awareness at the base station (BS) can be outdated due to vehicle mobility and limited location reporting frequencies; the situational awareness may be incomplete since vehicles could be <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">invisible</i> to the BS if they are not connected. To demonstrate the scalability of the proposed beam selection solution in the large antenna array regime, we propose two solutions to recommend multiple beams and exploit an extra phase of beam sweeping among the recommended beams. The numerical results show that situational awareness-assisted beam selection using machine learning is able to provide beam prediction, with accuracy that increases with more complete knowledge of the environment."}}
{"id": "f06GoJHYGK", "cdate": 1514764800000, "mdate": null, "content": {"title": "MmWave Vehicular Beam Training with Situational Awareness by Machine Learning.", "abstract": "Configuring beams in millimeter-wave (mmWave) vehicular communication is a challenging task. Large antenna arrays and narrow beams are deployed at transceivers to exploit beamforming gain, which leads to significant system overhead if an exhaustive beam search is adopted. In this paper, we propose to learn the optimal beam pair index by exploiting the locations and sizes of the receiver and its neighboring vehicles (parts of the situational awareness for automated driving), leveraging machine learning tools with the past beam training records. MmWave beam selection is formulated as a classification problem based on situational awareness. We provide a comprehensive comparison of different classification models and various levels of situational awareness. Practical issues are considered in realistic implementations, including GPS inaccuracies, out-dated locations due to fixed location reporting frequencies and missing features with limited connected vehicles penetration rate. The result shows that we can achieve up to 86% of alignment probability with ideal assumptions."}}
