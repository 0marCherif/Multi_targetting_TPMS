{"id": "rMm9d_aDtOa", "cdate": 1621630105827, "mdate": null, "content": {"title": "Online Knapsack with Frequency Predictions", "abstract": "There has been recent interest in using machine-learned predictions to improve the worst-case guarantees of online algorithms.  In this paper we continue this line of work by studying the online knapsack problem, but with very weak predictions: in the form of knowing an upper and lower bound for the number of items of each value.  We systematically derive online algorithms that attain the best possible competitive ratio for any fixed prediction; we also extend the results to more general settings such as generalized one-way trading and two-stage online knapsack. Our work shows that even seemingly weak predictions can be utilized effectively to provably improve the performance of online algorithms."}}
{"id": "1XxaUEa3Yz", "cdate": 1621630105827, "mdate": null, "content": {"title": "Online Knapsack with Frequency Predictions", "abstract": "There has been recent interest in using machine-learned predictions to improve the worst-case guarantees of online algorithms.  In this paper we continue this line of work by studying the online knapsack problem, but with very weak predictions: in the form of knowing an upper and lower bound for the number of items of each value.  We systematically derive online algorithms that attain the best possible competitive ratio for any fixed prediction; we also extend the results to more general settings such as generalized one-way trading and two-stage online knapsack. Our work shows that even seemingly weak predictions can be utilized effectively to provably improve the performance of online algorithms."}}
{"id": "RYL_709qe9Y", "cdate": 1621629962868, "mdate": null, "content": {"title": "Logarithmic Regret from Sublinear Hints", "abstract": "We consider the online linear optimization problem, where at every step the algorithm plays a point $x_t$ in the unit ball, and suffers loss $\\langle c_t, x_t \\rangle$ for some cost vector $c_t$ that is then revealed to the algorithm. Recent work showed that if an algorithm  receives a _hint_ $h_t$ that has non-trivial correlation with $c_t$ before it plays $x_t$, then it can achieve a regret guarantee of $O(\\log T)$, improving on the bound of $\\Theta(\\sqrt{T})$ in the standard setting. In this work, we study the question of whether an algorithm really requires a hint at _every_ time step. Somewhat surprisingly, we show that an algorithm can obtain $O(\\log T)$ regret with just $O(\\sqrt{T})$ hints under a natural query model; in contrast, we also show that $o(\\sqrt{T})$ hints cannot guarantee better than $\\Omega(\\sqrt{T})$ regret. We give two applications of our result, to the well-studied setting of {\\em optimistic} regret bounds, and to the problem of online learning with abstention. "}}
{"id": "acpY_J2F5q7", "cdate": 1609459200000, "mdate": null, "content": {"title": "Power of Hints for Online Learning with Movement Costs", "abstract": "We consider the online linear optimization problem with movement costs, a variant of online learning in which the learner must not only respond to cost vectors $c_t$ with points $x_t$ in order to maintain low regret, but is also penalized for movement by an additional cost $\\|x_t-x_{t+1}\\|^{1+\\epsilon}$ for some $\\epsilon>0$. Classically, simple algorithms that obtain the optimal $\\sqrt{T}$ regret already are very stable and do not incur a significant movement cost. However, recent work has shown that when the learning algorithm is provided with weak \u201chint\u201d vectors that have a positive correlation with the costs, the regret can be significantly improved to $\\log(T)$. In this work, we study the stability of such algorithms, and provide matching upper and lower bounds showing that incorporating movement costs results in intricate tradeoffs between $\\log(T)$ when $\\epsilon\\ge 1$ and $\\sqrt{T}$ regret when $\\epsilon=0$."}}
{"id": "pcxtQg9ncb4", "cdate": 1577836800000, "mdate": null, "content": {"title": "Upper Confidence Bounds for Combining Stochastic Bandits", "abstract": "We provide a simple method to combine stochastic bandit algorithms. Our approach is based on a \"meta-UCB\" procedure that treats each of $N$ individual bandit algorithms as arms in a higher-level $N$-armed bandit problem that we solve with a variant of the classic UCB algorithm. Our final regret depends only on the regret of the base algorithm with the best regret in hindsight. This approach provides an easy and intuitive alternative strategy to the CORRAL algorithm for adversarial bandits, without requiring the stability conditions imposed by CORRAL on the base algorithms. Our results match lower bounds in several settings, and we provide empirical validation of our algorithm on misspecified linear bandit and model selection problems."}}
{"id": "f6QJ8ilcqq2", "cdate": 1577836800000, "mdate": null, "content": {"title": "Interleaved Caching with Access Graphs", "abstract": "We consider a semi-online model for caching in which request sequences are generated by walks on a directed graph, called the access graph. The caching algorithm knows the access graph but not the actual request sequences. We then extend this model to multiple access graphs, where request sequences from the access graphs are interleaved arbitrarily and presented to the caching algorithm. For both these problems, we obtain tight upper and lower bounds on the competitive ratio; our bounds depend on a structural property of the access graph. Our work is motivated by multitasking systems with shared cache, where each task can be abstracted as a directed graph with nodes corresponding to data access and directed edges corresponding to the control flow of the task."}}
{"id": "bYEEvcvtF2-", "cdate": 1577836800000, "mdate": null, "content": {"title": "Scale-Free Allocation, Amortized Convexity, and Myopic Weighted Paging", "abstract": "We consider a natural semi-online model for weighted paging, where at any time the algorithm is given predictions, possibly with errors, about the next arrival of each page. The model is inspired by Belady's classic optimal offline algorithm for unweighted paging, and extends the recently studied model for learning-augmented paging (Lykouris and Vassilvitskii, 2018) to the weighted setting. For the case of perfect predictions, we provide an $\\ell$-competitive deterministic and an $O(\\log \\ell)$-competitive randomized algorithm, where $\\ell$ is the number of distinct weight classes. Both these bounds are tight, and imply an $O(\\log W)$- and $O(\\log \\log W)$-competitive ratio, respectively, when the page weights lie between $1$ and $W$. Previously, it was not known how to use these predictions in the weighted setting and only bounds of $k$ and $O(\\log k)$ were known, where $k$ is the cache size. Our results also generalize to the interleaved paging setting and to the case of imperfect predictions, with the competitive ratios degrading smoothly from $O(\\ell)$ and $O(\\log \\ell)$ to $O(k)$ and $O(\\log k)$, respectively, as the prediction error increases. Our results are based on several insights on structural properties of Belady's algorithm and the sequence of page arrival predictions, and novel potential functions that incorporate these predictions. For the case of unweighted paging, the results imply a very simple potential function based proof of the optimality of Belady's algorithm, which may be of independent interest."}}
{"id": "_rGcJzV3jMS", "cdate": 1577836800000, "mdate": null, "content": {"title": "On Scheduling Coflows", "abstract": "Applications designed for data-parallel computation frameworks such as MapReduce usually alternate between computation and communication stages. Coflow scheduling is a recent popular networking abstraction introduced to capture such application-level communication patterns in datacenters. In this framework, a datacenter is modeled as a single non-blocking switch with m input ports and m output ports. A coflow j is a collection of flow demands $$\\{d^j_{io}\\}_{i \\in \\{1,\\ldots ,m\\}, o \\in \\{1,\\ldots ,m\\}}$$ { d io j } i \u2208 { 1 , \u2026 , m } , o \u2208 { 1 , \u2026 , m } that is said to be complete once all of its requisite flows have been scheduled. We consider the offline coflow scheduling problem with and without release times to minimize the total weighted completion time. Coflow scheduling generalizes the well studied concurrent open shop scheduling problem and is thus NP-hard. Qiu et al. (in: ACM Symposium on parallelism in algorithms and architectures. ACM, New York, pp 294\u2013303, 2015) obtain the first constant approximation algorithms for this problem via LP rounding and give a deterministic $$\\frac{67}{3}$$ 67 3 -approximation and a randomized $$(9 + \\frac{16\\sqrt{2}}{3}) \\approx 16.54$$ ( 9 + 16 2 3 ) \u2248 16.54 -approximation algorithm. In this paper, we give a combinatorial algorithm that yields a deterministic 5-approximation algorithm for coflow scheduling with release times, and a deterministic 4-approximation for the case without release times. As for concurrent open shop problem with release times, we give a combinatorial 3-approximation algorithm."}}
{"id": "KXEkme8Ye_R", "cdate": 1577836800000, "mdate": null, "content": {"title": "Analyzing the Optimal Neighborhood: Algorithms for Partial and Budgeted Connected Dominating Set Problems", "abstract": "We study partial and budgeted versions of the well-studied connected dominating set problem. In the partial connected dominating set (PCDS) problem, we are given an undirected graph $G = (V,E)$ and an integer $n'$, and the goal is to find a minimum subset of vertices that induces a connected subgraph of $G$ and dominates at least $n'$ vertices. We obtain the first polynomial time algorithm with an $O(\\ln \\Delta)$ approximation guarantee for this problem, thereby significantly extending the results of Guha and Khuller [Algorithmica, 20(1998), pp. 374--387] for the connected dominating set problem. We note that none of the methods developed earlier can be applied directly to solve this problem. In the budgeted connected dominating set problem, there is a budget on the number of vertices we can select, and the goal is to dominate as many vertices as possible. We obtain a $\\frac{1}{12}(1-\\frac{1}{e})$ approximation algorithm for this problem. Finally, we show that our techniques extend to a more general setting where the profit function associated with a subset of vertices is a \u201cspecial\u201d submodular function. This generalization captures the connected dominating set problem with capacities and/or weighted profits as special cases. This implies an $O(\\ln q)$ approximation (where $q$ denotes the quota) and $O(1)$ approximation algorithms for the partial and budgeted versions of these problems. While the algorithms are simple, the results make a surprising use of the greedy set cover framework in defining a useful profit function. Finally, we prove that (both edge and node) weighted versions of the PCDS problem are as hard as the more general group Steiner tree problem."}}
{"id": "KQm9RLRvLMm", "cdate": 1577836800000, "mdate": null, "content": {"title": "Online Linear Optimization with Many Hints", "abstract": "We study an online linear optimization (OLO) problem in which the learner is provided access to $K$ \"hint\" vectors in each round prior to making a decision. In this setting, we devise an algorithm that obtains logarithmic regret whenever there exists a convex combination of the $K$ hints that has positive correlation with the cost vectors. This significantly extends prior work that considered only the case $K=1$. To accomplish this, we develop a way to combine many arbitrary OLO algorithms to obtain regret only a logarithmically worse factor than the minimum regret of the original algorithms in hindsight; this result is of independent interest."}}
