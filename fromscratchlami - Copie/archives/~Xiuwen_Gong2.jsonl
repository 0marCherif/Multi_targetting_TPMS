{"id": "3RvABeTa0PJ", "cdate": 1690848000000, "mdate": 1695949485911, "content": {"title": "Discriminative Metric Learning for Partial Label Learning", "abstract": "One simple strategy to deal with ambiguity in partial label learning (PLL) is to regard all candidate labels equally as the ground-truth label, and then solve the PLL problem using existing multiclass classification algorithms. However, due to the noisy false-positive labels in the candidate set, these approaches are readily mislead and do not generalize well in testing. Consequently, the method of identifying the ground-truth label straight from the candidate label set has grown popular and effective. When the labeling information in PLL is ambiguous, we ought to take advantage of the data\u2019s underlying structure, such as label and feature interdependencies, to conduct disambiguation. Furthermore, while metric learning is an excellent method for supervised learning classification that takes feature and label interdependencies into account, it cannot be used to solve the weekly supervised learning PLL problem directly due to the ambiguity of labeling information in the candidate label set. In this article, we propose an effective PLL paradigm called discriminative metric learning for partial label learning (DML-PLL), which aims to learn a Mahanalobis distance metric discriminatively while identifying the ground-truth label iteratively for PLL. We also design an efficient algorithm to alternatively optimize the metric parameter and the latent ground-truth label in an iterative way. Besides, we prove the convergence of the designed algorithms by two proposed lemmas. We additionally study the computational complexity of the proposed DML-PLL in terms of training and testing time for each iteration. Extensive experiments on both controlled UCI datasets and real-world PLL datasets from diverse domains demonstrate that the proposed DML-PLL regularly outperforms the compared approaches in terms of prediction accuracy."}}
{"id": "R9Bx-URUUwq", "cdate": 1688169600000, "mdate": 1695949485796, "content": {"title": "A Unifying Probabilistic Framework for Partially Labeled Data Learning", "abstract": "Partially labeled data learning (PLDL), including partial label learning (PLL) and partial multi-label learning (PML), has been widely used in nowadays data science. Researchers attempt to construct different specific models to deal with the different classification tasks for PLL and PML scenarios respectively. The main challenge in training classifiers for PLL and PML is how to deal with ambiguities caused by the noisy false-positive labels in the candidate label set. The state-of-the-art strategy for both scenarios is to perform disambiguation by identifying the ground-truth label(s) directly from the candidate label set, which can be summarized into two categories: \u2018the identifying method\u2019 and \u2018the embedding method\u2019. However, both kinds of methods are constructed by hand-designed heuristic modeling under considerations like feature/label correlations with no theoretical interpretation. Instead of adopting heuristic or specific modeling, we propose a novel unifying framework called A Unifying Probabilistic Framework for Partially Labeled Data Learning (UPF-PLDL), which is derived from a clear probabilistic formulation, and brings existing research on PLL and PML under one theoretical interpretation with respect to information theory. Furthermore, the proposed UPF-PLDL also unifies \u2018the identifying method\u2019 and \u2018the embedding method\u2019 into one integrated framework, which naturally incorporates the feature and label correlation considerations. Comprehensive experiments on synthetic and real-world datasets for both PLL and PML scenarios clearly demonstrate the superiorities of the derived framework."}}
{"id": "u_GQ0-V1M1", "cdate": 1672531200000, "mdate": 1681695899862, "content": {"title": "Relation Preference Oriented High-order Sampling for Recommendation", "abstract": "The introduction of knowledge graphs (KG) into recommendation systems (RS) has been proven to be effective because KG introduces a variety of relations between items. In fact, users have different relation preferences depending on the relationship in KG. Existing GNN-based models largely adopt random neighbor sampling strategies to process propagation; however, these models cannot aggregate biased relation preference local information for a specific user, and thus cannot effectively reveal the internal relationship between users' preferences. This will reduce the accuracy of recommendations, while also limiting the interpretability of the results. Therefore, we propose a Relation Preference oriented High-order Sampling (RPHS) model to dynamically sample subgraphs based on relation preference and hard negative samples for user-item pairs. We design a path sampling strategy based on relation preference, which can encode the critical paths between specific user-item pairs to sample the paths in the high-order message passing subgraphs. Next, we design a mixed sampling strategy and define a new propagation operation to further enhance RPHS's ability to distinguish negative signals. Through the above sampling strategies, our model can better aggregate local relation preference information and reveal the internal relationship between users' preferences. Experiments show that our model outperforms the state-of-the-art models on three datasets by 14.98%, 5.31%, and 8.65%, and also performs well in terms of interpretability. The codes are available at https://github.com/RPHS/RPHS.git"}}
{"id": "qodmvUoRie", "cdate": 1672531200000, "mdate": 1695949485797, "content": {"title": "Classification via Structure-Preserved Hypergraph Convolution Network for Hyperspectral Image", "abstract": "Graph convolutional network (GCN) as a combination of deep learning (DL) and graph learning has gained increasing attention in hyperspectral image (HSI) classification. However, most GCN methods consider the simple point-to-point structure between two pixels rather than the high-order structure of multiple pixels, which is contradict with the real feature distribution of ground object. And the nonlinear property of HSI also brings challenge for precise structural representation in GCN. To tackle these problems, this work proposes a structure-preserved hyper GCN (SPHGCN). It first builds a multiple neighborhood reconstruction (MNR) model to reveal the essential resemblance of multiple pixels in nonlinear spectral feature space. With the high-order structure, SPHGCN designs the hypergraph convolution operation for irregular feature aggregation among similar pixels from different regions, which achieves more discriminative features from multiple pixel nodes. Meanwhile, a structure preservation layer (SPL) is built to optimize the distribution of convolutional features under the guidance of high-order structure. Moreover, SPHGCN integrates local regular convolution and irregular hypergraph convolution to learn the structured semantic feature of HSI. This strategy breaks the boundary restriction in traditional convolution and aggregates semantic feature across different image patches. Experiments on three HSI datasets indicate that SPHGCN outperforms a few state-of-the-art methods for HSI classification."}}
{"id": "e-Kw5PdeH0G", "cdate": 1672531200000, "mdate": 1684050177746, "content": {"title": "Attention Multihop Graph and Multiscale Convolutional Fusion Network for Hyperspectral Image Classification", "abstract": "Convolutional neural networks (CNNs) for hyperspectral image (HSI) classification have generated good progress. Meanwhile, graph convolutional networks (GCNs) have also attracted considerable attention by using unlabeled data, broadly and explicitly exploiting correlations between adjacent parcels. However, the CNN with a fixed square convolution kernel is not flexible enough to deal with irregular patterns, while the GCN using the superpixel to reduce the number of nodes will lose the pixel-level features, and the features from the two networks are always partial. In this article, to make good use of the advantages of CNN and GCN, we propose a novel multiple feature fusion model termed attention multihop graph and multiscale convolutional fusion network (AMGCFN), which includes two subnetworks of multiscale fully CNN and multihop GCN to extract the multilevel information of HSI. Specifically, the multiscale fully CNN aims to comprehensively capture pixel-level features with different kernel sizes, and a multihead attention fusion module (MAFM) is used to fuse the multiscale pixel-level features. The multihop GCN systematically aggregates the multihop contextual information by applying multihop graphs on different layers to transform the relationships between nodes, and an MAFM is adopted to combine the multihop features. Finally, we design a cross-attention fusion module (CAFM) to adaptively fuse the features of two subnetworks. The AMGCFN makes full use of multiscale convolution and multihop graph features, which is conducive to the learning of multilevel contextual semantic features. Experimental results on three benchmark HSI datasets show that the AMGCFN has a better performance than a few state-of-the-art methods. Code: <uri xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">https://github.com/EdwardHaoz/IEEE_TGRS_AMGCFN</uri> ."}}
{"id": "_q16MUeKZC", "cdate": 1672531200000, "mdate": 1695949485775, "content": {"title": "Anomaly Detection of Hyperspectral Image With Hierarchical Antinoise Mutual-Incoherence- Induced Low-Rank Representation", "abstract": "Hyperspectral image (HSI) anomaly detection (AD) generally considers background pixels as low-rank distribution and anomaly pixels as sparse distribution. However, it is usually difficult to construct an accurate background dictionary for the background pixels composed of different land covers, and completely separate sparse anomaly targets from various complicated background pixels with complex mixed noise interference. To address these challenges, we propose an antinoise hierarchical mutual-incoherence-induced discriminative learning (AHMID) method for the AD of HSI. A structural incoherence constraint is designed to constrain the inherent dissimilarity and incoherence between the background and anomalies for improving their separability. Then, a first-order statistic constraint is conducted on targets to enhance the anomaly representation, and a decentralization constraint is used on the background to suppress the background representation. Meanwhile, a mixed noise model is constructed by <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"> <tex-math notation=\"LaTeX\">$\\ell _{1,1}$ </tex-math></inline-formula> -norm and Frobenius norm to improve the antinoise performance. Finally, a hierarchical alternative strategy is developed to gradually optimize the background and anomalies. Experiments on six HSI AD datasets show that the proposed method outperforms a few state-of-the-art AD algorithms. Code: <uri xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">https://github.com/HalongL/HAD-AHMID</uri>"}}
{"id": "ZBf3nrIH_-", "cdate": 1672531200000, "mdate": 1695949485804, "content": {"title": "Multiscale Diff-Changed Feature Fusion Network for Hyperspectral Image Change Detection", "abstract": "For hyperspectral image (HSI) change detection (CD), multiscale features are usually used to construct the detection models. However, the existing studies only consider the multiscale features containing changed and unchanged components, which is difficult to represent the subtle changes between bitemporal HSIs in each scale. To address this problem, we propose a multiscale diff-changed feature fusion network (MSDFFN) for HSI CD, which improves the ability of feature representation by learning the refined change components between bitemporal HSIs under different scales. In this network, a temporal feature encoder\u2013decoder subnetwork, which combines a reduced inception (RI) module and a cross-layer attention module to highlight the significant features, is designed to extract the temporal features of HSIs. A bidirectional diff-changed feature representation (BDFR) module is proposed to learn the fine changed features of bitemporal HSIs at various scales to enhance the discriminative performance of the subtle change. A multiscale attention fusion (MSAF) module is developed to adaptively fuse the changed features of various scales. The proposed method can not only discover the subtle change in bitemporal HSIs but also improve the discriminating power for HSI CD. Experimental results on three HSI datasets show that MSDFFN outperforms a few state-of-the-art methods."}}
{"id": "OEBM1iWAOh", "cdate": 1672531200000, "mdate": 1695949485783, "content": {"title": "Recurrent Residual Dual Attention Network for Airborne Laser Scanning Point Cloud Semantic Segmentation", "abstract": "Kernel point convolution (KPConv) can effectively represent the point features of point cloud data. However, KPConv-based methods just consider the local information of each point, which is very difficult to characterize the intrinsic properties of airborne laser scanning (ALS) point clouds for complex laser scanning conditions. Therefore, we rethink KPConv and propose a recurrent residual dual attention network (RRDAN) based on the encoder\u2013decoder structure for the semantic segmentation of ALS point cloud data. In the encoder stage, we design an attention KPConv (AKPConv) block by using a scaling factor of batch normalization to highlight the significant channel information. Then, we use the AKPConv block to develop a recurrent residual kernel attention (RRKA) module to iteratively aggregate the local neighborhood features. In the decoder stage, we design a global and local channel attention (GLCA) module with global connection and local 1-D convolution to interact the global and local information after fusing the upsampled high-level representations and the skip-connected low-level features. In addition, to reduce the influence of the long-tailed distribution of reflection intensity, we apply gamma transformation to correct the data as a normal distribution. The proposed RRDAN can achieve diversified feature aggregation to implement the refined semantic segmentation of ALS point clouds. We evaluate our method on three ALS datasets (i.e., ISPRS, DCF2019, and LASDU) to demonstrate its performance compared to a few advanced methods. The code is available at <uri xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">https://github.com/SC-shendazt/RRDAN</uri> ."}}
{"id": "CVx55qqtl3", "cdate": 1672531200000, "mdate": 1695949485784, "content": {"title": "Dual-View Spectral and Global Spatial Feature Fusion Network for Hyperspectral Image Classification", "abstract": "For hyperspectral image (HSI) classification, two branch networks generally use convolutional neural networks (CNNs) to extract the spatial features and long short-term memory (LSTM) to learn the spectral features. However, CNNs with a local kernel neglect the global properties of the whole HSI. LSTM does not consider the macroscopic and detailed information of spectra. In this article, we propose a dual-view spectral and global spatial feature fusion network (DSGSF) to extract the spatial\u2013spectral features for HSI classification (HSIC), including a spatial subnetwork and a spectral subnetwork. In the spatial subnetwork, we propose a global spatial feature representation model based on the encoder\u2013decoder structure with channel attention and spatial attention to learn the global spatial features. In the spectral subnetwork, we design a dual-view spectral feature aggregation model with view attention to learn the diversity of spectral features. By fusing the two subnetworks, we construct DSGSF to extract the spatial\u2013spectral features of HSI with strong discriminating performance. Experimental results on three public datasets illustrate that the proposed method can achieve competitive results compared with the state-of-the-art methods. Code:  <uri xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">https://github.com/RZWang-WH/DSGSF</uri> ."}}
{"id": "5QqCg21J1n", "cdate": 1672531200000, "mdate": 1681695899878, "content": {"title": "CLNode: Curriculum Learning for Node Classification", "abstract": "Node classification is a fundamental graph-based task that aims to predict the classes of unlabeled nodes, for which Graph Neural Networks (GNNs) are the state-of-the-art methods. Current GNNs assume that nodes in the training set contribute equally during training. However, the quality of training nodes varies greatly, and the performance of GNNs could be harmed by two types of low-quality training nodes: (1) inter-class nodes situated near class boundaries that lack the typical characteristics of their corresponding classes. Because GNNs are data-driven approaches, training on these nodes could degrade the accuracy. (2) mislabeled nodes. In real-world graphs, nodes are often mislabeled, which can significantly degrade the robustness of GNNs. To mitigate the detrimental effect of the low-quality training nodes, we present CLNode, which employs a selective training strategy to train GNN based on the quality of nodes. Specifically, we first design a multi-perspective difficulty measurer to accurately measure the quality of training nodes. Then, based on the measured qualities, we employ a training scheduler that selects appropriate training nodes to train GNN in each epoch. To evaluate the effectiveness of CLNode, we conduct extensive experiments by incorporating it in six representative backbone GNNs. Experimental results on real-world networks demonstrate that CLNode is a general framework that can be combined with various GNNs to improve their accuracy and robustness."}}
