{"id": "QcySjEtiLIf", "cdate": 1668670086621, "mdate": 1668670086621, "content": {"title": "SkexGen: Autoregressive Generation of CAD Construction Sequences with Disentangled Codebooks", "abstract": "We present SkexGen, a novel autoregressive generative model for computer-aided design (CAD) construction sequences containing sketch-and-extrude modeling operations. Our model utilizes distinct Transformer architectures to encode topological, geometric, and extrusion variations of construction sequences into disentangled codebooks. Autoregressive Transformer decoders generate CAD construction sequences sharing certain properties specified by the codebook vectors. Extensive experiments demonstrate that our disentangled codebook representation generates diverse and high-quality CAD models, enhances user control, and enables efficient exploration of the design space. The code is available at https://samxuxiang.github.io/skexgen."}}
{"id": "_puXOBx_E7W", "cdate": 1640995200000, "mdate": 1667336053498, "content": {"title": "SkexGen: Autoregressive Generation of CAD Construction Sequences with Disentangled Codebooks", "abstract": "We present SkexGen, a novel autoregressive generative model for computer-aided design (CAD) construction sequences containing sketch-and-extrude modeling operations. Our model utilizes distinct Tra..."}}
{"id": "LJJvelyz8gZ", "cdate": 1640995200000, "mdate": 1667336053517, "content": {"title": "SkexGen: Autoregressive Generation of CAD Construction Sequences with Disentangled Codebooks", "abstract": "We present SkexGen, a novel autoregressive generative model for computer-aided design (CAD) construction sequences containing sketch-and-extrude modeling operations. Our model utilizes distinct Transformer architectures to encode topological, geometric, and extrusion variations of construction sequences into disentangled codebooks. Autoregressive Transformer decoders generate CAD construction sequences sharing certain properties specified by the codebook vectors. Extensive experiments demonstrate that our disentangled codebook representation generates diverse and high-quality CAD models, enhances user control, and enables efficient exploration of the design space. The code is available at https://samxuxiang.github.io/skexgen."}}
{"id": "V2U-RwtEK1d", "cdate": 1609459200000, "mdate": 1667336053492, "content": {"title": "Structured Outdoor Architecture Reconstruction by Exploration and Classification", "abstract": "This paper presents an explore-and-classify framework for structured architectural reconstruction from an aerial image. Starting from a potentially imperfect building reconstruction by an existing algorithm, our approach 1) explores the space of building models by modifying the reconstruction via heuristic actions; 2) learns to classify the correctness of building models while generating classification labels based on the ground-truth, and 3) repeat. At test time, we iterate exploration and classification, seeking for a result with the best classification score. We evaluate the approach using initial reconstructions by two baselines and two state-of-the-art reconstruction algorithms. Qualitative and quantitative evaluations demonstrate that our approach consistently improves the reconstruction quality from every initial reconstruction."}}
{"id": "3ZFEkO2LZ4m", "cdate": 1609459200000, "mdate": 1667336053491, "content": {"title": "Structured Outdoor Architecture Reconstruction by Exploration and Classification", "abstract": "This paper presents an explore-and-classify framework for structured architectural reconstruction from an aerial image. Starting from a potentially imperfect building reconstruction by an existing algorithm, our approach 1) explores the space of building models by modifying the reconstruction via heuristic actions; 2) learns to classify the correctness of building models while generating classification labels based on the ground-truth; and 3) repeat. At test time, we iterate exploration and classification, seeking for a result with the best classification score. We evaluate the approach using initial reconstructions by two baselines and two state-of-the-art reconstruction algorithms. Qualitative and quantitative evaluations demonstrate that our approach consistently improves the reconstruction quality from every initial reconstruction."}}
{"id": "37K10p_3bTO", "cdate": 1609459200000, "mdate": 1667336053510, "content": {"title": "D3D-HOI: Dynamic 3D Human-Object Interactions from Videos", "abstract": "We introduce D3D-HOI: a dataset of monocular videos with ground truth annotations of 3D object pose, shape and part motion during human-object interactions. Our dataset consists of several common articulated objects captured from diverse real-world scenes and camera viewpoints. Each manipulated object (e.g., microwave oven) is represented with a matching 3D parametric model. This data allows us to evaluate the reconstruction quality of articulated objects and establish a benchmark for this challenging task. In particular, we leverage the estimated 3D human pose for more accurate inference of the object spatial layout and dynamics. We evaluate this approach on our dataset, demonstrating that human-object relations can significantly reduce the ambiguity of articulated object reconstructions from challenging real-world videos. Code and dataset are available at https://github.com/facebookresearch/d3d-hoi."}}
{"id": "LAfZd9jb3F", "cdate": 1577836800000, "mdate": 1667336053496, "content": {"title": "Student-Centric Network Learning for Improved Knowledge Transfer", "abstract": ""}}
{"id": "BBWL3SAkTi", "cdate": 1577836800000, "mdate": 1667336053496, "content": {"title": "MCMI: Multi-Cycle Image Translation with Mutual Information Constraints", "abstract": "We present a mutual information-based framework for unsupervised image-to-image translation. Our MCMI approach treats single-cycle image translation models as modules that can be used recurrently in a multi-cycle translation setting where the translation process is bounded by mutual information constraints between the input and output images. The proposed mutual information constraints can improve cross-domain mappings by optimizing out translation functions that fail to satisfy the Markov property during image translations. We show that models trained with MCMI produce higher quality images and learn more semantically-relevant mappings compared to state-of-the-art image translation methods. The MCMI framework can be applied to existing unpaired image-to-image translation models with minimum modifications. Qualitative experiments and a perceptual study demonstrate the image quality improvements and generality of our approach using several backbone models and a variety of image datasets."}}
{"id": "d_JrQCrlZ9", "cdate": 1546300800000, "mdate": 1667336053492, "content": {"title": "A spatial and temporal features mixture model with body parts for video-based person re-identification", "abstract": "The goal of video-based person re-identification is to recognize a person at different camera settings. Most previous methods use features from the full body to represent a person. In this paper, we propose a novel Spatial and Temporal Features Mixture Model (STFMM). Unlike previous approaches, our model first horizontally splits human body into N parts, which include the information of head, waist, legs and so on. The feature of each part is then integrated in order to achieve more expressive representation for each person. Experiments conducted on the iLIDS-VID and PRID-2011 datasets demonstrate that our approach outperforms the existing video-based person re-identification methods and significantly improves stability. Our model achieves a rank-1 CMC accuracy of 73.6% on the iLIDS-VID dataset and a rank-1 CMC accuracy of 47.8% for the cross-data testing."}}
{"id": "n9rWLdWQfo", "cdate": 1514764800000, "mdate": 1667336053495, "content": {"title": "Error Correction Maximization for Deep Image Hashing", "abstract": ""}}
