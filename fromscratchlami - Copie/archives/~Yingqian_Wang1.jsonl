{"id": "pCvKEFQ3QTq", "cdate": 1704067200000, "mdate": 1710830872889, "content": {"title": "Mixed-Precision Network Quantization for Infrared Small Target Segmentation", "abstract": "Network quantization is leveraged to reduce the model size, memory footprint, and computational cost of deep neural networks. It is achieved by representing float weights and activations with lower bit counterparts, which is essential for model deployment on resource-limited devices. However, due to the extremely small size of infrared small targets in the feature map, low-bit quantization could lead to huge information loss of small targets and thus causes severe segmentation performance degradation. To achieve low-bit quantization while maintaining the segmentation performance, we first study the quantization sensitivity of small target segmentation network and observe the sensitivity heterogeneity of different layers in the network. Specifically, feature maps in shallow layers and encoder subnetwork are more vulnerable to information loss caused by quantization as compared to deep layers and decoder subnetwork. Based on these observations, we are motivated to assign a different bitwidth for each block according to their quantization sensitivity. A simple yet effective symmetrically progressive decreasing mixed-precision quantization (SPMix-Q) method is proposed to achieve high-performance segmentation under low-bit quantization (i.e., 2.42 bits for weights and 3.82 bits for activations). The experimental results show that our SPMix-Q achieves comparable accuracy with only 1/13 model size, 1/4.6 memory footprint, and 1/29 computational cost to the full-precision counterparts. Compared with the homogeneous low-bit quantization methods, our method achieves much better performance in terms of intersection of union (IoU) on the benchmark datasets. Our mobile-system-on-a-chip (SOC) (e.g., Kyrin 980, Snapdragon 660, and Dimensity 800U) deployable android application package (APK) is available at: <uri xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">https://github.com/YeRen123455/SIRST-Quantization-Deployment</uri> ."}}
{"id": "OwjICEmAnD", "cdate": 1704067200000, "mdate": 1710830872885, "content": {"title": "Learning Remote Sensing Object Detection With Single Point Supervision", "abstract": "Pointly supervised object detection (PSOD) has attracted considerable interest due to its lower labeling cost when compared to box-level supervised object detection. However, the complex scenes and densely packed and dynamic-scale objects in remote-sensing (RS) images hinder the development of PSOD methods in the RS field. In this article, we make the first attempt to achieve RS object detection with single-point supervision and propose a PSOD method tailored for RS images. Specifically, we design a point label upgrader (PLUG) to generate pseudo-box labels from single-point labels and then use the pseudo-boxes to supervise the optimization of existing detectors. Moreover, to handle the challenge of the densely packed objects in RS images, we propose a sparse feature-guided semantic prediction (SemPred) module that can generate high-quality semantic maps by fully exploiting informative cues from sparse objects. Extensive ablation studies on the DOTA dataset have validated the effectiveness of our method. Our method can achieve significantly better performance when compared to state-of-the-art image-level and point-level supervised detection methods and reduce the performance gap between PSOD and box-level supervised object detection. The code is available at <uri xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">https://github.com/heshitian/PLUG</uri> ."}}
{"id": "fyQV7dK3cQL", "cdate": 1680307200000, "mdate": 1682001056435, "content": {"title": "Exploring Fine-Grained Sparsity in Convolutional Neural Networks for Efficient Inference", "abstract": "Neural networks contain considerable redundant computation, which drags down the inference efficiency and hinders the deployment on resource-limited devices. In this paper, we study the sparsity in convolutional neural networks and propose a generic sparse mask mechanism to improve the inference efficiency of networks. Specifically, sparse masks are learned in both data and channel dimensions to dynamically localize and skip redundant computation at a fine-grained level. Based on our sparse mask mechanism, we develop SMPointSeg, SMSR, and SMStereo for point cloud semantic segmentation, single image super-resolution, and stereo matching tasks, respectively. It is demonstrated that our sparse masks are well compatible to different model components and network architectures to accurately localize redundant computation, with computational cost being significantly reduced for practical speedup. Extensive experiments show that our SMPointSeg, SMSR, and SMStereo achieve state-of-the-art performance on benchmark datasets in terms of both accuracy and efficiency."}}
{"id": "seSH76iwNzm", "cdate": 1672531200000, "mdate": 1696060121510, "content": {"title": "Learning Remote Sensing Object Detection with Single Point Supervision", "abstract": "Pointly Supervised Object Detection (PSOD) has attracted considerable interests due to its lower labeling cost as compared to box-level supervised object detection. However, the complex scenes, densely packed and dynamic-scale objects in Remote Sensing (RS) images hinder the development of PSOD methods in RS field. In this paper, we make the first attempt to achieve RS object detection with single point supervision, and propose a PSOD framework tailored with RS images. Specifically, we design a point label upgrader (PLUG) to generate pseudo box labels from single point labels, and then use the pseudo boxes to supervise the optimization of existing detectors. Moreover, to handle the challenge of the densely packed objects in RS images, we propose a sparse feature guided semantic prediction module which can generate high-quality semantic maps by fully exploiting informative cues from sparse objects. Extensive ablation studies on the DOTA dataset have validated the effectiveness of our method. Our method can achieve significantly better performance as compared to state-of-the-art image-level and point-level supervised detection methods, and reduce the performance gap between PSOD and box-level supervised object detection. Code will be available at https://github.com/heshitian/PLUG."}}
{"id": "pP6fSY00VE", "cdate": 1672531200000, "mdate": 1682001056469, "content": {"title": "Dense Nested Attention Network for Infrared Small Target Detection", "abstract": "Single-frame infrared small target (SIRST) detection aims at separating small targets from clutter backgrounds. With the advances of deep learning, CNN-based methods have yielded promising results in generic object detection due to their powerful modeling capability. However, existing CNN-based methods cannot be directly applied to infrared small targets since pooling layers in their networks could lead to the loss of targets in deep layers. To handle this problem, we propose a dense nested attention network (DNA-Net) in this paper. Specifically, we design a dense nested interactive module (DNIM) to achieve progressive interaction among high-level and low-level features. With the repetitive interaction in DNIM, the information of infrared small targets in deep layers can be maintained. Based on DNIM, we further propose a cascaded channel and spatial attention module (CSAM) to adaptively enhance multi-level features. With our DNA-Net, contextual information of small targets can be well incorporated and fully exploited by repetitive fusion and enhancement. Moreover, we develop an infrared small target dataset (namely, NUDT-SIRST) and propose a set of evaluation metrics to conduct comprehensive performance evaluation. Experiments on both public and our self-developed datasets demonstrate the effectiveness of our method. Compared to other state-of-the-art methods, our method achieves better performance in terms of probability of detection ( <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"> <tex-math notation=\"LaTeX\">${P}_{d}$ </tex-math></inline-formula> ), false-alarm rate ( <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"> <tex-math notation=\"LaTeX\">${F}_{a}$ </tex-math></inline-formula> ), and intersection of union ( <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"> <tex-math notation=\"LaTeX\">$IoU$ </tex-math></inline-formula> )."}}
{"id": "hFEwKQc5dS", "cdate": 1672531200000, "mdate": 1700055246165, "content": {"title": "RepISD-Net: Learning Efficient Infrared Small-Target Detection Network via Structural Re-Parameterization", "abstract": "Infrared small-target detection is a challenging task for deep learning-based methods, because targets tend to disappear in the deep layers. To handle this problem, the existing deep neural networks usually apply various dense and skip connections for feature maintenance. Although these well-designed networks have achieved good detection performance, the complex network structures reduce their efficiency. In this article, we propose a simple yet efficient network (RepISD-Net) for infrared small-target detection. The core of our RepISD-Net is to use different network architectures but equivalent model parameters for training and inference, respectively. Specifically, in the training phase, we design a parallel multibranch edge compensation block (ECB) to enhance the local salient features and capture finer contour characteristic of infrared small targets. In the inference phase, the multibranch topology structures are merged into a single branch with only cascaded  <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"> <tex-math notation=\"LaTeX\">$3 \\times 3$ </tex-math></inline-formula>  convolutions for fast inference. We conduct extensive experiments on several public datasets to validate the effectiveness of our method. Experimental results demonstrate that our RepISD-Net can achieve comparable or even better detection performance with significant acceleration in inference speed as compared with state-of-the-art infrared small-target detection methods. Our code is available at  <uri xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">https://github.com/dalinlin-Wu/RepISD-Net</uri> ."}}
{"id": "h3ZSI_kava", "cdate": 1672531200000, "mdate": 1683955262634, "content": {"title": "NTIRE 2023 Challenge on Light Field Image Super-Resolution: Dataset, Methods and Results", "abstract": "In this report, we summarize the first NTIRE challenge on light field (LF) image super-resolution (SR), which aims at super-resolving LF images under the standard bicubic degradation with a magnification factor of 4. This challenge develops a new LF dataset called NTIRE-2023 for validation and test, and provides a toolbox called BasicLFSR to facilitate model development. Compared with single image SR, the major challenge of LF image SR lies in how to exploit complementary angular information from plenty of views with varying disparities. In total, 148 participants have registered the challenge, and 11 teams have successfully submitted results with PSNR scores higher than the baseline method LF-InterNet \\cite{LF-InterNet}. These newly developed methods have set new state-of-the-art in LF image SR, e.g., the winning method achieves around 1 dB PSNR improvement over the existing state-of-the-art method DistgSSR \\cite{DistgLF}. We report the solutions proposed by the participants, and summarize their common trends and useful tricks. We hope this challenge can stimulate future research and inspire new ideas in LF image SR."}}
{"id": "gUU1vO1sYiK", "cdate": 1672531200000, "mdate": 1682001056481, "content": {"title": "You Only Train Once: Learning a General Anomaly Enhancement Network With Random Masks for Hyperspectral Anomaly Detection", "abstract": "In this article, we introduce a new approach to address the challenge of generalization in hyperspectral anomaly detection (AD). Our method eliminates the need for adjusting parameters or retraining on new test scenes as required by most existing methods. Employing an image-level training paradigm, we achieve a general anomaly enhancement network for hyperspectral AD that only needs to be trained once. Trained on a set of anomaly-free hyperspectral images with random masks, our network can learn the spatial context characteristics between anomalies and backgrounds in an unsupervised way. In addition, a plug-and-play model selection module is proposed to search for a spatial\u2013spectral transform domain that is more suitable for AD tasks than the original data. To establish a unified benchmark to comprehensively evaluate our method and existing methods, we develop a large-scale hyperspectral AD dataset (HAD100) that includes 100 real test scenes with diverse anomaly targets. In comparison experiments, we combine our network with a parameter-free detector and achieve the optimal balance between detection accuracy and inference speed among state-of-the-art AD methods. Experimental results also show that our method still achieves competitive performance when the training and test sets are captured by different sensor devices. Our code is available at <uri xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">https://github.com/ZhaoxuLi123/AETNet</uri> ."}}
{"id": "g990CNmY21", "cdate": 1672531200000, "mdate": 1682001056380, "content": {"title": "Incorporating Deep Background Prior Into Model-Based Method for Unsupervised Moving Vehicle Detection in Satellite Videos", "abstract": "Background reconstruction is a key step of moving object detection in satellite videos. Most existing model-based methods exploit low-rank prior to recover background, which has achieved good performance but suffered degradation under complex and dynamic scenes. In this article, we introduce a deep background prior into model-based methods for moving vehicle detection in satellite videos. Our deep background prior is obtained by a background reconstruction network, which can learn to reconstruct the background from consecutive frames. By applying our deep background prior into model-based methods, a closed-form solution can be obtained via the alternating direction method of multipliers (ADMM), and then, detection results can be acquired through iterative optimization. More importantly, our background reconstruction network can be trained in an unsupervised way by introducing specifically designed loss, thus relieving the dependence on large-scale labeled datasets. Extensive experimental results demonstrate the efficiency and effectiveness of the proposed method."}}
{"id": "OT0ihqqOIOF", "cdate": 1672531200000, "mdate": 1682001056457, "content": {"title": "Spectral Difference Guided Graph Attention Autoencoder for Hyperspectral Anomaly Detection", "abstract": "Hyperspectral anomaly detection (HAD) aims at distinguishing anomalies from background in an unsupervised manner. Autoencoder (AE) and its variant-based methods have achieved promising detection performance in HAD. However, most existing methods neglect to exploit the local structure information of hyperspectral images (HSIs) that reflects the underlying relationships between each pixel and its surroundings. Hence, the representation capabilities of the networks are restricted. Moreover, reconstruction of anomalies during training compels the networks to learn abnormal patterns and, thus, reduces the spectral differences between background and anomalies. To address these problems, a spectral difference guided graph attention autoencoder (SDGATA) network is proposed for HAD. Specifically, the relationships among samples are modeled by a GAT encoder, where a spectral sharpening constraint is introduced to guide the attention coefficient learning. In this way, the encoder can also represent the spectral differences between central nodes and their neighbors. Then, a learnable GAT decoder is constructed to reconstruct node attributes and obtain the node reconstruction errors for HAD. Besides, a background purification method is proposed to generate superpixel-level samples to suppress anomaly reconstruction during training. Extensive quantitative and qualitative evaluations on six real datasets and one synthetic dataset show that the proposed method achieves competitive detection performance as compared with the state-of-the-art HAD methods."}}
