{"id": "rClOll5mtSy", "cdate": 1682899200000, "mdate": 1682352709121, "content": {"title": "Public goods games in directed networks", "abstract": ""}}
{"id": "f32zQdGtRSH", "cdate": 1672531200000, "mdate": 1682352709141, "content": {"title": "Complexity of Equilibria in First-Price Auctions under General Tie-Breaking Rules", "abstract": "We study the complexity of finding an approximate (pure) Bayesian Nash equilibrium in a first-price auction with common priors when the tie-breaking rule is part of the input. We show that the problem is PPAD-complete even when the tie-breaking rule is trilateral (i.e., it specifies item allocations when no more than three bidders are in tie, and adopts the uniform tie-breaking rule otherwise). This is the first hardness result for equilibrium computation in first-price auctions with common priors. On the positive side, we give a PTAS for the problem under the uniform tie-breaking rule."}}
{"id": "_MXcs330Sd", "cdate": 1672531200000, "mdate": 1682352709198, "content": {"title": "Near Optimal Memory-Regret Tradeoff for Online Learning", "abstract": "In the experts problem, on each of $T$ days, an agent needs to follow the advice of one of $n$ ``experts''. After each day, the loss associated with each expert's advice is revealed. A fundamental result in learning theory says that the agent can achieve vanishing regret, i.e. their cumulative loss is within $o(T)$ of the cumulative loss of the best-in-hindsight expert.   Can the agent perform well without sufficient space to remember all the experts? We extend a nascent line of research on this question in two directions:   $\\bullet$ We give a new algorithm against the oblivious adversary, improving over the memory-regret tradeoff obtained by [PZ23], and nearly matching the lower bound of [SWXZ22].   $\\bullet$ We also consider an adaptive adversary who can observe past experts chosen by the agent. In this setting we give both a new algorithm and a novel lower bound, proving that roughly $\\sqrt{n}$ memory is both necessary and sufficient for obtaining $o(T)$ regret."}}
{"id": "Q7cuEy7_XAV", "cdate": 1672531200000, "mdate": 1686333141687, "content": {"title": "Complexity of Equilibria in First-Price Auctions under General Tie-Breaking Rules", "abstract": "We study the complexity of finding an approximate (pure) Bayesian Nash equilibrium in a first-price auction with common priors when the tie-breaking rule is part of the input. We show that the problem is PPAD-complete even when the tie-breaking rule is trilateral (i.e., it specifies item allocations when no more than three bidders are in tie, and adopts the uniform tie-breaking rule otherwise). This is the first hardness result for equilibrium computation in first-price auctions with common priors. On the positive side, we give a PTAS for the problem under the uniform tie-breaking rule."}}
{"id": "Q19gWpl57Sc", "cdate": 1672531200000, "mdate": 1682352709230, "content": {"title": "Fully-dynamic-to-incremental reductions with known deletion order (e.g. sliding window)", "abstract": ""}}
{"id": "BnHCg_0ncF", "cdate": 1672531200000, "mdate": 1682352709116, "content": {"title": "Online Prediction in Sub-linear Space", "abstract": ""}}
{"id": "2RVRDlmzLN", "cdate": 1664928786209, "mdate": null, "content": {"title": "Memory bounds for continual learning", "abstract": "Continual learning, or lifelong learning, is a formidable current challenge to machine learning. It requires the learner to solve a sequence of $k$ different learning tasks, one after the other, while %with each new task learned it retaining its aptitude for earlier tasks; the continual learner should scale better than the obvious solution of developing and maintaining a separate learner for each of the $k$ tasks.  We embark on a complexity-theoretic study of continual learning in the PAC framework. We make novel uses of communication complexity to establish that any continual learner, even an improper one, needs memory that grows linearly with $k$, strongly suggesting that the problem is intractable.  When logarithmically many passes over the learning tasks are allowed, we provide an algorithm based on multiplicative weights update whose memory requirement scales well; we also establish that improper learning is necessary for such performance. We conjecture that these results may lead to new promising approaches to continual learning."}}
{"id": "z9cpLkoSNNh", "cdate": 1652737482013, "mdate": null, "content": {"title": "Continual learning: a feature extraction formalization, an efficient algorithm, and fundamental obstructions", "abstract": "Continual learning is an emerging paradigm in machine learning, wherein a model is exposed in an online fashion to data from multiple different distributions (i.e. environments), and is expected to adapt to the distribution change. Precisely, the goal is to perform well in the new environment, while simultaneously retaining the performance on the previous environments (i.e. avoid ``catastrophic forgetting'').\nWhile this setup has enjoyed a lot of attention in the applied community, there hasn't be theoretical work that even formalizes the desired guarantees. In this paper, we propose a framework for continual learning through the framework of feature extraction---namely, one in which features, as well as a classifier, are being trained with each environment. When the features are linear, we design an efficient gradient-based algorithm $\\mathsf{DPGrad}$, that is guaranteed to perform well on the current environment, as well as avoid catastrophic forgetting. In the general case, when the features are non-linear, we show such an algorithm cannot exist, whether efficient or not."}}
{"id": "uCqk19xfqy7", "cdate": 1640995200000, "mdate": 1682352709160, "content": {"title": "Fully-dynamic-to-incremental reductions with known deletion order (e.g. sliding window)", "abstract": "Dynamic algorithms come in three main flavors: $\\mathit{incremental}$ (insertions-only), $\\mathit{decremental}$ (deletions-only), or $\\mathit{fully}$ $\\mathit{dynamic}$ (both insertions and deletions). Fully dynamic is the holy grail of dynamic algorithm design; it is obviously more general than the other two, but is it strictly harder? Several works managed to reduce fully dynamic to the incremental or decremental models by taking advantage of either specific structure of the incremental/decremental algorithms (e.g. [HK99, HLT01, BKS12, ADKKP16, BS80, OL81, OvL81]), or specific order of insertions/deletions (e.g. [AW14,HKNS15,KPP16]). Our goal in this work is to get a black-box fully-to-incremental reduction that is as general as possible. We find that the following conditions are necessary: $\\bullet$ The incremental algorithm must have a worst-case (rather than amortized) running time guarantee. $\\bullet$ The reduction must work in what we call the $\\mathit{deletions}$-$\\mathit{look}$-$\\mathit{ahead}$ $\\mathit{model}$, where the order of deletions among current elements is known in advance. A notable practical example is the \"sliding window\" (FIFO) order of updates. Under those conditions, we design: $\\bullet$ A simple, practical, amortized-fully-dynamic to worst-case-incremental reduction with a $\\log(T)$-factor overhead on the running time, where $T$ is the total number of updates. $\\bullet$ A theoretical worst-case-fully-dynamic to worst-case-incremental reduction with a $\\mathsf{polylog}(T)$-factor overhead on the running time."}}
{"id": "c71yuL0TZj", "cdate": 1640995200000, "mdate": 1682352709749, "content": {"title": "Computational Hardness of the Hylland-Zeckhauser Scheme", "abstract": ""}}
