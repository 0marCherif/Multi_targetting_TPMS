{"id": "x_K8oG_rL-8", "cdate": 1672531200000, "mdate": 1695128942290, "content": {"title": "Learnable Spectral Wavelets on Dynamic Graphs to Capture Global Interactions", "abstract": "Learning on evolving(dynamic) graphs has caught the attention of researchers as static methods exhibit limited performance in this setting. The existing methods for dynamic graphs learn spatial features by local neighborhood aggregation, which essentially only captures the low pass signals and local interactions. In this work, we go beyond current approaches to incorporate global features for effectively learning representations of a dynamically evolving graph. We propose to do so by capturing the spectrum of the dynamic graph. Since static methods to learn the graph spectrum would not consider the history of the evolution of the spectrum as the graph evolves with time, we propose an approach to learn the graph wavelets to capture this evolving spectra. Further, we propose a framework that integrates the dynamically captured spectra in the form of these learnable wavelets into spatial features for incorporating local and global interactions. Experiments on eight standard datasets show that our method significantly outperforms related methods on various tasks for dynamic graphs."}}
{"id": "g__9sR8L4Q", "cdate": 1672531200000, "mdate": 1695128942300, "content": {"title": "Can Persistent Homology provide an efficient alternative for Evaluation of Knowledge Graph Completion Methods?", "abstract": "In this paper we present a novel method, $\\textit{Knowledge Persistence}$ ($\\mathcal{KP}$), for faster evaluation of Knowledge Graph (KG) completion approaches. Current ranking-based evaluation is quadratic in the size of the KG, leading to long evaluation times and consequently a high carbon footprint. $\\mathcal{KP}$ addresses this by representing the topology of the KG completion methods through the lens of topological data analysis, concretely using persistent homology. The characteristics of persistent homology allow $\\mathcal{KP}$ to evaluate the quality of the KG completion looking only at a fraction of the data. Experimental results on standard datasets show that the proposed metric is highly correlated with ranking metrics (Hits@N, MR, MRR). Performance evaluation shows that $\\mathcal{KP}$ is computationally efficient: In some cases, the evaluation time (validation+test) of a KG completion method has been reduced from 18 hours (using Hits@10) to 27 seconds (using $\\mathcal{KP}$), and on average (across methods & data) reduces the evaluation time (validation+test) by $\\approx$ $\\textbf{99.96}\\%$."}}
{"id": "KpVFPnqDV9D", "cdate": 1672531200000, "mdate": 1695128942277, "content": {"title": "Can Persistent Homology provide an efficient alternative for Evaluation of Knowledge Graph Completion Methods?", "abstract": "In this paper we present a novel method, Knowledge Persistence (), for faster evaluation of Knowledge Graph (KG) completion approaches. Current ranking-based evaluation is quadratic in the size of the KG, leading to long evaluation times and consequently a high carbon footprint. addresses this by representing the topology of the KG completion methods through the lens of topological data analysis, concretely using persistent homology. The characteristics of persistent homology allow to evaluate the quality of the KG completion looking only at a fraction of the data. Experimental results on standard datasets show that the proposed metric is highly correlated with ranking metrics (Hits@N, MR, MRR). Performance evaluation shows that is computationally efficient: In some cases, the evaluation time (validation+test) of a KG completion method has been reduced from 18 hours (using Hits@10) to 27 seconds (using ), and on average (across methods & data) reduces the evaluation time (validation+test) by \u2248 99.96%."}}
{"id": "pFuu2N_2uE", "cdate": 1640995200000, "mdate": 1695128942294, "content": {"title": "How Expressive are Transformers in Spectral Domain for Graphs?", "abstract": "The recent works proposing transformer-based models for graphs have proven the inadequacy of Vanilla Transformer for graph representation learning. To understand this inadequacy, there is a need to..."}}
{"id": "bcazFKdTwv", "cdate": 1640995200000, "mdate": 1663037053801, "content": {"title": "Investigating Expressiveness of Transformer in Spectral Domain for Graphs", "abstract": "The recent works proposing transformer-based models for graphs have proven the inadequacy of Vanilla Transformer for graph representation learning. To understand this inadequacy, there is a need to investigate if spectral analysis of the transformer will reveal insights into its expressive power. Similar studies already established that spectral analysis of Graph neural networks (GNNs) provides extra perspectives on their expressiveness. In this work, we systematically study and establish the link between the spatial and spectral domain in the realm of the transformer. We further provide a theoretical analysis and prove that the spatial attention mechanism in the transformer cannot effectively capture the desired frequency response, thus, inherently limiting its expressiveness in spectral space. Therefore, we propose FeTA, a framework that aims to perform attention over the entire graph spectrum (i.e., actual frequency components of the graphs) analogous to the attention in spatial space. Empirical results suggest that FeTA provides homogeneous performance gain against vanilla transformer across all tasks on standard benchmarks and can easily be extended to GNN-based models with low-pass characteristics (e.g., GAT)."}}
{"id": "YJUE20f0BI", "cdate": 1640995200000, "mdate": 1695128942280, "content": {"title": "Learnable Spectral Wavelets on Dynamic Graphs to Capture Global Interactions", "abstract": "Learning on evolving(dynamic) graphs has caught the attention of researchers as static methods exhibit limited performance in this setting. The existing methods for dynamic graphs learn spatial features by local neighborhood aggregation, which essentially only captures the low pass signals and local interactions. In this work, we go beyond current approaches to incorporate global features for effectively learning representations of a dynamically evolving graph. We propose to do so by capturing the spectrum of the dynamic graph. Since static methods to learn the graph spectrum would not consider the history of the evolution of the spectrum as the graph evolves with time, we propose a novel approach to learn the graph wavelets to capture this evolving spectra. Further, we propose a framework that integrates the dynamically captured spectra in the form of these learnable wavelets into spatial features for incorporating local and global interactions. Experiments on eight standard datasets show that our method significantly outperforms related methods on various tasks for dynamic graphs."}}
{"id": "HmFBdvBkUUY", "cdate": 1632875449145, "mdate": null, "content": {"title": "SpecTRA: Spectral Transformer for Graph Representation Learning", "abstract": "Transformers have recently been applied in the more generic domain of graphs. For the same, researchers proposed various positional and structural encoding schemes to overcome the limitation of transformers in modeling the positional invariance in graphs and graph topology. Some of these encoding techniques use the spectrum of the graph. In addition to graph topology, graph signals could be multi-channeled and contain heterogeneous information. We argue that transformers cannot model multichannel signals inherently spread over the graph spectrum. To this end, we propose SpecTRA, a novel approach that induces a spectral module into the transformer architecture to enable decomposition of graph spectrum and selectively learn useful information akin to filtering in the frequency domain. Results on standard benchmark datasets show that the proposed method performs comparably or better than existing transformer and GNN based architectures."}}
{"id": "jEYkAXaEq08", "cdate": 1609459200000, "mdate": 1663037053785, "content": {"title": "KGPool: Dynamic Knowledge Graph Context Selection for Relation Extraction", "abstract": "Abhishek Nadgeri, Anson Bastos, Kuldeep Singh, Isaiah Onando Mulang\u2019, Johannes Hoffart, Saeedeh Shekarpour, Vijay Saraswat. Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021. 2021."}}
{"id": "WNH9WmRvY1", "cdate": 1609459200000, "mdate": 1695128942324, "content": {"title": "HopfE: Knowledge Graph Representation Learning using Inverse Hopf Fibrations", "abstract": "Recently, several Knowledge Graph Embedding (KGE) approaches have been devised to represent entities and relations in dense vector space and employed in downstream tasks such as link prediction. A few KGE techniques address interpretability, i.e., mapping the connectivity patterns of the relations (i.e., symmetric/asymmetric, inverse, and composition) to a geometric interpretation such as rotations. Other approaches model the representations in higher dimensional space such as four-dimensional space (4D) to enhance the ability to infer the connectivity patterns (i.e., expressiveness). However, modeling relation and entity in a 4D space often comes at the cost of interpretability. This paper proposes HopfE, a novel KGE approach aiming to achieve the interpretability of inferred relations in the four-dimensional space. We first model the structural embeddings in 3D Euclidean space and view the relation operator as an SO(3) rotation. Next, we map the entity embedding vector from a 3D space to a 4D hypersphere using the inverse Hopf Fibration, in which we embed the semantic information from the KG ontology. Thus, HopfE considers the structural and semantic properties of the entities without losing expressivity and interpretability. Our empirical results on four well-known benchmarks achieve state-of-the-art performance for the KG completion task."}}
{"id": "KKbKm2BJfxi", "cdate": 1609459200000, "mdate": 1663037053811, "content": {"title": "RECON: Relation Extraction using Knowledge Graph Context in a Graph Neural Network", "abstract": "In this paper, we present a novel method named RECON, that automatically identifies relations in a sentence (sentential relation extraction) and aligns to a knowledge graph (KG). RECON uses a graph neural network to learn representations of both the sentence as well as facts stored in a KG, improving the overall extraction quality. These facts, including entity attributes (label, alias, description, instance-of) and factual triples, have not been collectively used in the state of the art methods. We evaluate the effect of various forms of representing the KG context on the performance of RECON. The empirical evaluation on two standard relation extraction datasets shows that RECON significantly outperforms all state of the art methods on NYT Freebase and Wikidata datasets."}}
