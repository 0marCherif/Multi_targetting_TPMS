{"id": "N2fhDRrZ0D5", "cdate": 1640995200000, "mdate": 1649213537936, "content": {"title": "Combining DNN partitioning and early exit", "abstract": "DNN inference is time-consuming and resource hungry. Partitioning and early exit are ways to run DNNs efficiently on the edge. Partitioning balances the computation load on multiple servers, and early exit offers to quit the inference process sooner and save time. Usually, these two are considered separate steps with limited flexibility. This work combines partitioning and early exit and proposes a performance model to estimate both inference latency and accuracy. We use this performance model to offer the best partitioned/early exit DNN based on deployment information and user preferences. Our experiments show that the flexibility in number and position of partitioning points and placement on available devices plays an important role in deciding the best output. In the future, we plan to turn this work into a \"one-click\" system to train and optimize models for edge computing."}}
{"id": "m0U5CNfZWjk", "cdate": 1609459200000, "mdate": 1649213537905, "content": {"title": "Remote COPD Severity and Exacerbation Detection Using Heart Rate and Activity Data Measured from a Wearable Device", "abstract": "Chronic obstructive pulmonary disease (COPD) is one of the leading causes of human mortality worldwide. Traditionally, estimating COPD severity has been done in controlled clinical conditions using cough sounds, respiration, and heart rate variability, with the latter reporting insights on the autonomic dysfunction caused by the disease. Advancements in remote monitoring and wearable device technologies, in turn, have allowed for remote COPD monitoring in daily life conditions. In this study, we explore the potential for predicting COPD severity and exacerbation using a low-cost wearable device that measures heart rate and activity data. We collected smartwatch sensor data from 35 COPD patients over a period of three months. Our evaluation shows that future trajectory of the disease can be predicted using only the first few days of continuous unobtrusive wearable data collected from COPD patients. Using features extracted from wearable device an Isolation Forest was able to predict exacerbation with an area under curve (AUC) 0.69 thus showing improvement over a random choice classifier."}}
{"id": "gUsU493BoTl", "cdate": 1609459200000, "mdate": 1649213537937, "content": {"title": "Coughwatch: Real-World Cough Detection using Smartwatches", "abstract": "Continuous monitoring of cough may provide insights into the health of individuals as well as the effectiveness of treatments. Smart-watches, in particular, are highly promising for such monitoring: they are inexpensive, unobtrusive, programmable, and have a variety of sensors. However, current mobile cough detection systems are not designed for smartwatches, and perform poorly when applied to real-world smartwatch data since they are often evaluated on data collected in the lab.In this work we propose CoughWatch, a lightweight cough detector for smartwatches that uses audio and movement data for in-the-wild cough detection. On our in-the-wild data, CoughWatch achieves a precision of 82% and recall of 55%, compared to 6% precision and 19% recall achieved by the current state-of-the-art approach. Furthermore, by incorporating gyroscope and accelerometer data, CoughWatch improves precision by up to 15.5 percentage points compared to an audio-only model."}}
{"id": "cGbSw5RDpqj", "cdate": 1609459200000, "mdate": 1649213537936, "content": {"title": "Sustainable Computing on the Edge: A System Dynamics Perspective", "abstract": "This paper explores the CO2 footprint of IoT applications by using system dynamics modeling to estimate the CO2 emissions over time from a wireless video analytics application. We model the impact of the application design and the mobile infrastructure on the short and long term emissions produced by running the application on both cloud and edge computing infrastructures. Our analysis shows that the base station radio and the wide-area data network are major contributors of CO2 emissions. We find that CO2 emissions can be reduced by 50% by placing edge centers near the base stations, exploiting new features of the 5G mobile network, and scheduling data uploads judiciously. We also analyze the long term effects of application design choices and increased user base on carbon emissions."}}
{"id": "XD5SKjEMMZn", "cdate": 1609459200000, "mdate": 1649213537917, "content": {"title": "RL-Scope: Cross-Stack Profiling for Deep Reinforcement Learning Workloads", "abstract": "Deep reinforcement learning (RL) has made groundbreaking advancements in robotics, data center management and other applications. Unfortunately, system-level bottlenecks in RL workloads are poorly understood; we observe fundamental structural differences in RL workloads that make them inherently less GPU-bound than supervised learning (SL). To explain where training time is spent in RL workloads, we propose RL-Scope, a cross-stack profiler that scopes low-level CPU/GPU resource usage to high-level algorithmic operations, and provides accurate insights by correcting for profiling overhead. Using RL-Scope, we survey RL workloads across its major dimensions including ML backend, RL algorithm, and simulator. For ML backends, we explain a $2.3\\times$ difference in runtime between equivalent PyTorch and TensorFlow algorithm implementations, and identify a bottleneck rooted in overly abstracted algorithm implementations. For RL algorithms and simulators, we show that on-policy algorithms are at least $3.5\\times$ more simulation-bound than off-policy algorithms. Finally, we profile a scale-up workload and demonstrate that GPU utilization metrics reported by commonly used tools dramatically inflate GPU usage, whereas RL-Scope reports true GPU-bound time. RL-Scope is an open-source tool available at https://github.com/UofT-EcoSystem/rlscope ."}}
{"id": "X6FCWObKHT", "cdate": 1609459200000, "mdate": 1649213537920, "content": {"title": "SSD-based Workload Characteristics and Their Performance Implications", "abstract": "Storage systems are designed and optimized relying on wisdom derived from analysis studies of file-system and block-level workloads. However, while SSDs are becoming a dominant building block in many storage systems, their design continues to build on knowledge derived from analysis targeted at hard disk optimization. Though still valuable, it does not cover important aspects relevant for SSD performance. In a sense, we are \u201csearching under the streetlight,\u201d possibly missing important opportunities for optimizing storage system design. We present the first I/O workload analysis designed with SSDs in mind. We characterize traces from four repositories and examine their \u201ctemperature\u201d ranges, sensitivity to page size, and \u201clogical locality.\u201d We then take the first step towards correlating these characteristics with three standard performance metrics: write amplification, read amplification, and flash read costs. Our results show that SSD-specific characteristics strongly affect performance, often in surprising ways."}}
{"id": "WFTtsDjdxBJ", "cdate": 1609459200000, "mdate": 1649213537921, "content": {"title": "A Distance-Based Scheme for Reducing Bandwidth in Distributed Geometric Monitoring", "abstract": "Tracking the value of a function computed from a dynamic, distributed data stream is a challenging problem with many real-world applications. Continuously forwarding data updates can be costly, yet complex functions are difficult to evaluate when data is not centralized. One general approach to continuous distributed monitoring is the Geometric Monitoring (GM) family of techniques. GM reduces the functional monitoring problem to a set of local constraints that each node checks locally, and uses a simple protocol to update those constraints as needed.While most work on GM focuses on reducing the number of messages exchanged by the common GM protocol, with one recent notable exception, there has been little attention to reducing the size of those messages, which impacts bandwidth.We propose the Distance Scheme: a novel bandwidth-efficient variation of the GM protocol that reduces the size of most monitoring messages in GM to a single scalar, and is compatible with the large body of prior work on GM. We apply it to monitor three different functions using three real-world datasets, and show it substantially reduces bandwidth while requiring fewer messages to be transmitted than the current state-of-the-art approach. We further describe a value-based scheme that, while typically outperformed by the Distance Scheme, is simpler to apply, matches state-of-the-art bandwidth performance with fewer messages, and is also compatible with existing work."}}
{"id": "U6mNgsQOhGU", "cdate": 1609459200000, "mdate": 1649213537940, "content": {"title": "WristO2: Reliable Peripheral Oxygen Saturation Readings from Wrist-Worn Pulse Oximeters", "abstract": "Peripheral blood oxygen saturation (SpO <sub xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">2</sub> ) is a vital health signal with many clinical applications. Modern wrist-worn devices, such as the Apple Watch, FitBit, and Samsung Gear, have pulse oximeter sensors, making them theoretically capable of measuring SpO <sub xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">2</sub> . However, current techniques for SpO <sub xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">2</sub> measurements using pulse oximeter sensors are based on readings taken from the fingertip. Readings collected from the wrist are unreliable and often inaccurate, due to motion and insufficient skin contact. Enabling accurate oxygen saturation monitoring on wearable devices would allow continuous health monitoring and open up new avenues of research. In this work, we explore the reliability of SpO <sub xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">2</sub> measurements from the wrist. Using a custom wrist-worn pulse oximeter, we find that existing algorithms used in traditional fingertip SpO <sub xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">2</sub> sensors are a poor match for taking measurements from the wrist and can lead to over 90% of readings being inaccurate. We further show that skin tone, IMU sensors, and user-level calibration affect measurement error, and must be considered when designing wrist-worn SpO <sub xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">2</sub> sensors and measurement algorithms. Next, based on our findings, we propose WristO <sub xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">2</sub> , an alternative approach for reliable SpO <sub xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">2</sub> sensing. By selectively pruning unreliable data, WristO <sub xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">2</sub> achieves an order of magnitude reduction in error compared to existing algorithms, while still providing sufficiently frequent readings for continuous health monitoring."}}
{"id": "-pt5tJLUPH", "cdate": 1609459200000, "mdate": 1649213537966, "content": {"title": "Skin tone, Confidence, and Data Quality of Heart Rate Sensing in WearOS Smartwatches", "abstract": "Smartwatches can collect heart rate data unobtrusively and continuously, making them a promising tool for conducting long term studies, monitoring chronic conditions, and providing timely intervention. Healthcare applications, however, require us to understand the reliability of collected readings, both in terms of quality and quantity. The accuracy of optical heart rate (HR) measurements has been studied extensively in recent years, identifying several common causes of errors. For example, previous research has demonstrated that inaccurate HR readings occur more frequently in dark skin as compared to light skin due to melanin absorption. Smartwatches therefore implement a confidence mechanism to estimate reliability of HR readings. We study the effect of skin tone on the reliability of confidence estimation of seven consumer-grade WearOS smartwatches. We find that some watches systematically underestimate the reliability of HR readings taken from dark skin, despite no substantial difference in actual error. This results in significantly fewer data points for people with darker skin tones, which can bias downstream applications. We also report a wide variation in how watches implement the same WearOS API for HR collection, with implications for researchers that intend to use them for studies."}}
{"id": "s3IcfZjg6az", "cdate": 1577836800000, "mdate": 1649213537938, "content": {"title": "Feather: Hierarchical Querying for the Edge", "abstract": "In many edge computing scenarios data is generated over a wide geographic area and is stored near the edges, before being pushed upstream to a hierarchy of data centers. Querying such geo-distributed data traditionally falls into two general approaches: push incoming queries down to the edge where the data is, or run them locally in the cloud. Feather is a hybrid querying scheme that exploits the hierarchical structure of such geo-distributed systems to trade temporal accuracy (freshness) for improved latency and reduced bandwidth. Rather than pushing queries to the edge or executing them in the cloud, Feather selectively pushes queries towards the edge while guaranteeing a user-supplied per-query freshness limit. Partial results are then aggregated along the path to the cloud, until a final result is provided with guaranteed freshness. We evaluate Feather in controlled experiments using real-world geo-tagged traces, as well as a real system running across 10 datacenters in 3 continents. Feather combines the best of cloud and edge execution, answering queries with a fraction of edge latency, providing fresher answers than cloud, while reducing network bandwidth and load on edges."}}
