{"id": "E8-tQ2Orn01", "cdate": 1667344563462, "mdate": 1667344563462, "content": {"title": "What\u2019s in the Image? Explorable Decoding of Compressed Images", "abstract": "The ever-growing amounts of visual contents captured on a daily basis necessitate the use of lossy compression methods in order to save storage space and transmission bandwidth. While extensive research efforts are devoted to improving compression techniques, every method inevitably discards information. Especially at low bit rates, this information often corresponds to semantically meaningful visual cues, so that decompression involves significant ambiguity. In spite of this fact, existing decompression algorithms typically produce only a single output, and do not allow the viewer to explore the set of images that map to the given compressed code. In this work we propose the first image decompression method to facilitate user-exploration of the diverse set of natural images that could have given rise to the compressed input code, thus granting users the ability to determine what could and what could not have been there in the original scene. Specifically, we develop a novel deep-network based decoder architecture for the ubiquitous JPEG standard, which allows traversing the set of decompressed images that are consistent with the compressed JPEG file. To allow for simple user interaction, we develop a graphical user interface comprising several intuitive exploration tools, including an automatic tool for examining specific solutions of interest. We exemplify our framework on graphical, medical and forensic use cases, demonstrating its wide range of potential applications."}}
{"id": "iWhPhL9h_u7", "cdate": 1640995200000, "mdate": 1681748435630, "content": {"title": "Neural Volume Super-Resolution", "abstract": "Neural volumetric representations have become a widely adopted model for radiance fields in 3D scenes. These representations are fully implicit or hybrid function approximators of the instantaneous volumetric radiance in a scene, which are typically learned from multi-view captures of the scene. We investigate the new task of neural volume super-resolution - rendering high-resolution views corresponding to a scene captured at low resolution. To this end, we propose a neural super-resolution network that operates directly on the volumetric representation of the scene. This approach allows us to exploit an advantage of operating in the volumetric domain, namely the ability to guarantee consistent super-resolution across different viewing directions. To realize our method, we devise a novel 3D representation that hinges on multiple 2D feature planes. This allows us to super-resolve the 3D scene representation by applying 2D convolutional networks on the 2D feature planes. We validate the proposed method by super-resolving multi-view consistent views on a diverse set of unseen 3D scenes, confirming qualitative and quantitatively favorable quality over existing approaches."}}
{"id": "PfcDPzWVqP", "cdate": 1640995200000, "mdate": 1681746271579, "content": {"title": "Explorable Data Consistent CT Reconstruction", "abstract": ""}}
{"id": "5MArKeTpoee", "cdate": 1640995200000, "mdate": 1681842661273, "content": {"title": "Beyond Local Processing: Adapting CNNs for CT Reconstruction", "abstract": "Convolutional neural networks (CNNs) are well suited for image restoration tasks, like super resolution, deblurring, and denoising, in which the information required for restoring each pixel is mostly concentrated in a small neighborhood around it in the degraded image. However, they are less natural for highly non-local reconstruction problems, such as computed tomography (CT). To date, this incompatibility has been partially circumvented by using CNNs with very large receptive fields. Here, we propose an alternative approach, which relies on the rearrangement of the CT projection measurements along the CNN\u2019s 3rd (channels\u2019) dimension. This leads to a more local inverse problem, which is suitable for CNNs. We demonstrate our approach on sparse-view and limited-view CT, and show that it significantly improves reconstruction accuracy for any given network model. This allows achieving the same level of accuracy with significantly smaller models, and thus induces shorter training and inference times."}}
{"id": "R6nFQy2vwQq", "cdate": 1621629832500, "mdate": null, "content": {"title": "Deep Self-Dissimilarities as Powerful Visual Fingerprints", "abstract": "Features extracted from deep layers of classification networks are widely used as image descriptors. Here, we exploit an unexplored property of these features: their internal dissimilarity. While small image patches are known to have similar statistics across image scales, it turns out that the internal distribution of deep features varies distinctively between scales. We show how this deep self dissimilarity (DSD) property can be used as a powerful visual fingerprint. Particularly, we illustrate that full-reference and no-reference image quality measures derived from DSD are highly correlated with human preference. In addition, incorporating DSD as a loss function in training of image restoration networks, leads to results that are at least as photo-realistic as those obtained by GAN based methods, while not requiring adversarial training."}}
{"id": "s4dgfjfPmDs", "cdate": 1609459200000, "mdate": 1681842692652, "content": {"title": "What's in the Image? Explorable Decoding of Compressed Images", "abstract": "The ever-growing amounts of visual contents captured on a daily basis necessitate the use of lossy compression methods in order to save storage space and transmission bandwidth. While extensive research efforts are devoted to improving compression techniques, every method inevitably discards information. Especially at low bit rates, this information often corresponds to semantically meaningful visual cues, so that decompression involves significant ambiguity. In spite of this fact, existing decompression algorithms typically produce only a single output, and do not allow the viewer to explore the set of images that map to the given compressed code. In this work we propose the first image decompression method to facilitate user-exploration of the diverse set of natural images that could have given rise to the compressed input code, thus granting users the ability to determine what could and what could not have been there in the original scene. Specifically, we develop a novel deep-network based decoder architecture for the ubiquitous JPEG standard, which allows traversing the set of decompressed images that are consistent with the compressed JPEG file. To allow for simple user interaction, we develop a graphical user interface comprising several intuitive exploration tools, including an automatic tool for examining specific solutions of interest. We exemplify our framework on graphical, medical and forensic use cases, demonstrating its wide range of potential applications."}}
{"id": "YpbQ27RM_L", "cdate": 1582372143356, "mdate": null, "content": {"title": "Explorable Super Resolution", "abstract": "Single image super resolution (SR) has seen major performance leaps in recent years. However, existing methods do not allow exploring the infinitely many plausible reconstructions that might have given rise to the observed low-resolution (LR) image. These different explanations to the LR image may dramatically vary in their textures and fine details, and may often encode completely different semantic information. In this paper, we introduce the task of explorable super resolution. We propose a framework comprising a graphical user interface with a neural network backend, allowing editing the SR output so as to explore the abundance of plausible HR explanations to the LR input. At the heart of our method is a novel module that can wrap any existing SR network, analytically guaranteeing that its SR outputs would precisely match the LR input, when downsampled. Besides its importance in our setting, this module is guaranteed to decrease the reconstruction error of any SR network it wraps, and can be used to cope with blur kernels that are different from the one the network was trained for. We illustrate our approach in a variety of use cases, ranging from medical imaging and forensics, to graphics."}}
{"id": "x0XSpezJFR", "cdate": 1577836800000, "mdate": 1681842692675, "content": {"title": "Classification Confidence Estimation with Test-Time Data-Augmentation", "abstract": "Machine learning plays an increasingly significant role in many aspects of our lives (including medicine, transportation, security, justice and other domains), making the potential consequences of false predictions increasingly devastating. These consequences may be mitigated if we can automatically flag such false predictions and potentially assign them to alternative, more reliable mechanisms, that are possibly more costly and involve human attention. This suggests the task of detecting errors, which we tackle in this paper for the case of visual classification. To this end, we propose a novel approach for classification confidence estimation. We apply a set of semantics-preserving image transformations to the input image, and show how the resulting image sets can be used to estimate confidence in the classifier's prediction. We demonstrate the potential of our approach by extensively evaluating it on a wide variety of classifier architectures and datasets, including ResNext/ImageNet, achieving state of the art performance. This paper constitutes a significant revision of our earlier work in this direction (Bahat & Shakhnarovich, 2018)."}}
{"id": "mUNv501Twyc", "cdate": 1577836800000, "mdate": 1681842692655, "content": {"title": "Explorable Super Resolution", "abstract": "Single image super resolution (SR) has seen major performance leaps in recent years. However, existing methods do not allow exploring the infinitely many plausible reconstructions that might have given rise to the observed low-resolution (LR) image. These different explanations to the LR image may dramatically vary in their textures and fine details, and may often encode completely different semantic information. In this paper, we introduce the task of explorable super resolution. We propose a framework comprising a graphical user interface with a neural network backend, allowing editing the SR output so as to explore the abundance of plausible HR explanations to the LR input. At the heart of our method is a novel module that can wrap any existing SR network, analytically guaranteeing that its SR outputs would precisely match the LR input, when down- sampled. Besides its importance in our setting, this module is guaranteed to decrease the reconstruction error of any SR network it wraps, and can be used to cope with blur kernels that are different from the one the network was trained for. We illustrate our approach in a variety of use cases, ranging from medical imaging and forensics, to graphics."}}
{"id": "Ysowe0Oqtt", "cdate": 1546300800000, "mdate": null, "content": {"title": "Natural and Adversarial Error Detection using Invariance to Image Transformations", "abstract": "We propose an approach to distinguish between correct and incorrect image classifications. Our approach can detect misclassifications which either occur $\\it{unintentionally}$ (\"natural errors\"), or due to $\\it{intentional~adversarial~attacks}$ (\"adversarial errors\"), both in a single $\\it{unified~framework}$. Our approach is based on the observation that correctly classified images tend to exhibit robust and consistent classifications under certain image transformations (e.g., horizontal flip, small image translation, etc.). In contrast, incorrectly classified images (whether due to adversarial errors or natural errors) tend to exhibit large variations in classification results under such transformations. Our approach does not require any modifications or retraining of the classifier, hence can be applied to any pre-trained classifier. We further use state of the art targeted adversarial attacks to demonstrate that even when the adversary has full knowledge of our method, the adversarial distortion needed for bypassing our detector is $\\it{no~longer~imperceptible~to~the~human~eye}$. Our approach obtains state-of-the-art results compared to previous adversarial detection methods, surpassing them by a large margin."}}
