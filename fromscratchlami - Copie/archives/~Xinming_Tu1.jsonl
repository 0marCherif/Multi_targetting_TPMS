{"id": "ee5o-BKV4az", "cdate": 1663106203322, "mdate": null, "content": {"title": "Expectation pooling: an effective and interpretable pooling method for predicting DNA\u2013protein binding", "abstract": "Motivation: Convolutional neural networks (CNNs) have outperformed conventional methods in modeling the sequence specificity of DNA\u2013protein binding. While previous studies have built a connection between CNNs and probabilistic models, simple models of CNNs cannot achieve sufficient accuracy on this problem. Recently, some methods of neural networks have increased performance using complex neural networks whose results cannot be directly interpreted. However, it is difficult to combine probabilistic models and CNNs effectively to improve DNA\u2013protein binding predictions.\nResults: In this article, we present a novel global pooling method: expectation pooling for predicting DNA\u2013protein binding. Our pooling method stems naturally from the expectation maximization algorithm, and its benefits can be interpreted both statistically and via deep learning theory. Through experiments, we demonstrate that our pooling method improves the prediction performance DNA\u2013protein binding. Our interpretable pooling method combines probabilistic ideas with global pooling by taking the expectations of inputs without increasing the number of parameters. We also analyze the hyperparameters in our method and propose optional structures to help fit different datasets. We explore how to effectively utilize these novel pooling methods and show that combining statistical methods with deep learning is highly beneficial, which is promising and meaningful for future studies in this field."}}
{"id": "Tfb73TeKnJ-", "cdate": 1652737807960, "mdate": null, "content": {"title": "Cross-Linked Unified Embedding for cross-modality representation learning", "abstract": "Multi-modal learning is essential for understanding information in the real world. Jointly learning from multi-modal data enables global integration of both shared and modality-specific information, but current strategies often fail when observa- tions from certain modalities are incomplete or missing for part of the subjects. To learn comprehensive representations based on such modality-incomplete data, we present a semi-supervised neural network model called CLUE (Cross-Linked Unified Embedding). Extending from multi-modal VAEs, CLUE introduces the use of cross-encoders to construct latent representations from modality-incomplete observations. Representation learning for modality-incomplete observations is common in genomics. For example, human cells are tightly regulated across multi- ple related but distinct modalities such as DNA, RNA, and protein, jointly defining a cell\u2019s function. We benchmark CLUE on multi-modal data from single cell measurements, illustrating CLUE\u2019s superior performance in all assessed categories of the NeurIPS 2021 Multimodal Single-cell Data Integration Competition. While we focus on analysis of single cell genomic datasets, we note that the proposed cross-linked embedding strategy could be readily applied to other cross-modality representation learning problems."}}
