{"id": "-ki1S7_2x4", "cdate": 1672531200000, "mdate": 1683716419715, "content": {"title": "A2TP: Aggregator-aware In-network Aggregation for Multi-tenant Learning", "abstract": ""}}
{"id": "w3NQHoozK3o", "cdate": 1640995200000, "mdate": 1683721743445, "content": {"title": "APS: Adaptive Packet Spraying to Isolate Mix-Flows in Data Center Network", "abstract": "Modern data centers host diverse applications, which generate a mix of short flows with stringent latency requirement and long flows requiring large sustained throughput. To solve the problem of resource competition between the mixed flows, we propose an adaptive traffic isolation scheme APS. Based on the packet spraying scheme in the multipath transmission, APS dynamically separates long flows from short ones on different paths to provide the low latency for the short flows. Meanwhile, to resolve the out-of-order problem, APS limits the long flows to a few paths with Equal Cost Multi Path (ECMP). Experimental results of NS2 simulation and testbed implementation show that, APS reduces the average completion time for short flows by up to 60 percent and increases the throughputs for long flows by about 1.68x over the state-of-the-art multipath transmission schemes."}}
{"id": "qgXC3zzApm", "cdate": 1640995200000, "mdate": 1683721743648, "content": {"title": "Synthesizing Audio and Video Bitrate Selections via Learning from Actual Requirements", "abstract": "Adaptive bitrate (ABR) algorithms are routinely adopted for transmitting media contents across dynamic networks. State-of-the-art ABR algorithms only adapt to video bitrate without considering audio bitrate adaption as they consider the im-pact on the video to be negligible due to the small size of the audio. However, to bring users an immersive experience, more and more content providers have applied high-quality audio with large sizes, like stereophonic and surround (Dolby Atmos). Therefore, improper audio bitrate selection will ad-versely affect video bitrate selection, leading to undesirable audio/video combinations (the highest video quality with the lowest audio quality, vice versa) and frequent playback inter-ruptions. To address these inefficiencies, we propose a Self-Play reinforcement learning-based Audio-aware ABR algorithm named SPA to learn strategies for audio and video bi-trate selections. Experimental results demonstrate SPA's con-siderable superiority as compared with existing approaches."}}
{"id": "nQ7UraxHyMj", "cdate": 1640995200000, "mdate": 1683721743543, "content": {"title": "A Buffer-Based Adaptive Bitrate Approach in Wireless Networks With Iterative Correction", "abstract": "Most providers of video streaming are interested in improving quality of user experience across various wireless network circumstances. Many buffer-based ABR algorithms have been proposed to adjust the bitrate according to the buffer occupancy at the client player. Though keeping the buffer occupancy stable, such ABR algorithms cannot provide satisfied responsiveness to bandwidth dynamics. To solve the problem, we propose an ABR algorithm BBA+ that iteratively corrects the mapping function between bitrate and buffer occupancy according to network throughput. The results show that BBA+ effectively improves the average bitrate and reduces the rebuffering ratio."}}
{"id": "W2ixtNjp6Wy", "cdate": 1640995200000, "mdate": 1683721743447, "content": {"title": "Achieving High Utilization by Elastic Chunk Scheduling in DASH Systems", "abstract": "Dynamic adaptive streaming over HTTP (DASH) has been widely deployed to provide various video services in the Internet. However, the HTTP/1.1 or HTTP/2 utilized by the DASH system cannot ensure high quality of user experience in highly dynamic network scenarios. Specifically, when the clients fetch the video chunks from servers, it is well known that HTTP/1.1 protocol suffers from low utilization due to its stop-wait fashion. Though HTTP/2 enables the servers proactively push multiple chunks to clients on a single request, it exhibits poor adaptability to the network dynamic, since the bitrate of multiple chunks is fixed in one push cycle. To address these inefficiencies, we propose elastic chunk scheduling (ECS) to adaptively adjust the batch size of chunks in each push cycle according to network dynamic. To achieve high utilization, ECS increases the batch size of chunks under low network dynamic. Otherwise, ECS reduces the batch size to flexibly change the bitrate of chunks to avoid rebuffer and overflow at the player buffer. Through achieving good tradeoff between high link utilization and flexible rate switching, ECS improves overall QoE performance. The experimental results of testbed implementations show that ECS greatly decreases the rebuffer ratio by up to 36% and increases the average bitrate by up to 10% compared with the state-of-the-art solutions."}}
{"id": "QCskWaFxeJe", "cdate": 1640995200000, "mdate": 1683716419845, "content": {"title": "Achieving Per-Flow Fairness and High Utilization With Limited Priority Queues in Data Center", "abstract": "Modern data centers often host multiple applications with diverse network demands. To provide fair bandwidth allocation to several thousand traversing flows, Approximate Fair Queueing (AFQ) utilizes multiple priority queues in switch to approximate ideal fair queueing. However, due to limited number of queues in programmable switches, AFQ easily experiences high packet loss and low link utilization. In this paper, we propose Elastic Fair Queueing (EFQ), which leverages limited priority queues to flexibly achieve both high network utilization and fair bandwidth allocation. EFQ dynamically assigns the free buffer space in priority queues for each packet to obtain high utilization without sacrificing flow-level fairness. The results of simulation experiments and real implementations show that EFQ reduces the average flow completion time by up to 82% over the state-of-the-art fair bandwidth allocation mechanisms."}}
{"id": "0K6lJ1nHvD", "cdate": 1640995200000, "mdate": 1683716419846, "content": {"title": "End-to-End Congestion Control to Provide Deterministic Latency Over Internet", "abstract": "The emerging latency-sensitive services such as smart grid and tactile internet require deterministic network performance including deterministic end-to-end latency, latency jitter and bounded packet loss rate. To empower standard Ethernet with such capability, we provide a deterministic forwarding system named DLCC with end-to-end congestion control and queue management available at common hardwares to provide bounded delay over Internet. Meanwhile, DLCC provides a per-hop delay correction scheme to minimize delay variation under dynamic scenarios. Compared with other schemes, DLCC effectively reduces the delay jitter by up to 90% and is able to quickly converge to the required end-to-end delay."}}
{"id": "Su76_s1ncLc", "cdate": 1609459200000, "mdate": 1683721743648, "content": {"title": "GTCP: Hybrid Congestion Control for Cross-Datacenter Networks", "abstract": "To improve the quality of experience for worldwide users, an increasing number of service providers deploy their services on geographically dispersed data centers, which are connected by wide area network (WAN). In the cross-datacenter networks, however, the intra- and inter-datacenter parts have different characteristics, including switch buffer depth, round-trip time and bandwidth. Besides, most of intra-DC flows belong to interactive services that require low delay while inter-DC flows typically need to achieve high throughput. Unfortunately, existing sender-based and receiver-driven transport protocols do not consider the network heterogeneity between inter- and intra- DC networks so that they fail to simultaneously achieve low latency for intra-DC flows and high throughput for inter-DC flows. This paper proposes a general hybrid congestion control mechanism called GTCP to address this problem. When the inter-DC flow detects congestion inside data center, it switches to the receiver-driven mode to avoid the impact on intra-DC flows. Otherwise, it switches back to the sender-based mode to proactively explore the available bandwidth. Besides, the intra-DC flow leverages the pausing mechanism to eliminate the queue build-up. Through a series of testbed experiments and large-scale NS2 simulations, we demonstrate that GTCP reduces flow completion time by up to 79.3% compared with existing protocols."}}
{"id": "OhEnItPDkot", "cdate": 1609459200000, "mdate": 1683716419866, "content": {"title": "Mitigating Port Starvation for Shallow-buffered Switches in Datacenter Networks", "abstract": "Explicit Congestion Notification (ECN) is widely utilized in modern data centers to achieve low latency and high throughput for various applications. In recent years, however, even with the sustainable growth of link bandwidth in data centers, the switch buffer size does not increase remarkably. Consequently, the standard per-port ECN scheme suffers from excessive packet loss. Though the shared-buffer ECN scheme alleviates the packet loss, we observe that it leads to severe unfairness, which we term as the Port Starvation problem. When flows destined for some ports have aggressively occupied the shared buffer, the later-arrival flows destined for other ports will be ECN-marked unfairly and obtain significantly lower throughput. To address the port starvation problem, we design a buffer-aware fair ECN-marking (BFEM) scheme for shallow-buffered switch. BFEM leverages the shared buffer to reduce packet loss and meanwhile punishes aggressive flows by ECN marking. We evaluate BFEM with both 40Gbps P4 testbed implementation and large-scale NS2 simulation. The test results show that, by improving fairness between egress ports, BFEM increases total link utilization and reduces the average flow completion time by up to 40% compared with the state-of-the-art per-port and shared-buffer ECN marking schemes."}}
{"id": "LDsofwXaJLV", "cdate": 1609459200000, "mdate": 1683721743452, "content": {"title": "Survey on Traffic Management in Data Center Network: From Link Layer to Application Layer", "abstract": "Due to the explosive growth of all kinds of Internet services, data centers have become an irreplaceable and vital infrastructure to support this soaring trend. Compared with traditional networks, data center networks (DCNs) have unique features, such as high bandwidth, low latency, many-to-one communication mode, shallow buffered switches, and multi-root topology. These new characteristics pose a lot of challenges to previous network technics (e.g., Ethernet, Equal Cost Multi-path (ECMP), TCP), making them hard to adapt to DCNs and leading to severe performance degradation. In order to solve these challenges, DCNs have attracted a lot of attention from the industry and academia in recent years, and many new mechanisms in different layers are proposed to improve the transmission performance of data center networks. In the meantime, many surveys have emerged currently to introduce the current research of data center networks. However, previous surveys of DCNs mainly focus on only one specific network layer, making them difficult for readers to know about advanced researches on a holistic level. To help readers comprehend the current research progress of data center networks quickly, we employ a multi-layered top down taxonomy to classify the literature and propose several probable dimensions for future research in this area."}}
