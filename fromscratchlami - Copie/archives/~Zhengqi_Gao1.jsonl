{"id": "w0QXrZ3N-s", "cdate": 1663850043743, "mdate": null, "content": {"title": "The Modality Focusing Hypothesis: Towards Understanding Crossmodal Knowledge Distillation", "abstract": "Crossmodal knowledge distillation (KD) extends traditional knowledge distillation to the area of multimodal learning and demonstrates great success in various applications. To achieve knowledge transfer across modalities, a pretrained network from one modality is adopted as the teacher to provide supervision signals to a student network learning from the other modality. In contrast to the empirical success reported in prior works, the working mechanism of crossmodal KD remains a mystery. In this paper, we present a thorough understanding of crossmodal KD. We begin by providing two failure cases and demonstrate that KD is not a universal cure in crossmodal knowledge transfer. We then present the modality Venn diagram to understand modality relationships and the modality focusing hypothesis revealing the decisive factor in the efficacy of crossmodal KD. Experimental results on 6 multimodal datasets help justify our hypothesis, diagnose failure cases, and point directions to improve crossmodal knowledge transfer in the future."}}
{"id": "Il0ymeSnKyL", "cdate": 1652737306898, "mdate": null, "content": {"title": "NeurOLight: A Physics-Agnostic Neural Operator Enabling Parametric Photonic Device Simulation", "abstract": "Optical computing has become emerging technology in next-generation efficient artificial intelligence (AI) due to its ultra-high speed and efficiency. Electromagnetic field simulation is critical to the design, optimization, and validation of photonic devices and circuits.\nHowever, costly numerical simulation significantly hinders the scalability and turn-around time in the photonic circuit design loop. Recently, physics-informed neural networks were proposed to predict the optical field solution of a single instance of a partial differential equation (PDE) with predefined parameters. Their complicated PDE formulation and lack of efficient parametrization mechanism limit their flexibility and generalization in practical simulation scenarios. In this work, for the first time, a physics-agnostic neural operator-based framework, dubbed NeurOLight, is proposed to learn a family of frequency-domain Maxwell PDEs for ultra-fast parametric photonic device simulation. Specifically, we discretize different devices into a unified domain, represent parametric PDEs with a compact wave prior, and encode the incident light via masked source modeling. We design our model to have parameter-efficient cross-shaped NeurOLight blocks and adopt superposition-based augmentation for data-efficient learning. With those synergistic approaches, NeurOLight demonstrates 2-orders-of-magnitude faster simulation speed than numerical solvers and outperforms prior NN-based models by ~54% lower prediction error using ~44% fewer parameters."}}
{"id": "wLZQzkPsEm", "cdate": 1640995200000, "mdate": 1668431092229, "content": {"title": "A Simple Data Mixing Prior for Improving Self-Supervised Learning", "abstract": "Data mixing (e.g., Mixup, Cutmix, ResizeMix) is an essential component for advancing recognition models. In this paper, we focus on studying its effectiveness in the self-supervised setting. By noticing the mixed images that share the same source images are intrinsically related to each other, we hereby propose SDMP, short for $\\textbf{S}$imple $\\textbf{D}$ata $\\textbf{M}$ixing $\\textbf{P}$rior, to capture this straightforward yet essential prior, and position such mixed images as additional $\\textbf{positive pairs}$ to facilitate self-supervised representation learning. Our experiments verify that the proposed SDMP enables data mixing to help a set of self-supervised learning frameworks (e.g., MoCo) achieve better accuracy and out-of-distribution robustness. More notably, our SDMP is the first method that successfully leverages data mixing to improve (rather than hurt) the performance of Vision Transformers in the self-supervised setting. Code is publicly available at https://github.com/OliverRensu/SDMP"}}
{"id": "tEuEShVYYli", "cdate": 1640995200000, "mdate": 1668431091999, "content": {"title": "NeurOLight: A Physics-Agnostic Neural Operator Enabling Parametric Photonic Device Simulation", "abstract": "Optical computing is an emerging technology for next-generation efficient artificial intelligence (AI) due to its ultra-high speed and efficiency. Electromagnetic field simulation is critical to the design, optimization, and validation of photonic devices and circuits. However, costly numerical simulation significantly hinders the scalability and turn-around time in the photonic circuit design loop. Recently, physics-informed neural networks have been proposed to predict the optical field solution of a single instance of a partial differential equation (PDE) with predefined parameters. Their complicated PDE formulation and lack of efficient parametrization mechanisms limit their flexibility and generalization in practical simulation scenarios. In this work, for the first time, a physics-agnostic neural operator-based framework, dubbed NeurOLight, is proposed to learn a family of frequency-domain Maxwell PDEs for ultra-fast parametric photonic device simulation. We balance the efficiency and generalization of NeurOLight via several novel techniques. Specifically, we discretize different devices into a unified domain, represent parametric PDEs with a compact wave prior, and encode the incident light via masked source modeling. We design our model with parameter-efficient cross-shaped NeurOLight blocks and adopt superposition-based augmentation for data-efficient learning. With these synergistic approaches, NeurOLight generalizes to a large space of unseen simulation settings, demonstrates 2-orders-of-magnitude faster simulation speed than numerical solvers, and outperforms prior neural network models by ~54% lower prediction error with ~44% fewer parameters. Our code is available at https://github.com/JeremieMelo/NeurOLight."}}
{"id": "rrqKD6vGB_", "cdate": 1640995200000, "mdate": 1668431092220, "content": {"title": "Co-advise: Cross Inductive Bias Distillation", "abstract": "The inductive bias of vision transformers is more relaxed that cannot work well with insufficient data. Knowledge distillation is thus introduced to assist the training of transformers. Unlike previous works, where merely heavy convolution-based teachers are provided, in this paper, we delve into the influence of models inductive biases in knowledge distillation (e.g., convolution and involution). Our key observation is that the teacher accuracy is not the dominant reason for the student accuracy, but the teacher inductive bias is more important. We demonstrate that lightweight teachers with different architectural inductive biases can be used to co-advise the student transformer with outstanding performances. The rationale behind is that models designed with different inductive biases tend to focus on diverse patterns, and teachers with different inductive biases attain various knowledge despite being trained on the same dataset. The diverse knowledge provides a more precise and comprehensive description of the data and compounds and boosts the performance of the student during distillation. Furthermore, we propose a token inductive bias alignment to align the inductive bias of the token with its target teacher model. With only lightweight teachers provided and using this cross inductive bias distillation method, our vision transformers (termed as CiT) outperform all previous vision transformers (ViT) of the same architecture on ImageNet. Moreover, our small size model CiT-SAK further achieves 82.7% Top-1 accuracy on ImageNet without modifying the attention module of the ViT. Code is available at https://github.com/OliverRensu/co-advise."}}
{"id": "rHsIOjTVEvR", "cdate": 1640995200000, "mdate": 1668431091983, "content": {"title": "Efficient Non-Monte-Carlo Yield Estimation", "abstract": "Parametric yield estimation is a critical component in the Integrated Circuit design flow. We propose an efficient non-Monte-Carlo yield estimation method. Key is the use of sensitivity information efficiently obtained with the nominal circuit response. Based on Taylor expansion, the circuit performance can be approximated with a multivariate Gaussian distribution. Combining this with the circuit performance specifications, the yield can be estimated efficiently by repeatedly sampling from the obtained Gaussian distribution. Also proposed is an efficient method to identify impactful factors leading to yield loss (e.g., the most or least sensitive process variables; the tightest performance specifications) based on a multidimensional Venn diagram. Circuit examples demonstrate that the proposed method can well estimate the yield while significantly reducing the number of circuit simulations. Moreover, the proposed yield analysis method can provide useful hints for yield enhancement."}}
{"id": "iSmDTdKJG5", "cdate": 1640995200000, "mdate": 1668431092059, "content": {"title": "Learning from Multiple Annotator Noisy Labels via Sample-wise Label Fusion", "abstract": "Data lies at the core of modern deep learning. The impressive performance of supervised learning is built upon a base of massive accurately labeled data. However, in some real-world applications, accurate labeling might not be viable; instead, multiple noisy labels (instead of one accurate label) are provided by several annotators for each data sample. Learning a classifier on such a noisy training dataset is a challenging task. Previous approaches usually assume that all data samples share the same set of parameters related to annotator errors, while we demonstrate that label error learning should be both annotator and data sample dependent. Motivated by this observation, we propose a novel learning algorithm. The proposed method displays superiority compared with several state-of-the-art baseline methods on MNIST, CIFAR-100, and ImageNet-100. Our code is available at: https://github.com/zhengqigao/Learning-from-Multiple-Annotator-Noisy-Labels."}}
{"id": "dldmZhFrjdG", "cdate": 1640995200000, "mdate": 1668431092000, "content": {"title": "Automatic Synthesis of Light Processing Functions for Programmable Photonics: Theory and Realization", "abstract": "Linear light processing functions (e.g., routing, splitting, filtering) are key functions requiring configuration to implement on a programmable photonic integrated circuit (PPIC). In recirculating waveguide meshes (which include loop-backs), this is usually done manually. Some previous results describe explorations to perform this task automatically, but their efficiency or applicability is still limited. In this paper, we propose an efficient method that can automatically realize configurations for many light processing functions on a square-mesh PPIC. At its heart is an automatic differentiation subroutine built upon analytical expressions of scattering matrices, that enables gradient descent optimization for functional circuit synthesis. Similar to the state-of-the-art synthesis techniques, our method can realize configurations for a wide range of light processing functions, and multiple functions on the same PPIC simultaneously. However, we do not need to separate the functions spatially into different subdomains of the mesh, and the resulting optimum can have multiple functions using the same part of the mesh. Furthermore, compared to non-gradient or numerical differentiation based methods, our proposed approach achieves 3x time reduction in computational cost."}}
{"id": "_FbyOKg1roe", "cdate": 1640995200000, "mdate": 1668431091966, "content": {"title": "Fast Statistical Analysis of Rare Failure Events With Truncated Normal Distribution in High-Dimensional Variation Space", "abstract": "In this article, to accurately estimate the rare failure rates for large-scale circuits (e.g., SRAM) where process variations are modeled as truncated normal distributions in high-dimensional space, we propose a novel truncated scaled-sigma sampling (T-SSS) method. Similar to scaled-sigma sampling (SSS), T-SSS distorts the truncated normal distributions by a scaling factor, resulting in an analytical model for failure rate estimation. By drawing random samples from the distorted distribution and estimating a sequence of scaled failure rates, we can solve all unknown model coefficients and predict the original failure rate by extrapolation. The accuracy of T-SSS is further assessed by estimating its confidence interval (CI) based on resampling. Our numerical results demonstrate that the proposed T-SSS method can achieve superior accuracy over the state-of-the-art method without increasing the computational cost."}}
{"id": "VIVcSkbJd", "cdate": 1640995200000, "mdate": 1668431092042, "content": {"title": "A Simple Data Mixing Prior for Improving Self-Supervised Learning", "abstract": "Data mixing (e.g., Mixup, Cutmix, ResizeMix) is an essential component for advancing recognition models. In this paper, we focus on studying its effectiveness in the self-supervised setting. By noticing the mixed images that share the same source images are intrinsically related to each other, we hereby propose SDMP, short for Simple Data Mixing Prior, to capture this straightforward yet essential prior, and position such mixed images as additional positive pairs to facilitate self-supervised representation learning. Our experiments verify that the proposed SDMP enables data mixing to help a set of self-supervised learning frameworks (e.g., MoCo) achieve better accuracy and out-of-distribution robustness. More notably, our SDMP is the first method that successfully leverages data mixing to improve (rather than hurt) the performance of Vision Transformers in the self-supervised setting. Code is publicly available at https://github.com/OliverRensu/SDMP."}}
