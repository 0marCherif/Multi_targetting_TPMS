{"id": "gIUVVajW16", "cdate": 1685942500046, "mdate": 1685942500046, "content": {"title": "Assistive Recipe Editing through Critiquing", "abstract": "There has recently been growing interest in the automatic generation of cooking recipes that satisfy some form of dietary restrictions, thanks in part to the availability of online recipe data. Prior studies have used pre-trained language models, or relied on small paired recipe data (e.g., a recipe paired with a similar one that satisfies a dietary constraint). However, pre-trained language models generate inconsistent or incoherent recipes, and paired datasets are not available at scale. We address these deficiencies with RecipeCrit, a hierarchical denoising auto-encoder that edits recipes given ingredient-level critiques. The model is trained for recipe completion to learn semantic relationships within recipes. Our work's main innovation is our unsupervised critiquing module that allows users to edit recipes by interacting with the predicted ingredients; the system iteratively rewrites recipes to satisfy users' feedback. Experiments on the Recipe1M recipe dataset show that our model can more effectively edit recipes compared to strong language-modeling baselines, creating recipes that satisfy user constraints and are more correct, serendipitous, coherent, and relevant as measured by human judges."}}
{"id": "E1wUOv0eY7n", "cdate": 1685942116276, "mdate": null, "content": {"title": "pNLP-Mixer: an Efficient all-MLP Architecture for Language", "abstract": "Large pre-trained language models drastically changed the natural language processing(NLP) landscape. Nowadays, they represent the go-to framework to tackle diverse NLP tasks, even with a limited number of annotations. However, using those models in production, either in the cloud or at the edge, remains a challenge due to the memory footprint and/or inference costs. As an alternative, recent work on efficient NLP has shown that small weight-efficient models can reach competitive performance at a fraction of the costs. Here, we introduce pNLP-Mixer, an embbedding-free model based on the MLP-Mixer architecture that achieves high weight-efficiency thanks to a novel linguistically informed projection layer. We evaluate our model on two multi-lingual semantic parsing datasets, MTOP and multiATIS. On MTOP our pNLP-Mixer almost matches the performance of mBERT, which has 38 times more parameters, and outperforms the state-of-the-art of tiny models (pQRNN) with 3 times fewer parameters. On a long-sequence classification task (Hyperpartisan) our pNLP-Mixer without pretraining outperforms RoBERTa, which has 100 times more parameters, demonstrating the potential of this architecture."}}
{"id": "W5eBJiA37qT", "cdate": 1685942072182, "mdate": null, "content": {"title": "Extracting Text Representations for Terms and Phrases in Technical Domains", "abstract": "Extracting dense representations for terms and phrases is a task of great importance for knowledge discovery platforms targeting highly-technical fields. Dense representations are used as features for downstream components and have multiple applications ranging from ranking results in search to summarization. Common approaches to create dense representations include training domain-specific embeddings with self-supervised setups or using sentence encoder models trained over similarity tasks. In contrast to static embeddings, sentence encoders do not suffer from the out-of-vocabulary (OOV) problem, but impose significant computational costs. In this paper, we propose a fully unsupervised approach to text encoding that consists of training small character-based models with the objective of reconstructing large pre-trained embedding matrices. Models trained with this approach can not only match the quality of sentence encoders in technical domains, but are 5 times smaller and up to 10 times faster, even on high-end GPUs."}}
{"id": "q_d4EitkIfJ", "cdate": 1674208633736, "mdate": 1674208633736, "content": {"title": "Unsupervised Term Extraction for Highly Technical Domains", "abstract": "Term extraction is an information extraction task at the root of knowledge discovery platforms. Developing term extractors that are able to generalize across very diverse and potentially highly technical domains is challenging, as annotations for domains requiring in-depth expertise are scarce and expensive to obtain. In this paper, we describe the term extraction subsystem of a commercial knowledge discovery platform that targets highly technical fields such as pharma, medical, and material science. To be able to generalize across domains, we introduce a fully unsupervised annotator (UA). It extracts terms by combining novel morphological signals from sub-word tokenization with term-to-topic and intra-term similarity metrics, computed using general-domain pre-trained sentence-encoders. The annotator is used to implement a weakly-supervised setup, where transformer-models are fine-tuned (or pre-trained) over the training data generated by running the UA over large unlabeled corpora. Our experiments demonstrate that our setup can improve the predictive performance while decreasing the inference latency on both CPUs and GPUs. Our annotators provide a very competitive baseline for all the cases where annotations are not available. "}}
{"id": "UdZbK41Q5Cn", "cdate": 1634225900138, "mdate": 1634225900138, "content": {"title": "Multi-Gradient Descent for Multi-Objective Recommender Systems", "abstract": "Recommender systems need to mirror the complexity of the\nenvironment they are applied in. The more we know about\nwhat might benefit the user, the more objectives the recom-\nmender system has. In addition there may be multiple stake-\nholders - sellers, buyers, shareholders - in addition to legal\nand ethical constraints. Simultaneously optimizing for a mul-\ntitude of objectives, correlated and not correlated, having the\nsame scale or not, has proven difficult so far.\nWe introduce a stochastic multi-gradient descent approach\nto recommender systems (MGDRec) to solve this problem.\nWe show that this exceeds state-of-the-art methods in tradi-\ntional objective mixtures, like revenue and recall. Not only\nthat, but through gradient normalization we can combine fun-\ndamentally different objectives, having diverse scales, into a\nsingle coherent framework. We show that uncorrelated ob-\njectives, like the proportion of quality products, can be im-\nproved alongside accuracy. Through the use of stochasticity,\nwe avoid the pitfalls of calculating full gradients and provide\na clear setting for its applicability."}}
{"id": "1m9oGccBmus", "cdate": 1634225796846, "mdate": 1634225796846, "content": {"title": "Multi-Dimensional Explanation of Target Variables from Documents", "abstract": "Automated predictions require explanations to be interpretable\nby humans. Past work used attention and rationale mechanisms\nto find words that predict the target variable of a document.\nOften though, they result in a tradeoff between noisy explana-\ntions or a drop in accuracy. Furthermore, rationale methods\ncannot capture the multi-faceted nature of justifications for\nmultiple targets, because of the non-probabilistic nature of\nthe mask. In this paper, we propose the Multi-Target Masker\n(MTM) to address these shortcomings. The novelty lies in the\nsoft multi-dimensional mask that models a relevance proba-\nbility distribution over the set of target variables to handle\nambiguities. Additionally, two regularizers guide MTM to in-\nduce long, meaningful explanations. We evaluate MTM on\ntwo datasets and show, using standard metrics and human\nannotations, that the resulting masks are more accurate and\ncoherent than those generated by the state-of-the-art methods.\nMoreover, MTM is the first to also achieve the highest F1\nscores for all the target variables simultaneously."}}
{"id": "IdLxtU5FsaR", "cdate": 1634225725129, "mdate": 1634225725129, "content": {"title": "Interacting with Explanations through Critiquing", "abstract": "Using personalized explanations to support recom-\nmendations has been shown to increase trust and\nperceived quality. However, to actually obtain bet-\nter recommendations, there needs to be a means for\nusers to modify the recommendation criteria by in-\nteracting with the explanation. We present a novel\nexplanation technique using aspect markers that\nlearns to generate personalized explanations of rec-\nommendations from review texts, and we show that\nhuman users significantly prefer these explanations\nover those produced by state-of-the-art techniques.\nOur work\u2019s most important innovation is that it al-\nlows users to react to a recommendation by cri-\ntiquing the textual explanation: removing (symmet-\nrically adding) certain aspects they dislike or that\nare no longer relevant (symmetrically that are of in-\nterest). The system updates its user model and the\nresulting recommendations according to the cri-\ntique. This is based on a novel unsupervised\ncritiquing method for single- and multi-step cri-\ntiquing with textual explanations. Empirical results\nshow that our system achieves good performance in\nadapting to the preferences expressed in multi-step\ncritiquing and generates consistent explanations."}}
{"id": "DFKQaXUFpNh", "cdate": 1634225690497, "mdate": 1634225690497, "content": {"title": "Addressing Fairness in Classification with a Model-Agnostic Multi-Objective Algorithm", "abstract": "The goal of fairness in classification is to learn a\nclassifier that does not discriminate against groups\nof individuals based on sensitive attributes, such as\nrace and gender. One approach to designing fair al-\ngorithms is to use relaxations of fairness notions as\nregularization terms or in a constrained optimiza-\ntion problem. We observe that the hyperbolic tan-\ngent function can approximate the indicator func-\ntion. We leverage this property to define a differen-\ntiable relaxation that approximates fairness notions\nprovably better than existing relaxations. In addi-\ntion, we propose a model-agnostic multi-objective\narchitecture that can simultaneously optimize for\nmultiple fairness notions and multiple sensitive\nattributes and supports all statistical parity-based\nnotions of fairness. We use our relaxation with\nthe multi-objective architecture to learn fair clas-\nsifiers. Experiments on public datasets show that\nour method suffers a significantly lower loss of ac-\ncuracy than current debiasing algorithms relative\nto the unconstrained model."}}
{"id": "-LbAmXwXN6", "cdate": 1634225587030, "mdate": 1634225587030, "content": {"title": "Fast Multi-Step Critiquing for VAE-based Recommender Systems", "abstract": "Recent studies have shown that providing personalized explanations alongside recommendations increases trust and perceived quality.\nFurthermore, it gives users an opportunity to refine the recommendations by critiquing parts of the explanations. On one hand, current\nrecommender systems model the recommendation, explanation, and critiquing objectives jointly, but this creates an inherent trade-off\nbetween their respective performance. On the other hand, although recent latent linear critiquing approaches are built upon an existing\nrecommender system, they suffer from computational inefficiency at inference due to the objective optimized at each conversation\u2019s\nturn. We address these deficiencies with M&Ms-VAE, a novel variational autoencoder for recommendation and explanation that is\nbased on multimodal modeling assumptions. We train the model under a weak supervision scheme to simulate both fully and partially\nobserved variables. Then, we leverage the generalization ability of a trained M&Ms-VAE model to embed the user preference and the\ncritique separately. Our work\u2019s most important innovation is our critiquing module, which is built upon and trained in a self-supervised\nmanner with a simple ranking objective. Experiments on four real-world datasets demonstrate that among state-of-the-art models,\nour system is the first to dominate or match the performance in terms of recommendation, explanation, and multi-step critiquing.\nMoreover, M&Ms-VAE processes the critiques up to 25.6x faster than the best baselines. Finally, we show that our model infers coherent\njoint and cross generation, even under weak supervision, thanks to our multimodal-based modeling and training scheme."}}
{"id": "IkkbE4v9YHi", "cdate": 1634225541539, "mdate": 1634225541539, "content": {"title": "Rationalization through Concepts", "abstract": "Automated predictions require explanations to\nbe interpretable by humans. One type of ex-\nplanation is a rationale, i.e., a selection of in-\nput features such as relevant text snippets from\nwhich the model computes the outcome. How-\never, a single overall selection does not pro-\nvide a complete explanation, e.g., weighing\nseveral aspects for decisions. To this end, we\npresent a novel self-interpretable model called\nConRAT. Inspired by how human explanations\nfor high-level decisions are often based on key\nconcepts, ConRAT extracts a set of text snip-\npets as concepts and infers which ones are de-\nscribed in the document. Then, it explains the\noutcome with a linear aggregation of concepts.\nTwo regularizers drive ConRAT to build in-\nterpretable concepts. In addition, we propose\ntwo techniques to boost the rationale and pre-\ndictive performance further. Experiments on\nboth single- and multi-aspect sentiment classi-\nfication tasks show that ConRAT is the first to\ngenerate concepts that align with human ratio-\nnalization while using only the overall label.\nFurther, it outperforms state-of-the-art meth-\nods trained on each aspect label independently."}}
