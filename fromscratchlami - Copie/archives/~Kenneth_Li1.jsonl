{"id": "DeG07_TcZvT", "cdate": 1663850007704, "mdate": null, "content": {"title": "Emergent World Representations: Exploring a Sequence Model Trained on a Synthetic Task", "abstract": "Language models show a surprising range of capabilities, but the source of their apparent competence is unclear. Do these networks just memorize a collection of surface statistics, or do they rely on internal representations of the process that generates the sequences they see? We investigate this question by applying a variant of the GPT model to the task of predicting legal moves in a simple board game, Othello. Although the network has no a priori knowledge of the game or its rules, we uncover evidence of an emergent nonlinear internal representation of the board state. Interventional experiments indicate this representation can be used to control the output of the network and create \"latent saliency maps\" that can help explain predictions in human terms."}}
{"id": "W2_tP65utJt", "cdate": 1640995200000, "mdate": 1667341337778, "content": {"title": "Emergent World Representations: Exploring a Sequence Model Trained on a Synthetic Task", "abstract": "Language models show a surprising range of capabilities, but the source of their apparent competence is unclear. Do these networks just memorize a collection of surface statistics, or do they rely on internal representations of the process that generates the sequences they see? We investigate this question by applying a variant of the GPT model to the task of predicting legal moves in a simple board game, Othello. Although the network has no a priori knowledge of the game or its rules, we uncover evidence of an emergent nonlinear internal representation of the board state. Interventional experiments indicate this representation can be used to control the output of the network and create \"latent saliency maps\" that can help explain predictions in human terms."}}
{"id": "5Bw_CZer00j", "cdate": 1632875426624, "mdate": null, "content": {"title": "Self-supervised Discovery of Human Actons from Long Kinematic Videos", "abstract": "For human action understanding, a popular research direction is to analyze short video clips with unambiguous semantic content, such as jumping and drinking. However, methods for understanding short semantic actions cannot be directly translated to long kinematic sequences such as dancing, where it becomes challenging even to semantically label the human movements. To promote analysis of long videos of complex human motions, we propose a self-supervised method for learning a representation of such motion sequences that is similar to words in a sentence, where videos are segmented and clustered into recurring temporal patterns, called actons. Our approach first obtains a frame-wise representation by contrasting two augmented views of video frames conditioned on their temporal context. The frame-wise representations across a collection of videos are then clustered by K-means. Actons are then automatically extracted by forming a continuous motion sequence from frames within the same cluster. We evaluate the self-supervised representation by temporal alignment metrics, and the clustering results by normalized mutual information and language entropy. We also study an application of this tokenization by using it to classify dance genres. On AIST++ and PKU-MMD datasets, actons are shown to bring significant performance improvements compared to several baselines."}}
{"id": "JvGzKO1QLet", "cdate": 1632875425008, "mdate": null, "content": {"title": "Intervention-based Recurrent Casual Model for Non-stationary Video Causal Discovery", "abstract": "Non-stationary casual structures are prevalent in real-world physical systems. For example, the stacked blocks interacted with one another until they fall apart, while the billiard balls are moving independently until they collide. However, most video causal discovery methods can not discover such non-stationary casual structures due to the lack of modeling for the instantaneous change and the dynamics of the casual structure. In this work, we propose the Intervention-based Recurrent Casual Model (IRCM) for non-stationary video casual discovery. First, we extend the existing intervention-based casual discovery framework for videos to formulate the instantaneous change of the casual structure in a principled manner. Then, we use a recurrent model to sequentially predict the causal structure model based on previous observations to capture the non-stationary dynamic of the casual structure. We evaluate our method on two popular physical system simulation datasets with various types of multi-body interactions. Experimental results show that the proposed IRCM achieves the state-of-the-art performance on both the counterfactual reasoning and future forecasting tasks."}}
{"id": "_EY-xHFRKQd", "cdate": 1609459200000, "mdate": 1667341337776, "content": {"title": "Towards Tokenized Human Dynamics Representation", "abstract": "For human action understanding, a popular research direction is to analyze short video clips with unambiguous semantic content, such as jumping and drinking. However, methods for understanding short semantic actions cannot be directly translated to long human dynamics such as dancing, where it becomes challenging even to label the human movements semantically. Meanwhile, the natural language processing (NLP) community has made progress in solving a similar challenge of annotation scarcity by large-scale pre-training, which improves several downstream tasks with one model. In this work, we study how to segment and cluster videos into recurring temporal patterns in a self-supervised way, namely acton discovery, the main roadblock towards video tokenization. We propose a two-stage framework that first obtains a frame-wise representation by contrasting two augmented views of video frames conditioned on their temporal context. The frame-wise representations across a collection of videos are then clustered by K-means. Actons are then automatically extracted by forming a continuous motion sequence from frames within the same cluster. We evaluate the frame-wise representation learning step by Kendall's Tau and the lexicon building step by normalized mutual information and language entropy. We also study three applications of this tokenization: genre classification, action segmentation, and action composition. On the AIST++ and PKU-MMD datasets, actons bring significant performance improvements compared to several baselines."}}
