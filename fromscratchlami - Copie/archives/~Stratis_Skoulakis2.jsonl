{"id": "bbI9NtVd3-o", "cdate": 1672531200000, "mdate": 1682321038275, "content": {"title": "Min-Max Optimization Made Simple: Approximating the Proximal Point Method via Contraction Maps", "abstract": "In this paper we present a first-order method that admits near-optimal convergence rates for convex/concave min-max problems while requiring a simple and intuitive analysis. Similarly to the seminal work of Nemirovski [26] and the recent approach of Piliouras et al. [28] in normal form games, our work is based on the fact that the update rule of the Proximal Point method (PP) can be approximated up to accuracy \u03b5 with only O (log 1/\u03b5) additional gradient-calls through the iterations of a contraction map. Then combining the analysis of (PP) method with an error-propagation analysis we establish that the resulting first order method, called Clairvoyant Extra Gradient, admits near-optimal time-average convergence for general domains and last-iterate convergence in the unconstrained case."}}
{"id": "YGSfh0bCvFz", "cdate": 1672531200000, "mdate": 1682321038241, "content": {"title": "Min-Max Optimization Made Simple: Approximating the Proximal Point Method via Contraction Maps", "abstract": "In this paper we present a first-order method that admits near-optimal convergence rates for convex/concave min-max problems while requiring a simple and intuitive analysis. Similarly to the seminal work of Nemirovski and the recent approach of Piliouras et al. in normal form games, our work is based on the fact that the update rule of the Proximal Point method (PP) can be approximated up to accuracy $\\epsilon$ with only $O(\\log 1/\\epsilon)$ additional gradient-calls through the iterations of a contraction map. Then combining the analysis of (PP) method with an error-propagation analysis we establish that the resulting first order method, called Clairvoyant Extra Gradient, admits near-optimal time-average convergence for general domains and last-iterate convergence in the unconstrained case."}}
{"id": "6dZqGFB8g-O", "cdate": 1663850439383, "mdate": null, "content": {"title": "STay-On-the-Ridge (STON'R): Guaranteed Convergence to Local Minimax Equilibrium in Nonconvex-Nonconcave Games", "abstract": "Min-max optimization problems involving nonconvex-nonconcave objectives have found important applications in adversarial training and other multi-agent learning settings. Yet, no known gradient descent-based method is guaranteed to converge to (even local notions of) min-max equilibrium in the nonconvex-nonconcave setting. For all known methods, there exist relatively simple objectives for which they cycle or exhibit other undesirable behavior different from converging to a point, let alone to some game-theoretically meaningful one [Flokas et al. '19, Hsieh et al. '21]. The only known convergence guarantees hold under the strong assumption that the initialization is very close to a local min-max equilibrium [Wang et al. '19]. Moreover, the afore-described challenges are not just theoretical curiosities. All known methods are  unstable in practice, even in simple settings.\n  \nWe propose the first method that is guaranteed to converge to a local min-max equilibrium for smooth nonconvex-nonconcave objectives. Our method is second-order and provably escapes limit cycles as long as it is initialized at an easy-to-find initial point. Both the definition of our method and its convergence analysis are motivated by the topological nature of the problem. In particular, our method is not designed to decrease some potential function, such as the distance of its iterate from the set of local min-max equilibria or the projected gradient of the objective, but is designed to satisfy a topological property that guarantees the avoidance of cycles and implies its convergence. "}}
{"id": "k98U0cb0Ig", "cdate": 1652737762618, "mdate": null, "content": {"title": "Adaptive Stochastic Variance Reduction for Non-convex Finite-Sum Minimization", "abstract": "We propose an adaptive variance-reduction method, called AdaSpider, for minimization of $L$-smooth, non-convex functions with a finite-sum structure. In essence, AdaSpider combines an AdaGrad-inspired (Duchi et al., 2011), but a fairly distinct, adaptive step-size schedule with the recursive \\textit{stochastic path integrated estimator} proposed in (Fang et al., 2018). To our knowledge, AdaSpider is the first parameter-free non-convex variance-reduction method in the sense that it does not require the knowledge of problem-dependent parameters, such as smoothness constant $L$, target accuracy $\\epsilon$ or any bound on gradient norms. In doing so, we are able to compute an $\\epsilon$-stationary point with $\\tilde{O}\\left(n + \\sqrt{n}/\\epsilon^2\\right)$ oracle-calls, which matches the respective lower bound up to logarithmic factors."}}
{"id": "suplyBhTDjC", "cdate": 1652737545171, "mdate": null, "content": {"title": "Beyond Time-Average Convergence: Near-Optimal Uncoupled Online Learning via Clairvoyant Multiplicative Weights Update", "abstract": "In this paper we provide a novel and simple algorithm, Clairvoyant Multiplicative Weights Updates (CMWU), for convergence to \\textit{Coarse Correlated Equilibria} (CCE) in general games. CMWU effectively corresponds to the standard MWU algorithm but where all agents, when updating their mixed strategies, use the payoff profiles based on tomorrow's behavior, i.e. the agents are clairvoyant. CMWU achieves constant regret of $\\ln(m)/\\eta$ in all normal-form games with m actions and fixed step-sizes $\\eta$. Although CMWU encodes in its definition a fixed point computation, which in principle could result in dynamics that are neither computationally efficient nor uncoupled, we show that both of these issues can be largely circumvented. Specifically, as long as the step-size $\\eta$ is upper bounded by $\\frac{1}{(n-1)V}$, where $n$ is the number of agents and $[0,V]$ is the payoff range, then the CMWU updates can be computed linearly fast via a contraction map. This implementation results in an uncoupled online learning dynamic that admits a $O(\\log T)$-sparse sub-sequence where each agent experiences at most $O(nV\\log m)$ regret. This implies that the CMWU dynamics converge with rate $O(nV \\log m \\log T / T)$ to a CCE and improves on the current state-of-the-art convergence rate. "}}
{"id": "yEUgnVT2BW", "cdate": 1640995200000, "mdate": 1682321038308, "content": {"title": "Fast Convergence of Optimistic Gradient Ascent in Network Zero-Sum Extensive Form Games", "abstract": "The study of learning in games has thus far focused primarily on normal form games. In contrast, our understanding of learning in extensive form games (EFGs) and particularly in EFGs with many agents lags far behind, despite them being closer in nature to many real world applications. We consider the natural class of Network Zero-Sum Extensive Form Games, which combines the global zero-sum property of agent payoffs, the efficient representation of graphical games as well the expressive power of EFGs. We examine the convergence properties of Optimistic Gradient Ascent (OGA) in these games. We prove that the time-average behavior of such online learning dynamics exhibits $O(1/T)$ rate convergence to the set of Nash Equilibria. Moreover, we show that the day-to-day behavior also converges to Nash with rate $O(c^{-t})$ for some game-dependent constant $c>0$."}}
{"id": "xOAy73x0dh", "cdate": 1640995200000, "mdate": 1681146880810, "content": {"title": "STay-ON-the-Ridge: Guaranteed Convergence to Local Minimax Equilibrium in Nonconvex-Nonconcave Games", "abstract": ""}}
{"id": "agKdNqT1d8", "cdate": 1640995200000, "mdate": 1682321038255, "content": {"title": "Fast Convergence of Optimistic Gradient Ascent in Network Zero-Sum Extensive Form Games", "abstract": "The study of learning in games has thus far focused primarily on normal form games. In contrast, our understanding of learning in extensive form games (EFGs) and particularly in EFGs with many agents lags behind, despite them being closer in nature to many real world applications. We consider the natural class of Network Zero-Sum Extensive Form Games, which combines the global zero-sum property of agent payoffs, the efficient representation of graphical games as well the expressive power of EFGs. We examine the convergence properties of Optimistic Gradient Ascent (OGA) in these games. We prove that the time-average behavior of such online learning dynamics exhibits O(1/T) rate of convergence to the set of Nash Equilibria. Moreover, we show that the day-to-day behavior also converges to a Nash with rate $$O(c^{-t})$$ for some game-dependent constant $$c>0$$ ."}}
{"id": "_ieMo4Xf4TT", "cdate": 1640995200000, "mdate": 1682321038239, "content": {"title": "Adaptive Stochastic Variance Reduction for Non-convex Finite-Sum Minimization", "abstract": "We propose an adaptive variance-reduction method, called AdaSpider, for minimization of $L$-smooth, non-convex functions with a finite-sum structure. In essence, AdaSpider combines an AdaGrad-inspired [Duchi et al., 2011, McMahan & Streeter, 2010], but a fairly distinct, adaptive step-size schedule with the recursive stochastic path integrated estimator proposed in [Fang et al., 2018]. To our knowledge, Adaspider is the first parameter-free non-convex variance-reduction method in the sense that it does not require the knowledge of problem-dependent parameters, such as smoothness constant $L$, target accuracy $\\epsilon$ or any bound on gradient norms. In doing so, we are able to compute an $\\epsilon$-stationary point with $\\tilde{O}\\left(n + \\sqrt{n}/\\epsilon^2\\right)$ oracle-calls, which matches the respective lower bound up to logarithmic factors."}}
{"id": "o-jyQsbTy35", "cdate": 1609459200000, "mdate": 1664346296028, "content": {"title": "Estimating the Number of Induced Subgraphs from Incomplete Data and Neighborhood Queries", "abstract": "We consider a natural setting where network parameters are estimated from noisy and incomplete information about the network. More specifically, we investigate how we can efficiently estimate the number of small subgraphs (e.g., edges, triangles, etc.) based on full access to one or two noisy and incomplete samples of a large underlying network and on few queries revealing the neighborhood of carefully selected vertices. After specifying a random generator which removes edges from the underlying graph, we present estimators with strong provable performance guarantees, which exploit information from the noisy network samples and query a constant number of the most important vertices for the estimation. Our experimental evaluation shows that, in practice, a single noisy network sample and a couple of hundreds neighborhood queries suffice for accurately estimating the number of triangles in networks with millions of vertices and edges."}}
