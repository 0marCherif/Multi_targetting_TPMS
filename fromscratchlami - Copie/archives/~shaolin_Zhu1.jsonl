{"id": "v1L_ELmiVku", "cdate": 1609459200000, "mdate": 1636944731280, "content": {"title": "Parallel sentences mining with transfer learning in an unsupervised setting", "abstract": "Yu Sun, Shaolin Zhu, Feng Yifan, Chenggang Mi. Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Student Research Workshop. 2021."}}
{"id": "Hp2yDMQ3FFM", "cdate": 1609459200000, "mdate": 1636944730083, "content": {"title": "An Explainable Evaluation of Unsupervised Transfer Learning for Parallel Sentences Mining", "abstract": "The parallel sentences are known as very important resources for training cross-lingual natural language process applications, such as machine translation (MT) systems. However, these resources are not available for many low-resource language pairs. Existing methods mined parallel sentences using transfer learning. Although several attempts can get a good performance, they are not able to explain why transfer learning can help mining parallel sentences for low-resource language pairs. In this paper, we propose an explainable evaluation to quantity why transfer learning is useful for parallel sentence mining. Besides, we propose a novel unsupervised transfer learning that can maintain the robustness of transfer learning. Experiments show that our proposed method improves the performance of mined parallel sentences compared with previous methods in a standard evaluation set. In particular, we achieve good results at two real-world low-resource language pairs."}}
{"id": "GXu2u68epa", "cdate": 1609459200000, "mdate": 1636944731232, "content": {"title": "Improving Loanword Identification in Low-Resource Language with Data Augmentation and Multiple Feature Fusion", "abstract": "Loanword identification is studied in recent years to alleviate data sparseness in several natural language processing (NLP) tasks, such as machine translation, cross-lingual information retrieval, and so on. However, recent studies on this topic usually put efforts on high-resource languages (such as Chinese, English, and Russian); for low-resource languages, such as Uyghur and Mongolian, due to the limitation of resources and lack of annotated data, loanword identification on these languages tends to have lower performance. To overcome this problem, we first propose a lexical constraint-based data augmentation method to generate training data for low-resource language loanword identification; then, a loanword identification model based on a log-linear RNN is introduced to improve the performance of low-resource loanword identification by incorporating features such as word-level embeddings, character-level embeddings, pronunciation similarity, and part-of-speech (POS) into one model. Experimental results on loanword identification in Uyghur (in this study, we mainly focus on Arabic, Chinese, Russian, and Turkish loanwords in Uyghur) showed that our proposed method achieves best performance compared with several strong baseline systems."}}
{"id": "6VKiX3kJRB", "cdate": 1609459200000, "mdate": 1636944730648, "content": {"title": "Inducing Bilingual Word Representations for Non-isomorphic Spaces by an Unsupervised Way", "abstract": "Bilingual word representations (BWRs) play a very key role in many natural language processing (NLP) tasks, especially cross-lingual applications such as machine translation and cross-lingual information retrieval et al. Most existing methods are based on offline unsupervised methods to learn BWRs. Those offline methods mainly rely on the isomorphic assumption that word representations have a similar distribution for different languages. Several authors also question this assumption and argue that word representation spaces are non-isomorphic for many language pairs. In this paper, we adopt a novel unsupervised method to implement joint training BWRs. We first use a dynamic programming algorithm to detect continuous bilingual segments. Then, we use the extracted bilingual data and monolingual corpora to train BWRs jointly. Experiments show that our approach improves the performance of BWRs compared with several baselines in the real-world dataset.(By unsupervised, we mean that no cross-lingual resources like parallel text or bilingual lexicons are directly used.)"}}
{"id": "thNm7Ud9I3D", "cdate": 1483228800000, "mdate": 1636944730716, "content": {"title": "Domain adaption based on lda and word embedding in SMT", "abstract": "Current methods about domain adaption in SMT mostly assume that a small in-domain sample is need at training time. However, the fact target domain may not be known at training time so that it may not satisfy the fact translation or is far away from user needs. We instead propose a more suitable method to avoid this situation. Our methods mainly contain two sections (1) Firstly, we use word embedding and LDA model to divide the training corpus into some similar semantic subdomains. (2) Secondly, for an actual source sentences we can select a more suitable translation system by semantic clues. We implement experiments on two language pairs. We can observe consistent improvements over three baselines."}}
{"id": "gSUbtxS3Im", "cdate": 1483228800000, "mdate": 1636944730010, "content": {"title": "Learning Bilingual Lexicon for Low-Resource Language Pairs", "abstract": "Learning bilingual lexicon from monolingual data is a novel idea in natural language process which can benefit many low-resource language pairs. In this paper, we present an approach for obtaining bilingual lexicon from monolingual data. Our method only requires a small seed bilingual lexicon and we use the Canonical Correlation Analysis to construct a shared latent space to explain two monolingual embeddings how to be linked. Experimental results show that a considerable precision and size bilingual lexicon can be learned in Chinese-Uyghur and Chinese-Kazakh monolingual data."}}
{"id": "41e7_qBM_K", "cdate": 1483228800000, "mdate": 1636944730408, "content": {"title": "Harvest Uyghur-Chinese Aligned-Sentences Bitexts from Multilingual Sites Based on Word Embedding", "abstract": "Obtaining bilingual parallel data from the multilingual websites is a long-standing research problem, which is very benefit for resource-scarce languages. In this paper, we present an approach for obtaining parallel data based on word embedding, and our model only rely on a small scale of bilingual lexicon. Our approach benefit from the recent advances of continuous word representations, which can reveal more context information compared with traditional methods. Our experiments show that high-precision and sizable parallel Uyghur-Chinese data can be obtained for lacking bilingual lexicon."}}
