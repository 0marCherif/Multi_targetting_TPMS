{"id": "AfeeU77SUx", "cdate": 1632875453806, "mdate": null, "content": {"title": "Learning with Few-Shot Complementary Labels", "abstract": "Complementary-label (CL) learning deals with the weak supervision scenario where each training instance is associated with one complementary label, which specifies the class label that the instance does not belong to. Since these CL algorithms rely on the assumption of a large amount of labeled/unlabeled training data, they cannot be applied in few-shot scenarios and perform well. To bridge the gap, we propose a Few-shot Complementary-Label (FsCL) training pattern with three kinds of surrogate loss, which is based on the Model-Agnostic Meta-Learning (MAML) and bilevel optimization. FsCL firstly modifies the inductive bias of the  meta-learner apart from the misleading of complementary label and insufficient sample diversity in the outer loop. Next, the inner loop is used to solve the target FsCL classification problem with base learner initialized from meta-learner. Accordingly, an unseen example can be precisely classified via the maximize probability output of base learner. We demonstrate the effectiveness of our approach in an extensive empirical study and theoretical analysis."}}
