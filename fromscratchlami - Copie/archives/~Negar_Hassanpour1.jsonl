{"id": "TVbDOOr6hL", "cdate": 1601308143764, "mdate": null, "content": {"title": "Variational Auto-Encoder Architectures that Excel at Causal Inference", "abstract": "This paper provides a generative approach for causal inference using data from observational studies. Inspired by the work of Kingma et al. (2014), we propose a sequence of three architectures (namely Series, Parallel, and Hybrid) that each incorporate their M1 and M2 models as building blocks. Each architecture is an improvement over the previous one in terms of estimating causal effect, culminating in the Hybrid model. The Hybrid model is designed to encourage decomposing the underlying factors of any observational dataset; this in turn, helps to accurately estimate all treatment outcomes. Our empirical results demonstrate the superiority of all three proposed architectures compared to both state-of-the-art discriminative as well as other generative approaches in the literature. "}}
{"id": "lxLEWmEq_c", "cdate": 1591575997962, "mdate": null, "content": {"title": "Variational Auto-Encoder for Causal Inference", "abstract": "This paper provides a generative approach for causal inference in observational studies. Inspired by the semi-supervised Variational Auto-Encoder (VAE), we propose a novel double-stacked M2 architecture with $\\beta$-VAE components that encourage learning disentangled representations. Our empirical results demonstrate the superiority of the proposed method compared to both state-of-the-art discriminative as well as generative approaches in the literature. \n"}}
{"id": "HkxBJT4YvB", "cdate": 1569438940967, "mdate": null, "content": {"title": "Learning Disentangled Representations for CounterFactual Regression", "abstract": "We consider the challenge of estimating treatment effects from observational data; and point out that, in general, only some factors based on the observed covariates X contribute to selection of the treatment T, and only some to determining the outcomes Y. We model this by considering three underlying sources of {X, T, Y} and show that explicitly modeling these sources offers great insight to guide designing models that better handle selection bias. This paper is an attempt to conceptualize this line of thought and provide a path to explore it further.\nIn this work, we propose an algorithm to (1) identify disentangled representations of the above-mentioned underlying factors from any given observational dataset D and (2) leverage this knowledge to reduce, as well as account for, the negative impact of selection bias on estimating the treatment effects from D. Our empirical results show that the proposed method achieves state-of-the-art performance in both individual and population based evaluation measures."}}
{"id": "Byx04g2uPr", "cdate": 1569402933538, "mdate": null, "content": {"title": "CounterFactual Regression with Importance Sampling Weights", "abstract": "Perhaps the most pressing concern of a patient diagnosed with cancer is her life expectancy under various treatment options. For a binary-treatment case, this translates into estimating the difference between the outcomes (e.g., survival time) of the two available treatment options \u2013 i.e., her Individual Treatment Effect (ITE). This is especially challenging to estimate from observational data, as that data has selection bias: the treatment assigned to a patient depends on that patient's attributes. In this work, we borrow ideas from domain adaptation to address the distributional shift between the source (outcome of the administered treatment, appearing in the observed training data) and target (outcome of the alternative treatment) that exists due to selection bias. We propose a context-aware importance sampling re-weighing scheme, built on top of a representation learning module, for estimating ITEs. Empirical results on two publicly available benchmarks demonstrate that the proposed method significantly outperforms state-of-the-art."}}
