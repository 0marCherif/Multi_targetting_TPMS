{"id": "-AzinNJt_8", "cdate": 1699750574874, "mdate": 1699750574874, "content": {"title": "Weakly Supervised Segmentation With Point Annotations for Histopathology Images via Contrast-Based Variational Model", "abstract": "Image segmentation is a fundamental task in the field of imaging and vision. Supervised deep learning for segmentation has achieved unparalleled success when sufficient training data with annotated labels are available. However, annotation is known to be expensive to obtain, especially for histopathology images where the target regions are usually with high morphology variations and irregular shapes. Thus, weakly supervised learning with sparse annotations of points is promising to reduce the annotation workload. In this work, we propose a contrast-based variational model to generate segmentation results, which serve as reliable complementary supervision to train a deep segmentation model for histopathology images. The proposed method considers the common characteristics of target regions in histopathology images and can be trained in an end-to-end manner. It can generate more regionally consistent and smoother boundary segmentation, and is more robust to unlabeled 'novel' regions. Experiments on two different histology datasets demonstrate its effectiveness and efficiency in comparison to previous models. Code is available at: https://github.com/hrzhang1123/CVM_WS_Segmentation."}}
{"id": "Yg4YsbtnDj", "cdate": 1667336708256, "mdate": null, "content": {"title": "FCNN: Fourier convolutional neural networks", "abstract": "The Fourier domain is used in computer vision and machine learning as image analysis tasks in the Fourier domain are analogous to spatial domain methods but are achieved using different operations. Convolutional Neural Networks (CNNs) use machine learning to achieve state-of-the-art results with respect to many computer vision tasks. One of the main limiting aspects of CNNs is the computational cost of updating a large number of convolution parameters. Further, in the spatial domain, larger images take exponentially longer than smaller image to train on CNNs due to the operations involved in convolution methods. Consequently, CNNs are often not a viable solution for large image computer vision tasks. In this paper a Fourier Convolution Neural Network (FCNN) is proposed whereby training is conducted entirely within the Fourier domain. The advantage offered is that there is a significant speed up in training time without loss of effectiveness. Using the proposed approach larger images can therefore be processed within viable computation time. The FCNN is fully described and evaluated. The evaluation was conducted using the benchmark Cifar10 and MNIST datasets, and a bespoke fundus retina image dataset. The results demonstrate that convolution in the Fourier domain gives a significant speed up without adversely affecting accuracy. For simplicity the proposed FCNN concept is presented in the context of a basic CNN architecture, however, the FCNN concept has the potential to improve the speed of any neural network system involving convolution."}}
{"id": "rvjtHvffsP", "cdate": 1667336625902, "mdate": 1667336625902, "content": {"title": "An artificial intelligence-based deep learning algorithm for the diagnosis of diabetic neuropathy using corneal confocal microscopy: a development and validation study", "abstract": "Corneal confocal microscopy is a rapid non-invasive ophthalmic imaging technique that identifies peripheral and central neurodegenerative disease. Quantification of corneal sub-basal nerve plexus morphology, however, requires either time-consuming manual annotation or a less-sensitive automated image analysis approach. We aimed to develop and validate an artificial intelligence-based, deep learning algorithm for the quantification of nerve fibre properties relevant to the diagnosis of diabetic neuropathy and to compare it with a validated automated analysis program, ACCMetrics."}}
{"id": "mH3lVQDx8A", "cdate": 1667336137627, "mdate": 1667336137627, "content": {"title": "Dense Fully Convolutional Segmentation of the Optic Disc and Cup in Colour Fundus for Glaucoma Diagnosis", "abstract": "Glaucoma is a group of eye diseases which can cause vision loss by damaging the optic nerve. Early glaucoma detection is key to preventing vision loss yet there is a lack of noticeable early symptoms. Colour fundus photography allows the optic disc (OD) to be examined to diagnose glaucoma. Typically, this is done by measuring the vertical cup-to-disc ratio (CDR); however, glaucoma is characterised by thinning of the rim asymmetrically in the inferior-superior-temporal-nasal regions in increasing order. Automatic delineation of the OD features has potential to improve glaucoma management by allowing for this asymmetry to be considered in the measurements. Here, we propose a new deep-learning-based method to segment the OD and optic cup (OC). The core of the proposed method is DenseNet with a fully-convolutional network, whose symmetric U-shaped architecture allows pixel-wise classification. The predicted OD and OC boundaries are then used to estimate the CDR on two axes for glaucoma diagnosis. We assess the proposed method\u2019s performance using a large retinal colour fundus dataset, outperforming state-of-the-art segmentation methods. Furthermore, we generalise our method to segment four fundus datasets from different devices without further training, outperforming the state-of-the-art on two and achieving comparable results on the remaining two."}}
{"id": "kwEG-ZxhYtl", "cdate": 1640995200000, "mdate": 1668005683972, "content": {"title": "Shape-Aware Weakly/Semi-Supervised Optic Disc and Cup Segmentation with Regional/Marginal Consistency", "abstract": "Glaucoma is a chronic eye disease that permanently impairs vision. Vertical cup to disc ratio (vCDR) is essential for glaucoma screening. Thus, accurately segmenting the optic disc (OD) and optic cup (OC) from colour fundus images is essential. Previous fully-supervised methods achieved accurate segmentation results; then, they calculated the vCDR with offline post-processing step. However, a large set of labeled segmentation images are required for the training, which is costly and time-consuming. To solve this, we propose a weakly/semi-supervised framework with the benefits of geometric associations and specific domain knowledge between pixel-wise segmentation probability map (PM), geometry-aware modified signed distance function representations (mSDF), and local boundary region of interest characteristics (B-ROI). Firstly, we propose a dual consistency regularisation based semi-supervised paradigm, where the regional and marginal consistency benefits the proposed model from the objects\u2019 inherent region and boundary coherence of a large amount of unlabeled data. Secondly, for the first time, we exploit the domain-specific knowledge between the boundary and region in terms of the perimeter and area of an oval shape of OD & OC, where a differentiable vCDR estimating module is proposed for the end-to-end training. Thus, our model does not need any offline post-process to generate vCDR. Furthermore, without requiring any additional laborious annotations, the supervision on vCDR can serve as a weakly-supervision for OD & OC region and boundary segmentation. Experiments on six large-scale datasets demonstrate that our method outperforms state-of-the-art semi-supervised approaches for segmentation of the optic disc and optic cup, and estimation of vCDR for glaucoma assessment in colour fundus images, respectively. The implementation code is made available. ( https://github.com/smallmax00/Share_aware_Weakly-Semi_ODOC_seg )"}}
{"id": "_I_CU6Trahf", "cdate": 1640995200000, "mdate": 1668005684065, "content": {"title": "DTFD-MIL: Double-Tier Feature Distillation Multiple Instance Learning for Histopathology Whole Slide Image Classification", "abstract": "Multiple instance learning (MIL) has been increasingly used in the classification of histopathology whole slide images (WSIs). However, MIL approaches for this specific classification problem still face unique challenges, particularly those related to small sample cohorts. In these, there are limited number of WSI slides (bags), while the resolution of a single WSI is huge, which leads to a large number of patches (instances) cropped from this slide. To address this issue, we propose to virtually enlarge the number of bags by introducing the concept of pseudo-bags, on which a double-tier MIL framework is built to effectively use the intrinsic features. Besides, we also contribute to deriving the instance probability under the framework of attentionbased MIL, and utilize the derivation to help construct and analyze the proposed framework. The proposed method outperforms other latest methods on the CAMELYON-16 by substantially large margins, and is also better in performance on the TCGA lung cancer dataset. The proposed framework is ready to be extended for wider MIL applications. The code is available at: https://github. com/hrzhang1123/DTFD-MIL."}}
{"id": "VPMPmUokqYZ", "cdate": 1640995200000, "mdate": 1668005684005, "content": {"title": "Counting with Adaptive Auxiliary Learning", "abstract": "This paper proposes an adaptive auxiliary task learning based approach for object counting problems. Unlike existing auxiliary task learning based methods, we develop an attention-enhanced adaptively shared backbone network to enable both task-shared and task-tailored features learning in an end-to-end manner. The network seamlessly combines standard Convolution Neural Network (CNN) and Graph Convolution Network (GCN) for feature extraction and feature reasoning among different domains of tasks. Our approach gains enriched contextual information by iteratively and hierarchically fusing the features across different task branches of the adaptive CNN backbone. The whole framework pays special attention to the objects' spatial locations and varied density levels, informed by object (or crowd) segmentation and density level segmentation auxiliary tasks. In particular, thanks to the proposed dilated contrastive density loss function, our network benefits from individual and regional context supervision in terms of pixel-independent and pixel-dependent feature learning mechanisms, along with strengthened robustness. Experiments on seven challenging multi-domain datasets demonstrate that our method achieves superior performance to the state-of-the-art auxiliary task learning based counting methods. Our code is made publicly available at: https://github.com/smallmax00/Counting_With_Adaptive_Auxiliary"}}
{"id": "LCwdYwX03Sr", "cdate": 1640995200000, "mdate": 1668005684006, "content": {"title": "3D Dense Face Alignment with Fused Features by Aggregating CNNs and GCNs", "abstract": "In this paper, we propose a novel multi-level aggregation network to regress the coordinates of the vertices of a 3D face from a single 2D image in an end-to-end manner. This is achieved by seamlessly combining standard convolutional neural networks (CNNs) with Graph Convolution Networks (GCNs). By iteratively and hierarchically fusing the features across different layers and stages of the CNNs and GCNs, our approach can provide a dense face alignment and 3D face reconstruction simultaneously for the benefit of direct feature learning of 3D face mesh. Experiments on several challenging datasets demonstrate that our method outperforms state-of-the-art approaches on both 2D and 3D face alignment tasks."}}
{"id": "KiogA4Yol_f", "cdate": 1640995200000, "mdate": 1668005683982, "content": {"title": "NerveFormer: A Cross-Sample Aggregation Network for Corneal Nerve Segmentation", "abstract": "The segmentation of corneal nerves in corneal confocal microscopy (CCM) is of great  to the quantification of clinical parameters in the diagnosis of eye-related diseases and systematic diseases. Existing works mainly use convolutional neural networks to improve the segmentation accuracy, while further improvement is needed to mitigate the nerve discontinuity and noise interference. In this paper, we propose a novel corneal nerve segmentation network, named NerveFormer, to resolve the above-mentioned limitations. The proposed NerveFormer includes a Deformable and External Attention Module (DEAM), which exploits the Transformer-based Deformable Attention (TDA) and External Attention (TEA) mechanisms. TDA is introduced to explore the local internal nerve features in a single CCM, while TEA is proposed to model global external nerve features across different CCM images. Specifically, to efficiently fuse the internal and external nerve features, TDA obtains the query set required by TEA, thereby strengthening the characterization ability of TEA. Therefore, the proposed model aggregates the learned features from both single-sample and cross-sample, allowing for better extraction of corneal nerve features across the whole dataset. Experimental results on two public CCM datasets show that our proposed method achieves state-of-the-art performance, especially in terms of segmentation continuity and noise discrimination."}}
{"id": "FfdoGsoLPq", "cdate": 1640995200000, "mdate": 1668005683996, "content": {"title": "Machine learning-based predictions of dietary restriction associations across ageing-related genes", "abstract": "Background Dietary restriction (DR) is the most studied pro-longevity intervention; however, a complete understanding of its underlying mechanisms remains elusive, and new research directions may emerge from the identification of novel DR-related genes and DR-related genetic features. Results This work used a Machine Learning (ML) approach to classify ageing-related genes as DR-related or NotDR-related using 9 different types of predictive features: PathDIP pathways, two types of features based on KEGG pathways, two types of Protein\u2013Protein Interactions (PPI) features, Gene Ontology (GO) terms, Genotype Tissue Expression (GTEx) expression features, GeneFriends co-expression features and protein sequence descriptors. Our findings suggested that features biased towards curated knowledge (i.e. GO terms and biological pathways), had the greatest predictive power, while unbiased features (mainly gene expression and co-expression data) have the least predictive power. Moreover, a combination of all the feature types diminished the predictive power compared to predictions based on curated knowledge. Feature importance analysis on the two most predictive classifiers mostly corroborated existing knowledge and supported recent findings linking DR to the Nuclear Factor Erythroid 2-Related Factor 2 (NRF2) signalling pathway and G protein-coupled receptors (GPCR). We then used the two strongest combinations of feature type and ML algorithm to predict DR-relatedness among ageing-related genes currently lacking DR-related annotations in the data, resulting in a set of promising candidate DR-related genes (GOT2, GOT1, TSC1, CTH, GCLM, IRS2 and SESN2) whose predicted DR-relatedness remain to be validated in future wet-lab experiments. Conclusions This work demonstrated the strong potential of ML-based techniques to identify DR-associated features as our findings are consistent with literature and recent discoveries. Although the inference of new DR-related mechanistic findings based solely on GO terms and biological pathways was limited due to their knowledge-driven nature, the predictive power of these two features types remained useful as it allowed inferring new promising candidate DR-related genes."}}
