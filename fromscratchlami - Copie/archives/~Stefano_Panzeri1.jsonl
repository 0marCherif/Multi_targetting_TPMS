{"id": "BxXf9rahTP", "cdate": 1683904185134, "mdate": 1683904185134, "content": {"title": "Learning to focus on number", "abstract": "With age and education, children become increasingly accurate in processing numerosity. This developmental trend is often interpreted as a progressive refinement of the mental representation of number. Here we provide empirical and theoretical support for an alternative possibility, the filtering hypothesis, which proposes that development primarily affects the ability to focus on the relevant dimension of number and to avoid interference from irrelevant but often co-varying quantitative dimensions. Data from the same numerical comparison task in adults and children of various levels of numeracy, including Munduruc\u00fa Indians and western dyscalculics, show that, as predicted by the filtering hypothesis, age and education primarily increase the ability to focus on number and filter out potentially interfering information on the non-numerical dimensions. These findings can be captured by a minimal computational model where learning consists in the training of a multivariate classifier whose discrimination boundaries get progressively aligned to the task-relevant dimension of number. This view of development has important consequences for education."}}
{"id": "U4BFFvgngN", "cdate": 1669852800000, "mdate": 1683966771535, "content": {"title": "Population coding strategies in human tactile afferents", "abstract": "Author summary Touching an object elicits neural responses from hundreds or thousands of individual tactile receptors of different classes embedded within our hand. Information about the extent of contact, the strength of the touch, and its temporal profile are carried jointly in this population response to be processed further by the central nervous system. However, studying the nature of the population code is empirically challenging, as electrophysiological recordings are typically obtained from single or a small number of neurons at most. Here, we make use of a computer simulation to recreate the population activity of large numbers of tactile neurons and examine how information is spread across different neurons. We find that tactile information increases with afferent density, but the saturation point depends on both the tactile feature and afferent class. Importantly, information is generally spread across multiple afferent classes, such that a combination of afferents from multiple classes yields higher information than the same number of neurons from a single class. These results will be useful to guide future experiments and theoretical work on the processing of tactile information by the central nervous system."}}
{"id": "zdmYnIRXvKS", "cdate": 1652737815705, "mdate": null, "content": {"title": "Biologically plausible solutions for spiking networks with efficient coding", "abstract": "Understanding how the dynamics of neural networks is shaped by the computations they perform is a fundamental question in neuroscience. \nRecently, the framework of efficient coding proposed a theory of how spiking neural networks can compute low-dimensional stimulus signals with high efficiency. Efficient spiking networks are based on time-dependent minimization of a loss function related to information coding with spikes. To inform the understanding of the function and dynamics of biological networks in the brain, however, the mathematical models have to be informed by biology and obey the same constraints as biological networks. Currently, spiking network models of efficient coding have been extended to include some features of biological plausibility, such as architectures with excitatory and inhibitory neurons. However, biological realism of efficient coding theories is still limited to simple cases and does not include  single neuron and network properties that are known to be key in biological circuits. Here, we revisit the theory of efficient coding with spikes to  develop spiking neural networks that are closer to biological circuits. Namely, we find a biologically plausible spiking model realizing efficient coding in the case of a generalized leaky integrate-and-fire network with excitatory and inhibitory units, equipped with fast and slow synaptic currents, local homeostatic currents such as spike-triggered adaptation, hyperpolarization-activated rebound current, heterogeneous firing thresholds and resets, heterogeneous postsynaptic potentials, and structured, low-rank connectivity. We show how the rank of E-E connectivity matrix shapes network responses."}}
{"id": "smqe9598Tm", "cdate": 1640995200000, "mdate": 1683880158070, "content": {"title": "Inferring the temporal evolution of synaptic weights from dynamic functional connectivity", "abstract": "How to capture the temporal evolution of synaptic weights from measures of dynamic functional connectivity between the activity of different simultaneously recorded neurons is an important and open problem in systems neuroscience. Here, we report methodological progress to address this issue. We first simulated recurrent neural network models of spiking neurons with spike timing-dependent plasticity mechanisms that generate time-varying synaptic and functional coupling. We then used these simulations to test analytical approaches that infer fixed and time-varying properties of synaptic connectivity from directed functional connectivity measures, such as cross-covariance and transfer entropy. We found that, while both cross-covariance and transfer entropy provide robust estimates of which synapses are present in the network and their communication delays, dynamic functional connectivity measured via cross-covariance better captures the evolution of synaptic weights over time. We also established how measures of information transmission delays from static functional connectivity computed over long recording periods (i.e., several hours) can improve shorter time-scale estimates of the temporal evolution of synaptic weights from dynamic functional connectivity. These results provide useful information about how to accurately estimate the temporal variation of synaptic strength from spiking activity measures."}}
{"id": "pMjxAxoL2u1", "cdate": 1640995200000, "mdate": 1683966771518, "content": {"title": "Biologically plausible solutions for spiking networks with efficient coding", "abstract": "Understanding how the dynamics of neural networks is shaped by the computations they perform is a fundamental question in neuroscience. Recently, the framework of efficient coding proposed a theory of how spiking neural networks can compute low-dimensional stimulus signals with high efficiency. Efficient spiking networks are based on time-dependent minimization of a loss function related to information coding with spikes. To inform the understanding of the function and dynamics of biological networks in the brain, however, the mathematical models have to be informed by biology and obey the same constraints as biological networks. Currently, spiking network models of efficient coding have been extended to include some features of biological plausibility, such as architectures with excitatory and inhibitory neurons. However, biological realism of efficient coding theories is still limited to simple cases and does not include single neuron and network properties that are known to be key in biological circuits. Here, we revisit the theory of efficient coding with spikes to develop spiking neural networks that are closer to biological circuits. Namely, we find a biologically plausible spiking model realizing efficient coding in the case of a generalized leaky integrate-and-fire network with excitatory and inhibitory units, equipped with fast and slow synaptic currents, local homeostatic currents such as spike-triggered adaptation, hyperpolarization-activated rebound current, heterogeneous firing thresholds and resets, heterogeneous postsynaptic potentials, and structured, low-rank connectivity. We show how the rank of E-E connectivity matrix shapes network responses."}}
{"id": "nttlriasiCA", "cdate": 1640995200000, "mdate": 1683966771519, "content": {"title": "Optimizing Measures of Information Encoding in Astrocytic Calcium Signals", "abstract": "While most models of brain information encoding focus on neurons, recent studies have shown that calcium dynamics of astrocytes, the major class of non-neural cells in the brain, can add information about key cognitive variables that is not found in the activity of nearby neurons. This raises the question of what could be the contribution of astrocytes in information processing, and calls for analysis tools to characterize this contribution. Here we construct simulations with realistic dependencies of astrocytic activity on external variables and we use these simulations to understand how to optimally set parameters of information theoretic analysis of astrocytic activities. Applications of our techniques to simulated and real astrocytic data show how to set parameters of information analyses that provide conservative, yet reliable, estimates of astrocytic calcium dynamics contribution to circuit-level brain information processing."}}
{"id": "lxgZN-68rKD", "cdate": 1640995200000, "mdate": 1683966771604, "content": {"title": "Constraints on the design of neuromorphic circuits set by the properties of neural population codes", "abstract": "In the brain, information is encoded, transmitted and used to inform behaviour at the level of timing of action potentials distributed over population of neurons. To implement neural-like systems in silico, to emulate neural function, and to interface successfully with the brain, neuromorphic circuits need to encode information in a way compatible to that used by populations of neuron in the brain. To facilitate the cross-talk between neuromorphic engineering and neuroscience, in this Review we first critically examine and summarize emerging recent findings about how population of neurons encode and transmit information. We examine the effects on encoding and readout of information for different features of neural population activity, namely the sparseness of neural representations, the heterogeneity of neural properties, the correlations among neurons, and the time scales (from short to long) at which neurons encode information and maintain it consistently over time. Finally, we critically elaborate on how these facts constrain the design of information coding in neuromorphic circuits. We focus primarily on the implications for designing neuromorphic circuits that communicate with the brain, as in this case it is essential that artificial and biological neurons use compatible neural codes. However, we also discuss implications for the design of neuromorphic systems for implementation or emulation of neural computation."}}
{"id": "XRl1UO5x1Al", "cdate": 1640995200000, "mdate": 1683966771539, "content": {"title": "SmaRT2P: a software for generating and processing smart line recording trajectories for population two-photon calcium imaging", "abstract": "Two-photon fluorescence calcium imaging allows recording the activity of large neural populations with subcellular spatial resolution, but it is typically characterized by low signal-to-noise ratio (SNR) and poor accuracy in detecting single or few action potentials when large number of neurons are imaged. We recently showed that implementing a smart line scanning approach using trajectories that optimally sample the regions of interest increases both the SNR fluorescence signals and the accuracy of single spike detection in population imaging in vivo. However, smart line scanning requires highly specialised software to design recording trajectories, interface with acquisition hardware, and efficiently process acquired data. Furthermore, smart line scanning needs optimized strategies to cope with movement artefacts and neuropil contamination. Here, we develop and validate SmaRT2P, an open-source, user-friendly and easy-to-interface Matlab-based software environment to perform optimized smart line scanning in two-photon calcium imaging experiments. SmaRT2P is designed to interface with popular acquisition software (e.g., ScanImage) and implements novel strategies to detect motion artefacts, estimate neuropil contamination, and minimize their impact on functional signals extracted from neuronal population imaging. SmaRT2P is structured in a modular way to allow flexibility in the processing pipeline, requiring minimal user intervention in parameter setting. The use of SmaRT2P for smart line scanning has the potential to facilitate the functional investigation of large neuronal populations with increased SNR and accuracy in detecting the discharge of single and few action potentials."}}
{"id": "31CUiWCFc3K", "cdate": 1640995200000, "mdate": 1683880158313, "content": {"title": "Estimating the Temporal Evolution of Synaptic Weights from Dynamic Functional Connectivity", "abstract": "How to capture the temporal evolution of synaptic weights from measures of dynamic functional connectivity (DFC) between the activity of different simultaneously recorded neurons is an important and open problem in systems neuroscience. To address this issue, we first simulated models of recurrent neural networks of spiking neurons that had a spike-timing-dependent plasticity mechanism generating time-varying synaptic and functional coupling. We then used these simulations to test analytical approaches that relate dynamic functional connectivity to time-varying synaptic connectivity. We investigated how to use different measures of directed DFC, such as cross-covariance and transfer entropy, to build algorithms that infer how synaptic weights evolve over time. We found that, while both cross-covariance and transfer entropy provide robust estimates of structural connectivity and communication delays, cross-covariance better captures the evolution of synaptic weights over time. We also established how leveraging estimates of connectivity derived from entire simulated recordings could further boost the estimation of time-varying synaptic weights from the DFC. These results provide useful information to estimate accurately time variations of synaptic strength from spiking activity measures."}}
{"id": "vVwclNCcDDm", "cdate": 1609459200000, "mdate": 1683966771866, "content": {"title": "Inferring Neural Circuit Interactions and Neuromodulation from Local Field Potential and Electroencephalogram Measures", "abstract": "Electrical recordings of neural mass activity, such as local field potentials (LFPs) and electroencephalograms (EEGs), have been instrumental in studying brain function. However, being aggregate signals that lack cellular resolution, these signals are not easy to interpret directly in terms of neural functions. Developing tools for a reliable estimation of key neural parameters from these signals, such as the interaction between excitation and inhibition or the level of neuromodulation, is important both for neuroscience and clinical applications. Over the years we have developed tools based on the combination of neural network modelling and computational analysis of empirical data to estimate neural parameters from aggregate neural signals. The purpose of this paper, which accompanies an Invited Plenary Lecture in this conference, is to review the main tools that we have developed to estimate neural parameters from mass signals, and to outline future challenges and directions for developing computational tools to invert aggregate neural signals in terms of neural circuit parameters."}}
