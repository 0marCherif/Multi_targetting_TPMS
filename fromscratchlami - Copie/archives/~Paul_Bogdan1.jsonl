{"id": "Re5xbn-QH3U", "cdate": 1682899200000, "mdate": 1683611603678, "content": {"title": "A Scalable Distributed Dynamical Systems Approach to Learn the Strongly Connected Components and Diameter of Networks", "abstract": "Finding strongly connected components (SCCs) and the diameter of a directed network play a key role in a variety of machine learning and control theory problems. In this article, we provide for the first time a scalable distributed solution for these two problems by leveraging dynamical consensus-like protocols to find the SCCs. The proposed solution has a time complexity of <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><tex-math notation=\"LaTeX\">$\\mathcal {O}(NDd_{\\text{in-degree}}^{\\max })$</tex-math></inline-formula> , where <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><tex-math notation=\"LaTeX\">$N$</tex-math></inline-formula> is the number of vertices in the network, <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><tex-math notation=\"LaTeX\">$D$</tex-math></inline-formula> is the (finite) diameter of the network, and <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><tex-math notation=\"LaTeX\">$d_{\\text{in-degree}}^{\\max }$</tex-math></inline-formula> is the maximum in-degree of the network. Additionally, we prove that our algorithm terminates in <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><tex-math notation=\"LaTeX\">$D+2$</tex-math></inline-formula> iterations, which allows us to retrieve the finite diameter of the network. We perform exhaustive simulations that support the outperformance of our algorithm against the state of the art on several random networks, including Erd\u0151s\u2013R\u00e9nyi, Barab\u00e1si\u2013Albert, and Watts\u2013Strogatz networks."}}
{"id": "qzpVxhzIYG4", "cdate": 1672531200000, "mdate": 1681162948137, "content": {"title": "Coupled Multiwavelet Neural Operator Learning for Coupled Partial Differential Equations", "abstract": ""}}
{"id": "NSUWlpRJJTt", "cdate": 1672531200000, "mdate": 1683611603383, "content": {"title": "Fractional dynamics foster deep learning of COPD stage prediction", "abstract": "Chronic obstructive pulmonary disease (COPD) is one of the leading causes of death worldwide. Current COPD diagnosis (i.e., spirometry) could be unreliable because the test depends on an adequate effort from the tester and testee. Moreover, the early diagnosis of COPD is challenging. We address COPD detection by constructing two novel physiological signals datasets (4432 records from 54 patients in the WestRo COPD dataset and 13824 medical records from 534 patients in the WestRo Porti COPD dataset). The authors demonstrate their complex coupled fractal dynamical characteristics and perform a fractional-order dynamics deep learning analysis to diagnose COPD. The authors found that the fractional-order dynamical modeling can extract distinguishing signatures from the physiological signals across patients with all COPD stages from stage 0 (healthy) to stage 4 (very severe). They use the fractional signatures to develop and train a deep neural network that predicts COPD stages based on the input features (such as thorax breathing effort, respiratory rate, or oxygen saturation). The authors show that the fractional dynamic deep learning model (FDDLM) achieves a COPD prediction accuracy of 98.66% and can serve as a robust alternative to spirometry. The FDDLM also has high accuracy when validated on a dataset with different physiological signals."}}
{"id": "JNQd3J3bSNp", "cdate": 1672531200000, "mdate": 1683611603235, "content": {"title": "Raising The Limit Of Image Rescaling Using Auxiliary Encoding", "abstract": "Normalizing flow models using invertible neural networks (INN) have been widely investigated for successful generative image super-resolution (SR) by learning the transformation between the normal distribution of latent variable $z$ and the conditional distribution of high-resolution (HR) images gave a low-resolution (LR) input. Recently, image rescaling models like IRN utilize the bidirectional nature of INN to push the performance limit of image upscaling by optimizing the downscaling and upscaling steps jointly. While the random sampling of latent variable $z$ is useful in generating diverse photo-realistic images, it is not desirable for image rescaling when accurate restoration of the HR image is more important. Hence, in places of random sampling of $z$, we propose auxiliary encoding modules to further push the limit of image rescaling performance. Two options to store the encoded latent variables in downscaled LR images, both readily supported in existing image file format, are proposed. One is saved as the alpha-channel, the other is saved as meta-data in the image header, and the corresponding modules are denoted as suffixes -A and -M respectively. Optimal network architectural changes are investigated for both options to demonstrate their effectiveness in raising the rescaling performance limit on different baseline models including IRN and DLV-IRN."}}
{"id": "BOe83-USWS", "cdate": 1672531200000, "mdate": 1683611603353, "content": {"title": "C-SAR: SAT Attack Resistant Logic Locking for RSFQ Circuits", "abstract": "Since the development of semiconductor technologies, exascale computing and its associated applications have required increasing degrees of efficiency. Semiconductor-transistor-based circuits (STbCs) have struggled in increasing the GHz frequency. Emerging as an alternative to STbC, the superconducting electrons (SCE) technology promises higher-speed clock frequencies at ultra-low power consumption. The rapid single flux quantum (RSFQ) circuits have a theoretical potential for three orders of magnitude reduction in power while operating at clock frequencies higher than 100 GHz. Although the security in semiconductor technology has been extensively researched and developed, the security design in the superconducting field requires field demands attention. In this paper, C-SAR is presented that aims to protect the superconducting circuit electronics from Boolean satisfiability (SAT) based attacks. The SAT attack is an attack that can break all the existing combinational logic locking techniques. C-SAR can immunize against SAT attacks by increasing the key search space and prolonging the clock cycles of attack inputs. Even in the worst case of C-SAR, in face of S-SAT a specially designed SAT attack, C-SAR can also soar the attack cost exponentially with key bits first, then linearly with the length of camouflaged DFF array. We have shown in this work that the cost of C-SAR is manageable as it only linearly increases as a function of key bits."}}
{"id": "A_OoUgLv8W", "cdate": 1672531200000, "mdate": 1683611603404, "content": {"title": "A Majority Logic Synthesis Framework For Single Flux Quantum Circuits", "abstract": "Exascale computing and its associated applications have required increasing degrees of efficiency. Semiconductor-Transistor-based Circuits (STbCs) have struggled with increasing the GHz frequency while dealing with power dissipation issues. Emerging as an alternative to STbC, single flux quantum (SFQ) logic in the superconducting electrons (SCE) technology promises higher-speed clock frequencies at ultra-low power consumption. However, its quantized pulse-based operation and high environmental requirements, process variations and other SFQ-specific non-idealities are the significant causes of logic error for SFQ circuits. A suitable method of minimizing the impact of the afore-mentioned error sources is to minimize the number of Josephson Junctions (JJs) in the circuits, hence an essential part of the design flow of large SFQ circuits. This paper presents a novel SFQ logic synthesis framework that given a netlist, offers an automated mapping solution including majority (MAJ) logic with the goal of minimizing the number of JJs, while catering to the unique characteristics and requirements of the design. Our experiments confirm that our synthesis framework significantly outperforms the state-of-the-art academic SFQ technology mapper, namely reducing the number of JJs on average by 35.0%."}}
{"id": "kIo_C6QmMOM", "cdate": 1663850530163, "mdate": null, "content": {"title": "Coupled Multiwavelet Operator Learning for Coupled Differential Equations", "abstract": "Coupled partial differential equations (PDEs) are key tasks in modeling the complex dynamics of many physical processes. Recently, neural operators have shown the ability to solve PDEs by learning the integral kernel directly in Fourier/Wavelet space, so the difficulty of solving the coupled PDEs depends on dealing with the coupled mappings between the functions. Towards this end, we propose a \\textit{coupled multiwavelets neural operator} (CMWNO) learning scheme by decoupling the coupled integral kernels during the multiwavelet decomposition and reconstruction procedures in the Wavelet space. The proposed model achieves significantly higher accuracy compared to previous learning-based solvers in solving the coupled PDEs including Gray-Scott (GS) equations and the non-local mean field game (MFG) problem. According to our experimental results, the proposed model exhibits a $2X-4X$ improvement relative $L$2 error compared to the best results from the state-of-the-art models."}}
{"id": "k7qRYoxUlB", "cdate": 1663850198521, "mdate": null, "content": {"title": "Structural Code Representation Learning for Auto-Vectorization", "abstract": "The single instruction multiple data (SIMD) capability in modern processors is critical to improving the performance of current compute-intensive programs. SIMD allows architectures to exploit the natural data parallelism that exists in a wide-range of real applications (e.g., games, signal processing, etc) by executing a single instruction on multiple data items simultaneously. Modern compilers use vectorization techniques to exploit the SIMD capability, by detecting data parallelism in scalar source code and transforming a group of scalar instructions into vector-based instructions. In this work, we focus on one of the most common vectorization techniques called \\emph{loop-based vectorization}, which targets loops and optimize their performance by grouping multiple occurrences of the same operation across loop iterations into single SIMD instructions. This is achieved by setting two key parameters: (1) the vectorization factor (VF), and (2) the interleaving factor (IF). Unfortunately, vectorizing loop computations effectively is a key challenging problem for both programmers and compilers due to the large search space. For example, manual vectorization of each loop puts a huge burden on the programmer, is more error-prone, and/or requires expert knowledge of both the software and the architecture. Alternatively, current compilers use fixed-cost models based on expert heuristics to make automatic vectorization decisions. However, these models often ignore the data dependencies, as well as the underlying computation graph. In this paper, we propose a data-driven graph-based learning framework for automatic vectorization, called \\emph{autograph}, which takes an input program, extracts the loops, then learns a structured representation to automatically predict the correct VF/IF factors. Our proposed framework utilizes deep reinforcement learning to learn an optimal policy (observations to actions) from an intelligent agent in a SIMD environment, and automatically injects the predicted vectorization pragmas into the input program. We conducted an extensive evaluation on multiple benchmark datasets and comparisons with state-of-the-art baselines. Our experimental results show that the proposed framework can achieve up to 1.02x-2.26x and 1.06x-4.27x performance improvement, compared to state-of-the-art baseline and LLVM -O3 respectively."}}
{"id": "TM9jOSaIzN", "cdate": 1663849954733, "mdate": null, "content": {"title": "Neural Decoding of Visual Imagery via Hierarchical Variational Autoencoders", "abstract": "Reconstructing natural images from fMRI recordings is a challenging task of great importance in neuroscience. The current architectures are bottlenecked because they fail to effectively capture the hierarchical processing of visual stimuli that takes place in the human brain. Motivated by that fact, we introduce a novel neural network architecture for the problem of neural decoding. Our architecture uses Hierarchical Variational Autoencoders (HVAEs) to learn meaningful representations of natural images and leverages their latent space hierarchy to learn voxel-to-image mappings. By mapping the early stages of the visual pathway to the first set of latent variables and the higher visual cortex areas to the deeper layers in the latent hierarchy, we are able to construct a latent variable neural decoding model that replicates the hierarchical visual information processing. Our model achieves better reconstructions compared to the state of the art and our ablation study indicates that the hierarchical structure of the latent space is responsible for that performance. "}}
{"id": "nGqJY4DODN", "cdate": 1662812632560, "mdate": null, "content": {"title": "Efficient Representation Learning for Higher-Order Data with Simplicial Complexes", "abstract": "Graph-based machine learning is experiencing explosive growth, driven by impressive recent developments and wide applicability. Typical approaches for graph representation learning predominantly focus on pairwise interactions, while neglecting the patterns of higher-order interactions common to complex systems. This paper explores many-body interaction models, centering on simplicial complexes. From a theoretical point of view, we offer a pair of insights illustrating why higher-order models are necessary, why non-graph-based models generally cannot generalize well, while graph-based models may be able to do so. We conduct experiments on synthetic data, co-citation networks, co-authorship networks and gene-disease associations and show that simplicial complexes with certain relaxations can more efficiently capture underlying higher-order structures than non-graph structure, regular graph, hypergraph, and traditional simplicial complex-based learning frameworks."}}
