{"id": "IMfRxG579w6", "cdate": 1683883781638, "mdate": 1683883781638, "content": {"title": "fMRI BOLD signal decomposition using a multivariate low-rank model", "abstract": "Standard methodologies for functional Magnetic Resonance Imaging (fMRI) data analysis decompose the observed Blood Oxygenation Level Dependent (BOLD) signals using voxelwise linear model and perform maximum likelihood estimation to get the parameters associated with the regressors. In task fMRI, the latter are usually defined from the experimental paradigm and some confounds whereas in resting-state acquisitions, a seedvoxel time-course may be used as predictor. Nowadays, most fMRI datasets offer resting-state acquisitions, requiring multivariate approaches (e.g., PCA, ICA, etc) to extract meaningful information in a data-driven manner. Here, we propose a novel low-rank model of fMRI BOLD data but instead of considering a dimension reduction in space as in ICA, our model relies on convolutional sparse coding between the hemodynamic system and a few temporal atoms which code for the neural activity inducing signals. A rank-1 constraint is also associated with each temporal atom to spatially map its influence in the brain. Within a variational framework, the joint estimation of the neural signals and the associated spatial maps is formulated as a nonconvex optimization problem. A local minimizer is computed using an efficient alternate minimization algorithm. The proposed approach is first validated on simulations and then applied to task fMRI data for illustration purpose. Its comparison to a state-of-the-art approach suggests that our method is competitive regarding the uncovered neural fingerprints while offering a richer decomposition in time and space."}}
{"id": "U915QFBzcHn", "cdate": 1683883451568, "mdate": 1683883451568, "content": {"title": "Multivariate semi-blind deconvolution of fMRI time series", "abstract": "Whole brain estimation of the haemodynamic response function (HRF) in functional magnetic resonance imaging (fMRI) is critical to get \n insight on the global status of the neurovascular coupling of an individual in healthy or pathological condition. Most of existing approaches in the literature works on task-fMRI data and relies on the experimental paradigm as a surrogate of neural activity, hence remaining inoperative on resting-stage fMRI (rs-fMRI) data. To cope with this issue, recent works have performed either a two-step analysis to detect large neural events and then characterize the HRF shape or a joint estimation of both the neural and haemodynamic components in an univariate fashion. In this work, we express the neural activity signals as a combination of piece-wise constant temporal atoms associated with sparse spatial maps and introduce an haemodynamic parcellation of the brain featuring a temporally dilated version of a given HRF model in each parcel with unknown dilation parameters. We formulate the joint estimation of the HRF shapes and spatio-temporal neural representations as a multivariate semi-blind deconvolution problem in a paradigm-free setting and introduce constraints inspired from the dictionary learning literature to ease its identifiability. A fast alternating minimization algorithm, along with its efficient implementation, is proposed and validated on both synthetic and real rs-fMRI data at the subject level. To demonstrate its significance at the population level, we apply this new framework to the UK Biobank data set, first for the discrimination of haemodynamic territories between balanced groups (individuals in each) patients with an history of stroke and healthy controls and second, for the analysis of normal aging on the neurovascular coupling. Overall, we statistically demonstrate that a pathology like stroke or a condition like normal brain aging induce longer haemodynamic delays in certain brain areas (e.g. Willis polygon, occipital, temporal and frontal cortices) and that this haemodynamic feature may be predictive with an accuracy of 74 % of the individual\u2019s age in a supervised classification task performed on subjects.\n\n"}}
{"id": "25Xf-EwPhB", "cdate": 1683883263924, "mdate": 1683883263924, "content": {"title": "Learning to solve TV regularised problems with unrolled algorithms", "abstract": "Total Variation (TV) is a popular regularization strategy that promotes piece-wise constant signals by constraining the L1-norm of the first order derivative of the estimated signal. The resulting optimization problem is usually solved using iterative algorithms such as proximal gradient descent, primal-dual algorithms or ADMM. However, such methods can require a very large number of iterations to converge to a suitable solution. In this paper, we accelerate such iterative algorithms by unfolding proximal gradient descent solvers in order to learn their parameters for 1D TV regularized problems. While this could be done using the synthesis formulation, we demonstrate that this leads to slower performances. The main difficulty in applying such methods in the analysis formulation lies in proposing a way to compute the derivatives through the proximal operator. As our main contribution, we develop and characterize two approaches to do so, describe their benefits and limitations, and discuss the regime where they can actually improve over iterative procedures. We validate those findings with experiments on synthetic and real data."}}
{"id": "DeljV8MAVZs", "cdate": 1683882703866, "mdate": 1683882703866, "content": {"title": "Sparsity-based blind deconvolution of neural activation signal in fMRI", "abstract": "The estimation of the hemodynamic response function (HRF) in functional magnetic resonance imaging (fMRI) is critical\nto deconvolve a time-resolved neural activity and get insights on the underlying cognitive processes. Existing methods propose to estimate the HRF using the experimental paradigm (EP) in task fMRI as a surrogate of neural activity. These approaches induce a bias as they do not account for latencies in the cognitive responses compared to EP and cannot be applied to resting-state data as no EP is available. In this\nwork, we formulate the joint estimation of the HRF and neural activation signal as a semi blind deconvolution problem. Its solution can be approximated using an efficient alternate minimization algorithm. The proposed approach is applied to task fMRI data for validation purpose and compared to a state-of-the-art HRF estimation technique. Numerical experiments suggest that our approach is competitive with others while not requiring EP information."}}
{"id": "ufdYz4Rl3bl", "cdate": 1672531200000, "mdate": 1681652937098, "content": {"title": "Using convolutional dictionary learning to detect task-related neuromagnetic transients and ageing trends in a large open-access dataset", "abstract": ""}}
{"id": "qpQvgLXaV_", "cdate": 1672531200000, "mdate": 1679155144517, "content": {"title": "Sliced-Wasserstein on Symmetric Positive Definite Matrices for M/EEG Signals", "abstract": ""}}
{"id": "Z24qJD_IrXA", "cdate": 1672531200000, "mdate": 1679901406719, "content": {"title": "A Near-Optimal Algorithm for Bilevel Empirical Risk Minimization", "abstract": ""}}
{"id": "YtGDt_YPr3", "cdate": 1672531200000, "mdate": 1681726067845, "content": {"title": "Wavelets in the Deep Learning Era", "abstract": "Sparsity-based methods, such as wavelets, have been the state of the art for more than 20 years for inverse problems before being overtaken by neural networks. In particular, U-nets have proven to be extremely effective. Their main ingredients are a highly nonlinear processing, a massive learning made possible by the flourishing of optimization algorithms with the power of computers (GPU) and the use of large available datasets for training. It is far from obvious to say which of these three ingredients has the biggest impact on the performance. While the many stages of nonlinearity are intrinsic to deep learning, the usage of learning with training data could also be exploited by sparsity-based approaches. The aim of our study is to push the limits of sparsity to use, similarly to U-nets, massive learning and large datasets, and then to compare the results with U-nets. We present a new network architecture, called learnlets, which conserves the properties of sparsity-based methods such as exact reconstruction and good generalization properties, while fostering the power of neural networks for learning and fast calculation. We evaluate the model on image denoising tasks. Our conclusion is that U-nets perform better than learnlets on image quality metrics in distribution, while learnlets have better generalization properties."}}
{"id": "Z2Kgq-czhh", "cdate": 1663850366186, "mdate": null, "content": {"title": "FaDIn: Fast Discretized Inference for Hawkes Processes with General Parametric Kernels", "abstract": "Temporal point processes (TPP) are a natural tool for modeling event-based data. Among all TPP models, Hawkes processes have proven to be the most widely used, mainly due to their simplicity and computational ease when considering exponential or non-parametric kernels. Although non-parametric kernels are an option, such models require large datasets. While exponential kernels are more data efficient and relevant for certain applications where events immediately trigger more events, they are ill-suited for applications where latencies need to be estimated, such as in neuroscience. This work aims to offer an efficient solution to TPP inference using general parametric kernels with finite support. The developed solution consists of a fast L2 gradient-based solver leveraging a discretized version of the events. After supporting the use of discretization theoretically, the statistical and computational efficiency of the novel approach is demonstrated through various numerical experiments. Finally, the effectiveness of the method is evaluated by modeling the occurrence of stimuli-induced patterns from brain signals recorded with magnetoencephalography (MEG). Given the use of general parametric kernels, results show that the proposed approach leads to a more plausible estimation of pattern latency compared to the state-of-the-art.\n"}}
{"id": "hpr8KTZzz4W", "cdate": 1663850258871, "mdate": null, "content": {"title": "PAVI: Plate-Amortized Variational Inference", "abstract": "Given observed data and a probabilistic generative model, Bayesian inference aims at obtaining the distribution of a model\u2019s latent parameters that could have yielded the data. This task is challenging for large population studies where thousands of measurements are performed over a cohort of hundreds of subjects, resulting in a massive latent parameter space. This large cardinality renders off-the-shelf Variational Inference (VI) computationally impractical.\n\nIn this work, we design structured VI families that can efficiently tackle large population studies. Our main idea is to share the parameterization and learning across the different i.i.d. variables in a generative model --symbolized by the model\u2019s plates. We name this concept plate amortization, and illustrate the powerful synergies it entitles, resulting in expressive, parsimoniously parameterized and orders of magnitude faster to train large scale hierarchical variational distributions.\n\nWe illustrate the practical utility of PAVI through a challenging Neuroimaging example featuring a million latent parameters, demonstrating a significant step towards scalable and expressive Variational Inference."}}
