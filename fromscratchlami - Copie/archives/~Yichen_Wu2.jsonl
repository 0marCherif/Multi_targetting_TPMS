{"id": "rVM8wD2G7Dy", "cdate": 1663850232562, "mdate": null, "content": {"title": "Imbalanced Semi-supervised Learning with Bias Adaptive Classifier", "abstract": "Pseudo-labeling has proven to be a promising semi-supervised learning (SSL) paradigm. Existing pseudo-labeling methods commonly assume that the class distributions of training data are balanced. However, such an assumption is far from realistic scenarios and thus severely limits the performance of current pseudo-labeling methods under the context of class-imbalance. To alleviate this problem, we design a bias adaptive classifier that targets the imbalanced SSL setups. The core idea is to automatically assimilate the training bias caused by class imbalance via the bias adaptive classifier, which is composed of a novel bias attractor and the original linear classifier. The bias attractor is designed as a light-weight residual network and learned through a bi-level learning framework, which enables the bias adaptive classifier to fit imbalanced training data, while the linear classifier can provide unbiased label prediction for each class. We conduct extensive experiments under various imbalanced semi-supervised setups, and the results demonstrate that our method can be applied to different pseudo-labeling models and is superior to current state-of-the-art methods."}}
{"id": "pFqgUJxXXz", "cdate": 1652737457420, "mdate": null, "content": {"title": "Adversarial Task Up-sampling for Meta-learning", "abstract": "The success of meta-learning on existing benchmarks is predicated on the assumption that the distribution of meta-training tasks covers meta-testing tasks. Frequent violation of the assumption in applications with either insufficient tasks or a very narrow meta-training task distribution leads to memorization or learner overfitting. Recent solutions have pursued augmentation of meta-training tasks, while it is still an open question to generate both correct and sufficiently imaginary tasks. In this paper, we seek an approach that up-samples meta-training tasks from the task representation via a task up-sampling network. Besides, the resulting approach named Adversarial Task Up-sampling (ATU) suffices to generate tasks that can maximally contribute to the latest meta-learner by maximizing an adversarial loss. On few-shot sine regression and image classification datasets, we empirically validate the marked improvement of ATU over state-of-the-art task augmentation strategies in the meta-testing performance and also the quality of up-sampled tasks."}}
{"id": "fYVikSA1oy", "cdate": 1640995200000, "mdate": 1668082745532, "content": {"title": "Survey on rain removal from videos or a single image", "abstract": "Rain can cause performance degradation of outdoor computer vision tasks. Thus, the exploration of rain removal from videos or a single image has drawn considerable attention in the field of image processing. Recently, various deraining methodologies have been proposed. However, no comprehensive survey work has yet been conducted to summarize existing deraining algorithms and quantitatively compare their generalization ability, and especially, no off-the-shelf toolkit exists for accumulating and categorizing recent representative methods for easy performance reproduction and deraining capability evaluation. In this regard, herein, we present a comprehensive overview of existing video and single image deraining methods as well as reproduce and evaluate current state-of-the-art deraining methods. In particular, these approaches are mainly classified into model- and deep-learning-based methods, and more elaborate branches of each method are presented. Inherent abilities, especially generalization performance, of the state-of-the-art methods have been both quantitatively and visually analyzed through thorough experiments conducted on synthetic and real benchmark datasets. Moreover, to facilitate the reproduction of existing deraining methods for general users, we present a comprehensive repository with detailed classification, including direct links to 85 deraining papers, 24 relevant project pages, source codes of 12 and 25 algorithms for video and single image deraining, respectively, 5 and 10 real and synthesized datasets, respectively, and 7 frequently used image quality evaluation metrics, along with the corresponding computation codes. Research limitations worthy of further exploration have also been discussed for future research along this direction."}}
{"id": "bd5jZFWFjOP", "cdate": 1640995200000, "mdate": 1683878759829, "content": {"title": "Adversarial Task Up-sampling for Meta-learning", "abstract": "The success of meta-learning on existing benchmarks is predicated on the assumption that the distribution of meta-training tasks covers meta-testing tasks. Frequent violation of the assumption in applications with either insufficient tasks or a very narrow meta-training task distribution leads to memorization or learner overfitting. Recent solutions have pursued augmentation of meta-training tasks, while it is still an open question to generate both correct and sufficiently imaginary tasks. In this paper, we seek an approach that up-samples meta-training tasks from the task representation via a task up-sampling network. Besides, the resulting approach named Adversarial Task Up-sampling (ATU) suffices to generate tasks that can maximally contribute to the latest meta-learner by maximizing an adversarial loss. On few-shot sine regression and image classification datasets, we empirically validate the marked improvement of ATU over state-of-the-art task augmentation strategies in the meta-testing performance and also the quality of up-sampled tasks."}}
{"id": "OnCLHhUfFDm", "cdate": 1640995200000, "mdate": 1681650503167, "content": {"title": "Learning to generate imaginary tasks for improving generalization in meta-learning", "abstract": ""}}
{"id": "q5vvFfn04c", "cdate": 1609459200000, "mdate": 1668400288092, "content": {"title": "Structural residual learning for single image rain removal", "abstract": ""}}
{"id": "p9ZbSdpI5X4", "cdate": 1609459200000, "mdate": 1668082745536, "content": {"title": "Learning to Purify Noisy Labels via Meta Soft Label Corrector", "abstract": "Recent deep neural networks (DNNs) can easily overfit to biased training data with noisy labels. Label correction strategy is commonly used to alleviate this issue by identifying suspected noisy labels and then correcting them. Current approaches to correcting corrupted labels usually need manually pre-defined label correction rules, which makes it hard to apply in practice due to the large variations of such manual strategies with respect to different problems. To address this issue, we propose a meta-learning model, aiming at attaining an automatic scheme which can estimate soft labels through meta-gradient descent step under the guidance of a small amount of noise-free meta data. By viewing the label correction procedure as a meta-process and using a meta-learner to automatically correct labels, our method can adaptively obtain rectified soft labels gradually in iteration according to current training problems. Besides, our method is model-agnostic and can be combined with any other existing classification models with ease to make it available to noisy label cases. Comprehensive experiments substantiate the superiority of our method in both synthetic and real-world problems with noisy labels compared with current state-of-the-art label correction strategies."}}
{"id": "8HbOjVt06cy", "cdate": 1609459200000, "mdate": 1674901023831, "content": {"title": "Neighbor Matching for Semi-supervised Learning", "abstract": "Consistency regularization has shown superiority in deep semi-supervised learning, which commonly estimates pseudo-label conditioned on each single sample and its perturbations. However, such a strategy ignores the relation between data points, and probably arises error accumulation problems once one sample and its perturbations are integrally misclassified. Against this issue, we propose Neighbor Matching, a pseudo-label estimator that propagates labels for unlabeled samples according to their neighboring ones (labeled samples with the same semantic category) during training in an online manner. Different from existing methods, for an unlabeled sample, our Neighbor Matching defines a mapping function that predicts its pseudo-label conditioned on itself and its local manifold. Concretely, the local manifold is constructed by a memory padding module that memorizes the embeddings and labels of labeled data across different mini-batches. We experiment with two distinct benchmark datasets for semi-supervised classification of thoracic disease and skin lesion, and the results demonstrate the superiority of our approach beyond other state-of-the-art methods. Source code is publicly available at https://github.com/renzhenwang/neighbor-matching ."}}
{"id": "dmIJiuV26c7", "cdate": 1577836800000, "mdate": null, "content": {"title": "Learning to Purify Noisy Labels via Meta Soft Label Corrector", "abstract": "Recent deep neural networks (DNNs) can easily overfit to biased training data with noisy labels. Label correction strategy is commonly used to alleviate this issue by designing a method to identity suspected noisy labels and then correct them. Current approaches to correcting corrupted labels usually need certain pre-defined label correction rules or manually preset hyper-parameters. These fixed settings make it hard to apply in practice since the accurate label correction usually related with the concrete problem, training data and the temporal information hidden in dynamic iterations of training process. To address this issue, we propose a meta-learning model which could estimate soft labels through meta-gradient descent step under the guidance of noise-free meta data. By viewing the label correction procedure as a meta-process and using a meta-learner to automatically correct labels, we could adaptively obtain rectified soft labels iteratively according to current training problems without manually preset hyper-parameters. Besides, our method is model-agnostic and we can combine it with any other existing model with ease. Comprehensive experiments substantiate the superiority of our method in both synthetic and real-world problems with noisy labels compared with current SOTA label correction strategies."}}
{"id": "Gj75FFbaAfa", "cdate": 1577836800000, "mdate": 1623597668223, "content": {"title": "Single image rain streaks removal: a review and an exploration", "abstract": "Recently, rain streaks removal from a single image has attracted much research attention to alleviate the degenerated performance of computer vision tasks implemented on rainy images. In this paper, we provide a thorough review for current single-image-based rain removal techniques, which can be mainly categorized into three classes: early filter-based, conventional prior-based, and recent deep learning-based approaches. Furthermore, inspired by the rationality of current deep learning-based methods and insightful characteristics underlying rain shapes, we build a specific coarse-to-fine deraining network architecture, which can finely deliver the rain structures and progressively removes rain streaks from the input image, accordingly. The superiority of the proposed network is substantiated by experiments implemented on synthetic and real rainy images both visually and quantitatively, as compared with comprehensive state-of-the-art methods along this line. Especially, it is verified that the proposed network possesses better generalization capability on real rainy images, implying its potential usefulness for this task."}}
