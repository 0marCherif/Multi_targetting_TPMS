{"id": "AG8yyZQ7-w", "cdate": 1669694000928, "mdate": null, "content": {"title": "Causal Deep Learning (Supplemental)", "abstract": "We derive a set of causal deep neural networks whose architectures are a consequence of tensor (multilinear) factor analysis. Forward causal questions are addressed with a neural network architecture composed of causal capsules and a tensor transformer. The former estimate a set of latent variables that represent the causal factors, and the latter governs their interaction. Causal capsules and tensor transformers may be implemented using shallow autoencoders, but for a scalable architecture, we employ block algebra and derive a deep neural network composed of a hierarchy of autoencoders. An interleaved kernel hierarchy preprocesses the data resulting in a hierarchy of kernel tensor factor models. Inverse causal questions are addressed with a neural network that implements multilinear projection and estimates the causes of effects. As an alternative to aggressive bottleneck dimension reduction or regularized regression that may camouflage an inherently underdetermined inverse problem, we prescribe modeling different aspects of the mechanism of data formation with piecewise tensor models whose multilinear projections are well-defined and produce multiple candidate solutions. Our forward and inverse neural network architectures are suitable for asynchronous parallel computation.\n"}}
{"id": "RfTquz6B_Iq", "cdate": 1664524392512, "mdate": null, "content": {"title": "Causal Deep Learning", "abstract": "We derive a set of causal deep neural networks whose architectures are a consequence of tensor (multilinear) factor\nanalysis. Forward causal questions are addressed with a neural network architecture composed of causal capsules and a tensor\ntransformer. The former estimate a set of latent variables that represent the causal factors, and the latter governs their interaction.\nCausal capsules and tensor transformers may be implemented using shallow autoencoders, but for a scalable architecture we\nemploy block algebra and derive a deep neural network composed of a hierarchy of autoencoders. An interleaved kernel hierarchy pre-\nprocesses the data resulting in a hierarchy of kernel tensor factor models. Inverse causal questions are addressed with a neural\nnetwork that implements multilinear projection and estimates the causes of effects. As an alternative to aggressive bottleneck\ndimension reduction or regularized regression that may camouflage an inherently underdetermined inverse problem, we prescribe\nmodeling different aspects of the mechanism of data formation with piecewise tensor models whose multilinear projections are well-\ndefined and produce multiple candidate solutions. Our forward and inverse neural network architectures are suitable for asynchronous\nparallel computation."}}
{"id": "ptEYWyAhCX", "cdate": 1664524187631, "mdate": 1664524187631, "content": {"title": "Adaptive Meshes and Shells: Irregular Triangulation, Discontinuities, and Hierarchical Subdivision", "abstract": "Adaptive meshes are dynamic networks of nodal masses interconnected by adjustable springs. They are useful for nonuniformly sampling and reconstructing visual data. This paper extends the adaptive mesh model in the following ways: it (i) develops open\nadaptive meshes and closed adaptive shells based on triangular and rectangular elements, (ii) proposes a discontinuity detection\nand preservation algorithm suitable for the model, and (iii) develops techniques for adaptive hierarchical subdivision of adaptive\nmeshes and shells. The extended model is applied to image and 3D surface data."}}
{"id": "5ziLr3pWz77", "cdate": 1632875447282, "mdate": null, "content": {"title": "Neural network architectures for disentangling the multimodal structure of data ensembles", "abstract": "We introduce neural network architectures that model the mechanism that generates data and address the difficult problem of disentangling the multimodal structure of data ensembles. We provide (i) an autoencoder-decoder architecture that implements the $M$-mode SVD and (ii) a generalized autoencoder that employs a kernel activation and implements the doubly nonlinear Kernel-MPCA.  The neural network projection architecture decomposes an unlabeled data given an estimated forward model and a set of observations that constrain the solution set."}}
{"id": "qSy8VLQUKLX", "cdate": 1623728336754, "mdate": null, "content": {"title": "TensorTextures: Multilinear Image-Based Rendering", "abstract": "This paper introduces a tensor framework for image-based rendering.  In particular, we develop an algorithm called TensorTexturesthat learns a parsimonious model of the bidirectional texture function (BTF) from observational data.  Given an ensemble of images of a textured surface, our nonlinear, generative model explicitly represents the multifactor interaction implicit in the detailed appearance of the surface under varying photometric angles, including lo-cal (per-texel) reflectance, complex mesostructural self-occlusion, interreflection and self-shadowing,  and other  BTF-relevant phenomena.   Mathematically,  TensorTextures is based on multilinear algebra, the algebra of higher-order tensors, hence its name.  It is computed through a decomposition known as the N-mode SVD, an extension to tensors of the conventional matrix singular value decomposition (SVD). We demonstrate the application of Tensor-Textures to the image-based rendering of natural and synthetic textured surfaces under continuously varying viewpoint and illumination conditions."}}
{"id": "mc9OBhx9XAQ", "cdate": 1623728073838, "mdate": null, "content": {"title": "A MULTILINEAR (TENSOR) ALGEBRAIC FRAMEWORK FOR COMPUTER GRAPHICS, COMPUTER VISION, AND MACHINE LEARNING", "abstract": "This thesis introduces a multilinear algebraic framework for computer graphics, computer vision,\nand machine learning, particularly for the fundamental purposes of image synthesis, analysis, and recognition. Natural images result from the multifactor interaction between the imaging process, the scene\nillumination, and the scene geometry. We assert that a principled mathematical approach to disentangling and explicitly representing these causal factors, which are essential to image formation, is through\nnumerical multilinear algebra, the algebra of higher-order tensors.\n\nOur new image modeling framework is based on (i) a multilinear generalization of principal components analysis (PCA), (ii) a novel multilinear generalization of independent components analysis (ICA),\nand (iii) a multilinear projection for use in recognition that maps images to the multiple causal factor\nspaces associated with their formation. Multilinear PCA employs a tensor extension of the conventional\nmatrix singular value decomposition (SVD), known as the M-mode SVD, while our multilinear ICA\nmethod involves an analogous M-mode ICA algorithm.\n\nAs applications of our tensor framework, we tackle important problems in computer graphics, computer vision, and pattern recognition; in particular, (i) image-based rendering, specifically introducing\nthe multilinear synthesis of images of textured surfaces under varying view and illumination conditions,\na new technique that we call \u201cTensorTextures\u201d, as well as (ii) the multilinear analysis and recognition\nof facial images under variable face shape, view, and illumination conditions, a new technique that we\ncall \u201cTensorFaces\u201d. In developing these applications, we introduce a multilinear image-based rendering\nalgorithm and a multilinear appearance-based recognition algorithm. As a final, non-image-based application of our framework, we consider the analysis, synthesis and recognition of human motion data\nusing multilinear methods, introducing a new technique that we call \u201cHuman Motion Signatures\u201d."}}
{"id": "t9bsf6ru7e7", "cdate": 1623727014605, "mdate": null, "content": {"title": "CausalX: Causal eXplanations and Block Multilinear Factor Analysis", "abstract": "By adhering to the dictum, \"No causation without manipulation (treatment, intervention)\", cause and effect data analysis represents changes in observed data in terms of changes in the causal factors. When causal factors are not amenable for active manipulation in the real world due to current technological limitations or ethical considerations, a counterfactual approach performs an intervention on the model of data formation. In the case of object representation or activity (temporal object) representation, varying object parts is generally unfeasible whether they be spatial and/or temporal. Multilinear algebra, the algebra of higher-order tensors, is a suitable and transparent framework for disentangling the causal factors of data formation. Learning a part-based intrinsic causal factor representations in a multilinear framework requires applying a set of interventions on a part-based multilinear model. We propose a unified multilinear model of wholes and parts. We derive a hierarchical block multilinear factorization, the M-mode Block SVD, that computes a disentangled representation of the causal factors by optimizing simultaneously across the entire object hierarchy. Given computational efficiency considerations, we introduce an incremental bottom-up computational alternative, the Incremental M-mode Block SVD, that employs the lower-level abstractions, the part representations, to represent the higher level of abstractions, the parent wholes. This incremental computational approach may also be employed to update the causal model parameters when data becomes available incrementally. The resulting object representation is an interpretable combinatorial choice of intrinsic causal factor representations related to an object's recursive hierarchy of wholes and parts that renders object recognition robust to occlusion and reduces training data requirements."}}
{"id": "gWcZinFSbcq", "cdate": 1609459200000, "mdate": 1668593745342, "content": {"title": "CausalX: Causal Explanations and Block Multilinear Factor Analysis", "abstract": "By adhering to the dictum, \"No causation without manipulation (treatment, intervention)\", cause and effect data analysis represents changes in observed data in terms of changes in the causal factors. When causal factors are not amenable for active manipulation in the real world due to current technological limitations or ethical considerations, a counterfactual approach performs an intervention on the model of data formation. In the case of object representation or activity (temporal object) representation, varying object parts is generally unfeasible whether they be spatial and/or temporal. Multilinear algebra, the algebra of higher-order tensors, is a suitable and transparent framework for disentangling the causal factors of data formation. Learning a part-based intrinsic causal factor representations in a multilinear framework requires applying a set of interventions on a part-based multilinear model. We propose a unified multilinear model of wholes and parts. We derive a hierarchical block multilinear factorization, the M-mode Block SVD, that computes a disentangled representation of the causal factors by optimizing simultaneously across the entire object hierarchy. Given computational efficiency considerations, we introduce an incremental bottom-up computational alternative, the Incremental M-mode Block SVD, that employs the lower-level abstractions, the part representations, to represent the higher level of abstractions, the parent wholes. This incremental computational approach may also be employed to update the causal model parameters when data becomes available incrementally. The resulting object representation is an interpretable combinatorial choice of intrinsic causal factor representations related to an object's recursive hierarchy of wholes and parts that renders object recognition robust to occlusion and reduces training data requirements."}}
{"id": "zUoUOTHNmH", "cdate": 1582362453236, "mdate": null, "content": {"title": "Multilinear Projection For Face Recognition Via Canonical Decomposition", "abstract": "This paper introduces a new multilinear projection algorithm for appearance-based recognition in a tensor framework. The multilinear projection simultaneously maps an unlabeled image from the pixel space into multiple causal factors underlying image formation, including illumination, imaging, and scene structure. For facial recognition, the most relevant aspect of scene structure is the specific person whose face has been imaged. Our new multilinear projection algorithm, which is based on the canonical decomposition of tensors, is superior to our previously proposed multilinear projection algorithm that is based on an Mmode SVD. To develop our new algorithm, we extend and formalize the definition of the mode-m product, the modem identity tensor, and the mode-m pseudo-inverse tensor. We demonstrate our multilinear projection in the context of facial image recognition and compare its results in simultaneously inferring the identity, view, illumination, etc., coefficient vectors of an unlabeled test image against those obtained using multilinear projection based on the M-mode SVD, as well as against the results obtained using a set of multiple linear projections. Finally, we present a strategy for developing a practical biometric system that can enroll an uncooperative subject using a one or more images and then recognize that subject in unconstrained test images."}}
{"id": "UyfeHiT-N4", "cdate": 1582362148588, "mdate": null, "content": {"title": "Face Tracking with Multilinear (Tensor) Active Appearance Models", "abstract": "Face tracking in an unconstrained environment must contend with images that vary with viewpoint, illumination, expression, identity, and other causal factors. In a statistical approach, the multifactor nature of the image data makes the aforementioned problem amenable to analysis in a multilinear framework. In this paper, we propose Multilinear (Tensor) Active Appearance Models (MAAMs). The MAAM is a multilinear statistical model of facial appearance and shape that generalizes the linear Active Appearnce Model (AAM). As models of data variability, the latter fail to distinguish and account for the different sources of variabilty. On the other hand, our MAAMs explicitly represent the underlying processes of image formation, thus preserving attributes that are relevant to the task of tracking the human face.\n"}}
