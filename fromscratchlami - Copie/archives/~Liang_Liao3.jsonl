{"id": "g7_IeVQcDJC", "cdate": 1609459200000, "mdate": 1631878535134, "content": {"title": "Image Inpainting Guided by Coherence Priors of Semantics and Textures", "abstract": "Existing inpainting methods have achieved promising performance in recovering defected images of specific scenes. However, filling holes involving multiple semantic categories remains challenging due to the obscure semantic boundaries and the mixture of different semantic textures. In this paper, we introduce coherence priors between the semantics and textures which make it possible to concentrate on completing separate textures in a semantic-wise manner. Specifically, we adopt a multi-scale joint optimization framework to first model the coherence priors and then accordingly interleavingly optimize image inpainting and semantic segmentation in a coarse-to-fine manner. A Semantic-Wise Attention Propagation (SWAP) module is devised to refine completed image textures across scales by exploring non-local semantic coherence, which effectively mitigates mix-up of textures. We also propose two coherence losses to constrain the consistency between the semantics and the inpainted image in terms of the overall structure and detailed textures. Experimental results demonstrate the superiority of our proposed method for challenging cases with complex holes."}}
{"id": "aolNlOe8XiB", "cdate": 1609459200000, "mdate": 1631878534738, "content": {"title": "Uncertainty-Aware Semantic Guidance and Estimation for Image Inpainting", "abstract": "Completing a corrupted image by filling in correct structures and reasonable textures for a complex scene remains an elusive challenge. In case that a missing hole involves diverse semantic information, conventional two-stage approaches based on structural information often lead to unreliable structural prediction and ambiguous visual texture generation. To address the problem, we propose a SEmantic GUidance and Estimation Network (SeGuE-Net) that iteratively evaluates the uncertainty of inpainted visual contents based on pixel-wise semantic inference and optimize structural priors and inpainted contents alternatively. Specifically, SeGuE-Net utilizes semantic segmentation maps as guidance in each iteration of image inpainting, under which location-dependent inferences are re-estimated, and, accordingly, poorly-inferred regions are refined in subsequent iterations. Extensive experiments on real-world images demonstrate the superiority of our proposed method over state-of-the-art approaches in terms of clear boundaries and photo-realistic textures."}}
{"id": "xkw0ibojAYq", "cdate": 1577836800000, "mdate": 1631878534741, "content": {"title": "Learned Representation of Satellite Image Series for Data Compression", "abstract": "Real-time transmission of satellite video data is one of the fundamentals in the applications of video satellite. Making use of the historical information to eliminate the long-term background redundancy (LBR) is considered to be a crucial way to bridge the gap between the compressed data rate and the bandwidth between the satellite and the Earth. The main challenge lies in how to deal with the variant image pixel values caused by the change of shooting conditions while keeping the structure of the same landscape unchanged. In this paper, we propose a representation learning based method to model the complex evolution of the landscape appearance under different conditions by making use of the historical image series. Under this representation model, the image is disentangled into the content part and the style part. The former represents the consistent landscape structure, while the latter represents the conditional parameters of the environment. To utilize the knowledge learned from the historical image series, we generate synthetic reference frames for the compression of video frames through image translation by the representation model. The synthetic reference frames can highly boost the compression efficiency by changing the original intra-frame prediction to inter-frame prediction for the intra-coded picture (I frame). Experimental results show that the proposed representation learning-based compression method can save an average of 44.22% bits over HEVC, which is significantly higher than that using references generated under the same conditions. Bitrate savings reached 18.07% when applied to satellite video data with arbitrarily collected reference images."}}
{"id": "d2uNpSmZOS", "cdate": 1577836800000, "mdate": 1631878534741, "content": {"title": "Image Inpainting Guided by Coherence Priors of Semantics and Textures", "abstract": "Existing inpainting methods have achieved promising performance in recovering defected images of specific scenes. However, filling holes involving multiple semantic categories remains challenging due to the obscure semantic boundaries and the mixture of different semantic textures. In this paper, we introduce coherence priors between the semantics and textures which make it possible to concentrate on completing separate textures in a semantic-wise manner. Specifically, we adopt a multi-scale joint optimization framework to first model the coherence priors and then accordingly interleavingly optimize image inpainting and semantic segmentation in a coarse-to-fine manner. A Semantic-Wise Attention Propagation (SWAP) module is devised to refine completed image textures across scales by exploring non-local semantic coherence, which effectively mitigates mix-up of textures. We also propose two coherence losses to constrain the consistency between the semantics and the inpainted image in terms of the overall structure and detailed textures. Experimental results demonstrate the superiority of our proposed method for challenging cases with complex holes."}}
{"id": "2vrgY0zxmy4", "cdate": 1577836800000, "mdate": 1631878534739, "content": {"title": "Motion Feedback Design for Video Frame Interpolation", "abstract": "This paper introduces a feedback-based approach to interpolate video frames involving small and fast-moving objects. Unlike the existing feedforward-based methods that estimate optical flow and synthesize in-between frames sequentially, we introduce a motion-oriented component that adds a feedback block to the existing multi-scale autoencoder pipeline, which feedbacks information of small objects shared between architectures of two different scales. We show that feeding this additional information enables more robust detection of optical flow caused by small objects in fast motion. Using experiments on various datasets, we show that the feedback mechanism allows our method to achieve state-of-the-art results, both qualitatively and quantitatively."}}
{"id": "FdmzSIpzgLu", "cdate": 1546300800000, "mdate": 1631878534739, "content": {"title": "Artist-Net: Decorating the Inferred Content With Unified Style for Image Inpainting", "abstract": "Recently, context learning networks have shown promise in filling large holes in natural images. These networks can decorate the predicted contents with high-frequency details by borrowing or copying neural information from the known region. However, this operation might introduce undesired content change in the synthesized region, especially when similar neural patterns cannot be found in the known region. To solve this problem, we present a network named Artist-Net to decompose an image into the content code and style code explicitly. The Artist-Net completes a corrupted image following the way an artist restores a damaged picture. It can produce more detailed content by inferring the content code of the corrupted images in the latent space since the dimension of the content space is lower than the original image. The Artist-Net can also keep style consistent over the entire image by decorating the inferred content code with the style code extracted from the known region. The experiments on multiple datasets, including structural and natural images demonstrate that the proposed network out-performs the existing ones in terms of content accuracy as well as texture details."}}
{"id": "iU-LCzMouoW", "cdate": 1514764800000, "mdate": 1631878534741, "content": {"title": "Edge-Aware Context Encoder for Image Inpainting", "abstract": "We present Edge-aware Context Encoder (E-CE): an image inpainting model which takes scene structure and context into account. Unlike previous CE which predicts the missing regions using context from entire image, E-CE learns to recover the texture according to edge structures, attempting to avoid context blending across boundaries. In our approach, edges are extracted from the masked image, and completed by a full-convolutional network. The completed edge map together with the original masked image are then input into the modified CE network to predict the missing region. The experiments demonstrate that E-CE can generate images with better shapes and structures than CE."}}
{"id": "ZrQW6L7RIzz", "cdate": 1483228800000, "mdate": 1631878534742, "content": {"title": "A sensitive object-oriented approach to big surveillance data compression for social security applications in smart cities", "abstract": "Surveillance has become a fairly common practice with the global boom in \u201csmart cities\u201d. How to efficiently store and manage the vast quantities of surveillance data is a persistent challenge in term..."}}
{"id": "JoFbkD15cc", "cdate": 1451606400000, "mdate": 1631878534889, "content": {"title": "Criminal Investigation Oriented Saliency Detection for Surveillance Videos", "abstract": "Detecting the salient regions, namely locating the key regions that contain rich clues, is of great significance for better mining and analyzing the crucial information in surveillance videos. Yet, to date, the existed saliency detection methods are mainly designed to fit human perception. Nevertheless, what we value most during in surveillance videos, i.e. criminal investigation attentive objects (CIAOs) such as pedestrians, human faces, vehicles and license plates, is often different from those sensitive to human vision in general situations. In this paper, we proposed criminal investigation oriented saliency detection method for surveillance videos. A criminal investigation attentive model (CIAM) is constructed to score the occurrence probabilities of CIAOs in spatial domain and novelly utilize score to represent saliency, thus making CIAO regions more salient than non-CIAO regions. In addition, we refine the spatial domain saliency map with the motion information in temporal domain to obtain the spatio-temporal saliency map that has high distinctiveness for regions of moving CIAOs, static CIAOs, moving non-CIAOs and static non-CIAOs. Experimental results on surveillance video datasets demonstrate that the proposed method outperforms the state-of-art saliency detection methods."}}
{"id": "Dlk6nL4xlbW", "cdate": 1451606400000, "mdate": 1631878534738, "content": {"title": "An Analysis-Oriented ROI Based Coding Approach on Surveillance Video Data", "abstract": "Driven by the growing amount of surveillance video data, intelligent video analysis has been applied to manipulate the stored videos automatically. As the most important method of video storage, the conventional coding method with high compression ratio severely degrades the video quality, which restrict the performance of intelligent analysis. In this paper, we propose an analysis-oriented region of interest (ROI) based coding approach to relieve this problem. We qualitatively analyze the effect of video compression on the performance of video analysis, such as feature similarity and object detection. Based on the analysis, we generate the ROI by the prior knowledge of interest objects rather than considering the characteristics of Human Visual System (HVS). Then, a weight-based rate control scheme is proposed to protect the quality of ROI by assigning more bits to encode it. Experimental results show that the proposed approach can reach 5.52% and 4.39% gains average over HEVC on the performance of feature similarity and object detection respectively under the same bitrate."}}
