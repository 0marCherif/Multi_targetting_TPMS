{"id": "ZaOG6ci_IP7", "cdate": 1663849826697, "mdate": null, "content": {"title": "kaBEDONN: posthoc eXplainable Artificial Intelligence with Data Ordered Neural Network", "abstract": "Different approaches to eXplainable Artificial Intelligence (XAI) have been explored including (1) the systematic study of the effect of individual training data sample on the final model (2) posthoc attribution methods that assign importance values to the components of each data sample. Combining concepts from both approaches, we introduce kaBEDONN, a system of ordered dataset coupled with a posthoc and model-agnostic method for querying \\textit{relevant} training data samples. These \\textit{relevant} data are intended as the explanations for model predictions that are both user-friendly and easily adjustable by developers. Explanations can thus be finetuned and damage control can be performed with ease."}}
{"id": "X55dLasnEcC", "cdate": 1663849810972, "mdate": null, "content": {"title": "Evaluating Weakly Supervised Object Localization Methods Right? A Study on Heatmap-based XAI and Neural Backed Decision Tree", "abstract": "Choe et al have investigated several aspects of Weakly Supervised Object Localization (WSOL) with only image label. They addressed the ill-posed nature of the problem and showed that WSOL has not significantly improved beyond the baseline method class activation mapping (CAM). We report the results of similar experiments on ResNet50 with some crucial differences: (1) we perform WSOL using heatmap-based eXplanaible AI (XAI) methods (2) our model is not class agnostic since we are interested in the XAI aspect as well. Under similar protocol, we find that XAI methods perform WSOL with very sub-standard MaxBoxAcc scores. The experiment is then repeated for the same model trained with Neural Backed Decision Tree (NBDT) and we found that vanilla CAM yields significantly better WSOL performance after NBDT training."}}
{"id": "E3gF8L-mmS3", "cdate": 1632875648487, "mdate": null, "content": {"title": "Use of small auxiliary networks and scarce data to improve the adversarial robustness of deep learning models", "abstract": "Deep Learning models for image classification are known to be vulnerable to adversarial examples. \nAdversarial training is one of the most effective ways to provide defense against such threats, however it is a cumbersome process which requires many data points and long computation times. \nIn a setting where only small amounts of data are available for this process, adversarial training may negatively impact the classification performance on clean images by overfitting on the small amount of data.\nThis would be undesirable, especially when a large pre-trained model with satisfactory performance on clean data is already available.\nWe propose a new strategy to make a previously-trained model more robust against adversarial attacks, using scarce data and without degrading its performance on clean samples.\nThe proposed strategy consists in freezing the parameters of the originally trained base model and adding small auxiliary networks along the architecture, which process the features to reduce the effect of any adversarial perturbation.\nThis method can be used to defend a model against any arbitrary attack.\nA practical advantage of using auxiliary networks is that no modifications on the originally trained base model is required. \nTherefore, it can serve as a patch or add on to fix large and expensive existing deep learning models with little additional resources.\nExperiments on the CIFAR10 dataset showed that using only $10\\%$ of the full training set, the proposed method was able to adequately defend the model against the AutoPGD attack while maintaining a classification accuracy on clean images outperforming the model with adversarial training by $7\\%$. Indeed, the proposed method still performs reasonably well compared to adversarial training using $1\\%$ of the full training set."}}
{"id": "-FP1-bBxOzv", "cdate": 1632875440155, "mdate": null, "content": {"title": "Self Reward Design with Fine-grained Interpretability", "abstract": "Transparency and fairness issues in Deep Reinforcement Learning may stem from the black-box nature of deep neural networks used to learn its policy, value functions etc. This paper proposes a way to circumvent the issues through the bottom-up design of neural networks (NN) with detailed interpretability, where each neuron or layer has its own meaning and utility that corresponds to humanly understandable concept. With deliberate design, we show that lavaland problems can be solved using NN model with few parameters. Furthermore, we introduce the Self Reward Design (SRD), inspired by the Inverse Reward Design, so that our interpretable design can (1) solve the problem by pure design (although imperfectly) (2) be optimized via SRD (3) perform avoidance of unknown states by recognizing the inactivations of neurons aggregated as the activation in \\(w_{unknown}\\)."}}
{"id": "xOHuV8s7Yl", "cdate": 1632875440082, "mdate": null, "content": {"title": "Two Instances of Interpretable Neural Network for Universal Approximations", "abstract": "This paper proposes two bottom-up interpretable neural network (NN) constructions for universal approximation, namely Triangularly-constructed NN (TNN) and Semi-Quantized Activation NN (SQANN). The notable properties are (1) resistance to catastrophic forgetting (2) existence of proof for arbitrarily high accuracies on training dataset (3) for an input x, users can identify specific samples of training data whose activation \"fingerprints\" are similar to that of x's activations. Users can also identify samples that are out of distribution."}}
{"id": "w3k1UdJ-DH8", "cdate": 1577836800000, "mdate": null, "content": {"title": "Assessment of the Efficacy of EEG-Based MI-BCI With Visual Feedback and EEG Correlates of Mental Fatigue for Upper-Limb Stroke Rehabilitation", "abstract": "Objective: This single-arm multisite trial investigates the efficacy of the neurostyle brain exercise therapy towards enhanced recovery (nBETTER) system, an electroencephalogram (EEG)-based motor imagery brain-computer interface (MI-BCI) employing visual feedback for upper-limb stroke rehabilitation, and the presence of EEG correlates of mental fatigue during BCI usage. Methods: A total of 13 recruited stroke patients underwent thrice-weekly nBETTER therapy coupled with standard arm therapy over six weeks. Upper-extremity Fugl-Meyer motor assessment (FMA) scores were measured at baseline (week 0), post-intervention (week 6), and follow-ups (weeks 12 and 24). In total, 11/13 patients (mean age 55.2 years old, mean post-stroke duration 333.7 days, mean baseline FMA 35.5) completed the study. Results: Significant FMA gains relative to baseline were observed at weeks 6 and 24. Retrospectively comparing to the standard arm therapy (SAT) control group and BCI with haptic knob (BCI-HK) intervention group from a previous similar study, the SAT group had no significant gains, whereas the BCI-HK group had significant gains at weeks 6, 12, and 24. EEG analysis revealed significant positive correlations between relative beta power and BCI performance in the frontal and central brain regions, suggesting that mental fatigue may contribute to poorer BCI performance. Conclusion: nBETTER, an EEG-based MI-BCI employing only visual feedback, helps stroke survivors sustain short-term FMA improvement. Analysis of EEG relative beta power indicates that mental fatigue may be present. Significance: This study adds nBETTER to the growing literature of safe and effective stroke rehabilitation MI-BCI, and suggests an additional fatigue-monitoring role in future such BCI."}}
{"id": "sU81KrbRBP", "cdate": 1577836800000, "mdate": null, "content": {"title": "Federated Transfer Learning for EEG Signal Classification", "abstract": "The success of deep learning (DL) methods in the Brain-Computer Interfaces (BCI) field for classification of electroencephalographic (EEG) recordings has been restricted by the lack of large datasets. Privacy concerns associated with EEG signals limit the possibility of constructing a large EEG-BCI dataset by the conglomeration of multiple small ones for jointly training machine learning models. Hence, in this paper, we propose a novel privacy-preserving DL architecture named federated transfer learning (FTL) for EEG classification that is based on the federated learning framework. Working with the single-trial covariance matrix, the proposed architecture extracts common discriminative information from multi-subject EEG data with the help of domain adaptation techniques. We evaluate the performance of the proposed architecture on the PhysioNet dataset for 2-class motor imagery classification. While avoiding the actual data sharing, our FTL approach achieves 2% higher classification accuracy in a subject-adaptive analysis. Also, in the absence of multi-subject data, our architecture provides 6% better accuracy compared to other state-of-the-art DL architectures."}}
{"id": "sMtMnKLlesi", "cdate": 1577836800000, "mdate": null, "content": {"title": "Towards a Fast Steady-State Visual Evoked Potentials (SSVEP) Brain-Computer Interface (BCI)", "abstract": "Steady-state visual evoked potentials (SSVEP) brain-computer interface (BCI) provides reliable responses leading to high accuracy and information throughput. But achieving high accuracy typically requires a relatively long time window of one second or more. Various methods were proposed to improve sub-second response accuracy through subject-specific training and calibration. Substantial performance improvements were achieved with tedious calibration and subject-specific training; resulting in the user's discomfort. So, we propose a training-free method by combining spatial-filtering and temporal alignment (CSTA) to recognize SSVEP responses in sub-second response time. CSTA exploits linear correlation and non-linear similarity between steady-state responses and stimulus templates with complementary fusion to achieve desirable performance improvements. We evaluated the performance of CSTA in terms of accuracy and Information Transfer Rate (ITR) in comparison with both training-based and training-free methods using two SSVEP data-sets. We observed that CSTA achieves the maximum mean accuracy of 97.43$\\pm$2.26 % and 85.71$\\pm$13.41 % with four-class and forty-class SSVEP data-sets respectively in sub-second response time in offline analysis. CSTA yields significantly higher mean performance (p<0.001) than the training-free method on both data-sets. Compared with training-based methods, CSTA shows 29.33$\\pm$19.65 % higher mean accuracy with statistically significant differences in time window less than 0.5 s. In longer time windows, CSTA exhibits either better or comparable performance though not statistically significantly better than training-based methods. We show that the proposed method brings advantages of subject-independent SSVEP classification without requiring training while enabling high target recognition performance in sub-second response time."}}
{"id": "o_qVaUQ6R_", "cdate": 1577836800000, "mdate": null, "content": {"title": "TSception: A Deep Learning Framework for Emotion Detection Using EEG", "abstract": "In this paper, we propose a deep learning framework, TSception, for emotion detection from electroencephalogram (EEG). TSception consists of temporal and spatial convolutional layers, which learn discriminative representations in the time and channel domains simultaneously. The temporal learner consists of multi-scale 1D convolutional kernels whose lengths are related to the sampling rate of the EEG signal, which learns multiple temporal and frequency representations. The spatial learner takes advantage of the asymmetry property of emotion responses at the frontal brain area to learn the discriminative representations from the left and right hemispheres of the brain. In our study, a system is designed to study the emotional arousal in an immersive virtual reality (VR) environment. EEG data were collected from 18 healthy subjects using this system to evaluate the performance of the proposed deep learning network for the classification of low and high emotional arousal states. The proposed method is compared with SVM, EEGNet, and LSTM. TSception achieves a high classification accuracy of 86.03%, which outperforms the prior methods significantly (p<0.05). The code is available at https://github.com/deepBrains/TSception"}}
{"id": "YoUpHaOwWjD", "cdate": 1577836800000, "mdate": null, "content": {"title": "A Brain-Computer Interface Framework Based on Compressive Sensing and Deep Learning", "abstract": "Compression of brain-computer interface (BCI) signals is significant to reduce transmission bandwidth to cloud/remote servers and to minimize storage cost. Precise reconstruction of the compressed signal is also crucial as these data are further used for spike detection and/or classification. The conventional compressive sensing (CS) techniques to reconstruct the compressed BCI signals are computationally expensive. There are several existing techniques for CS reconstruction, including block-sparse Bayesian learning and block-based CS, which also work to replace a reconstruction methodology of CS in medical imaging with deep learning (DL) techniques. DL can be helpful in reconstructing compressed BCI signals, including Electroencephalography (EEG) and Electrocorticography (ECoG). Pertinent to that, in this work, a convolutional neural network (CNN) based reconstruction framework has been proposed to reconstruct spike signals that has been highly compressed using the CS technique. An accuracy of 91.62% has been achieved over signals compressed at 90% compression rate, when compared with original signals using a cross-correlation technique."}}
