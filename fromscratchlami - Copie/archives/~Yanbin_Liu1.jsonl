{"id": "O-ncdx9cRB", "cdate": 1672531200000, "mdate": 1681698505786, "content": {"title": "Aligning Step-by-Step Instructional Diagrams to Video Demonstrations", "abstract": "Multimodal alignment facilitates the retrieval of instances from one modality when queried using another. In this paper, we consider a novel setting where such an alignment is between (i) instruction steps that are depicted as assembly diagrams (commonly seen in Ikea assembly manuals) and (ii) video segments from in-the-wild videos; these videos comprising an enactment of the assembly actions in the real world. To learn this alignment, we introduce a novel supervised contrastive learning method that learns to align videos with the subtle details in the assembly diagrams, guided by a set of novel losses. To study this problem and demonstrate the effectiveness of our method, we introduce a novel dataset: IAW for Ikea assembly in the wild consisting of 183 hours of videos from diverse furniture assembly collections and nearly 8,300 illustrations from their associated instruction manuals and annotated for their ground truth alignments. We define two tasks on this dataset: First, nearest neighbor retrieval between video segments and illustrations, and, second, alignment of instruction steps and the segments for each video. Extensive experiments on IAW demonstrate superior performances of our approach against alternatives."}}
{"id": "q-oWcTZhYnr", "cdate": 1640995200000, "mdate": 1681649721441, "content": {"title": "NeRFEditor: Differentiable Style Decomposition for Full 3D Scene Editing", "abstract": ""}}
{"id": "WK3xCKnB55", "cdate": 1640995200000, "mdate": 1681698506190, "content": {"title": "3D Brain and Heart Volume Generative Models: A Survey", "abstract": "Generative models such as generative adversarial networks and autoencoders have gained a great deal of attention in the medical field due to their excellent data generation capability. This paper provides a comprehensive survey of generative models for three-dimensional (3D) volumes, focusing on the brain and heart. A new and elaborate taxonomy of unconditional and conditional generative models is proposed to cover diverse medical tasks for the brain and heart: unconditional synthesis, classification, conditional synthesis, segmentation, denoising, detection, and registration. We provide relevant background, examine each task and also suggest potential future directions. A list of the latest publications will be updated on Github to keep up with the rapid influx of papers at https://github.com/csyanbin/3D-Medical-Generative-Survey."}}
{"id": "ULOYYEqFnfH", "cdate": 1640995200000, "mdate": 1681698505920, "content": {"title": "Diminishing Empirical Risk Minimization for Unsupervised Anomaly Detection", "abstract": "Unsupervised anomaly detection (AD) is a challenging task in realistic applications. Recently, there is an increasing trend to detect anomalies with deep neural networks (DNN). However, most popular deep AD detectors cannot protect the network from learning contaminated information brought by anomalous data, resulting in unsatisfactory detection performance and overfitting issues. In this work, we identify one reason that hinders most existing DNN-based anomaly detection methods from performing is the wide adoption of the Empirical Risk Minimization (ERM). ERM assumes that the performance of an algorithm on an unknown distribution can be approximated by averaging losses on the known training set. This averaging scheme thus ignores the distinctions between normal and anomalous instances. To break through the limitations of ERM, we propose a novel Diminishing Empirical Risk Minimization (DERM) framework. Specifically, DERM adaptively adjusts the impact of individual losses through a well-devised aggregation strategy. Theoretically, our proposed DERM can directly modify the gradient contribution of each individual loss in the optimization process to suppress the influence of outliers, leading to a robust anomaly detector. Empirically, DERM outperformed the state-of-the-art on the unsupervised AD benchmark consisting of 18 datasets."}}
{"id": "HcFe9XYe4p", "cdate": 1640995200000, "mdate": 1681698506118, "content": {"title": "Inflating 2D Convolution Weights for Efficient Generation of 3D Medical Images", "abstract": "The generation of three-dimensional (3D) medical images can have great application potential since it takes into account the 3D anatomical structure. There are two problems, however, that prevent effective training of a 3D medical generative model: (1) 3D medical images are very expensive to acquire and annotate, resulting in an insufficient number of training images, (2) a large number of parameters are involved in 3D convolution. To address both problems, we propose a novel GAN model called 3D Split&Shuffle-GAN. In order to address the 3D data scarcity issue, we first pre-train a two-dimensional (2D) GAN model using abundant image slices and inflate the 2D convolution weights to improve initialization of the 3D GAN. Novel 3D network architectures are proposed for both the generator and discriminator of the GAN model to significantly reduce the number of parameters while maintaining the quality of image generation. A number of weight inflation strategies and parameter-efficient 3D architectures are investigated. Experiments on both heart (Stanford AIMI Coronary Calcium) and brain (Alzheimer's Disease Neuroimaging Initiative) datasets demonstrate that the proposed approach leads to improved 3D images generation quality with significantly fewer parameters."}}
{"id": "FYumlRUuTvi", "cdate": 1640995200000, "mdate": 1681698505734, "content": {"title": "Feature-Robust Optimal Transport for High-Dimensional Data", "abstract": "Optimal transport is a machine learning problem with applications including distribution comparison, feature selection, and generative adversarial networks. In this paper, we propose feature-robust optimal transport (FROT) for high-dimensional data, which solves high-dimensional OT problems using feature selection to avoid the curse of dimensionality. Specifically, we find a transport plan with discriminative features. To this end, we formulate the FROT problem as a min\u2013max optimization problem. We then propose a convex formulation of the FROT problem and solve it using a Frank\u2013Wolfe-based optimization algorithm, whereby the subproblem can be efficiently solved using the Sinkhorn algorithm. Since FROT finds the transport plan from selected features, it is robust to noise features. To show the effectiveness of FROT, we propose using the FROT algorithm for the layer selection problem in deep neural networks for semantic correspondence. By conducting synthetic and benchmark experiments, we demonstrate that the proposed method can find a strong correspondence by determining important layers. We show that the FROT algorithm achieves state-of-the-art performance in real-world semantic correspondence datasets. Code can be found at https://github.com/Mathux/FROT ."}}
{"id": "85_jYKzHIUY", "cdate": 1640995200000, "mdate": 1681698506072, "content": {"title": "Diminishing Empirical Risk Minimization for Unsupervised Anomaly Detection", "abstract": "Unsupervised anomaly detection (AD) is a challenging task in realistic applications. Recently, there is an increasing trend to detect anomalies with deep neural networks (DNN). However, most popular deep AD detectors cannot protect the network from learning contaminated information brought by anomalous data, resulting in unsatisfactory detection performance and overfitting issues. In this work, we identify one reason that hinders most existing DNN-based anomaly detection methods from performing is the wide adoption of the Empirical Risk Minimization (ERM). ERM assumes that the performance of an algorithm on an unknown distribution can be approximated by averaging losses on the known training set. This averaging scheme thus ignores the distinctions between normal and anomalous instances. To break through the limitations of ERM, we propose a novel Diminishing Empirical Risk Minimization (DERM) framework. Specifically, DERM adaptively adjusts the impact of individual losses through a well-devised aggregation strategy. Theoretically, our proposed DERM can directly modify the gradient contribution of each individual loss in the optimization process to suppress the influence of outliers, leading to a robust anomaly detector. Empirically, DERM outperformed the state-of-the-art on the unsupervised AD benchmark consisting of 18 datasets."}}
{"id": "XzUThb_eUw-", "cdate": 1609459200000, "mdate": 1681698506413, "content": {"title": "Cross-aligned and Gumbel-refactored Autoencoders for Multi-view Anomaly Detection", "abstract": "Multi-view anomaly detection (AD) is a challenging task due to the complicated data distributions across different views. Specifically, there exist two types of anomalies in multi-view distributions: attribute anomaly that exhibits consistent anomalous pattern in each view and class anomaly that exhibits inconsistent traits (e.g., semantic label) across multiple views. Existing methods detect these anomalies in an unsupervised manner with the clustering assumption: normal data share consistent clustering structure across views while anomalous data exhibits inconsistent clusters across views. However, these methods would fail for complex multi-view data distributions where there is no obvious clusters. Moreover, existing models suffer from robustness since they are undermined by anomalies during training time. To get rid of the clustering assumption, we propose a Cross-aligned and Gumbel-refactored AutoEncoders (CGAEs) model to effectively detect two types of multi-view anomalies. In CGAEs, we devise a cross-reconstruction module to detect class anomaly by recovering one view from another view. Class anomalies would lead to high cross-reconstruction loss since they do not have the correct information in one view to generate another. We further design a view-alignment module to detect attribute anomaly by the alignment distance among multiple views in the latent space. Attribute anomalies possess large distances since they are less aligned due to fewer anomalous training instances. To handle the robustness issue, we propose a Gumbel-refactored reconstruction loss to replace the mean square error (MSE) in original autoencoders. The cross entropy loss is calculated between the discreterized input and Gumbel-sampled output, thus disregarding the irrelevant details to achieve model robustness. Experimental results validate the superiority of the proposed CGAEs model on both the benchmark datasets and real world datasets."}}
{"id": "SL5W2nHtUgc", "cdate": 1609459200000, "mdate": 1645807028292, "content": {"title": "LSMI-Sinkhorn: Semi-supervised Mutual Information Estimation with Optimal Transport", "abstract": "Estimating mutual information is an important statistics and machine learning problem. To estimate the mutual information from data, a common practice is preparing a set of paired samples $$\\{({\\boldsymbol{x}}_i,{\\boldsymbol{y}}_i)\\}_{i = 1}^n$$ $${\\mathop {\\sim }\\limits ^{\\mathrm {i.i.d.}}}p({\\boldsymbol{x}},{\\boldsymbol{y}})$$ . However, in many situations, it is difficult to obtain a large number of data pairs. To address this problem, we propose the semi-supervised Squared-loss Mutual Information (SMI) estimation method using a small number of paired samples and the available unpaired ones. We first represent SMI through the density ratio function, where the expectation is approximated by the samples from marginals and its assignment parameters. The objective is formulated using the optimal transport problem and quadratic programming. Then, we introduce the Least-Squares Mutual Information with Sinkhorn (LSMI-Sinkhorn) algorithm for efficient optimization. Through experiments, we first demonstrate that the proposed method can estimate the SMI without a large number of paired samples. Then, we show the effectiveness of the proposed LSMI-Sinkhorn algorithm on various types of machine learning problems such as image matching and photo album summarization. Code can be found at https://github.com/csyanbin/LSMI-Sinkhorn ."}}
{"id": "KHTcW2IVpE", "cdate": 1609459200000, "mdate": 1681698506077, "content": {"title": "Learning with Limited Labeled Data", "abstract": "The recent success of convolutional neural networks (CNNs) relies on a large amount of annotated training data. However, many research problems suffer from the scarcity of labeled data, since annotating a large number of data is time-consuming or infeasible. This dissertation focuses on learning with limited labeled data and addresses two problems: few-shot classification and object matching. For few-shot classification, a transductive propagation network (TPN) is first proposed to deal with the low-data issue. The idea is learning to propagate labels from labeled instances to unlabeled ones by exploiting the manifold structure of the data. Then, online feature selection with imbalanced streaming data, as a special few-shot problem, is tackled by the proposed adaptive sparse confidence-weighted (ASCW) algorithm. This algorithm utilizes the confidence-weighted (CW) learning to explore the feature correlation and maintains multiple confidence-weighted learners with different costs to address the imbalanced issue. For object matching, since the labeled matching pairs are usually scarce, finding the potential matching among unpaired objects is important. Based on this idea, two models are proposed to solve object matching with limited labeled data. First, a squared-loss mutual information (SMI) estimator is proposed to utilize a small number of paired samples and the available unpaired ones. The estimator is formulated with optimal transport and quadratic programming in an iterative way. Second, the specific object matching problem, namely semantic correspondence, can be solved in a unified optimal transport framework. The many to one matching and background matching issues are well addressed in the proposed framework. To evaluate the effectiveness of the aforementioned algorithms with limited labeled data, extensive experiments are conducted on various benchmark datasets, ranging from the UCI machine learning repository, few-shot image classification datasets, semantic correspondence datasets, etc."}}
