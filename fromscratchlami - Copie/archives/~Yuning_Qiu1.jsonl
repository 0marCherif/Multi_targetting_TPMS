{"id": "w7wQt3yYmDv", "cdate": 1640995200000, "mdate": 1682317848933, "content": {"title": "Bayesian Robust Tensor Ring Model for Incomplete Multiway Data", "abstract": "Robust tensor completion (RTC) aims to recover a low-rank tensor from its incomplete observation with outlier corruption. The recently proposed tensor ring (TR) model has demonstrated superiority in solving the RTC problem. However, the existing methods either require a pre-assigned TR rank or aggressively pursue the minimum TR rank, thereby often leading to biased solutions in the presence of noise. In this paper, a Bayesian robust tensor ring decomposition (BRTR) method is proposed to give more accurate solutions to the RTC problem, which can avoid exquisite selection of the TR rank and penalty parameters. A variational Bayesian (VB) algorithm is developed to infer the probability distribution of posteriors. During the learning process, BRTR can prune off slices of core tensor with marginal components, resulting in automatic TR rank detection. Extensive experiments show that BRTR can achieve significantly improved performance than other state-of-the-art methods."}}
{"id": "vENdodI3xW", "cdate": 1640995200000, "mdate": 1682317848934, "content": {"title": "A Generalized Graph Regularized Non-Negative Tucker Decomposition Framework for Tensor Data Representation", "abstract": "Non-negative Tucker decomposition (NTD) is one of the most popular techniques for tensor data representation. To enhance the representation ability of NTD by multiple intrinsic cues, that is, manifold structure and supervisory information, in this article, we propose a generalized graph regularized NTD (GNTD) framework for tensor data representation. We first develop the unsupervised GNTD (UGNTD) method by constructing the nearest neighbor graph to maintain the intrinsic manifold structure of tensor data. Then, when limited must-link and cannot-link constraints are given, unlike most existing semisupervised learning methods that only use the pregiven supervisory information, we propagate the constraints through the entire dataset and then build a semisupervised graph weight matrix by which we can formulate the semisupervised GNTD (SGNTD). Moreover, we develop a fast and efficient alternating proximal gradient-based algorithm to solve the optimization problem and show its convergence and correctness. The experimental results on unsupervised and semisupervised clustering tasks using four image datasets demonstrate the effectiveness and high efficiency of the proposed methods."}}
{"id": "rQBTiUMNe7", "cdate": 1640995200000, "mdate": 1682317848935, "content": {"title": "A High-Order Tensor Completion Algorithm Based on Fully-Connected Tensor Network Weighted Optimization", "abstract": "Tensor completion aims at recovering missing data, and it is one of the popular concerns in deep learning and signal processing. Among the higher-order tensor decomposition algorithms, the recently proposed fully-connected tensor network decomposition (FCTN) algorithm is the most advanced. In this paper, by leveraging the superior expression of the fully-connected tensor network (FCTN) decomposition, we propose a new tensor completion method named the fully connected tensor network weighted optimization (FCTN-WOPT). The algorithm performs a composition of the completed tensor by initializing the factors from the FCTN decomposition. We build a loss function with the weight tensor, the completed tensor and the incomplete tensor together, and then update the completed tensor using the lbfgs gradient descent algorithm to reduce the spatial memory occupation and speed up iterations. Finally we test the completion with synthetic data and real data (both image data and video data) and the results show the advanced performance of our FCTN-WOPT when it is applied to higher-order tensor completion."}}
{"id": "laCD3RkxxA", "cdate": 1640995200000, "mdate": 1682317849317, "content": {"title": "A high-order tensor completion algorithm based on Fully-Connected Tensor Network weighted optimization", "abstract": "Tensor completion aimes at recovering missing data, and it is one of the popular concerns in deep learning and signal processing. Among the higher-order tensor decomposition algorithms, the recently proposed fully-connected tensor network decomposition (FCTN) algorithm is the most advanced. In this paper, by leveraging the superior expression of the fully-connected tensor network (FCTN) decomposition, we propose a new tensor completion method named the fully connected tensor network weighted optization(FCTN-WOPT). The algorithm performs a composition of the completed tensor by initialising the factors from the FCTN decomposition. We build a loss function with the weight tensor, the completed tensor and the incomplete tensor together, and then update the completed tensor using the lbfgs gradient descent algorithm to reduce the spatial memory occupation and speed up iterations. Finally we test the completion with synthetic data and real data (both image data and video data) and the results show the advanced performance of our FCTN-WOPT when it is applied to higher-order tensor completion."}}
{"id": "l0OV2V8yvn", "cdate": 1640995200000, "mdate": 1682317848934, "content": {"title": "Multi-Aspect Streaming Tensor Ring Completion for Dynamic Incremental Data", "abstract": "As the volume of real-world data with numerous missing entries continues to grow rapidly, tensor completion has been a powerful tool to enhance such flawed data analysis. While existing methods mainly consider static data, there is a great need to deal with streaming data. In this letter, a multi-aspect streaming tensor ring completion (MASTR) method is proposed, where the low-rank tensor ring (TR) model is exploited to capture subspace information and transfer high-order correlations between multiple sub-tensors. Experimental results on synthetic data, hyperspectral data and video data demonstrate superior recovery performance compared to state-of-the-art methods."}}
{"id": "hQutPyaTKEz", "cdate": 1640995200000, "mdate": 1681717828803, "content": {"title": "Imbalanced low-rank tensor completion via latent matrix factorization", "abstract": ""}}
{"id": "XOpJT7iCYd", "cdate": 1640995200000, "mdate": 1682317849317, "content": {"title": "A dynamic hypergraph regularized non-negative tucker decomposition framework for multiway data analysis", "abstract": "Non-negative tensor decomposition has achieved significant success in machine learning due to its superiority in extracting the non-negative parts-based features and physically meaningful latent components from high-order data. To improve its representation ability, hypergraph has been incorporated into the tensor decomposition model to capture the nonlinear manifold structure of data. However, previous hypergraph regularized tensor decomposition methods rely on the original data space. This may result in inaccurate manifold structure and representation performance degeneration when original data suffer from noise corruption. To solve these problems, in this paper, we propose a dynamic hypergraph regularized non-negative Tucker decomposition (DHNTD) method for multiway data analysis. Specifically, to take full advantage of the multilinear structure and nonlinear manifold of tensor data, we learn the dynamic hypergraph and non-negative low-dimensional representation in a unified framework. Moreover, we develop a multiplicative update (MU) algorithm to solve our optimization problem and theoretically prove its convergence. Experimental results in clustering tasks using six image datasets demonstrate the superiority of our proposed method compared with the state-of-the-art methods."}}
{"id": "TsOkABQ9wZJ", "cdate": 1640995200000, "mdate": 1681717828280, "content": {"title": "Efficient Tensor Robust PCA Under Hybrid Model of Tucker and Tensor Train", "abstract": "Tensor robust principal component analysis (TRPCA) is a fundamental model in machine learning and computer vision. Recently, tensor train (TT) decomposition has been verified effective to capture the global low-rank correlation for tensor recovery tasks. However, due to the large-scale tensor data in real-world applications, existing TRPCA models often suffer from high computational complexity. In this letter, we propose an efficient TRPCA under hybrid model of Tucker and TT. Specifically, in theory we reveal that TT nuclear norm (TTNN) of the original big tensor can be equivalently converted to that of a much smaller tensor via a Tucker compression format, thereby significantly reducing the computational cost of singular value decomposition (SVD). Numerical experiments on both synthetic and real-world tensor data verify the superiority of the proposed model."}}
{"id": "KjbQ0BeFO-z", "cdate": 1640995200000, "mdate": 1682317848809, "content": {"title": "Spatial Information Regularized Tensor Decomposition Framework for Super-Resolution Reconstruction of Medical MRI and Radiographs", "abstract": "Super-resolution reconstruction of medical images effectually enhances visual qualities to provide clear visions on anatomical structures. However, the spatial information, which abounds in low-resolution images, has received scant attention in the task of super-resolution, resulting in suppressed reconstruction qualities. This paper brings the spatial information into effective action by virtue of high-dimensional structures of tensor-format data, and presents a method named <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">Tensor Decomposition based medical Image Super-resolution reconstruction</i> (TDIS). In particular, TDIS employs tensors to preserve rich image spatial information and effectually processes the spatial information contained in image tensors by reformulating transposed convolutional layers using tensor decomposition. Moreover, TDIS provides tensor based error terms to capture spatial differences between generated and target images to reduce visual contrasts between them. Experimental results about reconstructing a range of medical images empirically demonstrate the competence of TDIS compared to the state-of-the-art methods."}}
{"id": "GY55Ac8dk8", "cdate": 1640995200000, "mdate": 1681717828701, "content": {"title": "Noisy Tensor Completion via Low-rank Tensor Ring", "abstract": "Tensor completion is a fundamental tool for incomplete data analysis, where the goal is to predict missing entries from partial observations. However, existing methods often make the explicit or implicit assumption that the observed entries are noise-free to provide a theoretical guarantee of exact recovery of missing entries, which is quite restrictive in practice. To remedy such drawbacks, this paper proposes a novel noisy tensor completion model, which complements the incompetence of existing works in handling the degeneration of high-order and noisy observations. Specifically, the tensor ring nuclear norm (TRNN) and least-squares estimator are adopted to regularize the underlying tensor and the observed entries, respectively. In addition, a non-asymptotic upper bound of estimation error is provided to depict the statistical performance of the proposed estimator. Two efficient algorithms are developed to solve the optimization problem with convergence guarantee, one of which is specially tailored to handle large-scale tensors by replacing the minimization of TRNN of the original tensor equivalently with that of a much smaller one in a heterogeneous tensor decomposition framework. Experimental results on both synthetic and real-world data demonstrate the effectiveness and efficiency of the proposed model in recovering noisy incomplete tensor data compared with state-of-the-art tensor completion models."}}
