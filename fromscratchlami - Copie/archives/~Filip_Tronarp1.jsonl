{"id": "jBzMnpMhQb", "cdate": 1640995200000, "mdate": 1681742095259, "content": {"title": "Fenrir: Physics-Enhanced Regression for Initial Value Problems", "abstract": "We show how probabilistic numerics can be used to convert an initial value problem into a Gauss\u2013Markov process parametrised by the dynamics of the initial value problem. Consequently, the often dif..."}}
{"id": "iA8r6snHcu", "cdate": 1640995200000, "mdate": 1682670036927, "content": {"title": "Continuous-Discrete Filtering and Smoothing on Submanifolds of Euclidean Space", "abstract": "In this paper the issue of filtering and smoothing in continuous discrete time is studied when the state variable evolves in some submanifold of Euclidean space, which may not have the usual Lebesgue measure. Formal expressions for prediction and smoothing problems are reviewed, which agree with the classical results except that the formal adjoint of the generator is different in general. These results are used to generalise the projection approach to filtering and smoothing to the case when the state variable evolves in some submanifold that lacks a Lebesgue measure. The approach is used to develop projection filters and smoothers based on the von Mises\u2013Fisher distribution, which are shown to be outperform Gaussian estimators both in terms of estimation accuracy and computational speed in simulation experiments involving the tracking of a gravity vector."}}
{"id": "cHZVdl8_1CN", "cdate": 1640995200000, "mdate": 1681742095259, "content": {"title": "Pick-and-Mix Information Operators for Probabilistic ODE Solvers", "abstract": "Probabilistic numerical solvers for ordinary differential equations compute posterior distributions over the solution of an initial value problem via Bayesian inference. In this paper, we leverage their probabilistic formulation to seamlessly include additional information as general likelihood terms. We show that second-order differential equations should be directly provided to the solver, instead of transforming the problem to first order. Additionally, by including higher-order information or physical conservation laws in the model, solutions become more accurate and more physically meaningful. Lastly, we demonstrate the utility of flexible information operators by solving differential-algebraic equations. In conclusion, the probabilistic formulation of numerical solvers offers a flexible way to incorporate various types of information, thus improving the resulting solutions."}}
{"id": "WpPY-rcYCI", "cdate": 1640995200000, "mdate": 1681710340299, "content": {"title": "Orthonormal Expansions for Translation-Invariant Kernels", "abstract": "We present a general Fourier analytic technique for constructing orthonormal basis expansions of translation-invariant kernels from orthonormal bases of $\\mathscr{L}_2(\\mathbb{R})$. This allows us to derive explicit expansions on the real line for (i) Mat\\'ern kernels of all half-integer orders in terms of associated Laguerre functions, (ii) the Cauchy kernel in terms of rational functions, and (iii) the Gaussian kernel in terms of Hermite functions."}}
{"id": "SnNZOjgQSxq", "cdate": 1640995200000, "mdate": 1645715616491, "content": {"title": "Fenrir: Physics-Enhanced Regression for Initial Value Problems", "abstract": "We show how probabilistic numerics can be used to convert an initial value problem into a Gauss--Markov process parametrised by the dynamics of the initial value problem. Consequently, the often difficult problem of parameter estimation in ordinary differential equations is reduced to hyperparameter estimation in Gauss--Markov regression, which tends to be considerably easier. The method's relation and benefits in comparison to classical numerical integration and gradient matching approaches is elucidated. In particular, the method can, in contrast to gradient matching, handle partial observations, and has certain routes for escaping local optima not available to classical numerical integration. Experimental results demonstrate that the method is on par or moderately better than competing approaches."}}
{"id": "r-7_ixXHl5", "cdate": 1609459200000, "mdate": 1645715616501, "content": {"title": "Pick-and-Mix Information Operators for Probabilistic ODE Solvers", "abstract": "Probabilistic numerical solvers for ordinary differential equations compute posterior distributions over the solution of an initial value problem via Bayesian inference. In this paper, we leverage their probabilistic formulation to seamlessly include additional information as general likelihood terms. We show that second-order differential equations should be directly provided to the solver, instead of transforming the problem to first order. Additionally, by including higher-order information or physical conservation laws in the model, solutions become more accurate and more physically meaningful. Lastly, we demonstrate the utility of flexible information operators by solving differential-algebraic equations. In conclusion, the probabilistic formulation of numerical solvers offers a flexible way to incorporate various types of information, thus improving the resulting solutions."}}
{"id": "UZdRC_8nnCr", "cdate": 1609459200000, "mdate": 1681710340321, "content": {"title": "A Probabilistic Taylor Expansion with Applications in Filtering and Differential Equations", "abstract": "We study a class of Gaussian processes for which the posterior mean, for a particular choice of data, replicates a truncated Taylor expansion of any order. The data consists of derivative evaluations at the expansion point and the prior covariance kernel belongs to the class of Taylor kernels, which can be written in a certain power series form. This permits statistical modelling of the uncertainty in a variety of algorithms that exploit first and second order Taylor expansions. To demonstrate the utility of this Gaussian process model we introduce new probabilistic versions of the classical extended Kalman filter for non-linear state estimation and the Euler method for solving ordinary differential equations."}}
{"id": "B8T6-neZt33", "cdate": 1609459200000, "mdate": 1682670037036, "content": {"title": "Bayesian ODE solvers: the maximum a posteriori estimate", "abstract": "There is a growing interest in probabilistic numerical solutions to ordinary differential equations. In this paper, the maximum a posteriori estimate is studied under the class of $$\\nu $$ \u03bd times differentiable linear time-invariant Gauss\u2013Markov priors, which can be computed with an iterated extended Kalman smoother. The maximum a posteriori estimate corresponds to an optimal interpolant in the reproducing kernel Hilbert space associated with the prior, which in the present case is equivalent to a Sobolev space of smoothness $$\\nu +1$$ \u03bd + 1 . Subject to mild conditions on the vector field, convergence rates of the maximum a posteriori estimate are then obtained via methods from nonlinear analysis and scattered data approximation. These results closely resemble classical convergence results in the sense that a $$\\nu $$ \u03bd times differentiable prior process obtains a global order of $$\\nu $$ \u03bd , which is demonstrated in numerical examples."}}
{"id": "1Rd2UePcLbI", "cdate": 1609459200000, "mdate": null, "content": {"title": "Calibrated Adaptive Probabilistic ODE Solvers", "abstract": "Probabilistic solvers for ordinary differential equations assign a posterior measure to the solution of an initial value problem. The joint covariance of this distribution provides an estimate of the (global) approximation error. The contraction rate of this error estimate as a function of the solver\u2019s step-size identifies it as a well-calibrated worst-case error, but its explicit numerical value for a certain step size is not automatically a good estimate of the explicit error. Addressing this issue, we introduce, discuss, and assess several probabilistically motivated ways to calibrate the uncertainty estimate. Numerical experiments demonstrate that these calibration methods interact efficiently with adaptive step-size selection, resulting in descriptive, and efficiently computable posteriors. We demonstrate the efficiency of the methodology by benchmarking against the classic, widely used Dormand-Prince 4/5 Runge-Kutta method."}}
{"id": "heTKIMX85o0", "cdate": 1577836800000, "mdate": 1682670037036, "content": {"title": "State-Space Gaussian Process for Drift Estimation in Stochastic Differential Equations", "abstract": "This paper is concerned with the estimation of unknown drift functions of stochastic differential equations (SDEs) from observations of their sample paths. We propose to formulate this as a non-parametric Gaussian process regression problem and use an Ito-Taylor expansion for approximating the SDE. To address the computational complexity problem of Gaussian process regression, we cast the model in an equivalent state-space representation, such that (non-linear) Kalman filters and smoothers can be used. The benefit of these methods is that computational complexity scales linearly with respect to the number of measurements and hence the method remains tractable also with large amounts of data. The overall complexity of the proposed method is O(N log N), where N is the number of measurements, due to the requirement of sorting the input data. We evaluate the performance of the proposed method using simulated data as well as with real-data applications to sunspot activity and electromyography."}}
