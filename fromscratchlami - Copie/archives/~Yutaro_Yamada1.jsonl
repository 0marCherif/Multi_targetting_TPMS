{"id": "eHrqmewX1B-", "cdate": 1663850300363, "mdate": null, "content": {"title": "Can Wikipedia Help Offline Reinforcement Learning?", "abstract": "Fine-tuning reinforcement learning (RL) models has been challenging because of a lack of large scale off-the-shelf datasets as well as high variance in transferability among different environments. Recent work has looked at tackling offline RL from the perspective of sequence modeling with improved results as result of the introduction of the Transformer architecture. However, when the model is trained from scratch, it suffers from slow convergence speeds. In this paper, we look to take advantage of this formulation of reinforcement learning as sequence modeling and investigate the transferability of pre-trained sequence models on other domains (vision, language) when finetuned on offline RL tasks (control, games). To this end, we also propose techniques to improve transfer between these domains. Results show consistent performance gains in terms of both convergence speed and reward on a variety of environments, accelerating training by 3-6x and achieving state-of-the-art performance in a variety of tasks using Wikipedia-pretrained and GPT2 language models. We hope that this work not only brings light to the potentials of leveraging generic sequence modeling techniques and pre-trained models for RL, but also inspires future work on sharing knowledge between generative modeling tasks of completely different domains."}}
{"id": "qEz5Z3qP9pu", "cdate": 1640995200000, "mdate": 1668670220978, "content": {"title": "Can Wikipedia Help Offline Reinforcement Learning?", "abstract": "Fine-tuning reinforcement learning (RL) models has been challenging because of a lack of large scale off-the-shelf datasets as well as high variance in transferability among different environments. Recent work has looked at tackling offline RL from the perspective of sequence modeling with improved results as result of the introduction of the Transformer architecture. However, when the model is trained from scratch, it suffers from slow convergence speeds. In this paper, we look to take advantage of this formulation of reinforcement learning as sequence modeling and investigate the transferability of pre-trained sequence models on other domains (vision, language) when finetuned on offline RL tasks (control, games). To this end, we also propose techniques to improve transfer between these domains. Results show consistent performance gains in terms of both convergence speed and reward on a variety of environments, accelerating training by 3-6x and achieving state-of-the-art performance in a variety of tasks using Wikipedia-pretrained and GPT2 language models. We hope that this work not only brings light to the potentials of leveraging generic sequence modeling techniques and pre-trained models for RL, but also inspires future work on sharing knowledge between generative modeling tasks of completely different domains."}}
{"id": "pX114VVUfP4", "cdate": 1640995200000, "mdate": 1668670220978, "content": {"title": "Does Robustness on ImageNet Transfer to Downstream Tasks?", "abstract": "As clean ImageNet accuracy nears its ceiling, the re-search community is increasingly more concerned about ro-bust accuracy under distributional shifts. While a variety of methods have been proposed to robustify neural networks, these techniques often target models trained on ImageNet classification. At the same time, it is a common practice to use ImageNet pretrained backbones for downstream tasks such as object detection, semantic segmentation, and image classification from different domains. This raises a question: Can these robust image classifiers transfer robustness to downstream tasks? For object detection and semantic segmentation, we find that a vanilla Swin Transformer, a variant of Vision Transformer tailored for dense prediction tasks, transfers robustness better than Convolutional Neu-ral Networks that are trained to be robust to the corrupted version of ImageNet. For CIFAR10 classification, we find that models that are robustified for ImageNet do not re-tain robustness when fully fine-tuned. These findings sug-gest that current robustification techniques tend to empha-size ImageNet evaluations. Moreover, network architecture is a strong source of robustness when we consider transfer learning."}}
{"id": "2OU0qmy4JnC", "cdate": 1634055190829, "mdate": null, "content": {"title": "Exploiting 3D Shape Bias towards Robust Vision", "abstract": "Robustness research in machine vision faces a challenge. Many variants of ImageNet-scale robustness benchmarks have been proposed, only to reveal that current vision systems fail under distributional shifts. Although aiming for higher robustness accuracy on these benchmarks is important, we also observe that simply using larger models and larger training datasets may not lead to true robustness, demanding further innovation. To tackle the problem from a new perspective, we encourage closer collaboration between the robustness and 3D vision communities. This proposal is inspired by human vision, which is surprisingly robust to environmental variation, including both naturally occurring disturbances and artificial corruptions. We hypothesize that such robustness, at least in part, arises from our ability to infer 3D geometry from 2D retinal projections. In this work, we take a first step toward testing this hypothesis by viewing 3D reconstruction as a pretraining method for building more robust vision systems. We introduce a novel dataset called Geon3D, which is derived from objects that emphasize variation across shape features that the human visual system is thought to be particularly sensitive. This dataset enables, for the first time, a controlled setting where we can isolate the effect of ``3D shape bias'' in robustifying neural networks, and informs new approaches for increasing robustness by exploiting 3D vision tasks. Using Geon3D, we find that CNNs pretrained on 3D reconstruction are more resilient to viewpoint change, rotation, and shift than regular CNNs. Further, when combined with adversarial training, 3D reconstruction pretrained models improve adversarial and common corruption robustness over vanilla adversarially-trained models. We hope that our findings and dataset will encourage exploitation of synergies between the robustness researchers, 3D computer vision community, and computational perception researchers in cognitive science, paving a way for achieving human-like robustness under complex, real-world stimuli conditions."}}
{"id": "S-oyLlQ1i-7", "cdate": 1632875662837, "mdate": null, "content": {"title": "Geon3D: Exploiting 3D Shape Bias towards Building Robust Machine Vision", "abstract": "Robustness research in machine vision faces a challenge. Many variants of ImageNet-scale robustness benchmarks have been proposed, only to reveal that current vision systems fail under distributional shifts. Although aiming for higher robustness accuracy on these benchmarks is important, we also observe that simply using larger models and larger training datasets may not lead to true robustness, demanding further innovation. To tackle the problem from a new perspective, we encourage closer collaboration between the robustness and 3D vision communities. This proposal is inspired by human vision, which is surprisingly robust to environ-mental variation, including both naturally occurring disturbances (e.g., fog, snow, occlusion) and artificial corruptions (e.g., adversarial examples). We hypothesize that such robustness, at least in part, arises from our ability to infer 3D geometry from 2D retinal projections---the ability to go from images to their underlying causes, including the 3D scene. In this work, we take a first step toward testing this hypothesis by viewing 3D reconstruction as a pretraining method for building more robust vision systems. We introduce a novel dataset called Geon3D, which is derived from objects that emphasize variation across shape features that the human visual system is thought to be particularly sensitive. This dataset enables, for the first time, a controlled setting where we can isolate the effect of \u201c3D shape bias\u201d in robustifying neural networks, and informs new approaches for increasing robustness by exploiting 3D vision tasks.  Using Geon3D, we find that CNNs pretrained on 3D reconstruction are more resilient to viewpoint change, rotation, and shift than regular CNNs. Further, when combined with adversarial training, 3D reconstruction pretrained models improve adversarial and common corruption robustness over vanilla adversarially-trained models. We hope that our findings and dataset will encourage exploitation of synergies between the robustness researchers, 3D computer vision community, and computational perception researchers in cognitive science, paving a way for achieving human-like robustness under complex, real-world stimuli conditions."}}
{"id": "8HkbjXqbAnz", "cdate": 1623131443193, "mdate": null, "content": {"title": "Geon3D: Benchmarking 3D Shape Bias towards Building Robust Machine Vision", "abstract": "Human vision, unlike existing machine vision systems, is surprisingly robust to environmental variation, including both naturally occuring disturbances (e.g., fog, snow, occlusion) and artificial corruptions (e.g., adversarial examples). Such robustness, at least in part, arises from our ability to infer 3D geometry from 2D retinal projections---the ability to go from images to their underlying causes, including the 3D scene. How can we design machine learning systems with such strong shape bias? In this work, we view 3D reconstruction as a pretraining method for building more robust vision systems. Recent studies explore the role of shape bias in the robustness of vision models. However, most current approaches to increase shape bias based on ImageNet take an indirect approach, attempting to instead reduce texture bias via structured data augmentation. These approaches do not directly nor fully exploit the relationship between 2D features and their underlying 3D shapes. To fill this gap, we introduce a novel dataset called Geon3D, which is derived from objects that emphasize variation across shape features that the human visual system is thought to be particularly sensitive. This dataset enables, for the first time, a controlled setting where we can isolate the effect of ``3D shape bias'' in robustifying neural networks, and informs more direct approaches to increase shape bias by exploiting 3D vision tasks. Using Geon3D, we find that CNNs pretrained on 3D reconstruction are more resilient to viewpoint change, rotation, and shift than regular CNNs. Further, when combined with adversarial training, 3D reconstruction pretrained models improve adversarial and common corruption robustness over vanilla adversarially-trained models. This suggests that incorporating 3D shape bias is a promising direction for building robust machine vision systems."}}
{"id": "PbavmHH_hex", "cdate": 1609459200000, "mdate": 1668670220981, "content": {"title": "Support Recovery with Stochastic Gates: Theory and Application for Linear Models", "abstract": "Consider the problem of simultaneous estimation and support recovery of the coefficient vector in a linear data model with additive Gaussian noise. We study the problem of estimating the model coefficients based on a recently proposed non-convex regularizer, namely the stochastic gates (STG) [Yamada et al. 2020]. We suggest a new projection-based algorithm for solving the STG regularized minimization problem, and prove convergence and support recovery guarantees of the STG-estimator for a range of random and non-random design matrix setups. Our new algorithm has been shown to outperform the existing STG algorithm and other classical estimators for support recovery in various real and synthetic data analyses."}}
{"id": "M6lWmQmchy9", "cdate": 1577836800000, "mdate": 1668670220979, "content": {"title": "Feature Selection using Stochastic Gates", "abstract": "Feature selection problems have been extensively studied in the setting of linear estimation (e.g. LASSO), but less emphasis has been placed on feature selection for non-linear functions. In this s..."}}
{"id": "B1lda1HtvB", "cdate": 1569439679724, "mdate": null, "content": {"title": "Feature Selection using Stochastic Gates", "abstract": "Feature selection problems have been extensively studied in the setting of\nlinear estimation, for instance LASSO, but less emphasis has been placed on\nfeature selection for non-linear functions. In this study, we propose a method\nfor feature selection in high-dimensional non-linear function estimation\nproblems. The new procedure is based on directly penalizing the $\\ell_0$ norm of\nfeatures, or the count of the number of selected features. Our $\\ell_0$ based regularization relies on a continuous relaxation of the Bernoulli distribution, which\nallows our model to learn the parameters of the approximate Bernoulli\ndistributions via gradient descent. The proposed framework simultaneously learns\na non-linear regression or classification function while selecting a small\nsubset of features. We provide an information-theoretic justification for\nincorporating Bernoulli distribution into our approach. Furthermore, we evaluate\nour method using synthetic and real-life data and demonstrate that our approach\noutperforms other embedded methods in terms of predictive performance and feature selection."}}
{"id": "j8TKdPxywY", "cdate": 1514764800000, "mdate": 1668670220979, "content": {"title": "Defending against Adversarial Images using Basis Functions Transformations", "abstract": "We study the effectiveness of various approaches that defend against adversarial attacks on deep networks via manipulations based on basis function representations of images. Specifically, we experiment with low-pass filtering, PCA, JPEG compression, low resolution wavelet approximation, and soft-thresholding. We evaluate these defense techniques using three types of popular attacks in black, gray and white-box settings. Our results show JPEG compression tends to outperform the other tested defenses in most of the settings considered, in addition to soft-thresholding, which performs well in specific cases, and yields a more mild decrease in accuracy on benign examples. In addition, we also mathematically derive a novel white-box attack in which the adversarial perturbation is composed only of terms corresponding a to pre-determined subset of the basis functions, of which a \"low frequency attack\" is a special case."}}
