{"id": "ZJx2oc6fxPc", "cdate": 1672531200000, "mdate": 1681735171835, "content": {"title": "An Extended Sequence Tagging Vocabulary for Grammatical Error Correction", "abstract": "We extend a current sequence-tagging approach to Grammatical Error Correction (GEC) by introducing specialised tags for spelling correction and morphological inflection using the SymSpell and LemmInflect algorithms. Our approach improves generalisation: the proposed new tagset allows a smaller number of tags to correct a larger range of errors. Our results show a performance improvement both overall and in the targeted error categories. We further show that ensembles trained with our new tagset outperform those trained with the baseline tagset on the public BEA benchmark."}}
{"id": "OxeGqpaWymD", "cdate": 1672531200000, "mdate": 1681735171685, "content": {"title": "Modelling Temporal Document Sequences for Clinical ICD Coding", "abstract": "Past studies on the ICD coding problem focus on predicting clinical codes primarily based on the discharge summary. This covers only a small fraction of the notes generated during each hospital stay and leaves potential for improving performance by analysing all the available clinical notes. We propose a hierarchical transformer architecture that uses text across the entire sequence of clinical notes in each hospital stay for ICD coding, and incorporates embeddings for text metadata such as their position, time, and type of note. While using all clinical notes increases the quantity of data substantially, superconvergence can be used to reduce training costs. We evaluate the model on the MIMIC-III dataset. Our model exceeds the prior state-of-the-art when using only discharge summaries as input, and achieves further performance improvements when all clinical notes are used as input."}}
{"id": "5_zQDPr4k0J", "cdate": 1672531200000, "mdate": 1679917669184, "content": {"title": "Finding the Needle in a Haystack: Unsupervised Rationale Extraction from Long Text Classifiers", "abstract": ""}}
{"id": "dKThVlcCXg6", "cdate": 1640995200000, "mdate": 1681735171702, "content": {"title": "Guiding Visual Question Generation", "abstract": "Nihir Vedd, Zixu Wang, Marek Rei, Yishu Miao, Lucia Specia. Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. 2022."}}
{"id": "VpOJ8W044J1", "cdate": 1640995200000, "mdate": 1681735171645, "content": {"title": "Supervising Model Attention with Human Explanations for Robust Natural Language Inference", "abstract": "Natural Language Inference (NLI) models are known to learn from biases and artefacts within their training data, impacting how well they generalise to other unseen datasets. Existing de-biasing approaches focus on preventing the models from learning these biases, which can result in restrictive models and lower performance. We instead investigate teaching the model how a human would approach the NLI task, in order to learn features that will generalise better to previously unseen examples. Using natural language explanations, we supervise the model\u2019s attention weights to encourage more attention to be paid to the words present in the explanations, significantly improving model performance. Our experiments show that the in-distribution improvements of this method are also accompanied by out-of-distribution improvements, with the supervised models learning from features that generalise better to other NLI datasets. Analysis of the model indicates that human explanations encourage increased attention on the important words, with more attention paid to words in the premise and less attention paid to punctuation and stopwords."}}
{"id": "P6igczSJjOj", "cdate": 1640995200000, "mdate": 1681735172196, "content": {"title": "Logical Reasoning with Span-Level Predictions for Interpretable and Robust NLI Models", "abstract": ""}}
{"id": "MdYyuh-YCxS", "cdate": 1640995200000, "mdate": 1681735172283, "content": {"title": "Logical Reasoning with Span Predictions: Span-level Logical Atoms for Interpretable and Robust NLI Models", "abstract": "Current Natural Language Inference (NLI) models achieve impressive results, sometimes outperforming humans when evaluating on in-distribution test sets. However, as these models are known to learn from annotation artefacts and dataset biases, it is unclear to what extent the models are learning the task of NLI instead of learning from shallow heuristics in their training data. We address this issue by introducing a logical reasoning framework for NLI, creating highly transparent model decisions that are based on logical rules. Unlike prior work, we show that improved interpretability can be achieved without decreasing the predictive accuracy. We almost fully retain performance on SNLI, while also identifying the exact hypothesis spans that are responsible for each model prediction. Using the e-SNLI human explanations, we verify that our model makes sensible decisions at a span level, despite not using any span labels during training. We can further improve model performance and span-level decisions by using the e-SNLI explanations during training. Finally, our model is more robust in a reduced data setting. When training with only 1,000 examples, out-of-distribution performance improves on the MNLI matched and mismatched validation sets by 13% and 16% relative to the baseline. Training with fewer observations yields further improvements, both in-distribution and out-of-distribution."}}
{"id": "AVvhre-Ewj", "cdate": 1640995200000, "mdate": 1681735171661, "content": {"title": "Memorisation versus Generalisation in Pre-trained Language Models", "abstract": ""}}
{"id": "4zJfDimA7Y", "cdate": 1640995200000, "mdate": 1681735171653, "content": {"title": "Multimodal Conversation Modelling for Topic Derailment Detection", "abstract": ""}}
{"id": "0ct6z4sVop", "cdate": 1640995200000, "mdate": 1681735172399, "content": {"title": "Probing for targeted syntactic knowledge through grammatical error detection", "abstract": "Targeted studies testing knowledge of subject-verb agreement (SVA) indicate that pre-trained language models encode syntactic information. We assert that if models robustly encode subject-verb agreement, they should be able to identify when agreement is correct and when it is incorrect. To that end, we propose grammatical error detection as a diagnostic probe to evaluate token-level contextual representations for their knowledge of SVA. We evaluate contextual representations at each layer from five pre-trained English language models: BERT, XLNet, GPT-2, RoBERTa, and ELECTRA. We leverage public annotated training data from both English second language learners and Wikipedia edits, and report results on manually crafted stimuli for subject-verb agreement. We find that masked language models linearly encode information relevant to the detection of SVA errors, while the autoregressive models perform on par with our baseline. However, we also observe a divergence in performance when probes are trained on different training sets, and when they are evaluated on different syntactic constructions, suggesting the information pertaining to SVA error detection is not robustly encoded."}}
