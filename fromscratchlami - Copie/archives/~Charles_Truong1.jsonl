{"id": "_v78FgKeYHz", "cdate": 1672531200000, "mdate": 1683878893228, "content": {"title": "ASTRIDE: Adaptive Symbolization for Time Series Databases", "abstract": "We introduce ASTRIDE (Adaptive Symbolization for Time seRIes DatabasEs), a novel symbolic representation of time series, along with its accelerated variant FASTRIDE (Fast ASTRIDE). Unlike most symbolization procedures, ASTRIDE is adaptive during both the segmentation step by performing change-point detection and the quantization step by using quantiles. Instead of proceeding signal by signal, ASTRIDE builds a dictionary of symbols that is common to all signals in a data set. We also introduce D-GED (Dynamic General Edit Distance), a novel similarity measure on symbolic representations based on the general edit distance. We demonstrate the performance of the ASTRIDE and FASTRIDE representations compared to SAX (Symbolic Aggregate approXimation), 1d-SAX, SFA (Symbolic Fourier Approximation), and ABBA (Adaptive Brownian Bridge-based Aggregation) on reconstruction and, when applicable, on classification tasks. These algorithms are evaluated on 86 univariate equal-size data sets from the UCR Time Series Classification Archive. An open source GitHub repository called astride is made available to reproduce all the experiments in Python."}}
{"id": "RmJNi2ieCiC", "cdate": 1664806784404, "mdate": null, "content": {"title": "Supervised change-point detection with dimension reduction, applied to physiological signals", "abstract": "This paper proposes an automatic method to calibrate change point detection algorithms for high-dimensional time series. Our procedure builds on the ability of an expert (e.g. a medical researcher) to produce approximate segmentation estimates, called partial annotations, for a small number of signal examples. This contribution is a supervised approach to learn a diagonal Mahalanobis metric, which, once combined with a detection algorithm, is able to reproduce the expert's segmentation strategy on out-of-sample signals. Unlike previous works for change detection, our method includes a sparsity-inducing regularization which perform supervised dimension selection, and adapts to partial annotations. Experiments on activity signals collected from healthy and neurologically impaired patients support the fact that supervision markedly ameliorate detection accuracy."}}
{"id": "OfZ-cs52hW", "cdate": 1640995200000, "mdate": 1683878893392, "content": {"title": "Unsupervised study of plethysmography signals through DTW clustering", "abstract": "The study of plethysmography time series is crucial to better understand the breathing behavior of mice, in particular the influence of neurotoxins on the respiratory system. Current approaches rely on a few respiratory descriptors computed on individual breathing cycles that fail to account for the variety of breathing habits and their evolution with time. In this paper we introduce a new procedure for the automatic analysis of plethysmography signals. Our method relies on a new and robust segmentation of respiratory cycles and a DTW-based clustering algorithm to extract the most typical respiratory cycles (called reference sequences). We can then create a symbolic representation of any new recording by matching respiratory cycles to their closest reference sequence. This new representation is a visual and quantitative tool to assess the breathing behavior of mice and its evolution with time. Our method is applied to plethysmography signals collected on mice with two different genotypes and exposed to a neurotoxin. Clinical relevance This article proposes a novel approach to study plethysmography data. Our algorithm is able to accurately extract clinically meaningful respiratory cycles and the associated ventilation patterns descriptors such as tidal volume and inhalation/exhalation duration. In addition, thanks to the associated symbolic representation of signals, the temporal evolution of respiration is easily quantified. This opens a new research path to study the often slowly evolving and subtle influence of neurotoxins on the respiratory system."}}
{"id": "N_QnH1x53x", "cdate": 1609459200000, "mdate": 1683878893383, "content": {"title": "Adaptive Change-Point Detection for Studying Human Locomotion", "abstract": "This paper presents an innovative method to analyze inertial signals recorded in a semi-controlled environment. It uses an adaptive and supervised change point detection procedure to decompose the signals into homogeneous segments, allowing a refined analysis of the successive phases within a gait protocol. Thanks to a training procedure, the algorithm can be applied to a wide range of protocols and handles different levels of granularity. The method is tested on a cohort of 15 healthy subjects performing a complex protocol composed of different activities and shows promising results for the automated and adaptive study of human gait and activity.Clinical relevance\u2013 A new approach to study human activity and locomotion in Free-Living Environments FLEs through an adaptive change-point detection which isolates homogeneous phases."}}
{"id": "63ldexD1AD4", "cdate": 1609459200000, "mdate": 1683878893089, "content": {"title": "Bayesian Feature Discovery for Predictive Maintenance", "abstract": "This paper considers predictive maintenance, which is the task of predicting rare and anomalous events (typically, system failures) using event logs data, which are series of time-stamped symbolic codes emitted at regular or irregular intervals by a monitored system. Our objective is to find small sets of codes (called itemsets or patterns) that occur shortly before failures. Current prediction methods either produce patterns at a high computational cost or resort to kernel approaches which are often difficult to interpret. We introduce Bayesian Pattern Feature Discovery (BPFD), a new generic algorithm for pattern discovery. Our method, based on a pattern mining technique, produces informative and explainable features and is computationally efficient. The performance of BPFD is highlighted on real-world data sets, showing that enriching the feature space with the discovered patterns improves significantly the prediction power of a broad range of predictors and offers useful insight on the predictive maintenance task."}}
{"id": "vF2MltC2n5", "cdate": 1577836800000, "mdate": 1683878893139, "content": {"title": "Meta-analysis parameters computation: a Python approach to facilitate the crossing of experimental conditions", "abstract": "Meta-analysis is a data aggregation method that establishes an overall and objective level of evidence based on the results of several studies. It is necessary to maintain a high level of homogeneity in the aggregation of data collected from a systematic literature review. However, the current tools do not allow a cross-referencing of the experimental conditions that could explain the heterogeneity observed between studies. This article aims at proposing a Python programming code containing several functions allowing the analysis and rapid visualization of data from many studies, while allowing the possibility of cross-checking the results by experimental condition."}}
{"id": "oa0CXDrWhJc", "cdate": 1577836800000, "mdate": null, "content": {"title": "Selective review of offline change point detection methods.", "abstract": "Highlights \u2022 A structured and didactic review of more than 140 articles related to offline change point detection. Thanks to the methodological framework proposed in this survey, all methods are presented as the combination of three functional blocks, which facilitates comparison between the different approaches. \u2022 The survey provides details on mathematical as well as algorithmic aspects such as complexity, asymptotic consistency, estimation of the number of changes, calibration, etc. \u2022 The review is linked to a Python package that includes most of the pre- sented methods, and allows the user to perform experiments and bench- marks. Abstract This article presents a selective survey of algorithms for the offline detection of multiple change points in multivariate time series. A general yet structuring methodological strategy is adopted to organize this vast body of work. More precisely, detection algorithms considered in this review are characterized by three elements: a cost function, a search method and a constraint on the number of changes. Each of those elements is described, reviewed and discussed separately. Implementations of the main algorithms described in this article are provided within a Python package called ruptures. Previous article in issue Next article in issue"}}
{"id": "3LueGu_d6x", "cdate": 1577836800000, "mdate": 1683878893355, "content": {"title": "Selective review of offline change point detection methods", "abstract": ""}}
{"id": "zPOLNvKsxD", "cdate": 1546300800000, "mdate": 1683878893374, "content": {"title": "Supervised Kernel Change Point Detection with Partial Annotations", "abstract": "In this article, we propose an automatic procedure to calibrate change point detection algorithms. Our approach expands on the ability of an expert to provide very rough segmentation estimates, called partial annotations, for a few signal examples. Our contribution consists in a supervised strategy to learn a kernel Mahalanobis metric, which, once combined with a detection algorithm, can replicate the expert's segmentation strategy on new signals. Contrary to previous works, our approach is non-parametric, supervised and naturally accommodates partial annotations. Experiments on real-world data show that supervision significantly improves detection performance."}}
{"id": "pfvqm8UBmTZ", "cdate": 1546300800000, "mdate": null, "content": {"title": "Supervised Kernel Change Point Detection with Partial Annotations.", "abstract": "In this article, we propose an automatic procedure to calibrate change point detection algorithms. Our approach expands on the ability of an expert to provide very rough segmentation estimates, called partial annotations, for a few signal examples. Our contribution consists in a supervised strategy to learn a kernel Mahalanobis metric, which, once combined with a detection algorithm, can replicate the expert's segmentation strategy on new signals. Contrary to previous works, our approach is non-parametric, supervised and naturally accommodates partial annotations. Experiments on real-world data show that supervision significantly improves detection performance."}}
