{"id": "TqiuQJHJTV-", "cdate": 1672531200000, "mdate": 1681652400125, "content": {"title": "Randomized Greedy Algorithms and Composable Coreset for k-Center Clustering with Outliers", "abstract": ""}}
{"id": "kGQz0lt6Zu6", "cdate": 1652737674591, "mdate": null, "content": {"title": "Coresets for Wasserstein Distributionally Robust Optimization Problems", "abstract": "Wasserstein distributionally robust optimization (\\textsf{WDRO}) is a popular model to enhance the robustness of machine learning with ambiguous data. However, the complexity of \\textsf{WDRO} can be prohibitive in practice since solving its ``minimax'' formulation requires a great amount of computation. Recently, several fast \\textsf{WDRO} training algorithms for some specific machine learning tasks (e.g., logistic regression) have been developed. However, the research on designing efficient algorithms for general large-scale \\textsf{WDRO}s is still quite limited, to the best of our knowledge. \\textit{Coreset} is an important  tool for compressing large dataset, and thus it has been widely applied to  reduce the computational complexities for many optimization problems. In this paper, we introduce a unified framework to construct the $\\epsilon$-coreset for the general \\textsf{WDRO} problems. Though it is challenging to obtain a conventional coreset for \\textsf{WDRO}  due to the uncertainty issue of ambiguous data, we show that we can compute a ``dual coreset'' by using the strong duality property of \\textsf{WDRO}. Also, the error introduced by the dual coreset can be theoretically guaranteed for the original \\textsf{WDRO} objective. To construct the dual coreset, we propose a novel  grid sampling approach that is particularly suitable for the dual formulation of \\textsf{WDRO}. Finally, we implement our coreset approach and illustrate its effectiveness for several \\textsf{WDRO} problems in the experiments. See \\href{https://arxiv.org/abs/2210.04260}{arXiv:2210.04260} for the full version of this paper. The code is available at \\url{https://github.com/h305142/WDRO_coreset}."}}
{"id": "tPiE70y40cv", "cdate": 1652737673877, "mdate": null, "content": {"title": "Coresets for Relational Data and The Applications", "abstract": "A coreset is a small set that can approximately preserve the structure of the original input data set. Therefore we can run our algorithm on a coreset so as to reduce the total computational complexity. Conventional coreset techniques assume that the input data set is available to process explicitly. However, this assumption may not hold in real-world scenarios. In this paper, we consider the problem of coresets construction over relational data. Namely, the data is decoupled into several relational tables, and it could be very expensive to directly materialize the data matrix by joining the tables. We propose a novel approach called ``aggregation tree with pseudo-cube'' that can build a coreset from bottom to up. Moreover, our approach can neatly circumvent several troublesome issues of relational learning problems [Khamis et al., PODS 2019]. Under some mild assumptions, we show that our coreset approach can be applied for the machine learning tasks, such as clustering, logistic regression and SVM."}}
{"id": "r2btUV0Xcf", "cdate": 1640995200000, "mdate": 1681652400134, "content": {"title": "Coresets for Relational Data and The Applications", "abstract": ""}}
{"id": "0_XBqORJrxH", "cdate": 1640995200000, "mdate": 1681652400142, "content": {"title": "Coresets for Wasserstein Distributionally Robust Optimization Problems", "abstract": ""}}
{"id": "zN4brUW8XJ6", "cdate": 1609459200000, "mdate": 1681652400133, "content": {"title": "A Novel Sequential Coreset Method for Gradient Descent Algorithms", "abstract": ""}}
{"id": "upnxj0gv-7", "cdate": 1609459200000, "mdate": 1681652400127, "content": {"title": "A Novel Sequential Coreset Method for Gradient Descent Algorithms", "abstract": ""}}
