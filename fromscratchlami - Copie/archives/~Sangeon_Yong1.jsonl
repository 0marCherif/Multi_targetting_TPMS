{"id": "Je4Bn2N7pxw", "cdate": 1672531200000, "mdate": 1683376439751, "content": {"title": "A Phoneme-Informed Neural Network Model for Note-Level Singing Transcription", "abstract": "Note-level automatic music transcription is one of the most representative music information retrieval (MIR) tasks and has been studied for various instruments to understand music. However, due to the lack of high-quality labeled data, transcription of many instruments is still a challenging task. In particular, in the case of singing, it is difficult to find accurate notes due to its expressiveness in pitch, timbre, and dynamics. In this paper, we propose a method of finding note onsets of singing voice more accurately by leveraging the linguistic characteristics of singing, which are not seen in other instruments. The proposed model uses mel-scaled spectrogram and phonetic posteriorgram (PPG), a frame-wise likelihood of phoneme, as an input of the onset detection network while PPG is generated by the pre-trained network with singing and speech data. To verify how linguistic features affect onset detection, we compare the evaluation results through the dataset with different languages and divide onset types for detailed analysis. Our approach substantially improves the performance of singing transcription and therefore emphasizes the importance of linguistic features in singing analysis."}}
{"id": "L_oTE6s_K-p", "cdate": 1640995200000, "mdate": 1683376439969, "content": {"title": "Neural Vocoder Feature Estimation for Dry Singing Voice Separation", "abstract": "Singing voice separation (SVS) is a task that separates singing voice audio from its mixture with instrumental audio. Previous SVS studies have mainly employed the spectrogram masking method which requires a large dimensionality in predicting the binary masks. In addition, they focused on extracting a vocal stem that retains the wet sound with the reverberation effect. This result may hinder the reusability of the isolated singing voice. This paper addresses the issues by predicting mel-spectrogram of dry singing voices from the mixed audio as neural vocoder features and synthesizing the singing voice waveforms from the neural vocoder. We experimented with two separation methods. One is predicting binary masks in the mel-spectrogram domain and the other is directly predicting the mel-spectrogram. Furthermore, we add a singing voice detector to identify the singing voice segments over time more explicitly. We measured the model performance in terms of audio, dereverberation, separation, and overall quality. The results show that our proposed model outperforms state-of-the-art singing voice separation models in both objective and subjective evaluation except the audio quality."}}
{"id": "24TkoaLYU1t", "cdate": 1577836800000, "mdate": null, "content": {"title": "Korean Singing Voice Synthesis Based on Auto-Regressive Boundary Equilibrium Gan", "abstract": "Singing voice synthesis is a generative task that involves not only multidimensional controls of a singer model such as phonetic modulation by lyrics and pitch control by music score but also expressive elements such as breath sounds and vibrato. Recently, end-to-end learning models based on generative adversarial network (GAN) have drawn much interest as it requires less domain-specific processing but provides high sound quality. When GAN is applied to the audio domain, it entails several issues: the choice of audio representation to generate, handling temporal continuity between two adjacent outputs, and finding an effective loss metric for the audio representation. In this paper, we propose a Korean singing voice synthesis system that addresses the issues using an auto-regressive algorithm that generates spectrogram with the boundary equilibrium GAN objective. Through the qualitative test, we show the proposed methods are superior to the original GAN objective and non-auto-regressive model. We also show that our proposed method can render natural expressions such as continuous pitch contours and breath sounds."}}
{"id": "23nhkuxUbkE", "cdate": 1514764800000, "mdate": null, "content": {"title": "Singing Expression Transfer from One Voice to Another for a Given Song", "abstract": "We present a vocal processing algorithm to automatically transfer singing expressions from one voice to another for a given song. Depending on singers' competence, a song can be rendered with great variations in terms of local tempo, pitch and dynamics. The proposed method temporally aligns a pair of singing voices using melodic and lyrical features that they have in common. Then, it conducts time-scale modification on the source voice according to the time-stretching ratio from the alignment result after smoothing. Once the two voices are aligned, the method modifies pitch and energy expressions of the source voice in a frame-by-frame manner using a pitch-synchronous overlap-add algorithm and a simple amplitude envelope matching. We designed our experiment to transfer singing expressions from a highly technical singer to a plain singer. The results show that our proposed method improves the singing quality effectively."}}
{"id": "5XJPJer-YJN", "cdate": 1483228800000, "mdate": 1683376439750, "content": {"title": "Use the Force: Incorporating Touch Force Sensors into Mobile Music Interaction", "abstract": "The musical possibilities of force sensors on touchscreen devices are explored, using Apple\u2019s 3D Touch. Three functions are selected to be controlled by force: (a) excitation, (b) modification (aftertouch), and (c) mode change. Excitation starts a note, modification alters a playing note, and mode change controls binary on/off sound parameters. Four instruments are designed using different combinations of force-sound mapping strategies. ForceKlick is a single button instrument that plays consecutive notes within one touch by altering touch force, by detecting force down-peaks. The iPhone 6s/7 Ocarina features force-sensitive fingerholes that heightens octaves upon high force. Force Trombone continuously controls gain by force. Force Synth is a trigger pad array featuring all functions in one button: start note by touch, control vibrato with force, and toggle octaves upon abrupt burst of force. A simple user test suggests that adding force features to well-known instruments are more friendly and usable."}}
{"id": "1w9bOf0H1L", "cdate": 1483228800000, "mdate": 1683376439752, "content": {"title": "ForceClicks: Enabling Efficient Button Interaction with Single Finger Touch", "abstract": "ForceClicks is a novel touch button input technique for consecutive clicking which incorporates touch force sensors. From force data of a single continuous touch over time, ForceClicks detects peaks and generates discrete clicks. Compared to typical button interaction, this is effective in a sense that consecutive clicks do not require finger positional movements. Additionally, stable force over a certain time threshold can trigger an alternate state, long press, and can be mapped to other actions. The usability of ForceClicks has been evaluated in terms of a) scattering level and b) efficiency. Results suggest higher stability than typical touch, especially when the task requires visual engagement on remote content. The relatively scatter-free characteristic of ForceClicks allows it to be applied on rapid clicking while gaming, and reduce of visual dedication allows easier control of external devices, and two applications, a shooting game and a number picker, are presented for demonstration."}}
