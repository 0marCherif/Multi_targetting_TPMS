{"id": "addmrGVp-v", "cdate": 1580321547713, "mdate": null, "content": {"title": "Efficient and generalizable statistical models of shape and appearance for analysis of cardiac MRI", "abstract": "We present a framework for the analysis of short axis cardiac MRI, using statistical models of shape and appearance. The framework integrates temporal and structural constraints and avoids common optimization problems inherent in such high dimensional models. The first contribution is the introduction of an algorithm for fitting 3D active appearance models (AAMs) on short axis cardiac MRI. We observe a 44-fold increase in fitting speed and a segmentation accuracy that is on par with Gauss\u2013Newton optimization, one of the most widely used optimization algorithms for such problems. The second contribution involves an investigation on hierarchical 2D + time active shape models (ASMs), that integrate temporal constraints and simultaneously improve the 3D AAM based segmentation. We obtain encouraging results (endocardial/epicardial error 1.43 \u00b1 0.49 mm/1.51 \u00b1 0.48 mm) on 7980 short axis cardiac MR images acquired from 33 subjects. We have placed our dataset online, for the community to use and build upon."}}
{"id": "uIl2wGXlse", "cdate": 1580321352789, "mdate": null, "content": {"title": "50 years of object recognition: Directions forward", "abstract": "Object recognition systems constitute a deeply entrenched and omnipresent component of modern intelligent systems. Research on object recognition algorithms has led to advances in factory and office automation through the creation of optical character recognition systems, assembly-line industrial inspection systems, as well as chip defect identification systems. It has also led to significant advances in medical imaging, defence and biometrics. In this paper we discuss the evolution of computer-based object recognition systems over the last fifty years, and overview the successes and failures of proposed solutions to the problem. We survey the breadth of approaches adopted over the years in attempting to solve the problem, and highlight the important role that active and attentive approaches must play in any solution that bridges the semantic gap in the proposed object representations, while simultaneously leading to efficient learning and inference algorithms. From the earliest systems which dealt with the character recognition problem, to modern visually-guided agents that can purposively search entire rooms for objects, we argue that a common thread of all such systems is their fragility and their inability to generalize as well as the human visual system can. At the same time, however, we demonstrate that the performance of such systems in strictly controlled environments often vastly outperforms the capabilities of the human visual system. We conclude our survey by arguing that the next step in the evolution of object recognition algorithms will require radical and bold steps forward in terms of the object representations, as well as the learning and inference algorithms used."}}
{"id": "Dabl-Kf-Jo", "cdate": 1580321263839, "mdate": null, "content": {"title": "A low power high throughput fully event based stereo system", "abstract": "We introduce a stereo correspondence system implemented fully on event-based digital hardware, using a fully graph-based non von-Neumann computation model, where no frames, arrays, or any other such data-structures are used. This is the first time that an end-to-end stereo pipeline from image acquisition and rectification, multi-scale spatio-temporal stereo correspondence, winner-take-all, to disparity regularization is implemented fully on event-based hardware. Using a cluster of TrueNorth neurosynaptic processors, we demonstrate their ability to process bilateral event-based inputs streamed live by Dynamic Vision Sensors (DVS), at up to 2,000 disparity maps per second, producing high fidelity disparities which are in turn used to reconstruct, at low power, the depth of events produced from rapidly changing scenes. Experiments on real-world sequences demonstrate the ability of the system to take full advantage of the asynchronous and sparse nature of DVS sensors for low power depth reconstruction, in environments where conventional frame-based cameras connected to synchronous processors would be inefficient for rapidly moving objects. System evaluation on event-based sequences demonstrates a~ 200X improvement in terms of power per pixel per disparity map compared to the closest state-of-the-art, and maximum latencies of up to 11ms from spike injection to disparity map ejection."}}
{"id": "qR0xAfrvQd", "cdate": 1546300800000, "mdate": 1679934965630, "content": {"title": "TrueNorth: Accelerating From Zero to 64 Million Neurons in 10 Years", "abstract": ""}}
{"id": "Y3v-2D3DoyS", "cdate": 1546300800000, "mdate": 1681657627760, "content": {"title": "A Possible Reason for why Data-Driven Beats Theory-Driven Computer Vision", "abstract": "Why do some continue to wonder about the success and dominance of deep learning methods in computer vision and AI? Is it not enough that these methods provide practical solutions to many problems? Well no, it is not enough, at least for those who feel there should be a science that underpins all of this and that we should have a clear understanding of how this success was achieved. Here, this paper proposes that the dominance we are witnessing would not have been possible by the methods of deep learning alone: the tacit change has been the evolution of empirical practice in computer vision and AI over the past decades. We demonstrate this by examining the distribution of sensor settings in vision datasets and performance of both classic and deep learning algorithms under various camera settings. This reveals a strong mismatch between optimal performance ranges of classical theory-driven algorithms and sensor setting distributions in the common vision datasets, while data-driven models were trained for those datasets. The head-to-head comparisons between data-driven and theory-driven models were therefore unknowingly biased against the theory-driven models."}}
{"id": "9XKiyjp6qrf", "cdate": 1546300800000, "mdate": 1681657627758, "content": {"title": "Why Does Data-Driven Beat Theory-Driven Computer Vision?", "abstract": "This paper proposes that despite the success of deep learning methods in computer vision, the dominance we see would not have been possible by the methods of deep learning alone: the tacit change has been the evolution of empirical practice in computer vision. We demonstrate this by examining the distribution of sensor settings in vision datasets, only one potential dataset bias, and performance of both classic and deep learning algorithms under various camera settings. This reveals a strong mismatch between optimal performance ranges of theory-driven algorithms and sensor setting distributions in common vision datasets."}}
{"id": "1OYkNLV1qyg", "cdate": 1483228800000, "mdate": 1681657627764, "content": {"title": "Always-On Speech Recognition Using TrueNorth, a Reconfigurable, Neurosynaptic Processor", "abstract": ""}}
{"id": "t940h3QtIP", "cdate": 1451606400000, "mdate": 1679934965893, "content": {"title": "Convolutional Networks for Fast, Energy-Efficient Neuromorphic Computing", "abstract": ""}}
{"id": "bicJpsblda-", "cdate": 1451606400000, "mdate": 1681657627802, "content": {"title": "A low-power neurosynaptic implementation of Local Binary Patterns for texture analysis", "abstract": ""}}
{"id": "aiAOYdOzy3", "cdate": 1451606400000, "mdate": 1679934965893, "content": {"title": "Convolutional networks for fast, energy-efficient neuromorphic computing", "abstract": ""}}
