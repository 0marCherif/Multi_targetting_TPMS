{"id": "ymrLDcTOLY", "cdate": 1672531200000, "mdate": 1681502839820, "content": {"title": "Pathologies of Predictive Diversity in Deep Ensembles", "abstract": ""}}
{"id": "6sBiAIpkUiO", "cdate": 1664725485447, "mdate": null, "content": {"title": "The Best Deep Ensembles Sacrifice Predictive Diversity", "abstract": "Ensembling remains a hugely popular method for increasing the performance of a given class of models. In the case of deep learning, the benefits of ensembling are often attributed to the diverse predictions of the individual ensemble members. Here we investigate a tradeoff between diversity and individual model performance, and find that--surprisingly--encouraging diversity during training almost always yields worse ensembles. We show that this tradeoff arises from the Jensen gap between the single model and ensemble losses, and show that Jensen gap is a natural measure of diversity for both the mean squared error and cross entropy loss functions. Our results suggest that to reduce the ensemble error, we should move away from efforts to increase predictive diversity, and instead we should construct ensembles from less diverse (but more accurate) component models. "}}
{"id": "Wl1ZIgMqLlq", "cdate": 1652737584667, "mdate": null, "content": {"title": "Deep Ensembles Work, But Are They Necessary?", "abstract": "Ensembling neural networks is an effective way to increase accuracy, and can often match the performance of individual larger models. This observation poses a natural question: given the choice between a deep ensemble and a single neural network with similar accuracy, is one preferable over the other? Recent work suggests that deep ensembles may offer distinct benefits beyond predictive power: namely, uncertainty quantification and robustness to dataset shift. In this work, we demonstrate limitations to these purported benefits, and show that a single (but larger) neural network can replicate these qualities. First, we show that ensemble diversity, by any metric, does not meaningfully contribute to an ensemble's ability to detect out-of-distribution (OOD) data, but is instead highly correlated with the relative improvement of a single larger model. Second, we show that the OOD performance afforded by ensembles is strongly determined by their in-distribution (InD) performance, and - in this sense - is not indicative of any \"effective robustness.\" While deep ensembles are a practical way to achieve improvements to predictive power, uncertainty quantification, and robustness, our results show that these improvements can be replicated by a (larger) single model."}}
{"id": "Pxt0Byu_H0", "cdate": 1640995200000, "mdate": 1681502839822, "content": {"title": "Deep Ensembles Work, But Are They Necessary?", "abstract": ""}}
{"id": "YiQsXV6wi9h", "cdate": 1546300800000, "mdate": null, "content": {"title": "BehaveNet: nonlinear embedding and Bayesian neural decoding of behavioral videos", "abstract": "A fundamental goal of systems neuroscience is to understand the relationship between neural activity and behavior. Behavior has traditionally been characterized by low-dimensional, task-related variables such as movement speed or response times. More recently, there has been a growing interest in automated analysis of high-dimensional video data collected during experiments. Here we introduce a probabilistic framework for the analysis of behavioral video and neural activity. This framework provides tools for compression, segmentation, generation, and decoding of behavioral videos. Compression is performed using a convolutional autoencoder (CAE), which yields a low-dimensional continuous representation of behavior. We then use an autoregressive hidden Markov model (ARHMM) to segment the CAE representation into discrete \"behavioral syllables.\" The resulting generative model can be used to simulate behavioral video data. Finally, based on this generative model, we develop a novel Bayesian decoding approach that takes in neural activity and outputs probabilistic estimates of the full-resolution behavioral video. We demonstrate this framework on two different experimental paradigms using distinct behavioral and neural recording technologies."}}
{"id": "vW5vi3uvvv", "cdate": 1514764800000, "mdate": 1681502839820, "content": {"title": "Markerless tracking of user-defined features with deep learning", "abstract": ""}}
