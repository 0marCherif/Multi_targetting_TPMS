{"id": "x4MbtV1AwTv", "cdate": 1695501369709, "mdate": 1695501369709, "content": {"title": "Domain Adaptive Object Detection via Balancing between Self-Training and Adversarial Learning", "abstract": "Deep learning based object detectors struggle generalizing to a new target domain bearing significant variations in object and\nbackground. Most current methods align domains by using image or instance-level adversarial feature alignment. This often suffers due to\nunwanted background and lacks class-specific alignment. A straightforward approach to promote class-level alignment is to use high\nconfidence predictions on unlabeled domain as pseudo-labels. These predictions are often noisy since model is poorly calibrated under\ndomain shift. In this paper, we propose to leverage model\u2019s predictive uncertainty to strike the right balance between adversarial feature\nalignment and class-level alignment. We develop a technique to quantify predictive uncertainty on class assignments and bounding-box\npredictions. Model predictions with low uncertainty are used to generate pseudo-labels for self-training, whereas the ones with higher\nuncertainty are used to generate tiles for adversarial feature alignment. This synergy between tiling around uncertain object regions and\ngenerating pseudo-labels from highly certain object regions allows capturing both image and instance-level context during the model\nadaptation. We report thorough ablation study to reveal the impact of different components in our approach. Results on five diverse and\nchallenging adaptation scenarios show that our approach outperforms existing state-of-the-art methods with noticeable margins"}}
{"id": "_D-W1WHn3HS", "cdate": 1667372812113, "mdate": 1667372812113, "content": {"title": "Hierarchical Nearest Neighbor Graph Embedding for Efficient Dimensionality Reduction", "abstract": "Dimensionality reduction is crucial both for visualization and preprocessing high dimensional data for machine learning. We introduce a novel method based on a hierarchy built on 1-nearest neighbor graphs in the original space which is used to preserve the grouping properties of the data distribution on multiple levels. The core of the proposal is an optimization-free projection that is competitive with the latest versions of t-SNE and UMAP in performance and visualization quality while being an order of magnitude faster in run-time. Furthermore, its interpretable mechanics, the ability to project new data, and the natural separation of data clusters in visualizations make it a general purpose unsupervised dimension reduction technique. In the paper, we argue about the soundness of the proposed method and evaluate it on a diverse collection of datasets with sizes varying from 1K to 11M samples and dimensions from 28 to 16K. We perform comparisons with other state-of-the-art methods on multiple metrics and target dimensions highlighting its efficiency and performance. "}}
{"id": "l46nZ2YRfC", "cdate": 1667372598785, "mdate": 1667372598785, "content": {"title": "Temporally-Weighted Hierarchical Clustering for Unsupervised Action Segmentation", "abstract": "Action segmentation refers to inferring boundaries of semantically consistent visual concepts in videos and is an important requirement for many video understanding tasks. For this and other video understanding tasks, supervised approaches have achieved encouraging performance but require a high volume of detailed frame-level annotations. We present a fully automatic and unsupervised approach for segmenting actions in a video that does not require any training. Our proposal is an effective temporally-weighted hierarchical clustering algorithm that can group semantically consistent frames of the video. Our main finding is that representing a video with a 1-nearest neighbor graph by taking into account the time progression is sufficient to form semantically and temporally consistent clusters of frames where each cluster may represent some action in the video. Additionally, we establish strong unsupervised baselines for action segmentation and show significant performance improvements over published unsupervised methods on five challenging action segmentation datasets. Our code is available."}}
{"id": "a7YeDeacHpL", "cdate": 1652737678034, "mdate": null, "content": {"title": "Towards Improving Calibration in Object Detection Under Domain Shift", "abstract": "With deep neural network based solution more readily being incorporated in real-world applications, it has been pressing requirement that predictions by such models, especially in safety-critical environments, be  highly accurate and well-calibrated. Although some techniques addressing DNN calibration have been proposed, they are only limited to visual classification applications and in-domain predictions. Unfortunately, very little to no attention is paid towards addressing calibration of DNN-based visual object detectors, that occupy similar space and importance in many decision making systems as their visual classification counterparts. In this work, we study the calibration of DNN-based object detection models, particularly under domain shift. To this end, we first propose a new, plug-and-play, train-time calibration loss for object detection (coined as TCD). It can be used with various application-specific loss functions as an auxiliary loss function to improve detection calibration. Second, we devise a new implicit technique for improving calibration in self-training based domain adaptive detectors, featuring a new uncertainty quantification mechanism for object detection. We demonstrate TCD is capable of enhancing calibration with notable margins (1) across different DNN-based object detection paradigms both in in-domain and out-of-domain predictions, and (2) in different domain-adaptive detectors across challenging adaptation scenarios. Finally, we empirically show that our implicit calibration technique can be used in tandem with TCD during adaptation to further boost calibration in diverse domain shift scenarios."}}
{"id": "F93Z9Au6HxE", "cdate": 1621630165392, "mdate": null, "content": {"title": "SSAL: Synergizing between Self-Training and Adversarial Learning for Domain Adaptive Object Detection", "abstract": "We study adapting trained object detectors to unseen domains manifesting significant variations of object appearance, viewpoints and backgrounds. Most current methods align domains by either using image or instance-level feature alignment in an adversarial fashion. This often suffers due to the presence of unwanted background and as such lacks class-specific alignment. A common remedy to promote class-level alignment is to use high confidence predictions on the unlabelled domain as pseudo labels. These high confidence predictions are often fallacious since the model is poorly calibrated under domain shift. In this paper, we propose to leverage model\u2019s predictive uncertainty to strike the right balance between adversarial feature alignment and class-level alignment. Specifically, we measure predictive uncertainty on class assignments and the bounding box predictions. Model predictions with low uncertainty are used to generate pseudo-labels for self-supervision, whereas the ones with higher uncertainty are used to generate tiles for an adversarial feature alignment stage. This synergy between tiling around the uncertain object regions and generating pseudo-labels from highly certain object regions allows us to capture both the image and instance level context during the model adaptation stage. We perform extensive experiments covering various domain shift scenarios. Our approach improves upon existing state-of-the-art methods with visible margins."}}
{"id": "BiUDQ1Qld6B", "cdate": 1546300800000, "mdate": null, "content": {"title": "Efficient Parameter-Free Clustering Using First Neighbor Relations.", "abstract": "We present a new clustering method in the form of a single clustering equation that is able to directly discover groupings in the data. The main proposition is that the first neighbor of each sample is all one needs to discover large chains and finding the groups in the data. In contrast to most existing clustering algorithms our method does not require any hyper-parameters, distance thresholds and/or the need to specify the number of clusters. The proposed algorithm belongs to the family of hierarchical agglomerative methods. The technique has a very low computational overhead, is easily scalable and applicable to large practical problems. Evaluation on well known datasets from different domains ranging between 1077 and 8.1 million samples shows substantial performance gains when compared to the existing clustering techniques."}}
{"id": "BJEmZ0ZOWr", "cdate": 1514764800000, "mdate": null, "content": {"title": "A Pose-Sensitive Embedding for Person Re-Identification With Expanded Cross Neighborhood Re-Ranking", "abstract": "Person re-identification is a challenging retrieval task that requires matching a person\u2019s acquired image across non-overlapping camera views. In this paper we propose an effective approach that incorporates both the fine and coarse pose information of the person to learn a discrim- inative embedding. In contrast to the recent direction of explicitly modeling body parts or correcting for misalignment based on these, we show that a rather straightforward inclusion of acquired camera view and/or the detected joint locations into a convolutional neural network helps to learn a very effective representation. To increase retrieval performance, re-ranking techniques based on computed distances have recently gained much attention. We propose a new unsupervised and automatic re-ranking framework that achieves state-of-the-art re-ranking performance. We show that in contrast to the current state-of-the-art re-ranking methods our approach does not require to compute new rank lists for each image pair (e.g., based on reciprocal neighbors) and performs well by using simple direct rank list based comparison or even by just using the already computed euclidean distances between the images. We show that both our learned representation and our re-ranking method achieve state-of-the-art performance on a number of challenging surveillance image and video datasets."}}
{"id": "HXbSTUx_Tr", "cdate": 1483228800000, "mdate": null, "content": {"title": "Deep Perceptual Mapping for Cross-Modal Face Recognition.", "abstract": "Cross modal face matching between the thermal and visible spectrum is a much desired capability for night-time surveillance and security applications. Due to a very large modality gap, thermal-to-visible face recognition is one of the most challenging face matching problem. In this paper, we present an approach to bridge this modality gap by a significant margin. Our approach captures the highly non-linear relationship between the two modalities by using a deep neural network. Our model attempts to learn a non-linear mapping from the visible to the thermal spectrum while preserving the identity information. We show substantive performance improvement on three difficult thermal\u2013visible face datasets. The presented approach improves the state-of-the-art by more than 10 % on the UND-X1 dataset and by more than 15\u201330 % on the NVESD dataset in terms of Rank-1 identification. Our method bridges the drop in performance due to the modality gap by more than 40 %."}}
{"id": "rJo-zOvgW", "cdate": null, "mdate": null, "content": {"title": "A Simple and Effective Technique for Face Clustering in TV Series", "abstract": "In this paper, we present a simple aggregation of frame-level CNN features in a face track to produce a track-level feature representation for face clustering in movies or videos. The approach is invariant of the image sequence and the number of frames the track has. We demonstrate the effectiveness of this strategy on three challenging benchmark video face clustering datasets: Big Bang Theory, Buffy the Vampire Slayer, and Notting Hill. Experiments using our straightforward strategy shows promising results on all the datasets. In addition, our strategy is useful in improving the baseline performance of generic face clustering methods without using any additional external constraints."}}
