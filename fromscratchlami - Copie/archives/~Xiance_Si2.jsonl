{"id": "1etgJ2IUeBF", "cdate": 1546300800000, "mdate": null, "content": {"title": "How to Ask Better Questions? A Large-Scale Multi-Domain Dataset for Rewriting Ill-Formed Questions", "abstract": "We present a large-scale dataset for the task of rewriting an ill-formed natural language question to a well-formed one. Our multi-domain question rewriting MQR dataset is constructed from human contributed Stack Exchange question edit histories. The dataset contains 427,719 question pairs which come from 303 domains. We provide human annotations for a subset of the dataset as a quality estimate. When moving from ill-formed to well-formed questions, the question quality improves by an average of 45 points across three aspects. We train sequence-to-sequence neural models on the constructed dataset and obtain an improvement of 13.2% in BLEU-4 over baseline methods built from other data resources. We release the MQR dataset to encourage research on the problem of question rewriting."}}
{"id": "Bk-C6jl_Wr", "cdate": 1356998400000, "mdate": null, "content": {"title": "Deceptive Answer Prediction with User Preference Graph", "abstract": "In Community question answering (QA) sites, malicious users may provide deceptive answers to promote their products or services. It is important to identify and filter out these deceptive answers. In this paper, we first solve this problem with the traditional supervised learning methods. Two kinds of features, including textual and contextual features, are investigated for this task. We further propose to exploit the user relationships to identify the deceptive answers, based on the hypothesis that similar users will have similar behaviors to post deceptive or authentic answers. To measure the user similarity, we propose a new user preference graph based on the answer preference expressed by users, such as \u201chelpful\u201d voting and \u201cbest answer\u201d selection. The user preference graph is incorporated into traditional supervised learning framework with the graph regularization technique. The experiment results demonstrate that the user preference graph can indeed help improve the performance of deceptive answer pre"}}
{"id": "r1bNuTxuZB", "cdate": 1325376000000, "mdate": null, "content": {"title": "A Data-Driven Approach to Question Subjectivity Identification in Community Question Answering", "abstract": "Automatic Subjective Question Answering (ASQA), which aims at answering users' subjective questions using summaries of multiple opinions, becomes increasingly important. One challenge of ASQA is that expected answers for subjective questions may not readily exist in the Web. The rising and popularity of Community Question Answering (CQA) sites, which provide platforms for people to post and answer questions, provides an alternative to ASQA. One important task of ASQA is question subjectivity identification, which identifies whether a user is asking a subjective question. Unfortunately, there has been little labeled training data available for this task. In this paper, we propose an approach to collect training data automatically by utilizing social signals in CQA sites without involving any manual labeling. Experimental results show that our data-driven approach achieves 9:37% relative improvement over the supervised approach using manually labeled data, and achieves 5:15% relative gain over a state-of-the-art semi-supervised approach. In addition, we propose several heuristic features for question subjectivity identification. By adding these features, we achieve 11:23% relative improvement over word n-gram feature under the same experimental setting."}}
{"id": "Q-XaRHl_h5X", "cdate": 1325376000000, "mdate": null, "content": {"title": "Entity Disambiguation with Freebase", "abstract": "Entity disambiguation with a knowledge base becomes increasingly popular in the NLP community. In this paper, we employ Freebase as the knowledge base, which contains significantly more entities than Wikipedia and others. While huge in size, Freebase lacks context for most entities, such as the descriptive text and hyperlinks in Wikipedia, which are useful for disambiguation. Instead, we leverage two features of Freebase, namely the naturally disambiguated mention phrases (aka aliases) and the rich taxonomy, to perform disambiguation in an iterative manner. Specifically, we explore both generative and discriminative models for each iteration. Experiments on 2, 430, 707 English sentences and 33, 743 Freebase entities show the effectiveness of the two features, where 90% accuracy can be reached without any labeled data. We also show that discriminative models with proposed split training strategy is robust against over fitting problem, and constantly outperforms the generative ones."}}
{"id": "c3MH8yh1y6f", "cdate": 1293840000000, "mdate": null, "content": {"title": "K2Q: Generating Natural Language Questions from Keywords with User Refinements", "abstract": "Zhicheng Zheng, Xiance Si, Edward Chang, Xiaoyan Zhu. Proceedings of 5th International Joint Conference on Natural Language Processing. 2011."}}
{"id": "JT1uy5hjvCB", "cdate": 1293840000000, "mdate": null, "content": {"title": "Exploring the Granularity Level of Social Tags", "abstract": "Tags are widely used in Web 2.0 applications, such as blogs and online bookmarks. Many characteristics of tags have been studied in previous works, but the granularity level of tags still remains u..."}}
{"id": "0OhMc9c9w4x", "cdate": 1293840000000, "mdate": null, "content": {"title": "Question identification on twitter", "abstract": "In this paper, we investigate the novel problem of automatic question identification in the microblog environment. It contains two steps: detecting tweets that contain questions (we call them \"interrogative tweets\") and extracting the tweets which really seek information or ask for help (so called \"qweets\") from interrogative tweets. To detect interrogative tweets, both traditional rule-based approach and state-of-the-art learning-based method are employed. To extract qweets, context features like short urls and Tweet-specific features like Retweets are elaborately selected for classification. We conduct an empirical study with sampled one hour's English tweets and report our experimental results for question identification on Twitter."}}
{"id": "oH72Wa-Ytls", "cdate": 1262304000000, "mdate": null, "content": {"title": "Tag Allocation Model: Model Noisy Social Annotations by Reason Finding", "abstract": "We propose the Tag Allocation Model (TAM) to model social annotation data. TAM is a probabilistic generative model, its key feature is finding the latent reason for each tag. A latent reason can be any discrete features of the document (such as words) or a global noise variable. Inferring the reason for each tag helps TAM reduce the ambiguity of a document with multiple tags. By introducing noise as a reason, TAM can handle noise tags naturally. We perform experiments on three real world data sets. The results show that TAM outperforms state-of-the-art approaches in both held-out perplexity and tag recommendation accuracy."}}
{"id": "e_5WPIvdcc1", "cdate": 1262304000000, "mdate": null, "content": {"title": "Modeling Social Annotations via Latent Reason Identification", "abstract": "The probabilistic Tag Allocation Model (TAM) explains social tags by modeling the latent reasoning behind each tag in order to disambiguate them and identify noise."}}
{"id": "JgG5SqHgpht", "cdate": 1262304000000, "mdate": null, "content": {"title": "Confucius and Its Intelligent Disciples: Integrating Social with Search", "abstract": ""}}
