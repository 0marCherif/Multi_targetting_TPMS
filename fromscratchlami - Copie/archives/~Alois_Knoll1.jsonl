{"id": "SE20eKUvK5", "cdate": 1683904987062, "mdate": 1683904987062, "content": {"title": "Biological data questions the support of the self inhibition required for pattern generation in the half center model", "abstract": "Locomotion control in mammals has been hypothesized to be governed by a central pattern generator (CPG) located in the circuitry of the spinal cord. The most common model of the CPG is the half center model, where two pools of neurons generate alternating, oscillatory activity. In this model, the pools reciprocally inhibit each other ensuring alternating activity. There is experimental support for reciprocal inhibition. However another crucial part of the half center model is a self inhibitory mechanism which prevents the neurons of each individual pool from infinite firing. Self-inhibition is hence necessary to obtain alternating activity. But critical parts of the experimental bases for the proposed mechanisms for self-inhibition were obtained in vitro, in preparations of juvenile animals. The commonly used adaptation of spike firing does not appear to be present in adult animals in vivo. We therefore modeled several possible self inhibitory mechanisms for locomotor control. Based on currently published data, previously proposed hypotheses of the self inhibitory mechanism, necessary to support the CPG hypothesis, seems to be put into question by functional evaluation tests or by in vivo data. This opens for alternative explanations of how locomotion activity patterns in the adult mammal could be generated."}}
{"id": "LvUSk2wk8tQ", "cdate": 1683904849754, "mdate": null, "content": {"title": "Diversified physiological sensory input connectivity questions the existence of distinct classes of spinal interneurons in the adult cat in vivo", "abstract": "The spinal cord is engaged in all forms of motor performance but its functions are far from understood. Because network connectivity defines function, we explored the connectivity of muscular, tendon, and tactile sensory inputs among a wide population of spinal interneurons in the lower cervical segments. Using low noise intracellular whole cell recordings in the decerebrated, non-anesthetized cat in vivo, we could define mono-, di-, and trisynaptic inputs as well as the weights of each input. Whereas each neuron had a highly specific input, and each indirect input could moreover be explained by inputs in other recorded neurons, we unexpectedly also found the input connectivity of the spinal interneuron population to form a continuum. Our data hence contrasts with the currently widespread notion of distinct classes of interneurons. We argue that this suggested diversified physiological connectivity, which likely requires a major component of circuitry learning, implies a more flexible functionality."}}
{"id": "KvAJ3nmqTX", "cdate": 1681558491804, "mdate": null, "content": {"title": "Continual Invariant Image Mapping from Randomized Simulations for Sim2real Transfer in Robotic Manipulation", "abstract": "Currently, deep reinforcement learning algorithms require large amounts of training data to learn a specific task, which makes them infeasible to train directly on real robotic systems. To overcome this obstacle, one usually relies on training in simulation and randomizes aspects of the simulation to compensate for the mismatch between the simulator and the real system. However, it is not always clear which aspect of the simulation requires randomization and usually enabling an additional randomization parameter or simulation modifications require model retraining from scratch. To address this problem, in this paper we explore how continual state representation learning can be combined with parameter randomization for vision-based reinforcement learning of robotic tasks, to minimize the need for complete model retraining. To this end, we use variational autoencoder (VAE) to continually learn to reconstruct invariant image representation from sequentially randomized/augmented simulation images. Independently, a reinforcement learning model is trained on the invariant image representation to solve a robotic manipulation task. Then, the VAE is used to translate randomized/augmented simulation images or real-world images to the invariant representation images on which the RL agent can operate. Initial results show that the VAE can continually learn reconstruction to invariant images and it can also be used to bridge the sim2real gap by reconstructing correctly real camera images. "}}
{"id": "tyZ1ChGZIKO", "cdate": 1663850536141, "mdate": null, "content": {"title": "Selective Frequency Network for Image Restoration", "abstract": "Image restoration aims to reconstruct the latent sharp image from its corrupted counterpart. Besides dealing with this long-standing task in the spatial domain, a few approaches seek solutions in the frequency domain in consideration of the large discrepancy between spectra of sharp/degraded image pairs. However, these works commonly utilize transformation tools, e.g., wavelet transform, to split features into several frequency parts, which is not flexible enough to select the most informative frequency component to recover. In this paper, we exploit a multi-branch and content-aware module to decompose features into separate frequency subbands dynamically and locally, and then accentuate the useful ones via channel-wise attention weights. In addition, to handle large-scale degradation blurs, we propose an extremely simple decoupling and modulation module to enlarge the receptive field via global and window-based average pooling. Integrating two developed modules into a U-Net backbone, the proposed Selective Frequency Network (SFNet) performs favorably against state-of-the-art algorithms on five image restoration tasks, including single-image defocus deblurring, image dehazing, image motion deblurring, image desnowing, and image deraining."}}
{"id": "TTcpISh-_oI", "cdate": 1663850359388, "mdate": null, "content": {"title": "ResFed: Communication Efficient Federated Learning by Transmitting Deep Compressed Residuals", "abstract": "Federated learning enables cooperative training among massively distributed clients by sharing their learned local model parameters. However, with increasing model size, deploying federated learning requires a large communication bandwidth, which limits its deployment in wireless networks. To address this bottleneck, we introduce a residual-based federated learning framework (ResFed), where residuals rather than model parameters are transmitted in communication networks for training. In particular, we integrate two pairs of shared predictors for the model prediction in both server-to-client and client-to-server communication. By employing a common prediction rule, both locally and globally updated models are always fully recoverable in clients and the server. We highlight that the residuals only indicate the quasi-update of a model in a single inter-round, and hence contain more dense information and have a lower entropy than the model, comparing to model weights and gradients. Based on this property, we further conduct lossy compression of the residuals by sparsification and quantization and encode them for efficient communication. The experimental evaluation shows that our ResFed needs remarkably less communication costs and achieves better accuracy by leveraging less sensitive residuals, compared to standard federated learning. For instance, to train a 4.08 MB CNN model on CIFAR-10 with 10 clients under non-independent and identically distributed (Non-IID) setting, our approach achieves a compression ratio over 700X in each communication round with minimum impact on the accuracy. To reach an accuracy of 70%, it saves around 99% of the total communication volume from 587.61 Mb to 6.79 Mb in up-streaming and to 4.61 Mb in down-streaming on average for all clients."}}
{"id": "BlyXYc4wF2-", "cdate": 1632875480541, "mdate": null, "content": {"title": "Multi-Agent Constrained Policy Optimisation ", "abstract": "Developing reinforcement learning algorithms that satisfy safety constraints is becoming increasingly important in real-world applications. In multi-agent reinforcement learning (MARL) settings, policy optimisation with safety awareness is particularly challenging because each individual agent has to not only meet its own safety constraints, but also consider those of others so that their joint behaviour can be guaranteed safe. Despite its importance, the problem of safe multi-agent learning has not been rigorously studied; very few solutions have been proposed, nor a sharable testing environment or benchmarks. To fill these gaps, in this work, we formulate the safe MARL problem as a constrained Markov game and solve it with policy optimisation methods. Our solutions---Multi-Agent Constrained Policy Optimisation (MACPO) and MAPPO-Lagrangian---leverage the theories from both constrained policy optimisation and multi-agent trust region learning. Crucially, our methods enjoy theoretical guarantees of both monotonic improvement in reward and satisfaction of safety constraints at every iteration. To examine the effectiveness of our methods, we develop the benchmark suite of Safe Multi-Agent MuJoCo that involves a variety of  MARL baselines. Experimental results justify that MACPO/MAPPO-Lagrangian can consistently satisfy safety constraints, meanwhile achieving comparable performance to strong baselines."}}
{"id": "zgznkdZP8u", "cdate": 1609459200000, "mdate": 1624473239065, "content": {"title": "ACM-Net: Action Context Modeling Network for Weakly-Supervised Temporal Action Localization", "abstract": "Weakly-supervised temporal action localization aims to localize action instances temporal boundary and identify the corresponding action category with only video-level labels. Traditional methods mainly focus on foreground and background frames separation with only a single attention branch and class activation sequence. However, we argue that apart from the distinctive foreground and background frames there are plenty of semantically ambiguous action context frames. It does not make sense to group those context frames to the same background class since they are semantically related to a specific action category. Consequently, it is challenging to suppress action context frames with only a single class activation sequence. To address this issue, in this paper, we propose an action-context modeling network termed ACM-Net, which integrates a three-branch attention module to measure the likelihood of each temporal point being action instance, context, or non-action background, simultaneously. Then based on the obtained three-branch attention values, we construct three-branch class activation sequences to represent the action instances, contexts, and non-action backgrounds, individually. To evaluate the effectiveness of our ACM-Net, we conduct extensive experiments on two benchmark datasets, THUMOS-14 and ActivityNet-1.3. The experiments show that our method can outperform current state-of-the-art methods, and even achieve comparable performance with fully-supervised methods. Code can be found at https://github.com/ispc-lab/ACM-Net"}}
{"id": "zWH_rVZ0_lS", "cdate": 1609459200000, "mdate": 1624473239029, "content": {"title": "Grasp Planning for Flexible Production with Small Lot Sizes based on CAD models using GPIS and Bayesian Optimization", "abstract": "Grasp planning for multi-fingered hands is still a challenging task due to the high nonlinear quality metrics, the high dimensionality of hand posture configuration, and complex object shapes. Analytical-based grasp planning algorithms formulate the grasping problem as a constraint optimization problem using advanced convex optimization solvers. However, these are not guaranteed to find a globally optimal solution. Data-driven based algorithms utilize machine learning algorithm frameworks to learn the grasp policy using enormous training data sets. This paper presents a new approach for grasp generation by formulating a global optimization problem with Bayesian optimization. Furthermore, we parameterize the object shape utilizing the Gaussian Process Implicit Surface (GPIS) to integrate the object shape information into the optimization process. Moreover, a chart defined on the object surface is used to refine palm pose locally. We introduced a dual optimization stage to optimize the palm pose and contact points separately. We further extend the Bayesian optimization by utilizing the alternating direction method of multipliers (ADMM) to eliminate contact optimization constraints. We conduct the experiments in the graspit! Simulator that demonstrates the effectiveness of this approach quantitatively and qualitatively. Our approach achieves a 95% success rate on various commonly objects with diverse shapes, scales, and weights"}}
{"id": "w0puyJw0TYq", "cdate": 1609459200000, "mdate": 1624473234715, "content": {"title": "Transitioning Spiking Neural Network Simulators to Heterogeneous Hardware", "abstract": "Spiking neural networks (SNN) are among the most computationally intensive types of simulation models, with node counts on the order of up to 1011. Currently, there is intensive research into hardware platforms suitable to support large-scale SNN simulations, whereas several of the most widely used simulators still rely purely on the execution on CPUs. Enabling the execution of these established simulators on heterogeneous hardware allows new studies to exploit the many-core hardware prevalent in modern supercomputing environments, while still being able to reproduce and compare with results from a vast body of existing literature. In this article, we propose a transition approach for CPU-based SNN simulators to enable the execution on heterogeneous hardware (e.g., CPUs, GPUs, and FPGAs), with only limited modifications to an existing simulator code base and without changes to model code. Our approach relies on manual porting of a small number of core simulator functionalities as found in common SNN simulators, whereas the unmodified model code is analyzed and transformed automatically. We apply our approach to the well-known simulator NEST and make a version executable on heterogeneous hardware available to the community. Our measurements show that at full utilization, a single GPU achieves the performance of about 9 CPU cores. A CPU-GPU co-execution with load balancing is also demonstrated, which shows better performance compared to CPU-only or GPU-only execution. Finally, an analytical performance model is proposed to heuristically determine the optimal parameters to execute the heterogeneous NEST."}}
{"id": "sdlOq3XGL9L", "cdate": 1609459200000, "mdate": 1624473260889, "content": {"title": "An Evaluation of \"Crash Prediction Networks\" (CPN) for Autonomous Driving Scenarios in CARLA Simulator", "abstract": ""}}
