{"id": "bTXw8y6RyO", "cdate": 1668604518606, "mdate": 1668604518606, "content": {"title": "Contrast-reconstruction Representation Learning for Self-supervised Skeleton-based Action Recognition", "abstract": "Skeleton-based action recognition is widely used in varied areas, e.g., surveillance and human-machine interaction. Existing models are mainly learned in a supervised manner, thus heavily depending on large-scale labeled data, which could be infeasible when labels are prohibitively expensive. In this paper, we propose a novel Contrast-Reconstruction Representation Learning network (CRRL) that simultaneously captures postures and motion dynamics for unsupervised skeleton-based action recognition. It consists of three parts: Sequence Reconstructor (SER), Contrastive Motion Learner (CML), and Information Fuser (INF). SER learns representation from skeleton coordinate sequence via reconstruction. However the learned representation tends to focus on trivial postural coordinates and be hesitant in motion learning. To enhance the learning of motions, CML performs contrastive learning between the representation learned\nfrom coordinate sequences and additional velocity sequences, respectively. Finally, in the INF module, we explore varied strategies to combine SER and CML, and propose to couple postures and motions via a knowledge-distillation based fusion strategy which transfers the motion learning from CML to SER. Experimental results on several benchmarks, i.e., NTU RGB+D 60/120, PKU-MMD, CMU, and NW-UCLA, demonstrate the promise of the our method by outperforming state-of-the-art approaches."}}
{"id": "ilDfZG2BVDh", "cdate": 1667365147319, "mdate": 1667365147319, "content": {"title": "A novel domain adaptation theory with Jensen\u2013Shannon divergence", "abstract": "Domain adaptation aims to alleviate the shift between training and test distribution, where the DA theory is crucial in understanding the success of domain adaptation algorithms. In this paper, we reveal the incoherence between the empirical domain adversarial training and its generally assumed theoretical counterpart based on \\mathcal{H}-divergence. Concretely, we find that \\mathcal{H}-divergence is not equivalent to Jensen\u2013Shannon divergence, the optimization objective in domain adversarial training. To this end, we establish a new theoretical framework by directly proving the upper and lower target risk bounds based on the joint distributional Jensen\u2013Shannon divergence. We further derive bidirectional upper bounds for marginal and conditional shifts. Our framework exhibits inherent flexibility for different transfer learning problems, which is usable for various scenarios. From an algorithmic perspective, our theory enables a generic guideline of the unified principles of semantic conditional matching, feature marginal matching, and label marginal shift correction. We employ algorithms for each principle and empirically validate the benefits of our framework."}}
{"id": "YbmHRyXDWv7", "cdate": 1667353609907, "mdate": 1667353609907, "content": {"title": "Context-guided entropy minimization for semi-supervised domain adaptation", "abstract": "Semi-Supervised Domain Adaptation has been widely studied with various approaches to address domain shift with labeled source-domain data combined with scarcely labeled target-domain data. Model adaptation is becoming promising with a paradigm of source pre-training and target fine-tuning, which eliminates the simultaneous availability of data from both domains and makes for data privacy. Among the model adaptation methods, Entropy Minimization (EM) is popularly incorporated to encourage a low-density separation on target samples. However, EM tends to brutally force models to make over-confident predictions, which could make the models collapse with deteriorated performance. In this paper, we first study the over-confidence of EM with a quantitative analysis, which shows the importance of capturing the dependency among labels. To address this issue, we propose to guide EM via longitudinal self-distillation. Specifically, we produce a dynamic \u201cteacher\u201d label distribution during training by constructing a graph on target data and perform pseudo-label propagation to encourage the \u201cteacher\u201d distribution to capture context category dependency based on a global data structure. Then EM is guided longitudinally by distilling the learned label distribution to combat the brute-force over-confidence. Extensive experiments demonstrate the effectiveness of our methods."}}
{"id": "qIlLNOJsKxJ", "cdate": 1667353423465, "mdate": 1667353423465, "content": {"title": "Learning Spatial-Preserved Skeleton Representations for Few-Shot Action Recognition", "abstract": "Few-shot action recognition aims to recognize few-labeled novel action classes and attracts growing attention due to practical significance. Human skeletons provide explainable and data-efficient representation for this problem by explicitly modeling spatial-temporal relations among skeleton joints. However, existing skeleton-based spatial temporal models tend to deteriorate the positional distinguishability of joints, which leads to fuzzy spatial matching and poor explainability. To address these issues, we propose a novel spatial matching strategy consisting of spatial disentanglement and spatial activation. The motivation behind spatial disentanglement is that we find more spatial information for leaf nodes (e.g., the \u201chand\u201d joint ) is beneficial to increase representation diversity for skeleton matching. To achieve spatial disentanglement, we encourage the skeletons to be represented in a full rank space with rank maximization constraint. Finally, an attention-based spatial activation mechanism is introduced to incorporate the disentanglement, by adaptively adjusting the disentangled joints according to matching pairs. Extensive experiments on three skeleton benchmarks demonstrate that the proposed spatial matching strategy can be effectively inserted into existing temporal alignment frameworks, achieving considerable performance improvements as well as inherent explainability."}}
{"id": "SkxpDT4YvS", "cdate": 1569439077191, "mdate": null, "content": {"title": "Policy Optimization with Stochastic Mirror Descent", "abstract": "Improving sample efficiency has been a longstanding goal in reinforcement learning.\nIn this paper, we propose the $\\mathtt{VRMPO}$: a sample efficient policy gradient method with stochastic mirror descent.\nA novel variance reduced policy gradient estimator is the key of $\\mathtt{VRMPO}$ to improve sample efficiency.\nOur $\\mathtt{VRMPO}$ needs only $\\mathcal{O}(\\epsilon^{-3})$ sample trajectories to achieve an $\\epsilon$-approximate first-order stationary point, \nwhich matches the best-known sample complexity.\nWe conduct extensive experiments to show our algorithm outperforms state-of-the-art policy gradient methods in various settings."}}
{"id": "BosNJCWlOaB", "cdate": 1546300800000, "mdate": null, "content": {"title": "Exploiting Local Feature Patterns for Unsupervised Domain Adaptation.", "abstract": "Unsupervised domain adaptation methods aim to alleviate performance degradation caused by domain-shift by learning domain-invariant representations. Existing deep domain adaptation methods focus on holistic feature alignment by matching source and target holistic feature distributions, without considering local features and their multi-mode statistics. We show that the learned local feature patterns are more generic and transferable and a further local feature distribution matching enables fine-grained feature alignment. In this paper, we present a method for learning domain-invariant local feature patterns and jointly aligning holistic and local feature statistics. Comparisons to the state-of-the-art unsupervised domain adaptation methods on two popular benchmark datasets demonstrate the superiority of our approach and its effectiveness on alleviating negative transfer."}}
{"id": "rkzcvoA9YX", "cdate": 1538087777908, "mdate": null, "content": {"title": "Few-Shot Learning by Exploiting Object Relation", "abstract": "\nFew-shot learning trains image classifiers over datasets with few examples per category. \nIt poses challenges for the optimization algorithms, which typically require many examples to fine-tune the model parameters for new categories. \nDistance-learning-based approaches avoid the optimization issue by embedding the images into a metric space and applying the nearest neighbor classifier for new categories. In this paper, we propose to exploit the object-level relation to learn the image relation feature, which is converted into a distance directly.\nFor a new category, even though its images are not seen by the model, some objects may appear in the training images. Hence, object-level relation is useful for inferring the relation of images from unseen categories. Consequently, our model generalizes well for new categories without fine-tuning.\nExperimental results on benchmark datasets show that our approach outperforms state-of-the-art methods."}}
{"id": "H1bbPg-dbH", "cdate": 1514764800000, "mdate": null, "content": {"title": "Unsupervised Representation Learning With Long-Term Dynamics for Skeleton Based Action Recognition", "abstract": "In recent years, skeleton based action recognition is becoming an increasingly attractive alternative to existing video-based approaches, beneficial from its robust and comprehensive 3D information. In this paper, we explore an unsupervised representation learning approach for the first time to capture the long-term global motion dynamics in skeleton sequences. We design a conditional skeleton inpainting architecture for learning a fixed-dimensional representation, guided by additional adversarial training strategies. We quantitatively evaluate the effectiveness of our learning approach on three well-established action recognition datasets. Experimental results show that our learned representation is discriminative for classifying actions and can substantially reduce the sequence inpainting errors."}}
