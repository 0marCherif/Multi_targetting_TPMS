{"id": "BN0-VRl9cZ", "cdate": 1600105143410, "mdate": null, "content": {"title": "Exchangeable modelling of relational data: checking sparsity, train-test splitting, and sparse exchangeable Poisson matrix factorization", "abstract": "A variety of machine learning tasks\u2014e.g., matrix factorization, topic\nmodelling, and feature allocation\u2014can be viewed as learning the\nparameters of a probability distribution over bipartite graphs. Recently, a new class of models for networks, the sparse exchangeable\ngraphs, have been introduced to resolve some important pathologies of traditional approaches to statistical network modelling; most\nnotably, the inability to model sparsity (in the asymptotic sense).\nThe present paper explains some practical insights arising from\nthis work. We \u001brst show how to check if sparsity is relevant for\nmodelling a given (\u001bxed size) dataset by using network subsampling to identify a simple signature of sparsity. We discuss the\nimplications of the (sparse) exchangeable subsampling theory for\ntest\u2013train dataset splitting; we argue common approaches can lead\nto biased results, and we propose a principled alternative. Finally,\nwe study sparse exchangeable Poisson matrix factorization as a\nworked example. In particular, we show how to adapt mean \u001beld\nvariational inference to the sparse exchangeable setting, allowing\nus to scale inference to huge datasets."}}
{"id": "X2T4gTZa6KK", "cdate": 1600104985081, "mdate": null, "content": {"title": "An estimator for the tail-index of graphex processes", "abstract": "Graphex processes resolve some pathologies in traditional random graph models, notably, providing models that are both projective and\nallow sparsity. In a recent paper, Caron and Rousseau (2017) show that for\na large class of graphex models, the sparsity behaviour is governed by a\nsingle parameter: the tail-index of the function (the graphon) that parameterizes the model. We propose an estimator for this parameter and quantify\nits risk. Our estimator is a simple, explicit function of the degrees of the\nobserved graph. In many situations of practical interest, the risk decays\npolynomially in the size of the observed graph. We illustrate the importance of a good estimator for the tail-index through the graph analogue of\nthe unseen species problem. We also derive the analogous results for the\nbipartite graphex processes."}}
{"id": "H1xM0lu6LS", "cdate": 1568665801946, "mdate": null, "content": {"title": "Approximations in Probabilistic Programs", "abstract": "We introduce a new language construct, \"stat\", which converts the description of the Markov kernel of an ergodic Markov chain into a sample from its unique stationary distribution.  Up to minor changes in how certain error conditions are handled, we show that language constructs for soft-conditioning and normalization can be compiled away from the extended language. We then explore the problem of approximately implementing the semantics of the language with potentially nested \"stat\" expressions, in a language without \"stat\".\nFor a single \"stat\" term, the natural unrolling yields provable guarantees in an asymptotic sense. \nIn the general case, under uniform ergodicity assumptions, we are able to give quantitative error bounds and convergence results for the approximate implementation of the extended first-order language. We leave open the question of whether the same guarantees can be made assuming mere geometric ergodicity."}}
{"id": "BzG4kD3DyGc", "cdate": 1546300800000, "mdate": 1647438934679, "content": {"title": "Approximations in Probabilistic Programs", "abstract": "We study the first-order probabilistic programming language introduced by Staton et al. (2016), but with an additional language construct, $\\mathbf{stat}$, that, like the fixpoint operator of Atkinson et al. (2018), converts the description of the Markov kernel of an ergodic Markov chain into a sample from its unique stationary distribution. Up to minor changes in how certain error conditions are handled, we show that $\\mathbf{norm}$ and $\\mathbf{score}$ are eliminable from the extended language, in the sense of Felleisen (1991). We do so by giving an explicit program transformation and proof of correctness. In fact, our program transformation implements a Markov chain Monte Carlo algorithm, in the spirit of the \"Trace-MH\" algorithm of Wingate et al. (2011) and Goodman et al. (2008), but less sophisticated to enable analysis. We then explore the problem of approximately implementing the semantics of the language with potentially nested $\\mathbf{stat}$ expressions, in a language without $\\mathbf{stat}$. For a single $\\mathbf{stat}$ term, the error introduced by the finite unrolling proposed by Atkinson et al. (2018) vanishes only asymptotically. In the general case, no guarantees exist. Under uniform ergodicity assumptions, we are able to give quantitative error bounds and convergence results for the approximate implementation of the extended first-order language."}}
{"id": "oJaMduRT-y", "cdate": 1451606400000, "mdate": 1683818378599, "content": {"title": "Modeling trajectories of mental health: challenges and opportunities", "abstract": "More than two thirds of mental health problems have their onset during childhood or adolescence. Identifying children at risk for mental illness later in life and predicting the type of illness is not easy. We set out to develop a platform to define subtypes of childhood social-emotional development using longitudinal, multifactorial trait-based measures. Subtypes discovered through this study could ultimately advance psychiatric knowledge of the early behavioural signs of mental illness. To this extent we have examined two types of models: latent class mixture models and GP-based models. Our findings indicate that while GP models come close in accuracy of predicting future trajectories, LCMMs predict the trajectories as well in a fraction of the time. Unfortunately, neither of the models are currently accurate enough to lead to immediate clinical impact. The available data related to the development of childhood mental health is often sparse with only a few time points measured and require novel methods with improved efficiency and accuracy."}}
