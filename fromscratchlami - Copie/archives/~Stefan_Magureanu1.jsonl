{"id": "3mKsb38me8", "cdate": 1671895008666, "mdate": 1671895008666, "content": {"title": "Graph Neural Networks for Nomination and Representation Learning of Web Elements", "abstract": "This paper tackles the under-explored problem of DOM element\nnomination and representation learning with three important contributions. First, we present a large-scale and realistic dataset of\nwebpages, far richer and more diverse than other datasets proposed\nfor element representation learning, classification and nomination\non the web. The dataset contains 51, 701 manually labeled product\npages from 8, 175 real e-commerce websites. Second, we adapt several Graph Neural Network (GNN) architectures to website DOM\ntrees and benchmark their performance on a diverse set of element\nnomination tasks using our proposed dataset. In element nomination, a single element on a page is selected for a given class. We\nshow that on our challenging dataset a simple Convolutional GNN\noutperforms state-of-the-art methods on web element nomination.\nFinally, we propose a new training method that further boosts the\nelement nomination accuracy. In nomination for the web, classification (assigning a class to a given element) is usually used as\na surrogate objective for nomination during training. Our novel\ntraining methodology steers the classification objective towards\nthe more complex and useful nomination objective."}}
{"id": "rqJbOYy6n-Z", "cdate": 1609459200000, "mdate": 1681724657757, "content": {"title": "The Klarna Product Page Dataset: A Realistic Benchmark for Web Representation Learning", "abstract": "This paper tackles the under-explored problem of DOM element nomination and representation learning with three important contributions. First, we present a large-scale and realistic dataset of webpages, far richer and more diverse than other datasets proposed for element representation learning, classification and nomination on the web. The dataset contains $51,701$ manually labeled product pages from $8,175$ real e-commerce websites. Second, we adapt several Graph Neural Network (GNN) architectures to website DOM trees and benchmark their performance on a diverse set of element nomination tasks using our proposed dataset. In element nomination, a single element on a page is selected for a given class. We show that on our challenging dataset a simple Convolutional GNN outperforms state-of-the-art methods on web element nomination. Finally, we propose a new training method that further boosts the element nomination accuracy. In nomination for the web, classification (assigning a class to a given element) is usually used as a surrogate objective for nomination during training. Our novel training methodology steers the classification objective towards the more complex and useful nomination objective."}}
{"id": "KihZBTkkHeO", "cdate": 1609459200000, "mdate": 1681724657692, "content": {"title": "Online Learning of Optimally Diverse Rankings", "abstract": "Search engines answer users' queries by listing relevant items (e.g. documents, songs, products, web pages, ...). These engines rely on algorithms that learn to rank items so as to present an ordered list maximizing the probability that it contains relevant item. The main challenge in the design of learning-to-rank algorithms stems from the fact that queries often have different meanings for different users. In absence of any contextual information about the query, one often has to adhere to the {\\it diversity} principle, i.e., to return a list covering the various possible topics or meanings of the query. To formalize this learning-to-rank problem, we propose a natural model where (i) items are categorized into topics, (ii) users find items relevant only if they match the topic of their query, and (iii) the engine is not aware of the topic of an arriving query, nor of the frequency at which queries related to various topics arrive, nor of the topic-dependent click-through-rates of the items. For this problem, we devise LDR (Learning Diverse Rankings), an algorithm that efficiently learns the optimal list based on users' feedback only. We show that after $T$ queries, the regret of LDR scales as $O((N-L)\\log(T))$ where $N$ is the number of all items. We further establish that this scaling cannot be improved, i.e., LDR is order optimal. Finally, using numerical experiments on both artificial and real-world data, we illustrate the superiority of LDR compared to existing learning-to-rank algorithms."}}
{"id": "lBPID7fWTQ", "cdate": 1514764800000, "mdate": null, "content": {"title": "Online Learning of Optimally Diverse Rankings", "abstract": "Search engines answer users' queries by listing relevant items (e.g. documents, songs, products, web pages, ...). These engines rely on algorithms that learn to rank items so as to present an ordered list maximizing the probability that it contains relevant item. The main challenge in the design of learning-to-rank algorithms stems from the fact that queries often have different meanings for different users. In absence of any contextual information about the query, one often has to adhere to the diversity principle, i.e., to return a list covering the various possible topics or meanings of the query. To formalize this learning-to-rank problem, we propose a natural model where (i) items are categorized into topics, (ii) users find items relevant only if they match the topic of their query, and (iii) the engine is not aware of the topic of an arriving query, nor of the frequency at which queries related to various topics arrive, nor of the topic-dependent click-through-rates of the items. For this problem, we devise LDR (Learning Diverse Rankings), an algorithm that efficiently learns the optimal list based on users' feedback only. We show that after T queries, the regret of LDR scales as O((N-L)log(T)) where N is the number of all items. This scaling cannot be improved, i.e., LDR is order optimal."}}
{"id": "Z2tAE-aieAq", "cdate": 1514764800000, "mdate": null, "content": {"title": "Generic Asymptotically Optimal Algorithms for Multi-Armed Bandits", "abstract": "In this presentation, we address generic multi-armed bandit problems with stochastic rewards and known structure. Our notion of structure is generic and includes well-studied bandit structures such as linear, combinatorial, unimodal, Lipschitz, dueling etc. We propose a generic algorithm and prove its asymptotic optimality when the time horizon goes to infinity. We further propose a finite time regret analysis of our algorithm. As a byproduct of our analysis we develop several novel technical results which are useful to analyze generic bandit problems. More details can be found in the technical report https://arxiv.org/abs/1711.00400."}}
{"id": "Iqn-BF5bWtZ", "cdate": 1514764800000, "mdate": null, "content": {"title": "Efficient Online Learning under Bandit Feedback", "abstract": "In this thesis we address the multi-armed bandit (MAB) problem with stochastic rewards and correlated arms. Particularly, we investigate the case when the expected rewards are a Lipschitz function ..."}}
{"id": "X6158u8L6bj", "cdate": 1483228800000, "mdate": null, "content": {"title": "Online Learning of Optimally Diverse Rankings", "abstract": "Search engines answer users' queries by listing relevant items (e.g. documents, songs, products, web pages, ...). These engines rely on algorithms that learn to rank items so as to present an ordered list maximizing the probability that it contains relevant item. The main challenge in the design of learning-to-rank algorithms stems from the fact that queries often have different meanings for different users. In absence of any contextual information about the query, one often has to adhere to the {\\it diversity} principle, i.e., to return a list covering the various possible topics or meanings of the query. To formalize this learning-to-rank problem, we propose a natural model where (i) items are categorized into topics, (ii) users find items relevant only if they match the topic of their query, and (iii) the engine is not aware of the topic of an arriving query, nor of the frequency at which queries related to various topics arrive, nor of the topic-dependent click-through-rates of the items. For this problem, we devise LDR (Learning Diverse Rankings), an algorithm that efficiently learns the optimal list based on users' feedback only. We show that after $T$ queries, the regret of LDR scales as $O((N-L)\\log(T))$ where $N$ is the number of all items. We further establish that this scaling cannot be improved, i.e., LDR is order optimal. Finally, using numerical experiments on both artificial and real-world data, we illustrate the superiority of LDR compared to existing learning-to-rank algorithms."}}
{"id": "R6GZKgWYuix", "cdate": 1483228800000, "mdate": 1681724657702, "content": {"title": "Minimal Exploration in Structured Stochastic Bandits", "abstract": "This paper introduces and addresses a wide class of stochastic bandit problems where the function mapping the arm to the corresponding reward exhibits some known structural properties. Most existing structures (e.g. linear, Lipschitz, unimodal, combinatorial, dueling, ...) are covered by our framework. We derive an asymptotic instance-specific regret lower bound for these problems, and develop OSSB, an algorithm whose regret matches this fundamental limit. OSSB is not based on the classical principle of \"optimism in the face of uncertainty\" or on Thompson sampling, and rather aims at matching the minimal exploration rates of sub-optimal arms as characterized in the derivation of the regret lower bound. We illustrate the efficiency of OSSB using numerical experiments in the case of the linear bandit problem and show that OSSB outperforms existing algorithms, including Thompson sampling."}}
{"id": "HJ-GBv-OZr", "cdate": 1483228800000, "mdate": null, "content": {"title": "Minimal Exploration in Structured Stochastic Bandits", "abstract": "This paper introduces and addresses a wide class of stochastic bandit problems where the function mapping the arm to the corresponding reward exhibits some known structural properties. Most existing structures (e.g. linear, lipschitz, unimodal, combinatorial, dueling,...) are covered by our framework. We derive an asymptotic instance-specific regret lower bound for these problems, and develop OSSB, an algorithm whose regret matches this fundamental limit. OSSB is not based on the classical principle of ``optimism in the face of uncertainty'' or on Thompson sampling, and rather aims at matching the minimal exploration rates of sub-optimal arms as characterized in the derivation of the regret lower bound. We illustrate the efficiency of OSSB using numerical experiments in the case of the linear bandit problem and show that OSSB outperforms existing algorithms, including Thompson sampling"}}
{"id": "cMppFiqxC43", "cdate": 1451606400000, "mdate": null, "content": {"title": "Optimal Distributed Scheduling in Wireless Networks Under the SINR Interference Model", "abstract": "In wireless networks, the design of radio resource sharing mechanisms is complicated by the complex interference constraints among the various links. In their seminal paper (IEEE Trans. Autom. Control, vol. 37, no. 12, pp. 1936-1948), Tassiulas and Ephremides introduced Maximum Weighted Scheduling, a centralized resource sharing algorithm, and proved its optimality. Since then, there have been extensive research efforts to devise distributed implementations of this algorithm. Recently, distributed adaptive CSMA scheduling schemes have been proposed and shown to be optimal, without the need of message passing among transmitters. However, their analysis relies on the assumption that interference can be accurately modeled by a simple interference graph. In this paper, we consider the more realistic and challenging signal-to-interference-plus-noise ratio (SINR) interference model. We present distributed scheduling algorithms that: 1) are optimal under the SINR interference model; and 2) do not require any message passing. These algorithms are based on a combination of a simple and efficient power allocation strategy referred to as Power Packing and randomization techniques. The optimality of our algorithms is illustrated in various traffic scenarios using numerical experiments."}}
