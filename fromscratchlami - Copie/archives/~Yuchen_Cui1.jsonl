{"id": "Ffn8Z4Q-zU", "cdate": 1686324879381, "mdate": null, "content": {"title": "Gesture-Informed Robot Assistance via Foundation Models", "abstract": "Gestures serve as a fundamental and significant mode of non-verbal communication among humans. Deictic gestures (such as pointing towards an object), in particular, offer valuable means of efficiently expressing intent in situations where language is inaccessible, restricted, or highly specialized. As a result, it is essential for robots to comprehend gestures in order to infer human intentions and establish more effective coordination with them. Prior work often rely on a rigid hand-coded library of gestures along with their meanings. However, interpretation of gestures is often context-dependent, requiring more flexibility and common-sense reasoning. In this work, we propose a framework, GIRAF, for more flexibly interpreting gesture and language instructions by leveraging the power of large language models. Our framework is able to accurately infer human intent and contextualize the meaning of their gestures for more effective human-robot collaboration. We instantiate the framework for three table-top manipulation tasks and demonstrate that it is both effective and preferred by users. We further demonstrate GIRAF\u2019s ability on reasoning about diverse types of gestures by curating a GestureInstruct dataset consisting of 36 different task scenarios. GIRAF achieved 81% success rate on finding the correct plan for tasks in GestureInstruct.\nVideos and datasets can be found on our project website: https://tinyurl.com/giraf23"}}
{"id": "_A15qsPswaK", "cdate": 1686324869282, "mdate": null, "content": {"title": "HYDRA: Hybrid Robot Actions for Imitation Learning", "abstract": "Imitation Learning (IL) is a sample efficient paradigm for robot learning using expert demonstrations. However, policies learned through IL suffer from state distribution shift at test time, due to compounding errors in action prediction which lead to previously unseen states. Choosing an action representation for the policy that minimizes this distribution shift is critical in imitation learning. Prior work propose using temporal action abstractions to reduce compounding errors, but they often sacrifice policy dexterity or require domain-specific knowledge. To address these trade-offs, we introduce HYDRA, a method that leverages a hybrid action space with two levels of action abstractions: sparse high-level waypoints and dense low-level actions. HYDRA dynamically switches between action abstractions at test time to enable both coarse and fine-grained control of a robot. In addition, HYDRA employs action relabeling to increase the consistency of actions in the dataset, further reducing distribution shift. HYDRA outperforms prior imitation learning methods by 30-40% on seven challenging simulation and real world environments, involving long-horizon tasks in the real world like making coffee and toasting bread. Videos are found on our website: https://tinyurl.com/3mc6793z"}}
{"id": "Zlrp_gGYHbj", "cdate": 1653925428668, "mdate": null, "content": {"title": "Can Foundation Models Perform Zero-Shot Task Specification For Robot Manipulation?", "abstract": "Task specification is at the core of programming autonomous robots. A low-effort modality for task\nspecification is critical for engagement of non-expert end-users and ultimate adoption of personalized\nrobot agents. A widely studied approach to task specification is through goals, using either\ncompact state vectors or goal images from the same robot scene. The former is hard to interpret for\nnon-experts and necessitates detailed state estimation and scene understanding. The latter requires\nthe generation of desired goal image, which often requires a human to complete the task, defeating\nthe purpose of having autonomous robots. In this work, we explore alternate and more general\nforms of goal specification that are expected to be easier for humans to specify and use such as\nimages obtained from the internet, hand sketches that provide a visual description of the desired\ntask, or simple language descriptions. As a preliminary step towards this, we investigate the capabilities\nof large scale pre-trained models (foundation models) for zero-shot goal specification, and\nfind promising results in a collection of simulated robot manipulation tasks and real-world datasets."}}
{"id": "BHBz6bP2jb9", "cdate": 1647195908786, "mdate": null, "content": {"title": "Shared Autonomy for Robotic Manipulation with Language Corrections", "abstract": "Traditional end-to-end instruction following approaches for robotic manipulation are notoriously sample inefficient and lack adaptivity; for most single-turn methods, there is no way to provide additional language supervision to adapt robot behavior online \u2013 a property critical to deploying robots in collaborative, safety-critical environments. In this work, we present a method for incorporating language corrections, built on the insight that an initial instruction and subsequent corrections differ mainly in the amount of grounded context needed. To focus on manipulation domains where the sample efficiency of existing work is prohibitive, we incorporate our method into a shared autonomy system. Shared autonomy splits agency between the human and robot; rather than specifying a goal the robot needs to achieve alone, language informs the control space provided to the human. Splitting agency this way allows the robot to learn the coarse, high-level parts of a task, offloading more involved decisions \u2013 such as when to execute a grasp, or if a grasp is solid \u2013 to humans. Our user study on a Franka Emika Panda arm shows that our correction-aware system is sample-efficient and obtains significant gains over non-adaptive baselines."}}
{"id": "DGvcfLjQKEI", "cdate": 1624321500409, "mdate": 1624321500409, "content": {"title": "Risk-aware active inverse reinforcement learning", "abstract": "Active learning from demonstration allows a robot to query a human for specific types of input to achieve efficient learning. Existing work has explored a variety of active query strategies; however, to our knowledge, none of these strategies directly minimize the performance risk of the policy the robot is learning. Utilizing recent advances in performance bounds for inverse reinforcement learning, we propose a risk-aware active inverse reinforcement learning algorithm that focuses active queries on areas of the state space with the potential for large generalization error. We show that risk-aware active learning outperforms standard active IRL approaches on gridworld, simulated driving, and table setting tasks, while also providing a performance-based stopping criterion that allows a robot to know when it has received enough demonstrations to safely perform a task."}}
{"id": "iv7OylsjXxE", "cdate": 1546300800000, "mdate": null, "content": {"title": "Uncertainty-Aware Data Aggregation for Deep Imitation Learning.", "abstract": "Estimating statistical uncertainties allows autonomous agents to communicate their confidence during task execution and is important for applications in safety-critical domains such as autonomous driving. In this work, we present the uncertainty-aware imitation learning (UAIL) algorithm for improving end-to-end control systems via data aggregation. UAIL applies Monte Carlo Dropout to estimate uncertainty in the control output of end-to-end systems, using states where it is uncertain to selectively acquire new training data. In contrast to prior data aggregation algorithms that force human experts to visit sub-optimal states at random, UAIL can anticipate its own mistakes and switch control to the expert in order to prevent visiting a series of sub-optimal states. Our experimental results from simulated driving tasks demonstrate that our proposed uncertainty estimation method can be leveraged to reliably predict infractions. Our analysis shows that UAIL outperforms existing data aggregation algorithms on a series of benchmark tasks."}}
{"id": "eJ84gtvpuOk", "cdate": 1546300800000, "mdate": null, "content": {"title": "Uncertainty-Aware Data Aggregation for Deep Imitation Learning.", "abstract": "Estimating statistical uncertainties allows autonomous agents to communicate their confidence during task execution and is important for applications in safety-critical domains such as autonomous driving. In this work, we present the uncertainty-aware imitation learning (UAIL) algorithm for improving end-to-end control systems via data aggregation. UAIL applies Monte Carlo Dropout to estimate uncertainty in the control output of end-to-end systems, using states where it is uncertain to selectively acquire new training data. In contrast to prior data aggregation algorithms that force human experts to visit sub-optimal states at random, UAIL can anticipate its own mistakes and switch control to the expert in order to prevent visiting a series of sub-optimal states. Our experimental results from simulated driving tasks demonstrate that our proposed uncertainty estimation method can be leveraged to reliably predict infractions. Our analysis shows that UAIL outperforms existing data aggregation algorithms on a series of benchmark tasks."}}
{"id": "AZGOg_S5l4n", "cdate": 1546300800000, "mdate": null, "content": {"title": "Risk-Aware Active Inverse Reinforcement Learning.", "abstract": "Active learning from demonstration allows a robot to query a human for specific types of input to achieve efficient learning. Existing work has explored a variety of active query strategies; however, to our knowledge, none of these strategies directly minimize the performance risk of the policy the robot is learning. Utilizing recent advances in performance bounds for inverse reinforcement learning, we propose a risk-aware active inverse reinforcement learning algorithm that focuses active queries on areas of the state space with the potential for large generalization error. We show that risk-aware active learning outperforms standard active IRL approaches on gridworld, simulated driving, and table setting tasks, while also providing a performance-based stopping criterion that allows a robot to know when it has received enough demonstrations to safely perform a task."}}
{"id": "Sr3J9dqhtgZ", "cdate": 1514764800000, "mdate": null, "content": {"title": "Active Reward Learning from Critiques.", "abstract": "Learning from demonstration algorithms, such as Inverse Reinforcement Learning, aim to provide a natural mechanism for programming robots, but can often require a prohibitive number of demonstrations to capture important subtleties of a task. Rather than requesting additional demonstrations blindly, active learning methods leverage uncertainty to query the user for action labels at states with high expected information gain. However, this approach can still require a large number of labels to adequately reduce uncertainty and may also be unintuitive, as users are not accustomed to determining optimal actions in a single out-of-context state. To address these shortcomings, we propose a novel trajectory-based active Bayesian inverse reinforcement learning algorithm that (1) queries the user for <i xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">critiques</i> of automatically generated trajectories, rather than asking for demonstrations or action labels, (2) utilizes <i xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">trajectory segmentation</i> to expedite the critique / labeling process, and (3) predicts the user's critiques to generate the most highly informative trajectory queries. We evaluated our algorithm in simulated domains, finding it to compare favorably to prior work and a randomized baseline."}}
{"id": "CjPB3PkXHK", "cdate": 1514764800000, "mdate": null, "content": {"title": "Risk-Aware Active Inverse Reinforcement Learning.", "abstract": "Active learning from demonstration allows a robot to query a human for specific types of input to achieve efficient learning. Existing work has explored a variety of active query strategies; howeve..."}}
