{"id": "AY1MnxgxBxm", "cdate": 1684165167130, "mdate": 1684165167130, "content": {"title": "A probabilistic multi-label classifier with missing and noisy labels handling capability", "abstract": "Multi-label classification with a large set of labels is a challenging task. Label-Space Dimension Reduction (LSDR) is the most popular approach that addresses this problem. LSDR methods project the high-dimensional label vectors onto a low-dimensional space that can be predicted from the feature space. Many LSDR methods assume that the training data provide complete label vector for all training samples while this assumption is usually violated particularly when label vectors are high dimensional. In this paper, we propose a probabilistic model that has an effective mechanism to handle missing and noisy labels. In the proposed Bayesian network model, a set of auxiliary random variables, called experts, are incorporated to provide robustness to missing and noisy labels. Variational inference is utilized to find the desired probabilities in this model. The proposed approximate inference is highly parallelizable and can be implemented efficiently. Experiments on real-world datasets show that our method outperforms state-of-the-art multi-label classifiers by a large margin."}}
{"id": "xtUSvvbxW1", "cdate": 1684165060198, "mdate": 1684165060198, "content": {"title": "An Efficient Semi-supervised Multi-label Classi- fier Capable of Handling Missing Labels", "abstract": "Multi-label classification has received considerable interest in recent years. Multi-label classifiers usually need to address many issues including: handling large-scale datasets with many instances and a large set of labels, compensating missing label assignments in the training set, considering correlations between labels, as well as exploiting unlabeled data to improve prediction performance. To tackle datasets with a large set of labels, embedding-based methods represent the label assignments in a low-dimensional space. Many state-of-the-art embedding-based methods use a linear dimensionality reduction to map the label assignments to a low-dimensional space. However, by doing so, these methods actually neglect the tail labels - labels that are infrequently assigned to instances. In this paper, we propose an embedding-based method that non-linearly embeds the label vectors using a stochastic approach, thereby predicting the tail labels more accurately. Moreover, the proposed method has excellent mechanisms for handling missing labels, dealing with large-scale datasets, as well as exploiting unlabeled data. Experiments on real-world datasets show that our method outperforms state-of-the-art multi-label classifiers by a large margin, in terms of prediction performance, as well as training time. Our implementation of the proposed method is available online at:https://github.com/Akbarnejad/ESMC_ Implementation."}}
{"id": "xnpWnMq-ia", "cdate": 1672531200000, "mdate": 1699628564083, "content": {"title": "VISA-FSS: A Volume-Informed Self Supervised Approach for Few-Shot 3D Segmentation", "abstract": "Few-shot segmentation (FSS) models have gained popularity in medical imaging analysis due to their ability to generalize well to unseen classes with only a small amount of annotated data. A key requirement for the success of FSS models is a diverse set of annotated classes as the base training tasks. This is a difficult condition to meet in the medical domain due to the lack of annotations, especially in volumetric images. To tackle this problem, self-supervised FSS methods for 3D images have been introduced. However, existing methods often ignore intra-volume information in 3D image segmentation, which can limit their performance. To address this issue, we propose a novel self-supervised volume-aware FSS framework for 3D medical images, termed VISA-FSS. In general, VISA-FSS aims to learn continuous shape changes that exist among consecutive slices within a volumetric image to improve the performance of 3D medical segmentation. To achieve this goal, we introduce a volume-aware task generation method that utilizes consecutive slices within a 3D image to construct more varied and realistic self-supervised FSS tasks during training. In addition, to provide pseudo-labels for consecutive slices, a novel strategy is proposed that propagates pseudo-labels of a slice to its adjacent slices using flow field vectors to preserve anatomical shape continuity. In the inference time, we then introduce a volumetric segmentation strategy to fully exploit the inter-slice information within volumetric images. Comprehensive experiments on two common medical benchmarks, including abdomen CT and MRI, demonstrate the effectiveness of our model over state-of-the-art methods. Code is available at https://github.com/sharif-ml-lab/visa-fss"}}
{"id": "u4Qdq7PCp", "cdate": 1672531200000, "mdate": 1699628564055, "content": {"title": "Sina at SemEval-2023 Task 4: A Class-Token Attention-based Model for Human Value Detection", "abstract": "Omid Ghahroodi, Mohammad Ali Sadraei Javaheri, Doratossadat Dastgheib, Mahdieh Soleymani Baghshah, Mohammad Hossein Rohban, Hamid Rabiee, Ehsaneddin Asgari. Proceedings of the 17th International Workshop on Semantic Evaluation (SemEval-2023). 2023."}}
{"id": "Z7q9HefnUSC", "cdate": 1672531200000, "mdate": 1682320809460, "content": {"title": "A Distinct Unsupervised Reference Model From The Environment Helps Continual Learning", "abstract": "The existing continual learning methods are mainly focused on fully-supervised scenarios and are still not able to take advantage of unlabeled data available in the environment. Some recent works tried to investigate semi-supervised continual learning (SSCL) settings in which the unlabeled data are available, but it is only from the same distribution as the labeled data. This assumption is still not general enough for real-world applications and restricts the utilization of unsupervised data. In this work, we introduce Open-Set Semi-Supervised Continual Learning (OSSCL), a more realistic semi-supervised continual learning setting in which out-of-distribution (OoD) unlabeled samples in the environment are assumed to coexist with the in-distribution ones. Under this configuration, we present a model with two distinct parts: (i) the reference network captures general-purpose and task-agnostic knowledge in the environment by using a broad spectrum of unlabeled samples, (ii) the learner network is designed to learn task-specific representations by exploiting supervised samples. The reference model both provides a pivotal representation space and also segregates unlabeled data to exploit them more efficiently. By performing a diverse range of experiments, we show the superior performance of our model compared with other competitors and prove the effectiveness of each component of the proposed model."}}
{"id": "J9PoKngNAw0", "cdate": 1672531200000, "mdate": 1699628563908, "content": {"title": "Semantic Segmentation With Multiple Contradictory Annotations Using a Dynamic Score Function", "abstract": "Semantic Segmentation aims to partition an image into separate regions where each region conveys certain valuable information. In recent years, deep learning models have achieved high performance in this task. However, when several ground truth segmentations are available, aggregating the information of these segmentations into a single ground truth becomes a crucial pre-processing step. This task becomes challenging when the segmentations are contradictory and the existing classes in the segmentations are imbalanced. An elegant example is the grading of Prostate Cancer in the Gleason 2019 Challenge dataset. This dataset provides six annotations of relatively high contrast from expert pathologists for each image. Additionally, the low number of images for Gleason grade 5 has also resulted in an imbalanced dataset. The Majority Voting and the Simultaneous Truth And Performance Level Estimation (STAPLE) algorithm are the most popular algorithms for combining annotations. In this paper, we visually show that the outputs of these algorithms discard the semantics of the image in regions of high inconsistency and point out that they demote low-frequency patterns, making the final segmentations even more imbalanced. We claim these drawbacks highly decrease the performance of deep learning models trained on these ground truths. To solve this problem, we propose a dynamic score function that selects one of the six annotations for each image while balancing the Gleason grading among the annotations in terms of variability and quantity. Finally, we train and evaluate a Pyramid Scene Parsing network on the final ground truths to validate our claims."}}
{"id": "GK5m7a3Uy4", "cdate": 1663850375954, "mdate": null, "content": {"title": "A distinct unsupervised reference model from the environment helps continual learning", "abstract": "The existing continual learning methods are mainly focused on fully-supervised scenarios and are still not able to take advantage of unlabeled data available in the environment. Some recent works tried to investigate semi-supervised continual learning (SSCL) settings in which the unlabeled data are available, but it is only from the same distribution as the labeled data. This assumption is still not general enough for real-world applications and restricts the utilization of unsupervised data. In this work, we introduce Open-Set Semi-Supervised Continual Learning (OSSCL), a more realistic semi-supervised continual learning setting in which out-of-distribution (OoD) unlabeled samples in the environment are assumed to coexist with the in-distribution ones. Under this configuration, we present a model with two distinct parts: (i) the reference network captures general-purpose and task-agnostic knowledge in the environment by using a broad spectrum of unlabeled samples, (ii) the learner network is designed to learn task-specific representations by exploiting supervised samples. The reference model both provides a pivotal representation space and also segregates unlabeled data to exploit them more efficiently. By performing a diverse range of experiments, we show the superior performance of our model compared with other competitors and prove the effectiveness of each component of the proposed model."}}
{"id": "z5ZKQFjpV46", "cdate": 1640995200000, "mdate": 1668497512468, "content": {"title": "RA-GCN: Graph convolutional network for disease prediction problems with imbalanced data", "abstract": ""}}
{"id": "oSpKqbS_JW", "cdate": 1640995200000, "mdate": 1682320809620, "content": {"title": "DMNP: A Deep Learning Approach for Missing Node Prediction in Partially Observed Graphs", "abstract": "Missing data is unavoidable in graphs, which can significantly affect the accuracy of downstream tasks. Many methods have been proposed to mitigate missing data in partially observed graphs. Most of these approaches assume they have complete access to graph nodes and only focus on recovering missing links, while in practice a part of the graph nodes can also be out of access. This work presents Deep Missing Node Predictor (DMNP), a novel deep learning-based approach to recovering missing nodes in partly observed graphs. Our proposed approach does not rely on additional information that in many cases does not exist. We compare our model with graph completion and deep graph generation baselines. The experimental results show that the DMNP model outperforms previous state-of-the-art approaches."}}
{"id": "moNY1LQthY8", "cdate": 1640995200000, "mdate": 1682320810474, "content": {"title": "SOInter: A Novel Deep Energy Based Interpretation Method for Explaining Structured Output Models", "abstract": "We propose a novel interpretation technique to explain the behavior of structured output models, which learn mappings between an input vector to a set of output variables simultaneously. Because of the complex relationship between the computational path of output variables in structured models, a feature can affect the value of output through other ones. We focus on one of the outputs as the target and try to find the most important features utilized by the structured model to decide on the target in each locality of the input space. In this paper, we assume an arbitrary structured output model is available as a black box and argue how considering the correlations between output variables can improve the explanation performance. The goal is to train a function as an interpreter for the target output variable over the input space. We introduce an energy-based training process for the interpreter function, which effectively considers the structural information incorporated into the model to be explained. The effectiveness of the proposed method is confirmed using a variety of simulated and real data sets."}}
