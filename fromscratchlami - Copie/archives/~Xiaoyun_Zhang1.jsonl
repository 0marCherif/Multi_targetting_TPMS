{"id": "7yjkGW2kXk", "cdate": 1699065211004, "mdate": 1699065211004, "content": {"title": "Boost Video Frame Interpolation via Motion Adaptation", "abstract": "Video frame interpolation (VFI) is a challenging task that aims to generate intermediate frames between two consecutive frames in a video. Existing learning-based VFI methods have achieved great success, but they still suffer from limited generalization ability due to the limited motion distribution of training datasets. In this paper, we propose a novel optimization-based VFI method that can adapt to unseen motions at test time. Our method is based on a cycle-consistency adaptation strategy that leverages the motion characteristics among video frames. We also introduce a lightweight adapter that can be inserted into the motion estimation module of existing pre-trained VFI models to improve the efficiency of adaptation. Extensive experiments on various benchmarks demonstrate that our method can boost the performance of two-frame VFI models, outperforming the existing state-of-the-art methods, even those that use extra input."}}
{"id": "cDj7cWXbNY", "cdate": 1640995200000, "mdate": 1668150386197, "content": {"title": "LAR-SR: A Local Autoregressive Model for Image Super-Resolution", "abstract": ""}}
{"id": "Z1IAjGK-c8_", "cdate": 1640995200000, "mdate": 1668150386189, "content": {"title": "Unpaired Face Restoration via Learnable Cross-Quality Shift", "abstract": ""}}
{"id": "SpQ3ea5gw94", "cdate": 1640995200000, "mdate": 1668150386200, "content": {"title": "Task Decoupled Framework for Reference-based Super-Resolution", "abstract": ""}}
{"id": "NcA27uD2sVK", "cdate": 1640995200000, "mdate": 1668150386210, "content": {"title": "A Simple Plugin for Transforming Images to Arbitrary Scales", "abstract": ""}}
{"id": "ZqabiikWeyt", "cdate": 1621630246121, "mdate": null, "content": {"title": "Learning to Learn Graph Topologies", "abstract": "Learning a graph topology to reveal the underlying relationship between data entities plays an important role in various machine learning and data analysis tasks. Under the assumption that structured data vary smoothly over a graph, the problem can be formulated as a regularised convex optimisation over a positive semidefinite cone and solved by iterative algorithms. Classic methods require an explicit convex function to reflect generic topological priors, e.g. the $\\ell_1$ penalty for enforcing sparsity, which limits the flexibility and expressiveness in learning rich topological structures. We propose to learn a mapping from node data to the graph structure based on the idea of learning to optimise (L2O). Specifically, our model first unrolls an iterative primal-dual splitting algorithm into a neural network. The key structural proximal projection is replaced with a variational autoencoder that refines the estimated graph with enhanced topological properties. The model is trained in an end-to-end fashion with pairs of node data and graph samples. Experiments on both synthetic and real-world data demonstrate that our model is more efficient than classic iterative algorithms in learning a graph with specific topological properties. "}}
{"id": "HWx8BxihT4O", "cdate": 1609459200000, "mdate": 1668150386201, "content": {"title": "MEMC-Net: Motion Estimation and Motion Compensation Driven Neural Network for Video Interpolation and Enhancement", "abstract": ""}}
{"id": "rJxLSN1S2H", "cdate": 1574396990321, "mdate": null, "content": {"title": "KalmanFlow 2.0: Efficient Video Optical Flow Estimation via Context-Aware Kalman Filtering", "abstract": "Recent studies on optical flow typically focus on the estimation of the single flow field in between a pair of images but pay little attention to the multiple consecutive flow fields in a longer video sequence. In this paper, we propose an efficient video optical flow estimation method by exploiting the temporal coherence and context dynamics under a Kalman filtering system. In this system, pixel's motion flow is first formulated as a second-order time-variant state vector and then optimally estimated according to the measurement and system noise levels within the system by maximum a posteriori criteria. Specifically, we evaluate the measurement noise according to the flow's temporal derivative, spatial gradient, and warping error. We determine the system noise based on the similarity of contextual information, which is represented by the compact features learned by pre-trained convolutional neural networks. The context-aware Kalman filtering helps improve the robustness of our method against abrupt change of light and occlusion/dis-occlusion in complicated scenes. The experimental results and analyses on the MPI Sintel, Monkaa, and Driving video datasets demonstrate that the proposed method performs favorably against the state-of-the-art approaches.\n"}}
{"id": "BJlm07yr3r", "cdate": 1574396875159, "mdate": null, "content": {"title": "High-Order Model and Dynamic Filtering for Frame Rate Up-Conversion", "abstract": "This paper proposes a novel frame rate up-conversion method through high-order model and dynamic filtering (HOMDF) for video pixels. Unlike the constant brightness and linear motion assumptions in traditional methods, the intensity and position of the video pixels are both modeled with high-order polynomials in terms of time. Then, the key problem of our method is to estimate the polynomial coefficients that represent the pixel's intensity variation, velocity, and acceleration. We propose to solve it with two energy objectives: one minimizes the auto-regressive prediction error of intensity variation by its past samples, and the other minimizes video frame's reconstruction error along the motion trajectory. To efficiently address the optimization problem for these coefficients, we propose the dynamic filtering solution inspired by video's temporal coherence. The optimal estimation of these coefficients is reformulated into a dynamic fusion of the prior estimate from pixel's temporal predecessor and the maximum likelihood estimate from current new observation. Finally, frame rate up-conversion is implemented using motion-compensated interpolation by pixel-wise intensity variation and motion trajectory. Benefited from the advanced model and dynamic filtering, the interpolated frame has much better visual quality. Extensive experiments on the natural and synthesized videos demonstrate the superiority of HOMDF over the state-of-the-art methods in both subjective and objective comparisons.\n"}}
{"id": "rJgOAMJr3H", "cdate": 1574396624378, "mdate": null, "content": {"title": "Depth-Aware Video Frame Interpolation", "abstract": "Video frame interpolation aims to synthesize nonexistent frames in-between the original frames. While significant advances have been made from the recent deep convolutional neural networks, the quality of interpolation is often reduced due to large object motion or occlusion. In this work, we propose a video frame interpolation method which explicitly detects the occlusion by exploring the depth information. Specifically, we develop a depth-aware flow projection layer to synthesize intermediate flows that preferably sample closer objects than farther ones. In addition, we learn hierarchical features to gather contextual information from neighboring pixels. The proposed model then warps the input frames, depth maps, and contextual features based on the optical flow and local interpolation kernels for synthesizing the output frame. Our model is compact, efficient, and fully differentiable. Quantitative and qualitative results demonstrate that the proposed model performs favorably against state-of-the-art frame interpolation methods on a wide variety of datasets.\n"}}
