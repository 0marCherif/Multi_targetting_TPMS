{"id": "MjQwQS7ag-0", "cdate": 1675332330737, "mdate": 1675332330737, "content": {"title": " A Dynamic Variational Framework for Open-World Node Classification in Structured Sequences", "abstract": "Structured sequences are a popular data representation, used to model complex data such as traffic networks. A key machine learning task for structured sequences is node classification, that is predicting the class labels of unlabeled nodes. Though many node classification models were proposed, they assume a closed world setting, that all class labels appear in the training data. But in the real-world, the presence of  never-before-seen class labels in testing data can considerably degrade a classifier\u2019s accuracy. A promising solution to this issue is to build classifiers for an open-world setting, where samples with unknown class labels are continuously observed such that\ntraining and testing data may have different class label spaces.  Several approaches have been proposed for open-world learning\nproblems in computer vision and natural language processing, but they cannot be applied directly to structured sequences due\nto the complexity of their non-Euclidean properties and their dynamic nature. This paper addresses this important research\ngap by proposing a novel Open-world Structured Sequence node Classification (OSSC) model, to learn from structured sequences\nin an open-world setting. OSSC captures the structural and temporal information via a GCN-based dynamic variational\nframework. A latent distribution sequence is learned for each node using both stochastic states and deterministic states, to\ncapture the evolution of node attributes and topology, followed by a sampling process to generate node representations. An\nopen-world classification loss is further adopted to ensure that node representations are sensitive to unknown classes. And a\ncombination of Openmax and Softmax is utilized to recognize nodes from unknown classes and to classify others to one of the\nknown classes. Experiments on real-world datasets show that the proposed OSSC method is capable of learning accurate openworld node classifiers from structured sequence data."}}
{"id": "loMLbm7Aek", "cdate": 1675332021720, "mdate": 1675332021720, "content": {"title": "A survey for efficient open domain question answering", "abstract": "Open domain question answering (ODQA) is a longstanding task aimed at answering factual questions from a large knowledge corpus without any explicit evidence in natural language processing (NLP). Recent works have predominantly focused on improving the answering accuracy and achieved promising progress. However, higher accuracy often comes with more memory consumption and inference latency, which might not necessarily be efficient enough for direct deployment in the real world. Thus, a trade-off between accuracy, memory consumption and processing speed is pursued. In this paper, we provide a survey of recent advances in the efficiency of ODQA models. We walk through the ODQA models and conclude the core techniques on efficiency. Quantitative analysis on memory cost, processing speed, accuracy and overall comparison are given. We hope that this work would keep interested scholars informed of the advances and open challenges in ODQA efficiency research, and thus contribute to the further development of ODQA efficiency."}}
{"id": "zRsCSqrc4d", "cdate": 1640995200000, "mdate": 1668588897617, "content": {"title": "Deep Unsupervised Hashing with Latent Semantic Components", "abstract": "Deep unsupervised hashing has been appreciated in the regime of image retrieval. However, most prior arts failed to detect the semantic components and their relationships behind the images, which makes them lack discriminative power. To make up the defect, we propose a novel Deep Semantic Components Hashing (DSCH), which involves a common sense that an image normally contains a bunch of semantic components with homology and co-occurrence relationships. Based on this prior, DSCH regards the semantic components as latent variables under the Expectation-Maximization framework and designs a two-step iterative algorithm with the objective of maximum likelihood of training data. Firstly, DSCH constructs a semantic component structure by uncovering the fine-grained semantics components of images with a Gaussian Mixture Modal~(GMM), where an image is represented as a mixture of multiple components, and the semantics co-occurrence are exploited. Besides, coarse-grained semantics components, are discovered by considering the homology relationships between fine-grained components, and the hierarchy organization is then constructed. Secondly, DSCH makes the images close to their semantic component centers at both fine-grained and coarse-grained levels, and also makes the images share similar semantic components close to each other. Extensive experiments on three benchmark datasets demonstrate that the proposed hierarchical semantic components indeed facilitate the hashing model to achieve superior performance."}}
{"id": "iw2zHnr3Yp", "cdate": 1640995200000, "mdate": 1682338918025, "content": {"title": "Semisupervised Feature Selection via Structured Manifold Learning", "abstract": ""}}
{"id": "YImODXvH72", "cdate": 1640995200000, "mdate": 1684225868564, "content": {"title": "Logic tensor network with massive learned knowledge for aspect-based sentiment analysis", "abstract": ""}}
{"id": "S_PMgeHGfWr", "cdate": 1640995200000, "mdate": 1688041639528, "content": {"title": "Directly solving normalized cut for multi-view data", "abstract": ""}}
{"id": "Lakysvx7l2", "cdate": 1640995200000, "mdate": 1683893900693, "content": {"title": "Semantic-enhanced Image Clustering", "abstract": "Image clustering is an important and open-challenging task in computer vision. Although many methods have been proposed to solve the image clustering task, they only explore images and uncover clusters according to the image features, thus being unable to distinguish visually similar but semantically different images. In this paper, we propose to investigate the task of image clustering with the help of a visual-language pre-training model. Different from the zero-shot setting, in which the class names are known, we only know the number of clusters in this setting. Therefore, how to map images to a proper semantic space and how to cluster images from both image and semantic spaces are two key problems. To solve the above problems, we propose a novel image clustering method guided by the visual-language pre-training model CLIP, named \\textbf{Semantic-Enhanced Image Clustering (SIC)}. In this new method, we propose a method to map the given images to a proper semantic space first and efficient methods to generate pseudo-labels according to the relationships between images and semantics. Finally, we propose performing clustering with consistency learning in both image space and semantic space, in a self-supervised learning fashion. The theoretical result of convergence analysis shows that our proposed method can converge at a sublinear speed. Theoretical analysis of expectation risk also shows that we can reduce the expected risk by improving neighborhood consistency, increasing prediction confidence, or reducing neighborhood imbalance. Experimental results on five benchmark datasets clearly show the superiority of our new method."}}
{"id": "L60-JV83tG", "cdate": 1640995200000, "mdate": 1684304762130, "content": {"title": "Deep Unsupervised Hashing with Latent Semantic Components", "abstract": "Deep unsupervised hashing has been appreciated in the regime of image retrieval. However, most prior arts failed to detect the semantic components and their relationships behind the images, which makes them lack discriminative power. To make up the defect, we propose a novel Deep Semantic Components Hashing (DSCH), which involves a common sense that an image normally contains a bunch of semantic components with homology and co-occurrence relationships. Based on this prior, DSCH regards the semantic components as latent variables under the Expectation-Maximization framework and designs a two-step iterative algorithm with the objective of maximum likelihood of training data. Firstly, DSCH constructs a semantic component structure by uncovering the fine-grained semantics components of images with a Gaussian Mixture Modal~(GMM), where an image is represented as a mixture of multiple components, and the semantics co-occurrence are exploited. Besides, coarse-grained semantics components, are discovered by considering the homology relationships between fine-grained components, and the hierarchy organization is then constructed. Secondly, DSCH makes the images close to their semantic component centers at both fine-grained and coarse-grained levels, and also makes the images share similar semantic components close to each other. Extensive experiments on three benchmark datasets demonstrate that the proposed hierarchical semantic components indeed facilitate the hashing model to achieve superior performance."}}
{"id": "F_c6SWVm3B", "cdate": 1640995200000, "mdate": 1684308790229, "content": {"title": "A Dynamic Variational Framework for Open-World Node Classification in Structured Sequences", "abstract": "Structured sequences are a popular data representation, used to model complex data such as traffic networks. A key machine learning task for structured sequences is node classification, that is predicting the class labels of unlabeled nodes. Though many node classification models were proposed, they assume a closed world setting, that all class labels appear in the training data. But in the real-world, the presence of never-before-seen class labels in testing data can considerably degrade a classifier\u2019s accuracy. A promising solution to this issue is to build classifiers for an open-world setting, where samples with unknown class labels are continuously observed such that training and testing data may have different class label spaces. Several approaches have been proposed for open-world learning problems in computer vision and natural language processing, but they cannot be applied directly to structured sequences due to the complexity of their non-Euclidean properties and their dynamic nature. This paper addresses this important research gap by proposing a novel Open-world Structured Sequence node Classification (OSSC) model, to learn from structured sequences in an open-world setting. OSSC captures the structural and temporal information via a GCN-based dynamic variational framework. A latent distribution sequence is learned for each node using both stochastic states and deterministic states, to capture the evolution of node attributes and topology, followed by a sampling process to generate node representations. An open-world classification loss is further adopted to ensure that node representations are sensitive to unknown classes. And a combination of Openmax and Softmax is utilized to recognize nodes from unknown classes and to classify others to one of the known classes. Experiments on real-world datasets show that the proposed OSSC method is capable of learning accurate open-world node classifiers from structured sequence data."}}
{"id": "AJQItBrvme", "cdate": 1640995200000, "mdate": 1688041639526, "content": {"title": "Semisupervised Feature Selection With Sparse Discriminative Least Squares Regression", "abstract": "In big data time, selecting informative features has become an urgent need. However, due to the huge cost of obtaining enough labeled data for supervised tasks, researchers have turned their attention to semisupervised learning, which exploits both labeled and unlabeled data. In this article, we propose a sparse discriminative semisupervised feature selection (SDSSFS) method. In this method, the <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"> <tex-math notation=\"LaTeX\">$\\epsilon $ </tex-math></inline-formula> -dragging technique for the supervised task is extended to the semisupervised task, which is used to enlarge the distance between classes in order to obtain a discriminative solution. The flexible <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"> <tex-math notation=\"LaTeX\">$\\ell _{2,p}$ </tex-math></inline-formula> norm is implicitly used as regularization in the new model. Therefore, we can obtain a more sparse solution by setting smaller <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"> <tex-math notation=\"LaTeX\">$p$ </tex-math></inline-formula> . An iterative method is proposed to simultaneously learn the regression coefficients and <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"> <tex-math notation=\"LaTeX\">$\\epsilon $ </tex-math></inline-formula> -dragging matrix and predicting the unknown class labels. Experimental results on ten real-world datasets show the superiority of our proposed method."}}
