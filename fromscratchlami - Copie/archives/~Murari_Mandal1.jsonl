{"id": "3QqW0OfmF7", "cdate": 1672531200000, "mdate": 1681704992995, "content": {"title": "Efficient Neural Architecture Search for Emotion Recognition", "abstract": "Automated human emotion recognition from facial expressions is a well-studied problem and still remains a very challenging task. Some efficient or accurate deep learning models have been presented in the literature. However, it is quite difficult to design a model that is both efficient and accurate at the same time. Moreover, identifying the minute feature variations in facial regions for both macro and micro-expressions requires expertise in network design. In this paper, we proposed to search for a highly efficient and robust neural architecture for both macro and micro-level facial expression recognition. To the best of our knowledge, this is the first attempt to design a NAS-based solution for both macro and micro-expression recognition. We produce lightweight models with a gradient-based architecture search algorithm. To maintain consistency between macro and micro-expressions, we utilize dynamic imaging and convert microexpression sequences into a single frame, preserving the spatiotemporal features in the facial regions. The EmoNAS has evaluated over 13 datasets (7 macro expression datasets: CK+, DISFA, MUG, ISED, OULU-VIS CASIA, FER2013, RAF-DB, and 6 micro-expression datasets: CASME-I, CASME-II, CAS(ME)2, SAMM, SMIC, MEGC2019 challenge). The proposed models outperform the existing state-of-the-art methods and perform very well in terms of speed and space complexity."}}
{"id": "pscFOADewiK", "cdate": 1640995200000, "mdate": 1681704992942, "content": {"title": "TabSynDex: A Universal Metric for Robust Evaluation of Synthetic Tabular Data", "abstract": "Synthetic tabular data generation becomes crucial when real data is limited, expensive to collect, or simply cannot be used due to privacy concerns. However, producing good quality synthetic data is challenging. Several probabilistic, statistical, and generative adversarial networks (GANs) based approaches have been presented for synthetic tabular data generation. Once generated, evaluating the quality of the synthetic data is quite challenging. Some of the traditional metrics have been used in the literature but there is lack of a common, robust, and single metric. This makes it difficult to properly compare the effectiveness of different synthetic tabular data generation methods. In this paper we propose a new universal metric, TabSynDex, for robust evaluation of synthetic data. TabSynDex assesses the similarity of synthetic data with real data through different component scores which evaluate the characteristics that are desirable for \"high quality\" synthetic data. Being a single score metric, TabSynDex can also be used to observe and evaluate the training of neural network based approaches. This would help in obtaining insights that was not possible earlier. Further, we present several baseline models for comparative analysis of the proposed evaluation metric with existing generative models."}}
{"id": "huV457m77B", "cdate": 1640995200000, "mdate": 1681704992928, "content": {"title": "AutoMER: Spatiotemporal Neural Architecture Search for Microexpression Recognition", "abstract": "Facial microexpressions offer useful insights into subtle human emotions. This unpremeditated emotional leakage exhibits the true emotions of a person. However, the minute temporal changes in the video sequences are very difficult to model for accurate classification. In this article, we propose a novel spatiotemporal architecture search algorithm, AutoMER for microexpression recognition (MER). Our main contribution is a new parallelogram design-based search space for efficient architecture search. We introduce a spatiotemporal feature module named 3-D singleton convolution for cell-level analysis. Furthermore, we present four such candidate operators and two 3-D dilated convolution operators to encode the raw video sequences in an end-to-end manner. To the best of our knowledge, this is the first attempt to discover 3-D convolutional neural network (CNN) architectures with a network-level search for MER. The searched models using the proposed AutoMER algorithm are evaluated over five microexpression data sets: CASME-I, SMIC, CASME-II, CAS(ME) <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"> <tex-math notation=\"LaTeX\">$\\hat{2}$ </tex-math></inline-formula> , and SAMM. The proposed generated models quantitatively outperform the existing state-of-the-art approaches. The AutoMER is further validated with different configurations, such as downsampling rate factor, multiscale singleton 3-D convolution, parallelogram, and multiscale kernels. Overall, five ablation experiments were conducted to analyze the operational insights of the proposed AutoMER."}}
{"id": "SYxcUYX3R5D", "cdate": 1640995200000, "mdate": 1681704992688, "content": {"title": "Can Bad Teaching Induce Forgetting? Unlearning in Deep Networks using an Incompetent Teacher", "abstract": "Machine unlearning has become an important area of research due to an increasing need for machine learning (ML) applications to comply with the emerging data privacy regulations. It facilitates the provision for removal of certain set or class of data from an already trained ML model without requiring retraining from scratch. Recently, several efforts have been put in to make unlearning to be effective and efficient. We propose a novel machine unlearning method by exploring the utility of competent and incompetent teachers in a student-teacher framework to induce forgetfulness. The knowledge from the competent and incompetent teachers is selectively transferred to the student to obtain a model that doesn't contain any information about the forget data. We experimentally show that this method generalizes well, is fast and effective. Furthermore, we introduce the zero retrain forgetting (ZRF) metric to evaluate any unlearning method. Unlike the existing unlearning metrics, the ZRF score does not depend on the availability of the expensive retrained model. This makes it useful for analysis of the unlearned model after deployment as well. We present results of experiments conducted for random subset forgetting and class forgetting on various deep networks and across different application domains.~Source code is at: https://github.com/vikram2000b/bad-teaching-unlearning"}}
{"id": "SK_xS-jhIK", "cdate": 1640995200000, "mdate": 1681704992849, "content": {"title": "Deep Regression Unlearning", "abstract": "With the introduction of data protection and privacy regulations, it has become crucial to remove the lineage of data on demand from a machine learning (ML) model. In the last few years, there have been notable developments in machine unlearning to remove the information of certain training data efficiently and effectively from ML models. In this work, we explore unlearning for the regression problem, particularly in deep learning models. Unlearning in classification and simple linear regression has been considerably investigated. However, unlearning in deep regression models largely remains an untouched problem till now. In this work, we introduce deep regression unlearning methods that generalize well and are robust to privacy attacks. We propose the Blindspot unlearning method which uses a novel weight optimization process. A randomly initialized model, partially exposed to the retain samples and a copy of the original model are used together to selectively imprint knowledge about the data that we wish to keep and scrub off the information of the data we wish to forget. We also propose a Gaussian fine tuning method for regression unlearning. The existing unlearning metrics for classification are not directly applicable to regression unlearning. Therefore, we adapt these metrics for the regression setting. We conduct regression unlearning experiments for computer vision, natural language processing and forecasting applications. Our methods show excellent performance for all these datasets across all the metrics. Source code: https://github.com/ayu987/deep-regression-unlearning"}}
{"id": "ItZAkRWFjKA", "cdate": 1640995200000, "mdate": 1652774905600, "content": {"title": "Zero-Shot Machine Unlearning", "abstract": "Modern privacy regulations grant citizens the right to be forgotten by products, services and companies. In case of machine learning (ML) applications, this necessitates deletion of data not only from storage archives but also from ML models. Due to an increasing need for regulatory compliance required for ML applications, machine unlearning is becoming an emerging research problem. The right to be forgotten requests come in the form of removal of a certain set or class of data from the already trained ML model. Practical considerations preclude retraining of the model from scratch minus the deleted data. The few existing studies use either the whole training data, or a subset of training data, or some metadata stored during training to update the model weights for unlearning. However, strict regulatory compliance requires time-bound deletion of data. Thus, in many cases, no data related to the training process or training samples may be accessible even for the unlearning purpose. We therefore ask the question: is it possible to achieve unlearning with zero training samples? In this paper, we introduce the novel problem of zero-shot machine unlearning that caters for the extreme but practical scenario where zero original data samples are available for use. We then propose two novel solutions for zero-shot machine unlearning based on (a) error minimizing-maximizing noise and (b) gated knowledge transfer. These methods remove the information of the forget data from the model while maintaining the model efficacy on the retain data. The zero-shot approach offers good protection against the model inversion attacks and membership inference attacks. We introduce a new evaluation metric, Anamnesis Index (AIN) to effectively measure the quality of the unlearning method. The experiments show promising results for unlearning in deep learning models on benchmark vision data-sets."}}
{"id": "AvL30_AoM79", "cdate": 1640995200000, "mdate": 1668226633655, "content": {"title": "DroneSegNet: Robust Aerial Semantic Segmentation for UAV-Based IoT Applications", "abstract": "Unmanned Aerial Vehicles (UAVs) are the promising \u201cFlying IoT\u201d devices of the future, which can be equipped with various sensors and cognitive capabilities to perform numerous tasks related to remote sensing, search and rescue operations, object tracking, segmentation of roads and buildings, surveillance, etc. However, these AI-driven tasks require heavy computation and may lead to suboptimal performance with embedded processors on a power-constrained battery-operated drone. This work proposes a novel deep learning approach for performing robust semantic segmentation of aerial scenes captured by UAVs. In our setup, the power-constrained drone is used only for data collection, while the computationally intensive tasks are offloaded to a GPU cloud server. Our architecture performs robust semantic segmentation by learning the segmentation maps from jointly utilizing of aerial scenes along with the respective \u201celevation maps\u201d in a semi-supervised approach. We propose a three-tier deep learning architecture, wherein the first module aims at preliminary feature extraction from aerial scenes using a backbone feature extractor. The second module captures the spatial dependency between the aerial scenes and their respective elevation maps to obtain better semantic information, which is achieved by a bi-directional LSTM. The third module is aimed at enhancing the performance of semantic segmentation through a semi-supervised approach with an encoder to generate segmentation maps and a decoder to reconstruct feature maps. This semi-supervised feature learning ensures robust extraction along with scalability. The proposed architecture was validated on real-world aerial datasets and achieves state-of-the-art results for aerial image segmentation."}}
{"id": "utWLxNu5zBO", "cdate": 1609459200000, "mdate": 1668463924027, "content": {"title": "AI-Enabled Object Detection in UAVs: Challenges, Design Choices, and Research Directions", "abstract": "Unmanned aerial vehicles (UAVs) are emerging as a powerful tool for various industrial and smart city applications. UAVs coupled with various sensors can perform many cognitive tasks such as object detection, surveillance, traffic management, and urban planning. Deep learning has emerged as a popular technique to speed up the processing of high-dimensional data like images and videos, which has led to several applications in surveillance and autonomous driving. However, the area of aerial object detection has been understudied. This work proposes a deep learning approach for detection of objects in aerial scenes captured by UAVs. Our work first categorizes the current methods for aerial object detection using deep learning techniques and discusses how the task is different from general object detection scenarios. We delineate the specific challenges involved and experimentally demonstrate the key design decisions that significantly affect the accuracy and robustness of models. We further propose an optimized architecture that utilizes these optimal design choices along with the recent Res-NeSt backbone to achieve superior performance in aerial object detection. Lastly, we propose several research directions to inspire further advancement in aerial object detection."}}
{"id": "lm9pSN-nnjx", "cdate": 1609459200000, "mdate": 1681704992788, "content": {"title": "ReViewNet: A Fast and Resource Optimized Network for Enabling Safe Autonomous Driving in Hazy Weather Conditions", "abstract": "Adverse weather conditions such as fog, haze, snow, mist and glare create visibility problems for applications of autonomous vehicles. To ensure safe and smooth operations in frequent bad weather scenarios, image dehazing is crucial to any vehicular motion and navigation task on road or air. Moreover, the commonly deployed mobile systems are resource constrained in nature. Therefore, it is important to ensure memory, compute and run-time efficiency of dehazing algorithms. In this manuscript we propose ReViewNet, a fast, lightweight and robust dehazing system suitable for autonomous vehicles. The network uses components like spatial feature pooling, quadruple color-cue, multi-look architecture and multi-weighted loss to effectively dehaze images captured by cameras of autonomous vehicles. The effectiveness of the proposed model is analyzed by exhaustive quantitative evaluation on five benchmark datasets demonstrating its supremacy over other existing state-of-the-art methods. Further, a component-wise ablation and loss weight ratio analysis demonstrates the contribution of each and every component of the network. We also show the qualitative analysis with special use cases and visual responses on distinctive vehicular vision instances, establishing the effectiveness of the proposed method in numerous hazy weather conditions for autonomous vehicular applications."}}
{"id": "kaFPUKASYyt", "cdate": 1609459200000, "mdate": 1681704992795, "content": {"title": "TheiaNet: Towards fast and inexpensive CNN design choices for image dehazing", "abstract": ""}}
