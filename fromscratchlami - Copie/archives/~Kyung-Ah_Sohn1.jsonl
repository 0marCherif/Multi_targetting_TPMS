{"id": "ed1sWkGxjN", "cdate": 1677628800000, "mdate": 1682325795040, "content": {"title": "Attention-guided residual frame learning for video anomaly detection", "abstract": "The problem of anomaly detection in video surveillance data has been an active research topic. The main difficulty of video anomaly detection is due to two different definitions of anomalies: semantically abnormal objects and motion caused by unauthorized changes in objects. We propose a new framework for video anomaly detection by designing a convolutional long short-term memory-based model that emphasizes semantic objects using self-attention mechanisms and concatenation operations to further improve performance. Moreover, our proposed method is designed to learn only the residuals of the next frame, which allows the model to better focus on anomalous objects in video frames and also enhances stability of the training process. Our model substantially outperformed previous models on the Chinese University of Hong Kong (CUHK) Avenue and Subway Exit datasets. Our experiments also demonstrated that each module of the residual frame learning and the attention block incorporated into our framework is effective in improving the performance."}}
{"id": "BLBulxMHuOp", "cdate": 1663849852069, "mdate": null, "content": {"title": "Decomposing Texture and Semantics for Out-of-distribution Detection", "abstract": "Out-of-distribution (OOD) detection has made significant progress in recent years because the distribution mismatch between the training and testing can severely deteriorate the reliability of a machine learning system.Nevertheless, the lack of precise interpretation of the in-distribution limits the application of OOD detection methods to real-world system pipielines. To tackle this issue, we decompose the definition of the in-distribution into texture and semantics, motivated by real-world scenarios. In addition, we design new benchmarks to measure the robustness that OOD detection methods should have. To achieve a good balance between the OOD detection performance and robustness, our method takes a divide-and-conquer approach. That is, the model first tackles each component of the texture and semantics separately, and then combines them later. Such design philosophy is empirically proven by a series of benchmarks including not only ours but also the conventional counterpart."}}
{"id": "rIdGtErBnK", "cdate": 1640995200000, "mdate": 1682325795105, "content": {"title": "A Novel Multi-Modal Network-Based Dynamic Scene Understanding", "abstract": "In recent years, dynamic scene understanding has gained attention from researchers because of its widespread applications. The main important factor in successfully understanding the dynamic scenes lies in jointly representing the appearance and motion features to obtain an informative description. Numerous methods have been introduced to solve dynamic scene recognition problem, nevertheless, a few concerns still need to be investigated. In this article, we introduce a novel multi-modal network for dynamic scene understanding from video data, which captures both spatial appearance and temporal dynamics effectively. Furthermore, two-level joint tuning layers are proposed to integrate the global and local spatial features as well as spatial and temporal stream deep features. In order to extract the temporal information, we present a novel dynamic descriptor, namely, Volume Symmetric Gradient Local Graph Structure (VSGLGS), which generates temporal feature maps similar to optical flow maps. However, this approach overcomes the issues of optical flow maps. Additionally, Volume Local Directional Transition Pattern (VLDTP) based handcrafted spatiotemporal feature descriptor is also introduced, which extracts the directional information through exploiting edge responses. Lastly, a stacked Bidirectional Long Short-Term Memory (Bi-LSTM) network along with a temporal mixed pooling scheme is designed to achieve the dynamic information without noise interference. The extensive experimental investigation proves that the proposed multi-modal network outperforms most of the state-of-the-art approaches for dynamic scene understanding."}}
{"id": "kQY0hLeioH", "cdate": 1640995200000, "mdate": 1682325794784, "content": {"title": "Why Is It Hate Speech? Masked Rationale Prediction for Explainable Hate Speech Detection", "abstract": ""}}
{"id": "SWsVkgb_qa", "cdate": 1640995200000, "mdate": 1668426862007, "content": {"title": "Exploiting Distortion Information for Multi-degraded Image Restoration", "abstract": "In recent years, tremendous studies have been performed on the image distortion restoration task and deep learning-based methods have shown prominent performance improvement. However, assuming only a single distortion to an image may not be applicable in many real-world scenarios. To mitigate the issue, some studies have proposed multi-distortion datasets by applying the corruptions sequentially or spatially. In this work, we integrate the two perspectives on the multi-distortion nature and propose a new dataset that is a holistic multi-distortion dataset. To restore the multi-distortion effectively, we introduce a distortion information-guided restoration network, which exploits the conditional distortion information when reconstructing a given image. To do that, our framework first predicts the distortion type and their strength and delivers these to the restoration module. In our experiments, we show that the proposed model exceeds the others and we also demonstrate that any backbone network benefits from receiving the distortion information as prior knowledge."}}
{"id": "OWP8rjWhk30", "cdate": 1640995200000, "mdate": 1668426862026, "content": {"title": "Efficient deep neural network for photo-realistic image super-resolution", "abstract": ""}}
{"id": "DGcGyk8r3ui", "cdate": 1640995200000, "mdate": 1682325795154, "content": {"title": "Why Is It Hate Speech? Masked Rationale Prediction for Explainable Hate Speech Detection", "abstract": "In a hate speech detection model, we should consider two critical aspects in addition to detection performance-bias and explainability. Hate speech cannot be identified based solely on the presence of specific words: the model should be able to reason like humans and be explainable. To improve the performance concerning the two aspects, we propose Masked Rationale Prediction (MRP) as an intermediate task. MRP is a task to predict the masked human rationales-snippets of a sentence that are grounds for human judgment-by referring to surrounding tokens combined with their unmasked rationales. As the model learns its reasoning ability based on rationales by MRP, it performs hate speech detection robustly in terms of bias and explainability. The proposed method generally achieves state-of-the-art performance in various metrics, demonstrating its effectiveness for hate speech detection."}}
{"id": "2TMrmMmn3eL", "cdate": 1640995200000, "mdate": 1682325795149, "content": {"title": "An ensemble approach to anomaly detection using high- and low-variance principal components", "abstract": ""}}
{"id": "UYDtmk6BMf5", "cdate": 1632875505202, "mdate": null, "content": {"title": "Decomposing Texture and Semantics for Out-of-distribution Detection", "abstract": "Out-of-distribution (OOD) detection has made significant progress in recent years because the distribution mismatch between the training and testing can severely deteriorate the reliability of a machine learning system.Nevertheless, the lack of precise interpretation of the in-distribution limits the application of OOD detection methods to real-world system pipielines. To tackle this issue, we decompose the definition of the in-distribution into texture and semantics, motivated by real-world scenarios. In addition, we design new benchmarks to measure the robustness that OOD detection methods should have. To achieve a good balance between the OOD detection performance and robustness, our method takes a divide-and-conquer approach. That is, the model first tackles each component of the texture and semantics separately, and then combines them later. Such design philosophy is empirically proven by a series of benchmarks including not only ours but also the conventional counterpart."}}
{"id": "cav5FW0gy3C", "cdate": 1632875487275, "mdate": null, "content": {"title": "Dataset Bias Prediction for Few-Shot Image Classification", "abstract": "One of the obstacles which negatively affect the image classification performance is dataset bias. In particular, if each class has only a few training data samples, the data are highly likely to have dataset bias. Therefore, dataset bias can be a serious issue in few-shot learning, but has rarely been studied so far. To address this issue, we propose a bias prediction network to help improve the performance of few-shot image classification models. Once the features are extracted from an image data, the bias prediction network tries to recover the bias of the raw image such as color from the features. However, if the bias prediction network can recover it easily, we can assume that the extracted features also contain the color bias. Therefore, in our proposed framework, the full model tries to extract features that are difficult for the bias prediction network to recover from. We validate our method by adding the bias prediction network to several existing models and evaluating the performance improvement. Our experimental results show that the bias prediction network can suppress the negative effect of the dataset color bias, resulting in the substantial improvements in existing few-shot classification models. The proposed bias prediction network, which can be integrated with other models very easily, could potentially benefit many existing models for various tasks."}}
