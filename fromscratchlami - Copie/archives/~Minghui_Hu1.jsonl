{"id": "aI6q0Kj8UkO", "cdate": 1693526400000, "mdate": 1705309385287, "content": {"title": "Online dynamic ensemble deep random vector functional link neural network for forecasting", "abstract": ""}}
{"id": "Dc1Hh4kXDn", "cdate": 1685577600000, "mdate": 1705309385286, "content": {"title": "Versatile LiDAR-Inertial Odometry With SE(2) Constraints for Ground Vehicles", "abstract": "LiDAR SLAM has become one of the major localization systems for ground vehicles since LiDAR Odometry And Mapping (LOAM). Many extension works on LOAM mainly leverage one specific constraint to improve the performance, e.g., information from on-board sensors such as loop closure and inertial state; prior conditions such as ground level and motion dynamics. In many robotic applications, these conditions are often known partially, hence a SLAM system can be a comprehensive problem due to the existence of numerous constraints. Therefore, we can achieve a better SLAM result by fusing them properly. In this letter, we propose a hybrid LiDAR-inertial SLAM framework that leverages both the on-board perception system and prior information such as motion dynamics to improve localization performance. In particular, we consider the case for ground vehicles, which are commonly used for autonomous driving and warehouse logistics. We present a computationally efficient LiDAR-inertial odometry method that directly parameterizes ground vehicle poses on SE(2). The out-of-SE(2) motion perturbations are not neglected but incorporated into an integrated noise term of a novel SE(2)-constraints model. For odometric measurement processing, we propose a versatile, tightly coupled LiDAR-inertial odometry to achieve better pose estimation than traditional LiDAR odometry. Thorough experiments are performed to evaluate our proposed method's performance in different scenarios, including localization for both indoor and outdoor environments. The proposed method achieves superior performance in accuracy and robustness."}}
{"id": "w3pEV8II2H", "cdate": 1682899200000, "mdate": 1705309385363, "content": {"title": "Ensemble Deep Random Vector Functional Link Neural Network for Regression", "abstract": "Inspired by the ensemble strategy of machine learning, deep random vector functional link (dRVFL), and ensemble dRVFL (edRVFL) has shown state-of-the-art results on different datasets. Our present work first fills the gap of dRVFL and edRVFL work in the field of regression. We test and evaluate the performances of the dRVFLs on regression problems. Subsequently, we propose a novel regularization method [boosted factor (BF)], two dRVFLs variants [edRVFL with skip connection (edRVFL-SC) and edRVFL with random skip connections (edRVFL-RSC)] and one strategy [ensemble skip connection edRVFL (esc-edRVFL)] which show significant improvement over the original dRVFL. The BF is a newly introduced hyperparameter to scale the values of the activated hidden neurons to accommodate the diversity of the data, and it is also able to filter the neurons. edRVFL-SC and edRVFL-RSC are the edRVFL variants with skip connections. In edRVFL-SC, we apply dense skip connections to the edRVFL, which is inspired by the residual architecture in the deep learning area. However, due to the specificity of randomized networks, the simple skip connections are probably leading to the reuse of useless features. To address this problem, we propose a random skip connection-based edRVFL, which can keep the diversity in the latent space. esc-RVFL is an ensemble scheme that utilizes several edRVFL-RSC models trained on the different folds of the training dataset. The esc-edRVFL is identified as the best-performing algorithm through a comprehensive evaluation of 31 UCI datasets."}}
{"id": "xAJQS85PNEl", "cdate": 1672531200000, "mdate": 1705309385368, "content": {"title": "Locswinunet: A Neural Network for Urban Wireless Localization Using TOA and RSS Radio Maps", "abstract": "In outdoor environments, Global Navigation Satellite Systems (GNSS) is usually the preferred mode for localization of a user equipment (UE). The accuracy of GNSS localization depends on the line-of-sight (LoS) conditions between the ground UE and the GNSS satellites, and hence it often does not perform well in urban environment with building blockages. In such situations, user would have to rely on the widely deployed mobile network and use signal parameters such as received signal strength (RSS) and time of arrival (ToA) measured from several base stations (BS) for localization. However, the localization accuracy is still limited by the dense multipath and non-line-of-sight (NLoS) propagations. Radio maps which provide extensive location specific RF signatures can be a promising solution to overcome these limitations. In this paper, we present a novel neural network, LocSwinUNet, which utilizes the RSS and ToA measurements made by the UE and the corresponding radio maps of the BSs to perform the localization task. The proposed network achieves RMSE localization errors of 4.398 meters with clean measurements and 10.140 meters when the RSS and ToA measurements are distorted by Gaussian noises with \u03c3 <inf xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">p</inf> = 10 dB and \u03c3 <inf xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">t</inf> = 10 meters, respectively. Our method shows robustness across different realistic scenarios modelled by various Gaussian noises. The code is available at https: //github.com/mhh0318/WirelessLocation."}}
{"id": "s7liae8Ium5", "cdate": 1672531200000, "mdate": 1697704925365, "content": {"title": "Unified Discrete Diffusion for Simultaneous Vision-Language Generation", "abstract": ""}}
{"id": "nTJLvV2GGm", "cdate": 1672531200000, "mdate": 1697704925368, "content": {"title": "Cocktail: Mixing Multi-Modality Controls for Text-Conditional Image Generation", "abstract": "Text-conditional diffusion models are able to generate high-fidelity images with diverse contents. However, linguistic representations frequently exhibit ambiguous descriptions of the envisioned objective imagery, requiring the incorporation of additional control signals to bolster the efficacy of text-guided diffusion models. In this work, we propose Cocktail, a pipeline to mix various modalities into one embedding, amalgamated with a generalized ControlNet (gControlNet), a controllable normalisation (ControlNorm), and a spatial guidance sampling method, to actualize multi-modal and spatially-refined control for text-conditional diffusion models. Specifically, we introduce a hyper-network gControlNet, dedicated to the alignment and infusion of the control signals from disparate modalities into the pre-trained diffusion model. gControlNet is capable of accepting flexible modality signals, encompassing the simultaneous reception of any combination of modality signals, or the supplementary fusion of multiple modality signals. The control signals are then fused and injected into the backbone model according to our proposed ControlNorm. Furthermore, our advanced spatial guidance sampling methodology proficiently incorporates the control signal into the designated region, thereby circumventing the manifestation of undesired objects within the generated image. We demonstrate the results of our method in controlling various modalities, proving high-quality synthesis and fidelity to multiple external signals."}}
{"id": "bFa-umyoB64", "cdate": 1672531200000, "mdate": 1705309385327, "content": {"title": "Online learning using deep random vector functional link network", "abstract": ""}}
{"id": "L-ciYPTXxCv", "cdate": 1672531200000, "mdate": 1705309385326, "content": {"title": "Ensemble of Randomized Neural Network and Boosted Trees for Eye-Tracking-Based Driver Situation Awareness Recognition and Interpretation", "abstract": "Ensuring traffic safety is crucial in the pursuit of sustainable transportation. Across diverse traffic systems, maintaining good situation awareness (SA) is important in promoting and upholding traffic safety. This work focuses on a regression problem of using eye-tracking features to perform situation awareness (SA) recognition in the context of conditionally automated driving. As a type of tabular dataset, recent advances have shown that both neural networks (NNs) and gradient-boosted decision trees (GBDTs) are potential solutions to achieve better performance. To avoid the complex analysis to select the suitable model for the task, this work proposed to combine the NNs and tree-based models to achieve better performance on the task of SA assessment generally. Considering the necessity of the real-time measure for practical applications, the ensemble deep random vector functional link (edRVFL) and light gradient boosting machine (lightGBM) were used as the representative models of NNs and GBDTs in the investigation, respectively. Furthermore, this work exploited Shapley additive explanations (SHAP) to interpret the contributions of the input features, upon which we further developed two ensemble modes. Experimental results demonstrated that the proposed model outperformed the baseline models, highlighting its effectiveness. In addition, the interpretation results can also provide practitioners with references regarding the eye-tracking features that are more relevant to SA recognition."}}
{"id": "HvX_6KKNw4", "cdate": 1672531200000, "mdate": 1700034695556, "content": {"title": "MMoT: Mixture-of-Modality-Tokens Transformer for Composed Multimodal Conditional Image Synthesis", "abstract": "Existing multimodal conditional image synthesis (MCIS) methods generate images conditioned on any combinations of various modalities that require all of them must be exactly conformed, hindering the synthesis controllability and leaving the potential of cross-modality under-exploited. To this end, we propose to generate images conditioned on the compositions of multimodal control signals, where modalities are imperfectly complementary, i.e., composed multimodal conditional image synthesis (CMCIS). Specifically, we observe two challenging issues of the proposed CMCIS task, i.e., the modality coordination problem and the modality imbalance problem. To tackle these issues, we introduce a Mixture-of-Modality-Tokens Transformer (MMoT) that adaptively fuses fine-grained multimodal control signals, a multimodal balanced training loss to stabilize the optimization of each modality, and a multimodal sampling guidance to balance the strength of each modality control signal. Comprehensive experimental results demonstrate that MMoT achieves superior performance on both unimodal conditional image synthesis (UCIS) and MCIS tasks with high-quality and faithful image synthesis on complex multimodal conditions. The project website is available at https://jabir-zheng.github.io/MMoT."}}
{"id": "EYWf6StNIen", "cdate": 1672531200000, "mdate": 1705309385367, "content": {"title": "Significant wave height forecasting using hybrid ensemble deep randomized networks with neurons pruning", "abstract": ""}}
