{"id": "XtcdWmXFzP", "cdate": 1683931218633, "mdate": 1683931218633, "content": {"title": "Scalable and Efficient Comparison-based Search without Features", "abstract": "We consider the problem of finding a target object\nt using pairwise comparisons, by asking an oracle\nquestions of the form \u201cWhich object from the pair\n(i, j) is more similar to t?\u201d. Objects live in a space\nof latent features, from which the oracle generates\nnoisy answers. First, we consider the non-blind\nsetting where these features are accessible. We\npropose a new Bayesian comparison-based search\nalgorithm with noisy answers; it has low computational complexity yet is efficient in the number\nof queries. We provide theoretical guarantees, deriving the form of the optimal query and proving\nalmost sure convergence to the target t. Second,\nwe consider the blind setting, where the object\nfeatures are hidden from the search algorithm.\nIn this setting, we combine our search method\nand a new distributional triplet embedding algorithm into one scalable learning framework called\nLEARN2SEARCH. We show that the query complexity of our approach on two real-world datasets\nis on par with the non-blind setting, which is not\nachievable using any of the current state-of-theart embedding methods. Finally, we demonstrate\nthe efficacy of our framework by conducting an\nexperiment with users searching for movie actors."}}
{"id": "v33mNDKGeC", "cdate": 1678354615377, "mdate": 1678354615377, "content": {"title": "A Strong Baseline for Batch Imitation Learning", "abstract": "Imitation of expert behaviour is a highly desirable and safe approach to the problem of sequential decision making. We provide an easy-to-implement, novel algorithm for imitation learning under a strict data paradigm, in which the agent must learn solely from data collected a priori. This paradigm allows our algorithm to be used for environments in which safety or cost are of critical concern. Our algorithm requires no additional hyper-parameter tuning beyond any standard batch reinforcement learning (RL) algorithm, making it an ideal baseline for such data-strict regimes. Furthermore, we provide formal sample complexity guarantees for the algorithm in finite Markov Decision Problems. In doing so, we formally demonstrate an unproven claim from Kearns & Singh (1998). On the empirical side, our contribution is twofold. First, we develop a practical, robust and principled evaluation protocol for offline RL methods, making use of only the dataset provided for model selection. This stands in contrast to the vast majority of previous works in offline RL, which tune hyperparameters on the evaluation environment, limiting the practical applicability when deployed in new, cost-critical environments. As such, we establish precedent for the development and fair evaluation of offline RL algorithms. Second, we evaluate our own algorithm on challenging continuous control benchmarks, demonstrating its practical applicability and competitiveness with state-of-the-art performance, despite being a simpler algorithm."}}
{"id": "b5GQsfOlxKg", "cdate": 1667393651222, "mdate": null, "content": {"title": "Estimating long-term causal effects from short-term experiments and long-term observational data with unobserved confounding", "abstract": "Understanding and quantifying cause and effect relationships is an important problem in many domains. The generally-agreed standard solution to this problem is to perform a randomised controlled trial. However, even when randomised controlled trials can be performed, they usually have relatively short duration's due to cost considerations. This makes learning long-term causal effects a very challenging task in practice, since the long-term outcome is only observed after a long delay. In this paper, we study the identification and estimation of long-term treatment effects when both experimental and observational data are available. Previous work provided an estimation strategy to determine long-term causal effects from such data regimes. However, this strategy only works if one assumes there are no unobserved confounders in the observational data. In this paper, we specifically address the challenging case where unmeasured confounders are present in the observational data. Our long-term causal effect estimator is obtained by combining regression residuals with short-term experimental outcomes in a specific manner to create an instrumental variable, which is then used to quantify the long-term causal effect through instrumental variable regression. We prove this estimator is unbiased, and analytically study its variance. Finally, we empirically test our approach on synthetic data, as well as real-data from the International Stroke Trial. Relevant source code and documentation has been made freely available in our \\href{https://github.com/vangoffrier/UnConfounding}{online repository}."}}
{"id": "r-CsquKaHvk", "cdate": 1652737564310, "mdate": null, "content": {"title": "Temporally-Consistent Survival Analysis", "abstract": "We study survival analysis in the dynamic setting: We seek to model the time to an event of interest given sequences of states. Taking inspiration from temporal-difference learning, a central idea in reinforcement learning, we develop algorithms that estimate a discrete-time survival model by exploiting a temporal-consistency condition. Intuitively, this condition captures the fact that the survival distribution at consecutive states should be similar, accounting for the delay between states. Our method can be combined with any parametric survival model and naturally accommodates right-censored observations. We demonstrate empirically that it achieves better sample-efficiency and predictive performance compared to approaches that directly regress the observed survival outcome."}}
{"id": "Buddj8Ijcl9", "cdate": 1646077523024, "mdate": null, "content": {"title": "Multistate Analysis with Infinite Mixtures of Markov Chains", "abstract": "Driven by applications in clinical medicine and business, we address the problem of modeling trajectories over multiple states. We build on well-known methods from survival analysis and introduce a family of sequence models based on localized Bayesian Markov chains. We develop inference and prediction algorithms, and we apply the model to real-world data, demonstrating favorable empirical results. Our approach provides a practical and effective alternative to plain Markov chains and to existing (finite) mixture models; It retains the simplicity and computational benefits of the former while matching or exceeding the predictive performance of the latter."}}
{"id": "Ta4HIoSe4UW", "cdate": 1621246619949, "mdate": null, "content": {"title": "Scalable and Efficient Comparison-based Search without Features", "abstract": "We consider the problem of finding a target object t using pairwise comparisons, by asking an oracle questions of the form \u201cWhich object from the pair (i,j) is more similar to t?\u201d. Objects live in a space of latent features, from which the oracle generates noisy answers. First, we consider the non-blind setting where these features are accessible. We propose a new Bayesian comparison-based search algorithm with noisy answers; it has low computational complexity yet is efficient in the number of queries. We provide theoretical guarantees, deriving the form of the optimal query and proving almost sure convergence to the target t. Second, we consider the blind setting, where the object features are hidden from the search algorithm. In this setting, we combine our search method and a new distributional triplet embedding algorithm into one scalable learning framework called Learn2Search. We show that the query complexity of our approach on two real-world datasets is on par with the non-blind setting, which is not achievable using any of the current state-of-the-art embedding methods. Finally, we demonstrate the efficacy of our framework by conducting a movie actors search experiment with real users."}}
{"id": "XjJ5gUYoLPF", "cdate": 1621246525409, "mdate": null, "content": {"title": "Collaborative Classification from Noisy Labels", "abstract": "We consider a setting where users interact with a collection of N items on an online platform. We are given class labels possibly corrupted by noise, and we seek to recover the true class of each item. We postulate a simple probabilistic model of the interactions between users and items, based on the assumption that users interact with classes in different proportions. We then develop a message-passing algorithm that decodes the noisy class labels efficiently. Under suitable assumptions, our method provably recovers all items\u2019 true classes in the large N limit, even when the interaction graph remains sparse. Empirically, we show that our approach is effective on several practical applications, including predicting the location of businesses, the category of consumer goods, and the language of audio content."}}
{"id": "ryZCs4-u-B", "cdate": 1514764800000, "mdate": null, "content": {"title": "Can Who-Edits-What Predict Edit Survival?", "abstract": "As the number of contributors to online peer-production systems grows, it becomes increasingly important to predict whether the edits that users make will eventually be beneficial to the project. Existing solutions either rely on a user reputation system or consist of a highly specialized predictor that is tailored to a specific peer-production system. In this work, we explore a different point in the solution space that goes beyond user reputation but does not involve any content-based feature of the edits. We view each edit as a game between the editor and the component of the project. We posit that the probability that an edit is accepted is a function of the editor's skill, of the difficulty of editing the component and of a user-component interaction term. Our model is broadly applicable, as it only requires observing data about who makes an edit, what the edit affects and whether the edit survives or not. We apply our model on Wikipedia and the Linux kernel, two examples of large-scale peer-production systems, and we seek to understand whether it can effectively predict edit survival: in both cases, we provide a positive answer. Our approach significantly outperforms those based solely on user reputation and bridges the gap with specialized predictors that use content-based features. It is simple to implement, computationally inexpensive, and in addition it enables us to discover interesting structure in the data."}}
{"id": "rJWwynZOZS", "cdate": 1483228800000, "mdate": null, "content": {"title": "Just Sort It! A Simple and Effective Approach to Active Preference Learning", "abstract": "We address the problem of learning a ranking by using adaptively chosen pairwise comparisons. Our goal is to recover the ranking accurately but to sample the comparisons sparingly. If all compariso..."}}
{"id": "HJ-LL3WOZS", "cdate": 1483228800000, "mdate": null, "content": {"title": "ChoiceRank: Identifying Preferences from Node Traffic in Networks", "abstract": "Understanding how users navigate in a network is of high interest in many applications. We consider a setting where only aggregate node-level traffic is observed and tackle the task of learning edg..."}}
