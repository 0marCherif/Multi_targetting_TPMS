{"id": "t6vEK1QvDl", "cdate": 1672531200000, "mdate": 1682345325502, "content": {"title": "Fast and Multi-aspect Mining of Complex Time-stamped Event Streams", "abstract": "Given a huge, online stream of time-evolving events with multiple attributes, such as online shopping logs: (item, price, brand, time), and local mobility activities: (pick-up and drop-off locations, time), how can we summarize large, dynamic high-order tensor streams? How can we see any hidden patterns, rules, and anomalies? Our answer is to focus on two types of patterns, i.e., ''regimes'' and ''components'', for which we present CubeScope, an efficient and effective method over high-order tensor streams. Specifically, it identifies any sudden discontinuity and recognizes distinct dynamical patterns, ''regimes'' (e.g., weekday/weekend/holiday patterns). In each regime, it also performs multi-way summarization for all attributes (e.g., item, price, brand, and time) and discovers hidden ''components'' representing latent groups (e.g., item/brand groups) and their relationship. Thanks to its concise but effective summarization, CubeScope can also detect the sudden appearance of anomalies and identify the types of anomalies that occur in practice. Our proposed method has the following properties: (a) Effective: it captures dynamical multi-aspect patterns, i.e., regimes and components, and statistically summarizes all the events; (b) General: it is practical for successful application to data compression, pattern discovery, and anomaly detection on various types of tensor streams; (c) Scalable: our algorithm does not depend on the length of the data stream and its dimensionality. Extensive experiments on real datasets demonstrate that CubeScope finds meaningful patterns and anomalies correctly, and consistently outperforms the state-of-the-art methods as regards accuracy and execution speed."}}
{"id": "RctmolTWKI", "cdate": 1672531200000, "mdate": 1682345325676, "content": {"title": "Improving Predicate Representation in Scene Graph Generation by Self-Supervised Learning", "abstract": "Scene graph generation (SGG) aims to understand sophisticated visual information by detecting triplets of subject, object, and their relationship (predicate). Since the predicate labels are heavily imbalanced, existing supervised methods struggle to improve accuracy for the rare predicates due to insufficient labeled data. In this paper, we propose SePiR, a novel self-supervised learning method for SGG to improve the representation of rare predicates. We first train a relational encoder by contrastive learning without using predicate labels, and then fine-tune a predicate classifier with labeled data. To apply contrastive learning to SGG, we newly propose data augmentation in which subject-object pairs are augmented by replacing their visual features with those from other images having the same object labels. By such augmentation, we can increase the variation of the visual features while keeping the relationship between the objects. Comprehensive experimental results on the Visual Genome dataset show that the SGG performance of SePiR is comparable to the state-of-theart, and especially with the limited labeled dataset, our method significantly outperforms the existing supervised methods. Moreover, SePiR\u2019s improved representation enables the model architecture simpler, resulting in 3.6x and 6.3x reduction of the parameters and inference time from the existing method, independently."}}
{"id": "WMnoLsXoZxd", "cdate": 1661412808064, "mdate": 1661412808064, "content": {"title": "Topological Uncertainty: Monitoring trained neural networks through persistence of activation graphs", "abstract": "Although neural networks are capable of reaching\nastonishing performances on a wide variety of con-\ntexts, properly training networks on complicated\ntasks requires expertise and can be expensive from\na computational perspective. In industrial appli-\ncations, data coming from an open-world setting\nmight widely differ from the benchmark datasets on\nwhich a network was trained. Being able to monitor\nthe presence of such variations without retraining\nthe network is of crucial importance. In this article,\nwe develop a method to monitor trained neural net-\nworks based on the topological properties of their\nactivation graphs. To each new observation, we as-\nsign a Topological Uncertainty, a score that aims to\nassess the reliability of the predictions by investi-\ngating the whole network instead of its final layer\nonly, as typically done by practitioners. Our ap-\nproach entirely works at a post-training level and\ndoes not require any assumption on the network\narchitecture, optimization scheme, nor the use of\ndata augmentation or auxiliary datasets; and can be\nfaithfully applied on a large range of network ar-\nchitectures and data types. We showcase experi-\nmentally the potential of Topological Uncertainty\nin the context of trained network selection, Out-Of-\nDistribution detection, and shift-detection, both on\nsynthetic and real datasets of images and graphs."}}
{"id": "bGo0A4bJBc", "cdate": 1652737341742, "mdate": null, "content": {"title": "Cost-Sensitive Self-Training for Optimizing Non-Decomposable Metrics", "abstract": "Self-training based semi-supervised learning algorithms have enabled the learning of highly accurate deep neural networks, using only a fraction of labeled data. However, the majority of work on self-training has focused on the objective of improving accuracy whereas practical machine learning systems can have complex goals (e.g. maximizing the minimum of recall across classes, etc.) that are non-decomposable in nature. In this work, we introduce the Cost-Sensitive Self-Training (CSST) framework which generalizes the self-training-based methods for optimizing non-decomposable metrics. We prove that our framework can better optimize the desired non-decomposable metric utilizing unlabeled data, under similar data distribution assumptions made for the analysis of self-training.  Using the proposed CSST framework, we obtain practical self-training methods (for both vision and NLP tasks) for optimizing different non-decomposable metrics using deep neural networks.  Our results demonstrate that CSST achieves an improvement over the state-of-the-art in majority of the cases across datasets and objectives."}}
{"id": "NPMJt7eKB4Y", "cdate": 1615281330166, "mdate": null, "content": {"title": "PersLay: A Neural Network Layer for Persistence Diagrams andNew Graph Topological Signatures", "abstract": "Persistence diagrams, the most common de-scriptors of Topological Data Analysis, en-code topological properties of data and havealready proved pivotal in many different ap-plications of data science. However, since themetric space of persistence diagrams is notHilbert, they end up being difficult inputs formost Machine Learning techniques. To ad-dress this concern, several vectorization meth-ods have been put forward that embed persis-tence diagrams into either finite-dimensionalEuclidean space or implicit infinite dimen-sional Hilbert space with kernels.In this work, we focus on persistence diagramsbuilt on top of graphs. Relying on extendedpersistence theory and the so-called heat ker-nel signature, we show how graphs can beencoded by (extended) persistence diagramsin a provably stable way. We then propose ageneral and versatile framework for learningvectorizations of persistence diagrams, whichencompasses most of the vectorization tech-niques used in the literature. We finally show-case the experimental strength of our setup byachieving competitive scores on classificationtasks on real-life graph datasets."}}
{"id": "fwHK5nQSeEF", "cdate": 1609459200000, "mdate": 1632877768189, "content": {"title": "ATOL: Measure Vectorization for Automatic Topologically-Oriented Learning", "abstract": "Robust topological information commonly comes in the form of a set of persistence diagrams, finite measures that are in nature uneasy to affix to generic machine learning frameworks. We introduce a fast, learnt, unsupervised vectorization method for measures in Euclidean spaces and use it for reflecting underlying changes in topological behaviour in machine learning contexts. The algorithm is simple and efficiently discriminates important space regions where meaningful differences to the mean measure arise. It is proven to be able to separate clusters of persistence diagrams. We showcase the strength and robustness of our approach on a number of applications, from emulous and modern graph collections where the method reaches state-of-the-art performance to a geometric synthetic dynamical orbits problem. The proposed methodology comes with a single high level tuning parameter: the total measure encoding budget. We provide a completely open access software."}}
{"id": "XZYUk-EY7byj", "cdate": 1609459200000, "mdate": 1632877768186, "content": {"title": "Topological Uncertainty: Monitoring Trained Neural Networks through Persistence of Activation Graphs", "abstract": "Although neural networks are capable of reaching astonishing performance on a wide variety of contexts, properly training networks on complicated tasks requires expertise and can be expensive from a computational perspective. In industrial applications, data coming from an open-world setting might widely differ from the benchmark datasets on which a network was trained. Being able to monitor the presence of such variations without retraining the network is of crucial importance. In this paper, we develop a method to monitor trained neural networks based on the topological properties of their activation graphs. To each new observation, we assign a Topological Uncertainty, a score that aims to assess the reliability of the predictions by investigating the whole network instead of its final layer only as typically done by practitioners. Our approach entirely works at a post-training level and does not require any assumption on the network architecture, optimization scheme, nor the use of data augmentation or auxiliary datasets; and can be faithfully applied on a large range of network architectures and data types. We showcase experimentally the potential of Topological Uncertainty in the context of trained network selection, Out-Of-Distribution detection, and shift-detection, both on synthetic and real datasets of images and graphs."}}
{"id": "LZiAIWOI1V", "cdate": 1609459200000, "mdate": 1632877768187, "content": {"title": "Topological Uncertainty: Monitoring trained neural networks through persistence of activation graphs", "abstract": "Although neural networks are capable of reaching astonishing performances on a wide variety of contexts, properly training networks on complicated tasks requires expertise and can be expensive from a computational perspective. In industrial applications, data coming from an open-world setting might widely differ from the benchmark datasets on which a network was trained. Being able to monitor the presence of such variations without retraining the network is of crucial importance. In this article, we develop a method to monitor trained neural networks based on the topological properties of their activation graphs. To each new observation, we assign a Topological Uncertainty, a score that aims to assess the reliability of the predictions by investigating the whole network instead of its final layer only, as typically done by practitioners. Our approach entirely works at a post-training level and does not require any assumption on the network architecture, optimization scheme, nor the use of data augmentation or auxiliary datasets; and can be faithfully applied on a large range of network architectures and data types. We showcase experimentally the potential of Topological Uncertainty in the context of trained network selection, Out-Of-Distribution detection, and shift-detection, both on synthetic and real datasets of images and graphs."}}
{"id": "4LchLwjShW7", "cdate": 1609459200000, "mdate": 1632877768129, "content": {"title": "Optimizing persistent homology based functions", "abstract": "Solving optimization tasks based on functions and losses with a topological flavor is a very active and growing field of research in data science and Topological Data Analysis, with applications in..."}}
{"id": "szTsSnY3EaT", "cdate": 1602348634835, "mdate": null, "content": {"title": "Application of Topological Data Analysis to Delirium Detection", "abstract": "We propose a new scoring algorithm for detecting delirium from one-channel EEG, based on topological data analysis.  Numerical experiments demonstrated that our method achieved high predictive performance than the other existing methods. "}}
