{"id": "cYKtDg5JnxV", "cdate": 1677713827493, "mdate": null, "content": {"title": "Neuromodulation Gated Transformer", "abstract": "We introduce a novel architecture, the Neuromodulation Gated Transformer (NGT), which is a simple implementation of neuromodulation in transformers via a multiplicative effect. We compare it to baselines and show that it results in the best average performance on the SuperGLUE benchmark validation sets."}}
{"id": "Q5gX9UNURjQ", "cdate": 1577836800000, "mdate": null, "content": {"title": "Towards Knowledgeable Supervised Lifelong Learning Systems", "abstract": "Learning a sequence of tasks is a long-standing challenge in machine learning. This setting applies to learning systems that observe examples of a range of tasks at different points in time. A learning system should become more knowledgeable as more related tasks are learned. Although the problem of learning sequentially was acknowledged for the first time decades ago, the research in this area has been rather limited. Research in transfer learning, multitask learning, metalearning and deep learning has studied some challenges of these kinds of systems. Recent research in lifelong machine learning and continual learning has revived interest in this problem. We propose Proficiente, a full framework for long-term learning systems. Proficiente relies on knowledge transferred between hypotheses learned with Support Vector Machines. The first component of the framework is focused on transferring forward selectively from a set of existing hypotheses or functions representing knowledge acquired during previous tasks to a new target task. A second component of Proficiente is focused on transferring backward, a novel ability of long-term learning systems that aim to exploit knowledge derived from recent tasks to encourage refinement of existing knowledge. We propose a method that transfers selectively from a task learned recently to existing hypotheses representing previous tasks. The method encourages retention of existing knowledge whilst refining. We analyse the theoretical properties of the proposed framework. Proficiente is accompanied by an agnostic metric that can be used to determine if a long-term learning system is becoming more knowledgeable. We evaluate Proficiente in both synthetic and real-world datasets, and demonstrate scenarios where knowledgeable supervised learning systems can be achieved by means of transfer."}}
{"id": "r7N40zzxupH", "cdate": 1546300800000, "mdate": null, "content": {"title": "An SVM-Based Framework for Long-Term Learning Systems.", "abstract": "In our research, we study the problem of learning a sequence of supervised tasks. This is a long-standing challenge in machine learning. Our work relies on transfer of knowledge between hypotheses learned with Support Vector Machines. Transfer occurs in two directions: forward and backward. We have proposed to selectively transfer forward support vector coefficients from previous hypotheses as upper-bounds on support vector coefficients to be learned on a target task. We also proposed a novel method for refining existing hypotheses by transferring backward knowledge from a target hypothesis learned recently. We have improved this method through a hypothesis refinement approach that refines whilst encouraging retention of knowledge. Our contribution is represented in a long-term learning framework for binary classification tasks received sequentially one at a time."}}
{"id": "OE7Ocgq8tqt", "cdate": 1546300800000, "mdate": null, "content": {"title": "Selective Hypothesis Transfer for Lifelong Learning", "abstract": "Selective transfer has been proposed as an alternative for transferring fragments of knowledge. Previous work showed that transferring selectively from a group of hypotheses helps to speed learning on a target task. Similarly, existing hypotheses could benefit by selective backward transfer of recent knowledge. This setting applies to supervised machine learning systems that observe a sequence of related tasks. We propose a novel scheme for bi-directional transfer between hypotheses learned sequentially using Support Vector Machines. Transfer occurs in two directions: forward and backward. During transfer forward, a new binary classification task is to be learned. Existing knowledge is used to reinforce the importance of subspaces on the target training data that are related to source support vectors. While this target task is learned, subspaces of shared knowledge between each source hypothesis and the target hypothesis are identified. Representations of these subspaces are learned and used to refine the sources by transferring backward. Albeit fundamental, the exploration of the problem of hypothesis refinement has been very limited. We define this problem and propose a solution. Our experiments show that a learning system can gain up to 5.5 units in mean classification accuracy of tasks learned sequentially using our scheme, within 26.6% of the number of iterations when these tasks are learned from scratch."}}
{"id": "_38jFQTx1zZ", "cdate": 1514764800000, "mdate": null, "content": {"title": "A case study of algorithm-assisted decision making in child maltreatment hotline screening decisions.", "abstract": "Every year there are more than 3.6 million referrals made to child protection agencies across the US. The practice of screening calls is left to each jurisdiction to follow local practices and poli..."}}
{"id": "Sy-2tHzO-r", "cdate": 1483228800000, "mdate": null, "content": {"title": "AccGenSVM: Selectively Transferring from Previous Hypotheses", "abstract": "In our research, we consider transfer learning scenarios where a target learner does not have access to the source data, but instead to hypotheses or models induced from it. This is called the Hypothesis Transfer Learning (HTL) problem. Previous approaches concentrated on transferring source hypotheses as a whole. We introduce a novel method for selectively transferring elements from previous hypotheses learned with Support Vector Machines. The representation of an SVM hypothesis as a set of support vectors allows us to treat this information as privileged to aid learning during a new task. Given a possibly large number of source hypotheses, our approach selects the source support vectors that more closely resemble the target data, and transfers their learned coefficients as constraints on the coefficients to be learned. This strategy increases the importance of relevant target data points based on their similarity to source support vectors, while learning from the target data. Our method shows important improvements on the convergence rate on three classification datasets of varying sizes, decreasing the number of iterations by up to 56% on average compared to learning with no transfer and up to 92% compared to regular HTL, while maintaining similar accuracy levels."}}
{"id": "S17lxXGO-B", "cdate": 1483228800000, "mdate": null, "content": {"title": "A Framework for Long-Term Learning Systems", "abstract": "Increasing amounts of data have made the use of machine learning techniques much more widespread. A lot of research in machine learning has been dedicated to the design and application of effective and efficient algorithms to explain or predict facts. The development of intelligent machines that can learn over extended periods of time, and that improve their abilities as they execute more tasks, is still a pending contribution from computer science to the world. This weakness has been recognised for some decades, and an interest to solve it seems to be increasing, as demonstrated by recent leading work and broader discussions at main events in the field [Chen and Liu, 2015; Chen et al., 2016]. Our research is intended to help fill that gap."}}
{"id": "YW0Hkfqe2rF", "cdate": 1420070400000, "mdate": null, "content": {"title": "MOGACAR: A Method for Filtering Interesting Classification Association Rules", "abstract": "Knowledge Discovery process is intended to provide valid, novel, potentially useful and finally understandable patterns from data. An interesting research area concerns the identification and use of interestingness measures, in order to rank or filter results and provide what might be called better knowledge. For association rules mining, some research has been focused on how to filter itemsets and rules, in order to guide knowledge acquisition from the user\u2019s point of view, as well as to improve efficiency of the process. In this paper, we explain MOGACAR, an approach for ranking and filtering association rules when there are multiple technical and business interestingness measures; MOGACAR uses a multi-objective optimization method based on genetic algorithm for classification association rules, with the intention to find the most interesting, and still valid, itemsets and rules."}}
{"id": "ZJ3N7LjfpTz", "cdate": 1356998400000, "mdate": null, "content": {"title": "KDBuss Framework: Knowledge Discovery with Association Rules in the Business Context", "abstract": ""}}
