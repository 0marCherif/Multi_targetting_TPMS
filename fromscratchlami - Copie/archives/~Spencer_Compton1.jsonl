{"id": "snsTK5_BqvQ", "cdate": 1672531200000, "mdate": 1681491219510, "content": {"title": "Minimum-Entropy Coupling Approximation Guarantees Beyond the Majorization Barrier", "abstract": ""}}
{"id": "epKRq8WxIb", "cdate": 1640995200000, "mdate": 1683610234325, "content": {"title": "A Tighter Approximation Guarantee for Greedy Minimum Entropy Coupling", "abstract": "We examine the minimum entropy coupling problem, where one must find the minimum entropy variable that has a given set of distributions S = {p <inf xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">1</inf> ,\u2026,p <inf xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">m</inf> } as its marginals. Although this problem is NP-Hard, previous works have proposed algorithms with varying approximation guarantees. In this paper, we show that the greedy coupling algorithm of [Kocaoglu et al., AAAI\u201917] is always within log <inf xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">2</inf> (e) (\u2248 1.44) bits of the minimum entropy coupling. In doing so, we show that the entropy of the greedy coupling is upper-bounded by H(\u22c0S) + log <inf xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">2</inf> (e). This improves the previously best known approximation guarantee of 2 bits within the optimal [Li, IEEE Trans. Inf. Theory \u201921]. Moreover, we show our analysis is tight by constructing sets of distributions where the entropy of the minimum entropy coupling can be arbitrarily close to H(\u22c0S) + log <inf xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">2</inf> (e). Additionally, we examine a special class of instances where the greedy coupling algorithm is exactly optimal."}}
{"id": "Y_cTWVHlqax", "cdate": 1640995200000, "mdate": 1681491220169, "content": {"title": "Entropic Causal Inference: Graph Identifiability", "abstract": ""}}
{"id": "Ne9sq7mXoQ", "cdate": 1640995200000, "mdate": 1683610234329, "content": {"title": "A Tighter Approximation Guarantee for Greedy Minimum Entropy Coupling", "abstract": "We examine the minimum entropy coupling problem, where one must find the minimum entropy variable that has a given set of distributions $S = \\{p_1, \\dots, p_m \\}$ as its marginals. Although this problem is NP-Hard, previous works have proposed algorithms with varying approximation guarantees. In this paper, we show that the greedy coupling algorithm of [Kocaoglu et al., AAAI'17] is always within $\\log_2(e)$ ($\\approx 1.44$) bits of the minimum entropy coupling. In doing so, we show that the entropy of the greedy coupling is upper-bounded by $H\\left(\\bigwedge S \\right) + \\log_2(e)$. This improves the previously best known approximation guarantee of $2$ bits within the optimal [Li, IEEE Trans. Inf. Theory '21]. Moreover, we show our analysis is tight by proving there is no algorithm whose entropy is upper-bounded by $H\\left(\\bigwedge S \\right) + c$ for any constant $c<\\log_2(e)$. Additionally, we examine a special class of instances where the greedy coupling algorithm is exactly optimal."}}
{"id": "6-iUjNChRf-", "cdate": 1609459200000, "mdate": 1651442460512, "content": {"title": "Entropic Causal Inference: Identifiability and Finite Sample Results", "abstract": "Entropic causal inference is a framework for inferring the causal direction between two categorical variables from observational data. The central assumption is that the amount of unobserved randomness in the system is not too large. This unobserved randomness is measured by the entropy of the exogenous variable in the underlying structural causal model, which governs the causal relation between the observed variables. Kocaoglu et al. conjectured that the causal direction is identifiable when the entropy of the exogenous variable is not too large. In this paper, we prove a variant of their conjecture. Namely, we show that for almost all causal models where the exogenous variable has entropy that does not scale with the number of states of the observed variables, the causal direction is identifiable from observational data. We also consider the minimum entropy coupling-based algorithmic approach presented by Kocaoglu et al., and for the first time demonstrate algorithmic identifiability guarantees using a finite number of samples. We conduct extensive experiments to evaluate the robustness of the method to relaxing some of the assumptions in our theory and demonstrate that both the constant-entropy exogenous variable and the no latent confounder assumptions can be relaxed in practice. We also empirically characterize the number of observational samples needed for causal identification. Finally, we apply the algorithm on Tuebingen cause-effect pairs dataset."}}
{"id": "h6_OLbH-JvQ", "cdate": 1577836800000, "mdate": 1683610234329, "content": {"title": "Edge Matching with Inequalities, Triangles, Unknown Shape, and Two Players", "abstract": "We analyze the computational complexity of several new variants of edge-matching puzzles. First we analyze inequality (instead of equality) constraints between adjacent tiles, proving the problem NP-complete for strict inequalities but polynomial for nonstrict inequalities. Second we analyze three types of triangular edge matching, of which one is polynomial and the other two are NP-complete; all three are #P-complete. Third we analyze the case where no target shape is specified, and we merely want to place the (square) tiles so that edges match (exactly); this problem is NP-complete. Fourth we consider four 2-player games based on $1 \\times n$ edge matching, all four of which are PSPACE-complete. Most of our NP-hardness reductions are parsimonious, newly proving #P and ASP-completeness for, e.g., $1 \\times n$ edge matching."}}
{"id": "g3Ms5GlAtS8", "cdate": 1577836800000, "mdate": 1683610234323, "content": {"title": "New Partitioning Techniques and Faster Algorithms for Approximate Interval Scheduling", "abstract": "Interval scheduling is a basic problem in the theory of algorithms and a classical task in combinatorial optimization. We develop a set of techniques for partitioning and grouping jobs based on their starting and ending times, that enable us to view an instance of interval scheduling on many jobs as a union of multiple interval scheduling instances, each containing only a few jobs. Instantiating these techniques in dynamic and local settings of computation leads to several new results. For $(1+\\varepsilon)$-approximation of job scheduling of $n$ jobs on a single machine, we develop a fully dynamic algorithm with $O(\\frac{\\log{n}}{\\varepsilon})$ update and $O(\\log{n})$ query worst-case time. Further, we design a local computation algorithm that uses only $O(\\frac{\\log{N}}{\\varepsilon})$ queries when all jobs are length at least $1$ and have starting/ending times within $[0,N]$. Our techniques are also applicable in a setting where jobs have rewards/weights. For this case we design a fully dynamic deterministic algorithm whose worst-case update and query time are $\\operatorname{poly}(\\log n,\\frac{1}{\\varepsilon})$. Equivalently, this is the first algorithm that maintains a $(1+\\varepsilon)$-approximation of the maximum independent set of a collection of weighted intervals in $\\operatorname{poly}(\\log n,\\frac{1}{\\varepsilon})$ time updates/queries. This is an exponential improvement in $1/\\varepsilon$ over the running time of a randomized algorithm of Henzinger, Neumann, and Wiese ~[SoCG, 2020], while also removing all dependence on the values of the jobs' starting/ending times and rewards, as well as removing the need for any randomness. We also extend our approaches for interval scheduling on a single machine to examine the setting with $M$ machines."}}
{"id": "fblSHh0WEbf", "cdate": 1577836800000, "mdate": 1683610234320, "content": {"title": "Edge Matching with Inequalities, Triangles, Unknown Shape, and Two Players", "abstract": ""}}
{"id": "3YXR5vukute", "cdate": 1577836800000, "mdate": 1651442460583, "content": {"title": "Entropic Causal Inference: Identifiability and Finite Sample Results", "abstract": "Entropic causal inference is a framework for inferring the causal direction between two categorical variables from observational data. The central assumption is that the amount of unobserved randomness in the system is not too large. This unobserved randomness is measured by the entropy of the exogenous variable in the underlying structural causal model, which governs the causal relation between the observed variables. Kocaoglu et al. conjectured that the causal direction is identifiable when the entropy of the exogenous variable is not too large. In this paper, we prove a variant of their conjecture. Namely, we show that for almost all causal models where the exogenous variable has entropy that does not scale with the number of states of the observed variables, the causal direction is identifiable from observational data. We also consider the minimum entropy coupling-based algorithmic approach presented by Kocaoglu et al., and for the first time demonstrate algorithmic identifiability guarantees using a finite number of samples. We conduct extensive experiments to evaluate the robustness of the method to relaxing some of the assumptions in our theory and demonstrate that both the constant-entropy exogenous variable and the no latent confounder assumptions can be relaxed in practice. We also empirically characterize the number of observational samples needed for causal identification. Finally, we apply the algorithm on Tuebingen cause-effect pairs dataset."}}
