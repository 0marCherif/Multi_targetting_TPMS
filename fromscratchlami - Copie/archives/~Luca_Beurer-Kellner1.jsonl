{"id": "eirJfFBHC7B", "cdate": 1675209600000, "mdate": 1684271083991, "content": {"title": "A Transformational Approach to Managing Data Model Evolution of Web Services", "abstract": "The communication of web services is typically organized through public APIs, which rely on a common data model shared among all system components. Over time, this data model must be changed in order to accommodate new or changing requirements, and the system components including the data they are operating on must be migrated. In practice, however, not all the affected components can be migrated instantly and at the same time. A common approach is to plan data model changes in a backward compatible fashion, which eventually causes serious maintenance problems and is a common cause of technical debt. In this paper, we propose an alternative solution to this problem by using a translation layer serving as a round-trip migration service which is responsible for the lossless forth-and-back translation of object-oriented data model instances of different versions. We present a framework which offers a version-aware interface definition language (IDL) for APIs, a typed JavaScript-based language for defining migration functions using the IDL definition, and a run-time environment for executing migrations. This is bundled into an integrated development environment assisting developers in implementing migration functions. From a methodological point of view, the development of round-trip migrations is supported by a catalog which comprises a set of typical data model evolution scenarios along with corresponding suitable round-trip migration strategies. We validate our framework by carrying out an extensive evaluation including a systematic assessment of expressiveness using our catalog, micro-benchmarking the performance of round-trip migrations, as well as a practical application in a case study of a real-world e-commerce web application obtained from an industrial partner."}}
{"id": "AiY6XvomZV4", "cdate": 1652737771507, "mdate": null, "content": {"title": "Learning to Configure Computer Networks with Neural Algorithmic Reasoning", "abstract": "We present a new method for scaling automatic configuration of computer networks. The key idea is to relax the computationally hard search problem of finding a configuration that satisfies a given specification into an approximate objective amenable to learning-based techniques. Based on this idea, we train a neural algorithmic model which learns to generate configurations likely to (fully or partially) satisfy a given specification under existing routing protocols. By relaxing the rigid satisfaction guarantees, our approach (i) enables greater flexibility: it is protocol-agnostic, enables cross-protocol reasoning, and does not depend on hardcoded rules; and (ii) finds configurations for much larger computer networks than previously possible. Our learned synthesizer is up to 490x faster than state-of-the-art SMT-based methods, while producing configurations which on average satisfy more than 93% of the provided requirements.  "}}
{"id": "z_m2YCP7V8", "cdate": 1640995200000, "mdate": 1684271083991, "content": {"title": "Learning to Configure Computer Networks with Neural Algorithmic Reasoning", "abstract": "We present a new method for scaling automatic configuration of computer networks. The key idea is to relax the computationally hard search problem of finding a configuration that satisfies a given specification into an approximate objective amenable to learning-based techniques. Based on this idea, we train a neural algorithmic model which learns to generate configurations likely to (fully or partially) satisfy a given specification under existing routing protocols. By relaxing the rigid satisfaction guarantees, our approach (i) enables greater flexibility: it is protocol-agnostic, enables cross-protocol reasoning, and does not depend on hardcoded rules; and (ii) finds configurations for much larger computer networks than previously possible. Our learned synthesizer is up to 490x faster than state-of-the-art SMT-based methods, while producing configurations which on average satisfy more than 93% of the provided requirements."}}
{"id": "yOHqxDrxsL", "cdate": 1640995200000, "mdate": 1681841927513, "content": {"title": "On Distribution Shift in Learning-based Bug Detectors", "abstract": "Deep learning has recently achieved initial success in program analysis tasks such as bug detection. Lacking real bugs, most existing works construct training and test data by injecting synthetic b..."}}
{"id": "wDlxPST4F4Bh", "cdate": 1640995200000, "mdate": 1652729642827, "content": {"title": "On Distribution Shift in Learning-based Bug Detectors", "abstract": "Deep learning has recently achieved initial success in program analysis tasks such as bug detection. Lacking real bugs, most existing works construct training and test data by injecting synthetic bugs into correct programs. Despite achieving high test accuracy (e.g., 90%), the resulting bug detectors are found to be surprisingly unusable in practice, i.e., <10% precision when used to scan real software repositories. In this work, we argue that this massive performance difference is caused by a distribution shift, i.e., a fundamental mismatch between the real bug distribution and the synthetic bug distribution used to train and evaluate the detectors. To address this key challenge, we propose to train a bug detector in two phases, first on a synthetic bug distribution to adapt the model to the bug detection domain, and then on a real bug distribution to drive the model towards the real distribution. During these two phases, we leverage a multi-task hierarchy, focal loss, and contrastive learning to further boost performance. We evaluate our approach extensively on three widely studied bug types, for which we construct new datasets carefully designed to capture the real bug distribution. The results demonstrate that our approach is practically effective and successfully mitigates the distribution shift: our learned detectors are highly performant on both our test set and the latest version of open source repositories. Our code, datasets, and models are publicly available at https://github.com/eth-sri/learning-real-bug-detector."}}
{"id": "Zq3iwCNmlq9", "cdate": 1640995200000, "mdate": 1674983355643, "content": {"title": "Prompting Is Programming: A Query Language For Large Language Models", "abstract": "Large language models have demonstrated outstanding performance on a wide range of tasks such as question answering and code generation. On a high level, given an input, a language model can be used to automatically complete the sequence in a statistically-likely way. Based on this, users prompt these models with language instructions or examples, to implement a variety of downstream tasks. Advanced prompting methods can even imply interaction between the language model, a user, and external tools such as calculators. However, to obtain state-of-the-art performance or adapt language models for specific tasks, complex task- and model-specific programs have to be implemented, which may still require ad-hoc interaction. Based on this, we present the novel idea of Language Model Programming (LMP). LMP generalizes language model prompting from pure text prompts to an intuitive combination of text prompting and scripting. Additionally, LMP allows constraints to be specified over the language model output. This enables easy adaption to many tasks while abstracting language model internals and providing high-level semantics. To enable LMP, we implement LMQL(short for Language Model Query Language), which leverages the constraints and control flow from an LMP prompt to generate an efficient inference procedure that minimizes the number of expensive calls to the underlying language model. We show that LMQL can capture a wide range of state-of-the-art prompting methods in an intuitive way, especially facilitating interactive flows that are challenging to implement with existing high-level APIs. Our evaluation shows that we retain or increase the accuracy on several downstream tasks, while also significantly reducing the required amount of computation or cost in the case of pay-to-use APIs (26-85% cost savings)."}}
{"id": "9oY5Fa4ucXE", "cdate": 1640995200000, "mdate": 1684271083988, "content": {"title": "Learning to Configure Computer Networks with Neural Algorithmic Reasoning", "abstract": "We present a new method for scaling automatic configuration of computer networks. The key idea is to relax the computationally hard search problem of finding a configuration that satisfies a given specification into an approximate objective amenable to learning-based techniques. Based on this idea, we train a neural algorithmic model which learns to generate configurations likely to (fully or partially) satisfy a given specification under existing routing protocols. By relaxing the rigid satisfaction guarantees, our approach (i) enables greater flexibility: it is protocol-agnostic, enables cross-protocol reasoning, and does not depend on hardcoded rules; and (ii) finds configurations for much larger computer networks than previously possible. Our learned synthesizer is up to 490x faster than state-of-the-art SMT-based methods, while producing configurations which on average satisfy more than 93% of the provided requirements."}}
