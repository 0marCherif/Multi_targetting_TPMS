{"id": "XybEIpfrJ3t", "cdate": 1676827108242, "mdate": null, "content": {"title": "Regularized Online DR-Submodular Optimization", "abstract": "The utilization of online optimization techniques is prevalent in many fields of artificial intelligence, enabling systems to continuously learn and adjust to their surroundings. This paper outlines a regularized online optimization problem, where the regularizer is defined on the average of the actions taken. The objective is to maximize  the sum of rewards and the regularizer value while adhering to resource constraints, where the reward function is assumed to be DR-submodular. Both concave and DR-submodular regularizers are analyzed. Concave functions are useful in describing the impartiality of decisions, while DR-submodular functions can be employed to represent the overall effect of decisions on all relevant parties. We have developed two algorithms for each of the concave and DR-submodular regularizers. These algorithms are easy to implement, efficient, and produce sublinear regret in both cases. The performance of the proposed algorithms and regularizers has been verified through numerical experiments in the context of internet advertising."}}
{"id": "n2bJ4cyOkWL", "cdate": 1672531200000, "mdate": 1675174253470, "content": {"title": "Streaming adaptive submodular maximization", "abstract": ""}}
{"id": "GsLRt07h6zz", "cdate": 1672531200000, "mdate": 1675174253489, "content": {"title": "Partial-monotone adaptive submodular maximization", "abstract": "Many AI/Machine learning problems require adaptively selecting a sequence of items, each selected item might provide some feedback that is valuable for making better selections in the future, with the goal of maximizing an adaptive submodular function. Most of existing studies in this field focus on either monotone case or non-monotone case. Specifically, if the utility function is monotone and adaptive submodular, Golovin and Krause (J Artif Intell Res 42:427\u2013486, 2011) developed $$(1-1/e)$$ ( 1 - 1 / e ) approximation solution subject to a cardinality constraint. For the cardinality-constrained non-monotone case, Tang (Theor Comput Sci 850:249\u2013261, 2021) showed that a random greedy policy attains an approximation ratio of 1/e. In this work, we generalize the above mentioned results by studying the partial-monotone adaptive submodular maximization problem. To this end, we introduce the notation of adaptive monotonicity ratio $$m\\in [0,1]$$ m \u2208 [ 0 , 1 ] to measure the degree of monotonicity of a function. Our main result is to show that for the case of cardinality constraints, if the utility function has an adaptive monotonicity ratio of m and it is adaptive submodular, then a random greedy policy attains an approximation ratio of $$m(1-1/e)+(1-m)(1/e)$$ m ( 1 - 1 / e ) + ( 1 - m ) ( 1 / e ) . Notably this result recovers the aforementioned $$(1-1/e)$$ ( 1 - 1 / e ) and 1/e approximation ratios when $$m = 1$$ m = 1 and $$m = 0$$ m = 0 , respectively. We further extend our results to consider a knapsack constraint and develop a $$(m+1)/10$$ ( m + 1 ) / 10 approximation solution for this general case. One important implication of our results is that even for a non-monotone utility function, we still can attain an approximation ratio close to $$(1-1/e)$$ ( 1 - 1 / e ) if this function is \u201cclose\u201d to a monotone function. This leads to improved performance bounds for many machine learning applications whose utility functions are almost adaptive monotone."}}
{"id": "sj9l1JCrAk6", "cdate": 1652737508104, "mdate": null, "content": {"title": "Federated Submodel Optimization for Hot and Cold Data Features", "abstract": "We focus on federated learning in practical recommender systems and natural language processing scenarios. The global model for federated optimization typically contains a large and sparse embedding layer, while each client\u2019s local data tend to interact with part of features, updating only a small submodel with the feature-related embedding vectors. We identify a new and important issue that distinct data features normally involve different numbers of clients, generating the differentiation of hot and cold features. We further reveal that the classical federated averaging algorithm (FedAvg) or its variants, which randomly selects clients to participate and uniformly averages their submodel updates, will be severely slowed down, because different parameters of the global model are optimized at different speeds. More specifically, the model parameters related to hot (resp., cold) features will be updated quickly (resp., slowly). We thus propose federated submodel averaging (FedSubAvg), which introduces the number of feature-related clients as the metric of feature heat to correct the aggregation of submodel updates. We prove that due to the dispersion of feature heat, the global objective is ill-conditioned, and FedSubAvg works as a suitable diagonal preconditioner. We also rigorously analyze FedSubAvg\u2019s convergence rate to stationary points. We finally evaluate FedSubAvg over several public and industrial datasets. The evaluation results demonstrate that FedSubAvg significantly outperforms FedAvg and its variants."}}
{"id": "rWMjEXUVls", "cdate": 1640995200000, "mdate": 1675174253443, "content": {"title": "Toward Robust Monitoring of Malicious Outbreaks", "abstract": "Recently, diffusion processes in social networks have attracted increasing attention within computer science, marketing science, social sciences, and political science. Although the majority of exi..."}}
{"id": "ekQNzGaPn_", "cdate": 1640995200000, "mdate": 1675174253432, "content": {"title": "Constrained Stochastic Submodular Maximization with State-Dependent Costs", "abstract": "In this paper, we study the constrained stochastic submodular maximization problem with state-dependent costs. The input of our problem is a set of items whose states (i.e., the marginal contribution and the cost of an item) are drawn from a known probability distribution. The only way to know the realized state of an item is to select that item. We consider two constraints, i.e., inner and outer constraints. Recall that each item has a state-dependent cost, and the inner constraint states that the total realized cost of all selected items must not exceed a give budget. Thus, inner constraint is state-dependent. The outer constraint, on the other hand, is state-independent. It can be represented as a downward-closed family of sets of selected items regardless of their states. Our objective is to maximize the objective function subject to both inner and outer constraints. Under the assumption that larger cost indicates larger \u201cutility\u201d, we present a constant approximate solution to this problem."}}
{"id": "d8a8AHruMMV", "cdate": 1640995200000, "mdate": 1675174253422, "content": {"title": "Worst-Case Adaptive Submodular Cover", "abstract": "In this paper, we study the adaptive submodular cover problem under the worst-case setting. This problem generalizes many previously studied problems, namely, the pool-based active learning and the stochastic submodular set cover. The input of our problem is a set of items (e.g., medical tests) and each item has a random state (e.g., the outcome of a medical test), whose realization is initially unknown. One must select an item at a fixed cost in order to observe its realization. There is an utility function which maps a subset of items and their states to a non-negative real number. We aim to sequentially select a group of items to achieve a ``target value'' while minimizing the maximum cost across realizations (a.k.a. worst-case cost). To facilitate our study, we assume that the utility function is \\emph{worst-case submodular}, a property that is commonly found in many machine learning applications. With this assumption, we develop a tight $(\\log (Q/\\eta)+1)$-approximation policy, where $Q$ is the ``target value'' and $\\eta$ is the smallest difference between $Q$ and any achievable utility value $\\hat{Q}<Q$. We also study a worst-case maximum-coverage problem, a dual problem of the minimum-cost-cover problem, whose goal is to select a group of items to maximize its worst-case utility subject to a budget constraint. To solve this problem, we develop a $(1-1/e)/2$-approximation solution."}}
{"id": "bwMfqIiDtF", "cdate": 1640995200000, "mdate": 1675174253473, "content": {"title": "Partial-Monotone Adaptive Submodular Maximization", "abstract": "Many sequential decision making problems, including pool-based active learning and adaptive viral marketing, can be formulated as an adaptive submodular maximization problem. Most of existing studies on adaptive submodular optimization focus on either monotone case or non-monotone case. Specifically, if the utility function is monotone and adaptive submodular, \\cite{golovin2011adaptive} developed a greedy policy that achieves a $(1-1/e)$ approximation ratio subject to a cardinality constraint. If the utility function is non-monotone and adaptive submodular, \\cite{tang2021beyond} showed that a random greedy policy achieves a $1/e$ approximation ratio subject to a cardinality constraint. In this work, we aim to generalize the above mentioned results by studying the partial-monotone adaptive submodular maximization problem. To this end, we introduce the notation of adaptive monotonicity ratio $m\\in[0,1]$ to measure the degree of monotonicity of a function. Our main result is to show that a random greedy policy achieves an approximation ratio of $m(1-1/e)+(1-m)(1/e)$ if the utility function is $m$-adaptive monotone and adaptive submodular. Notably this result recovers the aforementioned $(1-1/e)$ and $1/e$ approximation ratios when $m = 0$ and $m = 1$, respectively. We further extend our results to consider a knapsack constraint. We show that a sampling-based policy achieves an approximation ratio of $(m+1)/10$ if the utility function is $m$-adaptive monotone and adaptive submodular. One important implication of our results is that even for a non-monotone utility function, we still can achieve an approximation ratio close to $(1-1/e)$ if this function is ``close'' to a monotone function. This leads to improved performance bounds for many machine learning applications whose utility functions are almost adaptive monotone."}}
{"id": "UmaYAP4a4JU", "cdate": 1640995200000, "mdate": 1675174253471, "content": {"title": "Stochastic submodular probing with state-dependent costs", "abstract": ""}}
{"id": "PaxE_1G_Xf", "cdate": 1640995200000, "mdate": 1675174253434, "content": {"title": "Streaming Adaptive Submodular Maximization", "abstract": "Many sequential decision making problems can be formulated as an adaptive submodular maximization problem. However, most of existing studies in this field focus on pool-based setting, where one can pick items in any order, and there have been few studies for the stream-based setting where items arrive in an arbitrary order and one must immediately decide whether to select an item or not upon its arrival. In this paper, we introduce a new class of utility functions, semi-policywise submodular functions. We develop a series of effective algorithms to maximize a semi-policywise submodular function under the stream-based setting."}}
