{"id": "HbaQ4FEh-6", "cdate": 1621630102604, "mdate": null, "content": {"title": "Adapting to function difficulty and growth conditions in private optimization", "abstract": "We develop algorithms for private stochastic convex optimization that adapt to the hardness of the specific function we wish to optimize. While previous work provide worst-case bounds for arbitrary convex functions, it is often the case that the function at hand belongs to a smaller class that enjoys faster rates. Concretely, we show that for functions exhibiting $\\kappa$-growth around the optimum, i.e., $f(x) \\ge f(x^\\star) + \\lambda \\kappa^{-1} \\|x-x^\\star\\|_2^\\kappa$ for $\\kappa > 1$, our algorithms improve upon the standard ${\\sqrt{d}}/{n\\varepsilon}$ privacy rate to the faster $({\\sqrt{d}}/{n\\varepsilon})^{\\tfrac{\\kappa}{\\kappa - 1}}$. Crucially, they achieve these rates without knowledge of the growth constant $\\kappa$ of the function. Our algorithms build upon the inverse sensitivity mechanism, which adapts to instance difficulty [2], and recent localization techniques in private optimization [25]. We complement our algorithms with matching lower bounds for these function classes and demonstrate that our adaptive algorithm is simultaneously (minimax) optimal over all $\\kappa \\ge 1+c$ whenever $c = \\Theta(1)$."}}
{"id": "Gm-0H9DZALK", "cdate": 1621629923203, "mdate": null, "content": {"title": "Stochastic Bias-Reduced Gradient Methods", "abstract": "We develop a new primitive for stochastic optimization: a low-bias, low-cost  estimator of the minimizer $x_\\star$ of any Lipschitz strongly-convex function $f$. In particular, we use a multilevel Monte-Carlo approach due to Blanchet and Glynn to turn any optimal stochastic gradient method into an estimator of $x_\\star$ with bias $\\delta$, variance $O(\\log(1/\\delta))$, and an expected sampling cost of $O(\\log(1/\\delta))$ stochastic gradient evaluations. As an immediate consequence, we obtain cheap and nearly unbiased gradient estimators for the Moreau envelope of any Lipschitz convex function. We demonstrate the potential of our estimator through four applications. First, we develop a method for minimizing the maximum of $N$ functions, improving on recent results and matching a lower bound up to logarithmic factors. Second and third, we recover state-of-the-art rates for projection-efficient and gradient-efficient optimization using simple algorithms with a transparent analysis. Finally, we show that an improved version of our estimator would yield a nearly linear-time, optimal-utility, differentially-private non-smooth stochastic optimization method."}}
{"id": "p1gA_NbozKt", "cdate": 1609459200000, "mdate": null, "content": {"title": "Private Stochastic Convex Optimization: Optimal Rates in \ud835\udcc11 Geometry", "abstract": "Stochastic convex optimization over an $\\ell_1$-bounded domain is ubiquitous in machine learning applications such as LASSO but remains poorly understood when learning with differential privacy. We show that, up to logarithmic factors the optimal excess population loss of any $(\\varepsilon,\\delta)$-differentially private optimizer is $\\sqrt{\\log(d)/n} + \\sqrt{d}/\\varepsilon n.$ The upper bound is based on a new algorithm that combines the iterative localization approach of~\\citet{FeldmanKoTa20} with a new analysis of private regularized mirror descent. It applies to $\\ell_p$ bounded domains for $p\\in [1,2]$ and queries at most $n^{3/2}$ gradients improving over the best previously known algorithm for the $\\ell_2$ case which needs $n^2$ gradients. Further, we show that when the loss functions satisfy additional smoothness assumptions, the excess loss is upper bounded (up to logarithmic factors) by $\\sqrt{\\log(d)/n} + (\\log(d)/\\varepsilon n)^{2/3}.$ This bound is achieved by a new variance-reduced version of the Frank-Wolfe algorithm that requires just a single pass over the data. We also show that the lower bound in this case is the minimum of the two rates mentioned above."}}
{"id": "yNfIyTKrMvm", "cdate": 1577836800000, "mdate": null, "content": {"title": "Finding Planted Cliques in Sublinear Time", "abstract": "We study the planted clique problem in which a clique of size k is planted in an Erdos-Renyi graph G(n,1/2) and one is interested in recovering this planted clique. It is widely believed that it exhibits a statistical-computational gap when computational efficiency is equated with the existence of polynomial time algorithms. We study this problem under a more fine-grained computational lens and consider the following two questions. 1. Do there exist sublinear time algorithms for recovering the planted clique? 2. What is the smallest running time any algorithm can hope to have? We show that because of a well known clique-completion property, very elementary sublinear time recovery algorithms do indeed exist for clique sizes k = {\\omega}(\\sqrt{n}). This points to a qualitatively stronger statistical-computational gap. The planted clique recovery problem can be solved without even looking at most of the input above the {\\Theta}(\\sqrt{n}) threshold and cannot be solved by any efficient algorithm below it. A running time lower bound for the recovery problem follows easily from the results of [RS19], and this implies our recovery algorithms are optimal whenever k = {\\Omega}(n^{2/3}). However, for k = o(n^{2/3}) there is a gap between our algorithmic upper bound and the information-theoretic lower bound implied by [RS19]. With some caveats, we show stronger detection lower bounds based on the Planted Clique Conjecture for a natural but restricted class of algorithms. The key idea is to relate very fast sublinear time algorithms for detecting large planted cliques to polynomial time algorithms for detecting small planted cliques."}}
{"id": "Hd8PfwR4MBe", "cdate": 1577836800000, "mdate": null, "content": {"title": "Instance-optimality in differential privacy via approximate inverse sensitivity mechanisms", "abstract": "We study and provide instance-optimal algorithms in differential privacy by extending and approximating the inverse sensitivity mechanism. We provide two approximation frameworks, one which only requires knowledge of local sensitivities, and a gradient-based approximation for optimization problems, which are efficiently computable for a broad class of functions. We complement our analysis with instance-specific lower bounds for vector-valued functions, which demonstrate that our mechanisms are (nearly) instance-optimal under certain assumptions and that minimax lower bounds may not provide an accurate estimate of the hardness of a problem in general: our algorithms can significantly outperform minimax bounds for well-behaved instances. Finally, we use our approximation framework to develop private mechanisms for unbounded-range mean estimation, principal component analysis, and linear regression. For PCA, our mechanisms give an efficient (pure) differentially private algorithm with near-optimal rates."}}
{"id": "9df6KqnRpcf", "cdate": 1577836800000, "mdate": null, "content": {"title": "Minibatch Stochastic Approximate Proximal Point Methods", "abstract": "We extend the Approximate-Proximal Point (aProx) family of model-based methods for solving stochastic convex optimization problems, including stochastic subgradient, proximal point, and bundle methods, to the minibatch setting. To do this, we propose two minibatched algorithms for which we prove a non-asymptotic upper bound on the rate of convergence, revealing a linear speedup in minibatch size. In contrast to standard stochastic gradient methods, these methods may have linear speedup in the minibatch setting even for non-smooth functions. Our algorithms maintain the desirable traits characteristic of the aProx family, such as robustness to initial step size choice. Additionally, we show improved convergence rates for \"interpolation\" problems, which (for example) gives a new parallelization strategy for alternating projections. We corroborate our theoretical results with extensive empirical testing, which demonstrates the gains provided by accurate modeling and minibatching."}}
{"id": "3e5guae17Zt", "cdate": 1577836800000, "mdate": null, "content": {"title": "Near Instance-Optimality in Differential Privacy", "abstract": "We develop two notions of instance optimality in differential privacy, inspired by classical statistical theory: one by defining a local minimax risk and the other by considering unbiased mechanisms and analogizing the Cramer-Rao bound, and we show that the local modulus of continuity of the estimand of interest completely determines these quantities. We also develop a complementary collection mechanisms, which we term the inverse sensitivity mechanisms, which are instance optimal (or nearly instance optimal) for a large class of estimands. Moreover, these mechanisms uniformly outperform the smooth sensitivity framework on each instance for several function classes of interest, including real-valued continuous functions. We carefully present two instantiations of the mechanisms for median and robust regression estimation with corresponding experiments."}}
{"id": "zHErQmXBHx0", "cdate": 1546300800000, "mdate": null, "content": {"title": "Element Level Differential Privacy: The Right Granularity of Privacy", "abstract": "Differential Privacy (DP) provides strong guarantees on the risk of compromising a user's data in statistical learning applications, though these strong protections make learning challenging and may be too stringent for some use cases. To address this, we propose element level differential privacy, which extends differential privacy to provide protection against leaking information about any particular \"element\" a user has, allowing better utility and more robust results than classical DP. By carefully choosing these \"elements,\" it is possible to provide privacy protections at a desired granularity. We provide definitions, associated privacy guarantees, and analysis to identify the tradeoffs with the new definition; we also develop several private estimation and learning methodologies, providing careful examples for item frequency and M-estimation (empirical risk minimization) with concomitant privacy and utility analysis. We complement our theoretical and methodological advances with several real-world applications, estimating histograms and fitting several large-scale prediction models, including deep networks."}}
{"id": "Jjd2VjWyp_M", "cdate": 1546300800000, "mdate": null, "content": {"title": "Stochastic (Approximate) Proximal Point Methods: Convergence, Optimality, and Adaptivity", "abstract": "We develop model-based methods for solving stochastic convex optimization problems, introducing the approximate-proximal point, or aProx, family, which includes the stochastic subgradient, proximal point, and bundle methods. When the modeling approaches we propose are appropriately accurate, the methods enjoy stronger convergence and robustness guarantees than classical approaches, even though the model-based methods typically add little to no computational overhead over stochastic subgradient methods. For example, we show that improved models converge with probability 1 and enjoy optimal asymptotic normality results under weak assumptions; these methods are also adaptive to a natural class of what we term easy optimization problems, achieving linear convergence under appropriate strong growth conditions on the objective. Our substantial experimental investigation shows the advantages of more accurate modeling over standard subgradient methods across many smooth and nonsmooth optimization problems."}}
{"id": "FPQLyM_jp2-x", "cdate": 1546300800000, "mdate": null, "content": {"title": "Nearly Optimal Constructions of PIR and Batch Codes", "abstract": "In this paper, we study two families of codes with availability, namely, private information retrieval (FIR) codes and batch codes. While the former requires that every information symbol has k mutually disjoint recovering sets, the latter imposes this property for each multiset request of k information symbols. The main problem under this paradigm is to minimize the number of redundancy symbols. We denote this value by r <sub xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">P</sub> (n, k) and r <sub xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">B</sub> (n, k), for PIR codes and batch codes, respectively, where n is the number of information symbols. Previous results showed that for any constant k, r <sub xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">P</sub> (n, k) = \u0398(\u221an) and r <sub xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">B</sub> (n, k) = O(\u221an log(n)). In this paper, we study the asymptotic behavior of these codes for non-constant k and specifically for k = \u0398(n <sup xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\u2208</sup> ). We also study the largest value of k such that the rate of the codes approaches 1 and show that for all \u03b5 <; 1, r <sub xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">P</sub> (n, n <sup xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\u2208</sup> ) = o(n) and rB(n, n <sup xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\u2208</sup> ) = o(n). Furthermore, several more results are proved for the case of fixed k."}}
