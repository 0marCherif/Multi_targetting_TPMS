{"id": "47tCmTyGtx", "cdate": 1681927721234, "mdate": 1681927721234, "content": {"title": "Timid semi\u2013supervised learning for face expression analysis", "abstract": "In the last years, semi\u2013supervised learning has been proposed as a strategy with high potential for improving machine learning capabilities. Face expression recognition may highly benefit from such a technique, as accurate labeling is both difficult and costly, whereas millions of unlabeled images with human faces are available on the Internet, but without annotations. In this paper we evaluate the benefits of semi\u2013supervised learning in the practical scenarios of face expression analysis. Our conclusion is that better performance is indeed achievable, but by methods that put a distinct emphasis on the diversity of exploring patterns in the unlabeled data domain. The evaluation is carried on multiple tasks such as detecting Action Units on EmotioNet, assessing Action Units intensity on the spontaneous DISFA database and, respectively, recognizing expressions on static images acquired in the wild, from the RAF-DB and FER+ databases. We show that, in these scenarios, a so\u2013called timid semi\u2013supervised learner is more robust and achieves higher performance than standard, confident semi\u2013supervised learners."}}
{"id": "Ud0k1Y3llJ", "cdate": 1681927616742, "mdate": 1681927616742, "content": {"title": "SoftClusterMix: learning soft boundaries for empirical risk minimization", "abstract": "Deep convolutional networks are data hungry learners and, to compensate for the limited amount of available data, various augmentation methods have been proposed. While the initial approaches aimed to fill the space around existing data points, more recent methods use the \u201cmixing\u201d procedure, which is a convex combination between points, being both holistic and local (from a spatial point of view). Although the mixing techniques improved the performance for standard benchmarks, we do notice that they are less effective for problems that exhibit poor class separation. For these scenarios, we propose a soft labeling technique based on distances to class prototypes, as extracted on an intermediate CNN layer. The mixing is performed between relative positions in the clustering space. The method, named SoftClusterMix, is shown to be competitive on standard image classification benchmarks and leads to significantly improved accuracy for problems where there is a poor class separation. We report better performance in three such categories: face expression recognition, aesthetic image classification and painting style classification. Ablation tests allow deep insights of the method."}}
{"id": "3jVv9eS-2jM", "cdate": 1649656568676, "mdate": 1649656568676, "content": {"title": "Margin-Mix: Semi-Supervised Learning for Face Expression Recognition", "abstract": "In this paper, as we aim to construct a semi-supervised learning algorithm, we exploit the characteristics of the Deep Convolutional\nNetworks to provide, for an input image, both an embedding descriptor and a prediction. The unlabeled data is combined with the labeled\none in order to provide synthetic data, which describes better the input space. The network is asked to provide a large margin between clusters, while new data is self-labeled by the distance to class centroids, in the embedding space. The method is tested on standard benchmarks for semi\u2013supervised learning, where it matches state of the art performance and on the problem of face expression recognition where it increases the accuracy by a noticeable margin."}}
{"id": "YlUXaApFSp", "cdate": 1581758035468, "mdate": null, "content": {"title": "Can We Teach Computers to Understand Art? Domain Adaptation forEnhancing Deep Networks Capacity to De-Abstract Art", "abstract": "Humans comprehend a natural scene at a single glance; painters and other visual artists, through their  abstract  representations,  stressed  this  capacity  to  the  limit.   The  performance  of  computer vision solutions matched that of humans in many problems of visual recognition. In this pa-per  we  address  the  problem  of  recognizing  the genre (subject) in digitized paintings using Convolutional Neural Networks (CNN) as part of the more general dealing with abstract and/or artistic representation of scenes.   Initially we establish the state of the art performance by training a CNN from scratch.  In the next level of evaluation, we identify aspects that hinder the CNNs\u2019 recognition, such as artistic abstraction.  Further,we test various domain adaptation methods that could  enhance  the  subject  recognition  capabilities of the CNNs. The evaluation is performed on a  database  of  80,000  annotated  digitized  paintings,  which is tentatively extended with artistic photographs, either original or stylized, in order to emulate artistic representations.  Surprisingly,the  most  efficient  domain  adaptation  is  not  the neural style transfer.  Finally, the paper provides an experiment-based assessment of the abstraction level that CNNs are able to achieve."}}
{"id": "n8mIS70qS", "cdate": 1581757797218, "mdate": null, "content": {"title": "Directed color transfer for low-light image enhancement", "abstract": "Underexposed, low-light, images are acquired when scene illumination is insufficient for a given camera. Camera limitation originates in the high chance of producing motion blurred images due to shaky hands. In this paper we suggest to actively use underexposing as a measure to prevent motion blurred images to appear and propose a novel color transfer as a method for low light image amplification. The proposed solution envisages a dual acquisition, containing a normally exposed, possibly blurred image and an underexposed/low-light, but sharp one. Good colors are learned from the normal exposed image and transferred to the low light one using a framework matching solution. To ensure that the transfer is spatially consistent, the images are divided into luminance perceptual consistent patches called frameworks and the optimal mapping is piece-wise approximated. The two image may differ by colors and subject to improve the robustness of the spatial matching, we added supplementary extreme channels. The proposed method shows robust results from both an objective and a subjective point of view."}}
{"id": "QPMdwBsdVv", "cdate": 1581757660187, "mdate": null, "content": {"title": "Large Margin Loss for Learning FacialMovements from Pseudo-Emotions", "abstract": "In this paper we propose a large margin based loss function that enables information transfer from an unsupervised domain to a supervised one.  The proposed methodology is applied in the context of face expression analysis. Categorical expressions are easier to understand and mutually exclusive, yet annotation is difficult and arguable.  In contrast,facial movements encoded as action units have gained wider acceptance.  Our strategy assumes self labeling images in the wild with pseudo-emotions to better learn action units.  The proposed method is tested in two challenging scenarios with expressions in the wild, showing improved performance with respect to the baseline"}}
{"id": "E6ScYC0kaG", "cdate": 1581757492869, "mdate": null, "content": {"title": "Annealed Label Transfer for Face Expression Recognition", "abstract": "In this paper we propose a method for recognizing facial expressions using information from a pair of domains: one has labelled data and one with unlabelled data.  As the two domains may differ in distribution, we depart from the traditional semi\u2013supervised framework towards a transfer learning approach. In our method, which we call Annealed Label Transfer, the deep learner explores and predicts labels on the unsupervised part,yet, in order to prevent too much confidence in its predictions (as domains are not identical), the global error is regularized with a randomization input via an annealing process.The method\u2019s evaluation is carried out on a set of four scenarios. The first two are standard benchmarks with expression faces in the wild, while the latter two have been little attempted before: face expression recognition in children and the study of the separability of anxiety-originated expressions in the wild. In all cases we show the superiority of the proposed method with respect to the strong baselines"}}
{"id": "SJV8kC-ubH", "cdate": 1451606400000, "mdate": null, "content": {"title": "Avoiding the Deconvolution: Framework Oriented Color Transfer for Enhancing Low-Light Images", "abstract": "In this paper we introduce a novel color transfer method to address the underexposed image amplification problem. Targeted scenario implies a dual acquisition, containing a normally exposed, possibly blurred, image and an underexposed/low-light but sharp one. The problem of enhancing the low-light image is addressed as a color transfer problem. To properly solve the color transfer, the scene is split into perceptual frameworks and we propose a novel piece-wise approximation. The proposed method is shown to lead to robust results from both an objective and a subjective point of view."}}
{"id": "r1-8cFWOZS", "cdate": 1388534400000, "mdate": null, "content": {"title": "Learning Pain from Emotion: Transferred HoT Data Representation for Pain Intensity Estimation", "abstract": "Automatic monitoring for the assessment of pain can significantly improve the psychological comfort of patients. Recently introduced databases with expert annotation opened the way for pain intensity estimation from facial analysis. In this contribution, pivotal face elements are identified using the Histograms of Topographical features (HoT) which are a generalization of the topographical primal sketch. In order to improve the discrimination between different pain intensity values and respectively the generalization with respect to the monitored persons, we transfer data representation from the emotion oriented Cohn-Kanade database to the UNBC McMaster Shoulder Pain database."}}
