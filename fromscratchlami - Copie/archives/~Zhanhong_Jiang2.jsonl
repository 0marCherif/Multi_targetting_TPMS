{"id": "wRo9j1iz2F", "cdate": 1640995200000, "mdate": 1699222438769, "content": {"title": "The Stochastic Augmented Lagrangian method for domain adaptation", "abstract": ""}}
{"id": "FHDDViDL6i", "cdate": 1640995200000, "mdate": 1668484620375, "content": {"title": "MDPGT: Momentum-Based Decentralized Policy Gradient Tracking", "abstract": "We propose a novel policy gradient method for multi-agent reinforcement learning, which leverages two different variance-reduction techniques and does not require large batches over iterations. Specifically, we propose a momentum-based decentralized policy gradient tracking (MDPGT) where a new momentum-based variance reduction technique is used to approximate the local policy gradient surrogate with importance sampling, and an intermediate parameter is adopted to track two consecutive policy gradient surrogates. MDPGT provably achieves the best available sample complexity of O(N -1 e -3) for converging to an e-stationary point of the global average of N local performance functions (possibly nonconcave). This outperforms the state-of-the-art sample complexity in decentralized model-free reinforcement learning and when initialized with a single trajectory, the sample complexity matches those obtained by the existing decentralized policy gradient methods. We further validate the theoretical claim for the Gaussian policy function. When the required error tolerance e is small enough, MDPGT leads to a linear speed up, which has been previously established in decentralized stochastic optimization, but not for reinforcement learning. Lastly, we provide empirical results on a multi-agent reinforcement learning benchmark environment to support our theoretical findings."}}
{"id": "ipYFCbVzVLl", "cdate": 1609459200000, "mdate": null, "content": {"title": "Cross-Gradient Aggregation for Decentralized Learning from Non-IID data", "abstract": "Decentralized learning enables a group of collaborative agents to learn models using a distributed dataset without the need for a central parameter server. Recently, decentralized learning algorithms have demonstrated state-of-the-art results on benchmark data sets, comparable with centralized algorithms. However, the key assumption to achieve competitive performance is that the data is independently and identically distributed (IID) among the agents which, in real-life applications, is often not applicable. Inspired by ideas from continual learning, we propose Cross-Gradient Aggregation (CGA), a novel decentralized learning algorithm where (i) each agent aggregates cross-gradient information, i.e., derivatives of its model with respect to its neighbors' datasets, and (ii) updates its model using a projected gradient based on quadratic programming (QP). We theoretically analyze the convergence characteristics of CGA and demonstrate its efficiency on non-IID data distributions sampled from the MNIST and CIFAR-10 datasets. Our empirical comparisons show superior learning performance of CGA over existing state-of-the-art decentralized learning algorithms, as well as maintaining the improved performance under information compression to reduce peer-to-peer communication overhead. The code is available here on GitHub."}}
{"id": "ZMZeXSF8Hfd", "cdate": 1577836800000, "mdate": null, "content": {"title": "Spatiotemporal Attention for Multivariate Time Series Prediction and Interpretation", "abstract": "Multivariate time series modeling and prediction problems are abundant in many machine learning application domains. Accurate interpretation of such prediction outcomes from a machine learning model that explicitly captures temporal correlations can significantly benefit the domain experts. In this context, temporal attention has been successfully applied to isolate the important time steps for the input time series. However, in multivariate time series problems, spatial interpretation is also critical to understand the contributions of different variables on the model outputs. We propose a novel deep learning architecture, called spatiotemporal attention mechanism (STAM) for simultaneous learning of the most important time steps and variables. STAM is a causal (i.e., only depends on past inputs and does not use future inputs) and scalable (i.e., scales well with an increase in the number of variables) approach that is comparable to the state-of-the-art models in terms of computational tractability. We demonstrate our models' performance on two popular public datasets and a domain-specific dataset. When compared with the baseline models, the results show that STAM maintains state-of-the-art prediction accuracy while offering the benefit of accurate spatiotemporal interpretability. The learned attention weights are validated from a domain knowledge perspective for these real-world datasets."}}
{"id": "KiAb2lofVpa", "cdate": 1577836800000, "mdate": null, "content": {"title": "Decentralized Deep Learning using Momentum-Accelerated Consensus", "abstract": "We consider the problem of decentralized deep learning where multiple agents collaborate to learn from a distributed dataset. While there exist several decentralized deep learning approaches, the majority consider a central parameter-server topology for aggregating the model parameters from the agents. However, such a topology may be inapplicable in networked systems such as ad-hoc mobile networks, field robotics, and power network systems where direct communication with the central parameter server may be inefficient. In this context, we propose and analyze a novel decentralized deep learning algorithm where the agents interact over a fixed communication topology (without a central server). Our algorithm is based on the heavy-ball acceleration method used in gradient-based optimization. We propose a novel consensus protocol where each agent shares with its neighbors its model parameters as well as gradient-momentum values during the optimization process. We consider both strongly convex and non-convex objective functions and theoretically analyze our algorithm's performance. We present several empirical comparisons with competing decentralized learning methods to demonstrate the efficacy of our approach under different communication topologies."}}
{"id": "B1l3hfy6jN", "cdate": 1557095092436, "mdate": null, "content": {"title": "Learning State Switching for Improved Exploration in Multi-sensor Environments", "abstract": "Reinforcement learning has been used to achieve state of the art results in several robotics applications. Despite massive success, issues remain regarding transfer to real world domains and being able to optimize over multi-dimensional control\ninputs as well as across several agents with different perspective views for the same environment, but sharing the same overall goal (multi-agent, multi-sensor robotics). This paper takes a fresh approach towards multi-sensor multi-agent integration for achieving improved performance using a control theoretic approach of \u201cstate-switching\u201d. A formulation based on state switching is adapted as a multi-agent reinforcement learning task in the form of a value iteration algorithm maximizing expected payoffs over time. A reinforcement learning task involving tracking an unknown object with unknown motion dynamics using manipulators is formulated for the well known sawyer one handed manipulator. Thereafter we formulate our state switching algorithm and show superior performance compared to using individual sensors. Our trained agent is then transferred from simulation to a real setup and is shown to perform nicely in the real domain as well."}}
{"id": "BJ4MiUZObH", "cdate": 1514764800000, "mdate": null, "content": {"title": "Online Robust Policy Learning in the Presence of Unknown Adversaries", "abstract": "The growing prospect of deep reinforcement learning (DRL) being used in cyber-physical systems has raised concerns around safety and robustness of autonomous agents. Recent work on generating adversarial attacks have shown that it is computationally feasible for a bad actor to fool a DRL policy into behaving sub optimally. Although certain adversarial attacks with specific attack models have been addressed, most studies are only interested in off-line optimization in the data space (e.g., example fitting, distillation). This paper introduces a Meta-Learned Advantage Hierarchy (MLAH) framework that is attack model-agnostic and more suited to reinforcement learning, via handling the attacks in the decision space (as opposed to data space) and directly mitigating learned bias introduced by the adversary. In MLAH, we learn separate sub-policies (nominal and adversarial) in an online manner, as guided by a supervisory master agent that detects the presence of the adversary by leveraging the advantage function for the sub-policies. We demonstrate that the proposed algorithm enables policy learning with significantly lower bias as compared to the state-of-the-art policy learning approaches even in the presence of heavy state information attacks. We present algorithm analysis and simulation results using popular OpenAI Gym environments."}}
{"id": "rkZkTw-OZr", "cdate": 1483228800000, "mdate": null, "content": {"title": "Collaborative Deep Learning in Fixed Topology Networks", "abstract": "There is significant recent interest to parallelize deep learning algorithms in order to handle the enormous growth in data and model sizes. While most advances focus on model parallelization and engaging multiple computing agents via using a central parameter server, aspect of data parallelization along with decentralized computation has not been explored sufficiently. In this context, this paper presents a new consensus-based distributed SGD (CDSGD) (and its momentum variant, CDMSGD) algorithm for collaborative deep learning over fixed topology networks that enables data parallelization as well as decentralized computation. Such a framework can be extremely useful for learning agents with access to only local/private data in a communication constrained environment. We analyze the convergence properties of the proposed algorithm with strongly convex and nonconvex objective functions with fixed and diminishing step sizes using concepts of Lyapunov function construction. We demonstrate the efficacy of our algorithms in comparison with the baseline centralized SGD and the recently proposed federated averaging algorithm (that also enables data parallelism) based on benchmark datasets such as MNIST, CIFAR-10 and CIFAR-100."}}
