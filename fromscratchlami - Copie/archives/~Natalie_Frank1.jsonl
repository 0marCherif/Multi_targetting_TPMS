{"id": "kpOShBfGbT6", "cdate": 1640995200000, "mdate": 1682544097501, "content": {"title": "Existence and Minimax Theorems for Adversarial Surrogate Risks in Binary Classification", "abstract": "Adversarial training is one of the most popular methods for training methods robust to adversarial attacks, however, it is not well-understood from a theoretical perspective. We prove and existence, regularity, and minimax theorems for adversarial surrogate risks. Our results explain some empirical observations on adversarial robustness from prior work and suggest new directions in algorithm development. Furthermore, our results extend previously known existence and minimax theorems for the adversarial classification risk to surrogate risks."}}
{"id": "BCysKI85q2", "cdate": 1640995200000, "mdate": 1682544097491, "content": {"title": "The Consistency of Adversarial Training for Binary Classification", "abstract": "Robustness to adversarial perturbations is of paramount concern in modern machine learning. One of the state-of-the-art methods for training robust classifiers is adversarial training, which involves minimizing a supremum-based surrogate risk. The statistical consistency of surrogate risks is well understood in the context of standard machine learning, but not in the adversarial setting. In this paper, we characterize which supremum-based surrogates are consistent for distributions absolutely continuous with respect to Lebesgue measure in binary classification. Furthermore, we obtain quantitative bounds relating adversarial surrogate risks to the adversarial classification risk. Lastly, we discuss implications for the $\\cH$-consistency of adversarial training."}}
{"id": "sNw3VBPL7rg", "cdate": 1621630270523, "mdate": null, "content": {"title": "Calibration and Consistency of Adversarial Surrogate Losses", "abstract": "Adversarial robustness is an increasingly critical property of classifiers in applications. The design of robust algorithms relies on surrogate losses since the optimization of the adversarial loss with most hypothesis sets is NP-hard. But, which surrogate losses should be used and when do they benefit from theoretical guarantees? We present an extensive study of this question, including a detailed analysis of the $\\mathcal{H}$-calibration and $\\mathcal{H}$-consistency of adversarial surrogate losses. We show that convex loss functions, or the supremum-based convex losses often used in applications, are not $\\mathcal{H}$-calibrated for common hypothesis sets used in machine learning. We then give a characterization of $\\mathcal{H}$-calibration and prove that some surrogate losses are indeed $\\mathcal{H}$-calibrated for the adversarial zero-one loss, with common hypothesis sets. In particular, we fix some calibration results presented in prior work for a family of linear models and significantly generalize the results to the nonlinear hypothesis sets. Next, we show that $\\mathcal{H}$-calibration is not sufficient to guarantee consistency and prove that, in the absence of any distributional assumption, no continuous surrogate loss is consistent in the adversarial setting. This, in particular, proves that a claim made in prior work is inaccurate. Next, we identify natural conditions under which some surrogate losses that we describe in detail are $\\mathcal{H}$-consistent. We also report a series of empirical results which show that many $\\mathcal{H}$-calibrated surrogate losses are indeed not $\\mathcal{H}$-consistent, and validate our theoretical assumptions. Our adversarial $\\mathcal{H}$-consistency results are novel, even for the case where $\\mathcal{H}$ is the family of all measurable functions."}}
{"id": "iQICgKcrGpE", "cdate": 1621630139826, "mdate": null, "content": {"title": "On the Existence of The Adversarial Bayes Classifier", "abstract": "Adversarial robustness is a critical property in a variety of modern machine learning applications. While it has been the subject of several recent theoretical studies, many important questions related to adversarial robustness are still open.  In this work, we study a fundamental question regarding Bayes optimality for adversarial robustness. We provide general sufficient conditions under which the existence of a Bayes optimal classifier can be guaranteed for adversarial robustness. Our results can provide a useful tool for a subsequent study of surrogate losses in adversarial robustness and their consistency properties."}}
{"id": "sCjqCLR3Gd", "cdate": 1609459200000, "mdate": 1668579913474, "content": {"title": "Calibration and Consistency of Adversarial Surrogate Losses", "abstract": "Adversarial robustness is an increasingly critical property of classifiers in applications. The design of robust algorithms relies on surrogate losses since the optimization of the adversarial loss with most hypothesis sets is NP-hard. But, which surrogate losses should be used and when do they benefit from theoretical guarantees? We present an extensive study of this question, including a detailed analysis of the $\\mathcal{H}$-calibration and $\\mathcal{H}$-consistency of adversarial surrogate losses. We show that convex loss functions, or the supremum-based convex losses often used in applications, are not $\\mathcal{H}$-calibrated for common hypothesis sets used in machine learning. We then give a characterization of $\\mathcal{H}$-calibration and prove that some surrogate losses are indeed $\\mathcal{H}$-calibrated for the adversarial zero-one loss, with common hypothesis sets. In particular, we fix some calibration results presented in prior work for a family of linear models and significantly generalize the results to the nonlinear hypothesis sets. Next, we show that $\\mathcal{H}$-calibration is not sufficient to guarantee consistency and prove that, in the absence of any distributional assumption, no continuous surrogate loss is consistent in the adversarial setting. This, in particular, proves that a claim made in prior work is inaccurate. Next, we identify natural conditions under which some surrogate losses that we describe in detail are $\\mathcal{H}$-consistent. We also report a series of empirical results which show that many $\\mathcal{H}$-calibrated surrogate losses are indeed not $\\mathcal{H}$-consistent, and validate our theoretical assumptions. Our adversarial $\\mathcal{H}$-consistency results are novel, even for the case where $\\mathcal{H}$ is the family of all measurable functions."}}
{"id": "2m09bMao5m", "cdate": 1609459200000, "mdate": 1682544097450, "content": {"title": "On the Existence of the Adversarial Bayes Classifier (Extended Version)", "abstract": "Adversarial robustness is a critical property in a variety of modern machine learning applications. While it has been the subject of several recent theoretical studies, many important questions related to adversarial robustness are still open. In this work, we study a fundamental question regarding Bayes optimality for adversarial robustness. We provide general sufficient conditions under which the existence of a Bayes optimal classifier can be guaranteed for adversarial robustness. Our results can provide a useful tool for a subsequent study of surrogate losses in adversarial robustness and their consistency properties. This manuscript is the extended and corrected version of the paper \\emph{On the Existence of the Adversarial Bayes Classifier} published in NeurIPS 2021. There were two errors in theorem statements in the original paper -- one in the definition of pseudo-certifiable robustness and the other in the measurability of $A^\\e$ for arbitrary metric spaces. In this version we correct the errors. Furthermore, the results of the original paper did not apply to some non-strictly convex norms and here we extend our results to all possible norms."}}
{"id": "ovU3Lno3XEk", "cdate": 1577836800000, "mdate": null, "content": {"title": "Adversarial Learning Guarantees for Linear Hypotheses and Neural Networks", "abstract": "Adversarial or test time robustness measures the susceptibility of a classifier to perturbations to the test input. While there has been a flurry of recent work on designing defenses against such p..."}}
