{"id": "xzutrIq95k", "cdate": 1672531200000, "mdate": 1696023651078, "content": {"title": "Statistical Indistinguishability of Learning Algorithms", "abstract": "When two different parties use the same learning rule on their own data, how can we test whether the distributions of the two outcomes are similar? In this paper, we study the similarity of outcome..."}}
{"id": "kRF_BsGGdc", "cdate": 1672531200000, "mdate": 1696023651067, "content": {"title": "Replicable Bandits", "abstract": ""}}
{"id": "6QuPsGIJjFF", "cdate": 1672531200000, "mdate": 1696023651091, "content": {"title": "Optimal Learners for Realizable Regression: PAC Learning and Online Learning", "abstract": "In this work, we aim to characterize the statistical complexity of realizable regression both in the PAC learning setting and the online learning setting. Previous work had established the sufficiency of finiteness of the fat shattering dimension for PAC learnability and the necessity of finiteness of the scaled Natarajan dimension, but little progress had been made towards a more complete characterization since the work of Simon 1997 (SICOMP '97). To this end, we first introduce a minimax instance optimal learner for realizable regression and propose a novel dimension that both qualitatively and quantitatively characterizes which classes of real-valued predictors are learnable. We then identify a combinatorial dimension related to the Graph dimension that characterizes ERM learnability in the realizable setting. Finally, we establish a necessary condition for learnability based on a combinatorial dimension related to the DS dimension, and conjecture that it may also be sufficient in this context. Additionally, in the context of online learning we provide a dimension that characterizes the minimax instance optimal cumulative loss up to a constant factor and design an optimal online learner for realizable regression, thus resolving an open question raised by Daskalakis and Golowich in STOC '22."}}
{"id": "gcD2UtCGMc2", "cdate": 1663850490209, "mdate": null, "content": {"title": "Replicable Bandits", "abstract": "In this paper, we introduce the notion of replicable policies in the context of stochastic bandits, one of the canonical problems in interactive learning. A policy in the bandit environment is called replicable if it pulls, with high probability, the exact same sequence of arms in two different and independent executions (i.e., under independent reward realizations). We show that not only do replicable policies exist, but also they achieve almost the same optimal (non-replicable) regret bounds in terms of the time horizon. More specifically, in the stochastic multi-armed bandits setting, we develop a policy with an optimal problem-dependent regret bound whose dependence on the replicability parameter is also optimal. Similarly, for stochastic linear bandits (with finitely and infinitely many arms) we develop replicable policies that achieve the best-known problem-independent regret bounds with an optimal dependency on the replicability parameter. Our results show that even though randomization is crucial for the exploration-exploitation trade-off, an optimal balance can still be achieved while pulling the exact same arms in two different rounds of executions. "}}
{"id": "dgWo-UyVEsa", "cdate": 1652737825200, "mdate": null, "content": {"title": "Linear Label Ranking with Bounded Noise", "abstract": "Label Ranking (LR) is the supervised task of learning a sorting function that maps feature vectors $x \\in \\mathbb{R}^d$ to rankings $\\sigma(x) \\in \\mathbb S_k$ over a finite set of $k$ labels. We focus on the fundamental case of learning linear sorting functions (LSFs) under Gaussian marginals: $x$ is sampled from the $d$-dimensional standard normal and  the ground truth ranking $\\sigma^\\star(x)$ is the ordering induced by  sorting the coordinates of the vector $W^\\star x$, where  $W^\\star \\in \\mathbb{R}^{k \\times d}$ is unknown. We consider learning LSFs in the presence of bounded noise: assuming that a noiseless example is of the form $(x, \\sigma^\\star(x))$, we observe $(x, \\pi)$, where for any pair of elements $i \\neq j$, the probability that the order of $i, j$ is different in $\\pi$ than in  $\\sigma^\\star(x)$ is at most $\\eta < 1/2$. We design efficient non-proper and proper learning algorithms that  learn hypotheses within normalized Kendall's Tau distance $\\epsilon$ from the ground truth  with $N= \\widetilde{O}(d\\log(k)/\\epsilon)$ labeled examples and runtime $\\mathrm{poly}(N, k)$. For the more challenging top-$r$ disagreement loss, we give an efficient proper learning algorithm that achieves $\\epsilon$ top-$r$ disagreement with the ground truth with $N = \\widetilde{O}(d k r /\\epsilon)$ samples and $\\mathrm{poly}(N)$ runtime."}}
{"id": "2Bus7sfjZh8", "cdate": 1652737569204, "mdate": null, "content": {"title": "Learning and Covering Sums of Independent Random Variables with Unbounded Support", "abstract": "We study the problem of covering and learning sums $X = X_1 + \\cdots + X_n$ of independent integer-valued random variables $X_i$ (SIIRVs) with infinite support. De et al. at FOCS 2018, showed that even when the collective support of $X_i$'s is of size $4$, the maximum value of the support necessarily appears in the sample complexity of learning $X$. In this work, we address two questions: (i) Are there general families of SIIRVs with infinite support that can be learned with sample complexity independent of both $n$ and the maximal element of the support? (ii) Are there general families of SIIRVs with infinite support that admit proper sparse covers in total variation distance? As for question (i), we provide a set of simple conditions that allow the infinitely supported SIIRV to be learned with complexity $ \\text{poly}(1/\\epsilon)$ bypassing the aforementioned lower bound. We further address question (ii) in the general setting where each variable $X_i$ has unimodal probability mass function and is a different member of some, possibly multi-parameter, exponential family $\\mathcal{E}$ that satisfies some structural properties. These properties allow $\\mathcal{E}$ to contain heavy tailed and non log-concave distributions. Moreover, we show that for every $\\epsilon > 0$, and every $k$-parameter family $\\mathcal{E}$ that satisfies some structural assumptions, there exists an algorithm with $\\widetilde{O}(k) \\cdot  \\text{poly}(1/\\epsilon)$ samples that learns a sum of $n$ arbitrary members of $\\mathcal{E}$ within $\\epsilon$ in TV distance. The output of the learning algorithm is also a sum of random variables within the family $\\mathcal{E}$. En route, we prove that any discrete unimodal exponential family with bounded constant-degree central moments can be approximated by the family corresponding to a bounded subset of the initial (unbounded) parameter space."}}
{"id": "7fdVZR_cl7", "cdate": 1652737564990, "mdate": null, "content": {"title": "Perfect Sampling from Pairwise Comparisons", "abstract": "In this work, we study how to efficiently obtain perfect samples from a discrete distribution $\\mathcal{D}$ given access only to pairwise comparisons of elements of its support. Specifically, we assume access to samples $(x, S)$, where $S$ is drawn from a distribution over sets $\\mathcal{Q}$ (indicating the elements being compared), and $x$ is drawn from the conditional distribution $\\mathcal{D}_S$ (indicating the winner of the comparison) and aim to output a clean sample $y$ distributed according to $\\mathcal{D}$. We mainly focus on the case of pairwise comparisons where all sets $S$ have size 2. We design a Markov chain whose stationary distribution coincides with $\\mathcal{D}$ and give an algorithm to obtain exact samples using the technique of Coupling from the Past. However, the sample complexity of this algorithm depends on the structure of the distribution $\\mathcal{D}$ and can be even exponential in the support of $\\mathcal{D}$ in many natural scenarios. Our main contribution is to provide an efficient exact sampling algorithm whose complexity does not depend on the structure of $\\mathcal{D}$. To this end, we give a parametric Markov chain that mixes significantly faster given a good approximation to the stationary distribution. We can obtain such an approximation using an efficient learning from pairwise comparisons algorithm (Shah et al., JMLR 17, 2016). Our technique for speeding up sampling from a Markov chain whose stationary distribution is approximately known is simple, general and possibly of independent interest."}}
{"id": "-N-OYK2cY7", "cdate": 1652737472747, "mdate": null, "content": {"title": "Multiclass Learnability Beyond the PAC Framework: Universal Rates and Partial Concept Classes", "abstract": "In this paper we study the problem of multiclass classification with a bounded number of different labels $k$, in the realizable setting. We extend the traditional PAC model to a) distribution-dependent learning rates, and b) learning rates under data-dependent assumptions. First, we consider the universal learning setting (Bousquet, Hanneke, Moran, van Handel and Yehudayoff, STOC'21), \nfor which we provide a complete characterization of the achievable learning rates that holds for every fixed distribution. In particular, we show the following trichotomy: for any concept class, the optimal learning rate is either exponential, linear or arbitrarily slow. Additionally, we provide complexity measures of the underlying hypothesis class that characterize when these rates occur. Second, we consider the problem of multiclass classification with structured data (such as data lying on a low dimensional manifold or satisfying margin conditions), a setting which is captured by partial concept classes (Alon, Hanneke, Holzman and Moran, FOCS'21). Partial concepts are functions that can be undefined in certain parts of the input space. We extend the traditional PAC learnability of total concept classes to partial concept classes in the multiclass setting and investigate differences between partial and total concepts."}}
{"id": "ju-ceLl90S", "cdate": 1640995200000, "mdate": 1664346295937, "content": {"title": "Differentially Private Regression with Unbounded Covariates", "abstract": "We provide computationally efficient, differentially private algorithms for the classical regression settings of Least Squares Fitting, Binary Regression and Linear Regression with unbounded covariates. Prior to our work, privacy constraints in such regression settings were studied under strong a priori bounds on covariates. We consider the case of Gaussian marginals and extend recent differentially private techniques on mean and covariance estimation (Kamath et al., 2019; Karwa and Vadhan, 2018) to the sub-gaussian regime. We provide a novel technical analysis yielding differentially private algorithms for the above classical regression settings. Through the case of Binary Regression, we capture the fundamental and widely-studied models of logistic regression and linearly-separable SVMs, learning an unbiased estimate of the true regression vector, up to a scaling factor."}}
{"id": "Yl1wHlO9Ed", "cdate": 1640995200000, "mdate": 1683712379093, "content": {"title": "Linear Label Ranking with Bounded Noise", "abstract": "Label Ranking (LR) is the supervised task of learning a sorting function that maps feature vectors $x \\in \\mathbb{R}^d$ to rankings $\\sigma(x) \\in \\mathbb S_k$ over a finite set of $k$ labels. We focus on the fundamental case of learning linear sorting functions (LSFs) under Gaussian marginals: $x$ is sampled from the $d$-dimensional standard normal and the ground truth ranking $\\sigma^\\star(x)$ is the ordering induced by sorting the coordinates of the vector $W^\\star x$, where $W^\\star \\in \\mathbb{R}^{k \\times d}$ is unknown. We consider learning LSFs in the presence of bounded noise: assuming that a noiseless example is of the form $(x, \\sigma^\\star(x))$, we observe $(x, \\pi)$, where for any pair of elements $i \\neq j$, the probability that the order of $i, j$ is different in $\\pi$ than in $\\sigma^\\star(x)$ is at most $\\eta &lt; 1/2$. We design efficient non-proper and proper learning algorithms that learn hypotheses within normalized Kendall's Tau distance $\\epsilon$ from the ground truth with $N= \\widetilde{O}(d\\log(k)/\\epsilon)$ labeled examples and runtime $\\mathrm{poly}(N, k)$. For the more challenging top-$r$ disagreement loss, we give an efficient proper learning algorithm that achieves $\\epsilon$ top-$r$ disagreement with the ground truth with $N = \\widetilde{O}(d k r /\\epsilon)$ samples and $\\mathrm{poly}(N)$ runtime."}}
