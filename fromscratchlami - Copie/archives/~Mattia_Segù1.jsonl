{"id": "IyBlj_JCtwQ", "cdate": 1684250514641, "mdate": 1684250514641, "content": {"title": "SHIFT: A Synthetic Driving Dataset for Continuous Multi-Task Domain Adaptation", "abstract": "Adapting to a continuously evolving environment is a\nsafety-critical challenge inevitably faced by all autonomous\ndriving systems. Existing image and video driving datasets,\nhowever, fall short of capturing the mutable nature of the\nreal world. In this paper, we introduce the largest multitask synthetic dataset for autonomous driving, SHIFT. It\npresents discrete and continuous shifts in cloudiness, rain\nand fog intensity, time of day, and vehicle and pedestrian\ndensity. Featuring a comprehensive sensor suite and annotations for several mainstream perception tasks, SHIFT\nallows investigating the degradation of a perception system performance at increasing levels of domain shift, fostering the development of continuous adaptation strategies\nto mitigate this problem and assess model robustness and\ngenerality. Our dataset and benchmark toolkit are publicly\navailable at www.vis.xyz/shift."}}
{"id": "uD60APmckTW", "cdate": 1672531200000, "mdate": 1698657217429, "content": {"title": "COOLer: Class-Incremental Learning for Appearance-Based Multiple Object Tracking", "abstract": "Continual learning allows a model to learn multiple tasks sequentially while retaining the old knowledge without the training data of the preceding tasks. This paper extends the scope of continual learning research to class-incremental learning for multiple object tracking (MOT), which is desirable to accommodate the continuously evolving needs of autonomous systems. Previous solutions for continual learning of object detectors do not address the data association stage of appearance-based trackers, leading to catastrophic forgetting of previous classes' re-identification features. We introduce COOLer, a COntrastive- and cOntinual-Learning-based tracker, which incrementally learns to track new categories while preserving past knowledge by training on a combination of currently available ground truth labels and pseudo-labels generated by the past tracker. To further exacerbate the disentanglement of instance representations, we introduce a novel contrastive class-incremental instance representation learning technique. Finally, we propose a practical evaluation protocol for continual learning for MOT and conduct experiments on the BDD100K and SHIFT datasets. Experimental results demonstrate that COOLer continually learns while effectively addressing catastrophic forgetting of both tracking and detection. The code is available at https://github.com/BoSmallEar/COOLer."}}
{"id": "jJk6_H2-t5T", "cdate": 1672531200000, "mdate": 1698657217405, "content": {"title": "DARTH: Holistic Test-time Adaptation for Multiple Object Tracking", "abstract": "Multiple object tracking (MOT) is a fundamental component of perception systems for autonomous driving, and its robustness to unseen conditions is a requirement to avoid life-critical failures. Despite the urge of safety in driving systems, no solution to the MOT adaptation problem to domain shift in test-time conditions has ever been proposed. However, the nature of a MOT system is manifold - requiring object detection and instance association - and adapting all its components is non-trivial. In this paper, we analyze the effect of domain shift on appearance-based trackers, and introduce DARTH, a holistic test-time adaptation framework for MOT. We propose a detection consistency formulation to adapt object detection in a self-supervised fashion, while adapting the instance appearance representations via our novel patch contrastive loss. We evaluate our method on a variety of domain shifts - including sim-to-real, outdoor-to-indoor, indoor-to-outdoor - and substantially improve the source model performance on all metrics. Code: https://github.com/mattiasegu/darth."}}
{"id": "fNnR85y-4Zh", "cdate": 1672531200000, "mdate": 1681716785919, "content": {"title": "Batch normalization embeddings for deep domain generalization", "abstract": ""}}
{"id": "XDsJBMUocl", "cdate": 1672531200000, "mdate": 1698657217421, "content": {"title": "Towards Robust Object Detection Invariant to Real-World Domain Shifts", "abstract": ""}}
{"id": "MosSgoAdSmQ", "cdate": 1668678400597, "mdate": 1668678400597, "content": {"title": "SHIFT: A Synthetic Driving Dataset for Continuous Multi-Task Domain Adaptation", "abstract": "Adapting to a continuously evolving environment is a safety-critical challenge inevitably faced by all autonomous-driving systems. Existing image- and video-based driving datasets, however, fall short of capturing the mutable nature of the real world. In this paper, we introduce the largest multi-task synthetic dataset for autonomous driving, SHIFT. It presents discrete and continuous shifts in cloudiness, rain and fog intensity, time of day, and vehicle and pedestrian density. Featuring a comprehensive sensor suite and annotations for several mainstream perception tasks, SHIFT allows to investigate how a perception systems' performance degrades at increasing levels of domain shift, fostering the development of continuous adaptation strategies to mitigate this problem and assessing the robustness and generality of a model. Our dataset and benchmark toolkit are publicly available at www.vis.xyz/shift."}}
{"id": "vqSyt8D3ny", "cdate": 1663849932016, "mdate": null, "content": {"title": "Towards Robust Object Detection Invariant to Real-World Domain Shifts", "abstract": "Safety-critical applications such as autonomous driving require robust object detection invariant to real-world domain shifts. Such shifts can be regarded as different domain styles, which can vary substantially due to environment changes and sensor noises, but deep models only know the training domain style. Such domain style gap impedes object detection generalization on diverse real-world domains. Existing classification domain generalization (DG) methods cannot effectively solve the robust object detection problem, because they either rely on multiple source domains with large style variance or destroy the content structures of the original images. In this paper, we analyze and investigate effective solutions to overcome domain style overfitting for robust object detection without the above shortcomings. Our method, dubbed as Normalization Perturbation (NP), perturbs the channel statistics of source domain low-level features to synthesize various latent styles, so that the trained deep model can perceive diverse potential domains and generalizes well even without observations of target domain data in training. This approach is motivated by the observation that feature channel statistics of the target domain images deviate around the source domain statistics. We further explore the style-sensitive channels for effective style synthesis. Normalization Perturbation only relies on a single source domain and is surprisingly simple and effective, contributing a practical solution by effectively adapting or generalizing classification DG methods to robust object detection. Extensive experiments demonstrate the effectiveness of our method for generalizing object detectors under real-world domain shifts."}}
{"id": "n-CCeQoPk9N", "cdate": 1640995200000, "mdate": 1667407410228, "content": {"title": "Generative Cooperative Learning for Unsupervised Video Anomaly Detection", "abstract": "Video anomaly detection is well investigated in weakly-supervised and one-class classification (OCC) settings. However, unsupervised video anomaly detection methods are quite sparse, likely because anomalies are less frequent in occurrence and usually not well-defined, which when coupled with the absence of ground truth supervision, could adversely affect the performance of the learning algorithms. This problem is challenging yet rewarding as it can completely eradicate the costs of obtaining laborious annotations and enable such systems to be deployed without human intervention. To this end, we propose a novel unsupervised Generative Cooperative Learning (GCL) approach for video anomaly detection that exploits the low frequency of anomalies towards building a cross-supervision between a generator and a discriminator. In essence, both networks get trained in a cooperative fashion, thereby allowing unsupervised learning. We conduct extensive experiments on two large-scale video anomaly detection datasets, UCF crime and ShanghaiTech. Consistent improvement over the existing state-of-the-art unsupervised and OCC methods corroborate the effectiveness of our approach."}}
{"id": "YzwO_DCiXKh", "cdate": 1640995200000, "mdate": 1667407410287, "content": {"title": "SHIFT: A Synthetic Driving Dataset for Continuous Multi-Task Domain Adaptation", "abstract": "Adapting to a continuously evolving environment is a safety-critical challenge inevitably faced by all autonomous-driving systems. Existing image- and video-based driving datasets, however, fall short of capturing the mutable nature of the real world. In this paper, we introduce the largest multi-task synthetic dataset for autonomous driving, SHIFT. It presents discrete and continuous shifts in cloudiness, rain and fog intensity, time of day, and vehicle and pedestrian density. Featuring a comprehensive sensor suite and annotations for several mainstream perception tasks, SHIFT allows to investigate how a perception systems' performance degrades at increasing levels of domain shift, fostering the development of continuous adaptation strategies to mitigate this problem and assessing the robustness and generality of a model. Our dataset and benchmark toolkit are publicly available at www.vis.xyz/shift."}}
{"id": "VbvX18yePRK", "cdate": 1640995200000, "mdate": 1667407410232, "content": {"title": "SHIFT: A Synthetic Driving Dataset for Continuous Multi-Task Domain Adaptation", "abstract": "Adapting to a continuously evolving environment is a safety-critical challenge inevitably faced by all autonomous-driving systems. Existing image- and video-based driving datasets, however, fall short of capturing the mutable nature of the real world. In this paper, we introduce the largest multi-task synthetic dataset for autonomous driving, SHIFT. It presents discrete and continuous shifts in cloudiness, rain and fog intensity, time of day, and vehicle and pedestrian density. Featuring a comprehensive sensor suite and annotations for several mainstream perception tasks, SHIFT allows to investigate how a perception systems' performance degrades at increasing levels of domain shift, fostering the development of continuous adaptation strategies to mitigate this problem and assessing the robustness and generality of a model. Our dataset and benchmark toolkit are publicly available at www.vis.xyz/shift."}}
