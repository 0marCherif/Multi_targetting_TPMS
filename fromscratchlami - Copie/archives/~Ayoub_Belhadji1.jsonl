{"id": "0XFnF2oZhU", "cdate": 1680619802804, "mdate": 1680619802804, "content": {"title": "Revisiting RIP guarantees for sketching operators on mixture models", "abstract": "In the context of sketching for compressive mixture modeling, we revisit existing proofs of the Restricted Isometry Property of sketching operators with respect to certain mixtures models. After examining the shortcomings of existing guarantees, we propose an alternative analysis that circumvents the need to assume importance sampling when drawing random Fourier features to build random sketching operators. Our analysis is based on new deterministic bounds on the restricted isometry constant that depend solely on the set of\nfrequencies used to define the sketching operator; then we leverage these bounds to establish concentration inequalities for random sketching operators that lead to the desired RIP guarantees. Our analysis also opens the door to theoretical guarantees for structured sketching with frequencies associated to fast random linear operators."}}
{"id": "Eec8D4UNceq", "cdate": 1621629977059, "mdate": null, "content": {"title": "An analysis of Ermakov-Zolotukhin quadrature using kernels", "abstract": "We study a quadrature, proposed by Ermakov and Zolotukhin in the sixties, through the lens of kernel methods. The nodes of this quadrature rule follow the distribution of a determinantal point process, while the weights are defined through a linear system, similarly to the optimal kernel quadrature. In this work, we show how these two classes of quadrature are related, and we prove a tractable formula of the expected value of the squared worst-case integration error on the unit ball of an RKHS of the former quadrature. In particular, this formula involves the eigenvalues of the corresponding kernel and leads to improving on the existing theoretical guarantees of the optimal kernel quadrature with determinantal point processes. \n"}}
{"id": "IxYnfifh4C1", "cdate": 1620833466054, "mdate": null, "content": {"title": "Kernel quadrature with DPPs", "abstract": "We study quadrature rules for functions from an RKHS, using nodes sampled from a determinantal point process (DPP). DPPs are parametrized by a kernel, and we use a truncated and saturated version of the RKHS kernel. This link between the two kernels, along with DPP machinery, leads to relatively tight bounds on the quadrature error, that depends on the spectrum of the RKHS kernel. Finally, we experimentally compare DPPs to existing kernel-based quadratures such as herding, Bayesian quadrature, or leverage score sampling. Numerical results confirm the interest of DPPs, and even suggest faster rates than our bounds in particular cases. "}}
{"id": "dSZ0hKVZpm", "cdate": 1620532088407, "mdate": null, "content": {"title": "A determinantal point process for column subset selection", "abstract": "Two popular approaches to dimensionality reduction are principal component analysis, which projects onto a small number of well-chosen but non-interpretable directions, and feature selection, which selects a small number of the original features. Feature selection can be abstracted as selecting the subset of columns of a matrix X which minimize the approximation error, i.e., the norm of the residual after projecting X onto the space spanned by the selected columns. Such a combinatorial optimization is usually impractical, and there has been interest in polynomial-cost, random subset selection algorithms that favour small values of this approximation error. We propose sampling from a projection determinantal point process, a repulsive distribution over column indices that favours diversity among the selected columns. We bound the ratio of the expected approximation error over the optimal error of PCA. These bounds improve over the state-of-the-art bounds of volume sampling when some realistic structural assumptions are satisfied for X. Numerical experiments suggest that our bounds are tight, and that our algorithms have comparable performance with the double phase algorithm, often considered the practical state-of-the-art."}}
{"id": "TAlxI_h_frO", "cdate": 1620531949816, "mdate": null, "content": {"title": "Kernel interpolation with continuous volume sampling", "abstract": "A fundamental task in kernel methods is to pick\nnodes and weights, so as to approximate a given\nfunction from an RKHS by the weighted sum of\nkernel translates located at the nodes. This is the\ncrux of kernel quadrature or kernel interpolation\nfrom discrete samples. Furthermore, RKHSs offer a convenient mathematical and computational\nframework, connecting the discrete and continuous worlds. We introduce and analyse continuous\nvolume sampling (VS), the continuous counterpart \u2013 for choosing node locations \u2013 of a discrete\ndistribution introduced in (Deshpande & Vempala, 2006). Our contribution is theoretical: we\nprove almost optimal bounds for interpolation and\nquadrature under VS. While similar bounds already exist for some specific RKHSs using ad-hoc\nnode constructions, VS offers bounds that apply\nto any Mercer kernel and depend only on the spectrum of the associated integration operator. We\nemphasize that, unlike previous randomized approaches that rely on regularized leverage scores\nor determinantal point processes, evaluating the\npdf of VS only requires pointwise evaluations\nof the kernel. VS is thus naturally amenable to\nMCMC samplers."}}
{"id": "HyzT5BSlUH", "cdate": 1567802773403, "mdate": null, "content": {"title": "Kernel quadrature with DPPs", "abstract": "We study quadrature rules for functions living in an RKHS, using nodes sampled from a projection determinantal point process (DPP). DPPs are parametrized by a kernel, and we use a truncated and saturated version of the RKHS kernel. This natural link between the two kernels, along with DPP machinery, leads to relatively tight bounds on the quadrature error, that depend on the spectrum of the RKHS kernel. Finally, we experimentally compare DPPs to existing kernel-based quadratures such as herding, Bayesian quadrature, or continuous leverage score sampling. Numerical results confirm the interest of DPPs, and even suggest faster rates than our bounds in particular cases."}}
