{"id": "XHIY3cQ8Tew", "cdate": 1681425420920, "mdate": null, "content": {"title": "AutoGluon\u2013TimeSeries: AutoML for Probabilistic Time Series Forecasting", "abstract": "We introduce AutoGluon\u2013TimeSeries\u2014an open-source AutoML library for probabilistic time series forecasting. Focused on ease of use and robustness, AutoGluon\u2013TimeSeries enables users to generate accurate point and quantile forecasts with just 3 lines of Python code. Built on the design philosophy of AutoGluon, AutoGluon\u2013TimeSeries leverages ensembles of diverse forecasting models to deliver high accuracy within a short training time. AutoGluon\u2013TimeSeries combines both conventional statistical models, machine-learning based forecasting approaches, and ensembling techniques. In our evaluation on 29 benchmark datasets, AutoGluon\u2013TimeSeries demonstrates strong empirical performance, outperforming a range of forecasting methods in terms of both point and quantile forecast accuracy, and often even improving upon the best-in-hindsight combination of prior methods."}}
{"id": "0-fm1yFVyE9", "cdate": 1664300342880, "mdate": null, "content": {"title": "Quantifying Causal Contribution in Rare Event Data", "abstract": "We introduce a framework for causal discovery and attribution of causal influence for rare events in time series data--where the interest is in identifying causal links and root causes of individual discrete events rather than the types of these events. Specifically, we build on the theory of temporal point processes, and describe a discrete-time analogue of Hawkes processes to model the occurrence of self-exciting rare events with instantaneous effects. We then introduce several scores to measure causal influence among individual events. These statistics are drawn from causal inference and temporal point process theories, describe complementary aspects of causality in temporal event data, and obey commonly used axioms for feature attribution. We demonstrate the efficacy of our model and the proposed influence scores on real and synthetic data.\n"}}
{"id": "MTMyxzrIKsM", "cdate": 1621629683432, "mdate": null, "content": {"title": "Detecting Anomalous Event Sequences with Temporal Point Processes", "abstract": "Automatically detecting anomalies in event data can provide substantial value in domains such as healthcare, DevOps, and information security. In this paper, we frame the problem of detecting anomalous continuous-time event sequences as out-of-distribution (OOD) detection for temporal point processes (TPPs). First, we show how this problem can be approached using goodness-of-fit (GoF) tests. We then demonstrate the limitations of popular GoF statistics for TPPs and propose a new test that addresses these shortcomings. The proposed method can be combined with various TPP models, such as neural TPPs, and is easy to implement. In our experiments, we show that the proposed statistic excels at both traditional GoF testing, as well as at detecting anomalies in simulated and real-world data. "}}
{"id": "Qzwf9GeTFUX", "cdate": 1609459200000, "mdate": null, "content": {"title": "Neural Temporal Point Processes: A Review", "abstract": "Temporal point processes (TPP) are probabilistic generative models for continuous-time event sequences. Neural TPPs combine the fundamental ideas from point process literature with deep learning approaches, thus enabling construction of flexible and efficient models. The topic of neural TPPs has attracted significant attention in the recent years, leading to the development of numerous new architectures and applications for this class of models. In this review paper we aim to consolidate the existing body of knowledge on neural TPPs. Specifically, we focus on important design choices and general principles for defining neural TPP models. Next, we provide an overview of application areas commonly considered in the literature. We conclude this survey with the list of open challenges and important directions for future work in the field of neural TPPs."}}
{"id": "V1UPP2xwe0I", "cdate": 1577836800000, "mdate": null, "content": {"title": "Fast and Flexible Temporal Point Processes with Triangular Maps", "abstract": "Temporal point process (TPP) models combined with recurrent neural networks provide a powerful framework for modeling continuous-time event data. While such models are flexible, they are inherently sequential and therefore cannot benefit from the parallelism of modern hardware. By exploiting the recent developments in the field of normalizing flows, we design TriTPP - a new class of non-recurrent TPP models, where both sampling and likelihood computation can be done in parallel. TriTPP matches the flexibility of RNN-based methods but permits several orders of magnitude faster sampling. This enables us to use the new model for variational inference in continuous-time discrete-state systems. We demonstrate the advantages of the proposed framework on synthetic and real-world datasets."}}
{"id": "HygOjhEYDH", "cdate": 1569438880235, "mdate": null, "content": {"title": "Intensity-Free Learning of Temporal Point Processes", "abstract": "Temporal point processes are the dominant paradigm for modeling sequences of events happening at irregular intervals. The standard way of learning in such models is by estimating the conditional intensity function.  However, parameterizing the intensity function usually incurs several trade-offs. We show how to overcome the limitations of intensity-based approaches by directly modeling the conditional distribution of inter-event times.  We draw on the literature on normalizing flows to design models that are flexible and efficient. We additionally propose a simple mixture model that matches the flexibility of flow-based models, but also permits sampling and computing moments in closed form.  The proposed models achieve state-of-the-art performance in standard prediction tasks and are suitable for novel applications, such as learning sequence embeddings and imputing missing data."}}
{"id": "HklQxnC5tX", "cdate": 1538087915114, "mdate": null, "content": {"title": "Overlapping Community Detection with Graph Neural Networks", "abstract": "Community detection in graphs is of central importance in graph mining, machine learning and network science.  Detecting overlapping communities is especially challenging, and remains an open problem.  Motivated by the success of graph-based  deep  learning  in  other  graph-related  tasks,  we  study  the  applicability  of this framework for overlapping community detection. We propose a probabilistic model for overlapping community detection based on the graph neural network architecture.  Despite its simplicity, our model outperforms the existing approaches in the community recovery task by a large margin.  Moreover, due to the inductive formulation, the proposed model is able to perform out-of-sample community detection for nodes that were not present at training time"}}
{"id": "H15RufWAW", "cdate": 1518730162116, "mdate": null, "content": {"title": "GraphGAN: Generating Graphs via Random Walks", "abstract": "We propose GraphGAN - the first implicit generative model for graphs that enables to mimic real-world networks.\nWe pose the problem of graph generation as learning the distribution of biased random walks over a single input graph.\nOur model is based on a stochastic neural network that generates discrete output samples, and is trained using the Wasserstein GAN objective. GraphGAN enables us to generate sibling graphs, which have similar properties yet are not exact replicas of the original graph. Moreover, GraphGAN learns a semantic mapping from the latent input space to the generated graph's properties. We discover that sampling from certain regions of the latent space leads to varying properties of the output graphs, with smooth transitions between them. Strong generalization properties of GraphGAN are highlighted by its competitive performance in link prediction as well as promising results on node classification, even though not specifically trained for these tasks."}}
