{"id": "9dCdYg5gfa7", "cdate": 1685642151399, "mdate": 1685642151399, "content": {"title": "Approximate Causal Effect Identification under Weak Confounding", "abstract": "Causal effect estimation has been studied by many researchers when only observational data is available. Sound and complete algorithms have been developed for pointwise estimation of identifiable causal queries. For non-identifiable causal queries, researchers developed polynomial programs to estimate tight bounds on causal effect. However, these are computationally difficult to optimize for variables with large support sizes. In this paper, we analyze the effect of \u201cweak confounding\u201d on causal estimands. More specifically, under the assumption that the unobserved confounders that render a query non-identifiable have small entropy, we propose an efficient linear program to derive the upper and lower bounds of the causal effect. We show that our bounds are consistent in the sense that as the entropy of unobserved confounders goes to zero, the gap between the upper and lower bound vanishes. Finally, we conduct synthetic and real data simulations to compare our bounds with the bounds obtained\nby the existing work that cannot incorporate such entropy constraints and show that our bounds are\ntighter for the setting with weak confounders."}}
{"id": "LTQuwn0q0Hk", "cdate": 1672531200000, "mdate": 1695952296856, "content": {"title": "Approximate Causal Effect Identification under Weak Confounding", "abstract": "Causal effect estimation has been studied by many researchers when only observational data is available. Sound and complete algorithms have been developed for pointwise estimation of identifiable causal queries. For non-identifiable causal queries, researchers developed polynomial programs to estimate tight bounds on causal effect. However, these are computationally difficult to optimize for variables with large support sizes. In this paper, we analyze the effect of \"weak confounding\" on causal estimands. More specifically, under the assumption that the unobserved confounders that render a query non-identifiable have small entropy, we propose an efficient linear program to derive the upper and lower bounds of the causal effect. We show that our bounds are consistent in the sense that as the entropy of unobserved confounders goes to zero, the gap between the upper and lower bound vanishes. Finally, we conduct synthetic and real data simulations to compare our bounds with the bounds obtained by the existing work that cannot incorporate such entropy constraints and show that our bounds are tighter for the setting with weak confounders."}}
{"id": "-CPfqgc80O", "cdate": 1672531200000, "mdate": 1695952296855, "content": {"title": "Approximate Causal Effect Identification under Weak Confounding", "abstract": "Causal effect estimation has been studied by many researchers when only observational data is available. Sound and complete algorithms have been developed for pointwise estimation of identifiable c..."}}
