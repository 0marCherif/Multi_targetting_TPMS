{"id": "df3n4ddLg2E", "cdate": 1708044296516, "mdate": 1708044296516, "content": {"title": "The Flan Collection: Designing Data and Methods for Effective Instruction Tuning", "abstract": "We study the design decision of publicly available instruction tuning methods, by reproducing and breaking down the development of Flan 2022 (Chung et al., 2022). Through careful ablation studies on the Flan Collection of tasks and methods, we tease apart the effect of design decisions which enable Flan-T5 to outperform prior work by 3-17% across evaluation settings. We find task balancing and enrichment techniques are overlooked but critical to effective instruction tuning, and in particular, training with mixed prompt settings (zero-shot, few-shot, chain-of-thought) actually yields equivalent or stronger (2%) performance in all settings. In further experiments we show Flan-T5 requires less finetuning to converge higher and faster than T5 on single downstream tasks \u2013 motivating instruction-tuned models as more computationally-efficient starting checkpoints for new tasks. Finally, to accelerate research on instruction tuning, we make the Flan 2022 collection of datasets, templates, and methods publicly available."}}
{"id": "6uLhmE6tvCn", "cdate": 1708044083519, "mdate": 1708044083519, "content": {"title": "Mixture-of-experts meets instruction tuning: A winning combination for large language models", "abstract": "Sparse Mixture-of-Experts (MoE) is a neural architecture design that can be utilized to add learnable parameters to Large Language Models (LLMs) without increasing inference cost. Instruction tuning is a technique for training LLMs to follow instructions. We advocate combining these two approaches, as we find that MoE models benefit more from instruction tuning than dense models. In particular, we conduct empirical studies across three experimental setups: (i) Direct finetuning on individual downstream tasks devoid of instruction tuning; (ii) Instructiontuning followed by in-context few-shot or zero-shot generalization on downstream tasks; and (iii) Instruction tuning supplemented by further finetuning on individual downstream tasks. In the first scenario, MoE models overall underperform dense models of identical computational capacity. This narrative, however, dramatically changes with the introduction of instruction tuning (second and third scenario), used independently or in conjunction with task-specific finetuning. Our most powerful model, FLAN-MOE-32B, surpasses the performance of FLAN-PALM-62B on four benchmark tasks, while using only a third of the FLOPs. The advancements embodied byFLAN-MOE inspire a reevaluation of the design principles of large-scale, high-performance language models in the framework of task-agnostic learning."}}
{"id": "9yTSJIb5t_Z", "cdate": 1673287850377, "mdate": null, "content": {"title": "Few Shot Hematopoietic Cell Classification", "abstract": "We propose a few shot learning approach for the problem of hematopoietic cell classification in digital pathology. In hematopoiesis cell classification, the classes correspond to the different stages of the cellular maturation process. Two  consecutive stage categories are considered to have a neighborhood relationship, which implies a visual similarity between the two categories. We propose RelationVAE which incorporates these relationships between hematopoietic cell classes to robustly generate more data for the classes with limited training data. Specifically, we first model these relationships using a graphical model, and propose RelationVAE, a deep generative model which implements the graphical model. RelationVAE is trained to optimize the lower bound of the pairwise data likelihood of the graphical model. In this way, it can identify class level features of a specific class from a small number of input images together with the knowledge transferred from visually similar classes, leading to more robust sample synthesis. The experiments on our collected hematopoietic dataset show the improved results of our proposed RelationVAE over a baseline VAE model and other few shot learning methods. Our code and data are available at https://github.com/cvlab-stonybrook/hematopoiesis-relationvae."}}
{"id": "maHH3u4W5U3", "cdate": 1668786888936, "mdate": 1668786888936, "content": {"title": "Large scale shadow annotation and detection using lazy annotation and stacked CNNs", "abstract": "Recent shadow detection algorithms have shown initial success on small datasets of images from specific domains. However, shadow detection on broader image domains is still challenging due to the lack of annotated training data, caused by the intense manual labor required for annotating shadow data. In this paper we propose \u201clazy annotation\u201d, an efficient annotation method where an annotator only needs to mark the important shadow areas and some non-shadow areas. This yields data with noisy labels that are not yet useful for training a shadow detector. We address the problem of label noise by jointly learning a shadow region classifier and recovering the labels in the training set. We consider the training labels as unknowns and formulate label recovery as the minimization of the sum of squared leave-one-out errors of a Least Squares SVM, which can be efficiently optimized. Experimental results show"}}
{"id": "26Lueg8F7bi", "cdate": 1668786764492, "mdate": 1668786764492, "content": {"title": "Large-scale training of shadow detectors with noisily-annotated shadow examples", "abstract": "This paper introduces training of shadow detectors under the\nlarge-scale dataset paradigm. This was previously impossible due to the\nhigh cost of precise shadow annotation. Instead, we advocate the use of\nquickly but imperfectly labeled images. Our novel label recovery method\nautomatically corrects a portion of the erroneous annotations such that\nthe trained classifiers perform at state-of-the-art level. We apply our\nmethod to improve the accuracy of the labels of a new dataset that is\n20 times larger than existing datasets and contains a large variety of\nscenes and image types. Naturally, such a large dataset is appropriate\nfor training deep learning methods. Thus, we propose a semantic-aware\npatch level Convolutional Neural Network architecture that efficiently\ntrains on patch level shadow examples while incorporating image level\nsemantic information. This means that the detected shadow patches are\nrefined based on image semantics. Our proposed pipeline can be a useful\nbaseline for future advances in shadow detection."}}
{"id": "kPPVmUF6bM_", "cdate": 1663850382908, "mdate": null, "content": {"title": "Augmentation with Projection: Towards an Effective and Efficient Data Augmentation Paradigm for Distillation", "abstract": "Knowledge distillation is one of the primary methods of transferring knowledge from large to small models. However, it requires massive task-specific data, which may not be plausible in many real-world applications. Data augmentation methods such as representation interpolation, token replacement, or augmentation with models are applied to tackle this problem. However, these data augmentation methods either potentially cause shifts in decision boundaries (representation interpolation), are not expressive enough (token replacement), or introduce too much computational overhead (augmentation with models). To this end, we propose AugPro (Augmentation with Projection), an effective and efficient data augmentation method for distillation. Our method builds on top of representation interpolation augmentation methods to maintain the diversity of expressions and converts the augmented data to tokens to avoid shifting decision boundaries. It uses simple operations that come with little computational overhead. The results on multiple GLUE tasks show that our methods can improve distillation performance by a large margin at a low time cost."}}
{"id": "NiEtU7blzN", "cdate": 1663850228197, "mdate": null, "content": {"title": "Large Language Models Can Self-improve", "abstract": "Large Language Models (LLMs) have achieved excellent performances in various tasks. However, fine-tuning an LLM requires extensive supervision. Human, on the other hand, may improve their reasoning abilities by self-thinking without external inputs. In this work, we demonstrate that an LLM is also capable of self-improving with only unlabeled datasets. We use a pre-trained LLM to generate \u201chigh-confidence\u201d rationale-augmented answers for unlabeled questions using Chain-of-Thought prompting and self-consistency, and fine-tune the LLM using those self-generated solutions as target outputs. We show that our approach improves the general reasoning ability of a 540B-parameter LLM (74.4%\u219282.1% on GSM8K, 78.2%\u219283.0% on DROP, 90.0%\u219294.4% on OpenBookQA, and 63.4%\u219267.9% on ANLI-A3) and achieves state-of-the-art-level performance, without any ground truth label. We conduct ablation studies and show that finetuning on reasoning is critical for self-improvement."}}
{"id": "WZH7099tgfM", "cdate": 1663849902050, "mdate": null, "content": {"title": "Least-to-Most Prompting Enables Complex Reasoning in Large Language Models", "abstract": "Chain-of-thought prompting has demonstrated remarkable performance on various natural language reasoning tasks. However, it tends to perform poorly on tasks which requires solving problems harder than the exemplars shown in the prompts. To overcome this challenge of easy-to-hard generalization, we propose a novel prompting strategy, least-to-most prompting. The key idea in this strategy is to break down a complex problem into a series of simpler subproblems and then solve them in sequence. Solving each subproblem is facilitated by the answers to previously solved subproblems. Our experimental results on tasks related to symbolic manipulation, compositional generalization, and math reasoning reveal that least-to-most prompting is capable of generalizing to more difficult problems than those seen in the prompts. A notable finding is that when the GPT-3 code-davinci-002 model is used with least-to-most prompting, it can solve the compositional generalization benchmark SCAN in any split (including length split)  with an accuracy of at least 99\\% using just 14 exemplars, compared to only 16\\% accuracy with chain-of-thought prompting.  This is particularly noteworthy because neural-symbolic models in the literature that specialize in solving SCAN are trained on the entire training set containing over 15,000 examples. We have included prompts for all the tasks in the Appendix."}}
{"id": "jz7tDvX6XYR", "cdate": 1601308296977, "mdate": null, "content": {"title": "Speeding up Deep Learning Training by Sharing Weights and Then Unsharing", "abstract": "It has been widely observed that increasing deep learning model sizes often leads to significant performance improvements on a variety of natural language processing and computer vision tasks. In the meantime, however, computational costs and training time would dramatically increase when models get larger. In this paper, we propose a simple approach to speed up training for a particular kind of deep networks which contain repeated structures,  such as the transformer module. In our method, we first train such a deep network with the weights shared across all the repeated layers till some point. We then stop weight sharing and continue training until convergence. The untying point is automatically determined by monitoring gradient statistics. Our adaptive untying criterion is obtained from a theoretic analysis over deep linear networks.  Empirical results show that our method is able to reduce the training time of BERT  by 50%. "}}
{"id": "Q5B006Qoi-", "cdate": 1580417977771, "mdate": null, "content": {"title": "Large scale shadow annotation and detection using lazy annotation and stacked CNNs", "abstract": "Recent shadow detection algorithms have shown initial success on small datasets of images from specific domains. However, shadow detection on broader image domains is still challenging due to the lack of representative annotated training data. In this paper we propose \"lazy annotation\", an efficient annotation method where an annotator only needs to mark the important shadow areas and some non-shadow areas. This yields data with noisy labels that are not yet useful for training a shadow detector. We address the problem of label noise by jointly learning a shadow region classifier and recovering the labels in the training set. Experimental results show that a classifier trained with recovered labels achieves comparable performance to a classifier trained on the properly annotated data. These results motivated us to collect a new dataset that is 20 times larger than existing datasets and contains a large variety of scenes and image types. In addition, we propose a stacked Convolutional Neural Network architecture that efficiently trains on patch level shadow examples while incorporating image level semantic information. Our proposed pipeline, trained on recovered labels, performs at state-of-the art level."}}
