{"id": "cy-txnmStS", "cdate": 1640995200000, "mdate": 1681676405744, "content": {"title": "LanCon-Learn: Learning With Language to Enable Generalization in Multi-Task Manipulation", "abstract": "Robots must be capable of learning from previously solved tasks and generalizing that knowledge to quickly perform new tasks to realize the vision of ubiquitous and useful robot assistance in the real world. While multi-task learning research has produced agents capable of performing multiple tasks, these tasks are often encoded as one-hot goals. In contrast, natural language specifications offer an accessible means both for (1) users to describe a set of new tasks to the robot and (2) robots to reason about the similarities and differences among tasks through language-based task embeddings. Until now, multi-task learning with language has been limited to navigation based tasks and has not been applied to continuous manipulation tasks, requiring precision to grasp and move objects. We present <small>LanCon-Learn</small>, a novel attention-based approach to language-conditioned multi-task learning in manipulation domains to enable learning agents to reason about relationships between skills and task objectives through natural language and interaction. We evaluate <small>LanCon-Learn</small> for both reinforcement learning and imitation learning, across multiple virtual robot domains along with a demonstration on a physical robot. <small>LanCon-Learn</small> achieves up to a 200&#x0025; improvement in zero-shot task success rate and transfers known skills to novel tasks faster than non-language-based baselines, demonstrating the utility of language for goal specification."}}
{"id": "cRUVen2H41", "cdate": 1640995200000, "mdate": 1681676405747, "content": {"title": "Multi-UAV Planning for Cooperative Wildfire Coverage and Tracking with Quality-of-Service Guarantees", "abstract": "In recent years, teams of robot and Unmanned Aerial Vehicles (UAVs) have been commissioned by researchers to enable accurate, online wildfire coverage and tracking. While the majority of prior work focuses on the coordination and control of such multi-robot systems, to date, these UAV teams have not been given the ability to reason about a fire's track (i.e., location and propagation dynamics) to provide performance guarantee over a time horizon. Motivated by the problem of aerial wildfire monitoring, we propose a predictive framework which enables cooperation in multi-UAV teams towards collaborative field coverage and fire tracking with probabilistic performance guarantee. Our approach enables UAVs to infer the latent fire propagation dynamics for time-extended coordination in safety-critical conditions. We derive a set of novel, analytical temporal, and tracking-error bounds to enable the UAV-team to distribute their limited resources and cover the entire fire area according to the case-specific estimated states and provide a probabilistic performance guarantee. Our results are not limited to the aerial wildfire monitoring case-study and are generally applicable to problems, such as search-and-rescue, target tracking and border patrol. We evaluate our approach in simulation and provide demonstrations of the proposed framework on a physical multi-robot testbed to account for real robot dynamics and restrictions. Our quantitative evaluations validate the performance of our method accumulating 7.5x and 9.0x smaller tracking-error than state-of-the-art model-based and reinforcement learning benchmarks, respectively."}}
{"id": "XvAOXxz6bu", "cdate": 1640995200000, "mdate": 1681676405745, "content": {"title": "Cross-Loss Influence Functions to Explain Deep Network Representations", "abstract": "As machine learning is increasingly deployed in the real world, it is paramount that we develop the tools necessary to analyze the decision-making of the models we train and deploy to end-users. Recently, researchers have shown that influence functions, a statistical measure of sample impact, can approximate the effects of training samples on classification accuracy for deep neural networks. However, this prior work only applies to supervised learning, where training and testing share an objective function. No approaches currently exist for estimating the influence of unsupervised training examples for deep learning models. To bring explainability to unsupervised and semi-supervised training regimes, we derive the first theoretical and empirical demonstration that influence functions can be extended to handle mismatched training and testing (i.e., \"cross-loss\") settings. Our formulation enables us to compute the influence in an unsupervised learning setup, explain cluster memberships, and identify and augment biases in language models. Our experiments show that our cross-loss influence estimates even exceed matched-objective influence estimation relative to ground-truth sample impact."}}
{"id": "W5LEsuCUN6Q", "cdate": 1640995200000, "mdate": 1681676405749, "content": {"title": "Multi-UAV planning for cooperative wildfire coverage and tracking with quality-of-service guarantees", "abstract": "In recent years, teams of robot and Unmanned Aerial Vehicles (UAVs) have been commissioned by researchers to enable accurate, online wildfire coverage and tracking. While the majority of prior work focuses on the coordination and control of such multi-robot systems, to date, these UAV teams have not been given the ability to reason about a fire\u2019s track (i.e., location and propagation dynamics) to provide performance guarantee over a time horizon. Motivated by the problem of aerial wildfire monitoring, we propose a predictive framework which enables cooperation in multi-UAV teams towards collaborative field coverage and fire tracking with probabilistic performance guarantee. Our approach enables UAVs to infer the latent fire propagation dynamics for time-extended coordination in safety-critical conditions. We derive a set of novel, analytical temporal, and tracking-error bounds to enable the UAV-team to distribute their limited resources and cover the entire fire area according to the case-specific estimated states and provide a probabilistic performance guarantee. Our results are not limited to the aerial wildfire monitoring case-study and are generally applicable to problems, such as search-and-rescue, target tracking and border patrol. We evaluate our approach in simulation and provide demonstrations of the proposed framework on a physical multi-robot testbed to account for real robot dynamics and restrictions. Our quantitative evaluations validate the performance of our method accumulating $$7.5\\times$$ 7.5 \u00d7 and $$9.0\\times$$ 9.0 \u00d7 smaller tracking-error than state-of-the-art model-based and reinforcement learning benchmarks, respectively."}}
{"id": "HJ5P672lYe", "cdate": 1640995200000, "mdate": 1681676405776, "content": {"title": "Learning Interpretable, High-Performing Policies for Continuous Control Problems", "abstract": "Gradient-based approaches in reinforcement learning (RL) have achieved tremendous success in learning policies for autonomous vehicles. While the performance of these approaches warrants real-world adoption, these policies lack interpretability, limiting deployability in the safety-critical and legally-regulated domain of autonomous driving (AD). AD requires interpretable and verifiable control policies that maintain high performance. We propose Interpretable Continuous Control Trees (ICCTs), a tree-based model that can be optimized via modern, gradient-based, RL approaches to produce high-performing, interpretable policies. The key to our approach is a procedure for allowing direct optimization in a sparse decision-tree-like representation. We validate ICCTs against baselines across six domains, showing that ICCTs are capable of learning interpretable policy representations that parity or outperform baselines by up to 33% in AD scenarios while achieving a 300x-600x reduction in the number of policy parameters against deep learning baselines. Furthermore, we demonstrate the interpretability and utility of our ICCTs through a 14-car physical robot demonstration."}}
{"id": "BfM91_2XMXc", "cdate": 1640995200000, "mdate": 1648667750828, "content": {"title": "FedEmbed: Personalized Private Federated Learning", "abstract": "Federated learning enables the deployment of machine learning to problems for which centralized data collection is impractical. Adding differential privacy guarantees bounds on privacy while data are contributed to a global model. Adding personalization to federated learning introduces new challenges as we must account for preferences of individual users, where a data sample could have conflicting labels because one sub-population of users might view an input positively, but other sub-populations view the same input negatively. We present FedEmbed, a new approach to private federated learning for personalizing a global model that uses (1) sub-populations of similar users, and (2) personal embeddings. We demonstrate that current approaches to federated learning are inadequate for handling data with conflicting labels, and we show that FedEmbed achieves up to 45% improvement over baseline approaches to personalized private federated learning."}}
{"id": "B999NCHjCXq", "cdate": 1640995200000, "mdate": 1681676405745, "content": {"title": "FedPC: Federated Learning for Language Generation with Personal and Context Preference Embeddings", "abstract": "Federated learning is a training paradigm that learns from multiple distributed users without aggregating data on a centralized server. Such a paradigm promises the ability to deploy machine-learning at-scale to a diverse population of end-users without first collecting a large, labeled dataset for all possible tasks. As federated learning typically averages learning updates across a decentralized population, there is a growing need for personalization of federated learning systems (i.e conversational agents must be able to personalize to a specific user's preferences). In this work, we propose a new direction for personalization research within federated learning, leveraging both personal embeddings and shared context embeddings. We also present an approach to predict these ``preference'' embeddings, enabling personalization without backpropagation. Compared to state-of-the-art personalization baselines, our approach achieves a 50\\% improvement in test-time perplexity using 0.001\\% of the memory required by baseline approaches, and achieving greater sample- and compute-efficiency."}}
{"id": "a5JBK1eos9l", "cdate": 1624294074213, "mdate": 1624294074213, "content": {"title": "Robot Classification of Human Interruptibility and a Study of Its Effects", "abstract": "As robots become increasingly prevalent in human environments, there will inevitably be times when the robot needs to interrupt a human to initiate an interaction. Our work introduces the first interruptibility-aware\nmobile-robot system, which uses social and contextual cues online to accurately determine when to interrupt a person. We evaluate multiple non-temporal and temporal models on the interruptibility classification\ntask, and show that a variant of Conditional Random Fields (CRFs), the Latent-Dynamic CRF, is the most\nrobust, accurate, and appropriate model for use on our system. Additionally, we evaluate different classification features and show that the observed demeanor of a person can help in interruptibility classification;\nbut in the presence of detection noise, robust detection of object labels as a visual cue to the interruption\ncontext can improve interruptibility estimates. Finally, we deploy our system in a large-scale user study to\nunderstand the effects of interruptibility-awareness on human-task performance, robot-task performance,\nand on human interpretation of the robot\u2019s social aptitude. Our results show that while participants are able\nto maintain task performance, even in the presence of interruptions, interruptibility-awareness improves the\nrobot\u2019s task performance and improves participant social perceptions of the robot."}}
{"id": "rt8GJOnXGX5", "cdate": 1609459200000, "mdate": 1648667750761, "content": {"title": "Multimodal Punctuation Prediction with Contextual Dropout", "abstract": "Automatic speech recognition (ASR) is widely used in consumer electronics. ASR greatly improves the utility and accessibility of technology, but usually the output is only word sequences without punctuation. This can result in ambiguity in inferring user-intent. We first present a transformer-based approach for punctuation prediction that achieves 8% improvement on the IWSLT 2012 TED Task, beating the previous state of the art [1]. We next describe our multimodal model that learns from both text and audio, which achieves 8% improvement over the text-only algorithm on an internal dataset for which we have both the audio and transcriptions. Finally, we present an approach to learning a model using contextual dropout that allows us to handle variable amounts of future context at test time."}}
{"id": "pZUCUV1q1d1", "cdate": 1609459200000, "mdate": 1681676405747, "content": {"title": "Towards a Comprehensive Understanding and Accurate Evaluation of Societal Biases in Pre-Trained Transformers", "abstract": "Andrew Silva, Pradyumna Tambwekar, Matthew Gombolay. Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. 2021."}}
