{"id": "jd-NB0HNXC3", "cdate": 1696118400000, "mdate": 1681649981987, "content": {"title": "Attribute augmentation-based label integration for crowdsourcing", "abstract": ""}}
{"id": "zoFCwEur-QX", "cdate": 1672531200000, "mdate": 1681649981718, "content": {"title": "Instance difficulty-based noise correction for crowdsourcing", "abstract": ""}}
{"id": "ls7XVX7thlY", "cdate": 1672531200000, "mdate": 1681649981968, "content": {"title": "A multi-view-based noise correction algorithm for crowdsourcing learning", "abstract": ""}}
{"id": "EXe-kQ9blXv", "cdate": 1672531200000, "mdate": 1681649981972, "content": {"title": "Label confidence-based noise correction for crowdsourcing", "abstract": ""}}
{"id": "wxAWp8l4u0s", "cdate": 1640995200000, "mdate": 1681649981829, "content": {"title": "Attribute augmented and weighted naive Bayes", "abstract": ""}}
{"id": "ZWbLE3ScWhG", "cdate": 1640995200000, "mdate": 1681649981975, "content": {"title": "Label distribution-based noise correction for multiclass crowdsourcing", "abstract": ""}}
{"id": "WY8lNJhHX7", "cdate": 1640995200000, "mdate": 1681649982004, "content": {"title": "Fine tuning attribute weighted naive Bayes", "abstract": ""}}
{"id": "VZKKmvW_df", "cdate": 1640995200000, "mdate": 1681649981924, "content": {"title": "Label augmented and weighted majority voting for crowdsourcing", "abstract": ""}}
{"id": "VVWkUFDD7p", "cdate": 1640995200000, "mdate": 1681649982015, "content": {"title": "Learning From Crowds With Multiple Noisy Label Distribution Propagation", "abstract": ""}}
{"id": "SLm-tvG5Blq", "cdate": 1640995200000, "mdate": 1645744737506, "content": {"title": "Improving data and model quality in crowdsourcing using co-training-based noise correction", "abstract": "Crowdsourcing makes it much faster and cheaper to obtain labels for a large amount of data used in supervised learning. In the crowdsourcing scenario, an integrated label is inferred from a multiple noisy label set for each instance using ground truth inference algorithms, which is called label integration. However, a certain level of label noise remains in the integrated dataset, which degrades the performance of the models trained on it. To the best of our knowledge, existing label noise correction algorithms only use the original attribute space and do not use the information contained in the multiple noisy label sets for building models. To solve these problems, we propose a novel integrated label noise correction algorithm called co-training-based noise correction (CTNC). In CTNC, the weight is first calculated from the information provided by the multiple noisy label set for each instance. Subsequently, a label noise filter is used to identify noisy instances; a clean set and a noisy set are thus obtained. Another attribute view of each instance in both the clean and noisy sets is then generated by the classifiers trained on the original attribute view of the clean set. Finally, a co-training framework is used to train two classifiers to relabel the integrated instances. The performance on 34 simulated datasets and 2 real-world datasets demonstrates that our proposed CTNC outperforms all state-of-the-art label noise correction algorithms used for comparison."}}
