{"id": "JrZv_E_QDm", "cdate": 1672531200000, "mdate": 1681490806946, "content": {"title": "Certified Interpretability Robustness for Class Activation Mapping", "abstract": ""}}
{"id": "6PibKATdcf8", "cdate": 1672531200000, "mdate": 1677929970381, "content": {"title": "SantaCoder: don't reach for the stars!", "abstract": ""}}
{"id": "PvDY71zKsvP", "cdate": 1663850463805, "mdate": null, "content": {"title": "Min-Max Multi-objective Bilevel Optimization with Applications in Robust Machine Learning", "abstract": "We consider a generic min-max multi-objective bilevel optimization problem with applications in robust machine learning such as representation learning and hyperparameter optimization. We design MORBiT, a novel single-loop gradient descent-ascent bilevel optimization algorithm, to solve the generic problem and present a novel analysis showing that MORBiT converges to the first-order stationary point at a rate of $\\widetilde{\\mathcal{O}}(n^{1/2} K^{-2/5})$ for a class of weakly convex problems with $n$ objectives upon $K$ iterations of the algorithm. Our analysis utilizes novel results to handle the non-smooth min-max multi-objective setup and to obtain a sublinear dependence in the number of objectives $n$. Experimental results on robust representation learning and robust hyperparameter optimization showcase (i) the advantages of considering the min-max multi-objective setup, and (ii) convergence properties of the proposed \\morbit."}}
{"id": "oRJPVhCwxiR", "cdate": 1640995200000, "mdate": 1682321070147, "content": {"title": "ObSynth: An Interactive Synthesis System for Generating Object Models from Natural Language Specifications", "abstract": "We introduce ObSynth, an interactive system leveraging the domain knowledge embedded in large language models (LLMs) to help users design object models from high level natural language prompts. This is an example of specification reification, the process of taking a high-level, potentially vague specification and reifying it into a more concrete form. We evaluate ObSynth via a user study, leading to three key findings: first, object models designed using ObSynth are more detailed, showing that it often synthesizes fields users might have otherwise omitted. Second, a majority of objects, methods, and fields generated by ObSynth are kept by the user in the final object model, highlighting the quality of generated components. Third, ObSynth altered the workflow of participants: they focus on checking that synthesized components were correct rather than generating them from scratch, though ObSynth did not reduce the time participants took to generate object models."}}
{"id": "7hVYtQMk31", "cdate": 1640995200000, "mdate": 1681674176454, "content": {"title": "The Disagreement Problem in Explainable Machine Learning: A Practitioner's Perspective", "abstract": "As various post hoc explanation methods are increasingly being leveraged to explain complex models in high-stakes settings, it becomes critical to develop a deeper understanding of if and when the explanations output by these methods disagree with each other, and how such disagreements are resolved in practice. However, there is little to no research that provides answers to these critical questions. In this work, we introduce and study the disagreement problem in explainable machine learning. More specifically, we formalize the notion of disagreement between explanations, analyze how often such disagreements occur in practice, and how do practitioners resolve these disagreements. To this end, we first conduct interviews with data scientists to understand what constitutes disagreement between explanations generated by different methods for the same model prediction, and introduce a novel quantitative framework to formalize this understanding. We then leverage this framework to carry out a rigorous empirical analysis with four real-world datasets, six state-of-the-art post hoc explanation methods, and eight different predictive models, to measure the extent of disagreement between the explanations generated by various popular explanation methods. In addition, we carry out an online user study with data scientists to understand how they resolve the aforementioned disagreements. Our results indicate that state-of-the-art explanation methods often disagree in terms of the explanations they output. Our findings also underscore the importance of developing principled evaluation metrics that enable practitioners to effectively compare explanations."}}
{"id": "-ExEkSHJg7k", "cdate": 1640995200000, "mdate": 1674492694218, "content": {"title": "Min-Max Bilevel Multi-objective Optimization with Applications in Machine Learning", "abstract": "We consider a generic min-max multi-objective bilevel optimization problem with applications in robust machine learning such as representation learning and hyperparameter optimization. We design MORBiT, a novel single-loop gradient descent-ascent bilevel optimization algorithm, to solve the generic problem and present a novel analysis showing that MORBiT converges to the first-order stationary point at a rate of $\\widetilde{\\mathcal{O}}(n^{1/2} K^{-2/5})$ for a class of weakly convex problems with $n$ objectives upon $K$ iterations of the algorithm. Our analysis utilizes novel results to handle the non-smooth min-max multi-objective setup and to obtain a sublinear dependence in the number of objectives $n$. Experimental results on robust representation learning and robust hyperparameter optimization showcase (i) the advantages of considering the min-max multi-objective setup, and (ii) convergence properties of the proposed MORBiT. Our code is at https://github.com/minimario/MORBiT."}}
{"id": "crnXK0jC2F", "cdate": 1621630305138, "mdate": null, "content": {"title": "Three Operator Splitting with Subgradients, Stochastic Gradients, and Adaptive Learning Rates", "abstract": "Three Operator Splitting (TOS) (Davis & Yin, 2017) can minimize the sum of multiple convex functions effectively when an efficient gradient oracle or proximal operator is available for each term. This requirement often fails in machine learning applications: (i) instead of full gradients only stochastic gradients may be available; and (ii) instead of proximal operators, using subgradients to handle complex penalty functions may be more efficient and realistic. Motivated by these concerns, we analyze three potentially valuable extensions of TOS. The first two permit using subgradients and stochastic gradients, and are shown to ensure a $\\mathcal{O}(1/\\sqrt{t})$ convergence rate. The third extension AdapTOS endows TOS with adaptive step-sizes. For the important setting of optimizing a convex loss over the intersection of convex sets AdapTOS attains universal convergence rates, i.e., the rate adapts to the unknown smoothness degree of the objective. We compare our proposed methods with competing methods on various applications. \n"}}
{"id": "d0svLMnvzWK", "cdate": 1612102759311, "mdate": null, "content": {"title": "La-MAML: Look-ahead Meta Learning for Continual Learning, ML Reproducibility Challenge 2020", "abstract": "The Continual Learning (CL) problem involves performing well on a sequence of tasks under limited compute. Current\nalgorithms in the domain are either slow, offline or sensitive to hyper-parameters. La-MAML, an optimization-based\nmeta-learning algorithm claims to be better than other replay-based, prior-based and meta-learning based approaches.\nScope of Reproducibility\nAccording to the MER paper (1), metrics to measure performance in the continual learning arena are Retained Accuracy\n(RA) and Backward Transfer-Interference (BTI). La-MAML claims to perform better in these values when compared to\nthe SOTA in the domain. This is the main claim of the paper.\n\nMethodology\nWe used the author\u2019s code which was pretty new and built on the latest packages. We tried it on Free Google Colab\nNotebooks (Tesla T4 GPU). We simply ran the code according to the instructions given in the official implementation.\nWe found that the results were very similar to the ones given in the paper.\n\nResults\nWe reproduced the accuracy to within 4% of the reported value, which supports the paper\u2019s conclusion that it outperforms\nthe baselines.\n\nWhat was easy\nRunning the code was easy. The packages used for the official implementation were the latest. It was easy to incorporate\nWeights and Biases into the implementation.\n\nWhat was difficult\nFor some of the experiments, the computational requirement was too high. For example, the MNIST Many Permutations\nDataset requires more than 12GB of RAM to pass into the loader. Further, some other experiments exceeded 12 hours\nof running time due to which we had to use less powerful GPUs.\nCommunication with original authors\nFor most of the experiments concerning the main claim of the paper, the code was enough from the official repo provided\nby the authors on Github. However, reproducing some of the figures and the tables involving Gradient Alignment and\nCatastrophic Forgetting visualization proved to be difficult due to those parts not being published. We were able to\ncontact the authors and received help for those experiments."}}
{"id": "uKEwnGMw7V0", "cdate": 1609459200000, "mdate": 1682321070146, "content": {"title": "Reproducibility Report: La-MAML: Look-ahead Meta Learning for Continual Learning", "abstract": "The Continual Learning (CL) problem involves performing well on a sequence of tasks under limited compute. Current algorithms in the domain are either slow, offline or sensitive to hyper-parameters. La-MAML, an optimization-based meta-learning algorithm claims to be better than other replay-based, prior-based and meta-learning based approaches. According to the MER paper [1], metrics to measure performance in the continual learning arena are Retained Accuracy (RA) and Backward Transfer-Interference (BTI). La-MAML claims to perform better in these values when compared to the SOTA in the domain. This is the main claim of the paper, which we shall be verifying in this report."}}
{"id": "VwxiPu4ui9e", "cdate": 1609459200000, "mdate": 1682321070148, "content": {"title": "Three Operator Splitting with Subgradients, Stochastic Gradients, and Adaptive Learning Rates", "abstract": "Three Operator Splitting (TOS) (Davis &amp; Yin, 2017) can minimize the sum of multiple convex functions effectively when an efficient gradient oracle or proximal operator is available for each term. This requirement often fails in machine learning applications: (i) instead of full gradients only stochastic gradients may be available; and (ii) instead of proximal operators, using subgradients to handle complex penalty functions may be more efficient and realistic. Motivated by these concerns, we analyze three potentially valuable extensions of TOS. The first two permit using subgradients and stochastic gradients, and are shown to ensure a $\\mathcal{O}(1/\\sqrt{t})$ convergence rate. The third extension AdapTOS endows TOS with adaptive step-sizes. For the important setting of optimizing a convex loss over the intersection of convex sets AdapTOS attains universal convergence rates, i.e., the rate adapts to the unknown smoothness degree of the objective. We compare our proposed methods with competing methods on various applications."}}
