{"id": "WYGZDnsGksa", "cdate": 1650561521767, "mdate": 1650561521767, "content": {"title": "Neural Program Generation Modulo Static Analysis", "abstract": "State-of-the-art neural models of source code tend to be evaluated on the generation of individual expressions and lines of code, and commonly fail on long-horizon tasks such as the generation of entire method bodies. We propose to address this deficiency using weak supervision from a static program analyzer. Our neurosymbolic method allows a deep generative model to symbolically compute, using calls to a static analysis tool, long-distance semantic relationships in the code that it has already generated. During training, the model observes these relationships and learns to generate programs conditioned on them. We apply our approach to the problem of generating entire Java methods given the remainder of the class that contains the method. Our experiments show that the approach substantially outperforms a state-of-the-art transformer and a model that explicitly tries to learn program semantics on this task, both in terms of producing programs free of basic semantic errors and in terms of syntactically matching the ground truth."}}
{"id": "yaksQCYcRs", "cdate": 1621630312845, "mdate": null, "content": {"title": "Neural Program Generation Modulo Static Analysis", "abstract": "State-of-the-art neural models of source code tend to be evaluated on the generation of individual expressions and lines of code, and commonly fail on long-horizon tasks such as the generation of entire method bodies. We propose to address this deficiency using weak supervision from a static program analyzer. Our neurosymbolic method allows a deep generative model to symbolically compute, using calls to a static analysis tool, long-distance semantic relationships in the code that it has already generated. During training, the model observes these relationships and learns to generate programs conditioned on them. We apply our approach to the problem of generating entire Java methods given the remainder of the class that contains the method. Our experiments show that the approach substantially outperforms a state-of-the-art transformer and a model that explicitly tries to learn program semantics on this task, both in terms of producing programs free of basic semantic errors and in terms of syntactically matching the ground truth. "}}
{"id": "g11CZSghXyY", "cdate": 1601308158243, "mdate": null, "content": {"title": "Combining Ensembles and Data Augmentation Can Harm Your Calibration", "abstract": "Ensemble methods which average over multiple neural network predictions are a simple approach to improve a model\u2019s calibration and robustness. Similarly, data augmentation techniques, which encode prior information in the form of invariant feature transformations, are effective for improving calibration and robustness. In this paper, we show a surprising pathology: combining ensembles and data augmentation can harm model calibration. This leads to a trade-off in practice, whereby improved accuracy by combining the two techniques comes at the expense of calibration. On the other hand, selecting only one of the techniques ensures good uncertainty estimates at the expense of accuracy. We investigate this pathology and identify a compounding under-confidence among methods which marginalize over sets of weights and data augmentation techniques which soften labels. Finally, we propose a simple correction, achieving the best of both worlds with significant accuracy and calibration gains over using only ensembles or data augmentation individually. Applying the correction produces new state-of-the art in uncertainty calibration and robustness across CIFAR-10, CIFAR-100, and ImageNet."}}
{"id": "Sklf1yrYDr", "cdate": 1569439449791, "mdate": null, "content": {"title": "BatchEnsemble: an Alternative Approach to Efficient Ensemble and Lifelong Learning", "abstract": "\nEnsembles, where multiple neural networks are trained individually and their predictions are averaged, have been shown to be widely successful for improving both the accuracy and predictive uncertainty of single neural networks. However, an ensemble\u2019s cost for both training and testing increases linearly with the number of networks, which quickly becomes untenable.\nIn this paper, we propose BatchEnsemble, an ensemble method whose computational and memory costs are significantly lower than typical ensembles. BatchEnsemble achieves this by defining each weight matrix to be the Hadamard product of a shared weight among all ensemble members and a rank-one matrix per member. Unlike ensembles, BatchEnsemble is not only parallelizable across devices, where one device trains one member, but also parallelizable within a device, where multiple ensemble members are updated simultaneously for a given mini-batch. Across CIFAR-10, CIFAR-100, WMT14 EN-DE/EN-FR translation, and out-of-distribution tasks, BatchEnsemble yields competitive accuracy and uncertainties as typical ensembles; the speedup at test time is 3X and memory reduction is 3X at an ensemble of size 4. We also apply BatchEnsemble to lifelong learning, where on Split-CIFAR-100, BatchEnsemble yields comparable performance to progressive neural networks while having a much lower computational and memory costs. We further show that BatchEnsemble can easily scale up to lifelong learning on Split-ImageNet which involves 100 sequential learning tasks"}}
{"id": "H1lefTEKDS", "cdate": 1569438983892, "mdate": null, "content": {"title": "Benchmarking Model-Based Reinforcement Learning", "abstract": "Model-based reinforcement learning (MBRL) is widely seen as having the potential\nto be significantly more sample efficient than model-free RL. However, research in\nmodel-based RL has not been very standardized. It is fairly common for authors to\nexperiment with self-designed environments, and there are several separate lines of\nresearch, which are sometimes closed-sourced or not reproducible. Accordingly, it\nis an open question how these various existing algorithms perform relative to each\nother. To facilitate research in MBRL, in this paper we gather a wide collection\nof MBRL algorithms and propose over 18 benchmarking environments specially\ndesigned for MBRL. We benchmark these algorithms with unified problem settings,\nincluding noisy environments. Beyond cataloguing performance, we explore\nand unify the underlying algorithmic differences across MBRL algorithms. We\ncharacterize three key research challenges for future MBRL research: the dynamics\nbottleneck, the planning horizon dilemma, and the early-termination dilemma.\nFinally, to facilitate future research on MBRL, we open-source our benchmark."}}
{"id": "S1eB3sRqtm", "cdate": 1538087852589, "mdate": null, "content": {"title": "Exploring Curvature Noise in Large-Batch Stochastic Optimization", "abstract": "Using stochastic gradient descent (SGD) with large batch-sizes to train deep neural networks is an increasingly popular technique. By doing so, one can improve parallelization by scaling to multiple workers (GPUs) and hence leading to significant reductions in training time. Unfortunately, a major drawback is the so-called generalization gap: large-batch training typically leads to a degradation in generalization performance of the model as compared to small-batch training. In this paper, we propose to correct this generalization gap by adding diagonal Fisher curvature noise to large-batch gradient updates. We provide a theoretical analysis of our method in the convex quadratic setting. Our empirical study with state-of-the-art deep learning models shows that our method not only improves the generalization performance in large-batch training but furthermore, does so in a way where the training convergence remains desirable and the training duration is not elongated. We additionally connect our method to recent works on loss surface landscape in the experimental section. "}}
{"id": "rJNpifWAb", "cdate": 1518730160330, "mdate": null, "content": {"title": "Flipout: Efficient Pseudo-Independent Weight Perturbations on Mini-Batches", "abstract": "Stochastic neural net weights are used in a variety of contexts, including regularization, Bayesian neural nets, exploration in reinforcement learning, and evolution strategies. Unfortunately, due to the large number of weights, all the examples in a mini-batch typically share the same weight perturbation, thereby limiting the variance reduction effect of large mini-batches. We introduce flipout, an efficient method for decorrelating the gradients within a mini-batch by implicitly sampling pseudo-independent weight perturbations for each example. Empirically, flipout achieves the ideal linear variance reduction for fully connected networks, convolutional networks, and RNNs. We find significant speedups in training neural networks with multiplicative Gaussian perturbations. We show that flipout is effective at regularizing LSTMs, and outperforms previous methods. Flipout also enables us to vectorize evolution strategies: in our experiments, a single GPU with flipout can handle the same throughput as at least 40 CPU cores using existing methods, equivalent to a factor-of-4 cost reduction on Amazon Web Services."}}
