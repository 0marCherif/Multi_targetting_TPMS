{"id": "wgDzU5E53iW", "cdate": 1699878177899, "mdate": 1699878177899, "content": {"title": "Large-scale generative simulation artificial intelligence: The next hotspot", "abstract": "The concept of GenAI has been developed for decades. Until recently, it has impressed us with substantial breakthroughs in natural language processing and computer vision, actively engaging in industrial scenarios. Noticing the practical challenges, e.g., limited learning resources, and overly dependencies on scientific discovery empiricism, we nominate large-scale generative simulation artificial intelligence (LS-GenAI) as the next hotspot for GenAI to connect. Key to generative simulation artificial intelligence are scenario generation and fast skill transfer, which form a closed loop in practice."}}
{"id": "BBwFq8ljpT", "cdate": 1690848000000, "mdate": 1695978457123, "content": {"title": "Proving Information Inequalities and Identities With Symbolic Computation", "abstract": "Proving linear inequalities and identities of Shannon\u2019s information measures, possibly with linear constraints on the information measures, is an important problem in information theory. For this purpose, ITIP and other variant algorithms have been developed and implemented, which are all based on solving a linear program (LP). In particular, an identity <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"> <tex-math notation=\"LaTeX\">$f = 0$ </tex-math></inline-formula> is verified by solving two LPs, one for <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"> <tex-math notation=\"LaTeX\">$f \\ge 0$ </tex-math></inline-formula> and one for <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"> <tex-math notation=\"LaTeX\">$f \\le 0$ </tex-math></inline-formula> . In this paper, we develop a set of algorithms that can be implemented by symbolic computation. Based on these algorithms, procedures for verifying linear information inequalities and identities are devised. Compared with LP-based algorithms, our procedures can produce analytical proofs that are both human-verifiable and free of numerical errors. Our procedures are also more efficient computationally. For constrained inequalities, by taking advantage of the algebraic structure of the problem, the size of the LP that needs to be solved can be significantly reduced. For identities, instead of solving two LPs, the identity can be verified directly with very little computation."}}
{"id": "AaSRZl2qgh1", "cdate": 1675209600000, "mdate": 1683897653323, "content": {"title": "Improve Robustness and Accuracy of Deep Neural Network with L2,\u221e Normalization", "abstract": "In this paper, the L2,\u221e normalization of the weight matrices is used to enhance the robustness and accuracy of the deep neural network (DNN) with Relu as activation functions. It is shown that the L2,\u221e normalization leads to large dihedral angles between two adjacent faces of the DNN function graph and hence smoother DNN functions, which reduces over-fitting of the DNN. A global measure is proposed for the robustness of a classification DNN, which is the average radius of the maximal robust spheres with the training samples as centers. A lower bound for the robustness measure in terms of the L2,\u221e norm is given. Finally, an upper bound for the Rademacher complexity of DNNs with L2,\u221e normalization is given. An algorithm is given to train DNNs with the L2,\u221e normalization and numerical experimental results are used to show that the L2,\u221e normalization is effective in terms of improving the robustness and accuracy."}}
{"id": "iZHvKMqS5n", "cdate": 1672531200000, "mdate": 1695978457118, "content": {"title": "New Sparse Multivariate Polynomial Factorization Algorithms over Integers", "abstract": "We propose two algorithms for sparse polynomial factorization over integers. The first one has good practical performance and is efficient for factoring polynomials with sparse irreducible factors. The second one is based on the effective Hilbert irreducibility theorem and has complexity polynomial in the sizes of the input and output, and the partial degree. At high level, the algorithms follow the standard approaches by reducing multi-variate polynomial factorization to univariate or bivariate polynomial factorization. Our main contributions are twofold. First, a new variable substitution is given, which reduces the multi-variate polynomial to a separated one, that is, the coefficients of its factors in a main variable are monomials. Second, \u201cgood\u201d primes are selected such that the multi-variate factors can be recovered from the univariate or bivariate factors by direct division of the primes. As a consequence, the multivariate Hensel lifting in previous methods is avoided."}}
{"id": "WXecRPW898", "cdate": 1672531200000, "mdate": 1695978457112, "content": {"title": "Adversarial Parameter Attack on Deep Neural Networks", "abstract": "The parameter perturbation attack is a safety threat to deep learning, where small parameter perturbations are made such that the attacked network gives wrong or desired labels of the adversary to ..."}}
{"id": "ABdsWC2Qw8", "cdate": 1672531200000, "mdate": 1695978457110, "content": {"title": "Restore Translation Using Equivariant Neural Networks", "abstract": "Invariance to spatial transformations such as translations and rotations is a desirable property and a basic design principle for classification neural networks. However, the commonly used convolutional neural networks (CNNs) are actually very sensitive to even small translations. There exist vast works to achieve exact or approximate transformation invariance by designing transformation-invariant models or assessing the transformations. These works usually make changes to the standard CNNs and harm the performance on standard datasets. In this paper, rather than modifying the classifier, we propose a pre-classifier restorer to recover translated (or even rotated) inputs to the original ones which will be fed into any classifier for the same dataset. The restorer is based on a theoretical result which gives a sufficient and necessary condition for an affine operator to be translational equivariant on a tensor space."}}
{"id": "HOG-G4arLnU", "cdate": 1652737698112, "mdate": null, "content": {"title": "Isometric 3D Adversarial Examples in the Physical World", "abstract": "Recently, several attempts have demonstrated that 3D deep learning models are as vulnerable to adversarial example attacks as 2D models. However, these methods are still far from stealthy and suffer from severe performance degradation in the physical world. Although 3D data is highly structured, it is difficult to bound the perturbations with simple metrics in the Euclidean space. In this paper, we propose a novel $\\epsilon$-isometric ($\\epsilon$-ISO) attack method to generate natural and robust 3D adversarial examples in the physical world by considering the geometric properties of 3D objects and the invariance to physical transformations. For naturalness, we constrain the adversarial example and the original one to be $\\epsilon$-isometric by adopting the Gaussian curvature as the surrogate metric under a theoretical analysis. For robustness under physical transformations, we propose a maxima over transformation (MaxOT) method to actively search for the most difficult transformations rather than random ones to make the generated adversarial example more robust in the physical world. Extensive experiments on typical point cloud recognition models validate that our approach can improve the attack success rate and naturalness of the generated 3D adversarial examples than the state-of-the-art attack methods."}}
{"id": "zC3B5NoaVi", "cdate": 1640995200000, "mdate": 1683897653314, "content": {"title": "Optimal feedrate planning on a five-axis parametric tool path with global geometric and kinematic constraints", "abstract": ""}}
{"id": "yp0W1LJ_LB0", "cdate": 1640995200000, "mdate": 1683897653393, "content": {"title": "Isometric 3D Adversarial Examples in the Physical World", "abstract": "Recently, several attempts have demonstrated that 3D deep learning models are as vulnerable to adversarial example attacks as 2D models. However, these methods are still far from stealthy and suffer from severe performance degradation in the physical world. Although 3D data is highly structured, it is difficult to bound the perturbations with simple metrics in the Euclidean space. In this paper, we propose a novel $\\epsilon$-isometric ($\\epsilon$-ISO) attack method to generate natural and robust 3D adversarial examples in the physical world by considering the geometric properties of 3D objects and the invariance to physical transformations. For naturalness, we constrain the adversarial example and the original one to be $\\epsilon$-isometric by adopting the Gaussian curvature as the surrogate metric under a theoretical analysis. For robustness under physical transformations, we propose a maxima over transformation (MaxOT) method to actively search for the most difficult transformations rather than random ones to make the generated adversarial example more robust in the physical world. Extensive experiments on typical point cloud recognition models validate that our approach can improve the attack success rate and naturalness of the generated 3D adversarial examples than the state-of-the-art attack methods."}}
{"id": "tL-ygs6ZIuh", "cdate": 1640995200000, "mdate": 1683897653393, "content": {"title": "Proving Information Inequalities and Identities with Symbolic Computation", "abstract": "Proving linear inequalities and identities of Shannon's information measures, possibly with linear constraints on the information measures, is an important problem in information theory. For this purpose, ITIP and other variant algorithms have been developed and implemented, which are all based on solving a linear program (LP). In particular, an identity $f = 0$ is verified by solving two LPs, one for $f \\ge 0$ and one for $f \\le 0$. In this paper, we develop a set of algorithms that can be implemented by symbolic computation. Based on these algorithms, procedures for verifying linear information inequalities and identities are devised. Compared with LP-based algorithms, our procedures can produce analytical proofs that are both human-verifiable and free of numerical errors. Our procedures are also more efficient computationally. For constrained inequalities, by taking advantage of the algebraic structure of the problem, the size of the LP that needs to be solved can be significantly reduced. For identities, instead of solving two LPs, the identity can be verified directly with very little computation."}}
