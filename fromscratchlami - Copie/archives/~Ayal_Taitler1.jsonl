{"id": "IZvilh8LqN", "cdate": 1701378270515, "mdate": 1701378270515, "content": {"title": "eMARLIN: Distributed Coordinated Adaptive Traffic Signal Control with Topology-Embedding Propagation", "abstract": "In this paper, we examine the practical problem of minimizing the delay in traffic networks that are controlled at each intersection independently, without a centralized supervisory computer and with limited communication bandwidth. We find that existing learning algorithms have lackluster performance or are too computationally complex to be implemented in the field. Instead, we introduce a simple yet efficient and effective approach using multi-agent reinforcement learning (MARL) that applies the Deep Q-Network (DQN) learning algorithm in a fully decentralized setting. First, we decouple the DQN into per-intersection Q-networks and then transmit the output of each Q-network\u2019s hidden layer to its intersection neighbors. We show that our method is computationally efficient compared with other MARL methods, with minimal additional overhead compared with a naive isolated learning approach with no communication. This property enables our method to be implemented in real-world scenarios with less computation power. Finally, we conduct experiments for both synthetic and real-world scenarios and show that our method achieves better performance in minimizing intersection delay than other methods."}}
{"id": "WSv2Ir9YS1X", "cdate": 1701378175878, "mdate": 1701378175878, "content": {"title": "Unspread the Jam: Scheduling Traffic Lights to Reduce Congestion", "abstract": "In this paper, we consider the practical problem of scheduling traffic lights to reduce the average vehicle waiting times. We find that existing scheduling algorithms have lackluster performance. Instead, we introduce two algorithms. First, extended CMSM (eCMSM), which extends CMSM from a switch scheduling model to a general traffic-light scheduling model. We prove that eCMSM can optimally schedule any traffic batch. Second, we introduce Front-Pressure (FP), which aims to further reduce the average waiting time at general intersections. We then evaluate empirically these two algorithms. We find that when using them, the best average waiting time can be improved in 98% of the simulations when compared to several existing algorithms, most significantly in congested settings."}}
{"id": "WXF03hwvto", "cdate": 1701377840926, "mdate": 1701377840926, "content": {"title": "Perimeter Control Using Deep Reinforcement Learning: A Model-free Approach towards Homogeneous Flow Rate Optimization", "abstract": "Perimeter control maintains high traffic efficiency within protected regions by controlling transfer flows among regions to ensure that their traffic densities are below critical values. Existing approaches can be categorized as either model-based or model-free, depending on whether they rely on network transmission models (NTMs) and macroscopic fundamental diagrams (MFDs). Although model-based approaches are more data efficient and have performance guarantees, they are inherently prone to model bias and inaccuracy. For example, NTMs often become imprecise for a large number of protected regions, and MFDs can exhibit scatter and hysteresis that are not captured in existing model-based works. Moreover, no existing studies have employed reinforcement learning for homogeneous flow rate optimization in microscopic simulation, where spatial characteristics, vehicle-level information, and metering realizations -- often overlooked in macroscopic simulations -- are taken into account. To circumvent issues of model-based approaches and macroscopic simulation, we propose a model-free deep reinforcement learning approach that optimizes the flow rate homogeneously at the perimeter at the microscopic level. Results demonstrate that our model-free reinforcement learning approach without any knowledge of NTMs or MFDs can compete and match the performance of a model-based approach, and exhibits enhanced generalizability and scalability."}}
{"id": "wV6RlK51sn-", "cdate": 1701377638250, "mdate": 1701377638250, "content": {"title": "A2D: Anywhere Anytime Drumming", "abstract": "The drum kit, which has only been around for around 100 years, is a popular instrument in many music genres such as pop, rock, and jazz. However, the road to owning a kit is expensive, both financially and space-wise. Also, drums are more difficult to move around compared to other instruments, as they do not fit into a single bag. We propose a no-drums approach that uses only two sticks and a smartphone or a webcam to provide an air-drumming experience. The detection algorithm combines deep learning tools with tracking methods for an enhanced user experience. Based on both quantitative and qualitative testing with humans-in-the-loop, we show that our system has zero misses for beginner level play and negligible misses for advanced level play. Additionally, our limited human trials suggest potential directions for future research."}}
{"id": "WDLImGbc0O", "cdate": 1701377235102, "mdate": null, "content": {"title": "Combined time and energy optimal trajectory planning with quadratic drag for mixed discrete-continuous task planning", "abstract": "The problem of mixed discrete-continuous task planning for mechanical systems, such as aerial drones or other autonomous units, can be often treated as a sequence of point-to-point trajectories. In this work, the problem of optimal trajectory planning under a combined completion time and energy criterion, for a straight point to point path for a second-order system with quadratic under state (velocity) and control (acceleration) constraints is considered. The solution is obtained and proved to be optimal using the Pontryagin Maximum Principle. Simulation results for different cases are presented and compared with a customary numerical optimal control solver."}}
{"id": "hnOor9h3nyos", "cdate": 1640995200000, "mdate": 1671554344892, "content": {"title": "pyRDDLGym: From RDDL to Gym Environments", "abstract": "We present pyRDDLGym, a Python framework for auto-generation of OpenAI Gym environments from RDDL declerative description. The discrete time step evolution of variables in RDDL is described by conditional probability functions, which fits naturally into the Gym step scheme. Furthermore, since RDDL is a lifted description, the modification and scaling up of environments to support multiple entities and different configurations becomes trivial rather than a tedious process prone to errors. We hope that pyRDDLGym will serve as a new wind in the reinforcement learning community by enabling easy and rapid development of benchmarks due to the unique expressive power of RDDL. By providing explicit access to the model in the RDDL description, pyRDDLGym can also facilitate research on hybrid approaches for learning from interaction while leveraging model knowledge. We present the design and built-in examples of pyRDDLGym, and the additions made to the RDDL language that were incorporated into the framework."}}
{"id": "dzRcozDn9O", "cdate": 1640995200000, "mdate": 1681651548023, "content": {"title": "Time optimal control of a non-linear surface vehicle subject to disturbances", "abstract": ""}}
{"id": "0FT2-qWC4y", "cdate": 1640995200000, "mdate": 1681651548028, "content": {"title": "Minimum Mixed Time-Energy Trajectory Planning of a Nonlinear Vehicle Subject to 2D Disturbances", "abstract": ""}}
{"id": "cGFQyMmX-a", "cdate": 1609459200000, "mdate": 1681651548026, "content": {"title": "Automatic Generation of Flexible Plans via Diverse Temporal Planning", "abstract": ""}}
{"id": "_RB2UNnUENa", "cdate": 1609459200000, "mdate": 1681651548028, "content": {"title": "SOLO: Search Online, Learn Offline for Combinatorial Optimization Problems", "abstract": ""}}
