{"id": "O4lWP6F9Bn", "cdate": 1682899200000, "mdate": 1695951094242, "content": {"title": "Concept Drift Detection Delay Index", "abstract": "Data streams may encounter data distribution changes, which can significantly impair the accuracy of models. Concept drift detection tracks data distribution changes and signals when to update models. Many drift detection methods apply thresholds to distinguish between drift or non-drift streams and to claim their method outperforms others with non-aligned drift thresholds. We consider that selecting a proper drift threshold could be more important than developing a new drift detection algorithm, and different drift detection algorithms may end up with very similar performance with aligned drift thresholds. To better understand this process, we propose a novel threshold selection algorithm to align the drift thresholds of a set of algorithms so that they are all at the same sensitivity level. Based on comprehensive experiment evaluations, we observed that several state-of-the-art drift detection algorithms could achieve similar results by aligning their thresholds, providing a novel insight to explain how drift detection algorithms contribute to data stream learning. We noticed that a higher detection sensitivity improves accuracy for data streams with frequent distribution change. The evaluation results are showing that drift thresholds should not be fixed during stream learning. Rather, they should adjust dynamically based on the prevailing conditions of the data stream."}}
{"id": "-xfwSaifkU", "cdate": 1681833044435, "mdate": null, "content": {"title": "Indirect Functional Bayesian Neural Networks", "abstract": "Bayesian neural networks (BNNs) have made significant contributions in improving the robustness and uncertainty quantification of deep neural networks but suffer from problematic priors for network weights. We propose a new kind of indirect functional BNNs (IFBNN) by building a Wasserstein bridge, which consists of a 2-Wasserstein distance between the approximate posterior and a bridging distribution of network weights, and a 1-Wasserstein distance between the bridging distribution over functions induced by weight distributions and a functional GP prior. It can avoid the potential risks of invalid or infinite functional KL divergence commonly used by most existing functional BNNs. We demonstrate the improved extrapolation and predictive performances of the proposed IFBNN empirically on both synthetic and real-world datasets."}}
{"id": "ko0N5hiSCej", "cdate": 1677628800000, "mdate": 1676861161655, "content": {"title": "Direct Learning With Multi-Task Neural Networks for Treatment Effect Estimation", "abstract": ""}}
{"id": "iyqZ0bp7saC", "cdate": 1677628800000, "mdate": 1695951094208, "content": {"title": "DAFS: a domain aware few shot generative model for event detection", "abstract": "More and more, large-scale pre-trained models show apparent advantages in solving the event detection (ED), i.e., a task to solve the problem of event classification by identifying trigger words. However, this kind of model depends heavily on labeled training data. Unfortunately, there is not enough such data for some particular areas, such as finance, due to the high cost of the data annotation process. Besides, the manually labeled training data has many problems like uneven sampling distribution, poor diversity, and massive long-tail data. Recently, some researchers have used the generative model to label data. However, training the generative models needs rich domain knowledge, which cannot be obtained from a Few-Shot resource. Therefore, we propose a Domain-Aware Few-Shot (DAFS) generative model that can generate domain based training data through a relatively small amount of labeled data. First, DAFS utilizes self-supervised information from various categories of sentences to calculate words\u2019 transition probability under different domain and retain key triggers in each sentence. Then, we apply our joint algorithm to generate labeled training data that considers both diversity and effectiveness. Experimental results demonstrate that the training data generated by DAFS significantly improves the performance of ED in actual financial data. Especially when there are no more than 20 training data, DAFS can still ensure the generative quality to a certain extent. It also obtains new state-of-the-art results on ACE2005 multilingual corpora."}}
{"id": "mp-Lc-TEms", "cdate": 1672531200000, "mdate": 1695951094264, "content": {"title": "An Autonomous Non-monolithic Agent with Multi-mode Exploration based on Options Framework", "abstract": "Most exploration research on reinforcement learning (RL) has paid attention to \u2018the way of exploration\u2019, which is \u2018how to explore\u2019. The other exploration research, \u2018when to explore\u2019, has not been the main focus of RL exploration research. The issue of \u2018when\u2019 of a monolithic exploration in the usual RL exploration behaviour binds an exploratory action to an exploitational action of an agent. Recently, a non-monolithic exploration research has emerged to examine the mode-switching exploration behaviour of humans and animals. The ultimate purpose of our research is to enable an agent to decide when to explore or exploit autonomously. We describe the initial research of an autonomous multi-mode exploration of non-monolithic behaviour in an options framework. The higher performance of our method is shown against the existing non-monolithic exploration method through comparative experimental results."}}
{"id": "_TZKazdlVJ", "cdate": 1672531200000, "mdate": 1695951094253, "content": {"title": "An Autonomous Non-monolithic Agent with Multi-mode Exploration based on Options Framework", "abstract": "Most exploration research on reinforcement learning (RL) has paid attention to `the way of exploration', which is `how to explore'. The other exploration research, `when to explore', has not been the main focus of RL exploration research. The issue of `when' of a monolithic exploration in the usual RL exploration behaviour binds an exploratory action to an exploitational action of an agent. Recently, a non-monolithic exploration research has emerged to examine the mode-switching exploration behaviour of humans and animals. The ultimate purpose of our research is to enable an agent to decide when to explore or exploit autonomously. We describe the initial research of an autonomous multi-mode exploration of non-monolithic behaviour in an options framework. The higher performance of our method is shown against the existing non-monolithic exploration method through comparative experimental results."}}
{"id": "YZ2UCDv_HOi", "cdate": 1672531200000, "mdate": 1695951094197, "content": {"title": "A Determinantal Point Process Based Novel Sampling Method of Abstractive Text Summarization", "abstract": "In recent years abstractive text summarization (ATS) research has made considerable progress attributed to two key improvements, deep neural modeling and likelihood estimation based sampling, in the end-to-end optimization training. While modeling has grounded on a few de facto highly capable base models within encoder-decoder architecture, novel sampling ideas, such as random masking classification and generative prediction by unsupervised learning, have also been explored. They aim at improving prior knowledge, particularly of language modeling for downstream tasks. It has led to the notable performance gain of ATS. But several challenges remain, for example, undesirable word repeats. In this paper, we propose a determinantal point process (DPP) based novel sampling method to address the issue. It can be easily integrated with the existing ATS models. Our experiments and subsequent analysis have revealed that the adopted models trained by our sampling method reduce undesirable word repeats and improve word coverage while achieving competitive ROUGE scores."}}
{"id": "Vn1xRZhG0I", "cdate": 1672531200000, "mdate": 1695951094254, "content": {"title": "Improving proximal policy optimization with alpha divergence", "abstract": ""}}
{"id": "Qz3A1HAaPlh", "cdate": 1672531200000, "mdate": 1708512962002, "content": {"title": "Transformed Successor Features for Transfer Reinforcement Learning", "abstract": "Reinforcement learning algorithms require an extensive number of samples to perform a specific task. To achieve the same performance on a new task, the agent must learn from scratch. Transfer reinforcement learning is an emerging solution that aims to improve sample efficiency by reusing previously learnt knowledge in new tasks. Successor feature is a technique aiming to reuse representations to leverage that knowledge in unseen tasks. Successor feature has achieved outstanding results on the assumption that the transition dynamics must remain across tasks. Initial Successor feature approach omits settings with different environment dynamics, common among real-life tasks in reinforcement learning problems. Our approach transformed successor feature projects a set of diverse dynamics into a common dynamic distribution. Hence, it is an initial solution to relax the restriction of transference across fixed environment dynamics. Experimental results indicate that the transformed successor feature improves the transfer of knowledge in environments with fixed and diverse dynamics under the control of a simulated robotic arm, a robotic leg, and the cartpole environment."}}
{"id": "KVMLcLVawr", "cdate": 1672531200000, "mdate": 1708512962003, "content": {"title": "Mitigating Intrinsic Named Entity-Related Hallucinations of Abstractive Text Summarization", "abstract": ""}}
