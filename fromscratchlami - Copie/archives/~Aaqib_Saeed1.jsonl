{"id": "jNztKY6Z-f", "cdate": 1672531200000, "mdate": 1695972908166, "content": {"title": "Plug-and-Play Multilingual Few-shot Spoken Words Recognition", "abstract": "As technology advances and digital devices become prevalent, seamless human-machine communication is increasingly gaining significance. The growing adoption of mobile, wearable, and other Internet of Things (IoT) devices has changed how we interact with these smart devices, making accurate spoken words recognition a crucial component for effective interaction. However, building robust spoken words detection system that can handle novel keywords remains challenging, especially for low-resource languages with limited training data. Here, we propose PLiX, a multilingual and plug-and-play keyword spotting system that leverages few-shot learning to harness massive real-world data and enable the recognition of unseen spoken words at test-time. Our few-shot deep models are learned with millions of one-second audio clips across 20 languages, achieving state-of-the-art performance while being highly efficient. Extensive evaluations show that PLiX can generalize to novel spoken words given as few as just one support example and performs well on unseen languages out of the box. We release models and inference code to serve as a foundation for future research and voice-enabled user interface development for emerging devices."}}
{"id": "1nev4IaZH-l", "cdate": 1672531200000, "mdate": 1695972908165, "content": {"title": "The Augmented Image Prior: Distilling 1000 Classes by Extrapolating from a Single Image", "abstract": ""}}
{"id": "l8CpLrSaJy", "cdate": 1667260800000, "mdate": 1681660567266, "content": {"title": "Federated Self-training for Semi-supervised Audio Recognition", "abstract": "Federated Learning is a distributed machine learning paradigm dealing with decentralized and personal datasets. Since data reside on devices such as smartphones and virtual assistants, labeling is entrusted to the clients or labels are extracted in an automated way. Specifically, in the case of audio data, acquiring semantic annotations can be prohibitively expensive and time-consuming. As a result, an abundance of audio data remains unlabeled and unexploited on users\u2019 devices. Most existing federated learning approaches focus on supervised learning without harnessing the unlabeled data. In this work, we study the problem of semi-supervised learning of audio models via self-training in conjunction with federated learning. We propose\u00a0FedSTAR to exploit large-scale on-device unlabeled data to improve the generalization of audio recognition models. We further demonstrate that self-supervised pre-trained models can accelerate the training of on-device models, significantly improving convergence within fewer training rounds. We conduct experiments on diverse public audio classification datasets and investigate the performance of our models under varying percentages of labeled and unlabeled data. Notably, we show that with as little as 3% labeled data available,\u00a0FedSTAR\u00a0on average can improve the recognition rate by 13.28% compared to the fully supervised federated model."}}
{"id": "gNHMC4I0Pva", "cdate": 1665081437902, "mdate": null, "content": {"title": "Federated Learning with Noisy Labels: Achieving Generalization in the Face of Label Noise", "abstract": "Federated Learning (FL) is a distributed machine learning paradigm that enables learning models from decentralized private datasets, where the labeling effort is entrusted to the clients.\u00a0While most existing FL approaches assume high-quality labels are readily available on users' devices;\u00a0in reality,\u00a0label noise can naturally occur in FL and follows a non-i.i.d. distribution among clients.\u00a0Due to the ``non-iid-ness''\u00a0challenges, existing state-of-the-art centralized approaches\u00a0exhibit\u00a0unsatisfactory performance, while previous FL studies rely on data exchange\u00a0or\u00a0repeated server-side aid to improve\u00a0model's\u00a0performance.\u00a0Here,\u00a0we propose FedLN,\u00a0a framework to deal with label noise across different FL training stages; namely, FL initialization, and server-side model aggregation. Extensive experiments on various publicly available vision and audio datasets\u00a0demonstrate an improvement of 24% on average\u00a0compared to state-of-the-art methods\u00a0for a label noise level of 70%.\u00a0"}}
{"id": "mW2iLEJ1hq", "cdate": 1664806781381, "mdate": null, "content": {"title": "Automatic Sleep Scoring from Large-scale Multi-channel Pediatric EEG", "abstract": " Sleep is particularly important to the health of infants, children, and adolescents, and sleep scoring is the first step to accurate diagnosis and treatment of potentially life-threatening conditions. But pediatric sleep is severely under-researched compared to adult sleep in the context of machine learning for health, and sleep scoring algorithms developed for adults usually perform poorly on infants. Here, we present the first automated sleep scoring results on a recent large-scale pediatric sleep study dataset that was collected during standard clinical care. We develop a transformer-based model that learns to classify five sleep stages from millions of multi-channel electroencephalogram (EEG) sleep epochs with 78% overall accuracy. Further, we conduct an in-depth analysis of the model performance based on patient demographics and EEG channels. The results point to the growing need for machine learning research on pediatric sleep."}}
{"id": "6kxApT2r2i", "cdate": 1663849807643, "mdate": null, "content": {"title": "The Augmented Image Prior: Distilling 1000 Classes by Extrapolating from a Single Image", "abstract": "What can neural networks learn about the visual world when provided with only a single image as input? While any image obviously cannot contain the multitudes of all existing objects, scenes and lighting conditions -- within the space of all  $256^{3\\cdot224\\cdot224}$ possible $224$-sized square images, it might still provide a strong prior for natural images. To analyze this ``augmented image prior''  hypothesis, we develop a simple framework for training neural networks from scratch using a single image and augmentations using knowledge distillation from a supervised pretrained teacher. With this, we find the answer to the above question to be: `surprisingly, a lot'. In quantitative terms, we find accuracies of $94\\%$/$74\\%$ on CIFAR-10/100, $69$\\% on ImageNet, and by extending this method to video and audio, $51\\%$ on Kinetics-400 and $84$\\% on SpeechCommands. In extensive analyses spanning 13 datasets, we disentangle the effect of augmentations, choice of data and network architectures and also provide qualitative evaluations that include lucid ``panda neurons'' in networks that have never even seen one. "}}
{"id": "tBhvNfHClp", "cdate": 1640995200000, "mdate": 1681660567268, "content": {"title": "COCOA: Cross Modality Contrastive Learning for Sensor Data", "abstract": "Self-Supervised Learning (SSL) is a new paradigm for learning discriminative representations without labelled data and has reached comparable or even state-of-the-art results in comparison to supervised counterparts. Contrastive Learning (CL) is one of the most well-known approaches in SSL that attempts to learn general, informative representations of data. CL methods have been mostly developed for applications in computer vision and natural language processing where only a single sensor modality is used. A majority of pervasive computing applications, however, exploit data from a range of different sensor modalities. While existing CL methods are limited to learning from one or two data sources, we propose COCOA (Cross mOdality COntrastive leArning), a self-supervised model that employs a novel objective function to learn quality representations from multisensor data by computing the cross-correlation between different data modalities and minimizing the similarity between irrelevant instances. We evaluate the effectiveness of COCOA against eight recently introduced state-of-the-art self-supervised models, and two supervised baselines across five public datasets. We show that COCOA achieves superior classification performance to all other approaches. Also, COCOA is far more label-efficient than the other baselines including the fully supervised model using only one-tenth of available labelled data."}}
{"id": "pfA0j4smsq", "cdate": 1640995200000, "mdate": 1681660567271, "content": {"title": "Pediatric Sleep Scoring In-the-wild from Millions of Multi-channel EEG Signals", "abstract": "Sleep is particularly important to the health of infants, children, and adolescents, and sleep scoring is the first step to accurate diagnosis and treatment of potentially life-threatening conditions. But pediatric sleep is severely under-researched compared to adult sleep in the context of machine learning for health, and sleep scoring algorithms developed for adults usually perform poorly on infants. Here, we present the first automated sleep scoring results on a recent large-scale pediatric sleep study dataset that was collected during standard clinical care. We develop a transformer-based model that learns to classify five sleep stages from millions of multi-channel electroencephalogram (EEG) sleep epochs with 78% overall accuracy. Further, we conduct an in-depth analysis of the model performance based on patient demographics and EEG channels. The results point to the growing need for machine learning research on pediatric sleep."}}
{"id": "ovyeNDZjJUT", "cdate": 1640995200000, "mdate": 1681660567271, "content": {"title": "Federated Learning with Noisy Labels", "abstract": "Federated Learning (FL) is a distributed machine learning paradigm that enables learning models from decentralized private datasets, where the labeling effort is entrusted to the clients. While most existing FL approaches assume high-quality labels are readily available on users' devices; in reality, label noise can naturally occur in FL and is closely related to clients' characteristics. Due to scarcity of available data and significant label noise variations among clients in FL, existing state-of-the-art centralized approaches exhibit unsatisfactory performance, while prior FL studies rely on excessive on-device computational schemes or additional clean data available on server. Here, we propose FedLN, a framework to deal with label noise across different FL training stages; namely, FL initialization, on-device model training, and server model aggregation, able to accommodate the diverse computational capabilities of devices in a FL system. Specifically, FedLN computes per-client noise-level estimation in a single federated round and improves the models' performance by either correcting or mitigating the effect of noisy samples. Our evaluation on various publicly available vision and audio datasets demonstrate a 22% improvement on average compared to other existing methods for a label noise level of 60%. We further validate the efficiency of FedLN in human-annotated real-world noisy datasets and report a 4.8% increase on average in models' recognition performance, highlighting that~\\method~can be useful for improving FL services provided to everyday users."}}
{"id": "joEvN3eNmj", "cdate": 1640995200000, "mdate": 1681660567404, "content": {"title": "Active Learning of Non-semantic Speech Tasks with Pretrained Models", "abstract": "Pretraining neural networks with massive unlabeled datasets has become popular as it equips the deep models with a better prior to solve downstream tasks. However, this approach generally assumes that the downstream tasks have access to annotated data of sufficient size. In this work, we propose ALOE, a novel system for improving the data- and label-efficiency of non-semantic speech tasks with active learning. ALOE uses pretrained models in conjunction with active learning to label data incrementally and learn classifiers for downstream tasks, thereby mitigating the need to acquire labeled data beforehand. We demonstrate the effectiveness of ALOE on a wide range of tasks, uncertainty-based acquisition functions, and model architectures. Training a linear classifier on top of a frozen encoder with ALOE is shown to achieve performance similar to several baselines that utilize the entire labeled data."}}
