{"id": "rsFGdFRQ0DF", "cdate": 1640995200000, "mdate": 1668690711634, "content": {"title": "Adaptive Wavelet Transformer Network for 3D Shape Representation Learning", "abstract": "We present a novel method for 3D shape representation learning using multi-scale wavelet decomposition. Previous works often decompose 3D shapes into complementary components in spatial domain at a..."}}
{"id": "qKSQXHfWIku", "cdate": 1640995200000, "mdate": 1696224143429, "content": {"title": "Non-Rigid Multiple Point Set Registration Using Latent Gaussian Mixture", "abstract": "Point set registration is a fundamental task in 3D computer vision. Existing registration approaches mainly focus on either pair-wise or rigid registration. In this paper, we propose a robust group-wise registration method from a probabilistic view and adopt non-rigid transformations to register multiple point sets without bias toward any given set. The proposed method lessens the need of point correspondences by representing each point set as Gaussian Mixture Model and the registration is equivalent to multiple distributions alignment. Closed-form of Jensen-R\u00e9nyi divergence and L <inf xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">2</inf> distance are used as cost functions. We further design a neural network to extract correspondences between raw point sets and Gaussian Mixture Model (GMM) parameters, and recover the optimal diffeomorphic non-rigid transformations from the matched GMM parameters. The proposed method is compared against two well-known probabilistic methods for group-wise point-set registration on several public 2D and 3D datasets. The results demonstrate that our method improves registration accuracy."}}
{"id": "mp9aUCIxHQO", "cdate": 1640995200000, "mdate": 1668690711578, "content": {"title": "SHREC 2022: Protein-ligand binding site recognition", "abstract": ""}}
{"id": "kc5xcU_qAa", "cdate": 1640995200000, "mdate": 1683930381447, "content": {"title": "3D Point Cloud Completion with Geometric-Aware Adversarial Augmentation", "abstract": "With the popularity of 3D sensors in self-driving and other robotics applications, extensive research has focused on designing novel neural network architectures for accurate 3D point cloud completion. However, unlike point cloud classification and reconstruction, the role of adversarial samples in 3D point cloud completion has seldom been explored. In this work, we demonstrate that adversarial samples can benefit neural networks on 3D point cloud completion tasks. We propose a novel approach to craft adversarial samples that improve the performance of models on both clean and adversarial inputs. In contrast to the Projected Gradient Descent (PGD) attack, our method generates adversarial samples that keep the geometric features in clean samples and contain few outliers. In particular, we use minimum absolute curvature directions to constrain the adversarial perturbations for each input point. The gradient components in the minimum absolute curvature directions are taken as adversarial perturbations. In addition, we adopt attack strength accumulation and auxiliary Batch Normalization layers to speed up the training process and alleviate the distribution mismatch between clean and adversarial samples. Experimental results demonstrate that training with the adversarial samples crafted by our method under the geometric-aware constraint effectively enhances the performance of the Point Completion Network (PCN) on the ShapeNet dataset."}}
{"id": "eDXEsjQC6E", "cdate": 1640995200000, "mdate": 1682404182105, "content": {"title": "Unsupervised 3D Shape Representation Learning Using Normalizing Flow", "abstract": "Learning robust and compact shape representation learning plays an important role in many 3D vision tasks. Existing supervised learning-based methods have achieved remarkable performance, meanwhile requiring large-scale human-annotated datasets for model training. Self-supervised/unsupervised methods provide an attractive solution to this issue that can learn shape representations without the need for ground truth labels. In this paper, we introduce a novel self-supervised method for shape representation learning using normalizing flows. Specifically, we build a model upon a variational normalizing flow framework where a sequence of normalizing flow layers are adopted to model exact posterior latent distribution and enhance the representation power of the learned latent code. To further encourage inter-shape separability and intra-shape compactness among a batch of shapes, we design a contrastive-center loss that performs metric learning on features on a hypersphere. We validate the representation learning ability of our model on downstream classification tasks. Experiments on ModelNet40/10, ScanobjectNN, and ScanNet datasets demonstrate the superior performance of our method compared with current state-of-the-art methods."}}
{"id": "G2RrZ4Wlpk", "cdate": 1640995200000, "mdate": 1682490270957, "content": {"title": "Meta-Det3D: Learn to Learn Few-Shot 3D Object Detection", "abstract": "This paper addresses the problem of few-shot indoor 3D object detection by proposing a meta-learning-based framework that only relies on a few labeled samples from novel classes for training. Our model has two major components: a 3D meta-detector and a 3D object detector. Given a query 3D point cloud and a few support samples, the 3D meta-detector is trained over different 3D detection tasks to learn task distributions for different object classes and dynamically adapt the 3D object detector to complete a specific detection task. The 3D object detector takes task-specific information as input and produces 3D object detection results for the query point cloud. Specifically, the 3D object detector first extracts object candidates and their features from the query point cloud using a point feature learning network. Then, a class-specific re-weighting module generates class-specific re-weighting vectors from the support samples to characterize the task information, one for each distinct object class. Each re-weighting vector performs channel-wise attention to the candidate features to re-calibrate the query object features, adapting them to detect objects of the same classes. Finally, the adapted features are fed into a detection head to predict classification scores and bounding boxes for novel objects in the query point cloud. Several experiments on two 3D object detection benchmark datasets demonstrate that our proposed method acquired the ability to detect 3D objects in the few-shot setting."}}
{"id": "-k0OGvP_2j", "cdate": 1640995200000, "mdate": 1668690711579, "content": {"title": "Manifold Adversarial Learning for Cross-domain 3D Shape Representation", "abstract": "On a variety of 3D vision tasks, deep neural networks (DNNs) for point clouds have outperformed the conventional non-learning-based methods. However, generalization to out-of-distribution 3D point clouds remains challenging for DNNs. As annotating large-scale point clouds is prohibitively expensive or even impossible, strategies for generalizing DNN models to unseen domains of point clouds without access to those domains during training are urgently needed but have yet to be substantially investigated. In this paper, we design an adversarial learning scheme to learn point cloud representation on a seen source domain and then generalize the learned knowledge to an unseen target domain. Specifically, we unify several geometric transformations into a manifold-based framework under which a distance between transformations is well-defined. Measured by the distance, adversarial samples are mined to form intermediate domains and retained in an adaptive replay-based memory. We further provide theoretical justification for the intermediate domains to reduce the generalization error of the DNN models. Experimental results on synthetic-to-real datasets illustrate that our method outperforms existing 3D deep learning models for domain generalization."}}
{"id": "5MLb3cLCJY", "cdate": 1632875709497, "mdate": null, "content": {"title": "Adaptive Wavelet Transformer Network for 3D Shape Representation Learning", "abstract": "We present a novel method for 3D shape representation learning using multi-scale wavelet decomposition. Previous works often decompose 3D shapes into complementary components in spatial domain at a single scale. In this work, we study to decompose 3D shapes into sub-bands components in frequency domain at multiple scales, resulting in a hierarchical decomposition tree in a principled manner rooted in multi-resolution wavelet analysis. Specifically, we propose Adaptive Wavelet Transformer Network (AWT-Net) that firstly generates approximation or detail wavelet coefficients per point, classifying each point into high or low sub-bands components, using lifting scheme at multiple scales recursively and hierarchically. Then, AWT-Net exploits Transformer to enhance the original shape features by querying and fusing features from different but integrated sub-bands. The wavelet coefficients can be learned without direct supervision on coefficients, and AWT-Net is fully differentiable and can be learned in an end-to-end fashion. Extensive experiments demonstrate that AWT-Net achieves competitive performance on 3D shape classification and segmentation benchmarks."}}
{"id": "PgGLVXlFvzr", "cdate": 1609459200000, "mdate": 1668690711633, "content": {"title": "Residual Networks as Flows of Velocity Fields for Diffeomorphic Time Series Alignment", "abstract": "Non-linear (large) time warping is a challenging source of nuisance in time-series analysis. In this paper, we propose a novel diffeomorphic temporal transformer network for both pairwise and joint time-series alignment. Our ResNet-TW (Deep Residual Network for Time Warping) tackles the alignment problem by compositing a flow of incremental diffeomorphic mappings. Governed by the flow equation, our Residual Network (ResNet) builds smooth, fluid and regular flows of velocity fields and consequently generates smooth and invertible transformations (i.e. diffeomorphic warping functions). Inspired by the elegant Large Deformation Diffeomorphic Metric Mapping (LDDMM) framework, the final transformation is built by the flow of time-dependent vector fields which are none other than the building blocks of our Residual Network. The latter is naturally viewed as an Eulerian discretization schema of the flow equation (an ODE). Once trained, our ResNet-TW aligns unseen data by a single inexpensive forward pass. As we show in experiments on both univariate (84 datasets from UCR archive) and multivariate time-series (MSR Action-3D, Florence-3D and MSR Daily Activity), ResNet-TW achieves competitive performance in joint alignment and classification."}}
{"id": "MOs3vl_lTi", "cdate": 1609459200000, "mdate": 1668690711629, "content": {"title": "G-VAE, a Geometric Convolutional VAE for ProteinStructure Generation", "abstract": "Analyzing the structure of proteins is a key part of understanding their functions and thus their role in biology at the molecular level. In addition, design new proteins in a methodical way is a major engineering challenge. In this work, we introduce a joint geometric-neural networks approach for comparing, deforming and generating 3D protein structures. Viewing protein structures as 3D open curves, we adopt the Square Root Velocity Function (SRVF) representation and leverage its suitable geometric properties along with Deep Residual Networks (ResNets) for a joint registration and comparison. Our ResNets handle better large protein deformations while being more computationally efficient. On top of the mathematical framework, we further design a Geometric Variational Auto-Encoder (G-VAE), that once trained, maps original, previously unseen structures, into a low-dimensional (latent) hyper-sphere. Motivated by the spherical structure of the pre-shape space, we naturally adopt the von Mises-Fisher (vMF) distribution to model our hidden variables. We test the effectiveness of our models by generating novel protein structures and predicting completions of corrupted protein structures. Experimental results show that our method is able to generate plausible structures, different from the structures in the training data."}}
