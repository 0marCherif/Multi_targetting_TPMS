{"id": "reZxJhLwYRK", "cdate": 1643898534741, "mdate": 1643898534741, "content": {"title": "Coupled Patch Similarity Network FOR One-Shot Fine-Grained Image Recognition", "abstract": "One-shot fine-grained image recognition (OSFG) aims to distinguish different fine-grained categories with only one training sample per category. Previous works mainly focus on learning a global feature representation through only a using single similarity metric branch, which is unsuitable for OSFG to effectively capture subtle and local differences under limited supervision. In this work, we propose a Coupled Patch Similarity Network (CPSN) for OSFG. Firstly, we propose a Feature Enhancement Module (FEM) to extract more\ndiscriminative features of the fine-grained samples. Then, we develop two coupled and symmetrical branches to capture discriminative parts of the samples and reduce the deviation of the distance metric. For each branch, we design a Patch Similarity Module (PSM) to calculate the patch similarity map for the sample pair. Especially, a Patch Weight Generator (PWG) is proposed to generate the patch weight map, which indicates the degree of importance for each position in the patch similarity map, so that the model can focus on diverse and informative parts. We analyze the effect of the different components in the proposed network, and extensive experimental results demonstrate the effectiveness and superiority of the proposed method on two fine-grained benchmark datasets."}}
{"id": "uz7P2Y75t-", "cdate": 1640995200000, "mdate": 1668762626883, "content": {"title": "High Dimensional Convolution Acceleration via Tensor Decomposition", "abstract": "The high-dimensional convolution, in either linear or nonlinear form, has been employed in a wide range of computer vision solutions due to its beneficial smoothing property. However, its full-kern..."}}
{"id": "bpH_-vP3Xut", "cdate": 1640995200000, "mdate": 1668762626884, "content": {"title": "iFlowGAN: An Invertible Flow-Based Generative Adversarial Network for Unsupervised Image-to-Image Translation", "abstract": "We propose iFlowGAN that learns an <i>invertible flow</i> (a sequence of invertible mappings) via <i>adversarial learning</i> and exploit it to transform a source distribution into a target distribution for <i>unsupervised image-to-image translation</i> . Existing GAN-based generative model such as CycleGAN [1], StarGAN [2], AGGAN [3] and CyCADA [4] needs to learn a highly under-constraint forward mapping <inline-formula><tex-math notation=\"LaTeX\">$\\mathcal {F}: X \\rightarrow Y$</tex-math></inline-formula> from a source domain <inline-formula><tex-math notation=\"LaTeX\">$X$</tex-math></inline-formula> to a target domain <inline-formula><tex-math notation=\"LaTeX\">$Y$</tex-math></inline-formula> . Researchers do this by assuming there is a backward mapping <inline-formula><tex-math notation=\"LaTeX\">$\\mathcal {B}: Y \\rightarrow X$</tex-math></inline-formula> such that <inline-formula><tex-math notation=\"LaTeX\">$\\boldsymbol{x}$</tex-math></inline-formula> and <inline-formula><tex-math notation=\"LaTeX\">$\\boldsymbol{y}$</tex-math></inline-formula> are fixed points of the composite functions <inline-formula><tex-math notation=\"LaTeX\">$\\mathcal {B} \\circ \\mathcal {F}$</tex-math></inline-formula> and <inline-formula><tex-math notation=\"LaTeX\">$\\mathcal {F} \\circ \\mathcal {B}$</tex-math></inline-formula> . Inspired by zero-order reverse filtering [5], we (1) understand <inline-formula><tex-math notation=\"LaTeX\">$\\mathcal {F}$</tex-math></inline-formula> via contraction mappings on a metric space; (2) provide a simple yet effective algorithm to present <inline-formula><tex-math notation=\"LaTeX\">$\\mathcal {B}$</tex-math></inline-formula> via the parameters of <inline-formula><tex-math notation=\"LaTeX\">$\\mathcal {F}$</tex-math></inline-formula> in light of Banach fixed point theorem; (3) provide a Lipschitz-regularized network which indicates a general approach to compose the inverse for arbitrary Lipschitz-regularized networks via Banach fixed point theorem. This network is useful for image-to-image translation tasks because it could save the memory for the weights of <inline-formula><tex-math notation=\"LaTeX\">$\\mathcal {B}$</tex-math></inline-formula> . Although memory can also be saved by directly coupling the weights of the forward and backward mappings, the performance of the image-to-image translation network degrades significantly. This explains why current GAN-based generative models including CycleGAN must take different parameters to compose the forward and backward mappings instead of employing the same weights to build both mappings. Taking advantage of the Lipschitz-regularized network, we not only build iFlowGAN to solve the redundancy shortcoming of CycleGAN but also assemble the corresponding iFlowGAN versions of StarGAN, AGGAN and CyCADA without breaking their network architectures. Extensive experiments show that the iFlowGAN version could produce comparable results of the original implementation while saving half parameters."}}
{"id": "PmXLW9iCJa", "cdate": 1640995200000, "mdate": 1668762626935, "content": {"title": "RMVAE: one-class classification via divergence regularization and maximization mutual information", "abstract": "One-class classification aims to learn the classifier from only one class of data. Variational auto-encoder (VAE) has been widely used in it. Trained on the normal samples, all the images reconstructed by the VAE in the test stage are similar to the normal samples. Thus, the VAE can produce higher reconstruction errors for abnormal samples than normal ones, which can be used as a classification criterion. However, the VAE can reconstruct abnormal samples well and produce lower reconstruction errors due to the model generalization. It leads to the wrong classification for the normal images. To alleviate this shortcoming of the VAE, we propose to use mutual information module and divergence regularization to enhance the VAE. The new model is called RMVAE. Firstly, we refer to the idea of contrast learning to maximize the mutual information between the input image and the corresponding latent representation so that the encoder can express the unique characteristics of the normal class. Besides, the attention mechanism is used in the encoder to enhance the feature extraction capabilities of the model. Secondly, we introduce divergence regularization to make the latent representation of the normal samples evenly distributed in the latent space. Extensive experiments demonstrate that the proposed method achieves a better effect against other state-of-the-art methods on the three public benchmark datasets."}}
{"id": "LcnjggOf_Tg", "cdate": 1640995200000, "mdate": 1668762627001, "content": {"title": "Monaural Musical Octave Sound Separation Using Relaxed Extended Common Amplitude Modulation", "abstract": "Monaural music sound separation isolates individual instrument sources from a mono-channel polyphonic mixture. The primary challenge is to separate the source partials overlapped in time-frequency ..."}}
{"id": "KuIupIJ2RAQ", "cdate": 1640995200000, "mdate": 1668762626906, "content": {"title": "Simultaneously Calibration of Tx/Rx Frequency Response and IQ Skew for Coherent Optical Transceiver", "abstract": "We report a calibration method that can simultaneously characterize frequency-response and IQ-skew of coherent optical transceivers with laser frequency offset and phase noise. 50/40GBaud Nyquist-16/64QAM signals transmission is achieved using 22GHz commercial coherent optical transceiver."}}
{"id": "9HdddwRwu3", "cdate": 1640995200000, "mdate": 1668762626888, "content": {"title": "A selection function for pitched instrument source separation", "abstract": "There exist a large number of methods for pitched instrument source separation. The core problem is to separate the time-frequency overlapping harmonics. To yield better results, we propose a function to select fine harmonic separation results from existing methods. Our strategy is based on the discovery that a fine separation result usually has a low total amplitude fluctuation. For source harmonics overlapped in a frequency band, each method produces a separation result. Employing the harmonics separated by each method, we can estimate the total amplitude fluctuation of each group of overlapping harmonics. Our selection function maps the band index to the method index by selecting the method with the minimum total amplitude fluctuation. Experiments are conducted on sample mixtures from the University of Iowa Musical Instrument Sample Database. Three advanced separation techniques are compared, including common amplitude modulation (CAM), harmonic bandwidth companding (HBW-comp) and ideal binary mask (IBM) filtering. Experiment results indicate that the proposed selection function is able to boost the separation performance significantly."}}
{"id": "IuqKBVdQCP", "cdate": 1609459200000, "mdate": 1668762626834, "content": {"title": "MAT-Net: Representing Appearance-Irrelevant Warp Field by Multiple Affine Transformations", "abstract": "Warp-based methods for image animation estimate a warp field what do a rearrangement on the pixels of the input image to roughly align with the target image. Current methods predict accurate warp field by using manually annotated data. In this paper, we propose a simple method (MAT-net) to predict more precise warp field in self-supervised way. MAT-net decomposes complex spatial object movement between two images into multiple simple local motions (i.e. affine transformation) occurring in different areas of images. Sequentially, our model calculates a warp field depicting complex object movement by combining all local motions. MAT-net encodes appearance-irrelevant object movement accurately. Compared to the state-of-the-art method, MAT-net generates more realistic images with faster inference speed. We published the source code of our project online."}}
{"id": "A40aPwpovi2", "cdate": 1609459200000, "mdate": 1668762626865, "content": {"title": "Coupled Patch Similarity Network FOR One-Shot Fine-Grained Image Recognition", "abstract": "One-shot fine-grained image recognition (OSFG) aims to distinguish different fine-grained categories with only one training sample per category. Previous works mainly focus on learning a global feature representation through only a using single similarity metric branch, which is unsuitable for OSFG to effectively capture subtle and local differences under limited supervision. In this work, we propose a Coupled Patch Similarity Network (CPSN) for OSFG. Firstly, we propose a Feature Enhancement Module (FEM) to extract more discriminative features of the fine-grained samples. Then, we develop two coupled and symmetrical branches to capture discriminative parts of the samples and reduce the deviation of the distance metric. For each branch, we design a Patch Similarity Module (PSM) to calculate the patch similarity map for the sample pair. Especially, a Patch Weight Generator (PWG) is proposed to generate the patch weight map, which indicates the degree of importance for each position in the patch similarity map, so that the model can focus on diverse and informative parts. We analyze the effect of the different components in the proposed network, and extensive experimental results demonstrate the effectiveness and superiority of the proposed method on two fine-grained benchmark datasets."}}
{"id": "24ed7wprX3", "cdate": 1609459200000, "mdate": 1668762626903, "content": {"title": "Robust Kernelized Multiview Self-Representation for Subspace Clustering", "abstract": "In this article, we propose a multiview self-representation model for nonlinear subspaces clustering. By assuming that the heterogeneous features lie within the union of multiple linear subspaces, the recent multiview subspace learning methods aim to capture the complementary and consensus from multiple views to boost the performance. However, in real-world applications, data feature usually resides in multiple nonlinear subspaces, leading to undesirable results. To this end, we propose a kernelized version of tensor-based multiview subspace clustering, which is referred to as Kt-SVD-MSC, to jointly learn self-representation coefficients in mapped high-dimensional spaces and multiple views correlation in unified tensor space. In view-specific feature space, a kernel-induced mapping is introduced for each view to ensure the separability of self-representation coefficients. In unified tensor space, a new kind of tensor low-rank regularizer is employed on the rotated self-representation coefficient tensor to preserve the global consistency across different views. We also derive an algorithm to efficiently solve the optimization problem with all the subproblems having closed-form solutions. Furthermore, by incorporating the nonnegative and sparsity constraints, the proposed method can be easily extended to a useful variant, meaning that several useful variants can be easily constructed in a similar way. Extensive experiments of the proposed method are tested on eight challenging data sets, in which a significant (even a breakthrough) advance over state-of-the-art multiview clustering is achieved."}}
