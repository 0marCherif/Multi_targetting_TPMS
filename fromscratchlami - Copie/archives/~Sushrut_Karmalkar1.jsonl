{"id": "8ozSD4Oymw", "cdate": 1603473991172, "mdate": null, "content": {"title": "Compressed Sensing with Approximate Priors via Conditional Resampling", "abstract": "We characterize the measurement complexity of compressed sensing of\nsignals drawn from a known prior distribution, even when the support\nof the prior is the entire space (rather than, say, sparse vectors).\nWe show for Gaussian measurements and \\emph{any} prior distribution\non the signal, that the conditional resampling estimator achieves\nnear-optimal recovery guarantees.  Moreover, this result is robust\nto model mismatch, as long as the distribution estimate (e.g., from\nan invertible generative model) is close to the true distribution in\nWasserstein distance. We implement the conditional resampling\nestimator for deep generative priors using Langevin dynamics, and\nempirically find that it produces accurate estimates with more\ndiversity than MAP."}}
{"id": "BkxP2mnq8S", "cdate": 1568486318554, "mdate": null, "content": {"title": "Lower Bounds for Compressed Sensing with Generative Models", "abstract": "  The goal of compressed sensing is to learn a structured signal $x$\n  from a limited number of noisy linear measurements $y \\approx Ax$.  In\n  traditional compressed sensing, ``structure'' is represented by\n  sparsity in some known basis.  Inspired by the success of deep\n  learning in modeling images, recent work starting with~\\cite{BDJP17}\n  has instead considered structure to come from a generative model\n  $G: \\R^k \\to \\R^n$.  We present two results establishing the\n  difficulty of this latter task, showing that existing bounds are\n  tight.\n\n  First, we provide a lower bound matching the~\\cite{BDJP17} upper\n  bound for compressed sensing from $L$-Lipschitz generative models\n  $G$.  In particular, there exists such a function that requires\n  roughly $\\Omega(k \\log L)$ linear measurements for sparse recovery\n  to be possible.  This holds even for the more relaxed goal of\n  \\emph{nonuniform} recovery.\n\n  Second, we show that generative models generalize sparsity as a\n  representation of structure.  In particular, we construct a\n  ReLU-based neural network $G: \\R^{2k} \\to \\R^n$ with $O(1)$ layers\n  and $O(kn)$ activations per layer, such that the range of $G$\n  contains all $k$-sparse vectors.\n"}}
{"id": "B1e834rgIH", "cdate": 1567802542201, "mdate": null, "content": {"title": "List-decodable Linear Regression", "abstract": "We give the first polynomial-time algorithm for robust regression in the list-decodable setting where an adversary can corrupt a greater than 1/2 fraction of examples.   For any \\alpha < 1, our algorithm takes as input a sample {(x_i,y_i)}_{i \\leq n} of n linear equations where \\alpha n of the equations satisfy y_i = \\langle x_i,\\ell^*\\rangle +\\zeta for some small noise \\zeta and (1-\\alpha) n of the equations are {\\em arbitrarily} chosen. It outputs a list L of size O(1/\\alpha) - a fixed constant - that contains an \\ell that is close to \\ell^*.  Our algorithm succeeds whenever the inliers are chosen from a certifiably anti-concentrated distribution D. In particular, this gives a (d/\\alpha)^{O(1/\\alpha^8)} time algorithm to find a O(1/\\alpha) size list when the inlier distribution is a standard Gaussian. For discrete product distributions that are anti-concentrated only in regular directions, we give an algorithm that achieves similar guarantee under the promise that \\ell^* has all coordinates of the same magnitude. To complement our result, we prove that the anti-concentration assumption on the inliers is information-theoretically necessary.  To solve the problem we introduce a new framework for list-decodable learning that strengthens the ``identifiability to algorithms'' paradigm based on the sum-of-squares method."}}
{"id": "SJICXeWAb", "cdate": 1518730172789, "mdate": null, "content": {"title": "Depth separation and weight-width trade-offs for sigmoidal neural networks", "abstract": "Some recent work has shown separation between the expressive power of depth-2 and depth-3 neural networks. These separation results are shown by constructing functions and input distributions, so that the function is well-approximable by a depth-3 neural network of polynomial size but it cannot be well-approximated under the chosen input distribution by any depth-2 neural network of polynomial size. These results are not robust and require carefully chosen functions as well as input distributions.\n\nWe show a similar separation between the expressive power of depth-2 and depth-3 sigmoidal neural networks over a large class of input distributions, as long as the weights are polynomially bounded. While doing so, we also show that depth-2 sigmoidal neural networks with small width and small weights can be well-approximated by low-degree multivariate polynomials."}}
{"id": "SyZprb5xg", "cdate": null, "mdate": null, "content": {"title": "On Robust Concepts and Small Neural Nets", "abstract": "The universal approximation theorem for neural networks says that any reasonable function is well-approximated by a two-layer neural network with sigmoid gates but it does not provide good bounds on the number of hidden-layer nodes or the weights. However, robust concepts often have small neural networks in practice. We show an efficient analog of the universal approximation theorem on the boolean hypercube in this context.\n\nWe prove that any noise-stable boolean function on n boolean-valued input variables can be well-approximated by a two-layer linear threshold circuit with a small number of hidden-layer nodes and small weights, that depend only on the noise-stability and approximation parameters, and are independent of n. We also give a polynomial time learning algorithm that outputs a small two-layer linear threshold circuit that approximates such a given function. We also show weaker generalizations of this to noise-stable polynomial threshold functions and noise-stable boolean functions in general."}}
{"id": "ByUg_SNte", "cdate": null, "mdate": null, "content": {"title": "On Robust Concepts and Small Neural Nets", "abstract": "The universal approximation theorem for neural networks says that any reasonable function is well-approximated by a two-layer neural network with sigmoid gates but it does not provide good bounds on the number of hidden-layer nodes or the weights. However, robust concepts often have small neural networks in practice. We show an efficient analog of the universal approximation theorem on the boolean hypercube in this context.\n\nWe prove that any noise-stable boolean function on n boolean-valued input variables can be well-approximated by a two-layer linear threshold circuit with a small number of hidden-layer nodes and small weights, that depend only on the noise-stability and approximation parameters, and are independent of n. We also give a polynomial time learning algorithm that outputs a small two-layer linear threshold circuit that approximates such a given function. We also show weaker generalizations of this to noise-stable polynomial threshold functions and noise-stable boolean functions in general."}}
