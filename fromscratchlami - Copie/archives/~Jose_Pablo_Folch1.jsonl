{"id": "MuxjWpJDR7j", "cdate": 1680307200000, "mdate": 1680256269601, "content": {"title": "Combining multi-fidelity modelling and asynchronous batch Bayesian Optimization", "abstract": ""}}
{"id": "QudXypzItbt", "cdate": 1652737518328, "mdate": null, "content": {"title": "SnAKe: Bayesian Optimization with Pathwise Exploration", "abstract": "\"Bayesian Optimization is a very effective tool for optimizing expensive black-box functions. Inspired by applications developing and characterizing reaction chemistry using droplet microfluidic reactors, we consider a novel setting where the expense of evaluating the function can increase significantly when making large input changes between iterations. We further assume we are working asynchronously, meaning we have to decide on new queries before we finish evaluating previous experiments. This paper investigates the problem and introduces 'Sequential Bayesian Optimization via Adaptive Connecting Samples' (SnAKe), which provides a solution by considering large batches of queries and preemptively building optimization paths that minimize input costs. We investigate some convergence properties and empirically show that the algorithm is able to achieve regret similar to classical Bayesian Optimization algorithms in both the synchronous and asynchronous settings, while reducing the input costs significantly. We show the method is robust to the choice of its single hyper-parameter and provide a parameter-free alternative.\""}}
