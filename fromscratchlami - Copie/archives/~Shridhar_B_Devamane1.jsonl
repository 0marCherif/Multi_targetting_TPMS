{"id": "vr3Pu__LhO", "cdate": 1681729442543, "mdate": 1681729442543, "content": {"title": "Performance analysis of neural network based polar decoding algorithms with different code rates", "abstract": "Neural network approach with deep learning is of interest of late in channel decoding. Polar code is a desirable candidate in 5G and replaces Turbo code with better error correction capacities. In view of this, there is a need to explore polar decoding with neural network techniques. In this paper, the performance of polar decoding using conventional successive cancellation (SC) algorithm and belief propagation (BP) algorithm are evaluated in additive white Gaussian noise (AWGN) in python platform. Also, an effort is made to test the performance of decoding by implementing belief propagation algorithm using neural network, called as belief propagation neural network (BPNN). BPNN is chosen, as it requires a minimum number of iterations to complete the decoding operation. Performance is compared with that of conventional decoding. Performance analysis is carried out in terms of bit error rate (BER) for different input code lengths and code rates. Block length error rate (BLER) analysis of algorithms is also investigated. It is observed that BPNN performs better with improvement in the performance with modified neural network architecture and training sets."}}
{"id": "hZKdtT2juEb", "cdate": 1681729364876, "mdate": 1681729364876, "content": {"title": "Recurrent neural network based turbo decoding algorithms for different code rates", "abstract": "Application of deep learning to error control coding is gaining special attention and neural network architectures on decoding are approached to compare with conventional ones. Turbo codes conventionally use\nBCJR algorithm for decoding. In this paper, performances of neural Turbo decoder and deep learningbased Turbo decoder are examined. A category of sequential codes are utilized to construct the RSC\n(Recursive Systematic Convolutional) codes as basic elements for Turbo encoder. Sequential codes suit\nthe requirement of memory element present in convolution codes, which act as components for Turbo\nencoder. Turbo decoders are constructed by two means; as neural Turbo decoder and deep learning\nTurbo decoder. Both structures are based on recurrent neural network (RNN) architectures. RNN architectures are preferred due to the presence of memory as a feature. BER performance of both is compared\nwith that of a convolutional Viterbi decoder in awgn channel. Both the structures are studied for different\ninput data-lengths and code rates."}}
