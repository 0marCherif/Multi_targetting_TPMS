{"id": "r2c-KNmGMz7", "cdate": 1640995200000, "mdate": 1682331595596, "content": {"title": "The regularized feasible directions method for nonconvex optimization", "abstract": ""}}
{"id": "ovM1n47fAMe", "cdate": 1640995200000, "mdate": 1682331595653, "content": {"title": "A Dynamic Alternating Direction of Multipliers for Nonconvex Minimization with Nonlinear Functional Equality Constraints", "abstract": "This paper studies the minimization of a broad class of nonsmooth nonconvex objective functions subject to nonlinear functional equality constraints, where the gradients of the differentiable parts in the objective and the constraints are only locally Lipschitz continuous. We propose a specific proximal linearized alternating direction method of multipliers in which the proximal parameter is generated dynamically, and we design an explicit and tractable backtracking procedure to generate it. We prove subsequent convergence of the method to a critical point of the problem, and global convergence when the problem\u2019s data are semialgebraic. These results are obtained with no dependency on the explicit manner in which the proximal parameter is generated. As a byproduct of our analysis, we also obtain global convergence guarantees for the proximal gradient method with a dynamic proximal parameter under local Lipschitz continuity of the gradient of the smooth part of the nonlinear sum composite minimization model."}}
{"id": "jWgip_lLMZ", "cdate": 1609459200000, "mdate": 1673738269043, "content": {"title": "Regret Minimization in Stochastic Non-Convex Learning via a Proximal-Gradient Approach", "abstract": ""}}
{"id": "zjXyw25Q35l", "cdate": 1577836800000, "mdate": 1631284154704, "content": {"title": "On the Almost Sure Convergence of Stochastic Gradient Descent in Non-Convex Problems", "abstract": "In this paper, we analyze the trajectories of stochastic gradient descent (SGD) with the aim of understanding their convergence properties in non-convex problems. We first show that the sequence of iterates generated by SGD remains bounded and converges with probability $1$ under a very broad range of step-size schedules. Subsequently, we prove that the algorithm's rate of convergence to local minimizers with a positive-definite Hessian is $O(1/n^p)$ if the method is run with a $\u0398(1/n^p)$ step-size. This provides an important guideline for tuning the algorithm's step-size as it suggests that a cool-down phase with a vanishing step-size could lead to significant performance gains; we demonstrate this heuristic using ResNet architectures on CIFAR. Finally, going beyond existing positive probability guarantees, we show that SGD avoids strict saddle points/manifolds with probability $1$ for the entire spectrum of step-size policies considered."}}
{"id": "yJA1OVFTJD", "cdate": 1577836800000, "mdate": 1682331595864, "content": {"title": "Efficient Proximal Mapping of the 1-path-norm of Shallow Networks", "abstract": "We demonstrate two new important properties of the 1-path-norm of shallow neural networks. First, despite its non-smoothness and non-convexity it allows a closed form proximal operator which can be..."}}
{"id": "aofYusDp31u", "cdate": 1577836800000, "mdate": null, "content": {"title": "Efficient Proximal Mapping of the 1-path-norm of Shallow Networks", "abstract": "We demonstrate two new important properties of the 1-path-norm of shallow neural networks. First, despite its non-smoothness and non-convexity it allows a closed form proximal operator which can be efficiently computed, allowing the use of stochastic proximal-gradient-type methods for regularized empirical risk minimization. Second, when the activation functions is differentiable, it provides an upper bound on the Lipschitz constant of the network. Such bound is tighter than the trivial layer-wise product of Lipschitz constants, motivating its use for training networks robust to adversarial perturbations. In practical experiments we illustrate the advantages of using the proximal mapping and we compare the robustness-accuracy trade-off induced by the 1-path-norm, L1-norm and layer-wise constraints on the Lipschitz constant (Parseval networks)."}}
{"id": "XkXb99Eeg6G", "cdate": 1577836800000, "mdate": null, "content": {"title": "Regret minimization in stochastic non-convex learning via a proximal-gradient approach", "abstract": "Motivated by applications in machine learning and operations research, we study regret minimization with stochastic first-order oracle feedback in online constrained, and possibly non-smooth, non-convex problems. In this setting, the minimization of external regret is beyond reach for first-order methods, so we focus on a local regret measure defined via a proximal-gradient mapping. To achieve no (local) regret in this setting, we develop a prox-grad method based on stochastic first-order feedback, and a simpler method for when access to a perfect first-order oracle is possible. Both methods are min-max order-optimal, and we also establish a bound on the number of prox-grad queries these methods require. As an important application of our results, we also obtain a link between online and offline non-convex stochastic optimization manifested as a new prox-grad scheme with complexity guarantees matching those obtained via variance reduction techniques."}}
{"id": "TK9zNmzzbmo", "cdate": 1577836800000, "mdate": null, "content": {"title": "Finding Second-Order Stationary Points in Constrained Minimization: A Feasible Direction Approach", "abstract": "This paper introduces a method for computing points satisfying the second-order necessary optimality conditions for nonconvex minimization problems subject to a closed and convex constraint set. The method comprises two independent steps corresponding to the first- and second-order conditions. The first-order step is a generic closed map algorithm, which can be chosen from a variety of first-order algorithms, making it adjustable to the given problem. The second-order step can be viewed as a second-order feasible direction step for nonconvex minimization subject to a convex set. We prove that any limit point of the resulting scheme satisfies the second-order necessary optimality condition, and establish the scheme\u2019s convergence rate and complexity, under standard and mild assumptions. Numerical tests illustrate the proposed scheme."}}
{"id": "HZCjTxKbcuA", "cdate": 1577836800000, "mdate": null, "content": {"title": "On the Convergence to Stationary Points of Deterministic and Randomized Feasible Descent Directions Methods", "abstract": "This paper studies the class of nonsmooth nonconvex problems in which the difference between a continuously differentiable function and a convex nonsmooth function is minimized over linear constraints. Our goal is to attain a point satisfying the stationarity necessary optimality condition, defined as the lack of feasible descent directions. Although elementary in smooth optimization, this condition is nontrivial when the objective function is nonsmooth, and, correspondingly, there are very few methods that obtain stationary points in such settings. We prove that stationarity in our model can be characterized by a finite number of directions and develop two methods, one deterministic and one random, that use these directions to obtain stationary points. Numerical experiments illustrate the benefit of obtaining a stationary point and the advantage of using the random method to do so."}}
{"id": "DqaRX6qFY2u", "cdate": 1577836800000, "mdate": null, "content": {"title": "On the Almost Sure Convergence of Stochastic Gradient Descent in Non-Convex Problems", "abstract": "This paper analyzes the trajectories of stochastic gradient descent (SGD) to help understand the algorithm's convergence properties in non-convex problems. We first show that the sequence of iterates generated by SGD remains bounded and converges with probability $1$ under a very broad range of step-size schedules. Subsequently, going beyond existing positive probability guarantees, we show that SGD avoids strict saddle points/manifolds with probability $1$ for the entire spectrum of step-size policies considered. Finally, we prove that the algorithm's rate of convergence to Hurwicz minimizers is $\\mathcal{O}(1/n^{p})$ if the method is employed with a $\\Theta(1/n^p)$ step-size schedule. This provides an important guideline for tuning the algorithm's step-size as it suggests that a cool-down phase with a vanishing step-size could lead to faster convergence; we demonstrate this heuristic using ResNet architectures on CIFAR."}}
