{"id": "0PfIQs-ttQQ", "cdate": 1652737512278, "mdate": null, "content": {"title": "Self-supervised surround-view depth estimation with volumetric feature fusion", "abstract": "We present a self-supervised depth estimation approach using a unified volumetric feature fusion for surround-view images. Given a set of surround-view images, our method constructs a volumetric feature map by extracting image feature maps from surround-view images and fuse the feature maps into a shared, unified 3D voxel space. The volumetric feature map then can be used for estimating a depth map at each surround view by projecting it into an image coordinate. A volumetric feature contains 3D information at its local voxel coordinate; thus our method can also synthesize a depth map at arbitrary rotated viewpoints by projecting the volumetric feature map into the target viewpoints. Furthermore, assuming static camera extrinsics in the multi-camera system, we propose to estimate a canonical camera motion from the volumetric feature map. Our method leverages 3D spatio- temporal context to learn metric-scale depth and the canonical camera motion in a self-supervised manner. Our method outperforms the prior arts on DDAD and nuScenes datasets, especially estimating more accurate metric-scale depth and consistent depth between neighboring views."}}
{"id": "F0gnDXApQd0", "cdate": 1640995200000, "mdate": 1652613153529, "content": {"title": "Eigenlanes: Data-Driven Lane Descriptors for Structurally Diverse Lanes", "abstract": "A novel algorithm to detect road lanes in the eigenlane space is proposed in this paper. First, we introduce the notion of eigenlanes, which are data-driven descriptors for structurally diverse lanes, including curved, as well as straight, lanes. To obtain eigenlanes, we perform the best rank-M approximation of a lane matrix containing all lanes in a training set. Second, we generate a set of lane candidates by clustering the training lanes in the eigenlane space. Third, using the lane candidates, we determine an optimal set of lanes by developing an anchor-based detection network, called SIIC-Net. Experimental results demonstrate that the proposed algorithm provides excellent detection performance for structurally diverse lanes. Our codes are available at https://github.com/dongkwonjin/Eigenlanes."}}
{"id": "Bn3t5_lXRw", "cdate": 1609459200000, "mdate": 1652613153535, "content": {"title": "Harmonious Semantic Line Detection via Maximal Weight Clique Selection", "abstract": "A novel algorithm to detect an optimal set of semantic lines is proposed in this work. We develop two networks: selection network (S-Net) and harmonization network (H-Net). First, S-Net computes the probabilities and offsets of line candidates. Second, we filter out irrelevant lines through a selection-and-removal process. Third, we construct a complete graph, whose edge weights are computed by H-Net. Finally, we determine a maximal weight clique representing an optimal set of semantic lines. Moreover, to assess the overall harmony of detected lines, we propose a novel metric, called HIoU. Experimental results demonstrate that the proposed algorithm can detect harmonious semantic lines effectively and efficiently. Our codes are available at https://github.com/dongkwonjin/Semantic-Line-MWCS."}}
{"id": "Z7hiyS-Gkzm", "cdate": 1546300800000, "mdate": 1652613153660, "content": {"title": "Did It Change? Learning to Detect Point-Of-Interest Changes for Proactive Map Updates", "abstract": "Maps are an increasingly important tool in our daily lives, yet their rich semantic content still largely depends on manual input. Motivated by the broad availability of geo-tagged street-view images, we propose a new task aiming to make the map update process more proactive. We focus on automatically detecting changes of Points of Interest (POIs), specifically stores or shops of any kind, based on visual input. Faced with the lack of an appropriate benchmark, we build and release a large dataset, captured in two large shopping centers, that comprises 33K geo-localized images and 578 POIs. We then design a generic approach that compares two image sets captured in the same venue at different times and outputs POI changes as a ranked list of map locations. In contrast to logo or franchise recognition approaches, our system does not depend on an external franchise database. It is instead inspired by recent deep metric learning approaches that learn a similarity function fit to the task at hand. We compare various loss functions to learn a metric aligned with the POI change detection goal, and report promising results."}}
{"id": "UqlMM0clBw", "cdate": 1546300800000, "mdate": 1652613153536, "content": {"title": "Instance-Level Future Motion Estimation in a Single Image Based on Ordinal Regression", "abstract": "A novel algorithm to estimate instance-level future motion in a single image is proposed in this paper. We first represent the future motion of an instance with its direction, speed, and action classes. Then, we develop a deep neural network that exploits different levels of semantic information to perform the future motion estimation. For effective future motion classification, we adopt ordinal regression. Especially, we develop the cyclic ordinal regression scheme using binary classifiers. Experiments demonstrate that the proposed algorithm provides reliable performance and thus can be used effectively for vision applications, including single and multi object tracking. Furthermore, we release the future motion (FM) dataset, collected from diverse sources and annotated manually, as a benchmark for single-image future motion estimation."}}
{"id": "Nvldkkh9Rcl", "cdate": 1546300800000, "mdate": 1652613153529, "content": {"title": "Anchor Loss: Modulating Loss Scale Based on Prediction Difficulty", "abstract": "We propose a novel loss function that dynamically re-scales the cross entropy based on prediction difficulty regarding a sample. Deep neural network architectures in image classification tasks struggle to disambiguate visually similar objects. Likewise, in human pose estimation symmetric body parts often confuse the network with assigning indiscriminative scores to them. This is due to the output prediction, in which only the highest confidence label is selected without taking into consideration a measure of uncertainty. In this work, we define the prediction difficulty as a relative property coming from the confidence score gap between positive and negative labels. More precisely, the proposed loss function penalizes the network to avoid the score of a false prediction being significant. To demonstrate the efficacy of our loss function, we evaluate it on two different domains: image classification and human pose estimation. We find improvements in both applications by achieving higher accuracy compared to the baseline methods."}}
{"id": "5prlPa6aexj", "cdate": 1546300800000, "mdate": 1652613153532, "content": {"title": "Drop to Adapt: Learning Discriminative Features for Unsupervised Domain Adaptation", "abstract": "Recent works on domain adaptation exploit adversarial training to obtain domain-invariant feature representations from the joint learning of feature extractor and domain discriminator networks. However, domain adversarial methods render suboptimal performances since they attempt to match the distributions among the domains without considering the task at hand. We propose Drop to Adapt (DTA), which leverages adversarial dropout to learn strongly discriminative features by enforcing the cluster assumption. Accordingly, we design objective functions to support robust domain adaptation. We demonstrate efficacy of the proposed method on various experiments and achieve consistent improvements in both image classification and semantic segmentation tasks. Our source code is available at https://github.com/postBG/DTA.pytorch."}}
{"id": "2mKnKnkexQ_", "cdate": 1546300800000, "mdate": 1652613153530, "content": {"title": "Delegated Adversarial Training for Unsupervised Domain Adaptation", "abstract": "In this paper, we tackle unsupervised domain adaptation, where a target domain is unlabeled and lies on a considerably different distribution from a source domain. To alleviate such data discrepancies, we coin a novel deep neural network architecture that consists of a classifier and a domain discriminator on top of a shared feature extractor. Toward efficient regularization, we delegate a generation of the adversarial attacks to the domain discriminator. We then leverage the domain adversarial images to let the classification network learn important semantic features across the domains. Specifically, we employ consistency loss function that enables the joint use of clean and adversarial data. We present extensive experimental results on various domain adaptation benchmarks to show the efficacy of the proposed method."}}
{"id": "QkvIJKqBDci", "cdate": 1483228800000, "mdate": 1652613153531, "content": {"title": "End-to-end learning of image based lane-change decision", "abstract": "We propose an image based end-to-end learning framework that helps lane-change decisions for human drivers and autonomous vehicles. The proposed system, Safe Lane-Change Aid Network (SLCAN), trains a deep convolutional neural network to classify the status of adjacent lanes from rear view images acquired by cameras mounted on both sides of the vehicle. Rather than depending on any explicit object detection or tracking scheme, SLCAN reads the whole input image and directly decides whether initiation of the lane-change at the moment is safe or not. We collected and annotated 77,273 rear side view images to train and test SLCAN. Experimental results show that the proposed framework achieves 96.98% classification accuracy although the test images are from unseen roadways. We also visualize the saliency map to understand which part of image SLCAN looks at for correct decisions."}}
{"id": "uxabsno_tX", "cdate": 1451606400000, "mdate": 1652613153530, "content": {"title": "Progressive Tree-like Curvilinear Structure Reconstruction with Structured Ranking Learning and Graph Algorithm", "abstract": "We propose a novel tree-like curvilinear structure reconstruction algorithm based on supervised learning and graph theory. In this work we analyze image patches to obtain the local major orientations and the rankings that correspond to the curvilinear structure. To extract local curvilinear features, we compute oriented gradient information using steerable filters. We then employ Structured Support Vector Machine for ordinal regression of the input image patches, where the ordering is determined by shape similarity to latent curvilinear structure. Finally, we progressively reconstruct the curvilinear structure by looking for geodesic paths connecting remote vertices in the graph built on the structured output rankings. Experimental results show that the proposed algorithm faithfully provides topological features of the curvilinear structures using minimal pixels for various datasets."}}
