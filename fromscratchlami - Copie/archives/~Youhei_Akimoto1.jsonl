{"id": "m9_4CLW7K4s", "cdate": 1672531200000, "mdate": 1681685803614, "content": {"title": "Few-Shot Image-to-Semantics Translation for Policy Transfer in Reinforcement Learning", "abstract": "We investigate policy transfer using image-to-semantics translation to mitigate learning difficulties in vision-based robotics control agents. This problem assumes two environments: a simulator environment with semantics, that is, low-dimensional and essential information, as the state space, and a real-world environment with images as the state space. By learning mapping from images to semantics, we can transfer a policy, pre-trained in the simulator, to the real world, thereby eliminating real-world on-policy agent interactions to learn, which are costly and risky. In addition, using image-to-semantics mapping is advantageous in terms of the computational efficiency to train the policy and the interpretability of the obtained policy over other types of sim-to-real transfer strategies. To tackle the main difficulty in learning image-to-semantics mapping, namely the human annotation cost for producing a training dataset, we propose two techniques: pair augmentation with the transition function in the simulator environment and active learning. We observed a reduction in the annotation cost without a decline in the performance of the transfer, and the proposed approach outperformed the existing approach without annotation."}}
{"id": "hnfmo5vSru", "cdate": 1672531200000, "mdate": 1678250586171, "content": {"title": "Unauthorized AI cannot recognize me: Reversible adversarial example", "abstract": ""}}
{"id": "J82zTneENF7", "cdate": 1672531200000, "mdate": 1681685803451, "content": {"title": "Adaptive scenario subset selection for worst-case optimization and its application to well placement optimization", "abstract": ""}}
{"id": "F1PnRloXRz", "cdate": 1672531200000, "mdate": 1681685803463, "content": {"title": "Covariance Matrix Adaptation Evolutionary Strategy with Worst-Case Ranking Approximation for Min-Max Optimization and its Application to Berthing Control Tasks", "abstract": "In this study, we consider a continuous min--max optimization problem $\\min_{x \\in \\mathbb{X} \\max_{y \\in \\mathbb{Y}}}f(x,y)$ whose objective function is a black-box. We propose a novel approach to minimize the worst-case objective function $F(x) = \\max_{y} f(x,y)$ directly using a covariance matrix adaptation evolution strategy (CMA-ES) in which the rankings of solution candidates are approximated by our proposed worst-case ranking approximation (WRA) mechanism. We develop two variants of WRA combined with CMA-ES and approximate gradient ascent as numerical solvers for the inner maximization problem. Numerical experiments show that our proposed approach outperforms several existing approaches when the objective function is a smooth strongly convex--concave function and the interaction between $x$ and $y$ is strong. We investigate the advantages of the proposed approach for problems where the objective function is not limited to smooth strongly convex--concave functions. The effectiveness of the proposed approach is demonstrated in the robust berthing control problem with uncertainty.ngly convex--concave functions. The effectiveness of the proposed approach is demonstrated in the robust berthing control problem with uncertainty."}}
{"id": "rcMG-hzYtR", "cdate": 1652737675895, "mdate": null, "content": {"title": "Max-Min Off-Policy Actor-Critic Method Focusing on Worst-Case Robustness to Model Misspecification", "abstract": "In the field of reinforcement learning, because of the high cost and risk of policy training in the real world, policies are trained in a simulation environment and transferred to the corresponding real-world environment.\nHowever, the simulation environment does not perfectly mimic the real-world environment, lead to model misspecification. \nMultiple studies report significant deterioration of policy performance in a real-world environment.\nIn this study, we focus on scenarios involving a simulation environment with uncertainty parameters and the set of their possible values, called the uncertainty parameter set. \nThe aim is to optimize the worst-case performance on the uncertainty parameter set to guarantee the performance in the corresponding real-world environment.\nTo obtain a policy for the optimization, we propose an off-policy actor-critic approach called the Max-Min Twin Delayed Deep Deterministic Policy Gradient algorithm (M2TD3), which solves a max-min optimization problem using a simultaneous gradient ascent descent approach.\nExperiments in multi-joint dynamics with contact (MuJoCo) environments show that the proposed method exhibited a worst-case performance superior to several baseline approaches."}}
{"id": "yglhAkkdLl", "cdate": 1640995200000, "mdate": 1681685803771, "content": {"title": "Saddle Point Optimization with Approximate Minimization Oracle and Its Application to Robust Berthing Control", "abstract": "We propose an approach to saddle point optimization relying only on oracles that solve minimization problems approximately. We analyze its convergence property on a strongly convex\u2013concave problem and show its linear convergence toward the global min\u2013max saddle point. Based on the convergence analysis, we develop a heuristic approach to adapt the learning rate. An implementation of the developed approach using the (1+1)-CMA-ES as the minimization oracle, namely, Adversarial-CMA-ES, is shown to outperform several existing approaches on test problems. Numerical evaluation confirms the tightness of the theoretical convergence rate bound as well as the efficiency of the learning rate adaptation mechanism. As an example of real-world problems, the suggested optimization method is applied to automatic berthing control problems under model uncertainties, showing its usefulness in obtaining solutions robust to uncertainty."}}
{"id": "wOmz0KTJnZ", "cdate": 1640995200000, "mdate": 1681685803612, "content": {"title": "Monotone Improvement of Information-Geometric Optimization Algorithms with a Surrogate Function", "abstract": "A surrogate function is often employed to reduce the number of objective function evaluations for optimization. However, the effect of using a surrogate model in evolutionary approaches has not been theoretically investigated. This paper theoretically analyzes the information-geometric optimization framework using a surrogate function. The value of the expected objective function under the candidate sampling distribution is used as the measure of progress of the algorithm. We assume that the surrogate function is maintained so that the population version of the Kendall's rank correlation coefficient between the surrogate function and the objective function under the candidate sampling distribution is greater than or equal to a predefined threshold. We prove that information-geometric optimization using such a surrogate function leads to a monotonic decrease in the expected objective function value if the threshold is sufficiently close to one. The acceptable threshold value is analyzed for the case of the information-geometric optimization instantiated with Gaussian distributions, i.e., the rank-$\\mu$ update CMA-ES, on a convex quadratic objective function. As an alternative to the Kendall's rank correlation coefficient, we investigate the use of the Pearson correlation coefficient between the weights assigned to candidate solutions based on the objective function and the surrogate function."}}
{"id": "oOwejo4Xwg", "cdate": 1640995200000, "mdate": 1681685803612, "content": {"title": "Monotone improvement of information-geometric optimization algorithms with a surrogate function", "abstract": "A surrogate function is often employed to reduce the number of objective function evaluations for optimization. However, the effect of using a surrogate model in evolutionary approaches has not been theoretically investigated. This paper theoretically analyzes the information-geometric optimization framework using a surrogate function. The value of the expected objective function under the candidate sampling distribution is used as the measure of progress of the algorithm. We assume that the surrogate function is maintained so that the population version of the Kendall's rank correlation coefficient between the surrogate function and the objective function under the candidate sampling distribution is greater than or equal to a predefined threshold. We prove that information-geometric optimization using such a surrogate function leads to a monotonic decrease in the expected objective function value if the threshold is sufficiently close to one. The acceptable threshold value is analyzed for the case of the information-geometric optimization instantiated with Gaussian distributions, i.e., the rank-\u03bc update CMA-ES, on a convex quadratic objective function. As an alternative to the Kendall's rank correlation coefficient, we investigate the use of the Pearson correlation coefficient between the weights assigned to candidate solutions based on the objective function and the surrogate function."}}
{"id": "oEVDN7Jpyp", "cdate": 1640995200000, "mdate": 1681685803589, "content": {"title": "Convergence rate of the (1+1)-evolution strategy on locally strongly convex functions with lipschitz continuous gradient and their monotonic transformations", "abstract": "Evolution strategy (ES) is one of promising classes of algorithms for black-box continuous optimization. Despite its broad successes in applications, theoretical analysis on the speed of its convergence is limited on convex quadratic functions and their monotonic transformation. In this study, an upper bound and a lower bound of the rate of linear convergence of the (1+1)-ES on locally $L$-strongly convex functions with $U$-Lipschitz continuous gradient are derived as $\\exp\\left(-\\Omega_{d\\to\\infty}\\left(\\frac{L}{d\\cdot U}\\right)\\right)$ and $\\exp\\left(-\\frac1d\\right)$, respectively. Notably, any prior knowledge on the mathematical properties of the objective function such as Lipschitz constant is not given to the algorithm, whereas the existing analyses of derivative-free optimization algorithms require them."}}
{"id": "maPRDOcN_-", "cdate": 1640995200000, "mdate": 1678250586298, "content": {"title": "Domain Generalization Via Adversarially Learned Novel Domains", "abstract": ""}}
