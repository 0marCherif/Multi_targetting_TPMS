{"id": "rOalSeHWsoP", "cdate": 1609459200000, "mdate": 1668021983446, "content": {"title": "Towards Accurate Visual and Natural Language-Based Vehicle Retrieval Systems", "abstract": "In this work, we consider two tracks of the 2021 NVIDIA AI City Challenge, the City-Scale Multi-Camera Vehicle Re-identification and Natural language-based Vehicle Retrieval. For the vehicle re-identification task, we employ the state-of-art Excited Vehicle Re-Identification deep representation learning model coupled with best training practices and domain adaptation techniques to obtain robust embeddings. We further refine the re-identification results through a series of post-processing steps to remove camera and vehicle orientation bias that is inherent in the task of re-identification. We also take advantage of multiple observations of a vehicle using track-level information and finally obtain fine-grained retrieval results. For the task of Natural language-based vehicle retrieval we leverage the recently proposed Contrastive Language-Image Pre-training model and propose a simple yet effective text-based vehicle retrieval system. We compare our performance against the top submissions to the challenge and our systems are ranked 8^\\text th in the public leaderboard for both tracks."}}
{"id": "qV6I7hZi5T", "cdate": 1609459200000, "mdate": 1668021983533, "content": {"title": "Identification of Attack-Specific Signatures in Adversarial Examples", "abstract": "The adversarial attack literature contains a myriad of algorithms for crafting perturbations which yield pathological behavior in neural networks. In many cases, multiple algorithms target the same tasks and even enforce the same constraints. In this work, we show that different attack algorithms produce adversarial examples which are distinct not only in their effectiveness but also in how they qualitatively affect their victims. We begin by demonstrating that one can determine the attack algorithm that crafted an adversarial example. Then, we leverage recent advances in parameter-space saliency maps to show, both visually and quantitatively, that adversarial attack algorithms differ in which parts of the network and image they target. Our findings suggest that prospective adversarial attacks should be compared not only via their success rates at fooling models but also via deeper downstream effects they have on victims."}}
{"id": "cviGW9mqsP", "cdate": 1582060746013, "mdate": null, "content": {"title": "A Dual Path Model With Adaptive Attention For Vehicle Re-Identification", "abstract": "In recent years, attention models have been extensively\nused for person and vehicle re-identification. Most reidentification methods are designed to focus attention on\nkey-point locations. However, depending on the orientation, the contribution of each key-point varies. In this paper,\nwe present a novel dual-path adaptive attention model for\nvehicle re-identification (AAVER). The global appearance\npath captures macroscopic vehicle features while the orientation conditioned part appearance path learns to capture\nlocalized discriminative features by focusing attention\non the most informative key-points. Through extensive\nexperimentation, we show that the proposed AAVER method\nis able to accurately re-identify vehicles in unconstrained\nscenarios, yielding state of the art results on the challenging dataset VeRi-776. As a byproduct, the proposed system\nis also able to accurately predict vehicle key-points and\nshows an improvement of more than 7% over state of the\nart"}}
{"id": "hxD64gsgnz", "cdate": 1577836800000, "mdate": 1668021983534, "content": {"title": "The Devil Is in the Details: Self-supervised Attention for Vehicle Re-identification", "abstract": "In recent years, the research community has approached the problem of vehicle re-identification (re-id) with attention-based models, specifically focusing on regions of a vehicle containing discriminative information. These re-id methods rely on expensive key-point labels, part annotations, and additional attributes including vehicle make, model, and color. Given the large number of vehicle re-id datasets with various levels of annotations, strongly-supervised methods are unable to scale across different domains. In this paper, we present Self-supervised Attention for Vehicle Re-identification (SAVER), a novel approach to effectively learn vehicle-specific discriminative features. Through extensive experimentation, we show that SAVER improves upon the state-of-the-art on challenging VeRi, VehicleID, Vehicle-1M and VERI-Wild datasets."}}
{"id": "ToVoYSLfuh", "cdate": 1577836800000, "mdate": 1668021983534, "content": {"title": "Towards Real-Time Systems for Vehicle Re-Identification, Multi-Camera Tracking, and Anomaly Detection", "abstract": "Vehicle re-identification, multi-camera vehicle tracking, and anomaly detection are essential for city-scale intelligent transportation systems. Both vehicle re-id and multi-camera tracking are challenging due to variations in aspect-ratio, occlusion, and orientation. Robust re-id and tracking systems must consider small scale variations in a vehicle's appearance to accurately distinguish among vehicles of the same make, model, and color. Scalability is critical for multi-camera systems, as the number of objects in a scene is not known a-priori. Anomaly detection presents a unique challenge due to a dearth of annotations and varied video quality. In this paper, we address the task of vehicle re-id by introducing an unsupervised excitation layer to enhance representation learning. We propose a multi-camera tracking pipeline leveraging this re-id feature extractor to compute a distance matrix and perform clustering to obtain multi-camera vehicle trajectories. Lastly, we leverage background modeling techniques to localize anomalies such as stalled vehicles and collisions. We show the effectiveness of our proposed method on the NVIDIA AI City Challenge, where we obtain 7th place out of 41 teams for the task of vehicle re-id, with an mAP score of 66.68% and achieve state-of-the-art results on the Vehicle-ID dataset. We also obtain an IDF1 score of 12.45% on multi-camera vehicle tracking, and an S4 score of 29.52% for task of anomaly detection, ranking in the top 5 for both tracks."}}
{"id": "SX63rqgCSli", "cdate": 1577836800000, "mdate": 1668021983536, "content": {"title": "GANs with Variational Entropy Regularizers: Applications in Mitigating the Mode-Collapse Issue", "abstract": "Building on the success of deep learning, Generative Adversarial Networks (GANs) provide a modern approach to learn a probability distribution from observed samples. GANs are often formulated as a zero-sum game between two sets of functions; the generator and the discriminator. Although GANs have shown great potentials in learning complex distributions such as images, they often suffer from the mode collapse issue where the generator fails to capture all existing modes of the input distribution. As a consequence, the diversity of generated samples is lower than that of the observed ones. To tackle this issue, we take an information-theoretic approach and maximize a variational lower bound on the entropy of the generated samples to increase their diversity. We call this approach GANs with Variational Entropy Regularizers (GAN+VER). Existing remedies for the mode collapse issue in GANs can be easily coupled with our proposed variational entropy regularization. Through extensive experimentation on standard benchmark datasets, we show all the existing evaluation metrics highlighting difference of real and generated samples are significantly improved with GAN+VER."}}
{"id": "HjIN14Xe_pH", "cdate": 1546300800000, "mdate": null, "content": {"title": "Attention Driven Vehicle Re-identification and Unsupervised Anomaly Detection for Traffic Understanding.", "abstract": "Vehicle re-identification and anomaly detection are useful tools in traffic analytics applications. Vehicle re-identification is particularly challenging due to variations in viewpoint, illumination and occlusion. Moreover, the reality of multiple vehicles having the same make and model hinders the design of traditional deep network-based solutions. In this work, we leverage an attention-based model which learns to focus on different parts of a vehicle by conditioning the feature maps on visible key-points. We use triplet embedding to reduce the dimensionality of the features obtained from the ensemble of networks trained using different datasets. To address the problem of anomaly detection, we design an unsupervised algorithm to detect and localize anomalies in traffic scenes. To handle moving cameras, we use the results obtained from tracking to generate anomaly proposals which are then filtered in successive steps. We show the effectiveness of our method on the Nvidia AI City vehicle re-identification dataset, where we obtain mean Average Precision (mAP) score of 60.78% placing us at the 8th position out of 84 participating teams. In addition, we achieved the S3 score of 22.07% for vehicle anomaly detection."}}
{"id": "W8i4DN25YeU", "cdate": 1514764800000, "mdate": 1668021983533, "content": {"title": "Statistical Studies of Fading in Underwater Wireless Optical Channels in the Presence of Air Bubble, Temperature, and Salinity Random Variations (Long Version)", "abstract": "Optical signal propagation through underwater channels is affected by three main degrading phenomena, namely absorption, scattering, and fading. In this paper, we experimentally study the statistical distribution of intensity fluctuations in underwater wireless optical channels with random temperature and salinity variations as well as the presence of air bubbles. In particular, we define different scenarios to produce random fluctuations on the water refractive index across the propagation path, and then examine the accuracy of various statistical distributions in terms of their goodness of fit to the experimental data. We also obtain the channel coherence time to address the average period of fading temporal variations. The scenarios under consideration cover a wide range of scintillation index from weak to strong turbulence. Moreover, the effects of beam-collimator at the transmitter side and aperture averaging lens at the receiver side are experimentally investigated. We show that the use of a transmitter beam-collimator and/or a receiver aperture averaging lens suits single-lobe distributions such that the generalized Gamma and exponential Weibull distributions can excellently match the histograms of the acquired data. Our experimental results further reveal that the channel coherence time is on the order of $10^{-3}$ seconds and larger which implies to the slow fading turbulent channels."}}
{"id": "MNRa1OX_lYr", "cdate": 1514764800000, "mdate": 1668021983533, "content": {"title": "Statistical Studies of Fading in Underwater Wireless Optical Channels in the Presence of Air Bubble, Temperature, and Salinity Random Variations", "abstract": "Optical signal propagation through underwater channels is affected by three main degrading phenomena, namely, absorption, scattering, and fading. In this paper, we experimentally study the statistical distribution of intensity fluctuations in underwater wireless optical channels with random temperature and salinity variations, as well as the presence of air bubbles. In particular, we define different scenarios to produce random fluctuations on the water refractive index across the propagation path and, then, examine the accuracy of various statistical distributions in terms of their goodness of fit to the experimental data. We also obtain the channel coherence time to address the average period of fading temporal variations. The scenarios under consideration cover a wide range of scintillation index from weak to strong turbulence. Moreover, the effects of beam-expander-and-collimator (BEC) at the transmitter side and aperture averaging lens (AAL) at the receiver side are experimentally investigated. We show that the use of a transmitter BEC and/or a receiver AAL suits single-lobe distributions, such that the generalized Gamma and exponentiated Weibull distributions can excellently match the histograms of the acquired data. Our experimental results further reveal that the channel coherence time is on the order of 10 <sup xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">-3</sup> s and larger which implies to the slow fading turbulent channels."}}
{"id": "B1V72hZO-H", "cdate": 1514764800000, "mdate": null, "content": {"title": "A Semi-Automatic 2D Solution for Vehicle Speed Estimation From Monocular Videos", "abstract": "In this work, we present a novel approach for vehicle speed estimation from monocular videos. The pipeline consists of modules for multi-object detection, robust tracking, and speed estimation. The tracking algorithm has the capability for jointly tracking individual vehicles and estimating velocities in the image domain. However, since camera parameters are often unavailable and extensive variations are present in the scenes, transforming measurements in the image domain to real world is challenging. We propose a simple two-stage algorithm to approximate the transformation. Images are first rectified to restore affine properties, then the scaling factor is compensated for each scene. We show the effectiveness of the proposed method with extensive experiments on the traffic speed analysis dataset in the NVIDIA AI City challenge. We achieve a detection rate of 1.0 in vehicle detection and tracking, and Root Mean Square Error of 9.54 (mph) for the task of vehicle speed estimation in unconstrained traffic videos."}}
