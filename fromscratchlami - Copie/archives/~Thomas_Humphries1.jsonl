{"id": "LIp_NUf1-9", "cdate": 1671904091305, "mdate": 1671904091305, "content": {"title": "Investigating Membership Inference Attacks under Data Dependencies", "abstract": "Training machine learning models on privacy-sensitive data has become a popular practice, driving innovation in ever-expanding fields. This has opened the door to new attacks that can have serious privacy implications. One such attack, the Membership Inference Attack (MIA), exposes whether or not a particular data point was used to train a model. A growing body of literature uses Differentially Private (DP) training algorithms as a defence against such attacks. However, these works evaluate the defence under the restrictive assumption that all members of the training set, as well as non-members, are independent and identically distributed. This assumption does not hold for many real-world use cases in the literature. Motivated by this, we evaluate membership inference with statistical dependencies among samples and explain why DP does not provide meaningful protection (the privacy parameter \u03f5 scales with the training set size n) in this more general case. We conduct a series of empirical evaluations with off-the-shelf MIAs using training sets built from real-world data showing different types of dependencies among samples. Our results reveal that training set dependencies can severely increase the performance of MIAs, and therefore assuming that data samples are statistically independent can significantly underestimate the performance of MIAs."}}
{"id": "idpr_V5Kfd", "cdate": 1640995200000, "mdate": 1681826006111, "content": {"title": "An Extension of the iMOACO$\\mathbb {_R}$ Algorithm Based on Layer-Set Selection", "abstract": "iMOACO $$\\mathbb {_R}$$ is an ant colony optimization algorithm designed to tackle multi-objective optimization problems in continuous search spaces. It is built on top of ACO $$\\mathbb {_R}$$ and uses the R2 indicator (to improve its performance on high-dimensional objective function spaces) to rank the pheromone archive of the best previously-explored solutions. Due to the utilization of an R2-based selection mechanism, there are typically a large number of tied-ranks in iMOACO $$\\mathbb {_R}$$ \u2019s pheromone archive. It is worth noting that the solutions of a specific layer share the same importance based on the R2 indicator. A critical issue due to the large number of tied-ranks is a reduction of the algorithm\u2019s exploitation ability. In consequence, in this paper, we propose replacing iMOACO $$\\mathbb {_R}$$ \u2019s probabilistic solution selection mechanism with a mechanism tailored to these layer-sets. Our proposed layer-set selection uses rank-proportionate (roulette wheel) selection to select a layer, with all the solutions in the layer sharing equally in the layer\u2019s probability. Our experimental evaluation indicates that our proposal, which we call iMOACO $$\\mathbb {^{\\prime }_{R}}$$ , performs better than iMOACO $$\\mathbb {_R}$$ to a statistically significant extent on a large number of benchmark problems having from 3 to 10 objective functions."}}
{"id": "A5OYGvWRqN", "cdate": 1640995200000, "mdate": 1681826006239, "content": {"title": "Cache Me If You Can: Accuracy-Aware Inference Engine for Differentially Private Data Exploration", "abstract": "Differential privacy (DP) allows data analysts to query databases that contain users' sensitive information while providing a quantifiable privacy guarantee to users. Recent interactive DP systems such as APEx provide accuracy guarantees over the query responses, but fail to support a large number of queries with a limited total privacy budget, as they process incoming queries independently from past queries. We present an interactive, accuracy-aware DP query engine, CacheDP, which utilizes a differentially private cache of past responses, to answer the current workload at a lower privacy budget, while meeting strict accuracy guarantees. We integrate complex DP mechanisms with our structured cache, through novel cache-aware DP cost optimization. Our thorough evaluation illustrates that CacheDP can accurately answer various workload sequences, while lowering the privacy loss as compared to related work."}}
{"id": "8efX_WLkwt", "cdate": 1640995200000, "mdate": 1681826006251, "content": {"title": "Selective MPC: Distributed Computation of Differentially Private Key-Value Statistics", "abstract": "Key-value data is a naturally occurring data type that has not been thoroughly investigated in the local trust model. Existing local differentially private (LDP) solutions for computing statistics over key-value data suffer from the inherent accuracy limitations of each user adding their own noise. Multi-party computation (MPC) maintains better accuracy than LDP and similarly does not require a trusted central party. However, naively applying MPC to key-value data results in prohibitively expensive computation costs. In this work, we present selective multi-party computation, a novel approach to distributed computation that leverages DP leakage to efficiently and accurately compute statistics over key-value data. By providing each party with a view of a random subset of the data, we can capture subtractive noise. We prove that our protocol satisfies pure DP and is provably secure in the combined DP/MPC model. Our empirical evaluation demonstrates that we can compute statistics over 10,000 keys in 20 seconds and can scale up to 30 servers while obtaining results for a single key in under a second."}}
{"id": "5NBP4mjF3R5", "cdate": 1640995200000, "mdate": 1681826006034, "content": {"title": "Cache Me If You Can: Accuracy-Aware Inference Engine for Differentially Private Data Exploration", "abstract": ""}}
{"id": "Bv4Xqtyg2dI", "cdate": 1609459200000, "mdate": 1681826006133, "content": {"title": "Selective MPC: Distributed Computation of Differentially Private Key Value Statistics", "abstract": "Key-value data is a naturally occurring data type that has not been thoroughly investigated in the local trust model. Existing local differentially private (LDP) solutions for computing statistics over key-value data suffer from the inherent accuracy limitations of each user adding their own noise. Multi-party computation (MPC) maintains better accuracy than LDP and similarly does not require a trusted central party. However, naively applying MPC to key-value data results in prohibitively expensive computation costs. In this work, we present selective multi-party computation, a novel approach to distributed computation that leverages DP leakage to efficiently and accurately compute statistics over key-value data. By providing each party with a view of a random subset of the data, we can capture subtractive noise. We prove that our protocol satisfies pure DP and is provably secure in the combined DP/MPC model. Our empirical evaluation demonstrates that we can compute statistics over 10,000 keys in 20 seconds and can scale up to 30 servers while obtaining results for a single key in under a second."}}
{"id": "LarwHpXPWz", "cdate": 1577836800000, "mdate": 1681826006088, "content": {"title": "Differentially Private Learning Does Not Bound Membership Inference", "abstract": "Training machine learning models on privacy-sensitive data has become a popular practice, driving innovation in ever-expanding fields. This has opened the door to new attacks that can have serious privacy implications. One such attack, the Membership Inference Attack (MIA), exposes whether or not a particular data point was used to train a model. A growing body of literature uses Differentially Private (DP) training algorithms as a defence against such attacks. However, these works evaluate the defence under the restrictive assumption that all members of the training set, as well as non-members, are independent and identically distributed. This assumption does not hold for many real-world use cases in the literature. Motivated by this, we evaluate membership inference with statistical dependencies among samples and explain why DP does not provide meaningful protection (the privacy parameter $\\epsilon$ scales with the training set size $n$) in this more general case. We conduct a series of empirical evaluations with off-the-shelf MIAs using training sets built from real-world data showing different types of dependencies among samples. Our results reveal that training set dependencies can severely increase the performance of MIAs, and therefore assuming that data samples are statistically independent can significantly underestimate the performance of MIAs."}}
{"id": "6chz7VbMupU", "cdate": 1577836800000, "mdate": 1681826006113, "content": {"title": "Practical Over-Threshold Multi-Party Private Set Intersection", "abstract": "Over-Threshold Multi-Party Private Set Intersection (OT-MP-PSI) is the problem where several parties, each holding a set of elements, want to know which elements appear in at least t sets, for a certain threshold t, without revealing any information about elements that do not meet this threshold. This problem has many practical applications, but current solutions require a number of expensive operations exponential in t and thus are impractical. In this work we introduce two new OT-MP-PSI constructions using more efficient techniques. Our more refined scheme, which we call , runs in three communication rounds. achieves communication complexity that is linear in the number of parties, the number of elements they hold, and the intersection threshold. The computational cost of is still exponential in t, but it relies on cheap linear operations and thus it is still practical. We implement our new constructions to validate their practicality for varying thresholds, number of parties, and dataset size."}}
{"id": "dKSTrkMm4A", "cdate": 1514764800000, "mdate": 1681826006089, "content": {"title": "Solutions to Abel's Integral Equations in Distributions", "abstract": ""}}
