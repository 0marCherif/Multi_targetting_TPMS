{"id": "bcGkOCl_z4", "cdate": 1698835503505, "mdate": null, "content": {"title": "Image Desnowing via Deep Invertible Separation", "abstract": "Images taken on snowy days often suffer from severe negative visual effects caused by snowflakes. The task of removing snowflakes from a snowy image is known as image desnowing, which is challenging as image details are easily mistakenly treated and thus may be significantly lost during snowflake removal. Leveraging invertible neural networks (INNs), this paper presents a deep learning-based method for single image desnowing, which can remove snowflakes accurately while preserving image details well. Interpreting desnowing as an image decomposition problem, we propose an INN composed of two asymmetric interactive paths for predicting a latent image and a snowflake layer respectively. Such an INN is able to progressively refine the features of both latent images and snowflake layers for disentanglement, while retaining all information possibly relevant to latent image reconstruction. In addition, an attentive coupling layer supervised by snowflake masks is introduced to enhance feature dismantlement and a coupling-in-coupling structure is developed for further improvement. Extensive experiments show that, the proposed method outperforms existing ones on three benchmark datasets of synthetic and real-world images, and meanwhile it also shows advantages in terms of model size and computational efficiency."}}
{"id": "FxoJ_h4ViCA", "cdate": 1668080439047, "mdate": 1668080439047, "content": {"title": "Low-Light Image Enhancement Using Discrepant Untrained Network Priors", "abstract": "This paper proposes a deep learning method for low-light image enhancement, which exploits the generation capability of Neural Networks (NNs) while requiring no training samples except the input image itself. Based on the Retinex decomposition model, the reflectance and illumination of a low-light image are parameterized by two untrained NNs. The ambiguity between the two layers is resolved by the discrepancy between the two NNs in terms of architecture and capacity, while the complex noise with spatially-varying characteristics is handled by an illumination-adaptive self-supervised denoising module. The enhancement is done by jointly optimizing the Retinex decomposition and the illumination adjustment. Extensive experiments show that the proposed method not only outperforms existing non-learning-based and unsupervised-learning-based methods, but also competes favorably with some supervised-learning-based methods in extreme low-light conditions."}}
{"id": "vBefKMaZTk", "cdate": 1668047622171, "mdate": 1668047622171, "content": {"title": "Self-supervised Deep Image Restoration via Adaptive Stochastic Gradient Langevin Dynamics", "abstract": "While supervised deep  learning has been a prominent tool for solving many image restoration problems, \n  there is an increasing interest on studying self-supervised or un-supervised methods to address the challenges and costs of collecting  truth images. Based on the neuralization of a Bayesian estimator of the problem, this paper presents a self-supervised deep learning approach to general image restoration problems. The key ingredient of the neuralized estimator is  an adaptive stochastic gradient Langevin dynamics algorithm for efficiently sampling the posterior distribution of network weights.\n The proposed method is applied on two image restoration problems: compressed sensing and  phase retrieval. The experiments on these applications showed that  the proposed method not only outperformed existing non-learning and unsupervised  solutions in terms of image restoration quality, but also is more computationally efficient. "}}
{"id": "UPioh_Nk7J", "cdate": 1668047489929, "mdate": 1668047489929, "content": {"title": "Un-supervised learning for blind image deconvolution via Monte-Carlo sampling", "abstract": "Deep learning has been a powerful tool for solving many inverse imaging problems. The majority of existing deep-learning-based solutions are super- vised on an external dataset with many blurred/latent image pairs. Recently, there has been an increasing interest on developing dataset-free deep learn- ing methods for image recovery without any prerequisite on external training dataset, including blind deconvolution. This paper aims at developing an un- supervised learning method for blind image deconvolution, which does not call any training sample yet provides very competitive performance. Based on the re-parametrization of latent image using a deep network with random weights, this paper proposed to approximate the maximum-a posteriori estimator of the blur kernel using the Monte-Carlo (MC) sampling method. The MC sampling is efficiently implemented by using dropout and random noise layer, which does not require conjugate model as traditional variational inference does. Exten- sive experiments on popular benchmark datasets for blind image deconvolution showed that the proposed method not only outperformed existing non-learning methods, but also noticeably outperformed existing deep learning methods, including both supervised and un-supervised ones."}}
{"id": "kHMhPt4Mon", "cdate": 1667374938378, "mdate": 1667374938378, "content": {"title": "Learning Deep Non-Blind Image Deconvolution Without Ground Truths", "abstract": "Non-blind image deconvolution (NBID) is about restoring a latent sharp image from a blurred one, given an associated blur kernel. Most existing deep neural networks for NBID are trained over many ground truth (GT) images, which limits their applicability in practical applications such as microscopic imaging and medical imaging. This paper proposes an unsupervised deep learning approach for NBID which avoids accessing GT images. The challenge raised from the absence of GT images is tackled by a self-supervised reconstruction loss that approximates its supervised counterpart well. The possible errors of blur kernels are addressed by a self-supervised prediction loss based on intermediate samples as well as an ensemble inference scheme based on kernel perturbation. The experiments show that the proposed approach provides very competitive performance to existing supervised learning-based methods, no matter under accurate kernels or erroneous kernels"}}
{"id": "0mrQXpKoNM", "cdate": 1667374798451, "mdate": 1667374798451, "content": {"title": "Recorrupted-to-Recorrupted: Unsupervised Deep Learning for Image Denoising", "abstract": "Deep denoiser, the deep network for denoising, has been the focus of the recent development on image denoising. In the last few years, there is an increasing interest in developing unsupervised deep denoisers which only call unorganized noisy images without ground truth for training. Nevertheless, the performance of these unsupervised deep denoisers is not competitive to their supervised counterparts. Aiming at developing a more powerful unsupervised deep denoiser, this paper proposed a data augmentation technique, called recorrupted-to-recorrupted (R2R), to address the overfitting caused by the absence of truth images. For each noisy image, we showed that the cost function defined on the noisy/noisy image pairs constructed by the R2R method is statistically equivalent to its supervised counterpart defined on the noisy/truth image pairs. Extensive experiments showed that the proposed R2R method noticeably outperformed existing unsupervised deep denoisers, and is competitive to representative supervised deep denoisers."}}
{"id": "xOqqlH_E5k0", "cdate": 1652737750775, "mdate": null, "content": {"title": "Augmented Deep Unrolling Networks for Snapshot Compressive Hyperspectral Imaging", "abstract": "Snapshot compressive hyperspectral imaging requires reconstructing a hyperspectral image from its snapshot measurement. This paper proposes an augmented deep unrolling neural network for solving such a challenging reconstruction problem. The proposed network is based on the unrolling of a proximal gradient descent algorithm with two innovative modules for gradient update and proximal mapping. The gradient update is modeled by a memory-assistant descent module motivated by the momentum-based acceleration heuristics. The proximal mapping is modeled by a sub-network with a cross-stage self-attention which effectively exploits inherent self-similarities of a hyperspectral image along the spectral axis, as well as enhancing the feature flow through the network. Moreover, a spectral geometry consistency loss is proposed to encourage the model to concentrate more on the geometric layer of spectral curves for better reconstruction. Extensive experiments on several datasets showed the performance advantage of our approach over the latest methods."}}
{"id": "kSR-_SVzDR-", "cdate": 1621629791505, "mdate": null, "content": {"title": "Gaussian Kernel Mixture Network for Single Image Defocus Deblurring", "abstract": "Defocus blur is one kind of blur effects often seen in images, which is challenging to remove due to its spatially variant amount. This paper presents  an end-to-end deep learning approach for removing defocus blur from a single image, so as to have an all-in-focus image for consequent vision tasks. First, a  pixel-wise Gaussian kernel mixture (GKM) model is  proposed for representing spatially variant defocus blur kernels in an efficient linear parametric form, with higher accuracy than existing models. Then, a deep neural network called GKMNet is developed by unrolling a fixed-point iteration of the GKM-based deblurring.  The GKMNet is built on a lightweight scale-recurrent architecture, with a scale-recurrent attention module for estimating the mixing coefficients in GKM for defocus deblurring. Extensive experiments show that the GKMNet not only noticeably outperforms existing defocus deblurring methods, but also has its advantages in terms of model complexity and computational efficiency."}}
{"id": "OxXmQpfdiQG", "cdate": 1621629791505, "mdate": null, "content": {"title": "Gaussian Kernel Mixture Network for Single Image Defocus Deblurring", "abstract": "Defocus blur is one kind of blur effects often seen in images, which is challenging to remove due to its spatially variant amount. This paper presents  an end-to-end deep learning approach for removing defocus blur from a single image, so as to have an all-in-focus image for consequent vision tasks. First, a  pixel-wise Gaussian kernel mixture (GKM) model is  proposed for representing spatially variant defocus blur kernels in an efficient linear parametric form, with higher accuracy than existing models. Then, a deep neural network called GKMNet is developed by unrolling a fixed-point iteration of the GKM-based deblurring.  The GKMNet is built on a lightweight scale-recurrent architecture, with a scale-recurrent attention module for estimating the mixing coefficients in GKM for defocus deblurring. Extensive experiments show that the GKMNet not only noticeably outperforms existing defocus deblurring methods, but also has its advantages in terms of model complexity and computational efficiency."}}
{"id": "lU3Te8xLYR", "cdate": 1601308170600, "mdate": null, "content": {"title": "Self-supervised Bayesian Deep Learning for Image Denoising", "abstract": "Deep learning is currently one prominent approach for image denoising, and most of existing works train a denoising neural network (NN) on many pairs of noisy images and their clean counterparts. Recent studies showed that it is possible to train a denoising NN on a dataset consisting of only noisy images. This paper took one step further to study how to train a powerful denoising NN for a given image without any training samples, which is appealing to the applications where collecting training samples is challenging. For instance, biological imaging and medical imaging.\nBuilt on the Bayesian neural network (BNN), this paper proposed a self-supervised deep learning method for denoising a single image, in the absence of training samples. The experiments showed that the performance of our self-supervised method is very competitive to those state-of-the-art supervised ones."}}
