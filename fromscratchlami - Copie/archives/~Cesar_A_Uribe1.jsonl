{"id": "XmIO33yKUn", "cdate": 1693408097206, "mdate": 1693408097206, "content": {"title": "Near-optimal tensor methods for minimizing the gradient norm of convex functions and accelerated primal-dual tensor methods", "abstract": "Motivated, in particular, by the entropy-regularized optimal transport problem, we\nconsider convex optimization problems with linear equality constraints, where the\ndual objective has Lipschitz p-th order derivatives, and develop two approaches for\nsolving such problems. The first approach is based on the minimization of the norm of\nthe gradient in the dual problem and then the reconstruction of an approximate pri-\nmal solution. Recently, Grapiglia and Nesterov [22] showed lower complexity bounds\nfor the problem of minimizing the gradient norm of the function with Lipschitz p-th\norder derivatives. Still, the question of optimal or near-optimal methods remained\nopen as the algorithms presented in [22] achieve suboptimal bounds only. We close\nthis gap by proposing two near-optimal (up to logarithmic factors) methods with\ncomplexity bounds \u02dcO(\u03b5\u22122(p+1)/(3p+1)) and \u02dcO(\u03b5\u22122/(3p+1)) with respect to the initial\nobjective residual and the distance between the starting point and solution respec-\ntively. We then apply these results (having independent interest) to our primal-dual\nsetting. As the second approach, we propose a direct accelerated primal-dual tensor\nmethod for convex problems with linear equality constraints, where the dual objec-\ntive has Lipschitz p-th order derivatives. For this algorithm, we prove \u02dcO(\u03b5\u22121/(p+1))\ncomplexity in terms of the duality gap and the residual in the constraints. We il-\nlustrate the practical performance of the proposed algorithms in experiments on\nlogistic regression, entropy-regularized optimal transport problem, and the minimal\nmutual information problem."}}
{"id": "MBAIJg6BHoq", "cdate": 1680456873092, "mdate": 1680456873092, "content": {"title": "On the Performance of Gradient Tracking with Local Updates", "abstract": "We study the decentralized optimization problem where a network of n agents seeks to minimize the average of a set of heterogeneous non-convex cost functions distributedly. State-of-the-art decentralized algorithms like Exact Diffusion~(ED) and Gradient Tracking~(GT) involve communicating every iteration. However, communication is expensive, resource intensive, and slow. In this work, we analyze a locally updated GT method (LU-GT), where agents perform local recursions before interacting with their neighbors. While local updates have been shown to reduce communication overhead in practice, their theoretical influence has not been fully characterized. We show LU-GT has the same communication complexity as the Federated Learning setting but allows arbitrary network topologies. In addition, we prove that the number of local updates does not degrade the quality of the solution achieved by LU-GT. Numerical examples reveal that local updates can lower communication costs in certain regimes (e.g., well-connected graphs). "}}
{"id": "gnVFs9pt2e", "cdate": 1664924969474, "mdate": null, "content": {"title": "PersA-FL: Personalized Asynchronous Federated Learning", "abstract": "We study the personalized federated learning problem under asynchronous updates. In this problem, each client seeks to obtain a personalized model that simultaneously outperforms local and global models. We consider two optimization-based frameworks for personalization: (i) Model-Agnostic Meta-Learning (MAML) and (ii) Moreau Envelope (ME). MAML involves learning a joint model adapted for each client through fine-tuning, whereas ME requires a bi-level optimization problem with implicit gradients to enforce personalization via regularized losses. We focus on improving the scalability of personalized federated learning by removing the synchronous communication assumption. Moreover, we extend the studied function class by removing boundedness assumptions on the gradient norm. Our main technical contribution is a unified proof for asynchronous federated learning with bounded staleness that we apply to MAML and ME personalization frameworks. For the smooth and non-convex functions class, we show the convergence of our method to a first-order stationary point. We illustrate the performance of our method and its tolerance to staleness through experiments for classification tasks over heterogeneous datasets."}}
{"id": "MCULxzgbFMC", "cdate": 1663939410391, "mdate": null, "content": {"title": "Unbounded Gradients in Federated Learning with Buffered Asynchronous Aggregation", "abstract": "Synchronous updates may compromise the efficiency of cross-device federated learning once the number of active clients increases. The FedBuff algorithm (Nguyen et al.) alleviates this problem by allowing asynchronous updates (staleness), which enhances the scalability of training while preserving privacy via secure aggregation. We revisit the FedBuff algorithm for asynchronous federated learning and extend the existing analysis by removing the boundedness assumptions from the gradient norm. This paper presents a theoretical analysis of the convergence rate of this algorithm when heterogeneity in data, batch size, and delay are considered."}}
{"id": "B97oWNza7ej", "cdate": 1653595781755, "mdate": null, "content": {"title": "PARS-Push: Personalized, Asynchronous and Robust Decentralized Optimization", "abstract": "We study the decentralized multi-step Model-Agnostic Meta-Learning (MAML) framework where a group of $n$ agents seeks to find a common point that enables ``few-shot'' learning (personalization) via local stochastic gradient steps on their local functions. We formulate the personalized optimization problem under the MAML framework and propose PARS-Push, a decentralized asynchronous algorithm robust to message failures, communication delays, and directed message sharing. We characterize the convergence rate of PARS-Push for smooth and strongly convex and smooth and non-convex functions under arbitrary multi-step personalization. Moreover, we provide numerical experiments showing its performance under heterogeneous data setups."}}
{"id": "uZwkAm0yUUY", "cdate": 1648673408543, "mdate": null, "content": {"title": "On Arbitrary Compression for Decentralized Consensus and Stochastic Optimization over Directed Networks", "abstract": "We study the decentralized consensus and stochastic optimization problems under compressed message sharing over a fixed directed graph. Our goal is to minimize the sum of $n$ functions, each accessible to a single node, where local communications are subject to a directed network. In this work, we propose an iterative push-sum algorithm with compressed message sharing to reduce the communication overhead on the network. Contrary to existing literature, we allow for arbitrary compression ratios in the communicated messages. We provide explicit convergence rates for the stochastic optimization problem on smooth functions that are either (i) strongly convex, (ii) convex, or (iii) non-convex. Finally, we provide numerical experiments to illustrate the arbitrary compression and communication efficiency of our algorithm."}}
{"id": "Hk-MO3bOWH", "cdate": 1546300800000, "mdate": null, "content": {"title": "On the Complexity of Approximating Wasserstein Barycenters", "abstract": "We study the complexity of approximating the Wasserstein barycenter of $m$ discrete measures, or histograms of size $n$, by contrasting two alternative approaches that use entropic regularization. ..."}}
{"id": "Hy-OY8-ObS", "cdate": 1514764800000, "mdate": null, "content": {"title": "Decentralize and Randomize: Faster Algorithm for Wasserstein Barycenters", "abstract": "We study the decentralized distributed computation of discrete approximations for the regularized Wasserstein barycenter of a finite set of continuous probability measures distributedly stored over a network. We assume there is a network of agents/machines/computers, and each agent holds a private continuous probability measure and seeks to compute the barycenter of all the measures in the network by getting samples from its local measure and exchanging information with its neighbors. Motivated by this problem, we develop, and analyze, a novel accelerated primal-dual stochastic gradient method for general stochastic convex optimization problems with linear equality constraints. Then, we apply this method to the decen- tralized distributed optimization setting to obtain a new algorithm for the distributed semi-discrete regularized Wasserstein barycenter problem. Moreover, we show explicit non-asymptotic complexity for the proposed algorithm. Finally, we show the effectiveness of our method on the distributed computation of the regularized Wasserstein barycenter of univariate Gaussian and von Mises distributions, as well as some applications to image aggregation."}}
