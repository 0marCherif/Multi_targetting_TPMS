{"id": "iop8rRYtggi", "cdate": 1667393651668, "mdate": null, "content": {"title": "Stochastic Causal Programming for Bounding Treatment Effects", "abstract": "Causal effect estimation is important for many tasks in the natural and social sciences. We design algorithms for the continuous partial identification problem: bounding the effects of multivariate, continuous treatments when unmeasured confounding makes identification impossible. Specifically, we cast causal effects as objective functions within a constrained optimization problem, and minimize/maximize these functions to obtain bounds. We combine flexible learning algorithms with Monte Carlo methods to implement a family of solutions under the name of stochastic causal programming. In particular, we show how the generic framework can be efficiently formulated in settings where auxiliary variables are clustered into pre-treatment and post-treatment sets, where no fine-grained causal graph can be easily specified. In these settings, we can avoid the need for fully specifying the distribution family of hidden common causes. Monte Carlo computation is also much simplified, leading to algorithms which are more computationally stable against alternatives."}}
{"id": "4ibOA68LNC", "cdate": 1664815575241, "mdate": null, "content": {"title": "Partial identification without distributional assumptions", "abstract": "Causal effect estimation is important for numerous tasks in the natural and social sciences. However, identifying effects is impossible from observational data without making strong, often untestable assumptions which might not be applicable to real-world data. We consider algorithms for the partial identification problem, bounding the effects of multivariate, continuous treatments over multiple possible causal models when unmeasured confounding makes identification impossible. Even in the partial identification setting, most current work is only applicable in the discrete setting. We propose a framework which is applicable to continuous high-dimensional data. The observable evidence is matched to the implications of constraints encoded in a causal model by norm-based criteria. In particular, for the IV setting, we present ways by which such constrained optimization problems can be parameterized without likelihood functions for the causal or the observed data model, reducing the computational and statistical complexity of the task."}}
{"id": "DFKQaXUFpNh", "cdate": 1634225690497, "mdate": 1634225690497, "content": {"title": "Addressing Fairness in Classification with a Model-Agnostic Multi-Objective Algorithm", "abstract": "The goal of fairness in classification is to learn a\nclassifier that does not discriminate against groups\nof individuals based on sensitive attributes, such as\nrace and gender. One approach to designing fair al-\ngorithms is to use relaxations of fairness notions as\nregularization terms or in a constrained optimiza-\ntion problem. We observe that the hyperbolic tan-\ngent function can approximate the indicator func-\ntion. We leverage this property to define a differen-\ntiable relaxation that approximates fairness notions\nprovably better than existing relaxations. In addi-\ntion, we propose a model-agnostic multi-objective\narchitecture that can simultaneously optimize for\nmultiple fairness notions and multiple sensitive\nattributes and supports all statistical parity-based\nnotions of fairness. We use our relaxation with\nthe multi-objective architecture to learn fair clas-\nsifiers. Experiments on public datasets show that\nour method suffers a significantly lower loss of ac-\ncuracy than current debiasing algorithms relative\nto the unconstrained model."}}
