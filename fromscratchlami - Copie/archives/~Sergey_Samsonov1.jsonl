{"id": "fpMpNvte8P", "cdate": 1680307200000, "mdate": 1682603818859, "content": {"title": "Simultaneous approximation of a smooth function and its derivatives by deep neural networks with piecewise-polynomial activations", "abstract": ""}}
{"id": "JqkfNXJUbKl", "cdate": 1672531200000, "mdate": 1682603818826, "content": {"title": "Theoretical guarantees for neural control variates in MCMC", "abstract": "In this paper, we propose a variance reduction approach for Markov chains based on additive control variates and the minimization of an appropriate estimate for the asymptotic variance. We focus on the particular case when control variates are represented as deep neural networks. We derive the optimal convergence rate of the asymptotic variance under various ergodicity assumptions on the underlying Markov chain. The proposed approach relies upon recent results on the stochastic errors of variance reduction algorithms and function approximation theory."}}
{"id": "zb-xfApk4ZK", "cdate": 1652737460756, "mdate": null, "content": {"title": "Local-Global MCMC kernels: the best of both worlds", "abstract": "Recent works leveraging learning to enhance sampling have shown promising results, in particular by designing effective non-local moves and global proposals. However, learning accuracy is inevitably limited in regions where little data is available such as in the tails of distributions as well as in high-dimensional problems. In the present paper we study an Explore-Exploit Markov chain Monte Carlo strategy ($\\operatorname{Ex^2MCMC}$) that combines local and global samplers showing that it enjoys the advantages of both approaches. We prove $V$-uniform geometric ergodicity of $\\operatorname{Ex^2MCMC}$ without requiring a uniform adaptation of the global sampler to the target distribution. We also compute explicit bounds on the mixing rate of the Explore-Exploit strategy under realistic conditions. Moreover, we propose an adaptive version of the strategy ($\\operatorname{FlEx^2MCMC}$) where a normalizing flow is trained while sampling to serve as a proposal for global moves. We illustrate the efficiency of $\\operatorname{Ex^2MCMC}$ and its adaptive version on classical sampling benchmarks as well as in sampling high-dimensional distributions defined by Generative Adversarial Networks seen as Energy Based Models."}}
{"id": "HH_jBD2ObPq", "cdate": 1652737446106, "mdate": null, "content": {"title": "BR-SNIS: Bias Reduced Self-Normalized Importance Sampling", "abstract": "Importance Sampling (IS) is a method for approximating expectations with respect to a target distribution using independent samples from a proposal distribution and the associated to importance weights. In many cases, the target distribution is known up to a normalization constant and self-normalized IS (SNIS) is then used. While the use of self-normalization can have a positive effect on the dispersion of the estimator, it introduces bias. In this work, we propose a new method BR-SNIS whose complexity is essentially the same as SNIS and which significantly reduces bias. This method is a wrapper, in the sense that it uses the same proposal samples and importance weights but makes a clever use of iterated sampling-importance-resampling (i-SIR) to form a bias-reduced version of the estimator. We derive the proposed algorithm with rigorous theoretical results, including novel bias, variance, and high-probability bounds. We illustrate our findings with numerical examples."}}
{"id": "xB76o_B2CcW", "cdate": 1640995200000, "mdate": 1682603818813, "content": {"title": "Variance reduction for additive functionals of Markov chains via martingale representations", "abstract": "In this paper, we propose an efficient variance reduction approach for additive functionals of Markov chains relying on a novel discrete-time martingale representation. Our approach is fully non-asymptotic and does not require the knowledge of the stationary distribution (and even any type of ergodicity) or specific structure of the underlying density. By rigorously analyzing the convergence properties of the proposed algorithm, we show that its cost-to-variance product is indeed smaller than one of the naive algorithms. The numerical performance of the new method is illustrated for the Langevin-type Markov chain Monte Carlo (MCMC) methods."}}
{"id": "qDgy1I26tS", "cdate": 1640995200000, "mdate": 1682081387882, "content": {"title": "BR-SNIS: Bias Reduced Self-Normalized Importance Sampling", "abstract": "Importance Sampling (IS) is a method for approximating expectations under a target distribution using independent samples from a proposal distribution and the associated importance weights. In many applications, the target distribution is known only up to a normalization constant, in which case self-normalized IS (SNIS) can be used. While the use of self-normalization can have a positive effect on the dispersion of the estimator, it introduces bias. In this work, we propose a new method, BR-SNIS, whose complexity is essentially the same as that of SNIS and which significantly reduces bias without increasing the variance. This method is a wrapper in the sense that it uses the same proposal samples and importance weights as SNIS, but makes clever use of iterated sampling--importance resampling (ISIR) to form a bias-reduced version of the estimator. We furnish the proposed algorithm with rigorous theoretical results, including new bias, variance and high-probability bounds, and these are illustrated by numerical examples."}}
{"id": "G_XH34lm5X", "cdate": 1640995200000, "mdate": 1682603818733, "content": {"title": "From Dirichlet to Rubin: Optimistic Exploration in RL without Bonuses", "abstract": "We propose the Bayes-UCBVI algorithm for reinforcement learning in tabular, stage-dependent, episodic Markov decision process: a natural extension of the Bayes-UCB algorithm by Kaufmann et al. 2012..."}}
{"id": "1l8eesnV8_J", "cdate": 1640995200000, "mdate": 1682603818774, "content": {"title": "Finite-time High-probability Bounds for Polyak-Ruppert Averaged Iterates of Linear Stochastic Approximation", "abstract": "This paper provides a finite-time analysis of linear stochastic approximation (LSA) algorithms with fixed step size, a core method in statistics and machine learning. LSA is used to compute approximate solutions of a $d$-dimensional linear system $\\bar{\\mathbf{A}} \\theta = \\bar{\\mathbf{b}}$ for which $(\\bar{\\mathbf{A}}, \\bar{\\mathbf{b}})$ can only be estimated by (asymptotically) unbiased observations $\\{(\\mathbf{A}(Z_n),\\mathbf{b}(Z_n))\\}_{n \\in \\mathbb{N}}$. We consider here the case where $\\{Z_n\\}_{n \\in \\mathbb{N}}$ is an i.i.d. sequence or a uniformly geometrically ergodic Markov chain. We derive $p$-th moment and high-probability deviation bounds for the iterates defined by LSA and its Polyak-Ruppert-averaged version. Our finite-time instance-dependent bounds for the averaged LSA iterates are sharp in the sense that the leading term we obtain coincides with the local asymptotic minimax limit. Moreover, the remainder terms of our bounds admit a tight dependence on the mixing time $t_{\\operatorname{mix}}$ of the underlying chain and the norm of the noise variables. We emphasize that our result requires the SA step size to scale only with logarithm of the problem dimension $d$."}}
{"id": "7nWS_1Gkqt", "cdate": 1621630009223, "mdate": null, "content": {"title": "Tight High Probability Bounds for Linear Stochastic Approximation with Fixed Stepsize", "abstract": "This paper provides a non-asymptotic analysis of linear stochastic approximation (LSA) algorithms with fixed stepsize. This family of methods arises in many machine learning tasks and is used to obtain approximate solutions of a linear system $\\bar{A}\\theta = \\bar{b}$ for which $\\bar{A}$ and $\\bar{b}$ can only be accessed through random estimates $\\{({\\bf A}_n, {\\bf b}_n): n \\in \\mathbb{N}^*\\}$.  Our analysis is based on new results regarding moments and high probability bounds for products of matrices which are shown to be tight. We derive high probability bounds on the performance of LSA under weaker conditions on the sequence $\\{({\\bf A}_n, {\\bf b}_n): n \\in \\mathbb{N}^*\\}$ than previous works. However, in contrast, we establish polynomial concentration bounds with order depending on the stepsize. We show that our conclusions cannot be improved  without additional assumptions on the sequence of random matrices $\\{{\\bf A}_n: n \\in \\mathbb{N}^*\\}$, and in particular that no Gaussian or exponential high probability bounds can hold.  Finally, we pay a particular attention to establishing  bounds with sharp order with respect to the number of iterations and the stepsize and  whose leading terms contain the covariance matrices appearing in the central limit theorems."}}
{"id": "SjBjlKD9ciC", "cdate": 1609459200000, "mdate": 1653668433293, "content": {"title": "Tight High Probability Bounds for Linear Stochastic Approximation with Fixed Stepsize", "abstract": "This paper provides a non-asymptotic analysis of linear stochastic approximation (LSA) algorithms with fixed stepsize. This family of methods arises in many machine learning tasks and is used to obtain approximate solutions of a linear system $\\bar{A}\\theta = \\bar{b}$ for which $\\bar{A}$ and $\\bar{b}$ can only be accessed through random estimates $\\{({\\bf A}_n, {\\bf b}_n): n \\in \\mathbb{N}^*\\}$. Our analysis is based on new results regarding moments and high probability bounds for products of matrices which are shown to be tight. We derive high probability bounds on the performance of LSA under weaker conditions on the sequence $\\{({\\bf A}_n, {\\bf b}_n): n \\in \\mathbb{N}^*\\}$ than previous works. However, in contrast, we establish polynomial concentration bounds with order depending on the stepsize. We show that our conclusions cannot be improved without additional assumptions on the sequence of random matrices $\\{{\\bf A}_n: n \\in \\mathbb{N}^*\\}$, and in particular that no Gaussian or exponential high probability bounds can hold. Finally, we pay a particular attention to establishing bounds with sharp order with respect to the number of iterations and the stepsize and whose leading terms contain the covariance matrices appearing in the central limit theorems."}}
