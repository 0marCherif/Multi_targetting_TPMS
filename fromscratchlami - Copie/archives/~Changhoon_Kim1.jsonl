{"id": "43nOUI4VHUw", "cdate": 1663850476693, "mdate": null, "content": {"title": "Deep Watermarks for Attributing Generative Models", "abstract": "Generative models have enabled the creation of contents that are indistinguishable from those taken from the Nature. Open-source development of such models raised concerns about the risks in their misuse for malicious purposes. One potential risk mitigation strategy is to attribute generative models via watermarking. Current watermarking methods exhibit significant tradeoff between robust attribution accuracy and generation quality, and also lack principles for designing watermarks to improve this tradeoff. This paper investigates the use of latent semantic dimensions as watermarks, from where we can analyze the effects of design variables, including the choice of watermarking dimensions, watermarking strength, and the capacity of watermarks, on the accuracy-quality tradeoff. Compared with previous SOTA, our method requires minimum computation and is more applicable to large-scale models. We use StyleGAN2 and the latent diffusion model to demonstrate the efficacy of our method."}}
{"id": "_kxlwvhOodK", "cdate": 1601308286526, "mdate": null, "content": {"title": " Decentralized Attribution of Generative Models", "abstract": "Growing applications of generative models have led to new threats such as malicious personation and digital copyright infringement. \nOne solution to these threats is model attribution, i.e., the identification of user-end models where the contents under question are generated.\nExisting studies showed empirical feasibility of attribution through a centralized classifier trained on all existing user-end models. \nHowever, this approach is not scalable in a reality where the number of models ever grows. Neither does it provide an attributability guarantee.\nTo this end, this paper studies decentralized attribution, which relies on binary classifiers associated with each user-end model. \nEach binary classifier is parameterized by a user-specific key and distinguishes its associated model distribution from the authentic data distribution. \nWe develop sufficient conditions of the keys that guarantee an attributability lower bound.\nOur method is validated on MNIST, CelebA, and FFHQ datasets. We also examine the trade-off between generation quality and robustness of attribution against adversarial post-processes."}}
