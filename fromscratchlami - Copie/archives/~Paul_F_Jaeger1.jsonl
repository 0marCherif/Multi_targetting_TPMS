{"id": "YnkGMIh0gvX", "cdate": 1663850122489, "mdate": null, "content": {"title": "A Call to Reflect on Evaluation Practices for Failure Detection in Image Classification", "abstract": "Reliable application of machine learning-based decision systems in the wild is one of the major challenges currently investigated by the field. A large portion of established approaches aims to detect erroneous predictions by means of assigning confidence scores. This confidence may be obtained by either quantifying the model's predictive uncertainty, learning explicit scoring functions, or assessing whether the input is in line with the training distribution. Curiously, while these approaches all state to address the same eventual goal of detecting failures of a classifier upon real-world application, they currently constitute largely separated research fields with individual evaluation protocols, which either exclude a substantial part of relevant methods or ignore large parts of relevant failure sources. In this work, we systematically reveal current pitfalls caused by these inconsistencies and derive requirements for a holistic and realistic evaluation of failure detection. To demonstrate the relevance of this unified perspective, we present a large-scale empirical study for the first time enabling benchmarking confidence scoring functions w.r.t all relevant methods and failure sources. The revelation of a simple softmax response baseline as the overall best performing method underlines the drastic shortcomings of current evaluation in the plethora of publicized research on confidence scoring. Code and trained models are at https://github.com/https://github.com/IML-DKFZ/fd-shifts"}}
{"id": "24kBqy8rcB_", "cdate": 1649863755879, "mdate": null, "content": {"title": "Metrics Reloaded - A new recommendation framework for biomedical image analysis validation", "abstract": "Meaningful performance assessment of biomedical image analysis algorithms depends on objective and appropriate performance metrics. There are major shortcomings in the current state of the art. Yet, so far limited attention has been paid to practical pitfalls associated when using particular metrics for image analysis tasks. Therefore, a number of international initiatives have collaborated to offer researchers with guidance and tools for selecting performance metrics in a problem-aware manner. In our proposed framework, the characteristics of the given biomedical problem are first captured in a problem fingerprint, which identifies properties related to domain interests, the target structure(s), the input datasets, and algorithm output. A problem category-specific mapping is applied in the second step to match fingerprints to metrics that reflect domain requirements. Based on input from experts from more than 60 institutions worldwide, we believe our metric recommendation framework to be useful to the MIDL community and to enhance the quality of biomedical image analysis algorithm validation."}}
{"id": "b3RYnJdzOi", "cdate": 1640995200000, "mdate": 1652621612913, "content": {"title": "Realistic Evaluation of FixMatch on Imbalanced Medical Image Classification Tasks", "abstract": "Semi-supervised learning offers great potential for medical image analysis, as it reduces the annotation burden for clinicians. In this work, we apply the state-of-the-art method FixMatch to chest X-ray and retinal image datasets. Our comparison with the supervised-only method is based on a fair hyperparameter tuning budget and includes label imbalance in the labeled set, thus simulating a practical evaluation setup. We find that unlabeled data can be used effectively for the retinal images, especially when using additional methods to counteract label imbalance in the unsupervised loss. In experiments with CheXpert, however, FixMatch does not provide substantial gains."}}
{"id": "8VY5x9dSX_4", "cdate": 1640995200000, "mdate": 1652621612900, "content": {"title": "Abstract: nnDetection - A Self-configuring Method for Medical Object Detection", "abstract": "Simultaneous localisation and categorization of objects in medical images, also referred to as medical object detection, is of high clinical relevance because diagnostic decisions often depend on rating of objects rather than e.g. pixels. For this task, the cumbersome and iterative process of method configuration constitutes a major research bottleneck. Recently, nnU-Net has tackled this challenge for the task of image segmentation with great success."}}
{"id": "ZSUVGSfHt1z", "cdate": 1639139398009, "mdate": null, "content": {"title": "Contrastive Representations for UnsupervisedAnomaly Detection and Localization", "abstract": "Unsupervised anomaly detection in medical imaging aims to detect and localize arbitrary anomalies without requiring labels during training. Generally, this is achieved by learning a data distribution of normal samples and detecting anomalies as regions in the image which deviate from this distribution. In the medical imaging domain, most current state-of-the-art methods use latent variable generative models. Because such models operate directly on sample space, they tend to primarily encode low-level statistics (like pixel intensities), \nwhile having problems capturing fine semantic information within their representations. Recent work has shown that representations obtained from a feature extractor trained with a discriminative task are rich in semantic information. This, however, requires labeled datasets - a prerequisite that is often not fulfilled. We propose CRADL, a framework for unsupervised anomaly detection and localization consisting of a feature extractor trained with a contrastive pretext-task and a generative model which learns the distribution of representations. Through this, we circumvent the need for labels while still being able to fit the generative model on semantic-rich representations. We further compare the quality of these contrastive representations with representations obtained from a VAE and ceVAE in the context of anomaly localization. We evaluate CRADL on the BraTS and ISLES datasets, as well as an in-house dataset, and demonstrate state-of-the-art performance on the task of anomaly localization in our comparison with a VAE and ceVAE."}}
{"id": "3uQ2Z0MhnoE", "cdate": 1639065563124, "mdate": null, "content": {"title": "Improving Explainability of Disentangled Representations using Multipath-Attribution Mappings", "abstract": "Explainable AI aims to render model behavior understandable by humans, which can be seen as an intermediate step in extracting causal relations from correlative patterns. Due to the high risk of possible fatal decisions in image-based clinical diagnostics, it is necessary to integrate explainable AI into these safety-critical systems. Current explanatory methods typically assign attribution scores to pixel regions in the input image, indicating their importance for a model's decision. However, they fall short when explaining why a visual feature is used. We propose a framework that utilizes interpretable disentangled representations for downstream-task prediction. Through visualizing the disentangled representations, we enable experts to investigate possible causation effects by leveraging their domain knowledge. Additionally, we deploy a multi-path attribution mapping for enriching and validating explanations. We demonstrate the effectiveness of our approach on a synthetic benchmark suite and two medical datasets. We show that the framework not only acts as a catalyst for causal relation extraction but also enhances model robustness by enabling shortcut detection without the need for testing under distribution shifts. Code available at https://github.com/IML-DKFZ/m-pax_lib."}}
{"id": "76X9Mthzv4X", "cdate": 1617285716423, "mdate": null, "content": {"title": "Common limitations of performance metrics in biomedical image analysis", "abstract": "While the importance of automatic biomedical image analysis is increasing at an enormous pace, recent meta-research revealed major flaws with respect to algorithm validation. Performance metrics are key for objective, transparent and comparative performance assessment, but little attention has been given to their pitfalls. Under the umbrella of the Helmholtz Imaging Platform (HIP), three international initiatives - the MICCAI Society's challenge working group, the Biomedical Image Analysis Challenges (BIAS) initiative, as well as the benchmarking working group of the MONAI framework - have now joined forces with the mission to generate best practice recommendations with respect to metrics in medical image analysis. Consensus building is achieved via a Delphi process, a popular tool for integrating opinions in large international consortia. The current document serves as a teaser for the results presentation and focuses on the pitfalls of the most commonly used metric in biomedical image analysis, the Dice Similarity Coefficient (DSC), in the categories of (1) mathematical properties/edge cases, (2) task/metric fit and (3) metric aggregation. Being compiled by a large group of experts from more than 30 institutes worldwide, we believe that our framework could be of general interest to the MIDL community and will improve the quality of biomedical image analysis algorithm validation. "}}
{"id": "z5qSgeNkdHU", "cdate": 1609459200000, "mdate": 1652621612911, "content": {"title": "Abstract: Studying Robustness of Semantic Segmentation under Domain Shift in Cardiac MRI", "abstract": "Cardiac magnetic resonance imaging (cMRI) is an integral part of diagnosis in many heart related diseases. Recently, deep neural networks (DNN) have demonstrated successful automatic segmentation, thus alleviating the burden of time-consuming manual contouring of cardiac structures. Moreover, frameworks such as nnU-Net provide entirely automatic model configuration to unseen datasets enabling out-of-the-box application even by non-experts."}}
{"id": "wiS4LRW4h6P", "cdate": 1609459200000, "mdate": 1652621612913, "content": {"title": "Common Limitations of Image Processing Metrics: A Picture Story", "abstract": "While the importance of automatic image analysis is continuously increasing, recent meta-research revealed major flaws with respect to algorithm validation. Performance metrics are particularly key for meaningful, objective, and transparent performance assessment and validation of the used automatic algorithms, but relatively little attention has been given to the practical pitfalls when using specific metrics for a given image analysis task. These are typically related to (1) the disregard of inherent metric properties, such as the behaviour in the presence of class imbalance or small target structures, (2) the disregard of inherent data set properties, such as the non-independence of the test cases, and (3) the disregard of the actual biomedical domain interest that the metrics should reflect. This living dynamically document has the purpose to illustrate important limitations of performance metrics commonly applied in the field of image analysis. In this context, it focuses on biomedical image analysis problems that can be phrased as image-level classification, semantic segmentation, instance segmentation, or object detection task. The current version is based on a Delphi process on metrics conducted by an international consortium of image analysis experts from more than 60 institutions worldwide."}}
{"id": "kKqAxH1OA4", "cdate": 1609459200000, "mdate": 1652621612936, "content": {"title": "GP-ConvCNP: Better Generalization for Convolutional Conditional Neural Processes on Time Series Data", "abstract": "Neural Processes (NPs) are a family of conditional generative models that are able to model a distribution over functions, in a way that allows them to perform predictions at test time conditioned on a number of context points. A recent addition to this family, Convolutional Conditional Neural Processes (ConvCNP), have shown remarkable improvement in performance over prior art, but we find that they sometimes struggle to generalize when applied to time series data. In particular, they are not robust to distribution shifts and fail to extrapolate observed patterns into the future. By incorporating a Gaussian Process into the model, we are able to remedy this and at the same time improve performance within distribution. As an added benefit, the Gaussian Process reintroduces the possibility to sample from the model, a key feature of other members in the NP family."}}
