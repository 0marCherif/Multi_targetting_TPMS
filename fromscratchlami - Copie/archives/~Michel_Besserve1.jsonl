{"id": "AVi8sAlcd2a", "cdate": 1664300345201, "mdate": null, "content": {"title": "Estimating the mechanisms underlying transient dynamics based on peri-event data", "abstract": "Many important dynamical phenomena emerging in complex systems such as storms, stock market crashes, or reactivations of memory engrams in the mammalian brain are transient in nature. We consider the problem of learning accurate models of such phenomena based only on data gathered by detecting such transient events, and analyzing their peri-event dynamics. This approach is widely used to analyze spontaneous activity in brain recording, as it focuses on emerging events of particular significance to brain function. We show, however, that such an approach may misrepresent the properties of the system under study due to the event detection procedure that entails a selection bias. We develop the Debiased Snapshot (DeSnap) approach to de-bias the time-varying properties of the system estimated from such peri-event data and demonstrate its benefits in recovering state-dependent transient dynamics in toy examples and neural time series."}}
{"id": "Z1mlSfNrbnj", "cdate": 1664194165225, "mdate": null, "content": {"title": "Homomorphism AutoEncoder --- Learning Group Structured Representations from Observed Transitions", "abstract": "It is crucial for agents, both biological and artificial, to acquire world models that veridically represent the external world and how it is modified by the agent's own actions. \nWe consider the case where such modifications can be modelled as transformations from a group of symmetries structuring the world state space. \nWe use tools from representation learning and group theory to learn latent representations that account for both sensory information and the actions that alters it during interactions. \nWe introduce the Homomorphism AutoEncoder (HAE), an autoencoder equipped with a learned group representation linearly acting on its latent space trained on 2-step transitions to implicitly enforce the group homomorphism property on the action representation.\nCompared to existing work, our approach makes fewer assumptions on the group representation and on which transformations the agent can sample from. \nWe motivate our method theoretically, and demonstrate empirically that it can learn the correct representation of the groups and the topology of the environment. We also compare its performance in trajectory prediction with previous methods. "}}
{"id": "O_lFCPaF48t", "cdate": 1663850295805, "mdate": null, "content": {"title": "Structure by Architecture: Structured Representations without Regularization", "abstract": "We study the problem of self-supervised structured representation learning using autoencoders for downstream tasks such as generative modeling. Unlike most methods which rely on matching an arbitrary, relatively unstructured, prior distribution for sampling, we propose a sampling technique that relies solely on the independence of latent variables, thereby avoiding the trade-off between reconstruction quality and generative performance typically observed in VAEs. We design a novel autoencoder architecture capable of learning a structured representation without the need for aggressive regularization. Our structural decoders learn a hierarchy of latent variables, thereby ordering the information without any additional regularization or supervision. We demonstrate how these models learn a representation that improves results in a variety of downstream tasks including generation, disentanglement, and extrapolation using several challenging and natural image datasets."}}
{"id": "_eQoI06U3zF", "cdate": 1654886255721, "mdate": null, "content": {"title": "Structure by Architecture: Disentangled Representations without Regularization", "abstract": "We study the problem of self-supervised structured representation learning using autoencoders for downstream tasks such as generative modeling. Unlike most methods which rely on matching an arbitrary, relatively unstructured, prior distribution for sampling, we propose a sampling technique that relies solely on the independence of latent variables, thereby avoiding the trade-off between reconstruction quality and generative performance inherent to VAEs. We design a novel autoencoder architecture capable of learning a structured representation without the need for aggressive regularization. Our structural decoders learn a hierarchy of latent variables, akin to structural causal models, thereby ordering the information without any additional regularization. We demonstrate how these models learn a representation that improves results in a variety of downstream tasks including generation, disentanglement, and extrapolation using several challenging and natural image datasets.\n"}}
{"id": "pQkXDsgVwYJ", "cdate": 1654886254595, "mdate": null, "content": {"title": "Function Classes for Identifiable Nonlinear Independent Component Analysis", "abstract": "Unsupervised learning of latent variable models (LVMs) is widely used to represent data in machine learning. When such model reflects the ground truth factors and the mechanisms mapping them to observations, there is reason to expect that such models allow generalisation in downstream tasks. It is however well known that such identifiability guaranties are typically not achievable without putting constraints on the model class. This is notably the case for nonlinear Independent Component Analysis, in which the LVM maps statistically independent variables to observations via a deterministic nonlinear function. Several families of spurious solutions fitting perfectly the data, but that do not correspond to the ground truth factors can be constructed in generic settings. However, recent work suggests that constraining the function class of such models may promote identifiability. Specifically, function classes with constraints on their partial derivatives, gathered in the Jacobian matrix, have been proposed, such as orthogonal coordinate transformations (OCT), which impose orthogonality of the Jacobian columns. In the present work, we prove that a subclass of these transformations, conformal maps, is identifiable and provide novel theoretical results suggesting that OCTs have properties that prevent families of spurious solutions to spoil identifiability in a generic setting."}}
{"id": "9XUM3-KJ50U", "cdate": 1654886254531, "mdate": null, "content": {"title": "Homomorphism Autoencoder --- Learning Group Structured Representations from Interactions", "abstract": "It is crucial for agents, both biological and artificial, to acquire world models that veridically represent the external world and how it is modified by the agent's own actions. \nWe consider the case where such modifications can be modelled as transformations from a group of symmetries structuring the world state space. \nWe use tools from representation learning and group theory to learn latent representations that account for both sensory information and the actions that alters it during interactions. \nWe introduce the Homomorphism AutoEncoder (HAE), an autoencoder equipped with a learned group representation linearly acting on its latent space trained on 2-step transitions to implicitly enforce the group homomorphism property on the action representation.\nCompared to existing work, our approach makes fewer assumptions on the group representation and on which transformations the agent can sample from. \nWe motivate our method theoretically, and demonstrate empirically that it can learn the correct representation of the groups and the topology of the environment. We also compare its performance in trajectory prediction with previous methods. "}}
{"id": "0wlAmXOfGc", "cdate": 1654841141596, "mdate": null, "content": {"title": "Embrace the Gap: VAEs Perform Independent Mechanism Analysis", "abstract": "Despite the widespread use of variational autoencoders (VAEs), the consequences of optimizing the evidence lower bound (ELBO) opposed to the exact log-likelihood remain poorly understood. We shed light on this matter by studying nonlinear VAEs in the limit of near-deterministic decoders. We first prove that, in this regime, the optimal encoder approximately inverts the decoder---a commonly used but unproven conjecture---which we call self-consistency. Leveraging self-consistency, we show that the ELBO converges to a regularized log-likelihood rather than to the exact one. The regularization term allows VAEs to perform what has been termed independent mechanism analysis (IMA): it adds an inductive bias towards decoders with column-orthogonal Jacobians. This connection to IMA allows us to precisely characterize the gap w.r.t. the log-likelihood in near-deterministic VAEs. Furthermore, it elucidates an unanticipated benefit of ELBO optimization for nonlinear representation learning as, unlike the unregularized log-likelihood, the IMA-regularized objective promotes identification of the ground-truth latent factors. "}}
{"id": "hdZeYGNCTtN", "cdate": 1652737846582, "mdate": null, "content": {"title": "Exploring the Latent Space of Autoencoders with Interventional Assays", "abstract": "Autoencoders exhibit impressive abilities to embed the data manifold into a low-dimensional latent space, making them a staple of representation learning methods. However, without explicit supervision, which is often unavailable, the representation is usually uninterpretable, making analysis and principled progress challenging. We propose a framework, called latent responses, which exploits the locally contractive behavior exhibited by variational autoencoders to explore the learned manifold. More specifically, we develop tools to probe the representation using interventions in the latent space to quantify the relationships between latent variables. We extend the notion of disentanglement to take the learned generative process into account and consequently avoid the limitations of existing metrics that may rely on spurious correlations. Our analyses underscore the importance of studying the causal structure of the representation to improve performance on downstream tasks such as generation, interpolation, and inference of the factors of variation."}}
{"id": "G4GpqX4bKAH", "cdate": 1652737793020, "mdate": null, "content": {"title": "Embrace the Gap: VAEs Perform Independent Mechanism Analysis", "abstract": "Variational autoencoders (VAEs) are a popular framework for modeling complex data distributions; they can be efficiently trained via variational inference by maximizing the evidence lower bound (ELBO), at the expense of a gap to the exact (log-)marginal likelihood. While VAEs are commonly used for representation learning, it is unclear why ELBO maximization would yield useful representations, since unregularized maximum likelihood estimation cannot invert the data-generating process. Yet, VAEs often succeed at this task. We seek to elucidate this apparent paradox by studying nonlinear VAEs in the limit of near-deterministic decoders. We first prove that, in this regime, the optimal encoder approximately inverts the decoder---a commonly used but unproven conjecture---which we refer to as self-consistency. Leveraging self-consistency, we show that the ELBO converges to a regularized log-likelihood. This allows VAEs to perform what has recently been termed independent mechanism analysis (IMA): it adds an inductive bias towards decoders with column-orthogonal Jacobians, which helps recovering the true latent factors. The gap between ELBO and log-likelihood is therefore welcome, since it bears unanticipated benefits for nonlinear representation learning. In experiments on synthetic and image data, we show that VAEs uncover the true latent factors when the data generating process satisfies the IMA assumption."}}
{"id": "DpKaP-PY8bK", "cdate": 1652737725891, "mdate": null, "content": {"title": "Function Classes for Identifiable Nonlinear Independent Component Analysis", "abstract": "Unsupervised learning of latent variable models (LVMs) is widely used to represent data in machine learning. When such model reflects the ground truth factors and the mechanisms mapping them to observations, there is reason to expect that such models allow generalisation in downstream tasks. It is however well known that such identifiability guaranties are typically not achievable without putting constraints on the model class. This is notably the case for nonlinear Independent Component Analysis, in which the LVM maps statistically independent variables to observations via a deterministic nonlinear function. Several families of spurious solutions fitting perfectly the data, but that do not correspond to the ground truth factors can be constructed in generic settings. However, recent work suggests that constraining the function class of such models may promote identifiability. Specifically, function classes with constraints on their partial derivatives, gathered in the Jacobian matrix, have been proposed, such as orthogonal coordinate transformations (OCT), which impose orthogonality of the Jacobian columns. In the present work, we prove that a subclass of these transformations, conformal maps, is identifiable and provide novel theoretical results suggesting that OCTs have properties that prevent families of spurious solutions to spoil identifiability in a generic setting."}}
