{"id": "BzjLaVvr955", "cdate": 1686324869465, "mdate": null, "content": {"title": "Topology-Matching Normalizing Flows for Out-of-Distribution Detection in Robot Learning", "abstract": "To facilitate reliable deployments of autonomous robots in the real world, Out-of-Distribution (OOD) detection capabilities are often required. A powerful approach for OOD detection is based on density estimation with Normalizing Flows (NFs). However, we find that prior work with NFs attempts to match the complex target distribution topologically with na\u0131\u0308ve base distributions leading to adverse implications. In this work, we circumvent this topological mismatch using an expressive class-conditional base distribution trained with an information-theoretic objective to match the required topology. The proposed method enjoys the merits of wide compatibility with existing learned models without any performance degradation and minimum computation overhead while enhancing OOD detection capabilities. We demonstrate superior results in density estimation and 2D object detection benchmarks in comparison with extensive baselines. Moreover, we showcase the applicability of the method with a real-robot deployment."}}
{"id": "MXx4SlCtJh", "cdate": 1686250302962, "mdate": null, "content": {"title": "Safe and Efficient Operation with Constrained Hierarchical Reinforcement Learning", "abstract": "Hierarchical Reinforcement Learning (HRL) holds the promise of enhancing sample efficiency and generalization capabilities of Reinforcement Learning (RL) agents by leveraging task decomposition and temporal abstraction, which aligns with human reasoning. However, the adoption of HRL (and RL in general) to solve problems in the real world has been limited due to, among other reasons, the lack of effective techniques that make the agents adhere to safety requirements encoded as constraints, a common practice to define the functional safety of safety-critical systems. While some constrained Reinforcement Learning methods exist in the literature, we show that regular flat policies can face performance degradation when dealing with safety constraints. To overcome this limitation, we propose a constrained HRL topology that separates planning and control, with constraint optimization achieved at the lower-level abstraction. Simulation experiments show that our approach is able to keep its performance while adhering to safety constraints, even in scenarios where the flat policy's performance deteriorates when trying to prioritize safety."}}
{"id": "Q-s3SDRXFc", "cdate": 1677628800000, "mdate": 1683884434069, "content": {"title": "Generalized density attractor clustering for incomplete data", "abstract": "Mean shift is a popular and powerful clustering method for implementing density attractor clustering (DAC). However, DAC is underdeveloped in terms of modeling definitions and methods for incomplete data. Due to DAC\u2019s importance, solving this common issue is crucial. This work makes DAC more versatile by making it applicable to incomplete data: First, using formal modeling definitions, we propose a unifying framework for DAC. Second, we propose new methods that implement the definitions and perform DAC for incomplete data more efficiently and stably than others. We discuss and compare our methods and the closest competitor using theoretical analyses. We quantify the performance of our methods using synthetic datasets with known structures and real-life business data for three missing value types. Finally, we analyze Stack Overflow\u2019s 2021 survey to extract clusters of programmers from India and the USA. The experiments verify our methods\u2019 superiority to six alternatives. Code, Data: https://bit.ly/genDAC"}}
{"id": "iYA80086YH", "cdate": 1676472365159, "mdate": null, "content": {"title": "Training, Architecture, and Prior for Deterministic Uncertainty Methods", "abstract": "Accurate and efficient uncertainty estimation is crucial to build reliable Machine Learning (ML) models capable to provide calibrated uncertainty estimates, generalize and detect Out-Of-Distribution (OOD) datasets. To this end, Deterministic Uncertainty Methods (DUMs) is a promising model family capable to perform uncertainty estimation in a single forward pass. This work investigates important design choices in DUMs: (1) we show that training schemes decoupling the core architecture and the uncertainty head schemes can significantly improve uncertainty performances. (2) we demonstrate that the core architecture expressiveness is crucial for uncertainty performance and that additional architecture constraints to avoid feature collapse can deteriorate the trade-off between OOD generalization and detection. (3) Contrary to other Bayesian models, we show that the prior defined by DUMs do not have a strong effect on the final performances."}}
{"id": "cS3_jJ0se3z", "cdate": 1675896011536, "mdate": null, "content": {"title": "The Power of Motifs as Inductive Bias for Learning Molecular Distributions", "abstract": "Machine learning for molecules holds great potential for efficiently exploring the vast chemical space and thus streamlining the drug discovery process by facilitating the design of new therapeutic molecules. Deep generative models have shown promising results for molecule generation, but the benefits of specific inductive biases for learning distributions over small graphs are unclear. Our study aims to investigate the impact of subgraph structures and vocabulary design on distribution learning, using small drug molecules as a case study. To this end, we introduce Subcover, a new subgraph-based fragmentation scheme, and evaluate it through a two-step variational auto-encoder. Our results show that Subcover\u2019s improved identification of chemically meaningful subgraphs leads to a relative improvement of the FCD score by 30%, outperforming previous methods. Our findings highlight the potential of Subcover to enhance the performance and scalability of existing methods, contributing to the advancement of drug discovery."}}
{"id": "sxPa-fq10c", "cdate": 1672531200000, "mdate": 1680950859452, "content": {"title": "Are Defenses for Graph Neural Networks Robust?", "abstract": ""}}
{"id": "seOPjLri7Bf", "cdate": 1672531200000, "mdate": 1683884434611, "content": {"title": "Training, Architecture, and Prior for Deterministic Uncertainty Methods", "abstract": "Accurate and efficient uncertainty estimation is crucial to build reliable Machine Learning (ML) models capable to provide calibrated uncertainty estimates, generalize and detect Out-Of-Distribution (OOD) datasets. To this end, Deterministic Uncertainty Methods (DUMs) is a promising model family capable to perform uncertainty estimation in a single forward pass. This work investigates important design choices in DUMs: (1) we show that training schemes decoupling the core architecture and the uncertainty head schemes can significantly improve uncertainty performances. (2) we demonstrate that the core architecture expressiveness is crucial for uncertainty performance and that additional architecture constraints to avoid feature collapse can deteriorate the trade-off between OOD generalization and detection. (3) Contrary to other Bayesian models, we show that the prior defined by DUMs do not have a strong effect on the final performances."}}
{"id": "cDpJgtF7QQ", "cdate": 1672531200000, "mdate": 1681650823136, "content": {"title": "Ewald-based Long-Range Message Passing for Molecular Graphs", "abstract": ""}}
{"id": "bOILo2G2qIC", "cdate": 1672531200000, "mdate": 1683884434008, "content": {"title": "Diffusion Denoised Smoothing for Certified and Adversarial Robust Out-Of-Distribution Detection", "abstract": "As the use of machine learning continues to expand, the importance of ensuring its safety cannot be overstated. A key concern in this regard is the ability to identify whether a given sample is from the training distribution, or is an \"Out-Of-Distribution\" (OOD) sample. In addition, adversaries can manipulate OOD samples in ways that lead a classifier to make a confident prediction. In this study, we present a novel approach for certifying the robustness of OOD detection within a $\\ell_2$-norm around the input, regardless of network architecture and without the need for specific components or additional training. Further, we improve current techniques for detecting adversarial attacks on OOD samples, while providing high levels of certified and adversarial robustness on in-distribution samples. The average of all OOD detection metrics on CIFAR10/100 shows an increase of $\\sim 13 \\% / 5\\%$ relative to previous approaches."}}
{"id": "a-D6dwhi1-", "cdate": 1672531200000, "mdate": 1680950859452, "content": {"title": "Transformers Meet Directed Graphs", "abstract": ""}}
