{"id": "nerpglTF3L", "cdate": 1672531200000, "mdate": 1695968744738, "content": {"title": "Provably Learning Diverse Features in Multi-View Data with Midpoint Mixup", "abstract": "Mixup is a data augmentation technique that relies on training using random convex combinations of data points and their labels. In recent years, Mixup has become a standard primitive used in the t..."}}
{"id": "Usrjd--QCS", "cdate": 1672531200000, "mdate": 1695968744739, "content": {"title": "Hiding Data Helps: On the Benefits of Masking for Sparse Coding", "abstract": "Sparse coding, which refers to modeling a signal as sparse linear combinations of the elements of a learned dictionary, has proven to be a successful (and interpretable) approach in applications su..."}}
{"id": "YdFkY-QHkPl", "cdate": 1663849979175, "mdate": null, "content": {"title": "Provably Learning Diverse Features in Multi-View Data with Midpoint Mixup", "abstract": "Mixup is a data augmentation technique that relies on training using random convex combinations of data points and their labels. In recent years, Mixup has become a standard primitive used in the training of state-of-the-art image classification models due to its demonstrated benefits over empirical risk minimization with regards to generalization and robustness. In this work, we try to explain some of this success from a feature learning perspective. We focus our attention on classification problems in which each class may have multiple associated features (or views) that can be used to predict the class correctly. Our main theoretical results demonstrate that, for a non-trivial class of data distributions with two features per class, training a 2-layer convolutional network using empirical risk minimization can lead to learning only one feature for almost all classes while training with a specific instantiation of Mixup succeeds in learning both features for every class. We also show empirically that these theoretical insights extend to the practical settings of image benchmarks modified to have additional synthetic features."}}
{"id": "igHwwsrfC6M", "cdate": 1640995200000, "mdate": 1683996467577, "content": {"title": "Towards Understanding the Data Dependency of Mixup-style Training", "abstract": "In the Mixup training paradigm, a model is trained using convex combinations of data points and their associated labels. Despite seeing very few true data points during training, models trained using Mixup seem to still minimize the original empirical risk and exhibit better generalization and robustness on various tasks when compared to standard training. In this paper, we investigate how these benefits of Mixup training rely on properties of the data in the context of classification. For minimizing the original empirical risk, we compute a closed form for the Mixup-optimal classification, which allows us to construct a simple dataset on which minimizing the Mixup loss leads to learning a classifier that does not minimize the empirical loss on the data. On the other hand, we also give sufficient conditions for Mixup training to also minimize the original empirical risk. For generalization, we characterize the margin of a Mixup classifier, and use this to understand why the decision boundary of a Mixup classifier can adapt better to the full structure of the training data when compared to standard training. In contrast, we also show that, for a large class of linear models and linearly separable datasets, Mixup training leads to learning the same classifier as standard training."}}
{"id": "ieNJYujcGDO", "cdate": 1632875600580, "mdate": null, "content": {"title": "Towards Understanding the Data Dependency of Mixup-style Training", "abstract": "In the Mixup training paradigm, a model is trained using convex combinations of data points and their associated labels. Despite seeing very few true data points during training, models trained using Mixup seem to still minimize the original empirical risk and exhibit better generalization and robustness on various tasks when compared to standard training. In this paper, we investigate how these benefits of Mixup training rely on properties of the data in the context of classification. For minimizing the original empirical risk, we compute a closed form for the Mixup-optimal classification, which allows us to construct a simple dataset on which minimizing the Mixup loss leads to learning a classifier that does not minimize the empirical loss on the data. On the other hand, we also give sufficient conditions for Mixup training to also minimize the original empirical risk. For generalization, we characterize the margin of a Mixup classifier, and use this to understand why the decision boundary of a Mixup classifier can adapt better to the full structure of the training data when compared to standard training. In contrast, we also show that, for a large class of linear models and linearly separable datasets, Mixup training leads to learning the same classifier as standard training."}}
{"id": "SsiZyU0h7A1", "cdate": 1546300800000, "mdate": 1637029212521, "content": {"title": "Learning Cross-Lingual Sentence Representations via a Multi-task Dual-Encoder Model", "abstract": "Muthu Chidambaram, Yinfei Yang, Daniel Cer, Steve Yuan, Yunhsuan Sung, Brian Strope, Ray Kurzweil. Proceedings of the 4th Workshop on Representation Learning for NLP (RepL4NLP-2019). 2019."}}
{"id": "Q7ZfpYsYGh", "cdate": 1483228800000, "mdate": 1684266996883, "content": {"title": "Style Transfer Generative Adversarial Networks: Learning to Play Chess Differently", "abstract": "The idea of style transfer has largely only been explored in image-based tasks, which we attribute in part to the specific nature of loss functions used for style transfer. We propose a general formulation of style transfer as an extension of generative adversarial networks, by using a discriminator to regularize a generator with an otherwise separate loss function. We apply our approach to the task of learning to play chess in the style of a specific player, and present empirical evidence for the viability of our approach."}}
