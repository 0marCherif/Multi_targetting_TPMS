{"id": "Sl-eewIi9e5", "cdate": 1646077527662, "mdate": null, "content": {"title": "Reframed GES with a Neural Conditional Dependence Measure", "abstract": "In a nonparametric setting, the causal structure is often identifiable only up to Markov equivalence, and for the purpose of causal inference, it is useful to learn a graphical representation of the Markov equivalence class (MEC).  In this paper, we revisit the Greedy Equivalence Search (GES) algorithm, which is widely cited as a score-based algorithm for learning the MEC of the underlying causal structure. We observe that in order to make the GES algorithm consistent in a nonparametric setting, it is not necessary to design a scoring metric that evaluates graphs. Instead, it suffices to plug in a consistent estimator of a measure of conditional dependence to guide the search. We therefore present a reframing of the GES algorithm, which is more flexible than the standard score-based version and readily lends itself to the nonparametric setting with a general measure of conditional dependence. In addition, we propose a neural conditional dependence (NCD) measure, which utilizes the expressive power of deep neural networks to characterize conditional independence in a nonparametric manner. We establish the optimality of the reframed GES algorithm under standard assumptions and the consistency of using our NCD estimator to decide conditional independence. Together these results justify the proposed approach. Experimental results demonstrate the effectiveness of our method in causal discovery, as well as the advantages of using our NCD measure over kernel-based measures."}}
{"id": "XqUuMgFp_v7", "cdate": 1640995200000, "mdate": 1681653439797, "content": {"title": "Asymptotic Statistical Analysis of f-divergence GAN", "abstract": ""}}
{"id": "7Djk_p7cHw", "cdate": 1640995200000, "mdate": 1681653439767, "content": {"title": "Reframed GES with a neural conditional dependence measure", "abstract": ""}}
{"id": "bZBwFVhbO9I", "cdate": 1609459200000, "mdate": 1634225536253, "content": {"title": "TILGAN: Transformer-based Implicit Latent GAN for Diverse and Coherent Text Generation", "abstract": "Shizhe Diao, Xinwei Shen, Kashun Shum, Yan Song, Tong Zhang. Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021. 2021."}}
{"id": "2gzo62cSPEj", "cdate": 1609459200000, "mdate": 1652669894653, "content": {"title": "CausalVAE: Disentangled Representation Learning via Neural Structural Causal Models", "abstract": "Learning disentanglement aims at finding a low dimensional representation which consists of multiple explanatory and generative factors of the observational data. The framework of variational autoencoder (VAE) is commonly used to disentangle independent factors from observations. However, in real scenarios, factors with semantics are not necessarily independent. Instead, there might be an underlying causal structure which renders these factors dependent. We thus propose a new VAE based framework named CausalVAE, which includes a Causal Layer to transform independent exogenous factors into causal endogenous ones that correspond to causally related concepts in data. We further analyze the model identifiabitily, showing that the proposed model learned from observations recovers the true one up to a certain degree. Experiments are conducted on various datasets, including synthetic and real word benchmark CelebA. Results show that the causal representations learned by CausalVAE are semantically interpretable, and their causal relationship as a Directed Acyclic Graph (DAG) is identified with good accuracy. Furthermore, we demonstrate that the proposed CausalVAE model is able to generate counterfactual data through \"do-operation\" to the causal factors."}}
{"id": "agyFqcmgl6y", "cdate": 1601308184096, "mdate": null, "content": {"title": "Disentangled Generative Causal Representation Learning", "abstract": "This paper proposes a Disentangled gEnerative cAusal Representation (DEAR) learning method. Unlike existing disentanglement methods that enforce independence of the latent variables, we consider the general case where the underlying factors of interests can be causally correlated. We show that previous methods with independent priors fail to disentangle causally related factors. Motivated by this finding, we propose a new disentangled learning method called DEAR that enables causal controllable generation and causal representation learning. The key ingredient of this new formulation is to use a structural causal model (SCM) as the prior for a bidirectional generative model. A generator is then trained jointly with an encoder using a suitable GAN loss. Theoretical justification on the proposed formulation is provided, which guarantees disentangled causal representation learning under appropriate conditions. We conduct extensive experiments on both synthesized and real datasets to demonstrate the effectiveness of DEAR in causal controllable generation, and the benefits of the learned representations for downstream tasks in terms of sample efficiency and distributional robustness."}}
{"id": "vBVxy9LYnnq", "cdate": 1577836800000, "mdate": 1668395837227, "content": {"title": "Disentangled Generative Causal Representation Learning", "abstract": "This paper proposes a Disentangled gEnerative cAusal Representation (DEAR) learning method under appropriate supervised information. Unlike existing disentanglement methods that enforce independence of the latent variables, we consider the general case where the underlying factors of interests can be causally related. We show that previous methods with independent priors fail to disentangle causally related factors even under supervision. Motivated by this finding, we propose a new disentangled learning method called DEAR that enables causal controllable generation and causal representation learning. The key ingredient of this new formulation is to use a structural causal model (SCM) as the prior distribution for a bidirectional generative model. The prior is then trained jointly with a generator and an encoder using a suitable GAN algorithm incorporated with supervised information on the ground-truth factors and their underlying causal structure. We provide theoretical justification on the identifiability and asymptotic convergence of the proposed method. We conduct extensive experiments on both synthesized and real data sets to demonstrate the effectiveness of DEAR in causal controllable generation, and the benefits of the learned representations for downstream tasks in terms of sample efficiency and distributional robustness."}}
{"id": "Myjl4K_kc1g", "cdate": 1577836800000, "mdate": 1681653439963, "content": {"title": "Bidirectional Generative Modeling Using Adversarial Gradient Estimation", "abstract": ""}}
