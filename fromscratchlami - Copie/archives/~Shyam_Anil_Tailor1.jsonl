{"id": "AIgn9uwfcD1", "cdate": 1632875669825, "mdate": null, "content": {"title": "Prospect Pruning: Finding Trainable Weights at Initialization using Meta-Gradients", "abstract": "Pruning neural networks at initialization would enable us to find sparse models that retain the accuracy of the original network while consuming fewer computational resources for training and inference. However, current methods are insufficient to enable this optimization and lead to a large degradation in model performance. In this paper, we identify a fundamental limitation in the formulation of current methods, namely that their saliency criteria look at a single step at the start of training without taking into account the trainability of the network. While pruning iteratively and gradually has been shown to improve pruning performance, explicit consideration of the training stage that will immediately follow pruning has so far been absent from the computation of the saliency criterion. To overcome the short-sightedness of existing methods, we propose Prospect Pruning (ProsPr), which uses meta-gradients through the first few steps of optimization to determine which weights to prune. ProsPr combines an estimate of the higher-order effects of pruning on the loss and the optimization trajectory to identify the trainable sub-network. Our method achieves state-of-the-art pruning performance on a variety of vision classification tasks, with less data and in a single shot compared to existing pruning-at-initialization methods."}}
{"id": "hl9ePdHO4_s", "cdate": 1632875470468, "mdate": null, "content": {"title": "Do We Need Anisotropic Graph Neural Networks?", "abstract": "Common wisdom in the graph neural network (GNN) community dictates that anisotropic models---in which messages sent between nodes are a function of both the source and target node---are required to achieve state-of-the-art performance. Benchmarks to date have demonstrated that these models perform better than comparable isotropic models---where messages are a function of the source node only. In this work we provide empirical evidence challenging this narrative: we propose an isotropic GNN, which we call Efficient Graph Convolution (EGC), that consistently outperforms comparable anisotropic models, including the popular GAT or PNA architectures by using spatially-varying adaptive filters. In addition to raising important questions for the GNN community, our work has significant real-world implications for efficiency. EGC achieves higher model accuracy, with lower memory consumption and latency, along with characteristics suited to accelerator implementation, while being a drop-in replacement for existing architectures. As an isotropic model, it requires memory proportional to the number of vertices in the graph ($\\mathcal{O}(V)$); in contrast, anisotropic models require memory proportional to the number of edges ($\\mathcal{O}(E)$). We demonstrate that EGC outperforms existing approaches across 6 large and diverse benchmark datasets, and conclude by discussing questions that our work raise for the community going forward. Code and pretrained models for our experiments are provided at https://github.com/shyam196/egc."}}
{"id": "NSBrFgJAHg", "cdate": 1601308221793, "mdate": null, "content": {"title": "Degree-Quant: Quantization-Aware Training for Graph Neural Networks", "abstract": "Graph neural networks (GNNs) have demonstrated strong performance on a wide variety of tasks due to their ability to model non-uniform structured data. Despite their promise, there exists little research exploring methods to make them more efficient at inference time. In this work, we explore the viability of training quantized GNNs, enabling the usage of low precision integer arithmetic during inference. For GNNs seemingly unimportant choices in quantization implementation cause dramatic changes in performance. We identify the sources of error that uniquely arise when attempting to quantize GNNs, and propose an architecturally-agnostic and stable method, Degree-Quant, to improve performance over existing quantization-aware training baselines commonly used on other architectures, such as CNNs. We validate our method on six datasets and show, unlike previous quantization attempts, that models generalize to unseen graphs. Models trained with Degree-Quant for INT8 quantization perform as well as FP32 models in most cases; for INT4 models, we obtain up to 26% gains over the baselines. Our work enables up to 4.7x speedups on CPU when using INT8 arithmetic."}}
{"id": "qVXDarcKJyI", "cdate": 1577836800000, "mdate": null, "content": {"title": "A First Step Towards On-Device Monitoring of Body Sounds in the Wild", "abstract": "Body sounds provide rich information about the state of the human body and can be useful in many medical applications. Auscultation, the practice of listening to body sounds, has been used for centuries in respiratory and cardiac medicine to diagnose or track disease progression. To date, however, its use has been confined to clinical and highly controlled settings. Our work addresses this limitation: we devise a chest-mounted wearable for continuous monitoring of body sounds, that leverages data processing algorithms that run on-device. We concentrate on the detection of heart sounds to perform heart rate monitoring. To improve robustness to ambient noise and motion artefacts, our device uses an algorithm that explicitly segments the collected audio into the phases of the cardiac cycle. Our pilot study with 9 users demonstrates that it is possible to obtain heart rate estimates that are competitive with commercial heart rate monitors, with low enough power consumption for continuous use."}}
{"id": "d-SjsblLXsE", "cdate": 1577836800000, "mdate": null, "content": {"title": "Are Accelerometers for Activity Recognition a Dead-end?", "abstract": "Accelerometer-based (and by extension other inertial sensors) research for Human Activity Recognition (HAR) is a dead-end. This sensor does not offer enough information for us to progress in the core domain of HAR - to recognize everyday activities from sensor data. Despite continued and prolonged efforts in improving feature engineering and machine learning models, the activities that we can recognize reliably have only expanded slightly and many of the same flaws of early models are still present today. Instead of relying on acceleration data, we should instead consider modalities with much richer information - a logical choice are images. With the rapid advance in image sensing hardware and modelling techniques, we believe that a widespread adoption of image sensors will open many opportunities for accurate and robust inference across a wide spectrum of human activities. In this paper, we make the case for imagers in place of accelerometers as the default sensor for human activity recognition. Our review of past works has led to the observation that progress in HAR had stalled, caused by our reliance on accelerometers. We further argue for the suitability of images for activity recognition by illustrating their richness of information and the marked progress in computer vision. Through a feasibility analysis, we find that deploying imagers and CNNs on device poses no substantial burden on modern mobile hardware. Overall, our work highlights the need to move away from accelerometers and calls for further exploration of using imagers for activity recognition."}}
{"id": "J_6KLTtPd1L", "cdate": 1577836800000, "mdate": null, "content": {"title": "A first step towards on-device monitoring of body sounds in the wild", "abstract": "Body sounds provide rich information about the state of the human body and can be useful in many medical applications. Auscultation, the practice of listening to body sounds, has been used for centuries in respiratory and cardiac medicine to diagnose or track disease progression. To date, however, its use has been confined to clinical and highly controlled settings. Our work addresses this limitation: we devise a chest-mounted wearable for continuous monitoring of body sounds, that leverages data processing algorithms that run on-device. We concentrate on the detection of heart sounds to perform heart rate monitoring. To improve robustness to ambient noise and motion artefacts, our device uses an algorithm that explicitly segments the collected audio into the phases of the cardiac cycle. Our study with 9 users demonstrates that it is possible to obtain heart rate estimates that are competitive with commercial devices, with low enough power consumption for continuous use."}}
{"id": "J9pxXExiIUy", "cdate": 1577836800000, "mdate": null, "content": {"title": "Are Accelerometers for Activity Recognition a Dead-end?", "abstract": "Accelerometer-based (and by extension other inertial sensors) research for Human Activity Recognition (HAR) is a dead-end. This sensor does not offer enough information for us to progress in the core domain of HAR - to recognize everyday activities from sensor data. Despite continued and prolonged efforts in improving feature engineering and machine learning models, the activities that we can recognize reliably have only expanded slightly and many of the same flaws of early models are still present today. Instead of relying on acceleration data, we should instead consider modalities with much richer information - a logical choice are images. With the rapid advance in image sensing hardware and modelling techniques, we believe that a widespread adoption of image sensors will open many opportunities for accurate and robust inference across a wide spectrum of human activities. In this paper, we make the case for imagers in place of accelerometers as the default sensor for human activity recognition. Our review of past works has led to the observation that progress in HAR had stalled, caused by our reliance on accelerometers. We further argue for the suitability of images for activity recognition by illustrating their richness of information and the marked progress in computer vision. Through a feasibility analysis, we find that deploying imagers and CNNs on device poses no substantial burden on modern mobile hardware. Overall, our work highlights the need to move away from accelerometers and calls for further exploration of using imagers for activity recognition."}}
