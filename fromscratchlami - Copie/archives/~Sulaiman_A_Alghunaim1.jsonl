{"id": "MBAIJg6BHoq", "cdate": 1680456873092, "mdate": 1680456873092, "content": {"title": "On the Performance of Gradient Tracking with Local Updates", "abstract": "We study the decentralized optimization problem where a network of n agents seeks to minimize the average of a set of heterogeneous non-convex cost functions distributedly. State-of-the-art decentralized algorithms like Exact Diffusion~(ED) and Gradient Tracking~(GT) involve communicating every iteration. However, communication is expensive, resource intensive, and slow. In this work, we analyze a locally updated GT method (LU-GT), where agents perform local recursions before interacting with their neighbors. While local updates have been shown to reduce communication overhead in practice, their theoretical influence has not been fully characterized. We show LU-GT has the same communication complexity as the Federated Learning setting but allows arbitrary network topologies. In addition, we prove that the number of local updates does not degrade the quality of the solution achieved by LU-GT. Numerical examples reveal that local updates can lower communication costs in certain regimes (e.g., well-connected graphs). "}}
{"id": "hD3yWT-ly_-", "cdate": 1680214695131, "mdate": 1680214695131, "content": {"title": "Decentralized Proximal Gradient Algorithms with Linear Convergence Rates", "abstract": "This work studies a class of non-smooth decentralized multi-agent optimization problems where the\nagents aim at minimizing a sum of local strongly-convex smooth components plus a common non-smooth\nterm. We propose a general primal-dual algorithmic framework that unifies many existing state-of-the-art\nalgorithms. We establish linear convergence of the proposed method to the exact solution in the presence\nof the non-smooth term. Moreover, for the more general class of problems with agent specific non-smooth\nterms, we show that linear convergence cannot be achieved (in the worst case) for the class of algorithms\nthat uses the gradients and the proximal mappings of the smooth and non-smooth parts, respectively.\nWe further provide a numerical counterexample that shows how some state-of-the-art algorithms fail to\nconverge linearly for strongly-convex objectives and different local non-smooth terms.\n"}}
{"id": "84_3GaaMEAx", "cdate": 1680214613547, "mdate": 1680214613547, "content": {"title": "Linear Convergence of Primal-Dual Gradient Methods and their Performance in Distributed Optimization", "abstract": "In this work, we revisit a classical incremental implementation of the primal-descent dual-ascent gradient method\nused for the solution of equality constrained optimization problems. We provide a short proof that establishes the linear (exponential) convergence of the algorithm for smooth strongly-convex\ncost functions and study its relation to the non-incremental\nimplementation. We also study the effect of the augmented\nLagrangian penalty term on the performance of distributed\noptimization algorithms for the minimization of aggregate cost\nfunctions over multi-agent networks.\n"}}
{"id": "fpmTJgB98TC", "cdate": 1680214484967, "mdate": 1680214484967, "content": {"title": "A unified and refined convergence analysis for non-convex decentralized learning", "abstract": "We study the consensus decentralized optimization problem where the objective\nfunction is the average of n agents private non-convex cost functions; moreover, the\nagents can only communicate to their neighbors on a given network topology. The\nstochastic learning setting is considered in this paper where each agent can only access\na noisy estimate of its gradient. Many decentralized methods can solve such problem\nincluding EXTRA, Exact-Diffusion/D2\n, and gradient-tracking. Unlike the famed Dsgd\nalgorithm, these methods have been shown to be robust to the heterogeneity across\nthe local cost functions. However, the established convergence rates for these methods\nindicate that their sensitivity to the network topology is worse than Dsgd. Such\ntheoretical results imply that these methods can perform much worse than Dsgd over\nsparse networks, which, however, contradicts empirical experiments where Dsgd is\nobserved to be more sensitive to the network topology.\nIn this work, we study a general stochastic unified decentralized algorithm (SUDA)\nthat includes the above methods as special cases. We establish the convergence of\nSUDA under both non-convex and the Polyak- Lojasiewicz condition settings. Our results provide improved network topology dependent bounds for these methods (such as\nExact-Diffusion/D2 and gradient-tracking) compared with existing literature. Moreover, our results show that these methods are often less sensitive to the network topology compared to Dsgd, which agrees with numerical experiments.\n"}}
{"id": "doSG7eYxr9", "cdate": 1680214390640, "mdate": null, "content": {"title": "Local Exact-Diffusion for Decentralized Optimization and Learning", "abstract": "Distributed optimization methods with local updates have recently received a lot of attention due to their potential to reduce the communication cost of distributed methods. In these algorithms, a collection of nodes performs several local updates based on their local data and then communicates with each other to exchange estimate information. While there have been many studies on distributed local methods with centralized network connections, there has been less work on decentralized networks. In this work, we propose and investigate a locally updated decentralized method called Local Exact-Diffusion (LED). We establish the convergence of LED in both convex and nonconvex settings for the stochastic online setting. Our convergence rate bounds improves over the bounds of existing decentralized methods. When we specialize the network to the centralized case, we recover the state-of-the-art bound for centralized methods. We also link LED to several other distributed methods that have been studied independently, including Scaffnew, FedGate, and VRL-SGD. We also numerically investigate the benefits of local updates for decentralized networks and demonstrate the effectiveness of the proposed method."}}
{"id": "hg7D33k2yoI", "cdate": 1640995200000, "mdate": 1681695068682, "content": {"title": "On the Performance of Gradient Tracking with Local Updates", "abstract": "We study the decentralized optimization problem where a network of $n$ agents seeks to minimize the average of a set of heterogeneous non-convex cost functions distributedly. State-of-the-art decentralized algorithms like Exact Diffusion~(ED) and Gradient Tracking~(GT) involve communicating every iteration. However, communication is expensive, resource intensive, and slow. In this work, we analyze a locally updated GT method (LU-GT), where agents perform local recursions before interacting with their neighbors. While local updates have been shown to reduce communication overhead in practice, their theoretical influence has not been fully characterized. We show LU-GT has the same communication complexity as the Federated Learning setting but allows arbitrary network topologies. In addition, we prove that the number of local updates does not degrade the quality of the solution achieved by LU-GT. Numerical examples reveal that local updates can lower communication costs in certain regimes (e.g., well-connected graphs)."}}
{"id": "f4cyfF48c0", "cdate": 1640995200000, "mdate": 1681695068678, "content": {"title": "A Unified and Refined Convergence Analysis for Non-Convex Decentralized Learning", "abstract": "We study the consensus decentralized optimization problem where the objective function is the average of <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><tex-math notation=\"LaTeX\">$n$</tex-math></inline-formula> agents private non-convex cost functions; moreover, the agents can only communicate to their neighbors on a given network topology. The stochastic learning setting is considered in this paper where each agent can only access a noisy estimate of its gradient. Many decentralized methods can solve such problem including EXTRA, Exact-Diffusion/D <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><tex-math notation=\"LaTeX\">$^{2}$</tex-math></inline-formula> , and gradient-tracking. Unlike the famed <sc xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">Dsgd</small> algorithm, these methods have been shown to be robust to the heterogeneity across the local cost functions. However, the established convergence rates for these methods indicate that their sensitivity to the network topology is worse than <sc xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">Dsgd</small> . Such theoretical results imply that these methods can perform much worse than <sc xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">Dsgd</small> over sparse networks, which, however, contradicts empirical experiments where <sc xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">Dsgd</small> is observed to be more sensitive to the network topology. In this work, we study a general <underline xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">s</u> tochastic <underline xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">u</u> nified <underline xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">d</u> ecentralized <underline xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">a</u> lgorithm ( <bold xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">SUDA</b> ) that includes the above methods as special cases. We establish the convergence of <bold xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">SUDA</b> under both non-convex and the Polyak-\u0141ojasiewicz condition settings. Our results provide improved network topology dependent bounds for these methods (such as Exact-Diffusion/D <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><tex-math notation=\"LaTeX\">$^{2}$</tex-math></inline-formula> and gradient-tracking) compared with existing literature. Moreover, our results show that these methods are often less sensitive to the network topology compared to <sc xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">Dsgd</small> , which agrees with numerical experiments."}}
{"id": "uNdr9qYacvO", "cdate": 1609459200000, "mdate": 1681695068722, "content": {"title": "Removing Data Heterogeneity Influence Enhances Network Topology Dependence of Decentralized SGD", "abstract": "We consider the decentralized stochastic optimization problems, where a network of $n$ nodes, each owning a local cost function, cooperate to find a minimizer of the globally-averaged cost. A widely studied decentralized algorithm for this problem is decentralized SGD (D-SGD), in which each node averages only with its neighbors. D-SGD is efficient in single-iteration communication, but it is very sensitive to the network topology. For smooth objective functions, the transient stage (which measures the number of iterations the algorithm has to experience before achieving the linear speedup stage) of D-SGD is on the order of ${\\Omega}(n/(1-\\beta)^2)$ and $\\Omega(n^3/(1-\\beta)^4)$ for strongly and generally convex cost functions, respectively, where $1-\\beta \\in (0,1)$ is a topology-dependent quantity that approaches $0$ for a large and sparse network. Hence, D-SGD suffers from slow convergence for large and sparse networks.   In this work, we study the non-asymptotic convergence property of the D$^2$/Exact-diffusion algorithm. By eliminating the influence of data heterogeneity between nodes, D$^2$/Exact-diffusion is shown to have an enhanced transient stage that is on the order of $\\tilde{\\Omega}(n/(1-\\beta))$ and $\\Omega(n^3/(1-\\beta)^2)$ for strongly and generally convex cost functions, respectively. Moreover, when D$^2$/Exact-diffusion is implemented with gradient accumulation and multi-round gossip communications, its transient stage can be further improved to $\\tilde{\\Omega}(1/(1-\\beta)^{\\frac{1}{2}})$ and $\\tilde{\\Omega}(n/(1-\\beta))$ for strongly and generally convex cost functions, respectively. These established results for D$^2$/Exact-Diffusion have the best (i.e., weakest) dependence on network topology to our knowledge compared to existing decentralized algorithms. We also conduct numerical simulations to validate our theories."}}
{"id": "dMlQhPDIOr", "cdate": 1609459200000, "mdate": 1681695068718, "content": {"title": "A Unified and Refined Convergence Analysis for Non-Convex Decentralized Learning", "abstract": "We study the consensus decentralized optimization problem where the objective function is the average of $n$ agents private non-convex cost functions; moreover, the agents can only communicate to their neighbors on a given network topology. The stochastic learning setting is considered in this paper where each agent can only access a noisy estimate of its gradient. Many decentralized methods can solve such problem including EXTRA, Exact-Diffusion/D$^2$, and gradient-tracking. Unlike the famed DSGD algorithm, these methods have been shown to be robust to the heterogeneity across the local cost functions. However, the established convergence rates for these methods indicate that their sensitivity to the network topology is worse than DSGD. Such theoretical results imply that these methods can perform much worse than DSGD over sparse networks, which, however, contradicts empirical experiments where DSGD is observed to be more sensitive to the network topology. In this work, we study a general stochastic unified decentralized algorithm (SUDA) that includes the above methods as special cases. We establish the convergence of SUDA under both non-convex and the Polyak-Lojasiewicz condition settings. Our results provide improved network topology dependent bounds for these methods (such as Exact-Diffusion/D$^2$ and gradient-tracking) compared with existing literature. Moreover, our results show that these methods are often less sensitive to the network topology compared to DSGD, which agrees with numerical experiments."}}
{"id": "az_YOdJcPn", "cdate": 1609459200000, "mdate": 1652660258769, "content": {"title": "Dual Consensus Proximal Algorithm for Multi-Agent Sharing Problems", "abstract": "This work considers multi-agent sharing optimization problems, where each agent owns a local smooth function plus a non-smooth function, and the network seeks to minimize the sum of all local functions plus a coupling composite function (possibly non-smooth). For this non-smooth setting, centralized algorithms are known to converge linearly under certain conditions. On the other hand, decentralized algorithms have not been shown to achieve linear convergence under the same conditions. In this work, we propose a decentralized proximal primal-dual algorithm and establish its linear convergence under weaker conditions than existing decentralized works. Our result shows that decentralized algorithms match the linear rate of centralized algorithms without any extra condition. Finally, we provide numerical simulations that illustrate the theoretical findings and show the advantages of the proposed method."}}
