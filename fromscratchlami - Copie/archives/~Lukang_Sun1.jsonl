{"id": "8VCgHSpJ_VH", "cdate": 1674993506563, "mdate": 1674993506563, "content": {"title": "Federated Learning with a Sampling Algorithm under Isoperimetry", "abstract": "Federated learning uses a set of techniques to efficiently distribute the training of a machine learning algorithm across several devices, who own the training data. These techniques critically rely on reducing the communication cost -- the main bottleneck -- between the devices and a central server. Federated learning algorithms usually take an optimization approach: they are algorithms for minimizing the training loss subject to communication (and other) constraints. In this work, we instead take a Bayesian approach for the training task, and propose a communication-efficient variant of the Langevin algorithm to sample a posteriori. The latter approach is more robust and provides more knowledge of the \\textit{a posteriori} distribution than its optimization counterpart. We analyze our algorithm without assuming that the target distribution is strongly log-concave. Instead, we assume the weaker log Sobolev inequality, which allows for nonconvexity."}}
{"id": "zDQ0n0lK4e2", "cdate": 1674989344151, "mdate": null, "content": {"title": "Convergence of Stein variational gradient descent under a weaker smoothness condition", "abstract": "Stein Variational Gradient Descent (SVGD) is an important alternative to the Langevin-type algorithms for sampling from probability distributions of the form . In the existing theory of Langevin-type algorithms and SVGD, the potential function  is often assumed to be -smooth. However, this restrictive condition excludes a large class of potential functions such as polynomials of degree greater than . Our paper studies the convergence of the SVGD algorithm for distributions with -smooth potentials. This relaxed smoothness assumption was introduced by Zhang et al. [2019a] for the analysis of gradient clipping algorithms. With the help of trajectory-independent auxiliary conditions, we provide a descent lemma establishing that the algorithm decreases the  divergence at each iteration and prove a complexity bound for SVGD in the population limit in terms of the Stein Fisher information."}}
{"id": "X8Ui3rN_vk", "cdate": 1674989283541, "mdate": 1674989283541, "content": {"title": "A convergence theory for SVGD in the population limit under Talagrand\u2019s inequality T1", "abstract": "Stein Variational Gradient Descent (SVGD) is an algorithm for sampling from a target density which is known up to a multiplicative constant. Although SVGD is a popular algorithm in practice, its theoretical study is limited to a few recent works. We study the convergence of SVGD in the population limit,(ie, with an infinite number of particles) to sample from a non-logconcave target distribution satisfying Talagrand\u2019s inequality T1. We first establish the convergence of the algorithm. Then, we establish a dimension-dependent complexity bound in terms of the Kernelized Stein Discrepancy (KSD). Unlike existing works, we do not assume that the KSD is bounded along the trajectory of the algorithm. Our approach relies on interpreting SVGD as a gradient descent over a space of probability measures."}}
{"id": "eWvjcZIZrWu", "cdate": 1663850309896, "mdate": null, "content": {"title": "Improved Stein Variational Gradient Descent with Importance Weights", "abstract": "Stein Variational Gradient Descent~(\\algname{SVGD}) is a popular sampling algorithm used in various machine learning tasks. It is well known that \\algname{SVGD} arises from a discretization of the kernelized gradient flow of the Kullback-Leibler divergence $\\KL\\left(\\cdot\\mid\\pi\\right)$, where $\\pi$ is the target distribution. In this work, we propose to enhance \\algname{SVGD} via the introduction of  {\\em importance weights}, which leads to a new method for which we coin the name  \\algname{$\\beta$-SVGD}. In the continuous time and infinite particles regime, the time for this flow to converge to the equilibrium distribution $\\pi$, quantified by the Stein Fisher information, depends on $\\rho_0$ and $\\pi$ very weakly. This is very different from the kernelized gradient flow of Kullback-Leibler divergence, whose time complexity depends on $\\KL\\left(\\rho_0\\mid\\pi\\right)$. Under certain assumptions, we provide a descent lemma for the population limit \\algname{$\\beta$-SVGD}, which covers the descent lemma for the population limit \\algname{SVGD} when $\\beta\\to 0$. We also illustrate the advantages of \\algname{$\\beta$-SVGD} over \\algname{SVGD} by simple experiments."}}
{"id": "En7lGmzT_x", "cdate": 1663849953880, "mdate": null, "content": {"title": "Sharper Rates and Flexible Framework for Nonconvex SGD with Client and Data Sampling", "abstract": "We revisit the classical problem of finding an approximately stationary point of the average of $n$ smooth and possibly nonconvex functions. The optimal complexity of stochastic first-order methods in terms of the number of gradient evaluations of individual functions is $\\mathcal{O}\\left(n + n^{1/2}\\varepsilon^{-1}\\right)$, attained by the optimal SGD methods SPIDER (Cong Fang et al., 2018) and PAGE (Zhize Li et al., 2020), for example, where $\\varepsilon$ is the error tolerance. However, i) the big-$\\mathcal{O}$ notation hides crucial dependencies on the smoothness constants associated with the functions, and ii) the rates and theory in these methods assume simplistic sampling mechanisms that do not offer any flexibility. In this work we remedy the situation. First, we generalize the PAGE algorithm so that it can provably work with virtually any (unbiased) sampling mechanism. This is particularly useful in federated learning, as it allows us to construct and better understand the impact of various combinations of client and data sampling strategies. Second, our analysis is sharper as we make explicit use of certain novel inequalities  that capture the intricate interplay between the smoothness constants and the sampling procedure. Indeed, our analysis is better even for the simple sampling procedure analyzed in the PAGE paper. However, this already improved bound can be further sharpened by a different sampling scheme which we propose. In summary, we provide the most general and most accurate analysis of optimal SGD in the smooth nonconvex regime. Finally, our theoretical findings are supposed with carefully designed experiments."}}
