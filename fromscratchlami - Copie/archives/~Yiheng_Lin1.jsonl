{"id": "lXrsF0kA7t", "cdate": 1676827082079, "mdate": null, "content": {"title": "Convergence Rates for Localized Actor-Critic in Networked Markov Potential Games", "abstract": "We introduce a class of networked Markov potential games where agents are associated with nodes in a network. Each agent has its own local potential function, and the reward of each agent depends only on the states and actions of agents within a neighborhood.  In this context, we propose a localized actor-critic algorithm.  The algorithm is scalable since each agent uses only local information and does not need access to the global state.  Further, the algorithm overcomes the curse of dimensionality through the use of function approximation.  Our main results provide finite-sample guarantees up to a localization error and a function approximation error. Specifically, we achieve an $\\tilde{\\mathcal{O}}(\\tilde{\\epsilon}^{-4})$ sample complexity measured by the averaged Nash regret. This is the first finite-sample bound for multi-agent competitive games  that does not depend on the number of agents."}}
{"id": "jFVfKsmKa-", "cdate": 1652737593980, "mdate": null, "content": {"title": "Bounded-Regret MPC via Perturbation Analysis: Prediction Error, Constraints, and Nonlinearity", "abstract": "We study Model Predictive Control (MPC) and propose a general analysis pipeline to bound its dynamic regret. The pipeline first requires deriving a perturbation bound for a finite-time optimal control problem. Then, the perturbation bound is used to bound the per-step error of MPC, which leads to a bound on the dynamic regret. Thus, our pipeline reduces the study of MPC to the well-studied problem of perturbation analysis, enabling the derivation of regret bounds of MPC under a variety of settings. To demonstrate the power of our pipeline, we use it to generalize existing regret bounds on MPC in linear time-varying (LTV) systems to incorporate prediction errors on costs, dynamics, and disturbances. Further, our pipeline leads to regret bounds on MPC in systems with nonlinear dynamics and constraints."}}
{"id": "NHX9w7ex3fW", "cdate": 1621629984402, "mdate": null, "content": {"title": "Multi-Agent Reinforcement Learning in Stochastic Networked Systems", "abstract": "We study multi-agent reinforcement learning (MARL) in a stochastic network of agents. The objective is to find localized policies that maximize the (discounted) global reward. In general, scalability is a challenge in this setting because the size of the global state/action space can be exponential in the number of agents. Scalable algorithms are only known in cases where dependencies are static, fixed and local, e.g., between neighbors in a fixed, time-invariant underlying graph. In this work, we propose a Scalable Actor Critic framework that applies in settings where the dependencies can be non-local and stochastic, and provide a finite-time error bound that shows how the convergence rate depends on the speed of information spread in the network.  Additionally, as a byproduct of our analysis, we obtain novel finite-time convergence results for a general stochastic approximation scheme and for temporal difference learning with state aggregation, which apply beyond the setting of MARL in networked systems."}}
{"id": "xwGeq7I4Opv", "cdate": 1621629887905, "mdate": null, "content": {"title": "Perturbation-based Regret Analysis of Predictive Control in Linear Time Varying Systems", "abstract": "We study predictive control in a setting where the dynamics are time-varying and linear, and the costs are time-varying and well-conditioned. At each time step, the controller receives the exact predictions of costs, dynamics, and disturbances for the future $k$ time steps. We show that when the prediction window $k$ is sufficiently large, predictive control is input-to-state stable and achieves a dynamic regret of $O(\\lambda^k T)$, where $\\lambda < 1$ is a positive constant. This is the first dynamic regret bound on the predictive control of linear time-varying systems. We also show a variation of predictive control obtains the first competitive bound for the control of linear time-varying systems:  $1 + O(\\lambda^k)$. Our results are derived using a novel proof framework based on a perturbation bound that characterizes how a small change to the system parameters impacts the optimal trajectory."}}
