{"id": "P7TayMSBhnV", "cdate": 1652737541446, "mdate": null, "content": {"title": "Stability and Generalization for Markov Chain Stochastic Gradient Methods", "abstract": "Recently there is a large amount of work devoted to the study of Markov chain stochastic gradient methods (MC-SGMs)  which mainly focus on their convergence analysis for solving minimization problems. In this paper, we provide a comprehensive generalization analysis of MC-SGMs for both minimization and minimax problems through the lens of algorithmic stability in the framework of statistical learning theory. For empirical risk minimization (ERM) problems, we establish the optimal excess population risk bounds for both smooth and non-smooth cases by introducing on-average argument stability. For minimax problems, we develop a quantitative connection between on-average argument stability and generalization error which extends the existing results for uniform stability (Lei et al., 2021). We further develop the first nearly optimal convergence rates for convex-concave problems both in expectation and with high probability, which, combined with our stability results, show that the optimal generalization bounds can be attained for both smooth and non-smooth cases. To the best of our knowledge, this is the first generalization analysis of SGMs when the gradients are sampled from a Markov process.   \n "}}
{"id": "kSWI74GHDJN", "cdate": 1640995200000, "mdate": 1681650200269, "content": {"title": "Stability and Generalization for Markov Chain Stochastic Gradient Methods", "abstract": ""}}
{"id": "Pw9hCVEb4d", "cdate": 1640995200000, "mdate": 1681650200201, "content": {"title": "Differentially Private Stochastic Gradient Descent with Low-Noise", "abstract": ""}}
{"id": "paxcakYWwIu", "cdate": 1621629847386, "mdate": null, "content": {"title": "Simple Stochastic and Online Gradient Descent Algorithms for Pairwise Learning", "abstract": "Pairwise learning refers to learning tasks where  the loss function depends on a pair of  instances. It instantiates many important machine learning tasks such as bipartite ranking and metric learning. A popular approach to handle streaming data in pairwise learning is an online gradient descent (OGD) algorithm, where one needs to pair the current instance with a buffering set of previous instances with a sufficiently large size and therefore suffers from a scalability issue. In this paper, we propose simple stochastic and online gradient descent methods for pairwise learning. A notable difference from the existing studies  \nis that we only pair the current instance with the previous one in building a gradient direction, which is efficient in both the storage and computational complexity. We develop novel stability results, optimization, and generalization error bounds for both convex and nonconvex as well as both smooth and nonsmooth problems. We introduce novel techniques to decouple the dependency of models and the previous instance in both the optimization and generalization analysis. Our study resolves an open question on developing meaningful generalization bounds for OGD using a buffering set with a very small fixed size. We also extend our algorithms and stability analysis to develop differentially private SGD algorithms for pairwise learning which significantly improves the existing results."}}
{"id": "VXraeNhj4zI", "cdate": 1621629847386, "mdate": null, "content": {"title": "Simple Stochastic and Online Gradient Descent Algorithms for Pairwise Learning", "abstract": "Pairwise learning refers to learning tasks where  the loss function depends on a pair of  instances. It instantiates many important machine learning tasks such as bipartite ranking and metric learning. A popular approach to handle streaming data in pairwise learning is an online gradient descent (OGD) algorithm, where one needs to pair the current instance with a buffering set of previous instances with a sufficiently large size and therefore suffers from a scalability issue. In this paper, we propose simple stochastic and online gradient descent methods for pairwise learning. A notable difference from the existing studies  \nis that we only pair the current instance with the previous one in building a gradient direction, which is efficient in both the storage and computational complexity. We develop novel stability results, optimization, and generalization error bounds for both convex and nonconvex as well as both smooth and nonsmooth problems. We introduce novel techniques to decouple the dependency of models and the previous instance in both the optimization and generalization analysis. Our study resolves an open question on developing meaningful generalization bounds for OGD using a buffering set with a very small fixed size. We also extend our algorithms and stability analysis to develop differentially private SGD algorithms for pairwise learning which significantly improves the existing results."}}
{"id": "yzKb-ww2BKE", "cdate": 1609459200000, "mdate": 1652931560799, "content": {"title": "Differentially Private SGD with Non-Smooth Loss", "abstract": "In this paper, we are concerned with differentially private {stochastic gradient descent (SGD)} algorithms in the setting of stochastic convex optimization (SCO). Most of the existing work requires the loss to be Lipschitz continuous and strongly smooth, and the model parameter to be uniformly bounded. However, these assumptions are restrictive as many popular losses violate these conditions including the hinge loss for SVM, the absolute loss in robust regression, and even the least square loss in an unbounded domain. We significantly relax these restrictive assumptions and establish privacy and generalization (utility) guarantees for private SGD algorithms using output and gradient perturbations associated with non-smooth convex losses. Specifically, the loss function is relaxed to have an $\\alpha$-H\\\"{o}lder continuous gradient (referred to as $\\alpha$-H\\\"{o}lder smoothness) which instantiates the Lipschitz continuity ($\\alpha=0$) and the strong smoothness ($\\alpha=1$). We prove that noisy SGD with $\\alpha$-H\\\"older smooth losses using gradient perturbation can guarantee $(\\epsilon,\\delta)$-differential privacy (DP) and attain optimal excess population risk $\\mathcal{O}\\Big(\\frac{\\sqrt{d\\log(1/\\delta)}}{n\\epsilon}+\\frac{1}{\\sqrt{n}}\\Big)$, up to logarithmic terms, with the gradient complexity $ \\mathcal{O}( n^{2-\\alpha\\over 1+\\alpha}+ n).$ This shows an important trade-off between $\\alpha$-H\\\"older smoothness of the loss and the computational complexity for private SGD with statistically optimal performance. In particular, our results indicate that $\\alpha$-H\\\"older smoothness with $\\alpha\\ge {1/2}$ is sufficient to guarantee $(\\epsilon,\\delta)$-DP of noisy SGD algorithms while achieving optimal excess risk with the linear gradient complexity $\\mathcal{O}(n).$"}}
{"id": "qzEKClCNS3w", "cdate": 1609459200000, "mdate": 1648676433563, "content": {"title": "Simple Stochastic and Online Gradient Descent Algorithms for Pairwise Learning", "abstract": "Pairwise learning refers to learning tasks where the loss function depends on a pair of instances. It instantiates many important machine learning tasks such as bipartite ranking and metric learning. A popular approach to handle streaming data in pairwise learning is an online gradient descent (OGD) algorithm, where one needs to pair the current instance with a buffering set of previous instances with a sufficiently large size and therefore suffers from a scalability issue. In this paper, we propose simple stochastic and online gradient descent methods for pairwise learning. A notable difference from the existing studies is that we only pair the current instance with the previous one in building a gradient direction, which is efficient in both the storage and computational complexity. We develop novel stability results, optimization, and generalization error bounds for both convex and nonconvex as well as both smooth and nonsmooth problems. We introduce novel techniques to decouple the dependency of models and the previous instance in both the optimization and generalization analysis. Our study resolves an open question on developing meaningful generalization bounds for OGD using a buffering set with a very small fixed size. We also extend our algorithms and stability analysis to develop differentially private SGD algorithms for pairwise learning which significantly improves the existing results."}}
{"id": "oK9czLgm8Q", "cdate": 1609459200000, "mdate": 1652931560800, "content": {"title": "Simple Stochastic and Online Gradient Descent Algorithms for Pairwise Learning", "abstract": "Pairwise learning refers to learning tasks where the loss function depends on a pair of instances. It instantiates many important machine learning tasks such as bipartite ranking and metric learning. A popular approach to handle streaming data in pairwise learning is an online gradient descent (OGD) algorithm, where one needs to pair the current instance with a buffering set of previous instances with a sufficiently large size and therefore suffers from a scalability issue. In this paper, we propose simple stochastic and online gradient descent methods for pairwise learning. A notable difference from the existing studies is that we only pair the current instance with the previous one in building a gradient direction, which is efficient in both the storage and computational complexity. We develop novel stability results, optimization, and generalization error bounds for both convex and nonconvex as well as both smooth and nonsmooth problems. We introduce novel techniques to decouple the dependency of models and the previous instance in both the optimization and generalization analysis. Our study resolves an open question on developing meaningful generalization bounds for OGD using a buffering set with a very small fixed size. We also extend our algorithms and stability analysis to develop differentially private SGD algorithms for pairwise learning which significantly improves the existing results."}}
{"id": "kB4McyD5KO7", "cdate": 1609459200000, "mdate": 1652931560795, "content": {"title": "Stability and Generalization for Randomized Coordinate Descent", "abstract": "Randomized coordinate descent (RCD) is a popular optimization algorithm with wide applications in solving various machine learning problems, which motivates a lot of theoretical analysis on its convergence behavior. As a comparison, there is no work studying how the models trained by RCD would generalize to test examples. In this paper, we initialize the generalization analysis of RCD by leveraging the powerful tool of algorithmic stability. We establish argument stability bounds of RCD for both convex and strongly convex objectives, from which we develop optimal generalization bounds by showing how to early-stop the algorithm to tradeoff the estimation and optimization. Our analysis shows that RCD enjoys better stability as compared to stochastic gradient descent."}}
{"id": "eM-jBLixDUV", "cdate": 1609459200000, "mdate": 1652931560802, "content": {"title": "Differentially private empirical risk minimization for AUC maximization", "abstract": ""}}
