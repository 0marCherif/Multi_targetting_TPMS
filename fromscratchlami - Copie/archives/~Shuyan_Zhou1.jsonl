{"id": "tKNSwtjj4-K", "cdate": 1686208144221, "mdate": 1686208144221, "content": {"title": "Hierarchical Prompting Assists Large Language Model on Web Navigation", "abstract": "Large language models (LLMs) struggle on processing complicated observations in inter- active decision making. To alleviate this issue, we propose a simple hierarchical prompting approach. Diverging from previous prompting approaches that always put the full observation (e.g., a web page) to the prompt, we pro- pose to first construct an action-aware observation which is more condensed and relevant with a dedicated SUMMARIZER prompt. The ACTOR prompt then predicts the next action based on the summarized history. While our method has broad applicability, we particularly demonstrate its efficacy in the complex domain of web navigation where a full observation often contains redundant and irrelevant information. Our approach outperforms the previous state-of-the-art prompting mechanism with the same LLM by 6.2% on task success rate, demonstrating its potential on interactive decision making tasks with long observation traces."}}
{"id": "whyYoSuW3mY", "cdate": 1675290058931, "mdate": 1675290058931, "content": {"title": "Causal Reasoning About Entities and Events in Procedural Texts", "abstract": "Entities and events have long been regarded as the crux of machine reasoning. Specifically, procedural texts have received increasing attention due to the dynamic nature of involved entities and events. Existing work has exclusively focused on entity state tracking (e.g., the temperature of a pan) or counterfactual event reasoning (e.g., how likely am I to burn myself by touching the pan), while these two tasks are tightly intertwined. In this work, we propose CREPE, the first benchmark on causal reasoning about event plausibility based on entity states. We experiment with strong large language models and show that most models including GPT3 perform close to chance of .30 F1, lagging far behind the human performance of .87 F1. Inspired by the finding that structured representations such as programming languages benefits event reasoning as a prompt to code language models such as Codex, we creatively inject the causal relations between entities and events through intermediate variables and boost the performance to .67 to .72 F1. Our proposed event representation not only allows for knowledge injection, but also marks the first successful attempt of chain-of-thought reasoning with code language models."}}
{"id": "ZTCxT2t2Ru", "cdate": 1663850209747, "mdate": null, "content": {"title": "DocPrompting: Generating Code by Retrieving the Docs", "abstract": "Publicly available source-code libraries are continuously growing and changing. This makes it impossible for models of code\nto keep current with all available APIs by simply training these models on existing code repositories. Thus, existing models inherently cannot generalize to using unseen functions and libraries, because these would never appear in the training data. In contrast, when human programmers use functions and libraries for the first time, they frequently refer to textual resources such as code manuals and documentation, to explore and understand the available functionality. Inspired by this observation, we introduce DocPrompting: a natural-language-to-code generation approach that explicitly leverages documentation by (1) retrieving the relevant documentation pieces given an NL intent, and (2) generating code based on the NL intent and the retrieved documentation. DocPrompting is general: it can be applied to any programming language and is agnostic to the underlying neural model. We demonstrate that DocPrompting consistently improves NL-to-code models: DocPrompting improves strong base models such as CodeT5 by 2.85% in pass@1 (52% relative gain) and 4.39% in pass@10 (30% relative gain) in execution-based evaluation on the popular Python CoNaLa benchmark; on a new Bash dataset tldr, DocPrompting improves CodeT5 and GPT-Neo1.3B by up to absolute 6.9% exact match."}}
