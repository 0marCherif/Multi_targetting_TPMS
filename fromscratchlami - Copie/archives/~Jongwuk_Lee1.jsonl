{"id": "jDK19MUBT4_", "cdate": 1632875637719, "mdate": null, "content": {"title": "TailMix: Overcoming the Label Sparsity for Extreme Multi-label Classification", "abstract": "Extreme multi-label classification (XMC) aims at finding the most relevant labels from a huge label set at the industrial scale. The XMC problem inherently poses two challenges: data scalability and label sparsity. This work introduces a new augmentation method, namely TailMix, to address the label sparsity issue, i.e., the long-tail labels in XMC have few positive instances. TailMix utilizes the context vector generated from the label attention layer in a label-wise manner instead of using the existing Mixup methods in a sample-wise manner. In this process, TailMix selectively chooses two context vectors and augments the most plausible positive instances to improve the accuracy for long-tail labels. Despite the simplicity of TailMix, extensive experimental results show that TailMix consistently improves the baseline models without TailMix and other Mixup-based methods on three benchmark datasets. Notably, TailMix is effective for improving the performance for long-tail labels on PSP@k and PSN@k, which are the common metrics that reflect the propensity of labels."}}
{"id": "rx19UMFbC9u", "cdate": 1601308177783, "mdate": null, "content": {"title": "Waste not, Want not: All-Alive Pruning for Extremely Sparse Networks", "abstract": "Network pruning has been widely adopted for reducing computational cost and memory consumption in low-resource devices. Recent studies show that saliency-based pruning can achieve high compression ratios (e.g., 80-90% of the parameters in original networks are removed) without sacrificing much accuracy loss. Nevertheless, finding the well-trainable networks with sparse parameters (e.g., < 10% of the parameters remaining) is still challenging to network pruning, commonly believed to lack model capacity. In this work, we revisit the procedure of existing pruning methods and observe that dead connections, which do not contribute to model capacity, appear regardless of pruning methods. To this end, we propose a novel pruning method, called all-alive pruning (AAP), producing the pruned networks with only trainable weights. Notably, AAP is broadly applicable to various saliency-based pruning methods and model architectures. We demonstrate that AAP equipped with existing pruning methods (i.e., iterative pruning, one-shot pruning, and dynamic pruning) consistently improves the accuracy of original methods at 128\u00d7 - 4096\u00d7 compression ratios on three benchmark datasets."}}
{"id": "r1-vNzWO-H", "cdate": 1546300800000, "mdate": null, "content": {"title": "Dual Neural Personalized Ranking", "abstract": "Implicit user feedback is a fundamental dataset for personalized recommendation models. Because of its inherent characteristics of sparse one-class values, it is challenging to uncover meaningful user/item representations. In this paper, we propose dual neural personalized ranking (DualNPR), which fully exploits both user- and item-side pairwise rankings in a unified manner. The key novelties of the proposed model are three-fold: (1) DualNPR discovers mutual correlation among users and items by utilizing both user- and item-side pairwise rankings, alleviating the data sparsity problem. We stress that, unlike existing models that require extra information, DualNPR naturally augments both user- and item-side pairwise rankings from a user-item interaction matrix. (2) DualNPR is built upon deep matrix factorization to capture the variability of user/item representations. In particular, it chooses raw user/item vectors as an input and learns latent user/item representations effectively. (3) DualNPR employs a dynamic negative sampling method using an exponential function, further improving the accuracy of top-N recommendation. In experimental results over three benchmark datasets, DualNPR outperforms baseline models by 21.9-86.7% in hit rate, 14.5-105.8% in normalized discounted cumulative gain, and 5.1-23.3% in the area under the ROC curve."}}
{"id": "HJbLSz-OWB", "cdate": 1356998400000, "mdate": null, "content": {"title": "Fria: fast and robust instance alignment", "abstract": "This paper proposes Fria, a fast and robust instance alignment framework across two independently built knowledge bases (KBs). Our objective is two-fold: (1) to design an effective instance similarity measure and (2) to build a fast and robust alignment framework. Specifically, Fria consists of two-phases. Fria first achieves high-precision alignment for seed matches which have strong evidence for aligning. To obtain high-recall alignment, Fria then divides non-matched instances according to the types identified from seeds, and gives additional chances to the same-typed instances to be matched. Experimental results show that Fria is fast and robust, by achieving comparable accuracy to state-of-the-arts and a 10-times speed up."}}
{"id": "rJ-534ZOWH", "cdate": 1230768000000, "mdate": null, "content": {"title": "SkyTree: scalable skyline computation for sensor data", "abstract": "Skyline queries have gained attention for supporting multi-criteria analysis of large-scale datasets. While a lot of skyline algorithms have been proposed, most of the algorithms build upon pre-computed index structures that cannot generally be supported over sensor data of dynamically changing attribute values. We aim to design a scalable non-index skyline computation algorithm for sensor data. More specifically, we propose Algorithm Sky Tree constructing a dynamic lattice that divides a specific region into several subregions based on a pivot point maximizing dominance region. Such structure enables to perform region-wise dominance tests, which eliminates unnecessary point-wise dominance tests. In addition, we ensure the progressiveness that has not been supported by any non-index algorithm, where we can identify k points maximizing the sum of dominance regions as the greedy approximation method. The k points are used to reduce communication cost between sensors in computing global skyline. Our evaluation results validate the efficiency of Algorithm SkyTree, both in terms of response time and communication overhead, over existing algorithms."}}
{"id": "HJEEEEb_WS", "cdate": 1230768000000, "mdate": null, "content": {"title": "Query result clustering for object-level search", "abstract": "Query result clustering has recently attracted a lot of attention to provide users with a succinct overview of relevant results. However, little work has been done on organizing the query results for object-level search. Object-level search result clustering is challenging because we need to support diverse similarity notions over object-specific features (such as the price and weight of a product) of heterogeneous domains. To address this challenge, we propose a hybrid subspace clustering algorithm called Hydra. Algorithm Hydra captures the user perception of diverse similarity notions from millions of Web pages and disambiguates different senses using feature-based subspace locality measures. Our proposed solution, by combining wisdom of crowds and wisdom of data, achieves robustness and efficiency over existing approaches. We extensively evaluate our proposed framework and demonstrate how to enrich user experiences in object-level search using a real-world product search scenarios."}}
