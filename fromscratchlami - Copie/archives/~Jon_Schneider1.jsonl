{"id": "00jwOr7UA4P", "cdate": 1652737777187, "mdate": null, "content": {"title": "Anonymous Bandits for Multi-User Systems", "abstract": "In this work, we present and study a new framework for online learning in systems with multiple users that provide user anonymity. Specifically, we extend the notion of bandits to obey the standard $k$-anonymity constraint by requiring each observation to be an aggregation of rewards for at least $k$ users. This provides a simple yet effective framework where one can learn a clustering of users in an online fashion without observing any user's individual decision. We initiate the study of anonymous bandits and provide the first sublinear regret algorithms and lower bounds for this setting."}}
{"id": "hVnM-ni5o5nVQ", "cdate": 1621630328932, "mdate": null, "content": {"title": "Contextual Recommendations and Low-Regret Cutting-Plane Algorithms", "abstract": "We consider the following variant of contextual linear bandits motivated by routing applications in navigational engines  and recommendation systems. We wish to learn a hidden $d$-dimensional value $w^*$. Every round, we are presented with a subset $\\mathcal{X}_t \\subseteq \\mathbb{R}^d$ of possible actions. If we choose (i.e. recommend to the user) action $x_t$, we obtain utility $\\langle x_t, w^* \\rangle$ but only learn the identity of the best action $\\arg\\max_{x \\in \\X_t} \\langle x, w^* \\rangle$.\n\nWe design algorithms for this problem which achieve regret $O(d\\log T)$ and $\\exp(O(d \\log d))$. To accomplish this, we design novel cutting-plane algorithms with low \u201cregret\u201d -- the total distance between the true point $w^*$ and the hyperplanes the separation oracle returns. \n\nWe also consider the variant where we are allowed to provide a list of several recommendations. In this variant, we give an algorithm with $O(d^2 \\log d)$ regret and list size $\\poly(d)$. Finally, we construct nearly tight algorithms for a weaker variant of this problem where the learner only learns the identity of an action that is better than the recommendation. Our results rely on new algorithmic techniques in convex geometry (including a variant of Steiner\u2019s formula for the centroid of a convex set) which may be of independent interest. "}}
{"id": "45GfBQYtYlp", "cdate": 1621630328932, "mdate": null, "content": {"title": "Contextual Recommendations and Low-Regret Cutting-Plane Algorithms", "abstract": "We consider the following variant of contextual linear bandits motivated by routing applications in navigational engines  and recommendation systems. We wish to learn a hidden $d$-dimensional value $w^*$. Every round, we are presented with a subset $\\mathcal{X}_t \\subseteq \\mathbb{R}^d$ of possible actions. If we choose (i.e. recommend to the user) action $x_t$, we obtain utility $\\langle x_t, w^* \\rangle$ but only learn the identity of the best action $\\arg\\max_{x \\in \\X_t} \\langle x, w^* \\rangle$.\n\nWe design algorithms for this problem which achieve regret $O(d\\log T)$ and $\\exp(O(d \\log d))$. To accomplish this, we design novel cutting-plane algorithms with low \u201cregret\u201d -- the total distance between the true point $w^*$ and the hyperplanes the separation oracle returns. \n\nWe also consider the variant where we are allowed to provide a list of several recommendations. In this variant, we give an algorithm with $O(d^2 \\log d)$ regret and list size $\\poly(d)$. Finally, we construct nearly tight algorithms for a weaker variant of this problem where the learner only learns the identity of an action that is better than the recommendation. Our results rely on new algorithmic techniques in convex geometry (including a variant of Steiner\u2019s formula for the centroid of a convex set) which may be of independent interest. "}}
{"id": "XK4eVsG2LKw", "cdate": 1621630272561, "mdate": null, "content": {"title": "Margin-Independent Online Multiclass Learning via Convex Geometry", "abstract": "We consider the problem of multi-class classification, where a stream of adversarially chosen queries arrive and must be assigned a label online. Unlike traditional bounds which seek to minimize the misclassification rate, we minimize the total distance from each query to the region corresponding to its assigned label. When the true labels are determined via a nearest neighbor partition -- i.e. the label of a point is given by which of $k$ centers it is closest to in Euclidean distance -- we show that one can achieve a loss that is independent of the total number of queries. We complement this result by showing that learning general convex sets requires an almost linear loss per query. Our results build off of regret guarantees for the problem of contextual search. In addition, we develop a novel reduction technique from multiclass classification to binary classification which may be of independent interest. "}}
{"id": "TwgnHaJ_Rh3", "cdate": 1621606832193, "mdate": null, "content": {"title": "Variable Decomposition for Prophet Inequalities and Optimal Ordering", "abstract": "We introduce a new decomposition technique for random variables that maps a generic instance of the prophet inequalities problem to a new instance where all but a constant number of variables have a tractable structure that we refer to as $(\\epsilon, \\delta)$-smallness. Using this technique, we make progress on several outstanding problems in the area:\n\n1) We show that, even in the case of non-identical distributions, it is possible to achieve (arbitrarily close to) the optimal approximation ratio of $\\beta \\approx 0.745$ when the items arrive in a random order (this version is commonly known as prophet secretary) as long as we are allowed to remove a small constant number of distributions.  \n\n2) We show that for \\textit{frequent} instances (where each distribution reoccurs some number of times) and random arrival order, it is possible to achieve the optimal approximation ratio of $\\beta$ (improving over the previous best-known bound of $0.738$).\n\n3) We give a new, simpler proof of Kertz's optimal approximation guarantee of $\\beta \\approx 0.745$ for prophet inequalities with i.i.d. distributions. The proof is primal-dual and simultaneously produces upper and lower bounds.\n\n4) Using this decomposition in combination with a novel convex programming formulation, we construct the first (in parallel work with Segev-Singla'20) an Efficient PTAS (EPTAS) for the Optimal Ordering problem."}}
{"id": "rke-kSSxUr", "cdate": 1567802584633, "mdate": null, "content": {"title": "Contextual Bandits with Cross-Learning", "abstract": "In the classical contextual bandits problem, in each round $t$, a learner observes some context $c$, chooses some action $a$ to perform, and receives some reward $r_{a,t}(c)$. We consider the variant of this problem where in addition to receiving the reward $r_{a,t}(c)$, the learner also learns the values of $r_{a,t}(c')$ for all other contexts $c'$; i.e., the rewards that would have been achieved by performing that action under different contexts. This variant arises in several strategic settings, such as learning how to bid in non-truthful repeated auctions (in this setting the context is the decision maker's private valuation for each auction). We call this problem the contextual bandits problem with cross-learning.   The best algorithms for the classical contextual bandits problem achieve $\\tilde{O}(\\sqrt{CKT})$ regret against all stationary policies, where $C$ is the number of contexts, $K$ the number of actions, and $T$ the number of rounds. We demonstrate algorithms for the contextual bandits problem with cross-learning that remove the dependence on $C$ and achieve regret $\\tilde{O}(\\sqrt{KT})$ (when contexts are stochastic with known distribution), $\\tilde{O}(K^{1/3}T^{2/3})$ (when contexts are  stochastic with unknown distribution), and $\\tilde{O}(\\sqrt{KT})$ (when contexts are adversarial but rewards are stochastic). We simulate our algorithms on real auction data from an ad exchange running first-price auctions (showing that they outperform traditional contextual bandit algorithms)."}}
{"id": "H1W6vdWuWr", "cdate": 1514764800000, "mdate": null, "content": {"title": "Contextual Pricing for Lipschitz Buyers", "abstract": "We investigate the problem of learning a Lipschitz function from binary feedback. In this problem, a learner is trying to learn a Lipschitz function $f:[0,1]^d \\rightarrow [0,1]$ over the course of $T$ rounds. On round $t$, an adversary provides the learner with an input $x_t$, the learner submits a guess $y_t$ for $f(x_t)$, and learns whether $y_t &gt; f(x_t)$ or $y_t \\leq f(x_t)$. The learner's goal is to minimize their total loss $\\sum_t\\ell(f(x_t), y_t)$ (for some loss function $\\ell$). The problem is motivated by \\textit{contextual dynamic pricing}, where a firm must sell a stream of differentiated products to a collection of buyers with non-linear valuations for the items and observes only whether the item was sold or not at the posted price. For the symmetric loss $\\ell(f(x_t), y_t) = \\vert f(x_t) - y_t \\vert$, we provide an algorithm for this problem achieving total loss $O(\\log T)$ when $d=1$ and $O(T^{(d-1)/d})$ when $d&gt;1$, and show that both bounds are tight (up to a factor of $\\sqrt{\\log T}$). For the pricing loss function $\\ell(f(x_t), y_t) = f(x_t) - y_t {\\bf 1}\\{y_t \\leq f(x_t)\\}$ we show a regret bound of $O(T^{d/(d+1)})$ and show that this bound is tight. We present improved bounds in the special case of a population of linear buyers."}}
