{"id": "dLHtwZKvJmE", "cdate": 1654124927412, "mdate": null, "content": {"title": "PGT: a prompt based generative transformer for the patent domain", "abstract": "Patents are a valuable source of knowledge, but drafting them is a time-consuming and expensive task.\nMethods that assist patent generation can provide a two-fold improvement as they can speed up the generation process and\nsuggest to the inventor ideas and claims.\nHerein, influenced by recent advances in language modeling via multitask learning and prompt engineering, we present Patent Generative Transformer (PGT), a transformer-based language model trained to facilitate patent drafting.\nSpecifically, the model supports three tasks: part-of-patent generation, text infilling, and patent coherence evaluation.\nPGT complements inventors and assures the fast and successful transition from their input to a coherent patent disclosure taking advantage of its multitasking nature.\nWe show how the model outperforms a collection of task-specific baselines on relevant metrics. We further test the quality of the generated text via blind testing by subject matter experts.\nFinally, we explore a zero-shot extension of the model showing how to use PGT for generating domain-specific abstracts."}}
{"id": "aMbQNggNH1I", "cdate": 1609459200000, "mdate": 1632986888816, "content": {"title": "Adaptive Federated Learning in Presence of Concept Drift", "abstract": "Federated Learning (FL) is a promising research area in the machine learning field. Techniques and solutions belonging to this area operate in distributed scenarios, comprising a server and pervasively distributed clients, aiming at learning a single central model without sending (possibly sensitive) data from the clients to the server. Such an approach allows mitigating the privacy concerns that are nowadays perceived as relevant in distributed machine learning solutions leveraging data belonging to different users or companies. The literature in the field of FL is wide and many state-of-the-art solutions are available. Unfortunately, all these solutions assume (implicitly or explicitly) that the process generating the data is stationary (hence not changing its statistical behavior over time); an assumption that rarely holds in real-world conditions where concept drift occurs due to, e.g., seasonality or periodicity effects, faults in sensors or actuators or changes in the users' behaviour. In this paper, we introduce, for the first time in the literature, a novel FL algorithm called Adaptive-FedAVG, able to operate with nonstationary data generating processes affected by concept drifts. Following a passive approach, Adaptive-FedAVG is able to increase the accuracy in stationary conditions and promptly react to concept drift by adapting the learning rate to increase the plasticity of the learning phase. A wide experimental campaign shows the effectiveness of the proposed Adaptive-FedAVG algorithm by comparing it with a state-of-the-art FL algorithm present in the literature both in stationary and non-stationary conditions."}}
{"id": "Uqwj27NhgS", "cdate": 1609459200000, "mdate": 1632986888845, "content": {"title": "Tiny Machine Learning for Concept Drift", "abstract": "Tiny Machine Learning (TML) is a new research area whose goal is to design machine and deep learning techniques able to operate in Embedded Systems and IoT units, hence satisfying the severe technological constraints on memory, computation, and energy characterizing these pervasive devices. Interestingly, the related literature mainly focused on reducing the computational and memory demand of the inference phase of machine and deep learning models. At the same time, the training is typically assumed to be carried out in Cloud or edge computing systems (due to the larger memory and computational requirements). This assumption results in TML solutions that might become obsolete when the process generating the data is affected by concept drift (e.g., due to periodicity or seasonality effect, faults or malfunctioning affecting sensors or actuators, or changes in the users' behavior), a common situation in real-world application scenarios. For the first time in the literature, this paper introduces a Tiny Machine Learning for Concept Drift (TML-CD) solution based on deep learning feature extractors and a k-nearest neighbors classifier integrating a hybrid adaptation module able to deal with concept drift affecting the data-generating process. This adaptation module continuously updates (in a passive way) the knowledge base of TML-CD and, at the same time, employs a Change Detection Test to inspect for changes (in an active way) to quickly adapt to concept drift by removing the obsolete knowledge. Experimental results on both image and audio benchmarks show the effectiveness of the proposed solution, whilst the porting of TML-CD on three off-the-shelf micro-controller units shows the feasibility of what is proposed in real-world pervasive systems."}}
{"id": "OO0_7FEJP4z", "cdate": 1609459200000, "mdate": 1632986888778, "content": {"title": "Distributed Deep Convolutional Neural Networks for the Internet-of-Things", "abstract": "Severe constraints on memory and computation characterizing the Internet-of-Things (IoT) units may prevent the execution of Deep Learning (DL)-based solutions, which typically demand large memory and high processing load. In order to support a real-time execution of the considered DL model at the IoT unit level, DL solutions must be designed having in mind constraints on memory and processing capability exposed by the chosen IoT technology. In this article, we introduce a design methodology aiming at allocating the execution of Convolutional Neural Networks (CNNs) on a distributed IoT application. Such a methodology is formalized as an optimization problem where the latency between the data-gathering phase and the subsequent decision-making one is minimized, within the given constraints on memory and processing load at the units level. The methodology supports multiple sources of data as well as multiple CNNs in execution on the same IoT system allowing the design of CNN-based applications demanding autonomy, low decision-latency, and high Quality-of-Service."}}
{"id": "FxWFst50o8D", "cdate": 1609459200000, "mdate": 1632986888799, "content": {"title": "RECKONition: a NLP-based system for Industrial Accidents at Work Prevention", "abstract": "Extracting patterns and useful information from Natural Language datasets is a challenging task, especially when dealing with data written in a language different from English, like Italian. Machine and Deep Learning, together with Natural Language Processing (NLP) techniques have widely spread and improved lately, providing a plethora of useful methods to address both Supervised and Unsupervised problems on textual information. We propose RECKONition, a NLP-based system for Industrial Accidents at Work Prevention. RECKONition, which is meant to provide Natural Language Understanding, Clustering and Inference, is the result of a joint partnership with the Italian National Institute for Insurance against Accidents at Work (INAIL). The obtained results showed the ability to process textual data written in Italian describing industrial accidents dynamics and consequences."}}
{"id": "13zfrafBIca", "cdate": 1609459200000, "mdate": 1632986888787, "content": {"title": "A Machine-Learning Approach for the Prediction of Internal Corrosion in Pipeline Infrastructures", "abstract": "Pipeline infrastructures, moving either gas or oil from one place to another through their entire lifespan, suffer from internal corrosion. This phenomenon could be very dangerous both for the environment and human being. The former due to potential leakages of the fluids carried by the infrastructure itself, whereas the latter due to accidents which may cause explosions in presence of gas leakages. Therefore, it is crucial to design predictive mechanisms able to improve prevention and control of this phenomenon [1]. Unfortunately, the pipeline corrosion is not understood to the point of developing a mechanistic model, which would solve the prevention and control needs associated to the management of such infrastructures. Moreover, the phenomenon is complex enough to cause semi-empirical models to fail in reproducing its behavior. Recently, Machine Learning (ML) techniques have proven their capabilities in modeling complex phenomena given enough and appropriate data, becoming a promising potential solution for corrosion prediction. Unfortunately, in the literature, the proposed solutions are based on small data sets or the performance evaluations are not appropriately performed impairing the claims and the obtained results. For these reasons, in this paper, we introduce a ML-based approach to model the corrosion phenomenon comprising the data set creation, the definition of the ML-based model and its evaluation. Finally, we apply the above mentioned solution on real-world data."}}
{"id": "pFWL-q5UaHJ", "cdate": 1577836800000, "mdate": 1632986888857, "content": {"title": "Guest Editorial Special Issue on Recent Advances in Theory, Methodology, and Applications of Imbalanced Learning", "abstract": "Imbalanced learning is a challenging task in machine learning, faced by practitioners, and intensively investigated by researchers from a wide range of communities. However, as pointed out in the book titled \u201c <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">Imbalanced Learning: Foundations, Algorithms, and Applications</i> \u201d and collectively authored by experts in the field, many if not most of the approaches to imbalanced learning are heuristic and <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">ad hoc</i> in nature, hence leaving many questions unanswered. To fill this gap, the aim of this Special Issue is to collect recent research works that focus on the theory, methodology, and applications of imbalanced learning. After carefully reviewing a large number of submissions, we selected 15 works to be included in this Special Issue. These works can be roughly categorized into three types: deep-learning-based methods (6), methods based on other machine-learning paradigms (7), and empirical comparative studies (2)."}}
{"id": "mj1lxe7lUsQ", "cdate": 1577836800000, "mdate": 1632986888881, "content": {"title": "A Computational Intelligence Characterization of Solar Magnetograms", "abstract": "Space Weather (SW) poses a hazard to modern society. SW phenomena depend on the Sun's magnetic field and understanding and forecasting the solar magnetic field is an important research subject. To achieve this goal, in this paper Global Oscillation Network Group (GONG) solar magnetograms 2006-2019 are investigated with different approaches provided by unsupervised and supervised Computational Intelligence techniques. Such techniques were successful at providing insights into the behavior and evolution of the photospheric magnetic field, revealing patterns of activity and their relation with the different phases of the solar cycle. On the one hand, representative prototypes of synoptic maps were found, capturing the variations in homogeneity, intensity and variability of magnetic activity. On the other hand, Convolutional neural networks combined with transfer learning and dimensionality reduction techniques were helpful in providing classification models which accurately predict classes associated to the main stages of the cycle. Such models provide results in good correspondence with the natural classes found in feature spaces and have classification errors concentrated mostly at transition periods of the solar cycles."}}
{"id": "jlhlZYRrrT", "cdate": 1577836800000, "mdate": 1632986888959, "content": {"title": "A Privacy-Preserving Distributed Architecture for Deep-Learning-as-a-Service", "abstract": "Deep-learning-as-a-service is a novel and promising computing paradigm aiming at providing machine/deep learning solutions and mechanisms through Cloud-based computing infrastructures. Thanks to its ability to remotely execute and train deep learning models (that typically require high computational loads and memory occupation), such an approach guarantees high performance, scalability, and availability. Unfortunately, such an approach requires to send information to be processed (e.g., signals, images, positions, sounds, videos) to the Cloud, hence having potentially catastrophic-impacts on the privacy of users. This paper introduces a novel distributed architecture for deep-learning-as-a-service that is able to preserve the user sensitive data while providing Cloud-based machine and deep learning services. The proposed architecture, which relies on Homomorphic Encryption that is able to perform operations on encrypted data, has been tailored for Convolutional Neural Networks (CNNs) in the domain of image analysis and implemented through a client-server REST-based approach. Experimental results show the effectiveness of the proposed architecture."}}
{"id": "cL04zyBKx7I", "cdate": 1577836800000, "mdate": 1632986888850, "content": {"title": "An energy harvesting solution for computation offloading in Fog Computing networks", "abstract": "Fog Computing is a promising networking paradigm enabling the nodes at the edge to share computational and storage resources. Being pervasively distributed, Fog Nodes are often battery powered and, for this reason, an efficient energy management should be considered to prolong network lifetime. In this paper, we introduce a smart energy management solution able to exploit information about the predicted harvested and consumed energy by Fog Nodes, equipped with small solar panels. The smart energy management is applied on a cluster based Fog Computing environment where computation offloading operations are performed. In the experimental section the effect of the smart energy management is explored in terms of network lifetime by considering variable battery size and Fog Nodes density in a realistic solar-panel harvesting-model and Fog Nodes setting."}}
