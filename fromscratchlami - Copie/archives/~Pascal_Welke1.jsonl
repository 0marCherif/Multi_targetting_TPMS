{"id": "v0FqG0tJb1z", "cdate": 1672531200000, "mdate": 1695972982625, "content": {"title": "An Empirical Evaluation of the Rashomon Effect in Explainable Machine Learning", "abstract": "The Rashomon Effect describes the following phenomenon: for a given dataset there may exist many models with equally good performance but with different solution strategies. The Rashomon Effect has implications for Explainable Machine Learning, especially for the comparability of explanations. We provide a unified view on three different comparison scenarios and conduct a quantitative evaluation across different datasets, models, attribution methods, and metrics. We find that hyperparameter-tuning plays a role and that metric selection matters. Our results provide empirical support for previously anecdotal evidence and exhibit challenges for both scientists and practitioners."}}
{"id": "SW5vhM9vxb", "cdate": 1672531200000, "mdate": 1695972982667, "content": {"title": "A New Aligned Simple German Corpus", "abstract": ""}}
{"id": "LUn6Ojxtve", "cdate": 1672531200000, "mdate": 1695972982655, "content": {"title": "An Empirical Evaluation of the Rashomon Effect in Explainable Machine Learning", "abstract": "The Rashomon Effect describes the following phenomenon: for a given dataset there may exist many models with equally good performance but with different solution strategies. The Rashomon Effect has implications for Explainable Machine Learning, especially for the comparability of explanations. We provide a unified view on three different comparison scenarios and conduct a quantitative evaluation across different datasets, models, attribution methods, and metrics. We find that hyperparameter-tuning plays a role and that metric selection matters. Our results provide empirical support for previously anecdotal evidence and exhibit challenges for both scientists and practitioners."}}
{"id": "DvyVkWM9C2M", "cdate": 1672531200000, "mdate": 1695972982660, "content": {"title": "Expectation-Complete Graph Representations with Homomorphisms", "abstract": "We investigate novel random graph embeddings that can be computed in expected polynomial time and that are able to distinguish all non-isomorphic graphs in expectation. Previous graph embeddings ha..."}}
{"id": "C2pwE_QsMI", "cdate": 1672531200000, "mdate": 1695972982645, "content": {"title": "Expectation-Complete Graph Representations with Homomorphisms", "abstract": "We investigate novel random graph embeddings that can be computed in expected polynomial time and that are able to distinguish all non-isomorphic graphs in expectation. Previous graph embeddings have limited expressiveness and either cannot distinguish all graphs or cannot be computed efficiently for every graph. To be able to approximate arbitrary functions on graphs, we are interested in efficient alternatives that become arbitrarily expressive with increasing resources. Our approach is based on Lov\\'asz' characterisation of graph isomorphism through an infinite dimensional vector of homomorphism counts. Our empirical evaluation shows competitive results on several benchmark graph learning tasks."}}
{"id": "-JmXLufMaA", "cdate": 1672531200000, "mdate": 1695972982599, "content": {"title": "Hidden Schema Networks", "abstract": "Ramses Sanchez, Lukas Conrads, Pascal Welke, Kostadin Cvejoski, Cesar Ojeda Marin. Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 2023."}}
{"id": "tFU1LS7eJs", "cdate": 1669852800000, "mdate": 1695972982655, "content": {"title": "Machine learning framework to predict nonwoven material properties from fiber graph representations", "abstract": ""}}
{"id": "Zf-Mn6xzD2B", "cdate": 1664046166825, "mdate": null, "content": {"title": "Expectation Complete Graph Representations using Graph Homomorphisms", "abstract": "We propose and study a practical graph embedding that *in expectation* is able to distinguish all non-isomorphic graphs and can be computed in polynomial time. The embedding is based on Lov\u00e1sz' characterization of graph isomorphism through an infinite dimensional vector of homomorphism counts. Recent work has studied the expressiveness of graph embeddings by comparing their ability to distinguish graphs to that of the Weisfeiler-Leman hierarchy. While previous methods have either limited expressiveness or are computationally impractical, we devise efficient sampling-based alternatives that are maximally expressive in expectation. We empirically evaluate our proposed embeddings and show competitive results on several benchmark graph learning tasks."}}
{"id": "KyxJ9Yfxo2", "cdate": 1663850284812, "mdate": null, "content": {"title": "Hidden Schema Networks", "abstract": "Most modern language models infer representations that, albeit powerful, lack both compositionality and semantic interpretability. Starting from the assumption that a large proportion of semantic content is necessarily relational, we introduce a neural language model that discovers networks of symbols (schemata) from text datasets. Using a variational autoencoder (VAE) framework, our model encodes sentences into sequences of symbols (composed representation), which correspond to the nodes visited by biased random walkers on a global latent graph. We first demonstrate that the model is able to uncover ground-truth graphs from artificially generated datasets of random token sequences. Next we leverage pretrained BERT and GPT-2 language models as encoder and decoder, respectively, to train our model on language modelling and commonsense knowledge generation tasks. Qualitatively, the model is able to infer schema networks whose nodes (symbols) can be interpreted as encoding different aspects of natural language (as e.g. topics, sentiments). Quantitatively, our results show that the model successfully interprets the encoded symbol sequences, as it achieves state-of-the-art scores on VAE language modeling benchmarks. Source code to reproduce all experiments is provided with the supplementary material."}}
{"id": "8GJyW4i2oST", "cdate": 1662812635484, "mdate": null, "content": {"title": "Expectation Complete Graph Representations using Graph Homomorphisms", "abstract": "We propose and study a practical graph embedding that *in expectation* is able to distinguish all non-isomorphic graphs and can be computed in polynomial time. The embedding is based on Lov\u00e1sz' characterisation of graph isomorphism through an infinite dimensional vector of homomorphism counts. Recent work has studied the expressiveness of graph embeddings by comparing their ability to distinguish graphs to that of the Weisfeiler-Leman hierarchy. While previous methods have either limited expressiveness or are computationally impractical, we devise efficient sampling-based alternatives that are maximally expressive in expectation. We empirically evaluate our proposed embeddings and show competitive results on several benchmark graph learning tasks."}}
