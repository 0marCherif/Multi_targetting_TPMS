{"id": "0jXTqlhcmj", "cdate": 1684298514030, "mdate": 1684298514030, "content": {"title": "Conditional Score-Based Reconstructions for Multi-contrast MRI", "abstract": "Magnetic resonance imaging (MRI) exam protocols consist of multiple contrast-weighted images of\nthe same anatomy to emphasize different tissue properties. Due to the long acquisition times required to\ncollect fully sampled k-space measurements, it is common to only collect a fraction of k-space for some,\nor all, of the scans and subsequently solve an inverse problem for each contrast to recover the desired\nimage from sub-sampled measurements. Recently, there has been a push to further accelerate MRI exams\nusing data-driven priors, and generative models in particular, to regularize the ill-posed inverse problem\nof image reconstruction. These methods have shown promising improvements over classical methods.\nHowever, many of the approaches neglect the multi-contrast nature of clinical MRI exams and treat each\nscan as an independent reconstruction. In this work we show that by learning a joint Bayesian prior over\nmulti-contrast data with a score-based generative model we are able to leverage the underlying structure\nbetween multi-contrast images and thus improve image reconstruction fidelity over generative models\nthat only reconstruct images of a single contrast."}}
{"id": "wPGvczhRBRS", "cdate": 1684295425428, "mdate": 1684295425428, "content": {"title": "Accelerated Motion Correction for MRI using Score-Based Generative Models", "abstract": "Magnetic Resonance Imaging (MRI) is a powerful medical imaging modality, but unfortunately suffers\nfrom long scan times which, aside from increasing operational costs, can lead to image artifacts due to\npatient motion. Motion during the acquisition leads to inconsistencies in measured data that manifest\nas blurring and ghosting if unaccounted for in the image reconstruction process. Various deep learning\nbased reconstruction techniques have been proposed which decrease scan time by reducing the number of\nmeasurements needed for a high fidelity reconstructed image. Additionally, deep learning has been used\nto correct motion using end-to-end techniques. This, however, increases susceptibility to distribution\nshifts at test time (sampling pattern, motion level). In this work we propose a framework for jointly reconstructing highly sub-sampled MRI data while estimating patient motion using score-based generative\nmodels. Our method does not make specific assumptions on the sampling trajectory or motion pattern\nat training time and thus can be flexibly applied to various types of measurement models and patient\nmotion. We demonstrate our framework on retrospectively accelerated 2D brain MRI corrupted by rigid\nmotion"}}
{"id": "igjxsgnvZPd", "cdate": 1634622669074, "mdate": null, "content": {"title": "Robust Compressed Sensing MR Imaging with Deep Generative Priors", "abstract": "The CSGM framework (Bora-Jalal-Price-Dimakis'17) has shown that deep\ngenerative priors can be powerful tools for solving inverse problems.\nHowever, to date this framework has been empirically successful only on\ncertain datasets (for example, human faces and MNIST digits), and it\nis known to perform poorly on out-of-distribution samples. In this\npaper, we present the first successful application of the CSGM\nframework on clinical MRI data. We train a generative prior on brain\nscans from the fastMRI dataset, and show that posterior sampling via\nLangevin dynamics achieves high quality reconstructions. Furthermore,\nour experiments and theory show that posterior sampling is robust to\nchanges in the ground-truth distribution and measurement process."}}
{"id": "wHoIjrT6MMb", "cdate": 1621629746439, "mdate": null, "content": {"title": "Robust Compressed Sensing MRI with Deep Generative Priors", "abstract": "The CSGM framework (Bora-Jalal-Price-Dimakis'17) has shown that deep\ngenerative priors can be powerful tools for solving inverse problems.\nHowever, to date this framework has been empirically successful only on\ncertain datasets (for example, human faces and MNIST digits), and it\nis known to perform poorly on out-of-distribution samples. In this\npaper, we present the first successful application of the CSGM\nframework on clinical MRI data. We train a generative prior on brain\nscans from the fastMRI dataset, and show that posterior sampling via\nLangevin dynamics achieves high quality reconstructions. Furthermore,\nour experiments and theory show that posterior sampling is robust to\nchanges in the ground-truth distribution and measurement process.\nOur code and models are available at: \n\\url{https://github.com/utcsilab/csgm-mri-langevin}."}}
{"id": "qMH7nppDmWu", "cdate": 1609459200000, "mdate": 1633475189962, "content": {"title": "Instance-Optimal Compressed Sensing via Posterior Sampling", "abstract": "We characterize the measurement complexity of compressed sensing of signals drawn from a known prior distribution, even when the support of the prior is the entire space (rather than, say, sparse vectors). We show for Gaussian measurements and \\emph{any} prior distribution on the signal, that the posterior sampling estimator achieves near-optimal recovery guarantees. Moreover, this result is robust to model mismatch, as long as the distribution estimate (e.g., from an invertible generative model) is close to the true distribution in Wasserstein distance. We implement the posterior sampling estimator for deep generative priors using Langevin dynamics, and empirically find that it produces accurate estimates with more diversity than MAP."}}
{"id": "p_8-gVxPDt8", "cdate": 1609459200000, "mdate": 1633475189980, "content": {"title": "Fairness for Image Generation with Uncertain Sensitive Attributes", "abstract": "This work tackles the issue of fairness in the context of generative procedures, such as image super-resolution, which entail different definitions from the standard classification setting. Moreove..."}}
{"id": "TtFxsxxNXGI", "cdate": 1609459200000, "mdate": 1633475189974, "content": {"title": "Fairness for Image Generation with Uncertain Sensitive Attributes", "abstract": "This work tackles the issue of fairness in the context of generative procedures, such as image super-resolution, which entail different definitions from the standard classification setting. Moreover, while traditional group fairness definitions are typically defined with respect to specified protected groups -- camouflaging the fact that these groupings are artificial and carry historical and political motivations -- we emphasize that there are no ground truth identities. For instance, should South and East Asians be viewed as a single group or separate groups? Should we consider one race as a whole or further split by gender? Choosing which groups are valid and who belongs in them is an impossible dilemma and being \"fair\" with respect to Asians may require being \"unfair\" with respect to South Asians. This motivates the introduction of definitions that allow algorithms to be \\emph{oblivious} to the relevant groupings. We define several intuitive notions of group fairness and study their incompatibilities and trade-offs. We show that the natural extension of demographic parity is strongly dependent on the grouping, and \\emph{impossible} to achieve obliviously. On the other hand, the conceptually new definition we introduce, Conditional Proportional Representation, can be achieved obliviously through Posterior Sampling. Our experiments validate our theoretical results and achieve fair image reconstruction using state-of-the-art generative models."}}
{"id": "SPqkDN5JsgSA", "cdate": 1609459200000, "mdate": 1633475189972, "content": {"title": "Intermediate Layer Optimization for Inverse Problems using Deep Generative Models", "abstract": "We propose Intermediate Layer Optimization (ILO), a novel optimization algorithm for solving inverse problems with deep generative models. Instead of optimizing only over the initial latent code, we progressively change the input layer obtaining successively more expressive generators. To explore the higher dimensional spaces, our method searches for latent codes that lie within a small $l_1$ ball around the manifold induced by the previous layer. Our theoretical analysis shows that by keeping the radius of the ball relatively small, we can improve the established error bound for compressed sensing with deep generative models. We empirically show that our approach outperforms state-of-the-art methods introduced in StyleGAN-2 and PULSE for a wide range of inverse problems including inpainting, denoising, super-resolution and compressed sensing."}}
{"id": "NK5lxHchpk", "cdate": 1609459200000, "mdate": 1633475189929, "content": {"title": "Intermediate Layer Optimization for Inverse Problems using Deep Generative Models", "abstract": "We propose Intermediate Layer Optimization (ILO), a novel optimization algorithm for solving inverse problems with deep generative models. Instead of optimizing only over the initial latent code, w..."}}
{"id": "LnfLK9yTlru", "cdate": 1609459200000, "mdate": 1633475189924, "content": {"title": "Instance-Optimal Compressed Sensing via Posterior Sampling", "abstract": "We characterize the measurement complexity of compressed sensing of signals drawn from a known prior distribution, even when the support of the prior is the entire space (rather than, say, sparse v..."}}
