{"id": "HrLJpXgma4", "cdate": 1685532015331, "mdate": null, "content": {"title": "An $\\varepsilon$-Best-Arm Identification Algorithm for Fixed-Confidence and Beyond", "abstract": "We propose EB-TC$\\varepsilon$, a novel sampling rule for $\\varepsilon$-best arm identification in stochastic bandits. It is the first instance of Top Two algorithm analyzed for approximate best arm identification. EB-TC$\\varepsilon$ is an anytime sampling rule that can therefore be employed without modification for fixed confidence or fixed budget identification (without prior knowledge of the budget). We provide three types of theoretical guarantees for EB-TC$\\varepsilon$. First, we prove bounds on its expected sample complexity in the fixed confidence setting, notably showing its asymptotic optimality in combination with an adaptive tuning of its exploration parameter. We complement these findings with upper bounds on its probability of error at any time and for any slack parameter, which further yield upper bounds on its simple regret at any time. Finally, we show through numerical simulations that EB-TC$\\varepsilon$ performs favorably compared to existing algorithms for different approximate best arm identification tasks."}}
{"id": "t0aUb-LGJFp", "cdate": 1672531200000, "mdate": 1684334202317, "content": {"title": "On the Existence of a Complexity in Fixed Budget Bandit Identification", "abstract": "In fixed budget bandit identification, an algorithm sequentially observes samples from several distributions up to a given final time. It then answers a query about the set of distributions. A good algorithm will have a small probability of error. While that probability decreases exponentially with the final time, the best attainable rate is not known precisely for most identification tasks. We show that if a fixed budget task admits a complexity, defined as a lower bound on the probability of error which is attained by the same algorithm on all bandit problems, then that complexity is determined by the best non-adaptive sampling procedure for that problem. We show that there is no such complexity for several fixed budget identification tasks including Bernoulli best arm identification with two arms: there is no single algorithm that attains everywhere the best possible rate."}}
{"id": "mWJDEfmBPvA", "cdate": 1672531200000, "mdate": 1684334202402, "content": {"title": "A Formalization of Doob's Martingale Convergence Theorems in mathlib", "abstract": ""}}
{"id": "IMDMaGFnkA", "cdate": 1672531200000, "mdate": 1684137779665, "content": {"title": "Dealing with Unknown Variances in Best-Arm Identification", "abstract": "The problem of identifying the best arm among a collection of items having Gaussian rewards distribution is well understood when the variances are known. Despite its practical relevance for many ap..."}}
{"id": "htR7ZXXe_TY", "cdate": 1652737667409, "mdate": null, "content": {"title": "On Elimination Strategies for Bandit Fixed-Confidence Identification", "abstract": "Elimination algorithms for bandit identification, which prune the plausible correct answers sequentially until only one remains, are computationally convenient since they reduce the problem size over time. However, existing elimination strategies are often not fully adaptive (they update their sampling rule infrequently) and are not easy to extend to combinatorial settings, where the set of answers is exponentially large in the problem dimension. On the other hand, most existing fully-adaptive strategies to tackle general identification problems are computationally demanding since they repeatedly test the correctness of every answer, without ever reducing the problem size. We show that adaptive methods can be modified to use elimination in both their stopping and sampling rules, hence obtaining the best of these two worlds: the algorithms (1) remain fully adaptive, (2) suffer a sample complexity that is never worse of their non-elimination counterpart, and (3) provably eliminate certain wrong answers early. We confirm these benefits experimentally, where elimination improves significantly the computational complexity of adaptive methods on common tasks like best-arm identification in linear bandits."}}
{"id": "xLnfzQYSIue", "cdate": 1652737504602, "mdate": null, "content": {"title": "Top Two Algorithms Revisited", "abstract": "Top two algorithms arose as an adaptation of Thompson sampling to best arm identification in multi-armed bandit models for parametric families of arms. They select the next arm to sample from by randomizing among two candidate arms, a leader and a challenger. Despite their good empirical performance, theoretical guarantees for fixed-confidence best arm identification have only been obtained when the arms are Gaussian with known variances. In this paper, we provide a general analysis of top-two methods, which identifies desirable properties of the leader, the challenger, and the (possibly non-parametric) distributions of the arms. As a result, we obtain theoretically supported top-two algorithms for best arm identification with bounded distributions. Our proof method demonstrates in particular that the sampling step used to select the leader inherited from Thompson sampling can be replaced by other choices, like selecting the empirical best arm."}}
{"id": "lngbhLn-OS", "cdate": 1640995200000, "mdate": 1684137779689, "content": {"title": "Non-Asymptotic Analysis of a UCB-based Top Two Algorithm", "abstract": "A Top Two sampling rule for bandit identification is a method which selects the next arm to sample from among two candidate arms, a leader and a challenger. Due to their simplicity and good empirical performance, they have received increased attention in recent years. However, for fixed-confidence best arm identification, theoretical guarantees for Top Two methods have only been obtained in the asymptotic regime, when the error level vanishes. In this paper, we derive the first non-asymptotic upper bound on the expected sample complexity of a Top Two algorithm, which holds for any error level. Our analysis highlights sufficient properties for a regret minimization algorithm to be used as leader. These properties are satisfied by the UCB algorithm, and our proposed UCB-based Top Two algorithm simultaneously enjoys non-asymptotic guarantees and competitive empirical performance."}}
{"id": "cwJDiE49_J_", "cdate": 1640995200000, "mdate": 1684137779641, "content": {"title": "Top Two Algorithms Revisited", "abstract": "Top two algorithms arose as an adaptation of Thompson sampling to best arm identification in multi-armed bandit models for parametric families of arms. They select the next arm to sample from by randomizing among two candidate arms, a leader and a challenger. Despite their good empirical performance, theoretical guarantees for fixed-confidence best arm identification have only been obtained when the arms are Gaussian with known variances. In this paper, we provide a general analysis of top-two methods, which identifies desirable properties of the leader, the challenger, and the (possibly non-parametric) distributions of the arms. As a result, we obtain theoretically supported top-two algorithms for best arm identification with bounded distributions. Our proof method demonstrates in particular that the sampling step used to select the leader inherited from Thompson sampling can be replaced by other choices, like selecting the empirical best arm."}}
{"id": "P6UW8dGJjG", "cdate": 1640995200000, "mdate": 1684334202357, "content": {"title": "On Elimination Strategies for Bandit Fixed-Confidence Identification", "abstract": "Elimination algorithms for bandit identification, which prune the plausible correct answers sequentially until only one remains, are computationally convenient since they reduce the problem size over time. However, existing elimination strategies are often not fully adaptive (they update their sampling rule infrequently) and are not easy to extend to combinatorial settings, where the set of answers is exponentially large in the problem dimension. On the other hand, most existing fully-adaptive strategies to tackle general identification problems are computationally demanding since they repeatedly test the correctness of every answer, without ever reducing the problem size. We show that adaptive methods can be modified to use elimination in both their stopping and sampling rules, hence obtaining the best of these two worlds: the algorithms (1) remain fully adaptive, (2) suffer a sample complexity that is never worse of their non-elimination counterpart, and (3) provably eliminate certain wrong answers early. We confirm these benefits experimentally, where elimination improves significantly the computational complexity of adaptive methods on common tasks like best-arm identification in linear bandits."}}
{"id": "BKiKC7eQRJ", "cdate": 1640995200000, "mdate": 1684137779692, "content": {"title": "Choosing Answers in Epsilon-Best-Answer Identification for Linear Bandits", "abstract": "In pure-exploration problems, information is gathered sequentially to answer a question on the stochastic environment. While best-arm identification for linear bandits has been extensively studied ..."}}
