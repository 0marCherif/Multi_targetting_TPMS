{"id": "IWlVrx0615a", "cdate": 1686250302534, "mdate": null, "content": {"title": "Prioritizing States with Action Sensitive Return in Experience Replay", "abstract": "Experience replay for off-policy reinforcement learning has been shown to improve sample efficiency and stabilize training. However, typical uniformly sampled replay includes many irrelevant samples for the agent to reach good performance. We introduce Action Sensitive Experience Replay (ASER), a method to prioritize samples in the replay buffer and selectively model parts of the state-space more accurately where choosing sub-optimal actions has a larger effect on the return. We experimentally show that this can make training more sample efficient and that this allows smaller parametric function approximators -- like neural networks with few neurons -- to achieve good performance in environments where they would otherwise struggle."}}
{"id": "l5n5OVnRlka", "cdate": 1680334211912, "mdate": 1680334211912, "content": {"title": "Robotic Packaging Optimization with Reinforcement Learning", "abstract": "Intelligent manufacturing is becoming increasingly important due to the growing demand for maximizing productivity and flexibility while minimizing waste and lead times. This work investigates automated secondary robotic food packaging solutions that transfer food products from the conveyor belt into containers. A major problem in these solutions is varying product supply which can cause drastic productivity drops. Conventional rule-based approaches, used to address this issue, are often inadequate, leading to violation of the industry's requirements. Reinforcement learning, on the other hand, has the potential of solving this problem by learning responsive and predictive policy, based on experience. However, it is challenging to utilize it in highly complex control schemes. In this paper, we propose a reinforcement learning framework, designed to optimize the conveyor belt speed while minimizing interference with the rest of the control system. When tested on real-world data, the framework exceeds the performance requirements (99.8% packed products) and maintains quality (100% filled boxes). Compared to the existing solution, our proposed framework improves productivity, has smoother control, and reduces computation time."}}
{"id": "uMjVvtb-nK0", "cdate": 1677628800000, "mdate": 1683645860535, "content": {"title": "Benchmarking Behavior Prediction Models in Gap Acceptance Scenarios", "abstract": "Autonomous vehicles currently suffer from a time-inefficient driving style caused by uncertainty about human behavior in traffic interactions. Accurate and reliable prediction models enabling more efficient trajectory planning could make autonomous vehicles more assertive in such interactions. However, the evaluation of such models is commonly oversimplistic, ignoring the asymmetric importance of prediction errors and the heterogeneity of the datasets used for testing. We examine the potential of recasting interactions between vehicles as gap acceptance scenarios and evaluating models in this structured environment. To that end, we develop a framework aiming to facilitate the evaluation of any model, by any metric, and in any scenario. We then apply this framework to state-of-the-art prediction models, which all show themselves to be unreliable in the most safety-critical situations."}}
{"id": "tjgG2gTslo", "cdate": 1672531200000, "mdate": 1681490084071, "content": {"title": "Probabilistic Risk Assessment for Chance-Constrained Collision Avoidance in Uncertain Dynamic Environments", "abstract": ""}}
{"id": "pmeWyrdTLJ", "cdate": 1672531200000, "mdate": 1683645860532, "content": {"title": "TrajFlow: Learning the Distribution over Trajectories", "abstract": "Predicting the future behavior of human road users remains an open challenge for the development of risk-aware autonomous vehicles. An important aspect of this challenge is effectively capturing the uncertainty inherent to human behavior. This paper proposes an approach for probabilistic trajectory prediction based on normalizing flows, which provides an analytical expression of the learned distribution. We reformulate the problem of capturing distributions over trajectories into capturing distributions over abstracted trajectory features using an autoencoder, simplifying the learning task of the normalizing flows. TrajFlow improves the calibration of the learned distributions while achieving predictive performance on par with or superior to state-of-the-art methods on the ETH/UCY and the rounD data set."}}
{"id": "jx75T9uUp7", "cdate": 1672531200000, "mdate": 1683645860521, "content": {"title": "Learning from Few Demonstrations with Frame-Weighted Motion Generation", "abstract": "Learning from Demonstration (LfD) aims to encode versatile skills from human demonstrations. The field has been gaining popularity since it facilitates knowledge transfer to robots without requiring expert knowledge in robotics. During task executions, the robot motion is usually influenced by constraints imposed by environments. In light of this, task-parameterized LfD (TP-LfD) encodes relevant contextual information in reference frames, enabling better skill generalization to new situations. However, most TP-LfD algorithms require multiple demonstrations in various environment conditions to ensure sufficient statistics for a meaningful model. It is not a trivial task for robot users to create different situations and perform demonstrations under all of them. Therefore, this paper presents a novel concept for learning motion policies from few demonstrations by finding the reference frame weights which capture frame importance/relevance during task executions. Experimental results in both simulation and real robotic environments validate our approach."}}
{"id": "j3IDj6xFRx", "cdate": 1672531200000, "mdate": 1681490084064, "content": {"title": "Do You Need a Hand? - a Bimanual Robotic Dressing Assistance Scheme", "abstract": ""}}
{"id": "ScUfnzc3fLa", "cdate": 1672531200000, "mdate": 1681490084020, "content": {"title": "Robotic Fabric Flattening with Wrinkle Direction Detection", "abstract": ""}}
{"id": "EAz-ofwNdG1", "cdate": 1672531200000, "mdate": 1683645860588, "content": {"title": "Robotic Packaging Optimization with Reinforcement Learning", "abstract": "Intelligent manufacturing is becoming increasingly important due to the growing demand for maximizing productivity and flexibility while minimizing waste and lead times. This work investigates automated secondary robotic food packaging solutions that transfer food products from the conveyor belt into containers. A major problem in these solutions is varying product supply which can cause drastic productivity drops. Conventional rule-based approaches, used to address this issue, are often inadequate, leading to violation of the industry's requirements. Reinforcement learning, on the other hand, has the potential of solving this problem by learning responsive and predictive policy, based on experience. However, it is challenging to utilize it in highly complex control schemes. In this paper, we propose a reinforcement learning framework, designed to optimize the conveyor belt speed while minimizing interference with the rest of the control system. When tested on real-world data, the framework exceeds the performance requirements (99.8% packed products) and maintains quality (100% filled boxes). Compared to the existing solution, our proposed framework improves productivity, has smoother control, and reduces computation time."}}
{"id": "AGGeCovrQpK", "cdate": 1672531200000, "mdate": 1681490084136, "content": {"title": "Stable Motion Primitives via Imitation and Contrastive Learning", "abstract": ""}}
