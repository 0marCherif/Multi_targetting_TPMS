{"id": "u84visVWT5j", "cdate": 1514764800000, "mdate": null, "content": {"title": "Cross-Entropy Training of DNN Ensemble Acoustic Models for Low-Resource ASR", "abstract": "Deep neural networks (DNNs) have shown a great promise in exploiting out-of-language data, particularly for under-resourced languages. The common trend is to merge data from various source languages to train a multilingual DNN and then reuse the hidden layers as language-independent feature extractors for a low-resource target language. While there is a consensus that using as much data from various languages results in a better and more general multilingual DNN, employing only source languages similar to the target language has proven effective. In this study, we propose a novel framework for multilingual DNN training, which employs all the available training data and exploits complementary information from individual source languages at the same time. Toward this goal, we borrow the idea of an ensemble with one generalist and many specialists. The generalist is derived from a multilingual DNN acoustic model trained on all available multilingual data; the specialists are the DNNs derived from the source languages individually. Then, the constituents in the ensemble are combined using weighted averaging schemes, where the combination weights are trained to minimize the cross-entropy objective function. In this framework, we seek for complementary information among the constituents while it is possible to get at least the performance equal to the baseline. Moreover, unlike previous well-known system combination schemes, only one model is required during decoding. We successfully examined two combination methodologies and demonstrated their usefulness in different scenarios using the multilingual GlobalPhone dataset. It is observed that, specifically, speech recognition systems developed in low-resource settings profit from the proposed strategy."}}
{"id": "xb0KS5OtKkuF", "cdate": 1483228800000, "mdate": null, "content": {"title": "Crosslingual and Multilingual Speech Recognition Based on the Speech Manifold", "abstract": "Speech signals are produced by the smooth and continuous movements of the human articulators. An articulatory representation of speech is considered to be a more compact, more universal, and language-independent speech feature space and can, therefore, improve crosslingual and multilingual speech recognition systems, especially when porting components from one language to another in low-resource scenarios. However, learning the acoustic-to-articulatory conversion has proven to be a very challenging task. In this paper, we utilize a manifold learning technique to derive a nonlinear feature transformation from the conventional filterbank feature space to an articulatory-like feature space. The coordinates in the resultant representation of which some have demonstrable phonological meaning are shown to be highly portable across languages. We propose a proper framework in terms of data selection and graph construction to train coordinates from multilingual data, which allows for training the coordinate space when we have abundant out-of-language data. Deep neural network (DNN) bottleneck features are demonstrated to exhibit a greater degree of language independence when using this representation than in the case of filterbank features as inputs. The usability of this representation is further demonstrated in a number of speech recognition experiments using DNNs in a variety of crosslingual and multilingual scenarios using the multilingual GlobalPhone dataset. Especially, speech recognition systems developed in low-resource settings profit from the improved portability across languages."}}
{"id": "kvX0p8pPLqr", "cdate": 1483228800000, "mdate": null, "content": {"title": "Exploiting sequential Low-Rank Factorization for multilingual DNNS", "abstract": "DNNs have shown remarkable performance in multilingual scenarios; however, these models are often too large in size that adaptation to a target language with relatively small amount of data cannot be well accomplished. In our previous work, we utilized Low-Rank Factorization (LRF) using singular value decomposition for multilingual DNNs to learn compact models which can be adapted more successfully. In this paper, we address two problems associated with that LRF scheme and we propose a compellingly simple methodology to overcome them. First, factorizing all layers results in a huge drop in performance and consequently a long recovery process is required which is not practically efficient. Secondly, LRF can be viewed as a regularization by which some noise is added to weight layers; however, factorizing all layers together equates to adding too much noise which results in bad performance. To mitigate these problems, we propose to apply LRF sequentially. We demonstrate that the lost information after factorizing one layer is small and can be rapidly retrieved; hence, sequential factorization is more efficient. Moreover, the sequential LRF adds only a small amount of noise sequentially which is a better regularization. Our experiments are conducted on five languages from the GlobalPhone dataset."}}
{"id": "5aTvPowcdSq", "cdate": 1451606400000, "mdate": null, "content": {"title": "A study of rank-constrained multilingual DNNS for low-resource ASR", "abstract": "Multilingual Deep Neural Networks (DNNs) have been successfully used to exploit out-of-language data to improve under-resourced ASR. In this paper, we improve on a multilingual DNN by utilizing low-rank factorization (LRF) of weight matrices via Singular Value Decomposition (SVD) to sparsify a multilingual DNN. LRF was previously used for monolingual DNNs, yielding large computational savings without a significant loss in recognition accuracy. In this work, we show that properly applying LRF on a multilingual DNN can improve recognition accuracy for multiple low-resource ASR configurations. First, only the final weight layer is factorized. Since the output weight layer needs to be trained with language specific data, reducing the number of parameters is beneficial for under-resourced languages. It is common in multilingual DNN speech recognition, to further adapt the full neural network through retraining of the multilingual DNN on target language data. Again we observe that in low-resource situations, this adaptation can bring significant improvement if LRF is applied to all hidden layers. We demonstrate the positive effect of LRF in two very different scenarios: one is a phone recognition task for two related languages and the other is a word recognition task using five different languages from the GlobalPhone dataset."}}
{"id": "3wOudn8JwoP", "cdate": 1451606400000, "mdate": null, "content": {"title": "Using Weighted Model Averaging in Distributed Multilingual DNNs to Improve Low Resource ASR", "abstract": "Multilingual Deep Neural Networks (DNNs) have been successfully used to leverage out-of-language data to boost the performance of a low resource ASR. However, the mismatch between auxiliary source languages and the target language can leave a negative effect on acoustic modeling for the target language. Thus, a key challenge in multilingual DNNs is to exploit acoustic data from multiple donor languages to improve on ASR performance while mitigating the problem of language mismatch. In this paper, we propose to employ weighted model averaging in the framework of distributed multilingual DNN which allows the target language or similar languages to take higher weights during the multilingual DNN training, and consequently shift the parameters towards the acoustic space of target data. Furthermore, we utilize the same strategy in the adaptation phase where a conventional multilingual DNN is the starting point and retraining is applied using all languages with different weights. The experiments with four languages from the GlobalPhone dataset show that the recognition performances in both scenarios are improved. The latter, moreover, provides a low-cost and efficient methodology for multilingual DNNs."}}
{"id": "-bF804hh0kq", "cdate": 1356998400000, "mdate": null, "content": {"title": "A study of supervised intrinsic spectral analysis for TIMIT phone classification", "abstract": "Intrinsic Spectral Analysis (ISA) has been formulated within a manifold learning setting allowing natural extensions to out-of-sample data together with feature reduction in a learning framework. In this paper, we propose two approaches to improve the performance of supervised ISA, and then we examine the effect of applying Linear Discriminant technique in the intrinsic subspace compared with the extrinsic one. In the interest of reducing complexity, we propose a preprocessing operation to find a small subset of data points being well representative of the manifold structure; this is accomplished by maximizing the quadratic Renyi entropy. Furthermore, we use class based graphs which not only simplify our problem but also can be helpful in a classification task. Experimental results for phone classification task on TIMIT dataset showed that ISA features improve the performance compared with traditional features, and supervised discriminant techniques outperform in the ISA subspace compared to conventional feature spaces."}}
{"id": "PXS4jmKg_SX", "cdate": 1293840000000, "mdate": null, "content": {"title": "Evolutionary eigenvoice MLLR speaker adaptation", "abstract": "This paper considers the problem of rapid and robust speaker adaptation in automatic speech recognition (ASR) systems. We propose an approach using combination of eigenspace-based maximum likelihood linear regression (EMLLR) and evolutionary algorithms. To find the best solution for the coefficients estimation problem, we suggest using genetic algorithm (GA) for rapid speaker adaptation. This is due to the fact that genetic algorithms are not as sensitive as expectation maximization (EM) algorithm to the amount of adaptation data. Experimental results on TIMIT database illustrate that genetic algorithm, using random individuals in first population, leads to up to 1.03% improvement in phoneme recognition rate. Moreover, we show that if the first population contains coefficients initially estimated by maximum likelihood criterion, further improvement can be achieved as well. However, the amount of adaptation data does not have considerable effect on the proposed method."}}
{"id": "_vnDHRRZWdP", "cdate": 1262304000000, "mdate": null, "content": {"title": "New Approach in Transform-Based Speaker Adaptation Using Minimum Classification Error", "abstract": "Automatic speech recognition (ASR) systems work well when trained for a number of specific speakers. However, in most applications there are multiple speakers and they are unknown to the system; performance of ASR system may be degraded because of such speaker variations. This paper examines the use of minimum classification error (MCE) as a preprocessing operation to improve the performance of conventional MLLR (Maximum Likelihood Linear Regression) adaptation. MCE applies its effect by providing better classified components for regression tree in the case of making regression tree on the basis of acoustic space. In this case, distribution of Gaussians will be more smoothing in regression classes. Experimental results on TIMIT database show that 0.42%-0.58% relative improvement is achieved in phoneme recognition rate using our proposed method."}}
