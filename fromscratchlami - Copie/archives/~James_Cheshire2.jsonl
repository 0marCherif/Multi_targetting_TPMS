{"id": "ERzpLwEDOY", "cdate": 1621630173756, "mdate": null, "content": {"title": "Bandits with many optimal arms", "abstract": "We consider a stochastic bandit problem with a possibly infinite number of arms. We write $p^*$ for the proportion of optimal arms and $\\Delta$ for the minimal mean-gap between optimal and sub-optimal arms. We characterize the optimal learning rates both in the cumulative regret setting, and in the best-arm identification setting in terms of the problem parameters $T$ (the budget), $p^*$ and $\\Delta$. For the objective of minimizing the cumulative regret, we provide a lower bound of order $\\Omega(\\log(T)/(p^*\\Delta))$ and a UCB-style algorithm with matching upper bound up to a factor of $\\log(1/\\Delta)$. Our algorithm needs $p^*$ to calibrate its parameters, and we prove that this knowledge is necessary, since adapting to $p^*$ in this setting is impossible. For best-arm identification we also provide a lower bound of order $\\Omega(\\exp(-cT\\Delta^2p^*))$ on the probability of outputting a sub-optimal arm where $c>0$ is an absolute constant. We also provide an elimination algorithm with an upper bound matching the lower bound up to a factor of order $\\log(T)$ in the exponential, and that does not need $p^*$ or $\\Delta$ as parameter. Our results apply directly to the three related problems of competing against the $j$-th best arm, identifying an $\\epsilon$ good arm, and finding an arm with mean larger than a quantile of a known order."}}
{"id": "zX0UJrFLlVG", "cdate": 1609459200000, "mdate": 1683879382439, "content": {"title": "Bandits with many optimal arms", "abstract": "We consider a stochastic bandit problem with a possibly infinite number of arms. We write $p^*$ for the proportion of optimal arms and $\\Delta$ for the minimal mean-gap between optimal and sub-optimal arms. We characterize the optimal learning rates both in the cumulative regret setting, and in the best-arm identification setting in terms of the problem parameters $T$ (the budget), $p^*$ and $\\Delta$. For the objective of minimizing the cumulative regret, we provide a lower bound of order $\\Omega(\\log(T)/(p^*\\Delta))$ and a UCB-style algorithm with matching upper bound up to a factor of $\\log(1/\\Delta)$. Our algorithm needs $p^*$ to calibrate its parameters, and we prove that this knowledge is necessary, since adapting to $p^*$ in this setting is impossible. For best-arm identification we also provide a lower bound of order $\\Omega(\\exp(-cT\\Delta^2p^*))$ on the probability of outputting a sub-optimal arm where $c&gt;0$ is an absolute constant. We also provide an elimination algorithm with an upper bound matching the lower bound up to a factor of order $\\log(T)$ in the exponential, and that does not need $p^*$ or $\\Delta$ as parameter. Our results apply directly to the three related problems of competing against the $j$-th best arm, identifying an $\\epsilon$ good arm, and finding an arm with mean larger than a quantile of a known order."}}
{"id": "h54iI3XaxS", "cdate": 1609459200000, "mdate": 1683879382791, "content": {"title": "Problem Dependent View on Structured Thresholding Bandit Problems", "abstract": "We investigate the \\textit{problem dependent regime} in the stochastic \\emph{Thresholding Bandit problem} (\\tbp) under several \\emph{shape constraints}. In the \\tbp the objective of the learner is ..."}}
{"id": "ox6BHjCPBrZ", "cdate": 1577836800000, "mdate": 1683879382711, "content": {"title": "The Influence of Shape Constraints on the Thresholding Bandit Problem", "abstract": "We investigate the stochastic \\emph{Thresholding Bandit problem} (\\textit{TBP}) under several \\emph{shape constraints}. On top of (i) the vanilla, unstructured \\textit{TBP}, we consider the case where (ii) the sequence of arm\u2019s means $(\\mu_k)_k$ is monotonically increasing \\textit{MTBP}, (iii) the case where $(\\mu_k)_k$ is unimodal \\textit{UTBP} and (iv) the case where $(\\mu_k)_k$ is concave \\textit{CTBP}. In the \\textit{TBP} problem the aim is to output, at the end of the sequential game, the set of arms whose means are above a given threshold. The regret is the highest gap between a misclassified arm and the threshold. In the fixed budget setting, we provide \\emph{problem independent} minimax rates for the expected regret in all settings, as well as associated algorithms. We prove that the minimax rates for the regret are (i) $\\sqrt{\\log(K)K/T}$ for \\textit{TBP}, (ii) $\\sqrt{\\log(K)/T}$ for \\textit{MTBP}, (iii) $\\sqrt{K/T}$ for \\textit{UTBP} and (iv) $\\sqrt{\\log\\log K/T}$ for \\textit{CTBP}, where $K$ is the number of arms and $T$ is the budget. These rates demonstrate that \\textit{the dependence on $K$} of the minimax regret varies significantly depending on the shape constraint. This highlights the fact that the shape constraints modify fundamentally the nature of the \\textit{TBP}."}}
