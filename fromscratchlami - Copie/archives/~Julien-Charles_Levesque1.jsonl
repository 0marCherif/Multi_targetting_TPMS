{"id": "Z_Ukdn1YjQa", "cdate": 1594384817180, "mdate": null, "content": {"title": "Sequential Emotion Recognition using Latent-Dynamic Conditional Neural Fields", "abstract": "A wide number of problems in face and gesture analysis involve the labeling of temporal sequences. In this paper, we introduce a discriminative model for such sequence labeling tasks. This model involves two layers of latent dynamics, each with their separate roles. The first layer, the neural network or gating layer, aims to extract non-linear relationships between input data and output labels. The second layer, the hidden-states layer, aims to model temporal substructure in the sequence by learning hidden-states and their transition dynamics. A new regularization term is proposed for the training of this model, encouraging diversity between hidden-states. We evaluate the performance of this model on an audiovisual dataset of emotion recognition and compare it against other popular methods for sequence labeling."}}
{"id": "Eehz21kWEE9", "cdate": 1594384724584, "mdate": null, "content": {"title": "Bayesian Optimization for Conditional Hyperparameter Spaces", "abstract": "Hyperparameter optimization is now widely applied to tune the hyperparameters of learning algorithms. The hyperparameters can have structure, resulting in hyperparameters depending on conditions, or on the values of other hyperparameters. We target the problem of combined algorithm selection and hyperparameter optimization, which includes at least one conditional hyperparameter: the choice of the learning algorithm. In this work, we show that Bayesian optimization with Gaussian processes can be used for the optimization of conditional spaces with the injection of knowledge concerning conditions in the kernel. We propose and examine the behavior of two kernels, a conditional kernel which forces the similarity of two samples from different condition branches to be zero, and the Laplace kernel, based on similarities with Mondrian processes and random forests. We show the benefit of using such kernels, as well as proper imputation of inactive hyperparameters, on a benchmark of scikit-learn models."}}
