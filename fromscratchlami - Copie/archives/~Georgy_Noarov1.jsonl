{"id": "7N66cV3Qwio", "cdate": 1683890932475, "mdate": 1683890932475, "content": {"title": "Online Minimax Multiobjective Optimization: Multicalibeating and Other Applications", "abstract": "We introduce a simple but general online learning framework in which a learner plays against an adversary in a vector-valued game that changes every round. Even though the learner's objective is not convex-concave (and so the minimax theorem does not apply), we give a simple algorithm that can compete with the setting in which the adversary must announce their action first, with optimally diminishing regret. We demonstrate the power of our framework by using it to (re)derive optimal bounds and efficient algorithms across a variety of domains, ranging from multicalibration to a large set of no-regret algorithms, to a variant of Blackwell's approachability theorem for polytopes with fast convergence rates. As a new application, we show how to ``(multi)calibeat'' an arbitrary collection of forecasters --- achieving an exponentially improved dependence on the number of models we are competing against, compared to prior work."}}
{"id": "biYb9MFNtUg", "cdate": 1672531200000, "mdate": 1681838143638, "content": {"title": "The Scope of Multicalibration: Characterizing Multicalibration via Property Elicitation", "abstract": "We make a connection between multicalibration and property elicitation and show that (under mild technical conditions) it is possible to produce a multicalibrated predictor for a continuous scalar distributional property $\\Gamma$ if and only if $\\Gamma$ is elicitable. On the negative side, we show that for non-elicitable continuous properties there exist simple data distributions on which even the true distributional predictor is not calibrated. On the positive side, for elicitable $\\Gamma$, we give simple canonical algorithms for the batch and the online adversarial setting, that learn a $\\Gamma$-multicalibrated predictor. This generalizes past work on multicalibrated means and quantiles, and in fact strengthens existing online quantile multicalibration results. To further counter-weigh our negative result, we show that if a property $\\Gamma^1$ is not elicitable by itself, but is elicitable conditionally on another elicitable property $\\Gamma^0$, then there is a canonical algorithm that jointly multicalibrates $\\Gamma^1$ and $\\Gamma^0$; this generalizes past work on mean-moment multicalibration. Finally, as applications of our theory, we provide novel algorithmic and impossibility results for fair (multicalibrated) risk assessment."}}
{"id": "Dk7QQp8jHEo", "cdate": 1663850109662, "mdate": null, "content": {"title": "Batch Multivalid Conformal Prediction", "abstract": "We develop  fast distribution-free conformal prediction algorithms for obtaining multivalid coverage on exchangeable data in the batch setting. Multivalid coverage guarantees are stronger than marginal coverage guarantees in two ways: (1) They hold even conditional on group membership---that is, the target coverage level $1-\\alpha$ holds conditionally on membership in each of an arbitrary (potentially intersecting) group in a finite collection $\\mathcal{G}$ of regions in the feature space. (2) They hold even conditional on the value of the threshold used to produce the prediction set on a given example. In fact multivalid coverage guarantees hold even when conditioning on group membership and threshold value simultaneously.\n\nWe give two algorithms: both take as input an arbitrary non-conformity score and an arbitrary collection of possibly intersecting groups $\\mathcal{G}$, and then can equip arbitrary black-box predictors with prediction sets.  Our first algorithm is a direct extension of quantile regression, needs to solve only a single convex minimization problem, and produces an estimator which has group-conditional guarantees for each group in $\\mathcal{G}$. Our second algorithm is iterative, and gives the full guarantees of multivalid conformal prediction: prediction sets that are valid conditionally both on group membership and non-conformity threshold. We evaluate the performance of both of our algorithms in an extensive set of experiments. "}}
{"id": "10QpQu-brS0", "cdate": 1656633600000, "mdate": 1681838143822, "content": {"title": "SIGecom winter meeting 2022 highlights", "abstract": "Emily Diana is a rising fifth year Ph.D. student in Statistics and Data Science at the Wharton School, University of Pennsylvania, where she is advised by Michael Kearns and Aaron Roth. Her research focuses on the intersection of ethical algorithm design and socially aware machine learning, and she is honored to have been recognized as both a Rising Star in EECS by MIT and a Future Leader in Data Science by the University of Michigan. Before Penn, she received a B.A. in Applied Mathematics from Yale and an M.S. in Statistics from Stanford, and she spent two years as a software developer at Lawrence Livermore National Laboratory. Mingzi Niu is a rising fifth year Ph.D. student in Economics at Rice University, where she is advised by Mallesh Pai and H\u00fclya Eraslan. Her research interest are primarily in microeconomic theory, with a focus on mechanism design, information theory and behavioral economics. Before Rice, she received a B.A. in Finance and Banking and a B.S. in Mathematics and Statistics at Peking University, and a M.A. in Economics at Duke University. Georgy Noarov is a rising third year PhD student in Computer and Information Science at the University of Pennsylvania, advised by Michael Kearns and Aaron Roth. Previously, he graduated from Princeton University with a B.A. in Mathematics. His research interests span across the fields of uncertainty quantification, online learning, fairness in machine learning, and algorithmic game theory."}}
{"id": "Epk1RQUpOj0", "cdate": 1652737469558, "mdate": null, "content": {"title": "Online Minimax Multiobjective Optimization: Multicalibeating and Other Applications", "abstract": "We introduce a simple but general online learning framework in which a learner plays against an adversary in a vector-valued game that changes every round. Even though the learner's objective is not convex-concave (and so the minimax theorem does not apply), we give a simple algorithm that can compete with the setting in which the adversary must announce their action first, with optimally diminishing regret. We demonstrate the power of our framework by using it to (re)derive optimal bounds and efficient algorithms across a variety of domains, ranging from multicalibration to a large set of no-regret algorithms, to a variant of Blackwell's approachability theorem for polytopes with fast convergence rates. As a new application, we show how to ``(multi)calibeat'' an arbitrary collection of forecasters --- achieving an exponentially improved dependence on the number of models we are competing against, compared to prior work. "}}
{"id": "QNjyrDBx6tz", "cdate": 1652737390957, "mdate": null, "content": {"title": "Practical Adversarial Multivalid Conformal Prediction", "abstract": "We give a simple, generic conformal prediction method for sequential prediction that achieves target empirical coverage guarantees on adversarial data. It is computationally lightweight --- comparable to split conformal prediction --- but does not require having a held-out validation set, and so all data can be used for training models from which to derive a conformal score. Furthermore, it gives stronger than marginal coverage guarantees in two ways. First, it gives threshold-calibrated prediction sets that have correct empirical coverage even conditional on the threshold used to form the prediction set from the conformal score. Second, the user can specify an arbitrary collection of subsets of the feature space --- possibly intersecting --- and the coverage guarantees will also hold conditional on membership in each of these subsets. We call our algorithm MVP, short for MultiValid Prediction. We give both theory and an extensive set of empirical evaluations. "}}
{"id": "yYpWDip4Jdr", "cdate": 1640995200000, "mdate": 1681838143664, "content": {"title": "Practical Adversarial Multivalid Conformal Prediction", "abstract": "We give a simple, generic conformal prediction method for sequential prediction that achieves target empirical coverage guarantees against adversarially chosen data. It is computationally lightweight -- comparable to split conformal prediction -- but does not require having a held-out validation set, and so all data can be used for training models from which to derive a conformal score. It gives stronger than marginal coverage guarantees in two ways. First, it gives threshold calibrated prediction sets that have correct empirical coverage even conditional on the threshold used to form the prediction set from the conformal score. Second, the user can specify an arbitrary collection of subsets of the feature space -- possibly intersecting -- and the coverage guarantees also hold conditional on membership in each of these subsets. We call our algorithm MVP, short for MultiValid Prediction. We give both theory and an extensive set of empirical evaluations."}}
{"id": "kgZBYfO8MDx", "cdate": 1640995200000, "mdate": 1681838143824, "content": {"title": "Batch Multivalid Conformal Prediction", "abstract": "We develop fast distribution-free conformal prediction algorithms for obtaining multivalid coverage on exchangeable data in the batch setting. Multivalid coverage guarantees are stronger than marginal coverage guarantees in two ways: (1) They hold even conditional on group membership -- that is, the target coverage level $1-\\alpha$ holds conditionally on membership in each of an arbitrary (potentially intersecting) group in a finite collection $\\mathcal{G}$ of regions in the feature space. (2) They hold even conditional on the value of the threshold used to produce the prediction set on a given example. In fact multivalid coverage guarantees hold even when conditioning on group membership and threshold value simultaneously.   We give two algorithms: both take as input an arbitrary non-conformity score and an arbitrary collection of possibly intersecting groups $\\mathcal{G}$, and then can equip arbitrary black-box predictors with prediction sets. Our first algorithm (BatchGCP) is a direct extension of quantile regression, needs to solve only a single convex minimization problem, and produces an estimator which has group-conditional guarantees for each group in $\\mathcal{G}$. Our second algorithm (BatchMVP) is iterative, and gives the full guarantees of multivalid conformal prediction: prediction sets that are valid conditionally both on group membership and non-conformity threshold. We evaluate the performance of both of our algorithms in an extensive set of experiments. Code to replicate all of our experiments can be found at https://github.com/ProgBelarus/BatchMultivalidConformal"}}
{"id": "ckdB0G8TFjY", "cdate": 1640995200000, "mdate": 1681838143537, "content": {"title": "Online Multivalid Learning: Means, Moments, and Prediction Intervals", "abstract": "We present a general, efficient technique for providing contextual predictions that are \"multivalid\" in various senses, against an online sequence of adversarially chosen examples (x,y). This means that the resulting estimates correctly predict various statistics of the labels y not just marginally - as averaged over the sequence of examples - but also conditionally on x \u2208 G for any G belonging to an arbitrary intersecting collection of groups \ud835\udca2. We provide three instantiations of this framework. The first is mean prediction, which corresponds to an online algorithm satisfying the notion of multicalibration from [H\u00e9bert-Johnson et al., 2018]. The second is variance and higher moment prediction, which corresponds to an online algorithm satisfying the notion of mean-conditioned moment multicalibration from [Jung et al., 2021]. Finally, we define a new notion of prediction interval multivalidity, and give an algorithm for finding prediction intervals which satisfy it. Because our algorithms handle adversarially chosen examples, they can equally well be used to predict statistics of the residuals of arbitrary point prediction methods, giving rise to very general techniques for quantifying the uncertainty of predictions of black box algorithms, even in an online adversarial setting. When instantiated for prediction intervals, this solves a similar problem as conformal prediction, but in an adversarial environment and with multivalidity guarantees stronger than simple marginal coverage guarantees."}}
{"id": "CBOly_LMSY", "cdate": 1640995200000, "mdate": 1681838143620, "content": {"title": "Computing Approximate Equilibria in Weighted Congestion Games via Best-Responses", "abstract": "We present a deterministic polynomial-time algorithm for computing dd+o(d)-approximate (pure) Nash equilibria in (proportional sharing) weighted congestion games with polynomial cost functions of d..."}}
