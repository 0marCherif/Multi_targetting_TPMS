{"id": "zbF8LWc45XR", "cdate": 1672531200000, "mdate": 1699155026413, "content": {"title": "Bidirectional Gated Edge-Labeling Graph Recurrent Neural Network for Few-Shot Learning", "abstract": "Many existing graph-based methods for few-shot learning problem focused on either separately learning node features or edge features or simply utilizing graph convolution, failing to fully retain or exploit graph structure information. In this article, we proposed a bidirectional gated edge-labeling graph recurrent neural network (bi-GEGRN) which adopts both edge-labeling graph framework and graph convolution operation in the meta-learning scheme. We modified the gated graph neural network to adjacency matrix generator-based bidirectional formation which is able to process sequence graph data in two directions and then organically combined it with edge-labeled graph framework to cyclically upgrade features meanwhile aggregate graph structure information. In view of the excellent aggregating capability of graph convolution and good performance of the alternately cyclic update strategy, bi-GEGRN improves the information transferring between tasks in meta learning. To verify the validity and universality on both supervised and semi-supervised regimes, extensive experiments were conducted on three few-shot benchmark data sets and bi-GEGRN showed a good performance."}}
{"id": "MKb_yCLwlO", "cdate": 1672531200000, "mdate": 1699155026516, "content": {"title": "Gait Recognition via Gait Period Set", "abstract": "Gait recognition has promising application prospects in surveillance applications, with the recently proposed video-based gait recognition methods affording huge progress. However, due to the poor image quality of some gait frames, the original frame-level features extracted from gait silhouettes are not discriminative enough to be aggregated as gait features utilized during the final recognition. Besides, as a type of periodic biometric behavior, periodic gait information is considered efficacious for capturing typical human walking patterns and refining frame-level gait features. Therefore, this paper proposes a novel approach that exploits periodic gait information, named Gait Period Set (GPS), which divides the gait period into several phases and ensembles the gait phase features to refine frame-level features. Then, features from different phases are aggregated into a video-level feature. Moreover, the refined frame-level features are aggregated as the refined gait phase features with higher quality, which can be used to re-refine the frame-level features. Hence, we upgrade the GPS into the Iterative Gait Period Set (IGPS) to iteratively refine the frame-level features. The results of extensive experiments on prevailing gait recognition datasets validate the effectiveness of the GPS and IGPS modules and demonstrate that the proposed method achieves state-of-the-art performance."}}
{"id": "2IbbYQwp1O", "cdate": 1672531200000, "mdate": 1699155026424, "content": {"title": "Hierarchical Clustering and Refinement for Generalized Multi-Camera Person Tracking", "abstract": "Multi-camera person tracking has gained significant attention in recent times, owing to its widespread application in surveillance scenarios. However, this task is challenging due to the variance viewpoints, heavy occlusion, and illumination changes. In order to tackle these challenges, we propose a novel Hierarchical Clustering and Refinement framework for Generalized Multi-Camera Person Tracking. Specifically, our framework comprises two main components: hierarchical clustering and hierarchical refinement. Compared with directly clustering tracklets among multiple cameras, our hierarchical clustering strategy can progressively assign tracklets to correct targets. Nevertheless, the clustering and tracking process would inevitably produce incorrect matchings. Therefore, a hierarchical refinement strategy is proposed to reduce these incorrect matches which includes: intra-camera tracklet level refinement, appearance refinement, spatial-temporal refinement, and face refinement. Extensive experiments show the effectiveness of our method, which achieves 92% IDF1 in 2023 AI CITY CHALLENGE track1, ranking 5th on the leaderboard."}}
{"id": "tmD1NlP9RMZ", "cdate": 1640995200000, "mdate": 1699155026425, "content": {"title": "Spatial-wise and channel-wise feature uncertainty for occluded person re-identification", "abstract": ""}}
{"id": "s8Hh1MnVam", "cdate": 1640995200000, "mdate": 1666686680429, "content": {"title": "Reliability Exploration with Self-Ensemble Learning for Domain Adaptive Person Re-identification", "abstract": "Person re-identifcation (Re-ID) based on unsupervised domain adaptation (UDA) aims to transfer the pre-trained model from one labeled source domain to an unlabeled target domain. Existing methods tackle this problem by using clustering methods to generate pseudo labels. However, pseudo labels produced by these techniques may be unstable and noisy, substantially deteriorating models\u2019 performance. In this paper, we propose a Reliability Exploration with Self-ensemble Learning (RESL) framework for domain adaptive person ReID. First, to increase the feature diversity, multiple branches are presented to extract features from different data augmentations. Taking the temporally average model as a mean teacher model, online label refning is conducted by using its dynamic ensemble predictions from different branches as soft labels. Second, to combat the adverse effects of unreliable samples in clusters, sample reliability is estimated by evaluating the consistency of different clusters\u2019 results, followed by selecting reliable instances for training and re-weighting sample contribution within Re-ID losses. A contrastive loss is also utilized with cluster-level memory features which are updated by the mean feature. The experiments demonstrate that our method can signifcantly surpass the state-of-the-art performance on the unsupervised domain adaptive person ReID."}}
{"id": "4QeOWrlCaMp", "cdate": 1640995200000, "mdate": 1699155026412, "content": {"title": "Improving Transferability of Adversarial Examples on Face Recognition with Beneficial Perturbation Feature Augmentation", "abstract": "Face recognition (FR) models can be easily fooled by adversarial examples, which are crafted by adding imperceptible perturbations on benign face images. The existence of adversarial face examples poses a great threat to the security of society. In order to build a more sustainable digital nation, in this paper, we improve the transferability of adversarial face examples to expose more blind spots of existing FR models. Though generating hard samples has shown its effectiveness in improving the generalization of models in training tasks, the effectiveness of utilizing this idea to improve the transferability of adversarial face examples remains unexplored. To this end, based on the property of hard samples and the symmetry between training tasks and adversarial attack tasks, we propose the concept of hard models, which have similar effects as hard samples for adversarial attack tasks. Utilizing the concept of hard models, we propose a novel attack method called Beneficial Perturbation Feature Augmentation Attack (BPFA), which reduces the overfitting of adversarial examples to surrogate FR models by constantly generating new hard models to craft the adversarial examples. Specifically, in the backpropagation, BPFA records the gradients on pre-selected feature maps and uses the gradient on the input image to craft the adversarial example. In the next forward propagation, BPFA leverages the recorded gradients to add beneficial perturbations on their corresponding feature maps to increase the loss. Extensive experiments demonstrate that BPFA can significantly boost the transferability of adversarial attacks on FR."}}
{"id": "ltTqIexouEK", "cdate": 1609459200000, "mdate": 1699155026419, "content": {"title": "Video saliency prediction via spatio-temporal reasoning", "abstract": ""}}
{"id": "ZFYw3CrR3hP", "cdate": 1609459200000, "mdate": 1699155026422, "content": {"title": "Saliency detection via cross-scale deep inference", "abstract": ""}}
{"id": "OxD6ARHU6ie", "cdate": 1609459200000, "mdate": 1699155026419, "content": {"title": "Video Saliency Prediction via Deep Eye Movement Learning", "abstract": "Existing methods often utilize temporal motion information and spatial layout information in video to predict video saliency. However, the fixations are not always consistent with the moving object of interest, because human eye fixations are determined not only by the spatio-temporal information, but also by the velocity of eye movement. To address this issue, a new saliency prediction method via deep eye movement learning (EML) is proposed in this paper. Compared with previous methods that use human fixations as ground truth, our method uses the optical flow of fixations between successive frames as an extra ground truth for the purpose of eye movement learning. Experimental results on DHF1K, Hollywood2, and UCF-sports datasets show the proposed EML model achieves a promising result across a wide of metrics."}}
{"id": "MlbojXwftBy", "cdate": 1609459200000, "mdate": 1699155026413, "content": {"title": "Gaze estimation via bilinear pooling-based attention networks", "abstract": ""}}
