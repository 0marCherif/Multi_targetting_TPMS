{"id": "cDI3iNMmgM", "cdate": 1682354934202, "mdate": 1682354934202, "content": {"title": "DiracDiffusion: Denoising and Incremental Reconstruction with Assured Data-Consistency", "abstract": "Diffusion models have established new state of the art in a multitude of computer vision tasks, including image restoration. Diffusion-based inverse problem solvers generate reconstructions of exceptional visual quality from heavily corrupted measurements. However, in what is widely known as the perception-distortion trade-off, the price of perceptually appealing reconstructions is often paid in declined distortion metrics, such as PSNR. Distortion metrics measure faithfulness to the observation, a crucial requirement in inverse problems. In this work, we propose a novel framework for inverse problem solving, namely we assume that the observation comes from a stochastic degradation process that gradually degrades and noises the original clean image. We learn to reverse the degradation process in order to recover the clean image. Our technique maintains consistency with the original measurement throughout the reverse process, and allows for great flexibility in trading off perceptual quality for improved distortion metrics and sampling speedup via early-stopping. We demonstrate the efficiency of our method on different high-resolution datasets and inverse problems, achieving great improvements over other state-of-the-art diffusion-based methods with respect to both perceptual and distortion metrics. Source code and pre-trained models will be released soon."}}
{"id": "z0M3qHDqH20", "cdate": 1652737612574, "mdate": null, "content": {"title": "HUMUS-Net: Hybrid Unrolled Multi-scale Network Architecture for Accelerated MRI Reconstruction", "abstract": "In accelerated MRI reconstruction, the anatomy of a patient is recovered from a set of undersampled and noisy measurements. Deep learning approaches have been proven to be successful in solving this ill-posed inverse problem and are capable of producing very high quality reconstructions. However, current architectures heavily rely on convolutions, that are content-independent and have difficulties modeling long-range dependencies in images. Recently, Transformers, the workhorse of contemporary natural language processing, have emerged as powerful building blocks for a multitude of vision tasks. These models split input images into non-overlapping patches, embed the patches into lower-dimensional tokens and utilize a self-attention mechanism that does not suffer from the aforementioned weaknesses of convolutional architectures. However, Transformers incur extremely high compute and memory cost when 1) the input image resolution is high and 2) when the image needs to be split into a large number of patches to preserve fine detail information, both of which are typical in low-level vision problems such as MRI reconstruction, having a compounding effect. To tackle these challenges, we propose HUMUS-Net, a hybrid architecture that combines the beneficial implicit bias and efficiency of convolutions with the power of Transformer blocks in an unrolled and multi-scale network. HUMUS-Net extracts high-resolution features via convolutional blocks and refines low-resolution features via a novel Transformer-based multi-scale feature extractor. Features from both levels are then synthesized into a high-resolution output reconstruction. Our network establishes new state of the art on the largest publicly available MRI dataset, the fastMRI dataset. We further demonstrate the performance of HUMUS-Net on two other popular MRI datasets and perform fine-grained ablation studies to validate our design."}}
{"id": "MPg3F8Amt", "cdate": 1640995200000, "mdate": 1668706482983, "content": {"title": "HUMUS-Net: Hybrid unrolled multi-scale network architecture for accelerated MRI reconstruction", "abstract": "In accelerated MRI reconstruction, the anatomy of a patient is recovered from a set of under-sampled and noisy measurements. Deep learning approaches have been proven to be successful in solving this ill-posed inverse problem and are capable of producing very high quality reconstructions. However, current architectures heavily rely on convolutions, that are content-independent and have difficulties modeling long-range dependencies in images. Recently, Transformers, the workhorse of contemporary natural language processing, have emerged as powerful building blocks for a multitude of vision tasks. These models split input images into non-overlapping patches, embed the patches into lower-dimensional tokens and utilize a self-attention mechanism that does not suffer from the aforementioned weaknesses of convolutional architectures. However, Transformers incur extremely high compute and memory cost when 1) the input image resolution is high and 2) when the image needs to be split into a large number of patches to preserve fine detail information, both of which are typical in low-level vision problems such as MRI reconstruction, having a compounding effect. To tackle these challenges, we propose HUMUS-Net, a hybrid architecture that combines the beneficial implicit bias and efficiency of convolutions with the power of Transformer blocks in an unrolled and multi-scale network. HUMUS-Net extracts high-resolution features via convolutional blocks and refines low-resolution features via a novel Transformer-based multi-scale feature extractor. Features from both levels are then synthesized into a high-resolution output reconstruction. Our network establishes new state of the art on the largest publicly available MRI dataset, the fastMRI dataset. We further demonstrate the performance of HUMUS-Net on two other popular MRI datasets and perform fine-grained ablation studies to validate our design."}}
{"id": "eo1barn2Xmd", "cdate": 1632875505672, "mdate": null, "content": {"title": "SLIM-QN: A Stochastic, Light, Momentumized Quasi-Newton Optimizer for Deep Neural Networks", "abstract": "We propose SLIM-QN, a light stochastic quasi-Newton optimizer for training large-scale deep neural networks (DNNs).\nSLIM-QN addresses two key barriers in existing second-order methods for large-scale DNNs: 1) the high computational cost of obtaining the Hessian matrix and its inverse in every iteration (e.g. KFAC); 2) convergence instability due to stochastic training (e.g. L-BFGS).\nTo tackle the first challenge,SLIM-QN directly approximates the Hessian inverse using past parameters and gradients, without explicitly constructing the Hessian matrix and then computing its inverse.\nTo achieve stable convergence, SLIM-QN introduces momentum in Hessian updates together with an adaptive damping mechanism.\nWe provide rigorous theoretical results on the convergence of SLIM-QN in a stochastic setting.\nWe also demonstrate that SLIM-QN has much less compute and memory overhead compared to existing second-order methods. \nTo better understand the limitations and benefits of SLIM-QN, we evaluate its performance on various datasets and network architectures.\nFor instance on large datasets such as ImageNet, we show that SLIM-QN achieves near optimal accuracy $1.5\\times$ faster when compared with SGD ($1.36\\times$ faster in wall-clock time) using the same compute resources.\nWe also show that SLIM-QN can readily be applied to other contemporary non-convolutional architectures such as Transformers."}}
{"id": "x1X91zeCj58", "cdate": 1609459200000, "mdate": 1668706483078, "content": {"title": "Data augmentation for deep learning based accelerated MRI reconstruction with limited data", "abstract": "Deep neural networks have emerged as very successful tools for image restoration and reconstruction tasks. These networks are often trained end-to-end to directly reconstruct an image from a noisy ..."}}
{"id": "kEsxMLb28k", "cdate": 1609459200000, "mdate": 1668706482992, "content": {"title": "Data augmentation for deep learning based accelerated MRI reconstruction with limited data", "abstract": "Deep neural networks have emerged as very successful tools for image restoration and reconstruction tasks. These networks are often trained end-to-end to directly reconstruct an image from a noisy or corrupted measurement of that image. To achieve state-of-the-art performance, training on large and diverse sets of images is considered critical. However, it is often difficult and/or expensive to collect large amounts of training images. Inspired by the success of Data Augmentation (DA) for classification problems, in this paper, we propose a pipeline for data augmentation for accelerated MRI reconstruction and study its effectiveness at reducing the required training data in a variety of settings. Our DA pipeline, MRAugment, is specifically designed to utilize the invariances present in medical imaging measurements as naive DA strategies that neglect the physics of the problem fail. Through extensive studies on multiple datasets we demonstrate that in the low-data regime DA prevents overfitting and can match or even surpass the state of the art while using significantly fewer training data, whereas in the high-data regime it has diminishing returns. Furthermore, our findings show that DA can improve the robustness of the model against various shifts in the test distribution."}}
{"id": "lH2ukHnGDdq", "cdate": 1601308308235, "mdate": null, "content": {"title": "Data augmentation for deep learning based accelerated MRI reconstruction", "abstract": "Deep neural networks have emerged as very successful tools for image restoration and reconstruction tasks. These networks are often trained end-to-end to directly reconstruct an image from a noisy or corrupted measurement of that image. To achieve state-of-the-art performance, training on large and diverse sets of images is considered critical. However, it is often difficult and/or expensive to collect large amounts of training images. Inspired by the success of Data Augmentation (DA) for classification problems, in this paper, we propose a pipeline for data augmentation for image reconstruction tasks arising in medical imaging and explore its effectiveness at reducing the required training data in a variety of settings. We focus on accelerated magnetic resonance imaging, where the goal is to reconstruct an image from a few under-sampled linear measurements. Our DA pipeline is specifically designed to utilize the invariances present in medical imaging measurements as naive DA strategies that neglect the physics of the problem fail. We demonstrate the effectiveness of our data augmentation pipeline by showing that for some problem regimes, DA can achieve comparable performance to the state of the art on the FastMRI dataset while using significantly fewer training data. Specifically, for 8-fold acceleration we achieve performance comparable to the state of the art with only $10\\%$ of the training data for multi-coil reconstruction and with only $33\\%$ of the training data for single-coil reconstruction. Our findings show that in the low-data regime DA is beneficial, whereas in the high-data regime it has diminishing returns."}}
{"id": "kB_I7ChKWC3", "cdate": 1577836800000, "mdate": 1668706482786, "content": {"title": "3D Phase Retrieval at Nano-Scale via Accelerated Wirtinger Flow", "abstract": "Imaging 3D nano-structures at very high resolution is crucial in a variety of scientific fields. However, due to fundamental limitations of light propagation we can only measure the object indirectly via 2D intensity measurements of the 3D specimen through highly nonlinear projection mappings where a variety of information (including phase) is lost. Reconstruction therefore involves inverting highly non-linear and seemingly non-invertible mappings. In this paper, we introduce a novel technique where the 3D object is directly reconstructed from an accurate non-linear propagation model. Furthermore, we characterize the ambiguities of this model and leverage a priori knowledge to mitigate their effect and also significantly reduce the required number of measurements and hence the acquisition time. We demonstrate the performance of our algorithm via numerical experiments aimed at nano-scale reconstruction of 3D integrated circuits. Moreover, we provide rigorous theoretical guarantees for convergence to stationarity."}}
{"id": "dfl6xsCDdR", "cdate": 1577836800000, "mdate": 1668706482972, "content": {"title": "Minimax Lower Bounds for Transfer Learning with Linear and One-hidden Layer Neural Networks", "abstract": "Transfer learning has emerged as a powerful technique for improving the performance of machine learning models on new domains where labeled training data may be scarce. In this approach a model trained for a source task, where plenty of labeled training data is available, is used as a starting point for training a model on a related target task with only few labeled training data. Despite recent empirical success of transfer learning approaches, the benefits and fundamental limits of transfer learning are poorly understood. In this paper we develop a statistical minimax framework to characterize the fundamental limits of transfer learning in the context of regression with linear and one-hidden layer neural network models. Specifically, we derive a lower-bound for the target generalization error achievable by any algorithm as a function of the number of labeled source and target data as well as appropriate notions of similarity between the source and target tasks. Our lower bound provides new insights into the benefits and limitations of transfer learning. We further corroborate our theoretical finding with various experiments."}}
{"id": "Tt4G_fqTrb4", "cdate": 1577836800000, "mdate": 1668706482827, "content": {"title": "3D Phase Retrieval at Nano-Scale via Accelerated Wirtinger Flow", "abstract": "Imaging 3D nano-structures at very high resolution is crucial in a variety of scientific fields. However, due to fundamental limitations of light propagation we can only measure the object indirectly via 2D intensity measurements of the 3D specimen through highly nonlinear projection mappings where a variety of information (including phase) is lost. Reconstruction therefore involves inverting highly non-linear and seemingly noninvertible mappings. In this paper, we introduce a novel technique where the 3D object is directly reconstructed from an accurate non-linear propagation model. Furthermore, we characterize the ambiguities of this model and leverage a priori knowledge to mitigate their effect and also significantly reduce the required number of measurements and hence the acquisition time. We demonstrate the performance of our algorithm via numerical experiments aimed at nano-scale reconstruction of 3D integrated circuits. Moreover, we provide rigorous theoretical guarantees for convergence to stationarity."}}
