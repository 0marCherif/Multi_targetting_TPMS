{"id": "oNCjGUPabM", "cdate": 1672531200000, "mdate": 1680325336371, "content": {"title": "Real-Time Hierarchical Map Segmentation for Coordinating Multirobot Exploration", "abstract": ""}}
{"id": "nDL_hSmei7", "cdate": 1672531200000, "mdate": 1680325336372, "content": {"title": "Efficient Training of Large-scale Industrial Fault Diagnostic Models through Federated Opportunistic Block Dropout", "abstract": ""}}
{"id": "BmKuwF3F-C", "cdate": 1672531200000, "mdate": 1681676145606, "content": {"title": "LMExplainer: a Knowledge-Enhanced Explainer for Language Models", "abstract": "Large language models (LLMs) such as GPT-4 are very powerful and can process different kinds of natural language processing (NLP) tasks. However, it can be difficult to interpret the results due to the multi-layer nonlinear model structure and millions of parameters. A lack of clarity and understanding of how the language models (LMs) work can make them unreliable, difficult to trust, and potentially dangerous for use in real-world scenarios. Most recent works exploit attention weights to provide explanations for LM predictions. However, pure attention-based explanations are unable to support the growing complexity of LMs, and cannot reason about their decision-making processes. We propose LMExplainer, a knowledge-enhanced explainer for LMs that can provide human-understandable explanations. We use a knowledge graph (KG) and a graph attention neural network to extract the key decision signals of the LM. We further explore whether interpretation can also help the AI understand the task better. Our experimental results show that LMExplainer outperforms existing LM+KG methods on CommonsenseQA and OpenBookQA. We compare the explanation results with generated explanation methods and human-annotated results. The comparison shows our method can provide more comprehensive and clearer explanations. LMExplainer demonstrates the potential to enhance model performance and furnish explanations for the LM reasoning process in natural language."}}
{"id": "MLkJ8beIlx", "cdate": 1640995200000, "mdate": 1680325336369, "content": {"title": "FedOBD: Opportunistic Block Dropout for Efficiently Training Large-scale Neural Networks through Federated Learning", "abstract": ""}}
{"id": "IqOr4WE7Le", "cdate": 1640995200000, "mdate": 1680325336369, "content": {"title": "FLAS: A Platform for Studying Attacks on Federated Learning", "abstract": ""}}
{"id": "hhFG0vcnt3", "cdate": 1577836800000, "mdate": 1680325336369, "content": {"title": "A Multi-player Game for Studying Federated Learning Incentive Schemes", "abstract": ""}}
{"id": "CWLrKpQ464", "cdate": 1577836800000, "mdate": 1680325336372, "content": {"title": "A Gamified Research Tool for Incentive Mechanism Design in Federated Learning", "abstract": ""}}
{"id": "0Jf0ahveo5q", "cdate": 1546300800000, "mdate": 1680325336369, "content": {"title": "End-to-end Deep Reinforcement Learning for Multi-agent Collaborative Exploration", "abstract": ""}}
