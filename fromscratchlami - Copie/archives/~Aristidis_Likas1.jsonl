{"id": "q1N_I6hs8h", "cdate": 1704067200000, "mdate": 1707760937931, "content": {"title": "Silhouette Aggregation: From Micro to Macro", "abstract": "Silhouette coefficient is an established internal clustering evaluation measure that produces a score per data point, assessing the quality of its clustering assignment. To assess the quality of the clustering of the whole dataset, the scores of all the points in the dataset are either (micro) averaged into a single value or averaged at the cluster level and then (macro) averaged. As we illustrate in this work, by using a synthetic example, the micro-averaging strategy is sensitive both to cluster imbalance and outliers (background noise) while macro-averaging is far more robust to both. Furthermore, the latter allows cluster-balanced sampling which yields robust computation of the silhouette score. By conducting an experimental study on eight real-world datasets, estimating the ground truth number of clusters, we show that both coefficients, micro and macro, should be considered."}}
{"id": "pRXeVyPrU5a", "cdate": 1704067200000, "mdate": 1707760937935, "content": {"title": "Deep Clustering Using the Soft Silhouette Score: Towards Compact and Well-Separated Clusters", "abstract": "Unsupervised learning has gained prominence in the big data era, offering a means to extract valuable insights from unlabeled datasets. Deep clustering has emerged as an important unsupervised category, aiming to exploit the non-linear mapping capabilities of neural networks in order to enhance clustering performance. The majority of deep clustering literature focuses on minimizing the inner-cluster variability in some embedded space while keeping the learned representation consistent with the original high-dimensional dataset. In this work, we propose soft silhoutte, a probabilistic formulation of the silhouette coefficient. Soft silhouette rewards compact and distinctly separated clustering solutions like the conventional silhouette coefficient. When optimized within a deep clustering framework, soft silhouette guides the learned representations towards forming compact and well-separated clusters. In addition, we introduce an autoencoder-based deep learning architecture that is suitable for optimizing the soft silhouette objective function. The proposed deep clustering method has been tested and compared with several well-studied deep clustering methods on various benchmark datasets, yielding very satisfactory clustering results."}}
{"id": "ehan1PheuVC", "cdate": 1696118400000, "mdate": 1707760937890, "content": {"title": "Neural clustering based on implicit maximum likelihood", "abstract": "Clustering is one of the most fundamental unsupervised learning tasks with numerous applications in various fields. Clustering methods based on neural networks, called deep clustering methods, leverage the representational power of neural networks to enhance clustering performance. ClusterGan constitutes a generative deep clustering method that exploits generative adversarial networks (GANs) to perform clustering. However, it inherits some deficiencies of GANs, such as mode collapse, vanishing gradients and training instability. In order to tackle those deficiencies, the generative approach of implicit maximum likelihood estimation (IMLE) has been recently proposed. In this paper, we present a clustering method based on generative neural networks, called neural implicit maximum likelihood clustering, which adopts ideas from both ClusterGAN and IMLE. The proposed method has been compared with ClusterGAN and other neural clustering methods on both synthetic and real datasets, demonstrating promising results."}}
{"id": "GE4SxIvCD7", "cdate": 1677628800000, "mdate": 1686901246711, "content": {"title": "Distance from Unimodality for the Assessment of Opinion Polarization", "abstract": "Commonsense knowledge is often approximated by the fraction of annotators who classified an item as belonging to the positive class. Instances for which this fraction is equal to or above 50% are considered positive, including however ones that receive polarized opinions. This is a problematic encoding convention that disregards the potentially polarized nature of opinions and which is often employed to estimate subjectivity, sentiment polarity, and toxic language. We present the distance from unimodality (DFU), a novel measure that estimates the extent of polarization on a distribution of opinions and which correlates well with human judgment. We applied DFU to two use cases. The first case concerns tweets created over 9 months during the pandemic. The second case concerns textual posts crowd-annotated for toxicity. We specified the days for which the sentiment-annotated tweets were determined as polarized based on the DFU measure and we found that polarization occurred on different days for two different states in the USA. Regarding toxicity, we found that polarized opinions are more likely by annotators originating from different countries. Moreover, we show that DFU can be exploited as an objective function to train models to predict whether a post will provoke polarized opinions in the future."}}
{"id": "kiThfK3C9tb", "cdate": 1672531200000, "mdate": 1707760937941, "content": {"title": "A convolutional neural network based system for detection of actinic keratosis in clinical images of cutaneous field cancerization", "abstract": ""}}
{"id": "SuAOc2GGuW", "cdate": 1672531200000, "mdate": 1707760937931, "content": {"title": "A Multivariate Unimodality Test Harnenssing the Dip Statistic of Mahalanobis Distances Over Random Projections", "abstract": "Unimodality, pivotal in statistical analysis, offers insights into dataset structures and drives sophisticated analytical procedures. While unimodality's confirmation is straightforward for one-dimensional data using methods like Silverman's approach and Hartigans' dip statistic, its generalization to higher dimensions remains challenging. By extrapolating one-dimensional unimodality principles to multi-dimensional spaces through linear random projections and leveraging point-to-point distancing, our method, rooted in $\\alpha$-unimodality assumptions, presents a novel multivariate unimodality test named mud-pod. Both theoretical and empirical studies confirm the efficacy of our method in unimodality assessment of multidimensional datasets as well as in estimating the number of clusters."}}
{"id": "98j_0TaI29i", "cdate": 1672531200000, "mdate": 1707760937888, "content": {"title": "Explaining the Chronological Attribution of Greek Papyri Images", "abstract": "Greek literary papyri, which are unique witnesses of antique literature, do not usually bear a date. They are thus currently dated based on palaeographical methods, with broad approximations which often span more than a century. We created a dataset of 242 images of papyri written in \u201cbookhand\u201d scripts whose date can be securely assigned, and we used it to train machine and deep learning algorithms for the task of dating, showing its challenging nature. To address the data scarcity problem, we extended our dataset by segmenting each image to the respective text lines. By using the line-based version of our dataset, we trained a Convolutional Neural Network, equipped with a fragmentation-based augmentation strategy, and we achieved a mean absolute error of 54 years. The results improve further when the task is cast as a multiclass classification problem, predicting the century. Using our network, we computed and provided precise date estimations for papyri whose date is disputed or vaguely defined and we undertake an explainability-based analysis to facilitate future attribution."}}
{"id": "8AkYqvYvWkG", "cdate": 1672531200000, "mdate": 1707760937896, "content": {"title": "UniForCE: The Unimodality Forest Method for Clustering and Estimation of the Number of Clusters", "abstract": "Estimating the number of clusters k while clustering the data is a challenging task. An incorrect cluster assumption indicates that the number of clusters k gets wrongly estimated. Consequently, the model fitting becomes less important. In this work, we focus on the concept of unimodality and propose a flexible cluster definition called locally unimodal cluster. A locally unimodal cluster extends for as long as unimodality is locally preserved across pairs of subclusters of the data. Then, we propose the UniForCE method for locally unimodal clustering. The method starts with an initial overclustering of the data and relies on the unimodality graph that connects subclusters forming unimodal pairs. Such pairs are identified using an appropriate statistical test. UniForCE identifies maximal locally unimodal clusters by computing a spanning forest in the unimodality graph. Experimental results on both real and synthetic datasets illustrate that the proposed methodology is particularly flexible and robust in discovering regular and highly complex cluster shapes. Most importantly, it automatically provides an adequate estimation of the number of clusters."}}
{"id": "zGuD2hVMcD", "cdate": 1640995200000, "mdate": 1707760938007, "content": {"title": "Scanning X-ray Fluorescence Data Analysis for the Identification of Byzantine Icons' Materials, Techniques, and State of Preservation: A Case Study", "abstract": "X-ray fluorescence (XRF) spectrometry has proven to be a core, non-destructive, analytical technique in cultural heritage studies mainly because of its non-invasive character and ability to rapidly reveal the elemental composition of the analyzed artifacts. Being able to penetrate deeper into matter than the visible light, X-rays allow further analysis that may eventually lead to the extraction of information that pertains to the substrate(s) of an artifact. The recently developed scanning macroscopic X-ray fluorescence method (MA-XRF) allows for the extraction of elemental distribution images. The present work aimed at comparing two different analysis methods for interpreting the large number of XRF spectra collected in the framework of MA-XRF analysis. The measured spectra were analyzed in two ways: a merely spectroscopic approach and an exploratory data analysis approach. The potentialities of the applied methods are showcased on a notable 18th-century Greek religious panel painting. The spectroscopic approach separately analyses each one of the measured spectra and leads to the construction of single-element spatial distribution images (element maps). The statistical data analysis approach leads to the grouping of all spectra into distinct clusters with common features, while afterward dimensionality reduction algorithms help reduce thousands of channels of XRF spectra in an easily perceived dataset of two-dimensional images. The two analytical approaches allow extracting detailed information about the pigments used and paint layer stratigraphy (i.e., painting technique) as well as restoration interventions/state of preservation."}}
{"id": "pRW69ahV8D5", "cdate": 1640995200000, "mdate": 1707760937972, "content": {"title": "The UU-test for statistical modeling of unimodal data", "abstract": ""}}
