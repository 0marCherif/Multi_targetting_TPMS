{"id": "rHNF8Kq3u2P", "cdate": 1621630228560, "mdate": null, "content": {"title": "Neural Routing by Memory", "abstract": "Recent Convolutional Neural Networks (CNNs) have achieved significant success by stacking multiple convolutional blocks, named procedures in this paper, to extract semantic features. However, they use the same procedure sequence for all inputs, regardless of the intermediate features.\nThis paper proffers a simple yet effective idea of constructing parallel procedures and assigning similar intermediate features to the same specialized procedures in a divide-and-conquer fashion. It relieves each procedure's learning difficulty and thus leads to superior performance. \nSpecifically, we propose a routing-by-memory mechanism for existing CNN architectures. In each stage of the network, we introduce parallel Procedural Units (PUs). A PU consists of a memory head and a procedure. The memory head maintains a summary of a type of features. For an intermediate feature, we search its closest memory and forward it to the corresponding procedure in both training and testing. In this way, different procedures are tailored to different features and therefore tackle them better.\nNetworks with the proposed mechanism can be trained efficiently using a four-step training strategy. Experimental results show that our method improves VGGNet, ResNet, and EfficientNet's accuracies on Tiny ImageNet, ImageNet, and CIFAR-100 benchmarks with a negligible extra computational cost."}}
{"id": "gbEreV4H2Jv", "cdate": 1621630228560, "mdate": null, "content": {"title": "Neural Routing by Memory", "abstract": "Recent Convolutional Neural Networks (CNNs) have achieved significant success by stacking multiple convolutional blocks, named procedures in this paper, to extract semantic features. However, they use the same procedure sequence for all inputs, regardless of the intermediate features.\nThis paper proffers a simple yet effective idea of constructing parallel procedures and assigning similar intermediate features to the same specialized procedures in a divide-and-conquer fashion. It relieves each procedure's learning difficulty and thus leads to superior performance. \nSpecifically, we propose a routing-by-memory mechanism for existing CNN architectures. In each stage of the network, we introduce parallel Procedural Units (PUs). A PU consists of a memory head and a procedure. The memory head maintains a summary of a type of features. For an intermediate feature, we search its closest memory and forward it to the corresponding procedure in both training and testing. In this way, different procedures are tailored to different features and therefore tackle them better.\nNetworks with the proposed mechanism can be trained efficiently using a four-step training strategy. Experimental results show that our method improves VGGNet, ResNet, and EfficientNet's accuracies on Tiny ImageNet, ImageNet, and CIFAR-100 benchmarks with a negligible extra computational cost."}}
{"id": "SolgZb1Dg_pr", "cdate": 1546300800000, "mdate": null, "content": {"title": "A Comprehensive Study on Center Loss for Deep Face Recognition.", "abstract": "Deep convolutional neural networks (CNNs) trained with the softmax loss have achieved remarkable successes in a number of close-set recognition problems, e.g. object recognition, action recognition, etc. Unlike these close-set tasks, face recognition is an open-set problem where the testing classes (persons) are usually different from those in training. This paper addresses the open-set property of face recognition by developing the center loss. Specifically, the center loss simultaneously learns a center for each class, and penalizes the distances between the deep features of the face images and their corresponding class centers. Training with the center loss enables CNNs to extract the deep features with two desirable properties: inter-class separability and intra-class compactness. In addition, we extend the center loss in two aspects. First, we adopt parameter sharing between the softmax loss and the center loss, to reduce the extra parameters introduced by centers. Second, we generalize the concept of center from a single point to a region in embedding space, which further allows us to account for intra-class variations. The advanced center loss significantly enhances the discriminative power of deep features. Experimental results show that our method achieves high accuracies on several important face recognition benchmarks, including Labeled Faces in the Wild, YouTube Faces, IJB-A Janus, and MegaFace Challenging 1."}}
{"id": "rkZWmlM_ZB", "cdate": 1514764800000, "mdate": null, "content": {"title": "Deep Disguised Faces Recognition", "abstract": "Recently, deep learning based approaches have yielded a significant improvement in face recognition in the wild. However, \"disguised face\" recognition is still a challenging task that needs to be investigated, and the Disguised Faces in the Wild (DFW) competition is designed for this task. In this paper, we propose a two-stage training approach to utilize the small-scale training data provided by the DFW competition. Specifically, in the first stage, we train Deep Convolutional Neural Networks (DCNNs) for generic face recognition. In the second stage, we use Principal Components Analysis (PCA) based on the DFW training set to find the best transformation matrix for identity representation of disguised faces. We evaluate our model on the DFW testing dataset and it shows better performance over the state-of-the-art generic face recognition methods. It also achieves the best results on the DFW competition - Phase 1."}}
{"id": "rJbgn0W_br", "cdate": 1514764800000, "mdate": null, "content": {"title": "Attribute Augmented Convolutional Neural Network for Face Hallucination", "abstract": "Though existing face hallucination methods achieve great performance on the global region evaluation, most of them cannot recover local attributes accurately, especially when super-resolving a very low-resolution face image from 14X12 pixels to its 8X larger one. In this paper, we propose a brand new Attribute Augmented Convolutional Neural Network (AACNN) to assist face hallucination by exploiting facial attributes. The goal is to augment face hallucination, particularly the local regions, with informative attribute description. More specifically, our method fuses the advantages of both image domain and attribute domain, which significantly assists facial attributes recovery. Extensive experiments demonstrate that our proposed method achieves superior visual quality of hallucination on both local region and global region against the state-of-the-art methods. In addition, our AACNN still improves the performance of hallucination adaptively with partial attribute input."}}
{"id": "r1ZqJc-u-H", "cdate": 1514764800000, "mdate": null, "content": {"title": "Super-Identity Convolutional Neural Network for Face Hallucination", "abstract": "Face hallucination is a generative task to super-resolve the facial image with low resolution while human perception of face heavily relies on identity information. However, previous face hallucination approaches largely ignore facial identity recovery. This paper proposes Super-Identity Convolutional Neural Network (SICNN) to recover identity information for generating faces closed to the real identity. Specifically, we define a super-identity loss to measure the identity difference between a hallucinated face and its corresponding high-resolution face within the hypersphere identity metric space. However, directly using this loss will lead to a Dynamic Domain Divergence problem, which is caused by the large margin between the high-resolution domain and the hallucination domain. To overcome this challenge, we present a domain-integrated training approach by constructing a robust identity metric for faces from these two domains. Extensive experimental evaluations demonstrate that the proposed SICNN achieves superior visual quality over the state-of-the-art methods on a challenging task to super-resolve 12\u00a0 $$\\times $$ \u00a014 faces with an 8 $$\\times $$ upscaling factor. In addition, SICNN significantly improves the recognizability of ultra-low-resolution faces."}}
{"id": "SJ-F6xf_bB", "cdate": 1483228800000, "mdate": null, "content": {"title": "Detecting Faces Using Inside Cascaded Contextual CNN", "abstract": "Deep Convolutional Neural Networks (CNNs) achieve substantial improvements in face detection in the wild. Classical CNN-based face detection methods simply stack successive layers of filters where an input sample should pass through all layers before reaching a face/non-face decision. Inspired by the fact that for face detection, filters in deeper layers can discriminate between difficult face/non-face samples while those in shallower layers can efficiently reject simple non-face samples, we propose Inside Cascaded Structure that introduces face/non-face classifiers at different layers within the same CNN. In the training phase, we propose data routing mechanism which enables different layers to be trained by different types of samples, and thus deeper layers can focus on handling more difficult samples compared with traditional architecture. In addition, we introduce a two-stream contextual CNN architecture that leverages body part information adaptively to enhance face detection. Extensive experiments on the challenging FD-DB and WIDER FACE benchmarks demonstrate that our method achieves competitive accuracy to the state-of-the-art techniques while keeps real time performance."}}
{"id": "rk-3StWOWr", "cdate": 1451606400000, "mdate": null, "content": {"title": "A Discriminative Feature Learning Approach for Deep Face Recognition", "abstract": "Convolutional neural networks (CNNs) have been widely used in computer vision community, significantly improving the state-of-the-art. In most of the available CNNs, the softmax loss function is used as the supervision signal to train the deep model. In order to enhance the discriminative power of the deeply learned features, this paper proposes a new supervision signal, called center loss, for face recognition task. Specifically, the center loss simultaneously learns a center for deep features of each class and penalizes the distances between the deep features and their corresponding class centers. More importantly, we prove that the proposed center loss function is trainable and easy to optimize in the CNNs. With the joint supervision of softmax loss and center loss, we can train a robust CNNs to obtain the deep features with the two key learning objectives, inter-class dispension and intra-class compactness as much as possible, which are very essential to face recognition. It is encouraging to see that our CNNs (with such joint supervision) achieve the state-of-the-art accuracy on several important face recognition benchmarks, Labeled Faces in the Wild (LFW), YouTube Faces (YTF), and MegaFace Challenge. Especially, our new approach achieves the best results on MegaFace (the largest public domain face benchmark) under the protocol of small training set (contains under 500000 images and under 20000 persons), significantly improving the previous results and setting new state-of-the-art for both face recognition and face verification tasks."}}
{"id": "SJWWmeGOZS", "cdate": 1451606400000, "mdate": null, "content": {"title": "Gender and Smile Classification Using Deep Convolutional Neural Networks", "abstract": "Facial gender and smile classification in unconstrained environment is challenging due to the invertible and large variations of face images. In this paper, we propose a deep model composed of GNet and SNet for these two tasks. We leverage the multi-task learning and the general-to-specific fine-tuning scheme to enhance the performance of our model. Our strategies exploit the inherent correlation between face identity, smile, gender and other face attributes to relieve the problem of over-fitting on small training set and improve the classification performance. We also propose the tasks-aware face cropping scheme to extract attribute-specific regions. The experimental results on the ChaLearn 16 FotW dataset for gender and smile classification demonstrate the effectiveness of our proposed methods."}}
