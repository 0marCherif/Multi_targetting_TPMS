{"id": "75BYT32h3xs", "cdate": 1696617673127, "mdate": 1696617673127, "content": {"title": "No-Regret Online Prediction with Strategic Experts", "abstract": "We study a generalization of the online binary prediction with expert advice framework where at each round, the learner is allowed to pick $m\\geq 1$ experts from a pool of $K$ experts and the overall utility is a modular or submodular function of the chosen experts. We focus on the setting in which experts act strategically and aim to maximize their influence on the algorithm's predictions by potentially misreporting their beliefs about the events. Among others, this setting finds applications in forecasting competitions where the learner seeks not only to make predictions by aggregating different forecasters but also to rank them according to their relative performance. Our goal is to design algorithms that satisfy the following two requirements: 1) \\emph{Incentive-compatible}: Incentivize the experts to report their beliefs truthfully, and 2) \\emph{No-regret}: Achieve sublinear regret with respect to the true beliefs of the best fixed set of $m$ experts in hindsight. Prior works have studied this framework when $m=1$ and provided incentive-compatible no-regret algorithms for the problem. We first show that a simple reduction of our problem to the $m=1$ setting is neither efficient nor effective. \\textcolor{magenta}{did prior work consider the submodular case? if not be sure to name it here as our novelty.} Then, we provide algorithms that utilize the specific structure of the utility functions to achieve the two desired goals."}}
{"id": "g37shYx2fzB", "cdate": 1640995200000, "mdate": 1683769640342, "content": {"title": "Interactive Combinatorial Bandits: Balancing Competitivity and Complementarity", "abstract": "We investigate non-modular function maximization in an online setting with $m$ users. The optimizer maintains a set $S_q$ for each user $q \\in \\{1, \\ldots, m\\}$. At round $i$, a user with unknown utility $h_q$ arrives; the optimizer selects a new item to add to $S_q$, and receives a noisy marginal gain. The goal is to minimize regret compared to an $\\alpha$-approximation to the optimal full-knowledge selection (i.e., $\\alpha$-regret). Prior works study this problem under a submodularity assumption for all $h_q$. However, this is not ideally amenable to applications, e.g., movie recommendations, that involve complementarity between items, where e.g., watching the first movie in a series enhances the impression of watching the sequels. Hence, we consider objectives $h_q$, called \\textit{BP functions}, that decompose into the sum of monotone submodular $f_q$ and supermodular $g_q$; here, $g_q$ naturally models complementarity. Under different feedback assumptions, we develop UCB-style algorithms that use Nystrom sampling for computational efficiency. For these, we provide sublinear $\\alpha$-regret guarantees for $\\alpha = 1/\\kappa_{f} [1 - e^{-(1 - \\kappa^g) \\kappa_{f}} ]$, and $\\alpha = \\min\\{1 - \\kappa_f/e, 1 - \\kappa^g\\}$; here, $\\kappa_f, \\kappa^g$ are submodular and supermodular curvatures. Furthermore, we provide similar $\\alpha$-regret guarantees for functions that are almost submodular where $\\alpha$ is parameterized by the submodularity ratio of the objective functions. We numerically validate our algorithms for movie recommendation on the MovieLens dataset and selection of training subsets for classification tasks."}}
{"id": "qtAZBZLUYg", "cdate": 1609459200000, "mdate": 1684185025121, "content": {"title": "Improved Regret Bounds for Online Submodular Maximization", "abstract": "In this paper, we consider an online optimization problem over $T$ rounds where at each step $t\\in[T]$, the algorithm chooses an action $x_t$ from the fixed convex and compact domain set $\\mathcal{K}$. A utility function $f_t(\\cdot)$ is then revealed and the algorithm receives the payoff $f_t(x_t)$. This problem has been previously studied under the assumption that the utilities are adversarially chosen monotone DR-submodular functions and $\\mathcal{O}(\\sqrt{T})$ regret bounds have been derived. We first characterize the class of strongly DR-submodular functions and then, we derive regret bounds for the following new online settings: $(1)$ $\\{f_t\\}_{t=1}^T$ are monotone strongly DR-submodular and chosen adversarially, $(2)$ $\\{f_t\\}_{t=1}^T$ are monotone submodular (while the average $\\frac{1}{T}\\sum_{t=1}^T f_t$ is strongly DR-submodular) and chosen by an adversary but they arrive in a uniformly random order, $(3)$ $\\{f_t\\}_{t=1}^T$ are drawn i.i.d. from some unknown distribution $f_t\\sim \\mathcal{D}$ where the expected function $f(\\cdot)=\\mathbb{E}_{f_t\\sim\\mathcal{D}}[f_t(\\cdot)]$ is monotone DR-submodular. For $(1)$, we obtain the first logarithmic regret bounds. In terms of the second framework, we show that it is possible to obtain similar logarithmic bounds with high probability. Finally, for the i.i.d. model, we provide algorithms with $\\tilde{\\mathcal{O}}(\\sqrt{T})$ stochastic regret bound, both in expectation and with high probability. Experimental results demonstrate that our algorithms outperform the previous techniques in the aforementioned three settings."}}
{"id": "iTn75DeSMlK", "cdate": 1609459200000, "mdate": 1684185024720, "content": {"title": "Differentially Private Monotone Submodular Maximization Under Matroid and Knapsack Constraints", "abstract": "Numerous tasks in machine learning and artificial intelligence have been modeled as submodular maximization problems. These problems usually involve sensitive data about individuals, and in addition to maximizing the utility, privacy concerns should be considered. In this paper, we study the general framework of non-negative monotone submodular maximization subject to matroid or knapsack constraints in both offline and online settings. For the offline setting, we propose a differentially private $(1-\\frac{\\kappa}{e})$-approximation algorithm, where $\\kappa\\in[0,1]$ is the total curvature of the submodular set function, which improves upon prior works in terms of approximation guarantee and query complexity under the same privacy budget. In the online setting, we propose the first differentially private algorithm, and we specify the conditions under which the regret bound scales as $\u00d8(\\sqrt{T})$, i.e., privacy could be ensured while maintaining the same regret bound as the optimal regret guarantee in the non-private setting."}}
{"id": "a-cACtd79tA", "cdate": 1609459200000, "mdate": 1684185024882, "content": {"title": "Online DR-Submodular Maximization: Minimizing Regret and Constraint Violation", "abstract": "In this paper, we consider online continuous DR-submodular maximization with linear stochastic long-term constraints. Compared to the prior work on online submodular maximization, our setting introduces the extra complication of stochastic linear constraint functions that are i.i.d. generated at each round. In particular, at each time step a DR-submodular utility function and a constraint vector, i.i.d. generated from an unknown distribution, are revealed after committing to an action and we aim to maximize the overall utility while the expected cumulative resource consumption is below a fixed budget. Stochastic long-term constraints arise naturally in applications where there is a limited budget or resource available and resource consumption at each step is governed by stochastically time-varying environments. We propose the Online Lagrangian Frank-Wolfe (OLFW) algorithm to solve this class of online problems. We analyze the performance of the OLFW algorithm and we obtain sub-linear regret bounds as well as sub-linear cumulative constraint violation bounds, both in expectation and with high probability."}}
{"id": "K3La6HD2XKE", "cdate": 1609459200000, "mdate": 1684185024920, "content": {"title": "Faster First-Order Algorithms for Monotone Strongly DR-Submodular Maximization", "abstract": "Continuous DR-submodular functions are a class of functions that satisfy the Diminishing Returns (DR) property, which implies that they are concave along non-negative directions. Existing works have studied monotone continuous DR-submodular maximization subject to a convex constraint and have proposed efficient algorithms with approximation guarantees. However, in many applications, e.g., computing the stability number of a graph and mean-field inference for probabilistic log-submodular models, the DR-submodular function has the additional property of being \\emph{strongly} concave along non-negative directions that could be utilized for obtaining faster convergence rates. In this paper, we first introduce and characterize the class of \\emph{strongly DR-submodular} functions and show how such a property implies strong concavity along non-negative directions. Then, we study $L$-smooth monotone strongly DR-submodular functions that have bounded curvature, and we show how to exploit such additional structure to obtain algorithms with improved approximation guarantees and faster convergence rates for the maximization problem. In particular, we propose the SDRFW algorithm that matches the provably optimal $1-\\frac{c}{e}$ approximation ratio after only $\\lceil\\frac{L}{\\mu}\\rceil$ iterations, where $c\\in[0,1]$ and $\\mu\\geq 0$ are the curvature and the strong DR-submodularity parameter. Furthermore, we study the Projected Gradient Ascent (PGA) method for this problem and provide a refined analysis of the algorithm with an improved $\\frac{1}{1+c}$ approximation ratio and a linear convergence rate. Given that both algorithms require knowledge of the smoothness parameter $L$, we provide a \\emph{novel} characterization of $L$ for DR-submodular functions showing that in many cases, computing $L$ could be formulated as a convex problem, i.e., a geometric program, that could be solved efficiently."}}
{"id": "sI1gXm87j7", "cdate": 1577836800000, "mdate": 1684185024841, "content": {"title": "A Single Recipe for Online Submodular Maximization with Adversarial or Stochastic Constraints", "abstract": "In this paper, we consider an online optimization problem in which the reward functions are DR-submodular, and in addition to maximizing the total reward, the sequence of decisions must satisfy some convex constraints on average. Specifically, at each round $t\\in\\{1,\\dots,T\\}$, upon committing to an action $x_t$, a DR-submodular utility function $f_t(\\cdot)$ and a convex constraint function $g_t(\\cdot)$ are revealed, and the goal is to maximize the overall utility while ensuring the average of the constraint functions $\\frac{1}{T}\\sum_{t=1}^T g_t(x_t)$ is non-positive. Such cumulative constraints arise naturally in applications where the average resource consumption is required to remain below a prespecified threshold. We study this problem under an adversarial model and a stochastic model for the convex constraints, where the functions $g_t$ can vary arbitrarily or according to an i.i.d. process over time slots $t\\in\\{1,\\dots,T\\}$, respectively. We propose a single algorithm which achieves sub-linear (with respect to $T$) regret as well as sub-linear constraint violation bounds in both settings, without prior knowledge of the regime. Prior works have studied this problem in the special case of linear constraint functions. Our results not only improve upon the existing bounds under linear cumulative constraints, but also give the first sub-linear bounds for general convex long-term constraints."}}
{"id": "qwxesyuO9zX", "cdate": 1577836800000, "mdate": 1684185024927, "content": {"title": "Online DR-Submodular Maximization with Stochastic Cumulative Constraints", "abstract": "In this paper, we consider online continuous DR-submodular maximization with linear stochastic long-term constraints. Compared to the prior work on online submodular maximization, our setting introduces the extra complication of stochastic linear constraint functions that are i.i.d. generated at each round. To be precise, at step $t\\in\\{1,\\dots,T\\}$, a DR-submodular utility function $f_t(\\cdot)$ and a constraint vector $p_t$, i.i.d. generated from an unknown distribution with mean $p$, are revealed after committing to an action $x_t$ and we aim to maximize the overall utility while the expected cumulative resource consumption $\\sum_{t=1}^T \\langle p,x_t\\rangle$ is below a fixed budget $B_T$. Stochastic long-term constraints arise naturally in applications where there is a limited budget or resource available and resource consumption at each step is governed by stochastically time-varying environments. We propose the Online Lagrangian Frank-Wolfe (OLFW) algorithm to solve this class of online problems. We analyze the performance of the OLFW algorithm and we obtain sub-linear regret bounds as well as sub-linear cumulative constraint violation bounds, both in expectation and with high probability."}}
{"id": "GBUanNj7qcc", "cdate": 1577836800000, "mdate": 1683897366006, "content": {"title": "Function Design for Improved Competitive Ratio in Online Resource Allocation with Procurement Costs", "abstract": "We study the problem of online resource allocation, where multiple customers arrive sequentially and the seller must irrevocably allocate resources to each incoming customer while also facing a procurement cost for the total allocation. Assuming resource procurement follows an a priori known marginally increasing cost function, the objective is to maximize the reward obtained from fulfilling the customers' requests sans the cumulative procurement cost. We analyze the competitive ratio of a primal-dual algorithm in this setting, and develop an optimization framework for synthesizing a surrogate function for the procurement cost function to be used by the algorithm, in order to improve the competitive ratio of the primal-dual algorithm. Our first design method focuses on polynomial procurement cost functions and uses the optimal surrogate function to provide a more refined bound than the state of the art. Our second design method uses quasiconvex optimization to find optimal design parameters for a general class of procurement cost functions. Numerical examples are used to illustrate the design techniques. We conclude by extending the analysis to devise a posted pricing mechanism in which the algorithm does not require the customers' preferences to be revealed."}}
{"id": "9QA7Loqi2Um", "cdate": 1577836800000, "mdate": 1684185024760, "content": {"title": "Online Continuous DR-Submodular Maximization with Long-Term Budget Constraints", "abstract": "In this paper, we study a class of online optimization problems with long-term budget constraints where the objective functions are not necessarily concave (nor convex), but they instead satisfy th..."}}
