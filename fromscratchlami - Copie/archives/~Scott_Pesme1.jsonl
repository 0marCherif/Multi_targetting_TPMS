{"id": "vvi7KqHQiA", "cdate": 1621630009896, "mdate": null, "content": {"title": "Implicit Bias of SGD for Diagonal Linear Networks: a Provable Benefit of Stochasticity", "abstract": "Understanding the implicit bias of training algorithms is of crucial importance in order to explain the success of overparametrised neural networks. In this paper, we study the dynamics of stochastic gradient descent over diagonal linear networks through its continuous time version, namely stochastic gradient flow. We explicitly characterise the solution chosen by the stochastic flow and prove that it always enjoys better generalisation properties than that of gradient flow.Quite surprisingly, we show that the convergence speed of the training loss controls the magnitude of the biasing effect: the slower the convergence, the better the bias. To fully complete our analysis, we provide convergence guarantees for the dynamics. We also give experimental results which support our theoretical claims. Our findings highlight the fact that structured noise can induce better generalisation and they help explain the greater performances of stochastic gradient  descent over gradient descent observed in practice.\n\n\n"}}
{"id": "OGDgcaw7kR", "cdate": 1609459200000, "mdate": 1650361088360, "content": {"title": "Implicit Bias of SGD for Diagonal Linear Networks: a Provable Benefit of Stochasticity", "abstract": "Understanding the implicit bias of training algorithms is of crucial importance in order to explain the success of overparametrised neural networks. In this paper, we study the dynamics of stochastic gradient descent over diagonal linear networks through its continuous time version, namely stochastic gradient flow. We explicitly characterise the solution chosen by the stochastic flow and prove that it always enjoys better generalisation properties than that of gradient flow. Quite surprisingly, we show that the convergence speed of the training loss controls the magnitude of the biasing effect: the slower the convergence, the better the bias. To fully complete our analysis, we provide convergence guarantees for the dynamics. We also give experimental results which support our theoretical claims. Our findings highlight the fact that structured noise can induce better generalisation and they help explain the greater performances observed in practice of stochastic gradient descent over gradient descent."}}
{"id": "yBJL-359UYM", "cdate": 1577836800000, "mdate": 1650361088356, "content": {"title": "On Convergence-Diagnostic based Step Sizes for Stochastic Gradient Descent", "abstract": "Constant step-size Stochastic Gradient Descent exhibits two phases: a transient phase during which iterates make fast progress towards the optimum, followed by a stationary phase during which itera..."}}
{"id": "Ld9L6URM5Xt", "cdate": 1577836800000, "mdate": 1650361088361, "content": {"title": "Online Robust Regression via SGD on the l1 loss", "abstract": "We consider the robust linear regression problem in the online setting where we have access to the data in a streaming manner, one data point after the other. More specifically, for a true parameter $ \\theta^* $, we consider the corrupted Gaussian linear model $y = + \\varepsilon + b$ where the adversarial noise $b$ can take any value with probability $\\eta$ and equals zero otherwise. We consider this adversary to be oblivious (i.e., $b$ independent of the data) since this is the only contamination model under which consistency is possible. Current algorithms rely on having the whole data at hand in order to identify and remove the outliers. In contrast, we show in this work that stochastic gradient descent on the l1 loss converges to the true parameter vector at a $\\tilde{O}( 1 / (1 - \\eta)^2 n )$ rate which is independent of the values of the contaminated measurements. Our proof relies on the elegant smoothing of the l1 loss by the Gaussian data and a classical non-asymptotic analysis of Polyak-Ruppert averaged SGD. In addition, we provide experimental evidence of the efficiency of this simple and highly scalable algorithm."}}
