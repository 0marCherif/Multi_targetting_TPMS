{"id": "q-EOp3o8Hi", "cdate": 1699604185576, "mdate": 1699604185576, "content": {"title": "RecolorNeRF: Layer Decomposed Radiance Fields for Efficient Color Editing of 3D Scenes", "abstract": "Radiance fields have gradually become a main representation of media. Although its appearance editing has been studied, how to achieve view-consistent recoloring in an efficient manner is still under explored. We present RecolorNeRF, a novel user-friendly color editing approach for the neural radiance fields. Our key idea is to decompose the scene into a set of pure-colored layers, forming a palette. By this means, color manipulation can be conducted by altering the color components of the palette directly. To support efficient palette-based editing, the color of each layer needs to be as representative as possible. In the end, the problem is formulated as an optimization problem, where the layers and their blending weights are jointly optimized with the NeRF itself. Extensive experiments show that our jointly-optimized layer decomposition can be used against multiple backbones and produce photo-realistic recolored novel-view renderings. We demonstrate that RecolorNeRF outperforms baseline methods both quantitatively and qualitatively for color editing even in complex real-world scenes."}}
{"id": "Oaf30RP-bBi", "cdate": 1668768506968, "mdate": 1668768506968, "content": {"title": "Transformer-empowered Multi-scale Contextual Matching and Aggregation for Multi-contrast MRI Super-resolution", "abstract": "Magnetic resonance imaging (MRI) can present multi- contrast images of the same anatomical structures, enabling multi-contrast super-resolution (SR) techniques. Compared with SR reconstruction using a single-contrast, multi- contrast SR reconstruction is promising to yield SR images with higher quality by leveraging diverse yet complementary information embedded in different imaging modalities. However, existing methods still have two shortcomings: (1) they neglect that the multi-contrast features at different scales contain different anatomical details and hence lack effective mechanisms to match and fuse these features for better reconstruction; and (2) they are still deficient in capturing long-range dependencies, which are essential for the regions with complicated anatomical structures. We propose a novel network to comprehensively address these problems by developing a set of innovative Transformer- empowered multi-scale contextual matching and aggregation techniques; we call it McMRSR. Firstly, we tame trans- formers to model long-range dependencies in both reference and target images. Then, a new multi-scale contextual matching method is proposed to capture corresponding contexts from reference features at different scales. Further- more, we introduce a multi-scale aggregation mechanism to gradually and interactively aggregate multi-scale matched features for reconstructing the target SR MR image. Extensive experiments demonstrate that our network outperforms state-of-the-art approaches and has great potential to be applied in clinical practice."}}
{"id": "sybuBdQNsn8", "cdate": 1651837547101, "mdate": null, "content": {"title": "A multi-stage framework for cerebral microbleeds detection and segmentation", "abstract": "Description of the method of the Zihao team for solving task 2 - Microbleeds as part of the Where is Valdo challenge"}}
{"id": "WHA8009laxu", "cdate": 1632875542135, "mdate": null, "content": {"title": "Federated Learning from Only Unlabeled Data with Class-conditional-sharing Clients", "abstract": "Supervised federated learning (FL) enables multiple clients to share the trained model without sharing their labeled data. However, potential clients might even be reluctant to label their own data, which could limit the applicability of FL in practice. In this paper, we show the possibility of unsupervised FL whose model is still a classifier for predicting class labels, if the class-prior probabilities are shifted while the class-conditional distributions are shared among the unlabeled data owned by the clients. We propose federation of unsupervised learning (FedUL), where the unlabeled data are transformed into surrogate labeled data for each of the clients, a modified model is trained by supervised FL, and the wanted model is recovered from the modified model. FedUL is a very general solution to unsupervised FL: it is compatible with many supervised FL methods, and the recovery of the wanted model can be theoretically guaranteed as if the data have been labeled. Experiments on benchmark and real-world datasets demonstrate the effectiveness of FedUL. Code is available at https://github.com/lunanbit/FedUL."}}
{"id": "nZon4NT0WSw", "cdate": 1632875489529, "mdate": null, "content": {"title": "TsmoBN: Interventional Generalization for Unseen Clients in Federated Learning", "abstract": "Generalizing federated learning (FL) models to unseen clients with non-iid data is a crucial topic, yet unsolved so far. In this work, we propose to tackle this problem from a novel causal perspective. Specifically, we form a training structural causal model (SCM) to explain the challenges of model generalization in a distributed learning paradigm. Based on this, we present a simple yet effective method using test-specific and momentum tracked batch normalization (TsmoBN) to generalize FL models to testing clients. We give a causal analysis by formulating another testing SCM and demonstrate that the key factor in TsmoBN is the test-specific statistics (i.e., mean and variance) of features. Such statistics can be seen as a surrogate variable for causal intervention. In addition, by considering generalization bounds in FL, we show that our TsmoBN method can reduce divergence between training and testing feature distributions, which achieves a lower generalization gap than standard model testing. Our extensive experimental evaluations demonstrate significant improvements for unseen client generalization on three datasets with various types of distribution shifts and numbers of clients. It is worth noting that our proposed approach can be flexibly applied to different state-of-the-art federated learning algorithms and is orthogonal to existing domain generalization methods. "}}
{"id": "K4EpsbbO4_e", "cdate": 1612927216291, "mdate": null, "content": {"title": "Robust learning at noisy labeled medical images: applied to skin lesion classification", "abstract": "Deep neural networks (DNNs) have achieved great success in a wide variety of medical image analysis tasks. However, these achievements indispensably rely on the accurately-annotated datasets. If with the noisy-labeled images, the training procedure will immediately encounter difficulties, leading to a suboptimal classifier. This problem is even more crucial in the medical field, given that the annotation quality requires great expertise. In this paper, we propose an effective iterative learning framework for noisy-labeled medical image classification, to combat the lacking of high quality annotated medical data. Specifically, an online uncertainty sample mining method is proposed to eliminate the disturbance from noisy-labeled images. Next, we design a sample re-weighting strategy to preserve the usefulness of correctly-labeled hard samples. Our proposed method is validated on skin lesion classification task, and achieved very promising results."}}
{"id": "Y34M1qGt5l", "cdate": 1612927059354, "mdate": null, "content": {"title": "An Active Learning Approach for Reducing Annotation Cost in Skin Lesion Analysis", "abstract": "Automated skin lesion analysis is very crucial in clinical practice, as skin cancer is among the most common human malignancy. Existing approaches with deep learning have achieved remarkable performance on this challenging task, however, heavily relying on large-scale labelled datasets. In this paper, we present a novel active learning framework for cost-effective skin lesion analysis. The goal is to effectively select and utilize much fewer labelled samples, while the network can still achieve state-of-the-art performance. Our sample selection criteria complementarily consider both informativeness and representativeness, derived from decoupled aspects of measuring model certainty and covering sample diversity. To make wise use of the selected samples, we further design a simple yet effective strategy to aggregate intra-class images in pixel space, as a new form of data augmentation. We validate our proposed method on data of ISIC 2017 Skin Lesion Classification Challenge for two tasks. Using only up to 50% of samples, our approach can achieve state-of-the-art performances on both tasks, which are comparable or exceeding the accuracies with full-data training, and outperform other well-known active learning methods by a large margin."}}
{"id": "QmIYLhYORf5", "cdate": 1612926562282, "mdate": null, "content": {"title": "LRTD: Long-Range Temporal Dependency based Active Learning for Surgical Workflow Recognition", "abstract": "Abstract\nPurpose Automatic surgical workflow recognition in video is an essentially fundamental yet challenging problem for developing\ncomputer-assisted and robotic-assisted surgery. Existing approaches with deep learning have achieved remarkable\nperformance on analysis of surgical videos, however, heavily relying on large-scale labelled datasets. Unfortunately, the\nannotation is not often available in abundance, because it requires the domain knowledge of surgeons. Even for experts, it is\nvery tedious and time-consuming to do a sufficient amount of annotations.\nMethods In this paper, we propose a novel active learning method for cost-effective surgical video analysis. Specifically, we\npropose a non-local recurrent convolutional network, which introduces non-local block to capture the long-range temporal\ndependency (LRTD) among continuous frames. We then formulate an intra-clip dependency score to represent the overall\ndependencywithin this clip. By ranking scores among clips in unlabelled data pool, we select the clip with weak dependencies\nto annotate, which indicates the most informative ones to better benefit network training.\nResults We validate our approach on a large surgical video dataset (Cholec80) by performing surgical workflow recognition\ntask. By using our LRTD based selection strategy, we can outperform other state-of-the-art active learning methods who only\nconsider neighbor-frame information. Using only up to 50% of samples, our approach can exceed the performance of full-data\ntraining.\nConclusion By modeling the intra-clip dependency, our LRTD based strategy shows stronger capability to select informative\nvideo clips for annotation compared with other active learning methods, through the evaluation on a popular public surgical\ndataset. The results also show the promising potential of our framework for reducing annotation workload in the clinical\npractice."}}
{"id": "6YEQUn0QICG", "cdate": 1601308039944, "mdate": null, "content": {"title": "FedBN: Federated Learning on Non-IID Features via Local Batch Normalization", "abstract": "The emerging paradigm of federated learning (FL) strives to enable collaborative training of deep models on the network edge without centrally aggregating raw data and hence improving data privacy. In most cases, the assumption of independent and identically distributed samples across local clients does not hold for federated learning setups. Under this setting, neural network training performance may vary significantly according to the data distribution and even hurt training convergence. Most of the previous work has focused on a difference in the distribution of labels or client shifts. Unlike those settings, we address an important problem of FL, e.g., different scanners/sensors in medical imaging, different scenery distribution in autonomous driving (highway vs. city), where local clients store examples with different distributions compared to other clients, which we denote as feature shift non-iid. In this work, we propose an effective method that uses local batch normalization to alleviate the feature shift before averaging models. The resulting scheme, called FedBN, outperforms both classical FedAvg, as well as the state-of-the-art for non-iid data (FedProx) on our extensive experiments. These empirical results are supported by a convergence analysis that shows in a simplified setting that FedBN has a faster convergence rate than FedAvg. Code is available at https://github.com/med-air/FedBN."}}
{"id": "Hyl7jNSe8r", "cdate": 1567802523351, "mdate": null, "content": {"title": "Domain Generalization via Model-Agnostic Learning of Semantic Features", "abstract": "Generalization capability to unseen domains is crucial for machine learning models when deploying to real-world conditions. We investigate the challenging problem of domain generalization, i.e., training a model on multi-domain source data such that it can directly generalize to target domains with unknown statistics. We adopt a model-agnostic learning paradigm with gradient-based meta-train and meta-test procedures to expose the optimization to domain shift. Further, we introduce two complementary losses which explicitly regularize the semantic structure of the feature space. Globally, we align a derived soft confusion matrix to preserve general knowledge of inter-class relationships. Locally, we promote domain-independent class-specific cohesion and separation of sample features with a metric-learning component. The effectiveness of our method is demonstrated with new state-of-the-art results on two common object recognition benchmarks. Our method also shows consistent improvement on a medical image segmentation task."}}
