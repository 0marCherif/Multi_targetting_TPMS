{"id": "3qOWbM73id", "cdate": 1577836800000, "mdate": null, "content": {"title": "Explaining Symbolic Regression Predictions", "abstract": "The outgrowing application of machine learning methods has raised a discussion in the artificial intelligence community on model transparency. In the center of this discussion is the question of model explanation and interpretability. The genetic programming (GP) community has systematically pointed out as one of the major advantages of GP the fact that it produces models that can be interpreted by humans. However, as other interpretable supervised models, the more complex the model becomes, the less interpretable it is. This work focuses on post-hoc interpretability of GP for symbolic regression. This approach does not explain the process followed by a model to reach a decision. Instead, it justifies the predictions it makes. The proposed approach, named Explanation by Local Approximation (ELA), is simple and model agnostic: it finds the nearest neighbors of the point we want to explain and performs a linear regression using this subset of points. The coefficients of this linear regression are then used to generate a local explanation to the model. Results show that the errors of ELA are similar to those of the regression performed with all points. It also shows that simple visualizations can provide insights to the users about the most relevant attributes."}}
{"id": "2hl7KBqL-5c", "cdate": 1577836800000, "mdate": null, "content": {"title": "Is Rank Aggregation Effective in Recommender Systems? An Experimental Analysis", "abstract": "Recommender Systems are tools designed to help users find relevant information from the myriad of content available online. They work by actively suggesting items that are relevant to users according to their historical preferences or observed actions. Among recommender systems, top-N recommenders work by suggesting a ranking of N items that can be of interest to a user. Although a significant number of top-N recommenders have been proposed in the literature, they often disagree in their returned rankings, offering an opportunity for improving the final recommendation ranking by aggregating the outputs of different algorithms. Rank aggregation was successfully used in a significant number of areas, but only a few rank aggregation methods have been proposed in the recommender systems literature. Furthermore, there is a lack of studies regarding rankings\u2019 characteristics and their possible impacts on the improvements achieved through rank aggregation. This work presents an extensive two-phase experimental analysis of rank aggregation in recommender systems. In the first phase, we investigate the characteristics of rankings recommended by 15 different top-N recommender algorithms regarding agreement and diversity. In the second phase, we look at the results of 19 rank aggregation methods and identify different scenarios where they perform best or worst according to the input rankings\u2019 characteristics. Our results show that supervised rank aggregation methods provide improvements in the results of the recommended rankings in six out of seven datasets. These methods provide robustness even in the presence of a big set of weak recommendation rankings. However, in cases where there was a set of non-diverse high-quality input rankings, supervised and unsupervised algorithms produced similar results. In these cases, we can avoid the cost of the former in favor of the latter."}}
{"id": "O-TfiQTfgrI", "cdate": 1546300800000, "mdate": null, "content": {"title": "Multimodal data fusion framework based on autoencoders for top-N recommender systems", "abstract": "In this paper, we present a novel multimodal framework for video recommendation based on deep learning. Unlike most common solutions, we formulate video recommendations by exploiting simultaneously two data modalities, particularly: (i) the visual (i.e., image sequence) and (ii) the textual modalities, which in conjunction with the audio stream constitute the elementary data of a video document. More specifically, our framework firstly describe textual data by using the bag-of-words and TF-IDF models, fusing those features with deep convolutional descriptors extracted from the visual data. As result, we obtain a multimodal descriptor for each video document, from which we construct a low-dimensional sparse representation by using autoencoders. To qualify the recommendation task, we extend a sparse linear method with side information (SSLIM), by taking into account the sparse representations of video descriptors previously computed. By doing this, we are able to produce a ranking of the top-N most relevant videos to the user. Note that our framework is flexible, i.e., one may use other types of modalities, autoencoders, and fusion architectures. Experimental results obtained on three real datasets (MovieLens-1M, MovieLens-10M and Vine), containing 3,320, 8,400 and 18,576 videos, respectively, show that our framework can improve up to 60.6% the recommendation results, when compared to a single modality recommendation model and up to 31%, when compared to state-of-the art methods used as baselines in our study, demonstrating the effectiveness of our framework and highlighting the usefulness of multimodal information in recommender system."}}
{"id": "I7ggU9vZc9G", "cdate": 1546300800000, "mdate": null, "content": {"title": "Multimodal approach for tension levels estimation in news videos", "abstract": "In this paper, we present a novel multimodal approach to estimate tension levels in news videos. The news media constitute a particular type of discourse and has become a central part of the modern-day lives of millions of people. In this context, it is important to study how the news industry affects human life and how it works. To support such a study, our approach estimates tension levels (polarities) along the news narrative, revealing the communication patterns used. To achieve this goal, we combine audio and visual cues extracted from news participants (e.g., reporters and anchors), by using methods for: (1) emotion recognition from facial expressions, (2) field size estimation and (3) extraction of audio features (e.g., chroma and spectral features), as well as textual cues obtained from the (4) sentiment analysis of the speech transcriptions. Experimental results with a dataset containing 960 annotated news videos from three Brazilian and one American TV newscasts show that our approach achieves an overall accuracy as high as 64.17% in the tension levels classification task. Those results demonstrate the high potential of our approach to be used by media analysts in several applications, especially, in the journalistic domain."}}
{"id": "1w7HCOBeV9R", "cdate": 1546300800000, "mdate": null, "content": {"title": "On Modeling Context from Objects with a Long Short-Term Memory for Indoor Scene Recognition", "abstract": "Recognizing indoor scenes is still regarded an open challenge on the Computer Vision field. Indoor scenes can be well represented by their composing objects, which can vary in angle, appearance, besides often being partially occluded. Even though Convolutional Neural Networks are remarkable for image-related problems, the top performances on indoor scenes are from approaches modeling the intricate relationship of objects. Knowing that Recurrent Neural Networks were designed to model structure from a given sequence, we propose representing an image as a sequence of object-level information in order to feed a bidirectional Long Short-Term Memory network trained for scene classification. We perform a Many-to-Many training approach, such that each element outputs a scene prediction, allowing us to use each prediction to boost recognition. Our method outperforms RNN-based approaches on MIT67, an entirely indoor dataset, while also improved over the most successful methods through an ensemble of classifiers."}}
{"id": "w3fYJvTnpmd", "cdate": 1514764800000, "mdate": null, "content": {"title": "A computational approach to support the creation of terminological neologisms in sign languages", "abstract": "This work presents a novel approach to support the creation of terminological neologisms (technical signs) for Science, Technology, Engineering, and Mathematics (STEM) dictionaries in sign languages..."}}
{"id": "t_MFS84QTTh", "cdate": 1514764800000, "mdate": null, "content": {"title": "Multi-objective Evolutionary Rank Aggregation for Recommender Systems", "abstract": "Recommender systems help users to overcome the information overload problem by selecting relevant items according to their preferences. This paper deals with the problem of rank aggregation in recommender systems, where we want to generate a single consensus ranking from a given set of input rankings generated by different recommendation algorithms. This problem is NP-hard, and hence the use of meta-heuristics to solve it is appealing. Although accurate suggestions are mandatory for effective recommender systems, other recommendation quality measures need to be taken into account for delivering high-quality suggestions. This paper proposes Multi-objective Evolutionary Rank Aggregation (MERA), a genetic programming algorithm following the concepts of SPEA2 that considers three measures when suggesting items to users, namely mean average precision, diversity, and novelty. The method was tested in 3 realworld recommendation datasets, and the results show MERA can indeed find a balance for these metrics while generating a diverse set of solutions to the problem. MERA was able to return solutions with improvements of up to 15% in diversity (for the Movielens 1M dataset) and 7% in novelty (for the Filmtrust dataset) while maintaining, or even improving, the values of precision."}}
{"id": "k4MFTxUWNrh", "cdate": 1514764800000, "mdate": null, "content": {"title": "User-Oriented Objective Prioritization for Meta-Featured Multi-Objective Recommender Systems", "abstract": "Multi-Objective Recommender Systems (MO-RS) consider several objectives to produce useful recommendations. Besides accuracy, other important quality metrics include novelty and diversity of recommended lists of items. Previous research up to this point focused on naive combinations of objectives. In this paper, we present a new and adaptable strategy for prioritizing objectives focused on users' preferences. Our proposed strategy is based on meta-features, i.e., characteristics of the input data that are influential in the final recommendation. We conducted a series of experiments on three real-world datasets, from which we show that: (i) the use of meta-features leads to the improvement of the Pareto solution set in the search process; (ii) the strategy is effective at making choices according to the specificities of the users' preferences; and (iii) our approach outperforms state-of-the-art methods in MO-RS."}}
{"id": "2kVTimU51nG", "cdate": 1514764800000, "mdate": null, "content": {"title": "Exploiting Multiple Recommenders to Improve Group Recommendation", "abstract": "Group recommendation methods deal with scenarios where a group is the target of recommendation instead of a single user. An initial approach followed by these methods was to aggregate the rankings generated to each individual user of the group by traditional recommender systems. This approach was replaced to more sophisticated methods, but the potential and simplicity of the aggregation strategies were underexplored. This paper proposes to use multiple recommenders to generate recommendations to single group members before aggregating their recommendations. We show that this strategy significantly improves the results of aggregating single recommenders while overcoming the problem of selecting the best recommendation algorithm. We also propose five heuristics to select a subset of the available recommenders to be aggregated. We tested heuristics in seven dataset variations, showing that by using half of the available algorithms we can achieve results similar or better than those obtained by the whole set."}}
{"id": "cKV0b2v-YC9", "cdate": 1483228800000, "mdate": null, "content": {"title": "A video summarization approach based on the emulation of bottom-up mechanisms of visual attention", "abstract": "This work addresses the development of a computational model of visual attention to perform the automatic summarization of digital videos from television archives. Although the television system represents one of the most fascinating media phenomena ever created, we still observe the absence of effective solutions for content-based information retrieval from video recordings of programs produced by this media universe. This fact relates to the high complexity of the content-based video retrieval problem, which involves several challenges, among which we may highlight the usual demand on video summaries to facilitate indexing, browsing and retrieval operations. To achieve this goal, we propose a new computational visual attention model, inspired on the human visual system and based on computer vision methods (face detection, motion estimation and saliency map computation), to estimate static video abstracts, that is, collections of salient images or key frames extracted from the original videos. Experimental results with videos from the Open Video Project show that our approach represents an effective solution to the problem of automatic video summarization, producing video summaries with similar quality to the ground-truth manually created by a group of 50 users."}}
