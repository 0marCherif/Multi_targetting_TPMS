{"id": "LU1AepnLOG", "cdate": 1668047400405, "mdate": 1668047400405, "content": {"title": "Inverse Procedural Modeling of Branching Structures by Inferring L-Systems", "abstract": "We introduce an inverse procedural modeling approach that learns Lsystem representations of pixel images with branching structures. Our\nfully automatic model generates a compact set of textual rewriting rules\nthat describe the input. We use deep learning to discover atomic structures\nsuch as line segments or branchings. Orientation and scaling of these structures are determined and the detected structures are combined into a tree.\nThe initial representation is analyzed, and repeating parts are encoded into\na small grammar by using greedy optimization while the user can control\nthe size of the detected rules. The output is an L-system that represents\nthe input image as a simple text and a set of terminal symbols. We apply\nour approach to a variety of examples, demonstrate its robustness against\nnoise and blur, and we show that it can detect user sketches and complex\ninput structures."}}
{"id": "BnznzofWMi", "cdate": 1663849861882, "mdate": null, "content": {"title": "Representation Mutual Learning for End-to-End Weakly-Supervised Semantic Segmentation", "abstract": "In recent years, end-to-end solutions for Weakly Supervised Semantic Segmentation (WSSS) with image-level labels have been developed rapidly. Previous end-to-end methods usually rely on segmentation branches or decoders to predict segmentation masks, bringing additional parameter numbers and consumption time. In this paper, we propose a decoder-free Representation Mutual Learning (RML) framework to directly predict segmentation masks, which leverages collaborative learning and mutual teaching among multi-level feature representations to improve segmentation performance. Our RML is a straightforward and efficient end-to-end WSSS framework, which incorporates the instance-level, feature-level and pixel-level representation mutual learning strategies to improve segmentation quality. To enhance the Class Activation Map (CAM) representations, we propose a CAM-driven Instance-leave Mutual Learning strategy that preserves the equivariance of CAMs and expands the distance between different classes of semantic prototypes. Besides, we design a Multi-scale Feature-leave Mutual Learning strategy, which can align aggregated contextual representations and facilitate the representation capability of contextual representations. Furthermore, we also provide an Affinity-aware Pixel-level Mutual Learning strategy to learn semantic affinity representations. Experiments validate that our RML yields a significant performance improvement over recent end-to-end methods on the Pascal VOC 2012 dataset and the MS COCO 2014 dataset. The release code is available at supplementary material."}}
{"id": "8p67d4TMzR", "cdate": 1582099487985, "mdate": null, "content": {"title": "Photo Squarization by Deep Multi-Operator Retargeting", "abstract": "Squared forms of photos are widely used in social media as album covers or thumbnails of image streams. In this study, we realize photo squarization by modeling Retargeting Visual Perception Issues, which reflect human perception preference toward image ratargeting. General image retargeting techniques deal with three common issues, namely, salient content, object shape, and scene composition, to preserve the important information of original image. We propose a new way based on multi-operator techniques to investigate human behavior in balancing the three issues. We establish a new dataset and observe human behavior by inviting investigators to retarget images to square manually. We propose a data-driven approach\ncomposed of perception and distillation modules by using deep learning techniques to predict human perception preference.\nThe perception part learns the relations among the three issues, and the distillation part transfers the learned relations to a simple but effective network. Our study contributes to deep learning literature by optimizing a network index and lightening its running burden. Experimental results show that photo squarization results generated by the proposed model are consistent with human visual perception results."}}
{"id": "ryeK6nNFDr", "cdate": 1569438913167, "mdate": null, "content": {"title": "Effective and Robust Detection of Adversarial Examples via Benford-Fourier Coefficients", "abstract": "Adversarial examples have been well known as a serious threat to deep neural\nnetworks (DNNs). To ensure successful and safe operations of DNNs on realworld tasks, \nit is urgent to equip DNNs with effective defense strategies. In this\nwork, we study the detection of adversarial examples, based on the assumption\nthat the output and internal responses of one DNN model for both adversarial and\nbenign examples follow the generalized Gaussian distribution (GGD), but with\ndifferent parameters (i.e., shape factor, mean, and variance). GGD is a general\ndistribution family to cover many popular distributions (e.g., Laplacian, Gaussian,\nor uniform). It is more likely to approximate the intrinsic distributions of internal\nresponses than any specific distribution. Besides, since the shape factor is more\nrobust to different databases rather than the other two parameters, we propose\nto construct discriminative features via the shape factor for adversarial detection,\nemploying the magnitude of Benford-Fourier coefficients (MBF), which can be\neasily estimated using responses. Finally, a support vector machine is trained\nas the adversarial detector through leveraging the MBF features. Through the\nKolmogorov-Smirnov (KS) test, we empirically verify that: 1) the posterior vectors \nof both adversarial and benign examples follow GGD; 2) the extracted MBF features \nof adversarial and benign examples follow different distributions. Extensive \nexperiments in terms of image classification demonstrate that the proposed \ndetector is much more effective and robust on detecting adversarial examples \nof different crafting methods and different sources, in contrast to state-of-the-art \nadversarial detection methods."}}
{"id": "So8-7yQxOTS", "cdate": 1546300800000, "mdate": null, "content": {"title": "A Robust Local Spectral Descriptor for Matching Non-Rigid Shapes With Incompatible Shape Structures.", "abstract": "Constructing a robust and discriminative local descriptor for 3D shape is a key component of many computer vision applications. Although existing learning-based approaches can achieve good performance in some specific benchmarks, they usually fail to learn enough information from shapes with different shape types and structures (e.g., spatial resolution, connectivity, transformations, etc.) Focusing on this issue, in this paper, we present a more discriminative local descriptor for deformable 3D shapes with incompatible structures. Based on the spectral embedding using the Laplace-Beltrami framework on the surface, we first construct a novel local spectral feature which shows great resilience to change in mesh resolution, triangulation, transformation. Then the multi-scale local spectral features around each vertex are encoded into a `geometry image', called vertex spectral image, in a very compact way. Such vertex spectral images can be efficiently trained to learn local descriptors using a triplet neural network. Finally, for training and evaluation, we present a new benchmark dataset by extending the widely used FAUST dataset. We utilize a remeshing approach to generate modified shapes with different structures. We evaluate the proposed approach thoroughly and make an extensive comparison to demonstrate that our approach outperforms recent state-of-the-art methods on this benchmark."}}
{"id": "B1WepFZ_-S", "cdate": 1514764800000, "mdate": null, "content": {"title": "Learning 3D Keypoint Descriptors for Non-rigid Shape Matching", "abstract": "In this paper, we present a novel deep learning framework that derives discriminative local descriptors for 3D surface shapes. In contrast to previous convolutional neural networks (CNNs) that rely on rendering multi-view images or extracting intrinsic shape properties, we parameterize the multi-scale localized neighborhoods of a keypoint into regular 2D grids, which are termed as \u2018geometry images\u2019. The benefits of such geometry images include retaining sufficient geometric information, as well as allowing the usage of standard CNNs. Specifically, we leverage a triplet network to perform deep metric learning, which takes a set of triplets as input, and a newly designed triplet loss function is minimized to distinguish between similar and dissimilar pairs of keypoints. At the testing stage, given a geometry image of a point of interest, our network outputs a discriminative local descriptor for it. Experimental results for non-rigid shape matching on several benchmarks demonstrate the superior performance of our learned descriptors over traditional descriptors and the state-of-the-art learning-based alternatives."}}
{"id": "SyZXwlGubS", "cdate": 1483228800000, "mdate": null, "content": {"title": "Hardware-Efficient Guided Image Filtering for Multi-label Problem", "abstract": "The Guided Filter (GF) is well-known for its linear complexity. However, when filtering an image with an n-channel guidance, GF needs to invert an n \u00d7 n matrix for each pixel. To the best of our knowledge existing matrix inverse algorithms are inefficient on current hardwares. This shortcoming limits applications of multichannel guidance in computation intensive system such as multi-label system. We need a new GF-like filter that can perform fast multichannel image guided filtering. Since the optimal linear complexity of GF cannot be minimized further, the only way thus is to bring all potentialities of current parallel computing hardwares into full play. In this paper we propose a hardware-efficient Guided Filter (HGF), which solves the efficiency problem of multichannel guided image filtering and yields competent results when applying it to multi-label problems with synthesized polynomial multichannel guidance. Specifically, in order to boost the filtering performance, HGF takes a new matrix inverse algorithm which only involves two hardware-efficient operations: element-wise arithmetic calculations and box filtering. In order to break the linear model restriction, HGF synthesizes a polynomial multichannel guidance to introduce nonlinearity. Benefiting from our polynomial guidance and hardware-efficient matrix inverse algorithm, HGF not only is more sensitive to the underlying structure of guidance but also achieves the fastest computing speed. Due to these merits, HGF obtains state-of-the-art results in terms of accuracy and efficiency in the computation intensive multi-label systems."}}
{"id": "rk-4EZzuWS", "cdate": 1420070400000, "mdate": null, "content": {"title": "Fully Connected Guided Image Filtering", "abstract": "This paper presents a linear time fully connected guided filter by introducing the minimum spanning tree (MST) to the guided filter (GF). Since the intensity based filtering kernel of GF is apt to overly smooth edges and the fixed-shape local box support region adopted by GF is not geometric-adaptive, our filter introduces an extra spatial term, the tree similarity, to the filtering kernel of GF and substitutes the box window with the implicit support region by establishing all-pairs-connections among pixels in the image and assigning the spatial-intensity-aware similarity to these connections. The adaptive implicit support region composed by the pixels with large kernel weights in the entire image domain has a big advantage over the predefined local box window in presenting the structure of an image for the reason that: 1, MST can efficiently present the structure of an image, 2, the kernel weight of our filter considers the tree distance defined on the MST. Due to these reasons, our filter achieves better edge-preserving results. We demonstrate the strength of the proposed filter in several applications. Experimental results show that our method produces better results than state-of-the-art methods."}}
{"id": "S1NAMbGdZr", "cdate": 1420070400000, "mdate": null, "content": {"title": "Segment Graph Based Image Filtering: Fast Structure-Preserving Smoothing", "abstract": "In this paper, we design a new edge-aware structure, named segment graph, to represent the image and we further develop a novel double weighted average image filter (SGF) based on the segment graph. In our SGF, we use the tree distance on the segment graph to define the internal weight function of the filtering kernel, which enables the filter to smooth out high-contrast details and textures while preserving major image structures very well. While for the external weight function, we introduce a user specified smoothing window to balance the smoothing effects from each node of the segment graph. Moreover, we also set a threshold to adjust the edge-preserving performance. These advantages make the SGF more flexible in various applications and overcome the \"halo\" and \"leak\" problems appearing in most of the state-of-the-art approaches. Finally and importantly, we develop a linear algorithm for the implementation of our SGF, which has an O(N) time complexity for both gray-scale and high dimensional images, regardless of the kernel size and the intensity range. Typically, as one of the fastest edge-preserving filters, our CPU implementation achieves 0.15s per megapixel when performing filtering for 3-channel color images. The strength of the proposed filter is demonstrated by various applications, including stereo matching, optical flow, joint depth map upsampling, edge-preserving smoothing, edges detection, image abstraction and texture editing."}}
{"id": "Sy4WsbGuWS", "cdate": 1356998400000, "mdate": null, "content": {"title": "Cross-Field Joint Image Restoration via Scale Map", "abstract": "Color, infrared, and flash images captured in different fields can be employed to effectively eliminate noise and other visual artifacts. We propose a two-image restoration framework considering input images in different fields, for example, one noisy color image and one dark-flashed near infrared image. The major issue in such a framework is to handle structure divergence and find commonly usable edges and smooth transition for visually compelling image reconstruction. We introduce a scale map as a competent representation to explicitly model derivative-level confidence and propose new functions and a numerical solver to effectively infer it following new structural observations. Our method is general and shows a principled way for cross-field restoration."}}
