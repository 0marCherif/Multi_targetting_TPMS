{"id": "YVwQvDKFYNs", "cdate": 1664816292172, "mdate": null, "content": {"title": "SynBench: Task-Agnostic Benchmarking of Pretrained Representations using Synthetic Data", "abstract": "Recent success in fine-tuning large models, that are pretrained on broad data at scale, on downstream tasks has led to a significant paradigm shift in deep learning, from task-centric model design to task-agnostic representation learning and task-specific fine-tuning. As the representations of pretrained models are used as a foundation for different downstream tasks, this paper proposes a new task-agnostic framework, \\textit{SynBench}, to measure the quality of pretrained representations using synthetic data. Our framework applies to a wide range of pretrained models taking continuous data inputs and is independent of the downstream tasks and datasets. Evaluated with several pretrained vision transformer models, the experimental results show that our SynBench score well matches the actual linear probing performance of the pre-trained model , and can inform the design of robust linear probing on pretrained representations to mitigate the robustness-accuracy tradeoff in downstream tasks."}}
{"id": "TLx9diIRJVj", "cdate": 1663850304946, "mdate": null, "content": {"title": "SynBench: Task-Agnostic Benchmarking of Pretrained Representations using Synthetic Data", "abstract": "Recent success in fine-tuning large models, that are pretrained on broad data at scale, on downstream tasks has led to a significant paradigm shift in deep learning, from task-centric model design to task-agnostic representation learning and task-specific fine-tuning. As the representations of pretrained models are used as a foundation for different downstream tasks, this paper proposes a new task-agnostic framework, \\textit{SynBench}, to measure the quality of pretrained representations using synthetic data. We set up a reference by a theoretically-derived robustness-accuracy tradeoff of the class conditional Gaussian mixture. Given a pretrained model, the representations of data synthesized from the Gaussian mixture are used to compare with our reference to infer the quality. By comparing the ratio of area-under-curve between the raw data and their representations, SynBench offers a quantifiable score for robustness-accuracy performance benchmarking. Our framework applies to a wide range of pretrained models taking continuous data inputs and is independent of the downstream tasks and datasets. Evaluated with several pretrained vision transformer models, the experimental results show that our SynBench score well matches the actual linear probing performance of the pre-trained model when fine-tuned on downstream tasks. Moreover, our framework can be used to inform the design of robust linear probing on pretrained representations to mitigate the robustness-accuracy tradeoff in downstream tasks."}}
{"id": "UIQxciuYcon", "cdate": 1632875462029, "mdate": null, "content": {"title": "Revisiting Contrastive Learning through the Lens of Neighborhood Component Analysis: an Integrated Framework ", "abstract": "As a seminal tool in self-supervised representation learning, contrastive learning has gained unprecedented attention in recent years. In essence, contrastive learning aims to leverage pairs of positive and negative samples for representation learning, which relates to exploiting neighborhood information in a feature space. By investigating the connection between contrastive learning and neighborhood component analysis (NCA), we provide a novel stochastic nearest neighbor viewpoint of contrastive learning and subsequently propose a series of contrastive losses that outperform the existing ones. Under our proposed framework, we show a principled way to design integrated contrastive losses that simultaneously achieve good accuracy and robustness on downstream tasks."}}
{"id": "TlWAilHARWf", "cdate": 1609459200000, "mdate": null, "content": {"title": "Hidden Cost of Randomized Smoothing", "abstract": "The fragility of modern machine learning models has drawn a considerable amount of attention from both academia and the public. While immense interests were in either crafting adversarial attacks as a way to measure the robustness of neural networks or devising worst-case analytical robustness verification with guarantees, few methods could enjoy both scalability and robustness guarantees at the same time. As an alternative to these attempts, randomized smoothing adopts a different prediction rule that enables statistical robustness arguments which easily scale to large networks. However, in this paper, we point out the side effects of current randomized smoothing workflows. Specifically, we articulate and prove two major points: 1) the decision boundaries of smoothed classifiers will shrink, resulting in disparity in class-wise accuracy; 2) applying noise augmentation in the training process does not necessarily resolve the shrinking issue due to the inconsistent learning objectives."}}
{"id": "pf5jPjfrmtE", "cdate": 1577836800000, "mdate": null, "content": {"title": "Higher-Order Certification For Randomized Smoothing", "abstract": "Randomized smoothing is a recently proposed defense against adversarial attacks that has achieved state-of-the-art provable robustness against $\\ell_2$ perturbations. A number of works have extended the guarantees to other metrics, such as $\\ell_1$ or $\\ell_\\infty$, by using different smoothing measures. Although the current framework has been shown to yield near-optimal $\\ell_p$ radii, the total safety region certified by the current framework can be arbitrarily small compared to the optimal. In this work, we propose a framework to improve the certified safety region for these smoothed classifiers without changing the underlying smoothing scheme. The theoretical contributions are as follows: 1) We generalize the certification for randomized smoothing by reformulating certified radius calculation as a nested optimization problem over a class of functions. 2) We provide a method to calculate the certified safety region using zeroth-order and first-order information for Gaussian-smoothed classifiers. We also provide a framework that generalizes the calculation for certification using higher-order information. 3) We design efficient, high-confidence estimators for the relevant statistics of the first-order information. Combining the theoretical contribution 2) and 3) allows us to certify safety region that are significantly larger than ones provided by the current methods. On CIFAR and Imagenet, the new regions achieve significant improvements on general $\\ell_1$ certified radii and on the $\\ell_2$ certified radii for color-space attacks ($\\ell_2$ perturbation restricted to only one color/channel) while also achieving smaller improvements on the general $\\ell_2$ certified radii. As discussed in the future works section, our framework can also provide a way to circumvent the current impossibility results on achieving higher magnitudes of certified radii without requiring the use of data-dependent smoothing techniques."}}
{"id": "gKLEaxdhWSz", "cdate": 1577836800000, "mdate": null, "content": {"title": "Towards Verifying Robustness of Neural Networks Against A Family of Semantic Perturbations", "abstract": "Verifying robustness of neural networks given a specified threat model is a fundamental yet challenging task. While current verification methods mainly focus on the \u2113p-norm threat model of the input instances, robustness verification against semantic adversarial attacks inducing large \u2113p-norm perturbations, such as color shifting and lighting adjustment, are beyond their capacity. To bridge this gap, we propose Semantify-NN, a model-agnostic and generic robustness verification approach against semantic perturbations for neural networks. By simply inserting our proposed semantic perturbation layers (SP-layers) to the input layer of any given model, Semantify-NN is model-agnostic, and any \u2113p-norm based verification tools can be used to verify the model robustness against semantic perturbations. We illustrate the principles of designing the SP-layers and provide examples including semantic perturbations to image classification in the space of hue, saturation, lightness, brightness, contrast and rotation, respectively. In addition, an efficient refinement technique is proposed to further significantly improve the semantic certificate. Experiments on various network architectures and different datasets demonstrate the superior verification performance of Semantify-NN over \u2113p-norm-based verification frameworks that naively convert semantic perturbation to \u2113p-norm. The results show that Semantify-NN can support robustness verification against a wide range of semantic perturbations."}}
{"id": "ayvH7FsJz-w", "cdate": 1514764800000, "mdate": null, "content": {"title": "Optimal Gossip Algorithms for Exact and Approximate Quantile Computations", "abstract": "This paper gives drastically faster gossip algorithms to compute exact and approximate quantiles. Gossip algorithms, which allow each node to contact a uniformly random other node in each round, have been intensely studied and been adopted in many applications due to their fast convergence and their robustness to failures. Kempe et al. [24] gave gossip algorithms to compute important aggregate statistics if every node is given a value. In particular, they gave a beautiful O(logn + log 1 \u03b5 ) round algorithm to \u03b5-approximate the sum of all values and an O(log2 n) round algorithm to compute the exact \u03a6-quantile, i.e., the ?\u03a6n? smallest value. We give an quadratically faster and in fact optimal gossip algorithm for the exact \u03a6-quantile problem which runs in O(logn) rounds. We furthermore show that one can achieve an exponential speedup if one allows for an \u03b5-approximation. In particular, we give an O(log logn + log 1 \u03b5 ) round gossip algorithm which computes a value of rank between \u03a6n and (\u03a6 + \u03b5)n at every node. Our algorithms are extremely simple and very robust - they can be operated with the same running times even if every transmission fails with a, potentially different, constant probability. We also give a matching \u03a9(log logn + log 1 \u03b5 ) lower bound which shows that our algorithm is optimal for all values of \u03b5."}}
