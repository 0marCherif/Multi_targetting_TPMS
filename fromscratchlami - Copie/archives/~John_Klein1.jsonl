{"id": "2HeaXybt_hl", "cdate": 1589630560669, "mdate": null, "content": {"title": "Exploiting Adversarial Embeddings for Better Steganography", "abstract": "This work proposes a protocol to iteratively build a distortion function for adaptive steganography while increasing its practical security after each iteration. It relies on prior art on targeted attacks and iterative design of steganalysis schemes. It combines targeted attacks on a given detector with a \\min\\max strategy, which dynamically selects the most difficult stego content associated with the best classifier at each iteration. We theoretically prove the convergence, which is confirmed by the practical results. Applied on J-Uniward this new protocol increases \\perr from 7% to 20% estimated by Xu-Net, and from 10% to 23% for a non-targeted steganalysis by a linear classifier with GFR features."}}
{"id": "57nECqOqGua", "cdate": 1589630125915, "mdate": null, "content": {"title": "Decentralized learning with budgeted network load using Gaussian copulas and classifier ensembles", "abstract": "We examine a network of learners which address the same classification task but must learn from different data sets. The learners cannot share data but instead share their models. Models are shared only one time so as to preserve the network load. We introduce DELCO (standing for Decentralized Ensemble Learning with COpulas), a new approach allow- ing to aggregate the predictions of the classifiers trained by each learner. The proposed method aggregates the base classifiers using a probabilis- tic model relying on Gaussian copulas. Experiments on logistic regressor ensembles demonstrate competing accuracy and increased robustness in case of dependent classifiers. A companion python implementation can be downloaded at https://github.com/john-klein/DELCO."}}
{"id": "C_Ge_oglTXF", "cdate": 1589629995741, "mdate": null, "content": {"title": "Complementary Lipschitz continuity results for the distribution of intersections or unions of independent random sets in finite discrete spaces", "abstract": "We prove that intersections and unions of independent random sets in finite spaces achieve a form of Lipschitz continuity. More precisely, given the distribution of a random set \u039e, the function mapping any random set distribution to the distribution of its intersection (under independence assumption) with \u039e is Lipschitz continuous with unit Lipschitz constant if the space of random set distributions is endowed with a metric defined as the Lk norm distance between inclusion func- tionals also known as commonalities. Moreover, the function mapping any random set distribution to the distribution of its union (under independence assumption) with \u039e is Lipschitz continuous with unit Lipschitz constant if the space of random set distributions is endowed with a metric defined as the Lk norm distance between hitting func- tionals also known as plausibilities.\nUsing the epistemic random set interpretation of belief functions, we also discuss the ability of these distances to yield conflict measures. All the proofs in this paper are derived in the framework of Dempster- Shafer belief functions. Let alone the discussion on conflict measures, it is straightforward to transcribe the proofs into the general (non necessarily epistemic) random set terminology."}}
{"id": "Sc1FrGzx6Xk", "cdate": 1589629924753, "mdate": null, "content": {"title": "SPOCC: Scalable POssibilistic Classifier Combination \u2013 toward robust aggregation of classifiers", "abstract": "We investigate a problem in which each member of a group of learners is trained separately to solve the same classification task. Each learner has access to a training dataset (possibly with overlap across learners) but each trained classifier can be evaluated on a validation dataset.\nWe propose a new approach to aggregate the learner predictions in the possibility theory framework. For each classifier prediction, we build a possibility distribution assessing how likely the classifier prediction is cor- rect using frequentist probabilities estimated on the validation set. The possibility distributions are aggregated using an adaptive t-norm that can accommodate dependency and poor accuracy of the classifier predictions. We prove that the proposed approach possesses a number of desirable clas- sifier combination robustness properties. Moreover, the method is agnos- tic on the base learners, scales well in the number of aggregated classifiers and is incremental as a new classifier can be appended to the ensemble by building upon previously computed parameters and structures."}}
{"id": "vToTHeX0dDu", "cdate": 1589629713796, "mdate": null, "content": {"title": "MR to CT synthesis with multicenter data in the pelvic era using a conditional generative adversarial network", "abstract": "The establishment of an MRI-only workflow in radiotherapy depends on the ability to generate an accurate synthetic-CT (sCT) for dose calculation. Previously proposed methods have used a Generative Adversarial Network (GAN) for fast sCT generation in order to simplify the clinical workflow and reduces uncertainties. In the current paper we use a conditional Generative Adversarial Network (cGAN) framework called pix2pixHD to create a robust model prone to multicenter data.\nThis study included T2-weighted MR and CT images of 19 patients in treatment position from 3 different sites. The cGAN was trained on 2D transverse slices of 11 patients from 2 different sites. Once trained, the network was used to generate sCT images of 8 patients coming from a third site. The Mean Absolute Errors (MAE) for each patient were evaluated between real and synthetic CTs. A radiotherapy plan was optimized on the sCT series and re-calculated on CTs to assess the dose distribution in terms of voxel-wise dose difference and Dose Volume Histograms (DVH) analysis.\nIt takes on average of 7.5 \ud835\udc60 to generate a complete sCT (88 slices) for a patient on our GPU. The average MAE in HU between the sCT and actual patient CT (within the body contour) is 48.5 \u00b1 6 \ud835\udc3b\ud835\udc48 with our method. The maximum dose difference to the target is 1.3%.\nThis study demonstrates that an sCT can be generated in a multicentric context, with fewer pre- processing steps while being fast and accurate."}}
