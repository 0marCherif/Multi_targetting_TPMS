{"id": "QMrs1nggaL", "cdate": 1652737615161, "mdate": null, "content": {"title": "Faster and Scalable Algorithms for Densest Subgraph and Decomposition", "abstract": "We study the densest subgraph problem (DSG) and the densest subgraph local decomposition problem (DSG-LD) in undirected graphs. We also consider supermodular generalizations of these problems. For large scale graphs simple iterative algorithms perform much better in practice than theoretically fast algorithms based on network-flow or LP solvers. Boob et al [1] recently gave a fast iterative algorithm called Greedy++ for DSG. It was shown in [2] that it converges to a $(1-\\epsilon)$ relative approximation to the optimum density in $O(\\frac{1}{\\epsilon^2} \\frac{\\Delta(G)}{\\lambda^*})$ iterations where $\\Delta(G)$ is the maximum degree and $\\lambda^*$ is the optimum density. Danisch et al. [3] gave an iterative algorithm based on the Frank-Wolfe algorithm for DSG-LD that takes $O(\\frac{m\\Delta(G) }{\\epsilon^2})$ iterations to converge to an $\\epsilon$-additive approximate local decomposition vector $\\hat{b}$, where $m$ is number of edges in the graph.\n\nIn this paper we give a new iterative algorithm for both problems that takes at most $O(\\frac{\\sqrt{m\\Delta(G)}}{\\epsilon})$ iterations to converge to an $\\epsilon$-additive approximate local decomposition vector; each iteration can be implemented in $O(m)$ time. We describe a fractional peeling technique which has strong empirical performance as well as theoretical guarantees. The algorithm is scalable and simple, and can be applied to graphs with hundreds of millions of edges. \nWe test our algorithm on real and synthetic data sets and show that it provides a significant benefit over previous algorithms. The algorithm and analysis extends to hypergraphs."}}
{"id": "BLgBekOSbkY", "cdate": 1640995200000, "mdate": 1681675440523, "content": {"title": "Revisiting Random Points: Combinatorial Complexity and Algorithms", "abstract": "Consider a set $P$ of $n$ points picked uniformly and independently from $[0,1]^d$ for a constant dimension $d$ -- such a point set is extremely well behaved in many aspects. For example, for a fixed $r \\in [0,1]$, we prove a new concentration result on the number of pairs of points of $P$ at a distance at most $r$ -- we show that this number lies in an interval that contains only $O(n \\log n)$ numbers. We also present simple linear time algorithms to construct the Delaunay triangulation, Euclidean MST, and the convex hull of the points of $P$. The MST algorithm is an interesting divide-and-conquer algorithm which might be of independent interest. We also provide a new proof that the expected complexity of the Delaunay triangulation of $P$ is linear -- the new proof is simpler and more direct, and might be of independent interest. Finally, we present a simple $\\tilde{O}(n^{4/3})$ time algorithm for the distance selection problem for $d=2$."}}
{"id": "fhN1HKopUmu", "cdate": 1609459200000, "mdate": 1681675440505, "content": {"title": "Speeding up the AIFV-2 dynamic programs by two orders of magnitude using Range Minimum Queries", "abstract": ""}}
{"id": "v4dUCHKj9I", "cdate": 1577836800000, "mdate": 1681675440520, "content": {"title": "KFC: A Scalable Approximation Algorithm for k-center Fair Clustering", "abstract": "In this paper, we study the problem of fair clustering on the $k-$center objective. In fair clustering, the input is $N$ points, each belonging to at least one of $l$ protected groups, e.g. male, female, Asian, Hispanic. The objective is to cluster the $N$ points into $k$ clusters to minimize a classical clustering objective function. However, there is an additional constraint that each cluster needs to be fair, under some notion of fairness. This ensures that no group is either \"over-represented\" or \"under-represented\" in any cluster. Our work builds on the work of Chierichetti et al. (NIPS 2017), Bera et al. (NeurIPS 2019), Ahmadian et al. (KDD 2019), and Bercea et al. (APPROX 2019). We obtain a randomized $3-$approximation algorithm for the $k-$center objective function, beating the previous state of the art ($4-$approximation). We test our algorithm on real datasets, and show that our algorithm is effective in finding good clusters without over-representation or under-representation, surpassing the current state of the art in runtime speed, clustering cost, while achieving similar fairness violations."}}
{"id": "bFEhBwS96_4", "cdate": 1577836800000, "mdate": 1681675440542, "content": {"title": "Polynomial Time Algorithms for Constructing Optimal Binary AIFV-2 Codes", "abstract": "Huffman Codes are optimal Instantaneous Fixed-to-Variable (FV) codes in which every source symbol can only be encoded by one codeword. Relaxing these constraints permits constructing better FV codes. More specifically, recent work has shown that AIFV-$m$ codes can beat Huffman coding. AIFV-$m$ codes construct am $m$-tuple of different coding trees between which the code alternates and are only almost instantaneous (AI). This means that decoding a word might require a delay of a finite number of bits. Current algorithms for constructing optimal AIFV-$m$ codes are iterative processes that construct progressively \"better sets\" of code trees. The processes have been proven to finitely converge to the optimal code but with no known bounds on the convergence rate. This paper derives a geometric interpretation of the space of binary AIFV-$2$ codes, permitting the development of the first polynomially time-bounded iterative procedures for constructing optimal AIFV codes. We first show that a simple binary search procedure can replace the current iterative process to construct optimal binary AIFV-$2$ codes. We then describe how to frame the problem as a linear programming with an exponential number of constraints but a polynomial-time separability oracle. This permits using the Gr\\\"otschel, Lov\\'asz and Schrijver ellipsoid method to solve the problem in a polynomial number of steps. While more complicated, this second method has the potential to lead to a polynomial time algorithm to construct optimal AIFV-$m$ codes for general $m$."}}
{"id": "N4aEFC7T50", "cdate": 1577836800000, "mdate": 1681675440515, "content": {"title": "KFC: A Scalable Approximation Algorithm for $k$-center Fair Clustering", "abstract": "In this paper, we study the problem of fair clustering on the $k-$center objective. In fair clustering, the input is $N$ points, each belonging to at least one of $l$ protected groups, e.g. male, female, Asian, Hispanic. The objective is to cluster the $N$ points into $k$ clusters to minimize a classical clustering objective function. However, there is an additional constraint that each cluster needs to be fair, under some notion of fairness. This ensures that no group is either ``over-represented'' or ``under-represented'' in any cluster. Our work builds on the work of Chierichetti et al. (NIPS 2017), Bera et al. (NeurIPS 2019), Ahmadian et al. (KDD 2019), and Bercea et al. (APPROX 2019). We obtain a randomized $3-$approximation algorithm for the $k-$center objective function, beating the previous state of the art ($4-$approximation). We test our algorithm on real datasets, and show that our algorithm is effective in finding good clusters without over-representation or under-representation, surpassing the current state of the art in runtime speed, clustering cost, while achieving similar fairness violations."}}
{"id": "EeBgh4q2SGu", "cdate": 1577836800000, "mdate": 1681675440567, "content": {"title": "Speeding up the AIFV-2 dynamic programs by two orders of magnitude using Range Minimum Queries", "abstract": "AIFV-$2$ codes are a new method for constructing lossless codes for memoryless sources that provide better worst-case redundancy than Huffman codes. They do this by using two code trees instead of one and also allowing some bounded delay in the decoding process. Known algorithms for constructing AIFV-code are iterative; at each step they replace the current code tree pair with a \"better\" one. The current state of the art for performing this replacement is a pair of Dynamic Programming (DP) algorithms that use $O(n^5)$ time to fill in two tables, each of size $O(n^3)$ (where $n$ is the number of different characters in the source). This paper describes how to reduce the time for filling in the DP tables by two orders of magnitude, down to $O(n^3)$. It does this by introducing a grouping technique that permits separating the $\\Theta(n^3)$-space tables into $\\Theta(n)$ groups, each of size $O(n^2)$, and then using Two-Dimensional Range-Minimum Queries (RMQs) to fill in that group's table entries in $O(n^2)$ time. This RMQ speedup technique seems to be new and might be of independent interest."}}
{"id": "zWN7ZbPX5s", "cdate": 1546300800000, "mdate": 1681675440519, "content": {"title": "Polynomial Time Algorithms for Constructing Optimal AIFV Codes", "abstract": "Huffman Codes are \"optimal\" Fixed-to-Variable (FV) codes if every source symbol can only be encoded by one codeword. Relaxing this constraint permits constructing better FV codes. More specifically, recent work has shown that AIFV codes can beat Huffman coding. AIFV codes construct a set of different coding trees between which the code alternates and are only \"almost instantaneous\" (AI). This means that decoding a word might require a delay of a finite number of bits. Current algorithms for constructing optimal AIFV codes are iterative processes that construct progressively \"better sets\" of code trees. The processes have been proven to finitely converge to the optimal code but with no known bounds on the convergence time. This paper derives a geometric interpretation of the space of AIFV codes. This permits the development of new polynomially time-bounded iterative procedures for constructing optimal AIFV codes. For the simplest case we show that a binary search procedure can replace the current iterative process. For the more complicated cases we describe how to frame the problem as a linear programming problem with an exponential number of constraints but a polynomial time separability oracle. This permits using the Grotschel, Lovasz and Schrijver ellipsoid method to solve the problem in a polynomial number of steps."}}
