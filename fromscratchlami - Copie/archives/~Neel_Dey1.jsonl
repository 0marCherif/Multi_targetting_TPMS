{"id": "KolMbwNBNGv", "cdate": 1673287855023, "mdate": null, "content": {"title": "Data Consistent Deep Rigid MRI Motion Correction", "abstract": "Motion artifacts are a pervasive problem in MRI, leading to misdiagnosis or mischaracterization in population-level imaging studies. Current retrospective rigid intra-slice motion correction techniques jointly optimize estimates of the image and the motion parameters. In this paper, we use a deep network to reduce the joint image-motion parameter search to a search over rigid motion parameters alone. Our network produces a reconstruction as a function of two inputs: corrupted k-space data and motion parameters. We train the network using simulated, motion-corrupted k-space data generated from known motion parameters. At test-time, we estimate unknown motion parameters by minimizing a data consistency loss between the motion parameters, the network-based image reconstruction given those parameters, and the acquired measurements. Intra-slice motion correction experiments on simulated and realistic 2D fast spin echo brain MRI achieve high reconstruction fidelity while retaining the benefits of explicit data consistency-based optimization."}}
{"id": "lri_iAbpn_r", "cdate": 1673287852393, "mdate": null, "content": {"title": "E(3) x SO(3) - Equivariant Networks for Spherical Deconvolution in Diffusion MRI", "abstract": "We present Roto-Translation Equivariant Spherical Deconvolution (RT-ESD), an $E(3)\\times SO(3)$ equivariant framework for sparse deconvolution of volumes where each voxel contains a spherical signal. Such 6D data naturally arises in diffusion MRI (dMRI), a medical imaging modality widely used to measure microstructure and structural connectivity. As each dMRI voxel is typically a mixture of various overlapping structures, there is a need for blind deconvolution to recover crossing anatomical structures such as white matter tracts. Existing dMRI work takes either an iterative or deep learning approach to sparse spherical deconvolution, yet it typically does not account for relationships between neighboring measurements. This work constructs equivariant deep learning layers which respect to symmetries of spatial rotations, reflections, and translations, alongside the symmetries of voxelwise spherical rotations. As a result, RT-ESD improves on previous work across several tasks including fiber recovery on the DiSCo dataset, deconvolution-derived partial volume estimation on real-world in vivo human brain dMRI, and improved downstream reconstruction of fiber tractograms on the Tractometer dataset. Our implementation is available at \\url{https://github.com/AxelElaldi/e3so3_conv}."}}
{"id": "1xqE9fRZch5", "cdate": 1652737422082, "mdate": null, "content": {"title": "Local Spatiotemporal Representation Learning for Longitudinally-consistent Neuroimage Analysis", "abstract": "Recent self-supervised advances in medical computer vision exploit the global and local anatomical self-similarity for pretraining prior to downstream tasks such as segmentation. However, current methods assume i.i.d. image acquisition, which is invalid in clinical study designs where follow-up longitudinal scans track subject-specific temporal changes. Further, existing self-supervised methods for medically-relevant image-to-image architectures exploit only spatial or temporal self-similarity and do so via a loss applied only at a single image-scale, with naive multi-scale spatiotemporal extensions collapsing to degenerate solutions. To these ends, this paper makes two contributions: (1) It presents a local and multi-scale spatiotemporal representation learning method for image-to-image architectures trained on longitudinal images. It exploits the spatiotemporal self-similarity of learned multi-scale intra-subject image features for pretraining and develops several feature-wise regularizations that avoid degenerate representations; (2) During finetuning, it proposes a surprisingly simple self-supervised segmentation consistency regularization to exploit intra-subject correlation. Benchmarked across various segmentation tasks, the proposed framework outperforms both well-tuned randomly-initialized baselines and current self-supervised techniques designed for both i.i.d. and longitudinal datasets. These improvements are demonstrated across both longitudinal neurodegenerative adult MRI and developing infant brain MRI and yield both higher performance and longitudinal consistency."}}
{"id": "j7LKmb3_b8", "cdate": 1640995200000, "mdate": 1668176750440, "content": {"title": "DSFormer: A Dual-domain Self-supervised Transformer for Accelerated Multi-contrast MRI Reconstruction", "abstract": ""}}
{"id": "dJvshft6ByR", "cdate": 1640995200000, "mdate": 1668176750441, "content": {"title": "Local Spatiotemporal Representation Learning for Longitudinally-consistent Neuroimage Analysis", "abstract": ""}}
{"id": "LmV6bwtl7O", "cdate": 1640995200000, "mdate": 1668176750497, "content": {"title": "ContraReg: Contrastive Learning of Multi-modality Unsupervised Deformable Image Registration", "abstract": ""}}
{"id": "GjbgrE-Zje", "cdate": 1640995200000, "mdate": 1668176750447, "content": {"title": "ContraReg: Contrastive Learning of Multi-modality Unsupervised Deformable Image Registration", "abstract": ""}}
{"id": "1rAXJxBBVN", "cdate": 1640995200000, "mdate": 1668176750447, "content": {"title": "Dual-domain self-supervised learning for accelerated non-Cartesian MRI reconstruction", "abstract": ""}}
{"id": "udN9OEzp-Ll", "cdate": 1609459200000, "mdate": 1668176750463, "content": {"title": "Point-supervised Segmentation of Microscopy Images and Volumes via Objectness Regularization", "abstract": ""}}
{"id": "j7tDCUkbOi", "cdate": 1609459200000, "mdate": 1639270223494, "content": {"title": "Q-space Conditioned Translation Networks for Directional Synthesis of Diffusion Weighted Images from Multi-modal Structural MRI", "abstract": "Current deep learning approaches for diffusion MRI modeling circumvent the need for densely-sampled diffusion-weighted images (DWIs) by directly predicting microstructural indices from sparsely-sampled DWIs. However, they implicitly make unrealistic assumptions of static q-space sampling during training and reconstruction. Further, such approaches can restrict downstream usage of variably sampled DWIs for usages including the estimation of microstructural indices or tractography. We propose a generative adversarial translation framework for high-quality DWI synthesis with arbitrary q-space sampling given commonly acquired structural images (e.g., B0, T1, T2). Our translation network linearly modulates its internal representations conditioned on continuous q-space information, thus removing the need for fixed sampling schemes. Moreover, this approach enables downstream estimation of high-quality microstructural maps from arbitrarily subsampled DWIs, which may be particularly important in cases with sparsely sampled DWIs. Across several recent methodologies, the proposed approach yields improved DWI synthesis accuracy and fidelity with enhanced downstream utility as quantified by the accuracy of scalar microstructure indices estimated from the synthesized images. Code is available at https://github.com/mengweiren/q-space-conditioned-dwi-synthesis ."}}
