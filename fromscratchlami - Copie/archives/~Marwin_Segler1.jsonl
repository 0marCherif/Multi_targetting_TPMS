{"id": "nFHICo4JXp", "cdate": 1684142421976, "mdate": 1684142421976, "content": {"title": "Machine learning the ropes: principles, applications and directions in synthetic chemistry", "abstract": "Machine learning (ML) has emerged as a general, problem-solving paradigm with many applications in computer vision, natural language processing, digital safety, or medicine. By recognizing complex patterns in data, ML bears the potential to modernise the way how many chemical challenges are approached. In this review, an introduction to ML is given from the perspective of synthetic chemistry: starting from the fundamentals regarding algorithms and best-practice workflows, the review covers different applications of machine learning in synthesis planning, property prediction, molecular design, and reactivity prediction. In particular, different approaches of representing and utilizing organic molecules will be discussed \u2013 providing synthetic chemists both with the understanding and the tools required to apply machine learning in the context of their research, and pointers for further studying."}}
{"id": "8VLeT8DFeD", "cdate": 1664248832584, "mdate": null, "content": {"title": "Re-Evaluating Chemical Synthesis Planning Algorithms", "abstract": "Computer-Aided Chemical Synthesis Planning (CASP) algorithms have the potential to help chemists predict how to make molecules, and decide which molecules to prioritize for synthesis and testing. \nRecently, several algorithms have been proposed to tackle this problem, reporting large performance improvements. \nIn this work, we re-examine current and prior State-of-the-Art synthesis planning algorithms under controlled and identical conditions, providing a holistic view using several previously un-reported evaluation metrics which cover the common use-cases of these algorithms. \nIn contrast to prior studies, we find that under strict control, differences between algorithms are smaller than previously assumed. \nOur findings can guide users to choose the appropriate algorithms for specific tasks, as well as stimulate new research in improved algorithms."}}
{"id": "JLLqwx6OxKE", "cdate": 1636633891549, "mdate": 1636633891549, "content": {"title": "Molecular representation learning with language models and domain-relevant auxiliary tasks", "abstract": "We apply a Transformer architecture, specifically BERT, to learn flexible and high quality molecular representations for drug discovery problems. We study the impact of using different combinations of self-supervised tasks for pre-training, and present our results for the established Virtual Screening and QSAR benchmarks. We show that: i) The selection of appropriate self-supervised task(s) for pre-training has a significant impact on performance in subsequent downstream tasks such as Virtual Screening. ii) Using auxiliary tasks with more domain relevance for Chemistry, such as learning to predict calculated molecular properties, increases the fidelity of our learnt representations. iii) Finally, we show that molecular representations learnt by our model `MolBert' improve upon the current state of the art on the benchmark datasets.\n"}}
{"id": "ZTsoE8G3GG", "cdate": 1632875630480, "mdate": null, "content": {"title": "Learning to Extend Molecular Scaffolds with Structural Motifs", "abstract": "Recent advancements in deep learning-based modeling of molecules promise to accelerate in silico drug discovery. A plethora of generative models is available, building molecules either atom-by-atom and bond-by-bond or fragment-by-fragment. However, many drug discovery projects require a fixed scaffold to be present in the generated molecule, and incorporating that constraint has only recently been explored. Here, we propose MoLeR, a graph-based model that naturally supports scaffolds as initial seed of the generative procedure, which is possible because it is not conditioned on the generation history. Our experiments show that MoLeR performs comparably to state-of-the-art methods on unconstrained molecular optimization tasks, and outperforms them on scaffold-based tasks, while being an order of magnitude faster to train and sample from than existing approaches. Furthermore, we show the influence of a number of seemingly minor design choices on the overall performance."}}
{"id": "701FtuyLlAd", "cdate": 1629919760063, "mdate": null, "content": {"title": "FS-Mol: A Few-Shot Learning Dataset of Molecules", "abstract": "Small datasets are ubiquitous in drug discovery as data generation is expensive and can be restricted for ethical reasons (e.g. in vivo experiments). A widely applied technique in early drug discovery to identify novel active molecules against a protein target is modelling quantitative structure-activity relationships (QSAR). It is known to be extremely challenging, as available measurements of compound activities range in the low dozens or hundreds. However, many such related datasets exist, each with a small number of datapoints, opening up the opportunity for few-shot learning after pre-training on a substantially larger corpus of data. At the same time, many few-shot learning methods are currently evaluated in the computer-vision domain. We propose that expansion into a new application, as well as the possibility to use explicitly graph-structured data, will drive exciting progress in few-shot learning. Here, we provide a few-shot learning dataset (FS-Mol) and complementary benchmarking procedure. We define a set of tasks on which few-shot learning methods can be evaluated, with a separate set of tasks for use in pre-training. In addition, we implement and evaluate a number of existing single-task, multi-task, and meta-learning approaches as baselines for the community. We hope that our dataset, support code release, and baselines will encourage future work on this extremely challenging new domain for few-shot learning."}}
{"id": "9JEA5uVwG9F", "cdate": 1625139611141, "mdate": 1625139611141, "content": {"title": "Barking up the right tree: an approach to search over molecule synthesis DAGs", "abstract": "When designing new molecules with particular properties, it is not only important what to make but crucially how to make it. These instructions form a synthesis directed acyclic graph (DAG), describing how a large vocabulary of simple building blocks can be recursively combined through chemical reactions to create more complicated molecules of interest. In contrast, many current deep generative models for molecules ignore synthesizability. We therefore propose a deep generative model that better represents the real world process, by directly outputting molecule synthesis DAGs. We argue that this provides sensible inductive biases, ensuring that our model searches over the same chemical space that chemists would also have access to, as well as interoperability. We show that our approach is able to model chemical space well, producing a wide range of diverse molecules, and allows for unconstrained optimization of an inherently constrained problem: maximize certain chemical properties such that discovered molecules are synthesizable."}}
{"id": "xAOVh_mG-I", "cdate": 1577836800000, "mdate": null, "content": {"title": "RetroGNN: Approximating Retrosynthesis by Graph Neural Networks for De Novo Drug Design", "abstract": "De novo molecule generation often results in chemically unfeasible molecules. A natural idea to mitigate this problem is to bias the search process towards more easily synthesizable molecules using a proxy for synthetic accessibility. However, using currently available proxies still results in highly unrealistic compounds. We investigate the feasibility of training deep graph neural networks to approximate the outputs of a retrosynthesis planning software, and their use to bias the search process. We evaluate our method on a benchmark involving searching for drug-like molecules with antibiotic properties. Compared to enumerating over five million existing molecules from the ZINC database, our approach finds molecules predicted to be more likely to be antibiotics while maintaining good drug-like properties and being easily synthesizable. Importantly, our deep neural network can successfully filter out hard to synthesize molecules while achieving a $10^5$ times speed-up over using the retrosynthesis planning software."}}
{"id": "h8fVA75HW60", "cdate": 1577836800000, "mdate": null, "content": {"title": "Molecular representation learning with language models and domain-relevant auxiliary tasks", "abstract": "We apply a Transformer architecture, specifically BERT, to learn flexible and high quality molecular representations for drug discovery problems. We study the impact of using different combinations of self-supervised tasks for pre-training, and present our results for the established Virtual Screening and QSAR benchmarks. We show that: i) The selection of appropriate self-supervised task(s) for pre-training has a significant impact on performance in subsequent downstream tasks such as Virtual Screening. ii) Using auxiliary tasks with more domain relevance for Chemistry, such as learning to predict calculated molecular properties, increases the fidelity of our learnt representations. iii) Finally, we show that molecular representations learnt by our model `MolBert' improve upon the current state of the art on the benchmark datasets."}}
{"id": "afuTIYBbK6", "cdate": 1577836800000, "mdate": null, "content": {"title": "Barking up the right tree: an approach to search over molecule synthesis DAGs", "abstract": "When designing new molecules with particular properties, it is not only important what to make but crucially how to make it. These instructions form a synthesis directed acyclic graph (DAG), describing how a large vocabulary of simple building blocks can be recursively combined through chemical reactions to create more complicated molecules of interest. In contrast, many current deep generative models for molecules ignore synthesizability. We therefore propose a deep generative model that better represents the real world process, by directly outputting molecule synthesis DAGs. We argue that this provides sensible inductive biases, ensuring that our model searches over the same chemical space that chemists would also have access to, as well as interpretability. We show that our approach is able to model chemical space well, producing a wide range of diverse molecules, and allows for unconstrained optimization of an inherently constrained problem: maximize certain chemical properties such that discovered molecules are synthesizable."}}
{"id": "FFXn6yXxlSi", "cdate": 1577836800000, "mdate": null, "content": {"title": "Barking up the right tree: an approach to search over molecule synthesis DAGs", "abstract": "When designing new molecules with particular properties, it is not only important what to make but crucially how to make it. These instructions form a synthesis directed acyclic graph (DAG), describing how a large vocabulary of simple building blocks can be recursively combined through chemical reactions to create more complicated molecules of interest. In contrast, many current deep generative models for molecules ignore synthesizability. We therefore propose a deep generative model that better represents the real world process, by directly outputting molecule synthesis DAGs. We argue that this provides sensible inductive biases, ensuring that our model searches over the same chemical space that chemists would also have access to, as well as interoperability. We show that our approach is able to model chemical space well, producing a wide range of diverse molecules, and allows for unconstrained optimization of an inherently constrained problem: maximize certain chemical properties such that discovered molecules are synthesizable."}}
