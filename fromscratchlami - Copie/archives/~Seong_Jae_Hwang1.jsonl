{"id": "S0lx6I8j9xq", "cdate": 1646077524695, "mdate": null, "content": {"title": "PAC-Bayesian Domain Adaptation Bounds for Multiclass Learners", "abstract": "Multiclass neural networks are a common tool in modern unsupervised domain adaptation, yet an appropriate theoretical description for their non-uniform sample complexity is lacking in the adaptation literature. To fill this gap, we propose the first PAC-Bayesian adaptation bounds for multiclass learners. We facilitate practical use of our bounds by also proposing the first approximation techniques for the multiclass distribution divergences we consider. For divergences dependent on a Gibbs predictor, we propose additional PAC-Bayesian adaptation bounds which remove the need for inefficient Monte-Carlo estimation. Empirically, we test the efficacy of our proposed approximation techniques as well as some novel design-concepts which we include in our bounds. Finally, we apply our bounds to analyze a common adaptation algorithm that uses neural networks."}}
{"id": "jgBzGIG-kB", "cdate": 1617809095914, "mdate": null, "content": {"title": "Cycle Consistent Embedding of 3D Brains with Auto-Encoding Generative Adversarial Networks", "abstract": "Modern generative adversarial networks (GANs) have been enabling the realistic generation of full 3D brain images by sampling from a latent space prior $\\mathcal{Z}$ (i.e., random vectors) and mapping it to realistic images in $\\mathcal{X}$ (e.g., 3D MRIs). To address the ubiquitous mode collapse issue, recent works have strongly imposed certain characteristics such as Gaussianness to the prior by also explicitly mapping $\\mathcal{X}$ to $\\mathcal{Z}$ via encoder. These efforts, however, fail to accurately map 3D brain images to the desirable prior, which the generator assumes to be sampling the random vectors from. On the other hand, Variational Auto-Encoding GAN (VAE-GAN) solves mode collapse by enforcing Gaussianness by two learned parameter, yet causes blurriness in images. In this work, we show how our \\textit{cycle consistent embedding} GAN (CCE-GAN) both accurately encodes 3D MRIs to the standard normal prior, and maintains the quality of the generated images. We achieve this without a network-based code discriminator via the Wasserstein measure. We quantitatively and qualitatively assess the embeddings and the generated 3D MRIs using healthy T1-weighted MRIs from ADNI."}}
{"id": "DkCvYVwJHjb", "cdate": 1595260909565, "mdate": null, "content": {"title": "Classifying Nuclei Shape Heterogeneity in Breast Tumors with Skeletons", "abstract": "In this study, we demonstrate the efficacy of scoring statistics derived from a medial axis transform, for differentiating tumor and non-tumor nuclei, in malignant breast tumor histopathology images. Characterizing nuclei shape is a crucial part of diagnosing breast tumors for human doctors, and these scoring metrics may be integrated into machine perception algorithms which aggregate nuclei information across a region to label whole breast lesions. In particular, we present a low-dimensional representation capturing characteristics of a skeleton extracted from nuclei. We show that this representation outperforms both prior morphological features, as well as CNN features, for classification of tumors. Nuclei and region scoring algorithms such as the one presented here can aid pathologists in the diagnosis of breast tumors. "}}
{"id": "HyWCHpWOWS", "cdate": 1514764800000, "mdate": null, "content": {"title": "Tensorize, Factorize and Regularize: Robust Visual Relationship Learning", "abstract": "Visual relationships provide higher-level information of objects and their relations in an image \u2013 this enables a semantic understanding of the scene and helps downstream applications. Given a set of localized objects in some training data, visual relationship detection seeks to detect the most likely \u201crelationship\u201d between objects in a given image. While the specific objects may be well represented in training data, their relationships may still be infrequent. The empirical distribution obtained from seeing these relationships in a dataset does not model the underlying distribution well \u2014 a serious issue for most learning methods. In this work, we start from a simple multi-relational learning model, which in principle, offers a rich formalization for deriving a strong prior for learning visual relationships. While the inference problem for deriving the regularizer is challenging, our main technical contribution is to show how adapting recent results in numerical linear algebra lead to efficient algorithms for a factorization scheme that yields highly informative priors. The factorization provides sample size bounds for inference (under mild conditions) for the underlying [[object, predicate, object]] relationship learning task on its own and surprisingly outperforms (in some cases) existing methods even without utilizing visual features. Then, when integrated with an end to-end architecture for visual relationship detection leveraging image data, we substantially improve the state-of-the-art."}}
{"id": "HyVz1eGObH", "cdate": 1483228800000, "mdate": null, "content": {"title": "Online Graph Completion: Multivariate Signal Recovery in Computer Vision", "abstract": "The adoption of human-in-the-loop paradigms in computer vision and machine learning is leading to various applications where the actual data acquisition (e.g., human supervision) and the underlying inference algorithms are closely interwined. While classical work in active learning provides effective solutions when the learning module involves classification and regression tasks, many practical issues such as partially observed measurements, financial constraints and even additional distributional or structural aspects of the data typically fall outside the scope of this treatment. For instance, with sequential acquisition of partial measurements of data that manifest as a matrix (or tensor), novel strategies for completion (or collaborative filtering) of the remaining entries have only been studied recently. Motivated by vision problems where we seek to annotate a large dataset of images via a crowdsourced platform or alternatively, complement results from a state-of-the-art object detector using human feedback, we study the completion problem defined on graphs, where requests for additional measurements must be made sequentially. We design the optimization model in the Fourier domain of the graph describing how ideas based on adaptive submodularity provide algorithms that work well in practice. On a large set of images collected from Imgur, we see promising results on images that are otherwise difficult to categorize. We also show applications to an experimental design problem in neuroimaging."}}
{"id": "HkbKYtbdWr", "cdate": 1451606400000, "mdate": null, "content": {"title": "Adaptive Signal Recovery on Graphs via Harmonic Analysis for Experimental Design in Neuroimaging", "abstract": "Consider an experimental design of a neuroimaging study, where we need to obtain p measurements for each participant in a setting where $$p^\\prime (< p)$$ are cheaper and easier to acquire while the remaining $$(p-p^\\prime )$$ are expensive. For example, the $$p^{\\prime }$$ measurements may include demographics, cognitive scores or routinely offered imaging scans while the $$(p-p^{\\prime })$$ measurements may correspond to more expensive types of brain image scans with a higher participant burden. In this scenario, it seems reasonable to seek an \u201cadaptive\u201d design for data acquisition so as to minimize the cost of the study without compromising statistical power. We show how this problem can be solved via harmonic analysis of a band-limited graph whose vertices correspond to participants and our goal is to fully recover a multi-variate signal on the nodes, given the full set of cheaper features and a partial set of more expensive measurements. This is accomplished using an adaptive query strategy derived from probing the properties of the graph in the frequency space. To demonstrate the benefits that this framework can provide, we present experimental evaluations on two independent neuroimaging studies and show that our proposed method can reliably recover the true signal with only partial observations directly yielding substantial financial savings."}}
{"id": "H1-ahCbdbS", "cdate": 1451606400000, "mdate": null, "content": {"title": "Coupled Harmonic Bases for Longitudinal Characterization of Brain Networks", "abstract": "There is a great deal of interest in using large scale brain imaging studies to understand how brain connectivity evolves over time for an individual and how it varies over different levels/quantiles of cognitive function. To do so, one typically performs so-called tractography procedures on diffusion MR brain images and derives measures of brain connectivity expressed as graphs. The nodes correspond to distinct brain regions and the edges encode the strength of the connection. The scientific interest is in characterizing the evolution of these graphs over time or from healthy individuals to diseased. We pose this important question in terms of the Laplacian of the connectivity graphs derived from various longitudinal or disease time points - quantifying its progression is then expressed in terms of coupling the harmonic bases of a full set of Laplacians. We derive a coupled system of generalized eigenvalue problems (and corresponding numerical optimization schemes) whose solution helps characterize the full life cycle of brain connectivity evolution in a given dataset. Finally, we show a set of results on a diffusion MR imaging dataset of middle aged people at risk for Alzheimer's disease (AD), who are cognitively healthy. In such asymptomatic adults, we find that a framework for characterizing brain connectivity evolution provides the ability to predict cognitive scores for individual subjects, and for estimating the progression of participant's brain connectivity into the future."}}
{"id": "HJ-MoxG_ZB", "cdate": 1420070400000, "mdate": null, "content": {"title": "A Projection Free Method for Generalized Eigenvalue Problem with a Nonsmooth Regularizer", "abstract": "Eigenvalue problems are ubiquitous in computer vision, covering a very broad spectrum of applications ranging from estimation problems in multi-view geometry to image segmentation. Few other linear algebra problems have a more mature set of numerical routines available and many computer vision libraries leverage such tools extensively. However, the ability to call the underlying solver only as a \"black box\" can often become restrictive. Many 'human in the loop' settings in vision frequently exploit supervision from an expert, to the extent that the user can be considered a subroutine in the overall system. In other cases, there is additional domain knowledge, side or even partial information that one may want to incorporate within the formulation. In general, regularizing a (generalized) eigenvalue problem with such side information remains difficult. Motivated by these needs, this paper presents an optimization scheme to solve generalized eigenvalue problems (GEP) involving a (nonsmooth) regularizer. We start from an alternative formulation of GEP where the feasibility set of the model involves the Stiefel manifold. The core of this paper presents an end to end stochastic optimization scheme for the resultant problem. We show how this general algorithm enables improved statistical analysis of brain imaging data where the regularizer is derived from other 'views' of the disease pathology, involving clinical measurements and other image-derived representations."}}
