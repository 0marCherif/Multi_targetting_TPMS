{"id": "OHv-vlgXQOv", "cdate": 1669838472988, "mdate": null, "content": {"title": "Black-Box vs. Gray-Box: A Case Study on Learning Table Tennis Ball Trajectory Prediction with Spin and Impacts", "abstract": "In this paper, we present a method for table tennis ball trajectory filtering and prediction. Our gray-box approach builds on a physical model. At the same time, we use data to learn parameters of the dynamics model, of an extended Kalman filter, and of a neural model that infers the ball's initial condition. We demonstrate superior prediction performance of our approach over two black-box approaches, which are not supplied with physical prior knowledge. We demonstrate that initializing the spin from parameters of the ball launcher using a neural network drastically improves long-time prediction performance over estimating the spin purely from measured ball positions. An accurate prediction of the ball trajectory is crucial for successful returns. We therefore evaluate the return performance with a pneumatic artificial muscular robot and achieve a return rate of 29/30 (97.7%)."}}
{"id": "t-IO7wCaNgH", "cdate": 1655376335409, "mdate": null, "content": {"title": "Learning Temporally Extended Skills in Continuous Domains as Symbolic Actions for Planning", "abstract": "Problems which require both long-horizon planning and continuous control capabilities pose significant challenges to existing reinforcement learning agents. In this paper we introduce a novel hierarchical reinforcement learning agent which links temporally extended skills for continuous control with a forward model in a symbolic discrete abstraction of the environment's state for planning. We term our agent SEADS for Symbolic Effect-Aware Diverse Skills. We formulate an objective and corresponding algorithm which leads to unsupervised learning of a diverse set of skills through intrinsic motivation given a known state abstraction. The skills are jointly learned with the symbolic forward model which captures the effect of skill execution in the state abstraction. After training, we can leverage the skills as symbolic actions using the forward model for long-horizon planning and subsequently execute the plan using the learned continuous-action control skills. The proposed algorithm learns skills and forward models that can be used to solve complex tasks which require both continuous control and long-horizon planning capabilities with high success rate. It compares favorably with other flat and hierarchical reinforcement learning baseline agents and is successfully demonstrated with a real robot."}}
{"id": "USm6CxJ2bPI", "cdate": 1609459200000, "mdate": null, "content": {"title": "Explore the Context: Optimal Data Collection for Context-Conditional Dynamics Models", "abstract": "In this paper, we learn dynamics models for parametrized families of dynamical systems with varying properties. The dynamics models are formulated as stochastic processes conditioned on a latent context variable which is inferred from observed transitions of the respective system. The probabilistic formulation allows us to compute an action sequence which, for a limited number of environment interactions, optimally explores the given system within the parametrized family. This is achieved by steering the system through transitions being most informative for the context variable. We demonstrate the effectiveness of our method for exploration on a non-linear toy-problem and two well-known reinforcement learning environments."}}
{"id": "3Du_qlP2FDr", "cdate": 1591623882119, "mdate": null, "content": {"title": "Planning from Images with Deep Latent Gaussian Process Dynamics", "abstract": "Planning is a powerful approach to control problems with known environment dynamics. In unknown environments the agent needs to learn a model of the system dynamics to make planning applicable. This is particularly challenging when the underlying states are only indirectly observable through high-dimensional observations such as images. We propose to learn a deep latent Gaussian process dynamics (DLGPD) model that learns low-dimensional system dynamics from environment interactions with visual observations. The method infers latent state representations from observations using neural networks and models the system dynamics in the learned latent space with Gaussian processes. All parts of the model can be trained jointly by optimizing a lower bound on the likelihood of transitions in image space. We evaluate the proposed approach on the pendulum swing-up task while using the learned dynamics model for planning in latent space in order to solve the control problem. We also demonstrate that our method can quickly adapt a trained agent to changes in the system dynamics from just a few rollouts. We compare our approach to a state-of-the-art purely deep learning based method and demonstrate the advantages of combining Gaussian processes with deep learning for data efficiency and transfer learning."}}
{"id": "BzX7IuGkdwD", "cdate": 1577836800000, "mdate": null, "content": {"title": "Sample-efficient Cross-Entropy Method for Real-time Planning", "abstract": "Trajectory optimizers for model-based reinforcement learning, such as the Cross-Entropy Method (CEM), can yield compelling results even in high-dimensional control tasks and sparse-reward environments. However, their sampling inefficiency prevents them from being used for real-time planning and control. We propose an improved version of the CEM algorithm for fast planning, with novel additions including temporally-correlated actions and memory, requiring 2.7-22x less samples and yielding a performance increase of 1.2-10x in high-dimensional control problems."}}
{"id": "4CJT2niSykO", "cdate": 1577836800000, "mdate": null, "content": {"title": "Numerical Quadrature for Probabilistic Policy Search", "abstract": "Learning control policies has become an appealing alternative to the derivation of control laws based on classic control theory. Model-based approaches have proven an outstanding data efficiency, especially when combined with probabilistic models to eliminate model bias. However, a major difficulty for these methods is that multi-step-ahead predictions typically become intractable for larger planning horizons and can only poorly be approximated. In this paper, we propose the use of numerical quadrature to overcome this drawback and provide significantly more accurate multi-step-ahead predictions. As a result, our approach increases data efficiency and enhances the quality of learned policies. Furthermore, policy learning is not restricted to optimizing locally around one trajectory, as numerical quadrature provides a principled approach to extend optimization to all trajectories starting in a specified starting state region. Thus, manual effort, such as choosing informative starting points for simultaneous policy optimization, is significantly decreased. Furthermore, learning is highly robust to the choice of initial policy and, thus, interaction time with the system is minimized. Empirical evaluations on simulated benchmark problems show the efficiency of the proposed approach and support our theoretical results."}}
{"id": "-PTdAEBNY8", "cdate": 1577836800000, "mdate": null, "content": {"title": "Learning to Identify Physical Parameters from Video Using Differentiable Physics", "abstract": "Video representation learning has recently attracted attention in computer vision due to its applications for activity and scene forecasting or vision-based planning and control. Video prediction models often learn a latent representation of video which is encoded from input frames and decoded back into images. Even when conditioned on actions, purely deep learning based architectures typically lack a physically interpretable latent space. In this study, we use a differentiable physics engine within an action-conditional video representation network to learn a physical latent representation. We propose supervised and self-supervised learning methods to train our network and identify physical properties. The latter uses spatial transformers to decode physical states back into images. The simulation scenarios in our experiments comprise pushing, sliding and colliding objects, for which we also analyze the observability of the physical properties. In experiments we demonstrate that our network can learn to encode images and identify physical properties like mass and friction from videos and action sequences in the simulated scenarios. We evaluate the accuracy of our supervised and self-supervised methods and compare it with a system identification baseline which directly learns from state trajectories. We also demonstrate the ability of our method to predict future video frames from input images and actions."}}
{"id": "ry-TW-WAb", "cdate": 1518730169696, "mdate": null, "content": {"title": "Variational Network Quantization", "abstract": "In this paper, the preparation of a neural network for pruning and few-bit quantization is formulated as a variational inference problem. To this end, a quantizing prior that leads to a multi-modal, sparse posterior distribution over weights, is introduced and a differentiable Kullback-Leibler divergence approximation for this prior is derived. After training with Variational Network Quantization, weights can be replaced by deterministic quantization values with small to negligible loss of task accuracy (including pruning by setting weights to 0). The method does not require fine-tuning after quantization. Results are shown for ternary quantization on LeNet-5 (MNIST) and DenseNet (CIFAR-10)."}}
{"id": "Z70qtCgg7aW", "cdate": 1451606400000, "mdate": null, "content": {"title": "Robust calibration marker detection in powder bed images from laser beam melting processes", "abstract": "Laser beam melting (LBM) systems produce parts by melting metal powder according to the sliced 3D geometry using a laser. After each layer, new powder is deposited and the process is repeated. Process monitoring via acquisition and analysis of layer images during the build job is a promising approach to thorough quality control for LBM. Image analysis requires orthographic images, which are usually not available as the camera cannot be placed directly above the build layer due to the position of the laser window. The resulting perspective distortions have to be corrected before analysis. To this end we compute a homography from four circular markers which are \"drawn\" into the powder bed by the machine's laser and detected in the acquired images. In this work we present a robust method for the automatic detection of calibration markers, which deals with the noise-like powder regions, disconnected lines, visible support structures and blurred image regions. Our homography estimation method minimizes the shape error between transformed circular reference marker shapes and detected elliptical markers yielding an image with correct aspect ratio and minimal distortions. Our method achieves a detection rate of 96.3 % and a spatial detection error of 2.0 pixels (median, 95 %-percentile: 5.17pixels) compared to a manually created ground truth."}}
