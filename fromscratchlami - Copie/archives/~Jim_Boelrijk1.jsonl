{"id": "AlajIo2-rzf", "cdate": 1701388800000, "mdate": 1683640970548, "content": {"title": "Predicting RP-LC retention indices of structurally unknown chemicals from mass spectrometry data", "abstract": "Non-target analysis combined with liquid chromatography high resolution mass spectrometry is considered one of the most comprehensive strategies for the detection and identification of known and unknown chemicals in complex samples. However, many compounds remain unidentified due to data complexity and limited number structures in chemical databases. In this work, we have developed and validated a novel machine learning algorithm to predict the retention index (r $$_i$$ i ) values for structurally (un)known chemicals based on their measured fragmentation pattern. The developed model, for the first time, enabled the predication of r $$_i$$ i values without the need for the exact structure of the chemicals, with an $$R^2$$ R 2 of 0.91 and 0.77 and root mean squared error (RMSE) of 47 and 67 r $$_i$$ i units for the NORMAN ( $$n=3131$$ n = 3131 ) and amide ( $$n=604$$ n = 604 ) test sets, respectively. This fragment based model showed comparable accuracy in r $$_i$$ i prediction compared to conventional descriptor-based models that rely on known chemical structure, which obtained an $$R^2$$ R 2 of 0.85 with an RMSE of 67."}}
{"id": "fSa5IjNMmmi", "cdate": 1663850300838, "mdate": null, "content": {"title": "Multi-objective optimization via equivariant deep hypervolume approximation", "abstract": "Optimizing multiple competing objectives is a common problem across science and industry. The inherent inextricable trade-off between those objectives leads one to the task of exploring their Pareto front. A meaningful quantity for the purpose of the latter is the hypervolume indicator, which is used in Bayesian Optimization (BO) and Evolutionary Algorithms (EAs). However, the computational complexity for the calculation of the hypervolume scales unfavorably with increasing number of objectives and data points, which restricts its use in those common multi-objective optimization frameworks. \nTo overcome these restrictions, previous work has focused on approximating the hypervolume using deep learning. In this work, we propose a novel deep learning architecture to approximate the hypervolume function, which we call DeepHV. For better sample efficiency and generalization, we exploit the fact that the hypervolume is scale equivariant in each of the objectives as well as permutation invariant w.r.t. both the objectives and the samples, by using a deep neural network that is equivariant w.r.t. the combined group of scalings and permutations. We show through an ablation study that including these symmetries leads to significantly improved model accuracy. \nWe evaluate our method against exact, and approximate hypervolume methods in terms of accuracy, computation time, and generalization. We also apply and compare our methods to state-of-the-art multi-objective BO methods and EAs on a range of synthetic and real-world benchmark test cases. The results show that our methods are promising for such multi-objective optimization tasks."}}
{"id": "geFWmW982dp", "cdate": 1640995200000, "mdate": 1683640970551, "content": {"title": "Multi-objective optimization via equivariant deep hypervolume approximation", "abstract": "Optimizing multiple competing objectives is a common problem across science and industry. The inherent inextricable trade-off between those objectives leads one to the task of exploring their Pareto front. A meaningful quantity for the purpose of the latter is the hypervolume indicator, which is used in Bayesian Optimization (BO) and Evolutionary Algorithms (EAs). However, the computational complexity for the calculation of the hypervolume scales unfavorably with increasing number of objectives and data points, which restricts its use in those common multi-objective optimization frameworks. To overcome these restrictions we propose to approximate the hypervolume function with a deep neural network, which we call DeepHV. For better sample efficiency and generalization, we exploit the fact that the hypervolume is scale-equivariant in each of the objectives as well as permutation invariant w.r.t. both the objectives and the samples, by using a deep neural network that is equivariant w.r.t. the combined group of scalings and permutations. We evaluate our method against exact, and approximate hypervolume methods in terms of accuracy, computation time, and generalization. We also apply and compare our methods to state-of-the-art multi-objective BO methods and EAs on a range of synthetic benchmark test cases. The results show that our methods are promising for such multi-objective optimization tasks."}}
