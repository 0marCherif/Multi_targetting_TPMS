{"id": "IMAQh7lhGDI", "cdate": 1682899200000, "mdate": 1682495677678, "content": {"title": "Quantification of body ownership awareness induced by the visual movement illusion of the lower limbs: a study of electroencephalogram and surface electromyography", "abstract": "The visual movement illusion (VMI) is a subjective experience. This illusion is produced by watching the subject\u2019s motion video. At the same time, VMI evokes awareness of body ownership. We applied the power spectral density (PSD) matrix and the partial directed correlation (PDC) matrix to build the PPDC matrix for the \u03b32 band (34\u201398.5 Hz), combining cerebral cortical and musculomotor cortical complexity and PPDC to quantify the degree of body ownership. Thirty-five healthy subjects were recruited to participate in this experiment. The subjects\u2019 electroencephalography (EEG) and surface electromyography (sEMG) data were recorded under resting conditions, observation conditions, illusion conditions, and actual seated front-kick movements. The results show the following: (1) VMI activates the cerebral cortex to some extent; (2) VMI enhances cortical muscle excitability in the rectus femoris and medial vastus muscles; (3) VMI induces a sense of body ownership; (4) the use of PPDC values, fuzzy entropy values of muscles, and fuzzy entropy values of the cerebral cortex can quantify whether VMI induces awareness of body ownership. These results illustrate that PPDC can be used as a biomarker to show that VMI affects changes in the cerebral cortex and as a quantitative tool to show whether body ownership awareness arises. Graphical abstract"}}
{"id": "GQhJkeDPpnJ", "cdate": 1682899200000, "mdate": 1682495677644, "content": {"title": "EEG-based emotion recognition with cascaded convolutional recurrent neural networks", "abstract": "In recent years, deep learning has gradually become a prevailing way in EEG-based emotion recognition research because it can extract features and classify emotions automatically. To fully exploit the underlying information in EEG signals, we propose an emotion recognition method based on cascaded convolutional recurrent neural networks. Firstly, the differential entropy features of each channel signal are transformed into four-dimensional structure data, which are able to contain temporal-spatial-frequency information integratively. Then, the cascaded VGG16 and long short-term memory (LSTM) networks are applied to learn the spatiotemporal information of the samples, and the hidden layer of the last node of LSTM is output to a linear transformation classifier to perform classification. On DEAP dataset, the proposed method gives out an average accuracy of 94.43% and 94.85% in arousal-based and valence-based classification, respectively. On SEED dataset, the method achieves average accuracy of 94.16%. Compared with the existing methods, our method demonstrates superior performances in emotion recognition."}}
{"id": "xdrcDzYgTz", "cdate": 1680307200000, "mdate": 1682495678211, "content": {"title": "BAFN: Bi-Direction Attention Based Fusion Network for Multimodal Sentiment Analysis", "abstract": "Attention-based networks currently identify their effectiveness in multimodal sentiment analysis. However, existing methods ignore the redundancy of auxiliary modalities. More importantly, existing methods only attend to top-down attention (static process) or down-top attention (implicit process), leading to the coarse-grained multimodal sentiment context. In this paper, during the preprocessing period, we first propose the multimodal dynamic enhanced block to capture the intra-modality sentiment context. This can effectively decrease the intra-modality redundancy of auxiliary modalities. Furthermore, the bi-direction attention block is proposed to capture fine-grained multimodal sentiment context via the novel bi-direction multimodal dynamic routing mechanism. Specifically, the bi-direction attention block first highlights the explicit and low-level multimodal sentiment context. Then, the low-level multimodal context is transmitted to a carefully designed bi-direction multimodal dynamic routing procedure. This allows us to dynamically update and investigate high-level and much more fine-grained multimodal sentiment contexts. The experiments demonstrate that our fusion network can achieve state-of-the-art performance. Notably, our model outperforms the best baseline on the metric \u2018Acc-7\u2019 with an improvement of 6.9%."}}
{"id": "svo1UxLRYE", "cdate": 1675209600000, "mdate": 1682495678230, "content": {"title": "Fusion Graph Representation of EEG for Emotion Recognition", "abstract": "Various relations existing in Electroencephalogram (EEG) data are significant for EEG feature representation. Thus, studies on the graph-based method focus on extracting relevancy between EEG channels. The shortcoming of existing graph studies is that they only consider a single relationship of EEG electrodes, which results an incomprehensive representation of EEG data and relatively low accuracy of emotion recognition. In this paper, we propose a fusion graph convolutional network (FGCN) to extract various relations existing in EEG data and fuse these extracted relations to represent EEG data more comprehensively for emotion recognition. First, the FGCN mines brain connection features on topology, causality, and function. Then, we propose a local fusion strategy to fuse these three graphs to fully utilize the valuable channels with strong topological, causal, and functional relations. Finally, the graph convolutional neural network is adopted to represent EEG data for emotion recognition better. Experiments on SEED and SEED-IV demonstrate that fusing different relation graphs are effective for improving the ability in emotion recognition. Furthermore, the emotion recognition accuracy of 3-class and 4-class is higher than that of other state-of-the-art methods."}}
{"id": "hvDbJJUG6k", "cdate": 1672531200000, "mdate": 1682495677668, "content": {"title": "Effect of music stimuli on corticomuscular coupling and the brain functional connectivity network", "abstract": ""}}
{"id": "c-ls7l4QmP", "cdate": 1672531200000, "mdate": 1681717828950, "content": {"title": "Tree-Based Mix-Order Polynomial Fusion Network for Multimodal Sentiment Analysis", "abstract": "Multimodal sentiment analysis is an actively growing field of research, where tensor-based techniques have demonstrated great expressive efficiency in previous research. However, existing sequential sentiment analysis methods only focus on a single fixed-order representation space with a specific order, which results in the local optimal performance of the sentiment analysis model. Furthermore, existing methods could only employ a single sentiment analysis strategy at each layer, which indeed limits the capability of exploring comprehensive sentiment properties. In this work, the mixed-order polynomial tensor pooling (MOPTP) block is first proposed to adaptively activate the much more discriminative sentiment properties among mixed-order representation subspaces with varying orders, leading to relatively global optimal performance. Using MOPTP as a basic component, we further establish a tree-based mixed-order polynomial fusion network (TMOPFN) to explore multi-level sentiment properties via the parallel procedure. Indeed, TMOPFN allows using multiple sentiment analysis strategies at the same network layer simultaneously, resulting in the improvement of expressive power and the great flexibility of the model. We verified TMOPFN on three multimodal datasets with various experiments, and find it can obtain state-of-the-art or competitive performance."}}
{"id": "aJ3-zXQ1xBX", "cdate": 1667260800000, "mdate": 1682495678312, "content": {"title": "A semi-supervised label distribution learning model with label correlations and data manifold exploration", "abstract": ""}}
{"id": "i51x-FmRQTw", "cdate": 1640995200000, "mdate": 1682495678437, "content": {"title": "Coupled Projection Transfer Metric Learning for Cross-Session Emotion Recognition from EEG", "abstract": "Distribution discrepancies between different sessions greatly degenerate the performance of video-evoked electroencephalogram (EEG) emotion recognition. There are discrepancies since the EEG signal is weak and non-stationary and these discrepancies are manifested in different trails in each session and even in some trails which belong to the same emotion. To this end, we propose a Coupled Projection Transfer Metric Learning (CPTML) model to jointly complete domain alignment and graph-based metric learning, which is a unified framework to simultaneously minimize cross-session and cross-trial divergences. By experimenting on the SEED_IV emotional dataset, we show that (1) CPTML exhibits a significantly better performance than several other approaches; (2) the cross-session distribution discrepancies are minimized and emotion metric graph across different trials are optimized in the CPTML-induced subspace, indicating the effectiveness of data alignment and metric exploration; and (3) critical EEG frequency bands and channels for emotion recognition are automatically identified from the learned projection matrices, providing more insights into the occurrence of the effect."}}
{"id": "hdYAbLGSxu_", "cdate": 1640995200000, "mdate": 1682495678455, "content": {"title": "GFIL: A Unified Framework for the Importance Analysis of Features, Frequency Bands, and Channels in EEG-Based Emotion Recognition", "abstract": "Accurately and automatically recognizing the emotional states of human beings is the central task in affective computing. The electroencephalography (EEG) data, generated from the neural activities in brain cortex, provide us with a reliable data source to perform emotion recognition. Besides the recognition accuracy, it is also necessary to explore the importance of different EEG features, frequency bands, and channels in emotion expression. In this article, we propose a unified framework termed graph-regularized least square regression with feature importance learning (GFIL) to simultaneously achieve these goals by incorporating an autoweighting variable into the least square regression. Unlike the widely used trial-and-error manner, GFIL automatically completes the identification once it is trained. Specifically, GFIL can: 1) adaptively discriminate the contributions of different feature dimensions; 2) automatically identify the critical frequency bands and channels; and 3) quantitatively rank and select the features by the learned autoweighting variable. From the experimental results on the SEED_IV data set, we find GFIL obtained improved accuracies based on the feature autoweighting strategy, which are 75.33%, 75.03%, and 79.17% corresponding to the three cross-session recognition tasks (session1->session2, session1->session3, session2->session3), respectively. Additionally, the <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">Gamma</i> band is identified as the most important one and the channels locating in the prefrontal and left/right central regions are more important."}}
{"id": "hY1DpTFGIi", "cdate": 1640995200000, "mdate": 1682495678125, "content": {"title": "Analysis of Functional Corticomuscular Coupling Based on Multiscale Transfer Spectral Entropy", "abstract": "Functional corticomuscular coupling (FCMC) between the cerebral motor cortex and muscle activity reflects multi-layer and nonlinear interactions in the sensorimotor system. Considering the inherent multiscale characteristics of physiological signals, we proposed multiscale transfer spectral entropy (MSTSE) and introduced the unidirectionally coupled H\u00e9non maps model to verify the effectiveness of MSTSE. We recorded electroencephalogram (EEG) and surface electromyography (sEMG) in steady-state grip tasks of 29 healthy participants and 27 patients. Then, we used MSTSE to analyze the FCMC base on EEG of the bilateral motor areas and the sEMG of the flexor digitorum superficialis (FDS). The results show that MSTSE is superior to transfer spectral entropy (TSE) method in restraining the spurious coupling and detecting the coupling more accurately. The coupling strength was higher in the <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><tex-math notation=\"LaTeX\">${\\boldsymbol{\\beta}}$</tex-math></inline-formula> 1, <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><tex-math notation=\"LaTeX\">${\\boldsymbol{\\beta}}$</tex-math></inline-formula> 2, and <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><tex-math notation=\"LaTeX\">$\\ {\\boldsymbol{\\gamma}}$</tex-math></inline-formula> 2 bands, among which, it was highest in the <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><tex-math notation=\"LaTeX\">${\\boldsymbol{\\beta}}$</tex-math></inline-formula> 1 band, and reached its maximum at the 22\u201330 scale. On the directional characteristics of FCMC, the coupling strength of EEG\u2192sEMG is superior to the opposite direction in most cases. In addition, the coupling strength of the stroke-affected side was lower than that of healthy controls\u2019 right hand in the <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><tex-math notation=\"LaTeX\">${\\boldsymbol{\\beta}}$</tex-math></inline-formula> 1 and <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><tex-math notation=\"LaTeX\">${\\boldsymbol{\\beta}}$</tex-math></inline-formula> 2 bands and the stroke-unaffected side in the <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><tex-math notation=\"LaTeX\">${\\boldsymbol{\\beta}}$</tex-math></inline-formula> 1 band. The coupling strength of the stroke-affected side was higher than that of the stroke-unaffected side and the right hand of healthy controls in the sEMG\u2192EEG direction of <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><tex-math notation=\"LaTeX\">${\\boldsymbol{\\gamma}}$</tex-math></inline-formula> 2 band. This study provides a new perspective and lays a foundation for analyzing FCMC and motor dysfunction."}}
