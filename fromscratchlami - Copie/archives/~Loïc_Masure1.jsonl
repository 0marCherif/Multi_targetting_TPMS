{"id": "jbiJ0qd5CM", "cdate": 1672531200000, "mdate": 1680515156870, "content": {"title": "Don't Learn What You Already Know Scheme-Aware Modeling for Profiling Side-Channel Analysis against Masking", "abstract": ""}}
{"id": "PxhEsWe0Z5", "cdate": 1672531200000, "mdate": 1680515156805, "content": {"title": "Prime-Field Masking in Hardware and its Soundness against Low-Noise SCA Attacks", "abstract": ""}}
{"id": "84FhUOJQuh", "cdate": 1672531200000, "mdate": 1680515156821, "content": {"title": "Removing the Field Size Loss from Duc et al.'s Conjectured Bound for Masked Encodings", "abstract": ""}}
{"id": "T2O0sDyOSh", "cdate": 1640995200000, "mdate": 1680515156868, "content": {"title": "A Nearly Tight Proof of Duc et al.'s Conjectured Security Bound for Masked Implementations", "abstract": ""}}
{"id": "SrlZQPrEf7c", "cdate": 1640995200000, "mdate": 1648670043291, "content": {"title": "Efficient Profiled Side-Channel Analysis of Masked Implementations, Extended", "abstract": "We extend the study of efficient profiled attacks on masking schemes initiated by Lerman and Markowitch (TIFS, 2019) in different directions. First, we study both the profiling complexity and the online attack complexity of different profiled distinguishers. Second, we extend the range of the noise levels of their experiments, in order to cover (higher-noise) contexts where masking is effective. Third, we further contextualize the investigated distinguishers (e.g., in terms of adversarial capabilities and a priori assumptions on the leakage probability density function). Finally, we complete the list of distinguishers considered in this previous work and add expectation-maximization, soft analytical side-channel attacks and multi-layer perceptrons in our comparisons. Our results allow shedding an interesting new light on the respective strengths and weaknesses of these different statistical tools, both in the context of a side-channel security evaluation and for concrete attacks. In particular, they confirm the experimental relevance of evaluation shortcuts leveraging the masking randomness during profiling, in order to speed up the evaluation process."}}
{"id": "R89SXMGCVY6", "cdate": 1640995200000, "mdate": 1675079984805, "content": {"title": "Information Bounds and Convergence Rates for Side-Channel Security Evaluators", "abstract": ""}}
{"id": "Oa7cla3AEmX", "cdate": 1640995200000, "mdate": 1680515156818, "content": {"title": "Effective and Efficient Masking with Low Noise using Small-Mersenne-Prime Ciphers", "abstract": ""}}
{"id": "7_uIWtie9RM", "cdate": 1609459200000, "mdate": 1631647450905, "content": {"title": "Side Channel Analysis against the ANSSI's protected AES implementation on ARM", "abstract": ""}}
{"id": "ZrbMxM--vrI", "cdate": 1577836800000, "mdate": 1631647450975, "content": {"title": "Deep Learning Side-Channel Analysis on Large-Scale Traces - A Case Study on a Polymorphic AES", "abstract": "Code polymorphism is an approach to efficiently address the challenge of automatically applying the hiding of sensitive information leakage, as a way to protect cryptographic primitives against side-channel attacks (SCA) involving layman adversaries. Yet, recent improvements in SCA, involving more powerful threat models, e.g., using deep learning, emphasized the weaknesses of some hiding counter-measures. This raises two questions. On the one hand, the security of code polymorphism against more powerful attackers, which has never been addressed so far, might be affected. On the other hand, using deep learning SCA on code polymorphism would require to scale the state-of-the-art models to much larger traces than considered so far in the literature. Such a case typically occurs with code polymorphism due to the unknown precise location of the leakage from one execution to another. We tackle those questions through the evaluation of two polymorphic implementations of AES, similar to the ones used in a recent paper published in TACO 2019\u00a0 [6]. We show on our analysis how to efficiently adapt deep learning models used in SCA to scale on traces $$32$$ folds larger than what has been done so far in the literature. Our results show that the targeted polymorphic implementations are broken within $$20$$ queries with the most powerful threat models involving deep learning, whereas $$100,000$$ queries would not be sufficient to succeed the attacks previously investigated against code polymorphism. As a consequence, this paper pushes towards the search of new polymorphic implementations secured against state-of-the-art attacks, which currently remains to be found."}}
{"id": "KWeaBMmh8hg", "cdate": 1577836800000, "mdate": 1631647450938, "content": {"title": "A Comprehensive Study of Deep Learning for Side-Channel Analysis", "abstract": "Recently, several studies have been published on the application of deep learning to enhance Side-Channel Attacks (SCA). These seminal works have practically validated the soundness of the approach, especially against implementations protected by masking or by jittering. Concurrently, important open issues have emerged. Among them, the relevance of machine (and thereby deep) learning based SCA has been questioned in several papers based on the lack of relation between the accuracy, a typical performance metric used in machine learning, and common SCA metrics like the Guessing entropy or the key-discrimination success rate. Also, the impact of the classical side-channel counter-measures on the efficiency of deep learning has been questioned, in particular by the semi-conductor industry. Both questions enlighten the importance of studying the theoretical soundness of deep learning in the context of side-channel and of developing means to quantify its efficiency, especially with respect to the optimality bounds published so far in the literature for side-channel leakage exploitation. The first main contribution of this paper directly concerns the latter point. It is indeed proved that minimizing the Negative Log Likelihood (NLL for short) loss function during the training of deep neural networks is actually asymptotically equivalent to maximizing the Perceived Information introduced by Renauld et al. at EUROCRYPT 2011 as a lower bound of the Mutual Information between the leakage and the target secret. Hence, such a training can be considered as an efficient and effective estimation of the PI, and thereby of the MI (known to be complex to accurately estimate in the context of secure implementations). As a second direct consequence of our main contribution, it is argued that, in a side-channel exploitation context, choosing the NLL loss function to drive the training is sound from an information theory point of view. As a third contribution, classical counter-measures like Boolean masking or execution flow shuffling, initially dedicated to classical SCA, are proved to stay sound against deep Learning based attacks."}}
