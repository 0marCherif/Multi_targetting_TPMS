{"id": "WoM4RtdCwP", "cdate": 1672531200000, "mdate": 1682425785771, "content": {"title": "Goldfish: Peer selection using Matrix completion in unstructured P2P network", "abstract": "Peer-to-peer (P2P) networks underlie a variety of decentralized paradigms including blockchains, distributed file storage and decentralized domain name systems. A central primitive in P2P networks is the peer selection algorithm, which decides how a node should select a fixed number of neighbors to connect with. In this paper, we consider the design of a peer-selection algorithm for unstructured P2P networks with the goal of minimizing the broadcast latency. We propose Goldfish, a novel solution that dynamically decides the neighbor set by exploiting the past experiences as well as exploring new neighbors. The key technical contributions come from bringing ideas of matrix completion for estimating message delivery times for every possible message for every peer ever connected, and a streaming algorithm to efficiently perform the estimation while achieving good performance. The matrix completion interpolates the delivery times to all virtual connections in order to select the best combination of neighbors. Goldfish employs a streaming algorithm that only uses a short recent memory to finish matrix interpolation. When the number of publishing source is equal to a node's maximal number of connections, Goldfish found the global optimal solution with 92.7% probability by exploring every node only once. In more complex situations where nodes are publishing based on exponential distribution and adjusting connection in real time, we compare Goldfish with a baseline peer selection system, and show Goldfish saves approximately 14.5% less time under real world geolocation and propagation latency."}}
{"id": "KO8YVrfTS4F", "cdate": 1672531200000, "mdate": 1682425785762, "content": {"title": "DecVi: Adaptive Video Conferencing on Open Peer-to-Peer Networks", "abstract": "Video conferencing has become the preferred way of interacting virtually. Current video conferencing applications, like Zoom, Teams or WebEx, are centralized, cloud-based platforms whose performance crucially depends on the proximity of clients to their data centers. Clients from low-income countries are particularly affected as most data centers from major cloud providers are located in economically advanced nations. Centralized conferencing applications also suffer from occasional outages and are embattled by serious privacy violation allegations. In recent years, decentralized video conferencing applications built over p2p networks and incentivized through blockchain are becoming popular. A key characteristic of these networks is their openness: anyone can host a media server on the network. The reason, however, also leads to a security problem: a server may obfuscate its true location in order to gain an unfair business advantage. We propose DecVi, a decentralized multicast tree construction protocol that adaptively discovers efficient tree structures based on an exploration-exploitation framework. DecVi is motivated by the combinatorial multi-armed bandit problem and uses a succinct learning model to compute effective actions. Despite operating in a multi-agent setting with each server having only limited knowledge of the global network and without cooperation among servers, experimentally we show DecVi achieves similar quality-of-experience compared to a centralized globally optimal algorithm while achieving higher reliability and flexibility."}}
{"id": "tMtVVBgCFAO", "cdate": 1640995200000, "mdate": 1682425785773, "content": {"title": "Kadabra: Adapting Kademlia for the Decentralized Web", "abstract": "Blockchains have become the catalyst for a growing movement to create a more decentralized Internet. A fundamental operation of applications in a decentralized Internet is data storage and retrieval. As today's blockchains are limited in their storage functionalities, in recent years a number of peer-to-peer data storage networks have emerged based on the Kademlia distributed hash table protocol. However, existing Kademlia implementations are not efficient enough to support fast data storage and retrieval operations necessary for (decentralized) Web applications. In this paper, we present Kadabra, a decentralized protocol for computing the routing table entries in Kademlia to accelerate lookups. Kadabra is motivated by the multi-armed bandit problem, and can automatically adapt to heterogeneity and dynamism in the network. Experimental results show Kadabra achieving between 15-50% lower lookup latencies compared to state-of-the-art baselines."}}
{"id": "kQWIC-3O-pT", "cdate": 1640995200000, "mdate": 1681745112195, "content": {"title": "The Effect of Network Topology on Credit Network Throughput", "abstract": "The global economy relies on digital transactions between entities who do not trust one another. Today, such transactions are handled by intermediaries who extract fees (e.g., credit card providers). A natural question is how to build financial systems that limit the need for such middlemen."}}
{"id": "CuNiY_riZj", "cdate": 1640995200000, "mdate": 1682425785776, "content": {"title": "Less is More: Fairness in Wide-Area Proof-of-Work Blockchain Networks", "abstract": "Blockchain is rapidly emerging as an important class of network application, with a unique set of trust, security and transparency properties. In a blockchain system, participants record and update the `server-side' state of an application as blocks of a replicated, immutable ledger using a consensus protocol over the Internet. Mining blocks has become lucrative in recent years; e.g., a miner receives over USD 200,000 per mined block in Bitcoin today. A key factor affecting mining rewards, is the latency of broadcasting blocks over the network. In this paper, we consider the problem of topology design for optimizing mining rewards in a wide-area blockchain network that uses a Proof-of-Work protocol for consensus. Contrary to general wisdom that a faster network is always better for miners, we show a counter intuitive result where a slower network is actually beneficial to some miners. This is because competing miners must choose neighbors that not only decrease their own latency to others, but also ensure that the latency between other miners do not decrease because of itself. We formalize this problem, and provide both theoretical analysis and experimental results to support our claim."}}
{"id": "0AYUkolEDEv", "cdate": 1640995200000, "mdate": 1682425785773, "content": {"title": "DecVi: Adaptive Video Conferencing on Open Peer-to-Peer Networks", "abstract": "Video conferencing has become the preferred way of interacting virtually. Current video conferencing applications, like Zoom, Teams or WebEx, are centralized, cloud-based platforms whose performance crucially depends on the proximity of clients to their data centers. Clients from low-income countries are particularly affected as most data centers from major cloud providers are located in economically advanced nations. Centralized conferencing applications also suffer from occasional outages and are embattled by serious privacy violation allegations. In recent years, decentralized video conferencing applications built over p2p networks and incentivized through blockchain are becoming popular. A key characteristic of these networks is their openness: anyone can host a media server on the network and gain reward for providing service. Strong economic incentives combined with lower entry barrier to join the network, makes increasing server coverage to even remote regions of the world. These reasons, however, also lead to a security problem: a server may obfuscate its true location in order to gain an unfair business advantage. In this paper, we consider the problem of multicast tree construction for video conferencing sessions in open p2p conferencing applications. We propose DecVi, a decentralized multicast tree construction protocol that adaptively discovers efficient tree structures based on an exploration-exploitation framework. DecVi is motivated by the combinatorial multi-armed bandit problem and uses a succinct learning model to compute effective actions. Despite operating in a multi-agent setting with each server having only limited knowledge of the global network and without cooperation among servers, experimentally we show DecVi achieves similar quality-of-experience compared to a centralized globally optimal algorithm while achieving higher reliability and flexibility."}}
{"id": "uJnkw-xn-si", "cdate": 1609459200000, "mdate": 1681745112199, "content": {"title": "The Effect of Network Topology on Credit Network Throughput", "abstract": "Credit networks rely on decentralized, pairwise trust relationships (channels) to exchange money or goods. Credit networks arise naturally in many financial systems, including the recent construct of payment channel networks in blockchain systems. An important performance metric for these networks is their transaction throughput. However, predicting the throughput of a credit network is nontrivial. Unlike traditional communication channels, credit channels can become imbalanced; they are unable to support more transactions in a given direction once the credit limit has been reached. This potential for imbalance creates a complex dependency between a network's throughput and its topology, path choices, and the credit balances (state) on every channel. Even worse, certain combinations of these factors can lead the credit network to deadlocked states where no transactions can make progress. In this paper, we study the relationship between the throughput of a credit network and its topology and credit state. We show that the presence of deadlocks completely characterizes a network's throughput sensitivity to different credit states. Although we show that identifying deadlocks in an arbitrary topology is NP-hard, we propose a peeling algorithm inspired by decoding algorithms for erasure codes that upper bounds the severity of the deadlock. We use the peeling algorithm as a tool to compare the performance of different topologies as well as to aid in the synthesis of topologies robust to deadlocks."}}
{"id": "6gXEVa4J7W6", "cdate": 1609459200000, "mdate": 1681745112195, "content": {"title": "The effect of network topology on credit network throughput", "abstract": ""}}
{"id": "1Pvfpq96boZ", "cdate": 1596580400904, "mdate": null, "content": {"title": "Learning Scheduling Algorithms for Data Processing Clusters", "abstract": "Efficiently scheduling data processing jobs on distributed compute clusters requires complex algorithms. Current systems use simple,\ngeneralized heuristics and ignore workload characteristics, since developing and tuning a scheduling policy for each workload is infeasible. In this paper, we show that modern machine learning techniques can generate highly-efficient policies automatically. Decima uses reinforcement learning (RL) and neural networks to learn workload-specific scheduling algorithms without any human instruction beyond a high-level objective, such as minimizing average job completion time. However, off-the-shelf RL techniques cannot handle the complexity and scale of the scheduling problem. To build Decima, we had to develop new representations for jobs\u2019 dependency graphs, design scalable RL models, and invent RL training methods for dealing with continuous stochastic job arrivals. Our prototype integration with Spark on a 25-node cluster shows that Decima improves average job completion time by at least 21% over hand-tuned scheduling heuristics, achieving up to 2\u00d7 improvement during periods of high cluster load."}}
{"id": "AsAhOlv5bdg", "cdate": 1596580217382, "mdate": null, "content": {"title": "Placeto: Learning Generalizable Device Placement Algorithms for Distributed Machine Learning", "abstract": "We present Placeto, a reinforcement learning (RL) approach to efficiently find device placements for distributed neural network training. Unlike prior approaches that only find a device placement for a specific computation graph, Placeto can learn generalizable device placement policies that can be applied to any graph. We propose two key ideas in our approach: (1) we represent the policy as performing iterative placement improvements, rather than outputting a placement in one shot; (2) we use graph embeddings to capture relevant information about the structure of the computation graph, without relying on node labels for indexing. These ideas allow Placeto to train efficiently and generalize to unseen graphs. Our experiments show that Placeto requires up to 6.1\u00d7 fewer training steps to find\nplacements that are on par with or better than the best placements found by prior approaches. Moreover, Placeto is able to learn a generalizable placement policy for any given family of graphs, which can then be used without any retraining to predict optimized placements for unseen graphs from the same family. This eliminates the large overhead incurred by prior RL approaches whose lack of generalizability necessitates re-training from scratch every time a new graph is to be placed."}}
