{"id": "5wb3Jr1juV", "cdate": 1672531200000, "mdate": 1696330318880, "content": {"title": "Learning Probabilistic Piecewise Rigid Atlases of Model Organisms via Generative Deep Networks", "abstract": "Atlases are crucial to imaging statistics as they enable the standardization of inter-subject and inter-population analyses. While existing atlas estimation methods based on fluid/elastic/diffusion registration yield high-quality results for the human brain, these deformation models do not extend to a variety of other challenging areas of neuroscience such as the anatomy of C. elegans worms and fruit flies. To this end, this work presents a general probabilistic deep network-based framework for atlas estimation and registration which can flexibly incorporate various deformation models and levels of keypoint supervision that can be applied to a wide class of model organisms. Of particular relevance, it also develops a deformable piecewise rigid atlas model which is regularized to preserve inter-observation distances between neighbors. These modeling considerations are shown to improve atlas construction and key-point alignment across a diversity of datasets with small sample sizes including neuron positions in C. elegans hermaphrodites, fluorescence microscopy of male C. elegans, and images of fruit fly wings. Code is accessible at https://github.com/amin-nejat/Deformable-Atlas ."}}
{"id": "KFpSGA0HwX", "cdate": 1640995200000, "mdate": 1673992357449, "content": {"title": "Toward a more accurate 3D atlas of C. elegans neurons", "abstract": ""}}
{"id": "LeW4XOVCrl", "cdate": 1621629697206, "mdate": null, "content": {"title": "Estimating the Unique Information of Continuous Variables", "abstract": "The integration and transfer of information from multiple sources to multiple targets is a core motive of neural systems. The emerging field of partial information decomposition (PID) provides a novel information-theoretic lens into these mechanisms by identifying synergistic, redundant, and unique contributions to the mutual information between one and several variables. While many works have studied aspects of PID for Gaussian and discrete distributions, the case of general continuous distributions is still uncharted territory. In this work we present a method for estimating the unique information in continuous distributions, for the case of one versus two variables. Our method solves the associated optimization problem over the space of distributions with fixed bivariate  marginals by combining copula decompositions and techniques developed to optimize variational autoencoders. We obtain excellent agreement with known analytic results for Gaussians, and  illustrate the power of our new approach in several brain-inspired neural models. Our method is capable of recovering the effective connectivity of a chaotic network of rate neurons, and uncovers a complex trade-off between redundancy, synergy and unique information in recurrent networks trained to solve a generalized XOR~task.\n"}}
{"id": "KnkY7eIiGU", "cdate": 1609459200000, "mdate": 1681748345717, "content": {"title": "Estimating the Unique Information of Continuous Variables", "abstract": "The integration and transfer of information from multiple sources to multiple targets is a core motive of neural systems. The emerging field of partial information decomposition (PID) provides a novel information-theoretic lens into these mechanisms by identifying synergistic, redundant, and unique contributions to the mutual information between one and several variables. While many works have studied aspects of PID for Gaussian and discrete distributions, the case of general continuous distributions is still uncharted territory. In this work we present a method for estimating the unique information in continuous distributions, for the case of one versus two variables. Our method solves the associated optimization problem over the space of distributions with fixed bivariate marginals by combining copula decompositions and techniques developed to optimize variational autoencoders. We obtain excellent agreement with known analytic results for Gaussians, and illustrate the power of our new approach in several brain-inspired neural models. Our method is capable of recovering the effective connectivity of a chaotic network of rate neurons, and uncovers a complex trade-off between redundancy, synergy and unique information in recurrent networks trained to solve a generalized XOR~task."}}
{"id": "-6vXRJGD-B", "cdate": 1609459200000, "mdate": 1681748345696, "content": {"title": "Neuron matching in C. elegans with robust approximate linear regression without correspondence", "abstract": "We propose methods for estimating correspondence between two point sets under the presence of outliers in both the source and target sets. The proposed algorithms expand upon the theory of the regression without correspondence problem to estimate transformation coefficients using unordered multisets of covariates and responses. Previous theoretical analysis of the problem has been done in a setting where the responses are a complete permutation of the regressed covariates. This paper expands the problem setting by analyzing the cases where only a subset of the responses is a permutation of the regressed covariates in addition to some covariates possibly being adversarial outliers. We term this problem robust regression without correspondence and provide several algorithms based on random sample consensus for exact and approximate recovery in a noiseless and noisy one-dimensional setting as well as an approximation algorithm for multiple dimensions. The theoretical guarantees of the algorithms are verified in simulated data. We demonstrate an important computational neuroscience application of the proposed framework by demonstrating its effectiveness in a Caenorhabditis elegans neuron matching problem where the presence of outliers in both the source and target nematodes is a natural tendency. Open source code implementing this method is available at https://github.com/amin-nejat/RRWOC."}}
{"id": "lS380EVg_X", "cdate": 1577836800000, "mdate": null, "content": {"title": "Demixing Calcium Imaging Data in C. elegans via Deformable Non-negative Matrix Factorization", "abstract": "Extracting calcium traces from the neurons of C. elegans is an important problem, enabling the study of individual neuronal activity and the large-scale dynamics that govern behavior. Traditionally, non-negative matrix factorization (NMF) methods have been successful in demixing and denoising cellular calcium activity in relatively motionless or pre-registered videos. However, in the case of C. elegans or other animal models where motion compensation methods fail to stabilize the effect of even mild motion in the imaging data, standard NMF methods fail to capture cellular footprints since these footprints are variable in time. In this work, we introduce deformable non-negative matrix factorization (dNMF), which models the motion trajectory of the underlying image space using a polynomial basis function. Spatial footprints and neural activity are optimized jointly with motion trajectories in a matrix tri-factorization setting. On simulated data, dNMF is demonstrated to outperform currently available demixing methods as well as methods that account for motion and demixing separately. Furthermore, we display the practical utility of our approach in extracting calcium traces from C. elegans microscopy videos. The extracted traces elucidate spontaneous neural\u00a0activity as well as responses to stimuli. Open source code implementing this pipeline is available at https://github.com/amin-nejat/dNMF"}}
{"id": "gosb_xEzQ0e", "cdate": 1577836800000, "mdate": null, "content": {"title": "Statistical Atlas of C. elegans Neurons", "abstract": "Constructing a statistical atlas of neuron positions in the nematode Caenorhabditis elegans enables a wide range of applications that require neural identity. These applications include annotating gene expression, extracting calcium activity, and evaluating nervous-system mutations. Large complete sets of neural annotations are necessary to determine canonical neuron positions and their associated confidence regions. Recently, a transgene of C. elegans (\u201cNeuroPAL\u201d) has been introduced to assign correct identities to all neurons in the worm via a deterministic, fluorescent colormap. This strain has enabled efficient and accurate annotation of worm neurons. Using a dataset of 10 worms, we propose a statistical model that captures the latent means and covariances of neuron locations, with efficient optimization strategies to infer model parameters. We demonstrate the utility of this model in two critical applications. First, we use our trained atlas to automatically annotate neuron identities in C. elegans at the state-of-the-art rate. Second, we use our atlas to compute correlations between neuron positions, thereby determining covariance in neuron placement. The code to replicate the statistical atlas is distributed publicly at https://github.com/amin-nejat/StatAtlas ."}}
{"id": "cEPHDmlA41b", "cdate": 1577836800000, "mdate": null, "content": {"title": "Sinkhorn EM: An Expectation-Maximization algorithm based on entropic optimal transport", "abstract": "We study Sinkhorn EM (sEM), a variant of the expectation maximization (EM) algorithm for mixtures based on entropic optimal transport. sEM differs from the classic EM algorithm in the way responsibilities are computed during the expectation step: rather than assign data points to clusters independently, sEM uses optimal transport to compute responsibilities by incorporating prior information about mixing weights. Like EM, sEM has a natural interpretation as a coordinate ascent procedure, which iteratively constructs and optimizes a lower bound on the log-likelihood. However, we show theoretically and empirically that sEM has better behavior than EM: it possesses better global convergence guarantees and is less prone to getting stuck in bad local optima. We complement these findings with experiments on simulated data as well as in an inference task involving C. elegans neurons and show that sEM learns cell labels significantly better than other approaches."}}
{"id": "2FYSEWrD2T", "cdate": 1577836800000, "mdate": null, "content": {"title": "Probabilistic Joint Segmentation and Labeling of C. elegans Neurons", "abstract": "Automatic identification and segmentation of the neurons of C. elegans enables evaluating nervous system mutations, positional variability, and allows us to conduct high-throughput population studies employing many animals. A recently introduced transgene of C. elegans, named \u201cNeuroPAL\u201d has enabled the efficient annotation of neurons and the construction of a statistical atlas of their positions. Previous atlas-based segmentation approaches have modeled images of cells as a mixture model. The expectation-maximization (EM) algorithm and its variants are used to find the (local) maximum likelihood parameters for this class of models. We present a variation of the EM algorithm called Sinkhorn-EM (sEM) that uses regularized optimal transport Sinkhorn iterations to enforce constraints on the marginals of the joint distribution of observed variables and latent assignments in order to incorporate our prior information about cell sizes into the cluster-data assignment proportions. We apply our method to the problem of segmenting and labeling neurons in fluorescent microscopy images of C. elegans specimens. We show empirically that sEM outperforms vanilla EM and a recently proposed 3-step (filter, detect, identify) labeling approach. Open source code implementing this method is available at https://github.com/amin-nejat/SinkhornEM ."}}
{"id": "HkxPtJh4YB", "cdate": 1571237759407, "mdate": null, "content": {"title": "Sinkhorn Permutation  Variational Marginal Inference", "abstract": "We address the problem of marginal inference for an exponential family defined over the set of permutation matrices. This problem is known to quickly become intractable as the size of the permutation increases, since its involves the computation of the permanent of a matrix, a #P-hard problem. We introduce Sinkhorn variational marginal inference as a scalable alternative, a method whose validity is ultimately justified by the so-called Sinkhorn approximation of the permanent. We demonstrate the efectiveness of our method in the problem of probabilistic identification of neurons in the worm C.elegans"}}
