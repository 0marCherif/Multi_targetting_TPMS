{"id": "syZ09IRE6Pl", "cdate": 1683634741368, "mdate": null, "content": {"title": "Error Discovery by Clustering Influence Embeddings", "abstract": "We present a method for identifying groups of test examples\u2014slices\u2014on which\na pre-trained model under-performs, a task now known as slice discovery. We\nformalize coherence, a requirement that erroneous predictions within returned\nslices should be wrong for the same reason, as a key property that a slice discovery\nmethod should satisfy. We then leverage influence functions (Koh & Liang, 2017)\nto derive a new slice discovery method, InfEmbed, which satisfies coherence\nby returning slices whose examples are influenced similarly by the training data.\nInfEmbed is computationally simple, consisting of applying K-Means clustering\nto a novel representation we deem influence embeddings. Empirically, we show\nInfEmbed outperforms current state-of-the-art methods on a slice discovery\nbenchmark, and is effective for model debugging across several case studies."}}
{"id": "Rj8TUzl8nT8", "cdate": 1676472363481, "mdate": null, "content": {"title": "Error Discovery by Clustering Influence Embeddings", "abstract": "We present a method for identifying groups of test examples\u2014slices\u2014on which a pre-trained model under-performs, a task now known as slice discovery. We formalize coherence, a requirement that erroneous predictions within returned slices should be wrong for the same reason, as a key property that a slice discovery method should satisfy. We then leverage influence functions (Koh & Liang, 2017) to derive a new slice discovery method, InfEmbed, which satisfies coherence by returning slices whose examples are influenced similarly by the training data. InfEmbed is computationally simple, consisting of applying K-Means clustering to a novel representation we deem influence embeddings. Empirically, we show InfEmbed outperforms current state-of-the-art methods on a slice discovery benchmark, and is effective for model debugging across several case studies."}}
{"id": "GrHeFNdI8c1", "cdate": 1657560090874, "mdate": 1657560090874, "content": {"title": "Improving and Diagnosing Knowledge-Based Visual Question Answering via Entity Enhanced Knowledge Injection", "abstract": "Knowledge-Based Visual Question Answering (KBVQA) is a bimodal task requiring external world knowledge in order to correctly answer a text question and associated image. Recent single modality text work has shown knowledge injection into pre-trained language models, specifically entity enhanced knowledge graph embeddings, can improve performance on downstream entity-centric tasks. In this work, we empirically study how and whether such methods, applied in a bi-modal setting, can improve an existing VQA system\u2019s performance on the KBVQA task. We experiment with two large publicly available VQA datasets, (1) KVQA which contains mostly rare Wikipedia entities and (2) OKVQA which is less entity-centric and more aligned with common sense reasoning. Both lack explicit entity spans, and we study the effect of different weakly supervised and manual methods for obtaining them.  Additionally, we analyze how recently proposed bi-modal and single modal attention explanations are affected by the incorporation of such entity enhanced representations. Our results show substantially improved performance on the KBVQA task without the need for additional costly pre-training, and we provide insights for when entity knowledge injection helps improve a model\u2019s understanding. We provide code and enhanced datasets for reproducibility.\n."}}
{"id": "2zcZ5Cdx0vD", "cdate": 1640995200000, "mdate": 1683633986109, "content": {"title": "Intermediate Entity-based Sparse Interpretable Representation Learning", "abstract": ""}}
{"id": "LmtE-Gn4UcH", "cdate": 1609459200000, "mdate": 1683633986071, "content": {"title": "Biomedical Interpretable Entity Representations", "abstract": ""}}
{"id": "sNuv47zoAaD", "cdate": 1546300800000, "mdate": 1683633985981, "content": {"title": "Explaining Deep Classification of Time-Series Data with Learned Prototypes", "abstract": ""}}
{"id": "F5k7X1VMhH", "cdate": 1546300800000, "mdate": 1683633986014, "content": {"title": "Learning Dense Representations for Entity Retrieval", "abstract": "Daniel Gillick, Sayali Kulkarni, Larry Lansing, Alessandro Presta, Jason Baldridge, Eugene Ie, Diego Garcia-Olano. Proceedings of the 23rd Conference on Computational Natural Language Learning (CoNLL). 2019."}}
