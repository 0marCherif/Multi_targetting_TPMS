{"id": "MuOFB0LQKcy", "cdate": 1677713804786, "mdate": null, "content": {"title": "When Spiking Neural Networks Meet Temporal Attention Image Decoding and Adaptive Spiking Neuron", "abstract": "Spiking Neural Networks (SNNs) are capable of encoding and processing temporal information in a biologically plausible way. However, most existing SNN-based methods for image tasks do not fully exploit this feature. Moreover, they often overlook the role of adaptive threshold in spiking neurons, which can enhance their dynamic behavior and learning ability. To address these issues, we propose a novel method for image decoding based on temporal attention (TAID) and an adaptive Leaky-Integrate-and-Fire (ALIF) neuron model. Our method leverages the temporal information of SNN outputs to generate high-quality images that surpass the state-of-the-art (SOTA) in terms of Inception score, Fr\u00e9chet Inception Distance, and Fr\u00e9chet Autoencoder Distance. Furthermore, our ALIF neuron model achieves remarkable classification accuracy on MNIST (99.78%) and CIFAR-10 (93.89%) datasets, demonstrating the effectiveness of learning adaptive thresholds for spiking neurons."}}
{"id": "91Bcj6sgcxt", "cdate": 1677713801092, "mdate": null, "content": {"title": "Uni-Match: A Semantic Unified Model for Query-Product Retrieval", "abstract": "For most practical search systems, the cascaded matching-prerank-rank architecture is designed. In the prerank stage, the dual-tower structure is widely used to maintain efficiency. However, due to the lack of interaction between query and document, this architecture could only take into account efficiency but not both effectiveness and efficiency. Inspired by this, we propose a simple but effective dual-tower model: uni-match, which has the efficiency of dual-tower model and the effectiveness close to that of cross model. Sufficient offline and online experiments show the effectiveness of our proposed method. Currently, the Uni-match model has been deployed in the search system of a shortvideo App, providing daily services to hundreds of millions users."}}
{"id": "yjgOXzChTRy", "cdate": 1672531200000, "mdate": 1684120694768, "content": {"title": "SpikeGPT: Generative Pre-trained Language Model with Spiking Neural Networks", "abstract": "As the size of large language models continue to scale, so does the computational resources required to run it. Spiking Neural Networks (SNNs) have emerged as an energy-efficient approach to deep learning that leverage sparse and event-driven activations to reduce the computational overhead associated with model inference. While they have become competitive with non-spiking models on many computer vision tasks, SNNs have also proven to be more challenging to train. As a result, their performance lags behind modern deep learning, and we are yet to see the effectiveness of SNNs in language generation. In this paper, inspired by the Receptance Weighted Key Value (RWKV) language model, we successfully implement `SpikeGPT', a generative language model with binary, event-driven spiking activation units. We train the proposed model on two model variants: 45M and 216M parameters. To the best of our knowledge, SpikeGPT is the largest backpropagation-trained SNN model to date, rendering it suitable for both the generation and comprehension of natural language. We achieve this by modifying the transformer block to replace multi-head self attention to reduce quadratic computational complexity O(N^2) to linear complexity O(N) with increasing sequence length. Input tokens are instead streamed in sequentially to our attention mechanism (as with typical SNNs). Our preliminary experiments show that SpikeGPT remains competitive with non-spiking models on tested benchmarks, while maintaining 20x fewer operations when processed on neuromorphic hardware that can leverage sparse, event-driven activations."}}
{"id": "ZN1RprTGU05", "cdate": 1672531200000, "mdate": 1684120694779, "content": {"title": "Both Efficiency and Effectiveness! A Large Scale Pre-ranking Framework in Search System", "abstract": "In the realm of search systems, multi-stage cascade architecture is a prevalent method, typically consisting of sequential modules such as matching, pre-ranking, and ranking. It is generally acknowledged that the model used in the pre-ranking stage must strike a balance between efficacy and efficiency. Thus, the most commonly employed architecture is the representation-focused vector product based model. However, this architecture lacks effective interaction between the query and document, resulting in a reduction in the effectiveness of the search system. To address this issue, we present a novel pre-ranking framework called RankDFM. Our framework leverages DeepFM as the backbone and employs a pairwise training paradigm to learn the ranking of videos under a query. The capability of RankDFM to cross features provides significant improvement in offline and online A/B testing performance. Furthermore, we introduce a learnable feature selection scheme to optimize the model and reduce the time required for online inference, equivalent to a tree model. Currently, RankDFM has been deployed in the search system of a shortvideo App, providing daily services to hundreds of millions users."}}
{"id": "7_mc4N7BcjN", "cdate": 1640995200000, "mdate": 1684120694791, "content": {"title": "TCJA-SNN: Temporal-Channel Joint Attention for Spiking Neural Networks", "abstract": "Spiking Neural Networks (SNNs) is a practical approach toward more data-efficient deep learning by simulating neurons leverage on temporal information. In this paper, we propose the Temporal-Channel Joint Attention (TCJA) architectural unit, an efficient SNN technique that depends on attention mechanisms, by effectively enforcing the relevance of spike sequence along both spatial and temporal dimensions. Our essential technical contribution lies on: 1) compressing the spike stream into an average matrix by employing the squeeze operation, then using two local attention mechanisms with an efficient 1-D convolution to establish temporal-wise and channel-wise relations for feature extraction in a flexible fashion. 2) utilizing the Cross Convolutional Fusion (CCF) layer for modeling inter-dependencies between temporal and channel scope, which breaks the independence of the two dimensions and realizes the interaction between features. By virtue of jointly exploring and recalibrating data stream, our method outperforms the state-of-the-art (SOTA) by up to 15.7% in terms of top-1 classification accuracy on all tested mainstream static and neuromorphic datasets, including Fashion-MNIST, CIFAR10-DVS, N-Caltech 101, and DVS128 Gesture."}}
