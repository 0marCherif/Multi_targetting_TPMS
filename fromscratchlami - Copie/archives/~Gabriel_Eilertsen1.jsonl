{"id": "JAG6PqpS4pQ", "cdate": 1640995200000, "mdate": 1681713362027, "content": {"title": "Learning via nonlinear conjugate gradients and depth-varying neural ODEs", "abstract": "The inverse problem of supervised reconstruction of depth-variable (time-dependent) parameters in a neural ordinary differential equation (NODE) is considered, that means finding the weights of a residual network with time continuous layers. The NODE is treated as an isolated entity describing the full network as opposed to earlier research, which embedded it between pre- and post-appended layers trained by conventional methods. The proposed parameter reconstruction is done for a general first order differential equation by minimizing a cost functional covering a variety of loss functions and penalty terms. A nonlinear conjugate gradient method (NCG) is derived for the minimization. Mathematical properties are stated for the differential equation and the cost functional. The adjoint problem needed is derived together with a sensitivity problem. The sensitivity problem can estimate changes in the network output under perturbation of the trained parameters. To preserve smoothness during the iterations the Sobolev gradient is calculated and incorporated. As a proof-of-concept, numerical results are included for a NODE and two synthetic datasets, and compared with standard gradient approaches (not based on NODEs). The results show that the proposed method works well for deep learning with infinite numbers of layers, and has built-in stability and smoothness."}}
{"id": "Igz7PC6MyMs", "cdate": 1640995200000, "mdate": 1679995154610, "content": {"title": "Comparison of single image HDR reconstruction methods - the caveats of quality assessment", "abstract": ""}}
{"id": "-FNH_haZjV", "cdate": 1640995200000, "mdate": 1681713361997, "content": {"title": "Standalone Neural ODEs with Sensitivity Analysis", "abstract": "This paper presents the Standalone Neural ODE (sNODE), a continuous-depth neural ODE model capable of describing a full deep neural network. This uses a novel nonlinear conjugate gradient (NCG) descent optimization scheme for training, where the Sobolev gradient can be incorporated to improve smoothness of model weights. We also present a general formulation of the neural sensitivity problem and show how it is used in the NCG training. The sensitivity analysis provides a reliable measure of uncertainty propagation throughout a network, and can be used to study model robustness and to generate adversarial attacks. Our evaluations demonstrate that our novel formulations lead to increased robustness and performance as compared to ResNet models, and that it opens up for new opportunities for designing and developing machine learning with improved explainability."}}
{"id": "mdkdFR_lvsQ", "cdate": 1609459200000, "mdate": 1679995154688, "content": {"title": "How to cheat with metrics in single-image HDR reconstruction", "abstract": ""}}
{"id": "g0w2fRZypT", "cdate": 1609459200000, "mdate": 1679995154668, "content": {"title": "Unsupervised Anomaly Detection In Digital Pathology Using GANs", "abstract": ""}}
{"id": "Q4Y1Ub3A-wX", "cdate": 1609459200000, "mdate": 1679995154687, "content": {"title": "How to cheat with metrics in single-image HDR reconstruction", "abstract": ""}}
{"id": "OHNnP1xDgmx", "cdate": 1609459200000, "mdate": 1679995154714, "content": {"title": "Can uncertainty boost the reliability of AI-based diagnostic methods in digital pathology?", "abstract": ""}}
{"id": "MMr67H4nRw", "cdate": 1609459200000, "mdate": 1679995154629, "content": {"title": "Primary Tumor and Inter-Organ Augmentations for Supervised Lymph Node Colon Adenocarcinoma Metastasis Detection", "abstract": ""}}
{"id": "JvbxuVTA0Ck", "cdate": 1609459200000, "mdate": 1679995154670, "content": {"title": "Measuring Domain Shift for Deep Learning in Histopathology", "abstract": ""}}
{"id": "J1wqWmJs72R", "cdate": 1609459200000, "mdate": 1679995154610, "content": {"title": "Unsupervised anomaly detection in digital pathology using GANs", "abstract": ""}}
