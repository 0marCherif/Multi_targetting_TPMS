{"id": "q-hkDa5FyO", "cdate": 1672531200000, "mdate": 1693139189548, "content": {"title": "State and parameter learning with PARIS particle Gibbs", "abstract": "Non-linear state-space models, also known as general hidden Markov models (HMM), are ubiquitous in statistical machine learning, being the most classical generative models for serial data and seque..."}}
{"id": "40Vp_q1KqD", "cdate": 1672531200000, "mdate": 1693139172150, "content": {"title": "Monte Carlo guided Diffusion for Bayesian linear inverse problems", "abstract": "Ill-posed linear inverse problems that combine knowledge of the forward measurement model with prior models arise frequently in various applications, from computational photography to medical imaging. Recent research has focused on solving these problems with score-based generative models (SGMs) that produce perceptually plausible images, especially in inpainting problems. In this study, we exploit the particular structure of the prior defined in the SGM to formulate recovery in a Bayesian framework as a Feynman--Kac model adapted from the forward diffusion model used to construct score-based diffusion. To solve this Feynman--Kac problem, we propose the use of Sequential Monte Carlo methods. The proposed algorithm, MCGdiff, is shown to be theoretically grounded and we provide numerical simulations showing that it outperforms competing baselines when dealing with ill-posed inverse problems."}}
{"id": "PTo9C5G0qK9", "cdate": 1621629972515, "mdate": null, "content": {"title": "NEO: Non Equilibrium Sampling on the Orbits of a Deterministic Transform", "abstract": "Sampling from a complex distribution $\\pi$ and approximating its intractable normalizing constant $\\mathrm{Z}$ are challenging problems. \nIn this paper, a novel family of importance samplers (IS) and Markov chain Monte Carlo (MCMC) samplers is derived. \nGiven an invertible map $\\mathrm{T}$, these schemes combine (with weights) elements from the forward and backward Orbits   through points sampled from a proposal distribution $\\rho$. The map $\\mathrm{T}$ does not leave the target $\\pi$ invariant, hence the name NEO, standing for Non-Equilibrium Orbits. \nNEO-IS provides unbiased estimators of the normalizing constant and self-normalized IS estimators of expectations under $\\pi$ while NEO-MCMC combines multiple NEO-IS estimates of the normalizing constant and an iterated sampling-importance resampling mechanism to sample from $\\pi$. \nFor $\\mathrm{T}$ chosen as a discrete-time integrator of a conformal Hamiltonian system, NEO-IS achieves state-of-the art performance on difficult benchmarks and NEO-MCMC is able to explore highly multimodal targets. Additionally, we provide detailed theoretical results for both methods. In particular, we show that NEO-MCMC is uniformly geometrically ergodic and establish explicit mixing time estimates under mild conditions.\n"}}
{"id": "76tTYokjtG", "cdate": 1621629972515, "mdate": null, "content": {"title": "NEO: Non Equilibrium Sampling on the Orbits of a Deterministic Transform", "abstract": "Sampling from a complex distribution $\\pi$ and approximating its intractable normalizing constant $\\mathrm{Z}$ are challenging problems. \nIn this paper, a novel family of importance samplers (IS) and Markov chain Monte Carlo (MCMC) samplers is derived. \nGiven an invertible map $\\mathrm{T}$, these schemes combine (with weights) elements from the forward and backward Orbits   through points sampled from a proposal distribution $\\rho$. The map $\\mathrm{T}$ does not leave the target $\\pi$ invariant, hence the name NEO, standing for Non-Equilibrium Orbits. \nNEO-IS provides unbiased estimators of the normalizing constant and self-normalized IS estimators of expectations under $\\pi$ while NEO-MCMC combines multiple NEO-IS estimates of the normalizing constant and an iterated sampling-importance resampling mechanism to sample from $\\pi$. \nFor $\\mathrm{T}$ chosen as a discrete-time integrator of a conformal Hamiltonian system, NEO-IS achieves state-of-the art performance on difficult benchmarks and NEO-MCMC is able to explore highly multimodal targets. Additionally, we provide detailed theoretical results for both methods. In particular, we show that NEO-MCMC is uniformly geometrically ergodic and establish explicit mixing time estimates under mild conditions.\n"}}
{"id": "lRazhJPgFj", "cdate": 1609459200000, "mdate": 1682325950662, "content": {"title": "NEO: Non Equilibrium Sampling on the Orbits of a Deterministic Transform", "abstract": "Sampling from a complex distribution $\\pi$ and approximating its intractable normalizing constant $\\mathrm{Z}$ are challenging problems. In this paper, a novel family of importance samplers (IS) and Markov chain Monte Carlo (MCMC) samplers is derived. Given an invertible map $\\mathrm{T}$, these schemes combine (with weights) elements from the forward and backward Orbits through points sampled from a proposal distribution $\\rho$. The map $\\mathrm{T}$ does not leave the target $\\pi$ invariant, hence the name NEO, standing for Non-Equilibrium Orbits. NEO-IS provides unbiased estimators of the normalizing constant and self-normalized IS estimators of expectations under $\\pi$ while NEO-MCMC combines multiple NEO-IS estimates of the normalizing constant and an iterated sampling-importance resampling mechanism to sample from $\\pi$. For $\\mathrm{T}$ chosen as a discrete-time integrator of a conformal Hamiltonian system, NEO-IS achieves state-of-the art performance on difficult benchmarks and NEO-MCMC is able to explore highly multimodal targets. Additionally, we provide detailed theoretical results for both methods. In particular, we show that NEO-MCMC is uniformly geometrically ergodic and establish explicit mixing time estimates under mild conditions."}}
