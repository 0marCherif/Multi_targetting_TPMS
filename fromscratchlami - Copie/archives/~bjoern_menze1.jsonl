{"id": "X_AJqHfE1H", "cdate": 1673287852742, "mdate": null, "content": {"title": "Vesselformer: Towards Complete 3D Vessel Graph Generation from Images", "abstract": "The reconstruction of graph representations from Images (Image-to-graph) is a frequent task, especially vessel graph extraction from biomedical images. Traditionally, this problem is tackled by a two-stage process: segmentation followed by skeletonization. However, the ambiguity in the heuristic-based pruning of the centerline graph from the skeleta makes it hard to achieve a compact yet faithful graph representation. Recently, \\textit{Relationformer} proposed an end-to-end solution to extract graphs directly from images. However, it does not consider edge features, particularly radius information, which is crucial in many applications such as flow simulation. Further, Relationformer predicts only patch-based graphs. In this work, we address these two shortcomings. We propose a task-specific token, namely radius-token, which explicitly focuses on capturing radius information between two nodes. Second, we propose an efficient algorithm to infer a large 3D graph from patch inference. Finally, we show experimental results on a synthetic vessel dataset and achieve the first 3D complete graph prediction. Code is available at \\url{https://github.com/chinmay5/vesselformer}.\n"}}
{"id": "2Aoi0VKPOWT", "cdate": 1673287845647, "mdate": null, "content": {"title": "ViT-AE++: Improving Vision Transformer Autoencoder for Self-supervised Medical Image Representations", "abstract": "Self-supervised learning has attracted increasing attention as it learns data-driven representation from data without annotations. Vision transformer-based autoencoder (ViT-AE) by He et al. (2021) is a recent self-supervised learning technique that employs a patch-masking strategy to learn a meaningful latent space. In this paper, we focus on improving ViT-AE (nicknamed ViT-AE++) for a more effective representation of both 2D and 3D medical images. We propose two new loss functions to enhance the representation during the training stage. The first loss term aims to improve self-reconstruction by considering the structured dependencies and hence indirectly improving the representation. The second loss term leverages contrastive loss to directly optimize the representation from two randomly masked views.\nAs an independent contribution, we extended ViT-AE++ to a 3D fashion for volumetric medical images. \nWe extensively evaluate ViT-AE++ on both natural images and medical images, demonstrating consistent improvement over vanilla ViT-AE and its superiority over other contrastive learning approaches.  Our code is available at https://github.com/chinmay5/vit_ae_plus_plus.git"}}
{"id": "xTG5BaQxgAR", "cdate": 1672531200000, "mdate": 1677745227869, "content": {"title": "Understanding metric-related pitfalls in image analysis validation", "abstract": ""}}
{"id": "qozoME8TbjJ", "cdate": 1672531200000, "mdate": 1677745225329, "content": {"title": "ViT-AE++: Improving Vision Transformer Autoencoder for Self-supervised Medical Image Representations", "abstract": ""}}
{"id": "dAltdZtn7gh", "cdate": 1672531200000, "mdate": 1677745230358, "content": {"title": "Approaching Peak Ground Truth", "abstract": ""}}
{"id": "M6N7mXCcnU", "cdate": 1672531200000, "mdate": 1677745228983, "content": {"title": "The Liver Tumor Segmentation Benchmark (LiTS)", "abstract": ""}}
{"id": "2rekyGx9osHn", "cdate": 1672531200000, "mdate": 1677745230845, "content": {"title": "Learn-Morph-Infer: A new way of solving the inverse problem for brain tumor modeling", "abstract": ""}}
{"id": "8W1ar7zATN", "cdate": 1664090931394, "mdate": null, "content": {"title": "Graflow: Neural Blood Flow Solver for Vascular Graph", "abstract": "Simulating blood flow is paramount in identifying flow-based biomarkers for vascular-related diseases. A segmented vessel graph is used as a domain for the simulation. Traditionally, partial differential equations are solved with numerical methods. Here, we propose an alternative solver for the simulation of blood flow on a vascular graph leveraging geometric deep learning. Specifically, we reformulate the problem as an implicit function on the graph and learn the simulation by imposing the physics in the loss through a message passing layer. The resultant flow is accurate, fast, and applicable to various tasks."}}
{"id": "a3-QYAgcDBl", "cdate": 1663849858054, "mdate": null, "content": {"title": " Topologically faithful image segmentation via induced matching of persistence barcodes", "abstract": "Image segmentation is a largely researched field where neural networks find vast applications in many facets of technology.\nSome of the most popular approaches to train segmentation networks employ loss functions optimizing pixel-overlap, an objective that is \ninsufficient for many segmentation tasks. In recent years, their limitations fueled a growing interest in topology-aware methods, which aim to recover the correct topology of the segmented structures. However, so far, none of the existing approaches achieve a spatially correct matching between the topological features (persistence barcodes) of label (ground truth) and prediction (output of the neural network). \n\nIn this work, we propose the first topologically and feature-wise accurate metric and loss function for supervised image segmentation, which we term TopoMatch. We show how induced matchings guarantee the spatially correct matching between barcodes in a segmentation setting. Furthermore, we propose an efficient algorithm to compute TopoMatch for images. We show that TopoMatch is an interpretable metric to evaluate the topological correctness of segmentations. Moreover, we demonstrate how induced matchings can be used to train segmentation networks and improve the topological correctness of the segmentations across all 6 baseline datasets while preserving volumetric segmentation performance. "}}
{"id": "HZdwrageyj", "cdate": 1662300298283, "mdate": null, "content": {"title": "HeteroKG: Knowledge graphs for multi-modal learning", "abstract": "Medical knowledge graphs (KG) are a source of highly granular, semantically rich, and curated medical ontologies. However, they have seen limited adoption in various multi-modal medical imaging tasks owing to their sheer size.  Instead, semantic label embeddings from language models such as BERT and word2vec are currently employed. These embeddings are derived from word co-occurrences and encode rich semantic associations. However, they lack explicit relational information which KG intrinsically encode. On the other hand, the expressive power of KG is limited by its parsed size. In view of these observations, we propose a way to learn KG embeddings on the parsed heterogeneous graph and complement it with language embeddings. We test our hypothesis on generalized zero-shot learning of chest radiographs."}}
