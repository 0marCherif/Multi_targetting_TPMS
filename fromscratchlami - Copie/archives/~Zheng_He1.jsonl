{"id": "9xlU4lhri9", "cdate": 1663850049312, "mdate": null, "content": {"title": "Rethinking the Structure of Stochastic Gradients: Empirical and Statistical Evidence", "abstract": "It is well known that stochastic gradients significantly improve both optimization and generalization of deep neural networks (DNNs). Some works attempted to explain the success of stochastic optimization for deep learning by the arguably heavy-tail properties of gradient noise, while other works presented theoretical and empirical evidence against the heavy-tail hypothesis on gradient noise. Unfortunately, formal statistical tests for analyzing the structure and heavy tails of stochastic gradients in deep learning are still under-explored. In this paper, we mainly make two contributions. First, we conduct formal statistical tests on the distribution of stochastic gradients and gradient noise across both parameters and iterations. Our statistical tests reveal that dimension-wise gradients usually exhibit power-law heavy tails, while iteration-wise gradients and stochastic gradient noise caused by minibatch training usually do not exhibit power-law heavy tails. Second, we further discover that the covariance spectra of stochastic gradients have the power-law structures in deep learning. While previous papers believed that the anisotropic structure of stochastic gradients matters to deep learning, they did not expect the gradient covariance can have such an elegant mathematical structure. Our work challenges the existing belief and provides novel insights on the structure of stochastic gradients. The novel structure of stochastic gradients may help understand the success of stochastic optimization for deep learning."}}
{"id": "VyFmc-EbQsp", "cdate": 1640995200000, "mdate": 1668430074620, "content": {"title": "Sparse Double Descent: Where Network Pruning Aggravates Overfitting", "abstract": "People usually believe that network pruning not only reduces the computational cost of deep networks, but also prevents overfitting by decreasing model capacity. However, our work surprisingly discovers that network pruning sometimes even aggravates overfitting. We report an unexpected sparse double descent phenomenon that, as we increase model sparsity via network pruning, test performance first gets worse (due to overfitting), then gets better (due to relieved overfitting), and gets worse at last (due to forgetting useful information). While recent studies focused on the deep double descent with respect to model overparameterization, they failed to recognize that sparsity may also cause double descent. In this paper, we have three main contributions. First, we report the novel sparse double descent phenomenon through extensive experiments. Second, for this phenomenon, we propose a novel learning distance interpretation that the curve of $\\ell_{2}$ learning distance of sparse models (from initialized parameters to final parameters) may correlate with the sparse double descent curve well and reflect generalization better than minima flatness. Third, in the context of sparse double descent, a winning ticket in the lottery ticket hypothesis surprisingly may not always win."}}
{"id": "Vkr9sA_IRQM", "cdate": 1640995200000, "mdate": 1668430074597, "content": {"title": "Sparse Double Descent: Where Network Pruning Aggravates Overfitting", "abstract": "People usually believe that network pruning not only reduces the computational cost of deep networks, but also prevents overfitting by decreasing model capacity. However, our work surprisingly disc..."}}
{"id": "3nPp56yY7in", "cdate": 1640995200000, "mdate": 1682318339083, "content": {"title": "Rethinking the Structure of Stochastic Gradients: Empirical and Statistical Evidence", "abstract": "Stochastic gradients closely relate to both optimization and generalization of deep neural networks (DNNs). Some works attempted to explain the success of stochastic optimization for deep learning by the arguably heavy-tail properties of gradient noise, while other works presented theoretical and empirical evidence against the heavy-tail hypothesis on gradient noise. Unfortunately, formal statistical tests for analyzing the structure and heavy tails of stochastic gradients in deep learning are still under-explored. In this paper, we mainly make two contributions. First, we conduct formal statistical tests on the distribution of stochastic gradients and gradient noise across both parameters and iterations. Our statistical tests reveal that dimension-wise gradients usually exhibit power-law heavy tails, while iteration-wise gradients and stochastic gradient noise caused by minibatch training usually do not exhibit power-law heavy tails. Second, we further discover that the covariance spectra of stochastic gradients have the power-law structures in deep learning. While previous papers believed that the anisotropic structure of stochastic gradients matters to deep learning, they did not expect the gradient covariance can have such an elegant mathematical structure. Our work challenges the existing belief and provides novel insights on the structure of stochastic gradients in deep learning."}}
{"id": "_ERVcPna8IP", "cdate": 1632875698103, "mdate": null, "content": {"title": "Can network pruning benefit deep learning under label noise?", "abstract": "Network pruning is a widely-used technique to reduce the computational cost of over-parameterized neural networks. Conventional wisdom also regards pruning as a way to improve generalization: by zeroing out parameters, pruning reduces model capacity and prevents overfitting. However, this wisdom is facing challenges in a line of recent studies, which show that over-parameterization actually helps generalization. In this work, we demonstrate the existence of a novel double descent phenomenon in sparse regimes, namely, in the presence of label noise, medium sparsity induced by pruning hurts model performance, while high sparsity benefits. Through extensive experiments on noisy versions of MNIST, CIFAR-10 and CIFAR-100, We show that proper pruning could consistently promise non-trivial robustness against label noise, which provides a new lens for studying network pruning. Further, we reassess some common beliefs concerning the generalization of sparse networks, and hypothesize it is the distance from initialization that is key to robustness rather than sharpness/flatness. Experimental results correlate with this hypothesis. Together, our study provides valuable insight on whether, when and why network pruning benefits deep learning under label noise.\n"}}
{"id": "EDqEkRh3Z0S", "cdate": 1609459200000, "mdate": 1682318339017, "content": {"title": "Random Neural Graph Generation with Structure Evolution", "abstract": "In deep learning research, typical neural network models are multi-layered architectures, and weights are tuned while optimizing a carefully designed loss function. In recent years, studies of randomized neural networks have been extended towards deep architectures, opening a new research direction to the design of deep learning models. However, how the structure of the network can influence the model performance still remains unclear. In this paper, we move a further step to investigate the relation between network topology and performance via a structure evolution algorithm. Experimental results show that the graph would evolve towards a more small-world topology at the beginning of the training session along with gaining accuracy, and would also evolve towards a structure with more scale-free property in the following periods. These conclusions could help explain the effectiveness of the randomly connected networks, as well as give us insights in new possibilities of network architecture design."}}
