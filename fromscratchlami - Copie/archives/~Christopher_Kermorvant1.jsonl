{"id": "-RhY9Zi8bV", "cdate": 1675209600000, "mdate": 1682931417010, "content": {"title": "Confidence Estimation for Object Detection in Document Images", "abstract": ""}}
{"id": "zactG7czTb", "cdate": 1640995200000, "mdate": 1682931417318, "content": {"title": "A Comprehensive Comparison of Open-Source Libraries for Handwritten Text Recognition in Norwegian", "abstract": "In this paper, we introduce an open database of historical handwritten documents fully annotated in Norwegian, the first of its kind, allowing the development of handwritten text recognition models (HTR) in Norwegian. In order to evaluate the performance of state-of-the-art HTR models on this new base, we conducted a systematic survey of open-source HTR libraries published between 2019 and 2021, identified ten libraries and selected four of them to train HTR models. We trained twelve models in different configurations and compared their performance on both random and scripter-based data splitting. The best recognition results were obtained by the PyLaia and Kaldi libraries which have different and complementary characteristics, suggesting that they should be combined to further improve the results."}}
{"id": "Zsw1OdmOQb", "cdate": 1640995200000, "mdate": 1682931417191, "content": {"title": "A Comprehensive Study of Open-Source Libraries for Named Entity Recognition on Handwritten Historical Documents", "abstract": "In this paper, we propose an evaluation of several state-of-the-art open-source natural language processing (NLP) libraries for named entity recognition (NER) on handwritten historical documents: spaCy, Stanza and Flair. The comparison is carried out on three low-resource multilingual datasets of handwritten historical documents: HOME (a multilingual corpus of medieval charters), Balsac (a corpus of parish records from Quebec), and Esposalles (a corpus of marriage records in Catalan). We study the impact of the document recognition processes (text line detection and handwriting recognition) on the performance of the NER. We show that current off-the-shelf NER libraries yield state-of-the-art results, even on low-resource languages or multilingual documents using multilingual models. We show, in an end-to-end evaluation, that text line detection errors have a greater impact than handwriting recognition errors. Finally, we also report state-of-the-art results on the public Esposalles dataset."}}
{"id": "YpYNswQT9_W", "cdate": 1640995200000, "mdate": 1682931417443, "content": {"title": "The LAM Dataset: A Novel Benchmark for Line-Level Handwritten Text Recognition", "abstract": "Handwritten Text Recognition (HTR) is an open problem at the intersection of Computer Vision and Natural Language Processing. The main challenges, when dealing with historical manuscripts, are due to the preservation of the paper support, the variability of the handwriting \u2013 even of the same author over a wide time-span \u2013 and the scarcity of data from ancient, poorly represented languages. With the aim of fostering the research on this topic, in this paper we present the Ludovico Antonio Muratori (LAM) dataset, a large line-level HTR dataset of Italian ancient manuscripts edited by a single author over 60 years. The dataset comes in two configurations: a basic splitting and a date-based splitting which takes into account the age of the author. The first setting is intended to study HTR on ancient documents in Italian, while the second focuses on the ability of HTR systems to recognize text written by the same writer in time periods for which training data are not available. For both configurations, we analyze quantitative and qualitative characteristics, also with respect to other line-level HTR benchmarks, and present the recognition performance of state-of-the-art HTR architectures. The dataset is available for download at https://aimagelab.ing.unimore.it/go/lam."}}
{"id": "QzbQJ0bCQoV", "cdate": 1640995200000, "mdate": 1682931417436, "content": {"title": "Robust Text Line Detection in Historical Documents: Learning and Evaluation Methods", "abstract": "Text line segmentation is one of the key steps in historical document understanding. It is challenging due to the variety of fonts, contents, writing styles and the quality of documents that have degraded through the years. In this paper, we address the limitations that currently prevent people from building line segmentation models with a high generalization capacity. We present a study conducted using three state-of-the-art systems Doc-UFCN, dhSegment and ARU-Net and show that it is possible to build generic models trained on a wide variety of historical document datasets that can correctly segment diverse unseen pages. This paper also highlights the importance of the annotations used during training: each existing dataset is annotated differently. We present a unification of the annotations and show its positive impact on the final text recognition results. In this end, we present a complete evaluation strategy using standard pixel-level metrics, object-level ones and introducing goal-oriented metrics."}}
{"id": "H44dRmegQa", "cdate": 1640995200000, "mdate": 1682931417234, "content": {"title": "Confidence Estimation for Object Detection in Document Images", "abstract": "Deep neural networks are becoming increasingly powerful and large and always require more labelled data to be trained. However, since annotating data is time-consuming, it is now necessary to develop systems that show good performance while learning on a limited amount of data. These data must be correctly chosen to obtain models that are still efficient. For this, the systems must be able to determine which data should be annotated to achieve the best results. In this paper, we propose four estimators to estimate the confidence of object detection predictions. The first two are based on Monte Carlo dropout, the third one on descriptive statistics and the last one on the detector posterior probabilities. In the active learning framework, the three first estimators show a significant improvement in performance for the detection of document physical pages and text lines compared to a random selection of images. We also show that the proposed estimator based on descriptive statistics can replace MC dropout, reducing the computational cost without compromising the performances."}}
{"id": "FNAHdJ8LI4v", "cdate": 1640995200000, "mdate": 1682931417203, "content": {"title": "Robust text line detection in historical documents: learning and evaluation methods", "abstract": "Text line segmentation is one of the key steps in historical document understanding. It is challenging due to the variety of fonts, contents, writing styles and the quality of documents that have degraded through the years. In this paper, we address the limitations that currently prevent people from building line segmentation models with a high generalization capacity. We present a study conducted using three state-of-the-art systems Doc-UFCN, dhSegment and ARU-Net and show that it is possible to build generic models trained on a wide variety of historical document datasets that can correctly segment diverse unseen pages. This paper also highlights the importance of the annotations used during training: Each existing dataset is annotated differently. We present a unification of the annotations and show its positive impact on the final text recognition results. In this end, we present a complete evaluation strategy using standard pixel-level metrics, object-level ones and introducing goal-oriented metrics."}}
{"id": "B-G8nR-OZ0X", "cdate": 1640995200000, "mdate": 1667498851227, "content": {"title": "The LAM Dataset: A Novel Benchmark for Line-Level Handwritten Text Recognition", "abstract": "Handwritten Text Recognition (HTR) is an open problem at the intersection of Computer Vision and Natural Language Processing. The main challenges, when dealing with historical manuscripts, are due to the preservation of the paper support, the variability of the handwriting -- even of the same author over a wide time-span -- and the scarcity of data from ancient, poorly represented languages. With the aim of fostering the research on this topic, in this paper we present the Ludovico Antonio Muratori (LAM) dataset, a large line-level HTR dataset of Italian ancient manuscripts edited by a single author over 60 years. The dataset comes in two configurations: a basic splitting and a date-based splitting which takes into account the age of the author. The first setting is intended to study HTR on ancient documents in Italian, while the second focuses on the ability of HTR systems to recognize text written by the same writer in time periods for which training data are not available. For both configurations, we analyze quantitative and qualitative characteristics, also with respect to other line-level HTR benchmarks, and present the recognition performance of state-of-the-art HTR architectures. The dataset is available for download at \\url{https://aimagelab.ing.unimore.it/go/lam}."}}
{"id": "XKFh9s1O17E", "cdate": 1609459200000, "mdate": 1682931417012, "content": {"title": "Drilling a Large Corpus of Document Images of Geological Information Extraction", "abstract": "Geo-energy is a resource widely available on Earth that consists in using the first 10\u2013100 meters below the surface where the temperature is low and constant during the year. This 12 to 15\u00a0 $$^\\circ $$ C is ideal for heat pumps to provide heat and cold with an excellent coefficient of performance. Despite a very high potential, this resource is not often integrated in France. One of the main reasons is the lack of knowledge of rocks capacity to deliver sufficient power on surface. More than 2 millions of scanned documents are available on the french geological survey. We propose a way to classify and analyze them in order to quantify the underground resource."}}
{"id": "JKRQGLt74zq", "cdate": 1609459200000, "mdate": 1682931417418, "content": {"title": "Including Keyword Position in Image-based Models for Act Segmentation of Historical Registers", "abstract": "The segmentation of complex images into semantic regions has seen a growing interest these last years with the advent of Deep Learning. Until recently, most existing methods for Historical Document Analysis focused on the visual appearance of documents, ignoring the rich information that textual content can offer. However, the segmentation of complex documents into semantic regions is sometimes impossible relying only on visual features and recent models embed both visual and textual information. In this paper, we focus on the use of both visual and textual information for segmenting historical registers into structured and meaningful units such as acts. An act is a text recording containing valuable knowledge such as demographic information (baptism, marriage or death) or royal decisions (donation or pardon). We propose a simple pipeline to enrich document images with the position of text lines containing key-phrases and show that running a standard image-based layout analysis system on these images can lead to significant gains. Our experiments show that the detection of acts increases from 38 % of mAP to 74 % when adding textual information, in real use-case conditions where text lines positions and content are extracted with an automatic recognition system."}}
