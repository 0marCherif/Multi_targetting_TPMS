{"id": "gqfcmVbiYQ", "cdate": 1672531200000, "mdate": 1682670087397, "content": {"title": "gfpop: An R Package for Univariate Graph-Constrained Change-Point Detection", "abstract": "p>In a world with data that change rapidly and abruptly, it is important to detect those changes accurately. In this paper we describe an R package implementing a generalized version of an algorithm recently proposed by Hocking, Rigaill, Fearnhead, and Bourque (2020) for penalized maximum likelihood inference of constrained multiple change-point models. This algorithm can be used to pinpoint the precise locations of abrupt changes in large data sequences. There are many application domains for such models, such as medicine, neuroscience or genomics. Often, practitioners have prior knowledge about the changes they are looking for. For example in genomic data, biologists sometimes expect peaks: up changes followed by down changes. Taking advantage of such prior information can substantially improve the accuracy with which we can detect and estimate changes. Hocking et al. (2020) described a graph framework to encode many examples of such prior information and a generic algorithm to infer the optimal model parameters, but implemented the algorithm for just a single scenario. We present the gfpop package that implements the algorithm in a generic manner in R/C++. gfpop works for a user-defined graph that can encode prior assumptions about the types of changes that are possible and implements several loss functions (Gauss, Poisson, binomial, biweight, and Huber). We then illustrate the use of gfpop on isotonic simulations and several applications in biology. For a number of graphs the algorithm runs in a matter of seconds or minutes for 105 data points.</p>"}}
{"id": "Vi_eJaqCEN3", "cdate": 1672531200000, "mdate": 1682670087386, "content": {"title": "Online non-parametric changepoint detection with application to monitoring operational performance of network devices", "abstract": ""}}
{"id": "RHa77BXv6k", "cdate": 1652737597129, "mdate": null, "content": {"title": "Continuously Tempered PDMP samplers", "abstract": "New sampling algorithms based on simulating continuous-time stochastic processes called piece-wise deterministic Markov processes (PDMPs) have shown considerable promise. However, these methods can struggle to sample from multi-modal or heavy-tailed distributions. We show how tempering ideas can improve the mixing of PDMPs in such cases. We introduce an extended distribution defined over the state of the posterior distribution and an inverse temperature, which interpolates between a tractable distribution when the inverse temperature is 0 and the posterior when the inverse temperature is 1. The marginal distribution of the inverse temperature is a mixture of a continuous distribution on $[0,1)$ and a point mass at 1: which means that we obtain samples when the inverse temperature is 1, and these are draws from the posterior, but sampling algorithms will also explore distributions at lower temperatures which will improve mixing. We show how PDMPs, and particularly the Zig-Zag sampler, can be implemented to sample from such an extended distribution. The resulting algorithm is easy to implement and we show empirically that it can outperform existing PDMP-based samplers on challenging multimodal posteriors."}}
{"id": "w8BJGi99vvf", "cdate": 1640995200000, "mdate": 1682670087513, "content": {"title": "Efficient computation of the volume of a polytope in high-dimensions using Piecewise Deterministic Markov Processes", "abstract": "Computing the volume of a polytope in high dimensions is computationally challenging but has wide applications. Current state-of-the-art algorithms to compute such volumes rely on efficient sampling of a Gaussian distribution restricted to the polytope, using e.g. Hamiltonian Monte Carlo. We present a new sampling strategy that uses a Piecewise Deterministic Markov Process. Like Hamiltonian Monte Carlo, this new method involves simulating trajectories of a non-reversible process and inherits similar good mixing properties. However, importantly, the process can be simulated more easily due to its piecewise linear trajectories - and this leads to a reduction of the computational cost by a factor of the dimension of the space. Our experiments indicate that our method is numerically robust and is one order of magnitude faster (or better) than existing methods using Hamiltonian Monte Carlo. On a single core processor, we report computational time of a few minutes up to dimension 500."}}
{"id": "rHG0Chc-cnf", "cdate": 1640995200000, "mdate": 1682670087388, "content": {"title": "Innovative and Additive Outlier Robust Kalman Filtering With a Robust Particle Filter", "abstract": "In this paper, we propose CE-BASS, a particle mixture Kalman filter which is robust to both innovative and additive outliers, and able to fully capture multi-modality in the distribution of the hidden state. Furthermore, the particle sampling approach re-samples past states, which enables CE-BASS to handle innovative outliers which are not immediately visible in the observations, such as trend changes. The filter is computationally efficient as we derive new, accurate approximations to the optimal proposal distributions for the particles. The proposed algorithm is shown to compare well with existing approaches and is applied to both machine temperature and server data."}}
{"id": "lAJILe-vRW", "cdate": 1640995200000, "mdate": 1682670087386, "content": {"title": "Automatic Change-Point Detection in Time Series via Deep Learning", "abstract": "Detecting change-points in data is challenging because of the range of possible types of change and types of behaviour of data when there is no change. Statistically efficient methods for detecting a change will depend on both of these features, and it can be difficult for a practitioner to develop an appropriate detection method for their application of interest. We show how to automatically generate new offline detection methods based on training a neural network. Our approach is motivated by many existing tests for the presence of a change-point being representable by a simple neural network, and thus a neural network trained with sufficient data should have performance at least as good as these methods. We present theory that quantifies the error rate for such an approach, and how it depends on the amount of training data. Empirical results show that, even with limited training data, its performance is competitive with the standard CUSUM-based classifier for detecting a change in mean when the noise is independent and Gaussian, and can substantially outperform it in the presence of auto-correlated or heavy-tailed noise. Our method also shows strong results in detecting and localising changes in activity based on accelerometer data."}}
{"id": "huUxq-wX5K", "cdate": 1640995200000, "mdate": 1682670087384, "content": {"title": "Limit theory and robust evaluation methods for the extremal properties of GARCH(p, q) processes", "abstract": "Generalized autoregressive conditionally heteroskedastic (GARCH) processes are widely used for modelling financial returns, with their extremal properties being of interest for market risk management. For GARCH( $$p,q$$ p , q ) processes with $$\\max (p,q) = 1$$ max ( p , q ) = 1 all extremal features have been fully characterised, but when $$\\max (p,q)\\ge 2$$ max ( p , q ) \u2265 2 much remains to be found. Previous research has identified that both marginal and dependence extremal features of strictly stationary GARCH( $$p,q$$ p , q ) processes are determined by a multivariate regular variation property and tail processes. Currently there are no reliable methods for evaluating these characterisations, or even assessing the stationarity, for the classes of GARCH( $$p,q$$ p , q ) processes that are used in practice, i.e., with unbounded and asymmetric innovations. By developing a mixture of new limit theory and particle filtering algorithms for fixed point distributions we produce novel and robust evaluation methods for all extremal features for all GARCH( $$p,q$$ p , q ) processes, including ARCH and IGARCH processes. We investigate our methods\u2019 performance when evaluating the marginal tail index, the extremogram and the extremal index, the latter two being measures of temporal dependence."}}
{"id": "dWXO7bqRNq", "cdate": 1640995200000, "mdate": 1682670087384, "content": {"title": "Generalized Functional Pruning Optimal Partitioning (GFPOP) for Constrained Changepoint Detection in Genomic Data", "abstract": "p>We describe a new algorithm and R package for peak detection in genomic data sets using constrained changepoint models. These detect changes from background to peak regions by imposing the constraint that the mean should alternately increase then decrease. An existing algorithm for this problem exists, and gives state-of-the-art accuracy results, but it is computationally expensive when the number of changes is large. We propose a dynamic programming algorithm that jointly estimates the number of peaks and their locations by minimizing a cost function which consists of a data fitting term and a penalty for each changepoint. Empirically this algorithm has a cost that is O(N log(N )) for analyzing data of length N . We also propose a sequential search algorithm that finds the best solution with K segments in O(log(K) N log(N )) time, which is much faster than the previous O(K N log(N )) algorithm. We show that our disk-based implementation in the PeakSegDisk R package can be used to quickly compute constrained optimal models with many changepoints, which are needed to analyze typical genomic data sets that have tens of millions of observations.</p>"}}
{"id": "dROSuOEzFZm", "cdate": 1640995200000, "mdate": 1682670087395, "content": {"title": "A linear time method for the detection of collective and point anomalies", "abstract": "The challenge of efficiently identifying anomalies in data sequences is an important statistical problem that now arises in many applications. Although there has been substantial work aimed at making..."}}
{"id": "UBfVVOhrG1", "cdate": 1640995200000, "mdate": 1682670087547, "content": {"title": "Preferential Subsampling for Stochastic Gradient Langevin Dynamics", "abstract": "Stochastic gradient MCMC (SGMCMC) offers a scalable alternative to traditional MCMC, by constructing an unbiased estimate of the gradient of the log-posterior with a small, uniformly-weighted subsample of the data. While efficient to compute, the resulting gradient estimator may exhibit a high variance and impact sampler performance. The problem of variance control has been traditionally addressed by constructing a better stochastic gradient estimator, often using control variates. We propose to use a discrete, non-uniform probability distribution to preferentially subsample data points that have a greater impact on the stochastic gradient. In addition, we present a method of adaptively adjusting the subsample size at each iteration of the algorithm, so that we increase the subsample size in areas of the sample space where the gradient is harder to estimate. We demonstrate that such an approach can maintain the same level of accuracy while substantially reducing the average subsample size that is used."}}
