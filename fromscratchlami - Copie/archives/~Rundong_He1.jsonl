{"id": "H9jNEDqCai", "cdate": 1675263818673, "mdate": 1675263818673, "content": {"title": "Not All Parameters Should Be Treated Equally: Deep Safe Semi-supervised Learning under Class Distribution Mismatch", "abstract": "Deep semi-supervised learning (SSL) aims to utilize a size- able unlabeled set to train deep networks, thereby reducing the dependence on labeled instances. However, the unlabeled set often carries unseen classes that cause the deep SSL al- gorithm to lose generalization. Previous works focus on the data level that they attempt to remove unseen class data or assign lower weight to them but could not eliminate their ad- verse effects on the SSL algorithm. Rather than focusing on the data level, this paper turns attention to the model param- eter level. We find that only partial parameters are essential for seen-class classification, termed safe parameters. In con- trast, the other parameters tend to fit irrelevant data, termed harmful parameters. Driven by this insight, we propose Safe Parameter Learning (SPL) to discover safe parameters and make the harmful parameters inactive, such that we can miti- gate the adverse effects caused by unseen-class data. Specif- ically, we firstly design an effective strategy to divide all pa- rameters in the pre-trained SSL model into safe and harmful ones. Then, we introduce a bi-level optimization strategy to update the safe parameters and kill the harmful parameters. Extensive experiments show that SPL outperforms the state- of-the-art SSL methods on all the benchmarks by a large mar- gin. Moreover, experiments demonstrate that SPL can be inte- grated into the most popular deep SSL networks and be easily extended to handle other cases of class distribution mismatch."}}
{"id": "e5vtyXxDhZ", "cdate": 1675263670975, "mdate": 1675263670975, "content": {"title": "Safe-Student for Safe Deep Semi-Supervised Learning with Unseen-Class Unlabeled Data", "abstract": "Deep semi-supervised learning (SSL) methods aim to take advantage of abundant unlabeled data to improve the algorithm performance. In this paper, we consider the prob- lem of safe SSL scenario where unseen-class instances ap- pear in the unlabeled data. This setting is essential and commonly appears in a variety of real applications. One intuitive solution is removing these unseen-class instances after detecting them during the SSL process. Neverthe- less, the performance of unseen-class identification is lim- ited by the small number of labeled data and ignoring the availability of unlabeled data. To take advantage of these unseen-class data and ensure performance, we pro- pose a safe SSL method called SAFE-STUDENT from the teacher-student view. Firstly, a new scoring function called energy-discrepancy (ED) is proposed to help the teacher model improve the security of instances selection. Then, a novel unseen-class label distribution learning mechanism mitigates the unseen-class perturbation by calibrating the unseen-class label distribution. Finally, we propose an iter- ative optimization strategy to facilitate teacher-student net- work learning. Extensive studies on several representa- tive datasets show that SAFE-STUDENT remarkably out- performs the state-of-the-art, verifying the feasibility and robustness of our method in the under-explored problem."}}
{"id": "qwu5xQKkNF", "cdate": 1668593834972, "mdate": 1668593834972, "content": {"title": "RONF: Reliable Outlier Synthesis under Noisy Feature Space for Out-of-Distribution Detection", "abstract": "Out-of-distribution~(OOD) detection is fundamental to guaranteeing the reliability of multimedia applications during deployment in the open world. However, due to the lack of supervision signals from OOD data, the current model easily outputs overconfident predictions to OOD data during the inference phase. Several previous methods rely on large-scale auxiliary OOD datasets for model regularization. However, obtaining suitable and clean large-scale auxiliary OOD datasets is usually challenging. In this paper, we present \\underline{R}eliable \\underline{O}utlier synthesis under \\underline{N}oisy \\underline{F}eature space~(RONF), which synthesizes reliable virtual outliers in noisy feature space to provide supervision signals for model regularization. Specifically, RONF first introduces a novel virtual outlier synthesis strategy  \\underline{B}oundary \\underline{F}eature \\underline{M}ixup~(BFM), which mixes up samples from the low-likelihood region of the class-conditional distribution in the feature space. However, the feature space is noisy due to the spurious features, which cause unreliable outlier synthesizing. To mitigate this problem, RONF then introduces \\underline{O}ptimal \\underline{P}arameter \\underline{L}earning~(OPL) to obtain desirable features and remove spurious features. Alongside, RONF proposes a provable and effective scoring function called \\underline{E}nergy with \\underline{E}nergy \\underline{D}iscrepancy~(EED) for the uncertainty measurement of OOD data. Extensive studies on several representative datasets of multimedia applications show that RONF outperforms the state-of-the-arts remarkably."}}
{"id": "tNN_gBuwBf", "cdate": 1640995200000, "mdate": 1667347675815, "content": {"title": "Safe-Student for Safe Deep Semi-Supervised Learning with Unseen-Class Unlabeled Data", "abstract": "Deep semi-supervised learning (SSL) methods aim to take advantage of abundant unlabeled data to improve the algorithm performance. In this paper, we consider the problem of safe SSL scenario where unseen-class instances appear in the unlabeled data. This setting is essential and commonly appears in a variety of real applications. One intuitive solution is removing these unseen-class instances after detecting them during the SSL process. Nevertheless, the performance of unseen-class identification is limited by the small number of labeled data and ignoring the availability of unlabeled data. To take advantage of these unseen-class data and ensure performance, we propose a safe SSL method called SAFE-STUDENT from the teacher-student view. Firstly, a new scoring function called energy-discrepancy (ED) is proposed to help the teacher model improve the security of instances selection. Then, a novel unseen-class label distribution learning mechanism mitigates the unseen-class perturbation by calibrating the unseen-class label distribution. Finally, we propose an iterative optimization strategy to facilitate teacher-student network learning. Extensive studies on several representative datasets show that SAFE-STUDENT remarkably outperforms the state-of-the-art, verifying the feasibility and robustness of our method in the under-explored problem."}}
{"id": "qTNSIOCibQ", "cdate": 1640995200000, "mdate": 1684169133835, "content": {"title": "Towards safe and robust weakly-supervised anomaly detection under subpopulation shift", "abstract": ""}}
{"id": "G4QsFKGl4CJ", "cdate": 1640995200000, "mdate": 1684169133863, "content": {"title": "Not All Parameters Should Be Treated Equally: Deep Safe Semi-supervised Learning under Class Distribution Mismatch", "abstract": "Deep semi-supervised learning (SSL) aims to utilize a sizeable unlabeled set to train deep networks, thereby reducing the dependence on labeled instances. However, the unlabeled set often carries unseen classes that cause the deep SSL algorithm to lose generalization. Previous works focus on the data level that they attempt to remove unseen class data or assign lower weight to them but could not eliminate their adverse effects on the SSL algorithm. Rather than focusing on the data level, this paper turns attention to the model parameter level. We find that only partial parameters are essential for seen-class classification, termed safe parameters. In contrast, the other parameters tend to fit irrelevant data, termed harmful parameters. Driven by this insight, we propose Safe Parameter Learning (SPL) to discover safe parameters and make the harmful parameters inactive, such that we can mitigate the adverse effects caused by unseen-class data. Specifically, we firstly design an effective strategy to divide all parameters in the pre-trained SSL model into safe and harmful ones. Then, we introduce a bi-level optimization strategy to update the safe parameters and kill the harmful parameters. Extensive experiments show that SPL outperforms the state-of-the-art SSL methods on all the benchmarks by a large margin. Moreover, experiments demonstrate that SPL can be integrated into the most popular deep SSL networks and be easily extended to handle other cases of class distribution mismatch."}}
{"id": "G0VbpzUJwS", "cdate": 1640995200000, "mdate": 1684169134005, "content": {"title": "Topological Structure Learning for Weakly-Supervised Out-of-Distribution Detection", "abstract": "Out-of-distribution (OOD) detection is the key to deploying models safely in the open world. For OOD detection, collecting sufficient in-distribution (ID) labeled data is usually more time-consuming and costly than unlabeled data. When ID labeled data is limited, the previous OOD detection methods are no longer superior due to their high dependence on the amount of ID labeled data. Based on limited ID labeled data and sufficient unlabeled data, we define a new setting called Weakly-Supervised Out-of-Distribution Detection (WSOOD). To solve the new problem, we propose an effective method called Topological Structure Learning (TSL). Firstly, TSL uses a contrastive learning method to build the initial topological structure space for ID and OOD data. Secondly, TSL mines effective topological connections in the initial topological space. Finally, based on limited ID labeled data and mined topological connections, TSL reconstructs the topological structure in a new topological space to increase the separability of ID and OOD instances. Extensive studies on several representative datasets show that TSL remarkably outperforms the state-of-the-art, verifying the validity and robustness of our method in the new setting of WSOOD."}}
{"id": "9ISTFUEJ4C", "cdate": 1640995200000, "mdate": 1680060108260, "content": {"title": "RONF: Reliable Outlier Synthesis under Noisy Feature Space for Out-of-Distribution Detection", "abstract": ""}}
{"id": "h1G093xViY4", "cdate": 1609459200000, "mdate": 1684169134136, "content": {"title": "Robust Anomaly Detection from Partially Observed Anomalies with Augmented Classes", "abstract": "Anomaly detection is becoming increasingly ubiquitous in the society of data mining. Prominent anomaly detection works have achieved great success in theory and practice. However, they cannot handle the generalized semi-supervised scenario where there are only a handful of labeled anomalies, and plentiful unlabeled data that may bring in some instances of augmented anomaly classes but which are hard to be sampled. To solve this new problem, we propose a method called ACAD (Augmented Classes Anomaly Detection), which consists of three components. ACAD firstly suggests an augmented anomaly class discovery module that connects the isolation score and the similarity score to excavate the instances of hidden anomaly classes from unlabeled data accurately. ACAD then uses a specific cluster approach to compute useful similarity scores to separate reliable anomalous and normal instances among unlabeled data, respectively. ACAD finally builds a robust anomaly detector based on mined examples, successfully performing anomaly detection from partially observed anomalies with augmented classes. A series of empirical studies show that our algorithm remarkably outperforms state of the art on almost twenty datasets."}}
{"id": "DJ1GzOIpSk", "cdate": 1609459200000, "mdate": 1684311160386, "content": {"title": "Normality Learning in Multispace for Video Anomaly Detection", "abstract": "Video anomaly detection is a challenging task owing to the rare and diverse nature of abnormal events. However, most of the existing methods only learn the normality in a single space, focusing on low-level detailed features, which is easily affected by unimportant pixels. To address this issue, in this study, we propose a semi-supervised method based on the generative adversarial network and frame prediction, wherein the normality is learned in both the original image space and latent space, and the events deviating from the normality are detected as anomalies. In particular, given a video clip, we first predict a future frame and minimize the prediction errors between the generated frame and its ground truth. Thereafter, we encode the predicted frames and their ground truths in the latent space and minimize their differences. In the testing phase, we calculate the normal scores of each frame in both the image and latent spaces to obtain a comprehensive evaluation. Utilizing the multispace can capture more normality distribution information of the data, which can benefit anomaly detection. The results of experiments on three benchmark datasets demonstrate the effectiveness of the proposed method."}}
