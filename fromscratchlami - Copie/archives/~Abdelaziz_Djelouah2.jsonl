{"id": "rTP-aGzt8xc", "cdate": 1640995200000, "mdate": 1645806101199, "content": {"title": "Microdosing: Knowledge Distillation for GAN based Compression", "abstract": "Recently, significant progress has been made in learned image and video compression. In particular the usage of Generative Adversarial Networks has lead to impressive results in the low bit rate regime. However, the model size remains an important issue in current state-of-the-art proposals and existing solutions require significant computation effort on the decoding side. This limits their usage in realistic scenarios and the extension to video compression. In this paper, we demonstrate how to leverage knowledge distillation to obtain equally capable image decoders at a fraction of the original number of parameters. We investigate several aspects of our solution including sequence specialization with side information for image coding. Finally, we also show how to transfer the obtained benefits into the setting of video compression. Overall, this allows us to reduce the model size by a factor of 20 and to achieve 50% reduction in decoding time."}}
{"id": "NQJ9pMf9id", "cdate": 1614887118218, "mdate": null, "content": {"title": "Lossy Image Compression with Normalizing Flows", "abstract": "Deep learning based image compression has recently witnessed exciting progress and in some cases even managed to surpass transform coding based approaches. However, state-of-the-art solutions for deep image compression typically employ autoencoders which map the input to a lower dimensional latent space and thus irreversibly discard information already before quantization. In contrast, traditional approaches in image compression employ an invertible transformation before performing the quantization step. In this work, we propose a deep image compression method that is similarly able to go from low bit-rates to near lossless quality, by leveraging normalizing flows to learn a bijective mapping from the image space to a latent representation. We demonstrate further advantages unique to our solution, such as the ability to maintain constant quality results through reencoding, even when performed multiple times. To the best of our knowledge, this is the first work leveraging normalizing flows for lossy image compression."}}
{"id": "r5bTMGtIxq", "cdate": 1609459200000, "mdate": 1645806101067, "content": {"title": "Neural frame interpolation for rendered content", "abstract": "The demand for creating rendered content continues to drastically grow. As it often is extremely computationally expensive and thus costly to render high-quality computer-generated images, there is a high incentive to reduce this computational burden. Recent advances in learning-based frame interpolation methods have shown exciting progress but still have not achieved the production-level quality which would be required to render fewer pixels and achieve savings in rendering times and costs. Therefore, in this paper we propose a method specifically targeted to achieve high-quality frame interpolation for rendered content. In this setting, we assume that we have full input for every n-th frame in addition to auxiliary feature buffers that are cheap to evaluate (e.g. depth, normals, albedo) for every frame. We propose solutions for leveraging such auxiliary features to obtain better motion estimates, more accurate occlusion handling, and to correctly reconstruct non-linear motion between keyframes. With this, our method is able to significantly push the state-of-the-art in frame interpolation for rendered content and we are able to obtain production-level quality results."}}
{"id": "BRlZ6fGK8eq", "cdate": 1609459200000, "mdate": 1645806101165, "content": {"title": "Generic Image Restoration With Flow Based Priors", "abstract": "Image restoration has seen great progress in the last years thanks to the advances in deep neural networks. Most of these existing techniques are trained using full supervision with suitable image pairs to tackle a specific degradation. However, in a generic setting with unknown degradations this is not possible and a good prior remains crucial. Recently, neural network based approaches have been proposed to model such priors by leveraging either denoising autoencoders or the implicit regularization captured by the neural network structure itself. In contrast to this, we propose using normalizing flows to model the distribution of the target content and to use this as a prior in a maximum a posteriori (MAP) formulation. By expressing the MAP optimization process in the latent space through the learned bijective mapping, we are able to obtain solutions through gradient descent. To the best of our knowledge, this is the first work that explores normalizing flows as prior in generic image enhancement problems. Furthermore, we present experimental results for a number of different degradations on data sets varying in complexity and show competitive results when comparing with the deep image prior approach."}}
{"id": "auIgqo-gvP", "cdate": 1580484753912, "mdate": null, "content": {"title": "Deep Video Color Propagation", "abstract": "Traditional approaches for color propagation in videos rely on some form of matching between consecutive video frames. Using appearance descriptors, colors are then propagated both spatially and temporally. These methods, however, are computationally expensive and do not take advantage of semantic information of the scene. In this work we propose a deep learning framework for color propagation that combines a local strategy, to propagate colors frame-by-frame ensuring temporal stability, and a global strategy, using semantics for color propagation within a longer range. Our evaluation shows the superiority of our strategy over existing video and image color propagation methods as well as neural photo-realistic style transfer approaches."}}
{"id": "DoDZwnn7X", "cdate": 1580456293645, "mdate": null, "content": {"title": "Blind Image Super-Resolution with Spatially Variant Degradations", "abstract": "Existing deep learning approaches to single image super-resolution have achieved impressive results but mostly assume a setting with fixed pairs of high resolution and low resolution images. However, to robustly address realistic upscaling scenarios where the relation between high resolution and low resolution images is unknown, blind image super-resolution is required. To this end, we propose a solution that relies on three components: First, we use a degradation aware SR network to synthesize the HR image given a low resolution image and the corresponding blur kernel. Second, we train a kernel discriminator to analyze the generated high resolution image in order to predict errors present due to providing an incorrect blur kernel to the generator. Finally, we present an optimization procedure that is able to recover both the degradation kernel and the high resolution image by minimizing the error predicted by our kernel discriminator. We also show how to extend our approach to spatially variant degradations that typically arise in visual effects pipelines when compositing content from different sources and how to enable both local and global user interaction in the upscaling process."}}
{"id": "myhwPHQjV", "cdate": 1580456159920, "mdate": null, "content": {"title": "Neural Inter-Frame Compression for Video Coding", "abstract": "While there are many deep learning based approaches for\nsingle image compression, the field of end-to-end learned\nvideo coding has remained much less explored. Therefore,\nin this work we present an inter-frame compression approach for neural video coding that can seamlessly build up\non different existing neural image codecs. Our end-to-end\nsolution performs temporal prediction by optical flow based\nmotion compensation in pixel space. The key insight is that\nwe can increase both decoding efficiency and reconstruction quality by encoding the required information into a\nlatent representation that directly decodes into motion and\nblending coefficients. In order to account for remaining\nprediction errors, residual information between the original\nimage and the interpolated frame is needed. We propose to\ncompute residuals directly in latent space instead of in pixel\nspace as this allows to reuse the same image compression\nnetwork for both key frames and intermediate frames. Our\nextended evaluation on different datasets and resolutions\nshows that the rate-distortion performance of our approach\nis competitive with existing state-of-the-art codecs."}}
{"id": "xNeMCam-_MW", "cdate": 1577836800000, "mdate": null, "content": {"title": "Style Transfer for Keypoint Matching Under Adverse Conditions", "abstract": "In this work, we address the difficulty of matching local features between images captured at distant points in time resulting in a global appearance change. Inspired by recent neural style transfer techniques, we propose to use an image transformation network to translate night images into day-like appearance, with the objective of better matching performance. We extend traditional style transfer, that optimize for content and style, with a keypoint matching loss function. The joint optimization of these losses allows our model to generate images that can significantly improve the performance of local feature matching, in a self-supervised way. As a result, our approach is flexible and does not require paired training data, which is difficult to obtain in practice. We show how our method can be used as an extension to a state-of-the-art differentiable feature extractor to improve its performance in challenging scenarios. This is demonstrated in our evaluation on day-night image matching and visual localization tasks with night-rain image queries."}}
{"id": "SnEb6GzFLl9", "cdate": 1577836800000, "mdate": 1645806101196, "content": {"title": "Lossy Image Compression with Normalizing Flows", "abstract": "Deep learning based image compression has recently witnessed exciting progress and in some cases even managed to surpass transform coding based approaches that have been established and refined over many decades. However, state-of-the-art solutions for deep image compression typically employ autoencoders which map the input to a lower dimensional latent space and thus irreversibly discard information already before quantization. Due to that, they inherently limit the range of quality levels that can be covered. In contrast, traditional approaches in image compression allow for a larger range of quality levels. Interestingly, they employ an invertible transformation before performing the quantization step which explicitly discards information. Inspired by this, we propose a deep image compression method that is able to go from low bit-rates to near lossless quality by leveraging normalizing flows to learn a bijective mapping from the image space to a latent representation. In addition to this, we demonstrate further advantages unique to our solution, such as the ability to maintain constant quality results through re-encoding, even when performed multiple times. To the best of our knowledge, this is the first work to explore the opportunities for leveraging normalizing flows for lossy image compression."}}
{"id": "HRxVafGFUe5", "cdate": 1577836800000, "mdate": 1645806101197, "content": {"title": "Blind Image Restoration with Flow Based Priors", "abstract": "Image restoration has seen great progress in the last years thanks to the advances in deep neural networks. Most of these existing techniques are trained using full supervision with suitable image pairs to tackle a specific degradation. However, in a blind setting with unknown degradations this is not possible and a good prior remains crucial. Recently, neural network based approaches have been proposed to model such priors by leveraging either denoising autoencoders or the implicit regularization captured by the neural network structure itself. In contrast to this, we propose using normalizing flows to model the distribution of the target content and to use this as a prior in a maximum a posteriori (MAP) formulation. By expressing the MAP optimization process in the latent space through the learned bijective mapping, we are able to obtain solutions through gradient descent. To the best of our knowledge, this is the first work that explores normalizing flows as prior in image enhancement problems. Furthermore, we present experimental results for a number of different degradations on data sets varying in complexity and show competitive results when comparing with the deep image prior approach."}}
