{"id": "r6cNUjS8cm0", "cdate": 1621629788951, "mdate": null, "content": {"title": "Closing the Gap: Tighter Analysis of Alternating Stochastic Gradient Methods for Bilevel Problems", "abstract": "Stochastic nested optimization, including stochastic compositional, min-max, and bilevel optimization, is gaining popularity in many machine learning applications. \nWhile the three problems share a nested structure, existing works often treat them separately, thus developing problem-specific algorithms and analyses. \nAmong various exciting developments, simple SGD-type updates (potentially on multiple variables) are still prevalent in solving this class of nested problems, but they are believed to have a slower convergence rate than non-nested problems. \nThis paper unifies several SGD-type updates for stochastic nested problems into a single SGD approach that we term ALternating Stochastic gradient dEscenT (ALSET) method. By leveraging the hidden smoothness of the problem, this paper presents a tighter analysis of ALSET for stochastic nested problems. \nUnder the new analysis, to achieve an $\\epsilon$-stationary point of the nested problem, it requires ${\\cal O}(\\epsilon^{-2})$ samples in total. \nUnder certain regularity conditions, applying our results to stochastic compositional, min-max, and reinforcement learning problems either improves or matches the best-known sample complexity in the respective cases. \nOur results explain why simple SGD-type algorithms in stochastic nested problems all work very well in practice without the need for further modifications. "}}
{"id": "OItvP2-i9j", "cdate": 1621629788951, "mdate": null, "content": {"title": "Closing the Gap: Tighter Analysis of Alternating Stochastic Gradient Methods for Bilevel Problems", "abstract": "Stochastic nested optimization, including stochastic compositional, min-max, and bilevel optimization, is gaining popularity in many machine learning applications. \nWhile the three problems share a nested structure, existing works often treat them separately, thus developing problem-specific algorithms and analyses. \nAmong various exciting developments, simple SGD-type updates (potentially on multiple variables) are still prevalent in solving this class of nested problems, but they are believed to have a slower convergence rate than non-nested problems. \nThis paper unifies several SGD-type updates for stochastic nested problems into a single SGD approach that we term ALternating Stochastic gradient dEscenT (ALSET) method. By leveraging the hidden smoothness of the problem, this paper presents a tighter analysis of ALSET for stochastic nested problems. \nUnder the new analysis, to achieve an $\\epsilon$-stationary point of the nested problem, it requires ${\\cal O}(\\epsilon^{-2})$ samples in total. \nUnder certain regularity conditions, applying our results to stochastic compositional, min-max, and reinforcement learning problems either improves or matches the best-known sample complexity in the respective cases. \nOur results explain why simple SGD-type algorithms in stochastic nested problems all work very well in practice without the need for further modifications. "}}
{"id": "SJ-DA8bu-B", "cdate": 1514764800000, "mdate": null, "content": {"title": "On Markov Chain Gradient Descent", "abstract": "Stochastic gradient methods are the workhorse (algorithms) of large-scale optimization problems in machine learning, signal processing, and other computational sciences and engineering. This paper studies Markov chain gradient descent, a variant of stochastic gradient descent where the random samples are taken on the trajectory of a Markov chain. Existing results of this method assume convex objectives and a reversible Markov chain and thus have their limitations. We establish new non-ergodic convergence under wider step sizes, for nonconvex problems, and for non-reversible finite-state Markov chains. Nonconvexity makes our method applicable to broader problem classes. Non-reversible finite-state Markov chains, on the other hand, can mix substatially faster. To obtain these results, we introduce a new technique that varies the mixing levels of the Markov chains. The reported numerical results validate our contributions."}}
