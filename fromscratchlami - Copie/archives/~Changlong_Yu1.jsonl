{"id": "sioyKTap_O6", "cdate": 1672531200000, "mdate": 1682328537715, "content": {"title": "Exploring the Feasibility of ChatGPT for Event Extraction", "abstract": "Event extraction is a fundamental task in natural language processing that involves identifying and extracting information about events mentioned in text. However, it is a challenging task due to the lack of annotated data, which is expensive and time-consuming to obtain. The emergence of large language models (LLMs) such as ChatGPT provides an opportunity to solve language tasks with simple prompts without the need for task-specific datasets and fine-tuning. While ChatGPT has demonstrated impressive results in tasks like machine translation, text summarization, and question answering, it presents challenges when used for complex tasks like event extraction. Unlike other tasks, event extraction requires the model to be provided with a complex set of instructions defining all event types and their schemas. To explore the feasibility of ChatGPT for event extraction and the challenges it poses, we conducted a series of experiments. Our results show that ChatGPT has, on average, only 51.04% of the performance of a task-specific model such as EEQA in long-tail and complex scenarios. Our usability testing experiments indicate that ChatGPT is not robust enough, and continuous refinement of the prompt does not lead to stable performance improvements, which can result in a poor user experience. Besides, ChatGPT is highly sensitive to different prompt styles."}}
{"id": "SGSNzs3JT-", "cdate": 1672531200000, "mdate": 1682328537658, "content": {"title": "Mask-then-Fill: A Flexible and Effective Data Augmentation Framework for Event Extraction", "abstract": "We present Mask-then-Fill, a flexible and effective data augmentation framework for event extraction. Our approach allows for more flexible manipulation of text and thus can generate more diverse data while keeping the original event structure unchanged as much as possible. Specifically, it first randomly masks out an adjunct sentence fragment and then infills a variable-length text span with a fine-tuned infilling model. The main advantage lies in that it can replace a fragment of arbitrary length in the text with another fragment of variable length, compared to the existing methods which can only replace a single word or a fixed-length fragment. On trigger and argument extraction tasks, the proposed framework is more effective than baseline methods and it demonstrates particularly strong results in the low-resource setting. Our further analysis shows that it achieves a good balance between diversity and distributional similarity."}}
{"id": "XdeRQeP34MM", "cdate": 1640995200000, "mdate": 1673186985926, "content": {"title": "XDM: Improving Sequential Deep Matching with Unclicked User Behaviors for Recommender System", "abstract": ""}}
{"id": "RnoZ-eELo0w", "cdate": 1640995200000, "mdate": 1682328537677, "content": {"title": "CoCoLM: Complex Commonsense Enhanced Language Model with Discourse Relations", "abstract": ""}}
{"id": "QPd_i92YGr_", "cdate": 1640995200000, "mdate": 1682328537677, "content": {"title": "Improving Event Representation via Simultaneous Weakly Supervised Contrastive Learning and Clustering", "abstract": ""}}
{"id": "LjeiM6hJns", "cdate": 1640995200000, "mdate": 1682328537728, "content": {"title": "Translation-Based Implicit Annotation Projection for Zero-Shot Cross-Lingual Event Argument Extraction", "abstract": "Zero-shot cross-lingual event argument extraction (EAE) is a challenging yet practical problem in Information Extraction. Most previous works heavily rely on external structured linguistic features, which are not easily accessible in real-world scenarios. This paper investigates a translation-based method to implicitly project annotations from the source language to the target language. With the use of translation-based parallel corpora, no additional linguistic features are required during training and inference. As a result, the proposed approach is more cost effective than previous works on zero-shot cross-lingual EAE. Moreover, our implicit annotation projection approach introduces less noises and hence is more effective and robust than explicit ones. Experimental results show that our model achieves the best performance, outperforming a number of competitive baselines. The thorough analysis further demonstrates the effectiveness of our model compared to explicit annotation projection approaches."}}
{"id": "5k34KPUOWy", "cdate": 1640995200000, "mdate": 1682328537725, "content": {"title": "An Empirical Revisiting of Linguistic Knowledge Fusion in Language Understanding Tasks", "abstract": ""}}
{"id": "2WEfCgNPvvI", "cdate": 1640995200000, "mdate": 1682328537726, "content": {"title": "Title2Event: Benchmarking Open Event Extraction with a Large-scale Chinese Title Dataset", "abstract": "Haolin Deng, Yanan Zhang, Yangfan Zhang, Wangyang Ying, Changlong Yu, Jun Gao, Wei Wang, Xiaoling Bai, Nan Yang, Jin Ma, Xiang Chen, Tianhua Zhou. Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing. 2022."}}
{"id": "-oXaOxy6up", "cdate": 1581705812292, "mdate": null, "content": {"title": "Enriching Large-Scale Eventuality Knowledge Graph with Entailment Relations", "abstract": "Computational and cognitive studies suggest that the abstraction of eventualities (activities, states, and events) is crucial for humans to understand daily eventualities. In this paper, we propose a scalable approach to model the entailment relations between eventualities (\"eat an apple'' entails ''eat fruit''). As a result, we construct a large-scale eventuality entailment graph (EEG), which has 10 million eventuality nodes and 103 million entailment edges. Detailed experiments and analysis demonstrate the effectiveness of the proposed approach and quality of the resulting knowledge graph. Our datasets and code are available at https://github.com/HKUST-KnowComp/ASER-EEG."}}
{"id": "d0rqRYv20cI", "cdate": 1577836800000, "mdate": 1636276100035, "content": {"title": "Hypernymy Detection for Low-Resource Languages via Meta Learning", "abstract": "Changlong Yu, Jialong Han, Haisong Zhang, Wilfred Ng. Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. 2020."}}
