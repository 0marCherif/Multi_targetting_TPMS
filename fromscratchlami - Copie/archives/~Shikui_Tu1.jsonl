{"id": "ndOcNC3kpS", "cdate": 1698796800000, "mdate": 1708519460996, "content": {"title": "KGDiff: towards explainable target-aware molecule generation with knowledge guidance", "abstract": "Designing 3D molecules with high binding affinity for specific protein targets is crucial in drug design. One challenge is that the atomic interaction between molecules and proteins in 3D space has to be taken into account. However, the existing target-aware methods solely model the joint distribution between the molecules and proteins, disregarding the binding affinities between them, which leads to limited performance. In this paper, we propose an explainable diffusion model to generate molecules that can be bound to a given protein target with high affinity. Our method explicitly incorporates the chemical knowledge of protein\u2013ligand binding affinity into the diffusion model, and uses the knowledge to guide the denoising process towards the direction of high binding affinity. Specifically, an SE(3)-invariant expert network is developed to fit the Vina scoring functions and jointly trained with the denoising network, while the domain knowledge is distilled and conveyed from Vina functions to the expert network. An effective guidance is proposed on both continuous atom coordinates and discrete atom types by taking advantages of the gradient of the expert network. Experiments on the benchmark CrossDocked2020 demonstrate the superiority of our method. Additionally, an atom-level explanation of the generated molecules is provided, and the connections with the domain knowledge are established."}}
{"id": "VlwisQ8obSg", "cdate": 1696118400000, "mdate": 1708519461033, "content": {"title": "RefinePocket: An Attention-Enhanced and Mask-Guided Deep Learning Approach for Protein Binding Site Prediction", "abstract": "Protein binding site prediction is an important prerequisite task of drug discovery and design. While binding sites are very small, irregular and varied in shape, making the prediction very challenging. Standard 3D U-Net has been adopted to predict binding sites but got stuck with unsatisfactory prediction results, incomplete, out-of-bounds, or even failed. The reason is that this scheme is less capable of extracting the chemical interactions of the entire region and hardly takes into account the difficulty of segmenting complex shapes. In this paper, we propose a refined U-Net architecture, called RefinePocket, consisting of an attention-enhanced encoder and a mask-guided decoder. During encoding, taking binding site proposal as input, we employ Dual Attention Block (DAB) hierarchically to capture rich global information, exploring residue relationship and chemical correlations in spatial and channel dimensions respectively. Then, based on the enhanced representation extracted by the encoder, we devise Refine Block (RB) in the decoder to enable self-guided refinement of uncertain regions gradually, resulting in more precise segmentation. Experiments show that DAB and RB complement and promote each other, making RefinePocket has an average improvement of 10.02% on DCC and 4.26% on DVO compared with the state-of-the-art method on four test sets."}}
{"id": "JgGiBxTbSqS", "cdate": 1680307200000, "mdate": 1708519461146, "content": {"title": "A deep-learning method for the end-to-end prediction of intracranial aneurysm rupture risk", "abstract": ""}}
{"id": "VSidwOtONc", "cdate": 1677628800000, "mdate": 1684196186800, "content": {"title": "MGAE-DC: Predicting the synergistic effects of drug combinations through multi-channel graph autoencoders", "abstract": "Author summary Drug combination therapy is widely employed for various complex diseases because of its advantages of enhancing the efficiency, overcoming the drug resistance and reducing dose-dependent toxicity relative to monotherapy. To identify novel reliable and efficacious drug combinations for the patients, various methods have been proposed in the past decades. The trial-based methods are based on the clinical trials directly, but may cause patients to receive unnecessary or even harmful treatments. The experimental methods are labour and cost intensive, it is infeasible to test the complete drug combination space due to the combinatorial explosion. Computational methods provide attractive solutions to make the prediction based on the known data in silico, and thus narrow down the searching range of potential combinations. We have developed a novel deep learning method, named MGAE-DC, for predicting the synergistic effects of drug combinations. Our method explicitly characterizes not only synergistic combinations but also non-synergistic ones to obtain discriminative drug embeddings. Our method also learns common features of drug combinations across the cell lines for improved generalization performance. Computational experiments have verified the effectiveness of MGAE-DC."}}
{"id": "rcud3AKPwT", "cdate": 1672531200000, "mdate": 1708519460924, "content": {"title": "Multi-source unsupervised domain-adaptation for automatic sleep staging", "abstract": "Sleep staging using electroencephalogram (EEG) is of great significance for diagnosing sleep disorders. Recently, due to the high cost of manually annotating EEG signals and the problem of domain shift across different datasets, many unsupervised domain adaptation methods have been applied to sleep staging. However, all these methods are single-source unsupervised domain adaptation (SUDA) methods. When applied to the multi-source unsupervised domain adaptation (MUDA) problem, most SUDA methods treat all source domains equally, without considering the domain shift between them. As a result, achiving feature alignment across all domains becomes a challenge for these SUDA methods. In our proposed model, we address the challenge of domain shift in multi-source unsupervised domain adaptation (MUDA) for automatic sleep staging. Specially, we create a domain-specific branch for each pair of source and target domains, which focuses on aligning the features extracted from the respective domains using an adversarial-based domain adaptation approach. Additionally, we incorporate a domain-invariant branch into our model for learning the domain-invariant representation. We also introduce an adaptive-based mixing strategy to assigns weights to each branches, which can dynamically adjust the importance of each branch depending on their relevance to the specific prediction task. The experiments conducted on three public datasets show the superior performance of our model. Compared to other state-of-the-art MUDA models, our model\u2019s average classification accuracy improves by 2% to 9.9%. The source code is available at https://github.com/CMACH508/MUDAEEG."}}
{"id": "ngboW03E-BS", "cdate": 1672531200000, "mdate": 1708519461150, "content": {"title": "A Deep Temporal Factor Analysis Method for Large Scale Financial Portfolio Selection", "abstract": "Existing machine learning methods are effective in portfolio optimization on a small pool of assets. This is still not optimal because a larger number of assets in markets offers more opportunities for investors. However, existing methods are usually not scalable to large amount of assets which brings new challenges of high dimensionality and computing complexity. In this paper, we present a neural network temporal factor analysis (NN-TFA) model for dimensionality reduction and it enables us to build a scalable deep reinforcement learning method for large-scale portfolio management. Traditional TFA models the relation between asset prices and real economic activities via a small set of independent hidden factors. NN-TFA is developed from the traditional TFA by replacing the linear autoregressive model over the hidden factors with a neural network function, which well captures the complicated temporal patterns. The hidden factors are then sent to a policy network to generate portfolio weights. A calibration module to extract information from other assets features and a ratio module to catch the trend of the selected assets pool are proposed to enhance the performance of the policy network. Extensive tests demonstrate that our methods are capable of handling large-scale datasets and achieving promising results."}}
{"id": "nPZbw5HeIf", "cdate": 1672531200000, "mdate": 1708519461108, "content": {"title": "DeepTH: Chip Placement with Deep Reinforcement Learning Using a Three-Head Policy Network", "abstract": "Modern very-large-scale integrated (VLSI) circuit placement with huge state space is a critical task for achieving layouts with high performance. Recently, reinforcement learning (RL) algorithms have made a promising breakthrough to dramatically save design time than human effort. However, the previous RL-based works either require a large dataset of chip placements for pre-training or produce illegal final placement solutions. In this paper, DeepTH, a three-head policy gradient placer, is proposed to learn from scratch without the need of pre-training, and generate superior chip floorplans. Graph neural network is initially adopted to extract the features from nodes and nets of chips for estimating the policy and value. To efficiently improve the quality of floorplans, a reconstruction head is employed in the RL network to recover the visual representation of the current placement, by enriching the extracted features of placement embedding. Besides, the reconstruction error is used as a bonus during training to encourage exploration while alleviating the sparse reward problem. Furthermore, the expert knowledge of floorplanning preference is embedded into the decision process to narrow down the potential action space. Experiment results on the ISPD 2005 benchmark have shown that our method achieves 19.02% HPWL improvement than the analytic placer DREAMPlace and 19.89% improvement at least than the state-of-the-art RL algorithms."}}
{"id": "j_aG6DqA5M", "cdate": 1672531200000, "mdate": 1708519461130, "content": {"title": "PFB-Diff: Progressive Feature Blending Diffusion for Text-driven Image Editing", "abstract": "Diffusion models have showcased their remarkable capability to synthesize diverse and high-quality images, sparking interest in their application for real image editing. However, existing diffusion-based approaches for local image editing often suffer from undesired artifacts due to the pixel-level blending of the noised target images and diffusion latent variables, which lack the necessary semantics for maintaining image consistency. To address these issues, we propose PFB-Diff, a Progressive Feature Blending method for Diffusion-based image editing. Unlike previous methods, PFB-Diff seamlessly integrates text-guided generated content into the target image through multi-level feature blending. The rich semantics encoded in deep features and the progressive blending scheme from high to low levels ensure semantic coherence and high quality in edited images. Additionally, we introduce an attention masking mechanism in the cross-attention layers to confine the impact of specific words to desired regions, further improving the performance of background editing. PFB-Diff can effectively address various editing tasks, including object/background replacement and object attribute editing. Our method demonstrates its superior performance in terms of image fidelity, editing accuracy, efficiency, and faithfulness to the original image, without the need for fine-tuning or training."}}
{"id": "TjwLq9lP-Ju", "cdate": 1672531200000, "mdate": 1708519460960, "content": {"title": "A Deep Learning Method with Multi-view Attention and Multi-branch GCN for BECT Diagnosis", "abstract": "Epilepsy is a prevalent chronic neurological disorder in childhood, imposing a heavy burden on patients and their families. The development of deep learning and the accumulation of clinical medical data has led to a surge in neural network algorithms proposed for the automatic detection of childhood epilepsy using electroencephalogram (EEG) signals. However, for Benign Childhood Epilepsy with Centro-Temporal Spikes (BECT), the most common type of childhood epilepsy, there is no large-scale public dataset available for its detection. Moreover, although there were a few studies of BECT using private data, they focused only on identifying the presence of abnormal discharges, ignoring the sleep stage of the discharges, which is actually a critical factor for the doctor\u2019s diagnosis. To tackle these challenges, we create a BECT dataset containing more than 38,000 real samples from 100 subjects, meticulously annotated by neurology experts. Building on this dataset, we propose a multi-view attention and multi-branch graph convolutional neural network (MAMB) to differentiate abnormal discharges and classify sleep stages in the samples. Experimental results demonstrate that the model benefits from three-dimensional attention mechanisms in the spatial, temporal, and spectral domains, allowing better exploration of intrinsic relationships within EEG signals. Additionally, the sleep and BECT branches enhance the model\u2019s ability to detect abnormal discharges and differentiate various sleep stages. Our model achieves 88.07% and 90.91% accuracy for BECT classification and sleep stage staging, and 81.93% for the four-classification task of simultaneously judging BECT and sleep stage. In addition, the introduction of the multi-view attention mechanism makes the model interpretable and raises hopes of further assisting experts in disease and medication analysis. The implementation code is shown at github <sup xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">1</sup> ."}}
{"id": "Sj0hDz8P2V", "cdate": 1672531200000, "mdate": 1708519461086, "content": {"title": "Self-Supervised Bidirectional Learning for Graph Matching", "abstract": "Deep learning methods have demonstrated promising performance on the NP-hard Graph Matching (GM) problems. However, the state-of-the-art methods usually require the ground-truth labels, which may take extensive human efforts or be impractical to collect. In this paper, we present a robust self-supervised bidirectional learning method (IA-SSGM) to tackle GM in an unsupervised manner. It involves an affinity learning component and a classic GM solver. Specifically, we adopt the Hungarian solver to generate pseudo correspondence labels for the simple probabilistic relaxation of the affinity matrix. In addition, a bidirectional recycling consistency module is proposed to generate pseudo samples by recycling the pseudo correspondence back to permute the input. It imposes a consistency constraint between the pseudo affinity and the original one, which is theoretically supported to help reduce the matching error. Our method further develops a graph contrastive learning jointly with the affinity learning to enhance its robustness against the noise and outliers in real applications. Experiments deliver superior performance over the previous state-of-the-arts on five real-world benchmarks, especially under the more difficult outlier scenarios, demon- strating the effectiveness of our method."}}
