{"id": "1nlqYBo0fIi", "cdate": 1680307200000, "mdate": 1681698779255, "content": {"title": "Design and Optimization of Solar-Powered Shared Electric Autonomous Vehicle System for Smart Cities", "abstract": "Smart transportation shall address utility waste, traffic congestion, and air pollution problems with least human intervention in future smart cities. To realize the sustainable operation of smart transportation, we leverage solar-harvesting charging stations and rooftops to power electric autonomous vehicles(AVs) solely via design. With a fixed budget, our framework first optimizes the locations of charging stations based on historical spatial-temporal solar energy distribution and usage patterns, achieving <inline-formula><tex-math notation=\"LaTeX\">$(2+\\epsilon)$</tex-math></inline-formula> factor to the optimal. Then a stochastic algorithm is proposed to update the locations online to adapt to any shift in the distribution. Based on the deployment, a strategy is developed to assign energy requests in order to minimize their traveling distance to stations while not depleting their energy storage. Equipped with extra harvesting capability, we also optimize route planning to achieve a reasonable balance between energy consumed and harvested en-route. As a promising application, utility optimization of shared electric AVs is discussed, and <inline-formula><tex-math notation=\"LaTeX\">$(2k\\!+\\!1)$</tex-math></inline-formula> -approx algorithm is proposed to manage <inline-formula><tex-math notation=\"LaTeX\">$k$</tex-math></inline-formula> vehicles simultaneously. Our extensive simulations demonstrate the algorithm can approach the optimal solution within 10-15% approximation error, improve the operating range of vehicles by up to 2-3 times, and improve the utility by more than 50% compared to other competitive strategies."}}
{"id": "fiNqXeN0mws", "cdate": 1640995200000, "mdate": 1681698779270, "content": {"title": "Adaptive Federated Deep Reinforcement Learning for Proactive Content Caching in Edge Computing", "abstract": "With the aggravation of data explosion and backhaul loads on 5 G edge network, it is difficult for traditional centralized cloud to meet the low latency requirements for content access. The federated learning ( <u>F</u> L)-based <u>p</u> roactive content <u>c</u> aching (FPC) can alleviate the matter by placing content in local cache to achieve fast and repetitive data access while protecting the users\u2019 privacy. However, due to the non-independent and identically distributed (Non-IID) data across the clients and limited edge resources, it is unrealistic for FL to aggregate all participated devices in parallel for model update and adopt the fixed iteration frequency in local training process. To address this issue, we propose a distributed resources-efficient FPC policy to improve the content caching efficiency and reduce the resources consumption. Through theoretical analysis, we first formulate the FPC problem into a stacked autoencoders (SAE) model loss minimization problem while satisfying resources constraint. We then propose an adaptive FPC (AFPC) algorithm combined deep reinforcement learning (DRL) consisting of two mechanisms of client selection and local iterations number decision. Next, we show that when training data are Non-IID, aggregating the model parameters of all participated devices may be not an optimal strategy to improve the FL-based content caching efficiency, and it is more meaningful to adopt adaptive local iteration frequency when resources are limited. Finally, experimental results in three real datasets demonstrate that AFPC can effectively improve cache efficiency up to 38.4 <inline-formula><tex-math notation=\"LaTeX\">$\\%$</tex-math></inline-formula> and 6.84 <inline-formula><tex-math notation=\"LaTeX\">$\\%$</tex-math></inline-formula> , and save resources up to 47.4 <inline-formula><tex-math notation=\"LaTeX\">$\\%$</tex-math></inline-formula> and 35.6 <inline-formula><tex-math notation=\"LaTeX\">$\\%$</tex-math></inline-formula> , respectively, compared with traditional multi-armed bandit (MAB)-based and FL-based algorithms."}}
{"id": "PA5vj8cbXY", "cdate": 1640995200000, "mdate": 1668713991440, "content": {"title": "k-Level Truthful Incentivizing Mechanism and Generalized k-MAB Problem", "abstract": "Multi-armed bandits problem has been widely utilized in economy-related areas. Incentives are explored in the sharing economy to inspire users for better resource allocation. Previous works build a budget-feasible incentive mechanism to learn users\u2019 cost distribution. However, they only consider a special case that all tasks are considered as the same. The general problem asks for finding a solution when the cost for different tasks varies. In this paper, we investigate this problem by considering a system with <inline-formula><tex-math notation=\"LaTeX\">$k$</tex-math></inline-formula> levels of difficulty. We present two incentivizing strategies for offline and online implementation, and formally derive the ratio of utility between them in different scenarios. We propose a regret-minimizing mechanism to decide incentives by dynamically adjusting budget assignment and learning from users\u2019 cost distributions. We further extend the problem to a more generalized k-MAB problem by removing the contextual information of difficulties. CUE-UCB algorithm is proposed to address the online advertisement problem for multi-platforms. Our experiment demonstrates utility improvement about 7 times and time saving of 54% to meet a utility objective compared to the previous works in sharing economy, and up to 175% increment of utility for online advertising."}}
{"id": "1Vl7fmHaEV", "cdate": 1640995200000, "mdate": 1681698779465, "content": {"title": "iCOS: A Deep Reinforcement Learning Scheme for Wireless-Charged MEC Networks", "abstract": "Computation offloading is an effective method in mobile edge computing (MEC) to relieve user equipment (UE) from the limited computation resource and battery capacity. Meanwhile, simultaneous wireless information and power transmission (SWIPT) can be applied to MEC to extend the operating time of the equipment. However, in multi-user network environment, diverse computation task requirements and changeable network channel states make it challenging to obtain offloading strategy timely and accurately. To address the issue, we propose an intelligent computation offloading scheme (iCOS) based on enhanced priority deep deterministic policy gradient (EPDDPG) algorithm to minimize the energy consumption of all the UEs by jointly optimizing the offloading decision, the central processing unit (CPU) frequency and the power split ratio in a dynamic SWIPT-MEC network. In particular, we improve the traditional fully-connected network structure to obtain both discrete and continuous action outputs, and accelerate neural network parameter updates by using prioritized experience tuples. Furthermore, we use dynamic voltage and frequency scaling (DVFS) technology to dynamically adjust the CPU frequency of local computing, and employ SWIPT technology to balance the charging and communication according to the obtained strategy. Simulation results show that the algorithm proposed in this paper can effectively reduce the energy cost of UEs, and complete more computation tasks within the delay limit."}}
{"id": "Sof6jNo8_t7", "cdate": 1609459200000, "mdate": 1668713991465, "content": {"title": "Design of Self-sustainable Wireless Sensor Networks with Energy Harvesting and Wireless Charging", "abstract": "Energy provisioning plays a key role in the sustainable operations of Wireless Sensor Networks (WSNs). Recent efforts deploy multi-source energy harvesting sensors to utilize ambient energy. Meanwhile, wireless charging is a reliable energy source not affected by spatial-temporal ambient dynamics. This article integrates multiple energy provisioning strategies and adaptive adjustment to accomplish self-sustainability under complex weather conditions. We design and optimize a three-tier framework with the first two tiers focusing on the planning problems of sensors with various types and distributed energy storage powered by environmental energy. Then we schedule the Mobile Chargers (MC) between different charging activities and propose an efficient, 4-factor approximation algorithm. Finally, we adaptively adjust the algorithms to capture real-time energy profiles and jointly optimize those correlated modules. Our extensive simulations demonstrate significant improvement of network lifetime (\\(\\)), increase of harvested energy (15%), reduction of network cost (30%), and the charging capability of MC by 100%."}}
{"id": "NzMlqfqu3U", "cdate": 1609459200000, "mdate": 1668713991441, "content": {"title": "Towards Efficient Scheduling of Federated Mobile Devices Under Computational and Statistical Heterogeneity", "abstract": "Originated from distributed learning, federated learning enables privacy-preserved collaboration on a new abstracted level by sharing the model parameters only. While the current research mainly focuses on optimizing learning algorithms and minimizing communication overhead left by distributed learning, there is still a considerable gap when it comes to the real implementation on mobile devices. In this article, we start with an empirical experiment to demonstrate computation heterogeneity is a more pronounced bottleneck than communication on the current generation of battery-powered mobile devices, and the existing methods are haunted by mobile stragglers. Further, non-identically distributed data across the mobile users makes the selection of participants critical to the accuracy and convergence. To tackle the computational and statistical heterogeneity, we utilize data as a tuning knob and propose two efficient polynomial-time algorithms to schedule different workloads on various mobile devices, when data is identically or non-identically distributed. For identically distributed data, we combine partitioning and linear bottleneck assignment to achieve near-optimal training time without accuracy loss. For non-identically distributed data, we convert it into an average cost minimization problem and propose a greedy algorithm to find a reasonable balance between computation time and accuracy. We also establish an offline profiler to quantify the runtime behavior of different devices, which serves as the input to the scheduling algorithms. We conduct extensive experiments on a mobile testbed with two datasets and up to 20 devices. Compared with the common benchmarks, the proposed algorithms achieve 2-100\u00d7 speedup epoch-wise, 2\u20137 percent accuracy gain and boost the convergence rate by more than 100 percent on CIFAR10."}}
{"id": "8mPQLPtJn_", "cdate": 1577836800000, "mdate": 1668713991488, "content": {"title": "Towards Efficient Scheduling of Federated Mobile Devices under Computational and Statistical Heterogeneity", "abstract": "Originated from distributed learning, federated learning enables privacy-preserved collaboration on a new abstracted level by sharing the model parameters only. While the current research mainly focuses on optimizing learning algorithms and minimizing communication overhead left by distributed learning, there is still a considerable gap when it comes to the real implementation on mobile devices. In this paper, we start with an empirical experiment to demonstrate computation heterogeneity is a more pronounced bottleneck than communication on the current generation of battery-powered mobile devices, and the existing methods are haunted by mobile stragglers. Further, non-identically distributed data across the mobile users makes the selection of participants critical to the accuracy and convergence. To tackle the computational and statistical heterogeneity, we utilize data as a tuning knob and propose two efficient polynomial-time algorithms to schedule different workloads on various mobile devices, when data is identically or non-identically distributed. For identically distributed data, we combine partitioning and linear bottleneck assignment to achieve near-optimal training time without accuracy loss. For non-identically distributed data, we convert it into an average cost minimization problem and propose a greedy algorithm to find a reasonable balance between computation time and accuracy. We also establish an offline profiler to quantify the runtime behavior of different devices, which serves as the input to the scheduling algorithms. We conduct extensive experiments on a mobile testbed with two datasets and up to 20 devices. Compared with the common benchmarks, the proposed algorithms achieve 2-100x speedup epoch-wise, 2-7% accuracy gain and boost the convergence rate by more than 100% on CIFAR10."}}
{"id": "5YOqWx3p07X", "cdate": 1577836800000, "mdate": 1668713991474, "content": {"title": "Optimize Scheduling of Federated Learning on Battery-powered Mobile Devices", "abstract": "Federated learning learns a collaborative model by aggregating locally-computed updates from mobile devices for privacy preservation. While current research typically prioritizing the minimization of communication overhead, we demonstrate from an empirical study, that computation heterogeneity is a more pronounced bottleneck on battery-powered mobile devices. Moreover, if class is unbalanced among the mobile devices, inappropriate selection of participants may adversely cause gradient divergence and accuracy loss. In this paper, we utilize data as a tunable knob to schedule training and achieve near-optimal solutions of computation time and accuracy loss. Based on the offline profiling, we formulate optimization problems and propose polynomial-time algorithms when data is class-balanced or unbalanced. We evaluate the optimization framework extensively on a mobile testbed with two datasets. Compared with common benchmarks of federated learning, our algorithms achieve 210\u00d7 speedups with negligible accuracy loss. They also mitigate the impact from mobile stragglers and improve parallelism for federated learning."}}
{"id": "4-K0EBaNDW", "cdate": 1577836800000, "mdate": 1668713991477, "content": {"title": "Design and Optimization of Electric Autonomous Vehicles with Renewable Energy Source for Smart Cities", "abstract": "Electric autonomous vehicles provide a promising solution to the traffic congestion and air pollution problems in future smart cities. Considering intensive energy consumption, charging becomes of paramount importance to sustain the operation of these systems. Motivated by the innovations in renewable energy harvesting, we leverage solar energy to power autonomous vehicles via charging stations and solar-harvesting rooftops, and design a framework that optimizes the operation of these systems from end to end. With a fixed budget, our framework first optimizes the locations of charging stations based on historical spatial-temporal solar energy distribution and usage patterns, achieving (2 + \u03f5) factor to the optimal. Then a stochastic algorithm is proposed to update the locations online to adapt to any shift in the distribution. Based on the deployment, a strategy is developed to assign energy requests in order to minimize their traveling distance to stations while not depleting their energy storage. Equipped with extra harvesting capability, we also optimize route planning to achieve a reasonable balance between energy consumed and harvested en-route. Our extensive simulations demonstrate the algorithm can approach the optimal solution within 10-15% approximation error, and improve the operating range of vehicles by up to 2-3 times compared to other competitive strategies."}}
{"id": "0tZljaF2LC", "cdate": 1577836800000, "mdate": 1668713991443, "content": {"title": "E-Sharing: Data-driven Online Optimization of Parking Location Placement for Dockless Electric Bike Sharing", "abstract": "The rise of dockless electric bike sharing becomes a new urban lifestyle recently. More than just the first-and-last mile, it offers a new modality of green transportation. However, in addition to the traditional re-balance and overcrowding problems, it also brings new challenges to urban management and maintenance. Due to the safety risks of batteries, customers are regulated to park at designated locations, which potentially causes dissatisfaction and customer loss. Meanwhile, service providers should charge those scattering low-energy batteries in time. To address these issues, we propose E-sharing, a two-tier optimization framework that leverages data-driven online algorithms to plan parking locations and maintenance. First, we balance the user dissatisfaction and the number of parking locations by minimizing their sum. To account for real-time dynamics while not losing track of the historical optimality, we propose an online algorithm based on its near-optimal offline solution. Second, we develop an incentive mechanism to motivate users to aggregate low-battery bikes together, saving the cost of bike charging. Our experiment based on the public dataset demonstrates that the online algorithm can minimize the cost from the conflicting objectives and incentive mechanism further reduces the maintenance cost by 47%."}}
