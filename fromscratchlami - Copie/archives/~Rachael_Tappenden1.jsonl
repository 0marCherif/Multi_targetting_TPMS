{"id": "ZbzcLy5I4rz", "cdate": 1663849958361, "mdate": null, "content": {"title": "Stochastic Gradient Methods with Preconditioned Updates", "abstract": "This work considers non-convex finite sum minimization. There are a number of algorithms for such problems, but existing methods often work poorly when the problem is badly scaled and/or ill-conditioned, and a primary goal of this work is to introduce methods that alleviate this issue. Thus, here we include a preconditioner that is based upon Hutchinson's approach to approximating the diagonal of the Hessian, and couple it with several gradient based methods to give new `scaled' algorithms: Scaled  SARAH and Scaled L-SVRG. Theoretical complexity guarantees under smoothness assumptions are presented, and we prove linear convergence when both smoothness and the PL-condition is assumed. Because our adaptively scaled methods use approximate partial second order curvature information, they are better able to mitigate the impact of badly scaled problems, and this improved practical performance is demonstrated in the numerical experiments that are also presented in this work."}}
{"id": "XFIsnPLze4t", "cdate": 1652651423694, "mdate": 1652651423694, "content": {"title": "Efficient calculation of regular simplex gradients", "abstract": "Simplex gradients are an essential feature of many derivative free optimization algorithms, and can be employed, for example, as part of the process of defining a direction of search, or as part of a termination criterion. The calculation of a general simplex gradient in  can be computationally expensive, and often requires an overhead operation count of  and in some algorithms a storage overhead of . In this work we demonstrate that the linear algebra overhead and storage costs can be reduced, both to , when the simplex employed is regular and appropriately aligned. We also demonstrate that a gradient approximation that is second order accurate can be obtained cheaply from a combination of two, first order accurate (appropriately aligned) regular simplex gradients. Moreover, we show that, for an arbitrarily aligned regular simplex, the gradient can be computed in  operations."}}
{"id": "jTQOOhwSImH", "cdate": 1652651366196, "mdate": 1652651366196, "content": {"title": "A box constrained gradient projection algorithm for compressed sensing", "abstract": "A new algorithm is presented which aims to solve problems from compressed sensing \u2013 under-determined problems where the solution vector is known a priori to be sparse. Upper bounds on the solution vector are found so that the problem can be reformulated as a box-constrained quadratic programme. A sparse solution is sought using a Barzilai\u2013Borwein type projection algorithm. New insight into the choice of step length is provided through a study of the special structure of the underlying problem together with upper bounds on the step length. Numerical experiments are conducted and results given, comparing this algorithm with a number of other current algorithms."}}
{"id": "gzuzIybnxj", "cdate": 1652651307297, "mdate": 1652651307297, "content": {"title": "Gradient and diagonal Hessian approximations using quadratic interpolation models and aligned regular bases", "abstract": "This work investigates finite differences and the use of (diagonal) quadratic interpolation models to obtain approximations to the first and (non-mixed) second derivatives of a function. Here, it is shown that if a particular set of points is used in the interpolation model, then the solution to the associated linear system (i.e., approximations to the gradient and diagonal of the Hessian) can be obtained in  computations, which is the same cost as finite differences, and is a saving over the  cost when solving a general unstructured linear system. Moreover, if the interpolation points are chosen in a particular way, then the gradient approximation is  accurate, where h is related to the distance between the interpolation points. Numerical examples confirm the theoretical results."}}
{"id": "8ahoOVoT8Rg", "cdate": 1652651235259, "mdate": 1652651235259, "content": {"title": "Dual Free Adaptive Minibatch SDCA for Empirical Risk Minimization", "abstract": "In this paper, we develop an adaptive dual free Stochastic Dual Coordinate Ascent (adfSDCA) algorithm for regularized empirical risk minimization problems. This is motivated by the recent work on dual free SDCA of Shalev-Shwartz (2016). The novelty of our approach is that the coordinates to update at each iteration are selected non-uniformly from an adaptive probability distribution, and this extends the previously mentioned work which only allowed for a uniform selection of ``dual\" coordinates from a fixed probability distribution. We describe an efficient iterative procedure for generating the non-uniform samples, where the scheme selects the coordinate with the greatest potential to decrease the sub-optimality of the current iterate. We also propose a heuristic variant of adfSDCA that is more aggressive than the standard approach. Furthermore, in order to utilize multi-core machines, we consider a mini-batch adfSDCA algorithm and develop complexity results that guarantee the algorithm's convergence. The work is concluded with several numerical experiments to demonstrate the practical benefits of the proposed approach."}}
{"id": "O6OcgPLtA9E", "cdate": 1652651168514, "mdate": 1652651168514, "content": {"title": "Sonia: A symmetric blockwise truncated optimization algorithm", "abstract": "This work presents a new optimization algorithm for empirical risk minimization. The algorithm bridges the gap between first-and second-order methods by computing a search direction that uses a second-order-type update in one subspace, coupled with a scaled steepest descent step in the orthogonal complement. To this end, partial curvature information is incorporated to help with ill-conditioning, while simultaneously allowing the algorithm to scale to the large problem dimensions often encountered in machine learning applications. Theoretical results are presented to confirm that the algorithm converges to a stationary point in both the strongly convex and nonconvex cases. A stochastic variant of the algorithm is also presented, along with corresponding theoretical guarantees. Numerical results confirm the strengths of the new approach on standard machine learning problems."}}
{"id": "JE4xjPl7SXP", "cdate": 1652651060759, "mdate": 1652651060759, "content": {"title": "Fast and safe: accelerated gradient methods with optimality certificates and underestimate sequences", "abstract": "In this work we introduce the concept of an Underestimate Sequence (UES), which is motivated by Nesterov\u2019s estimate sequence. Our definition of a UES utilizes three sequences, one of which is a lower bound (or under-estimator) of the objective function. The question of how to construct an appropriate sequence of lower bounds is addressed, and we present lower bounds for strongly convex smooth functions and for strongly convex composite functions, which adhere to the UES framework. Further, we propose several first order methods for minimizing strongly convex functions in both the smooth and composite cases. The algorithms, based on efficiently updating lower bounds on the objective functions, have natural stopping conditions that provide the user with a certificate of optimality. Convergence of all algorithms is guaranteed through the UES framework, and we show that all presented algorithms converge linearly, with the accelerated variants enjoying the optimal linear rate of convergence."}}
{"id": "c39-pLGPMJ", "cdate": 1652650728160, "mdate": 1652650728160, "content": {"title": "Linear Convergence of Randomized Feasible Descent Methods Under the Weak Strong Convexity Assumption", "abstract": "In this paper we generalize the framework of the Feasible Descent Method (FDM) to a Randomized (R-FDM) and a Randomized Coordinate-wise Feasible Descent Method (RCFDM) framework. We show that many machine learning algorithms, including the famous SDCA algorithm for optimizing the SVM dual problem, or the stochastic coordinate descent method for the LASSO problem, fits into the framework of RC-FDM. We prove linear convergence for both R-FDM and RC-FDM under the weak strong convexity assumption. Moreover, we show that the duality gap converges linearly for RC-FDM, which implies that the duality gap also converges linearly for SDCA applied to the SVM dual problem."}}
{"id": "cp-hJW9_51I", "cdate": 1652650659703, "mdate": 1652650659703, "content": {"title": "A flexible ADMM algorithm for big data applications", "abstract": "We present a Flexible Alternating Direction Method of Multipliers (F-ADMM) algorithm for solving optimization problems involving a strongly convex objective function that is separable into n\u22652 blocks, subject to (non-separable) linear equality constraints. The F-ADMM algorithm uses a Gauss\u2013Seidel scheme to update blocks of variables, and a regularization term is added to each of the subproblems. We prove, under common assumptions, that F-ADMM is globally convergent and that the iterates converge linearly. We also present a special case of F-ADMM that is partially parallelizable, which makes it attractive in a big data setting. In particular, we partition the data into groups, so that each group consists of multiple blocks of variables. By applying F-ADMM to this partitioning of the data, and using a specific regularization matrix, we obtain a hybrid ADMM (H-ADMM) algorithm: the grouped data is updated in a Gauss\u2013Seidel fashion, and the blocks within each group are updated in a Jacobi (parallel) manner. Convergence of H-ADMM follows directly from the convergence properties of F-ADMM. Also, we describe a special case of H-ADMM that may be applied to functions that are convex, rather than strongly convex. Numerical experiments demonstrate the practical advantages of these new algorithms."}}
{"id": "sCE0NHCCgNO", "cdate": 1652650572275, "mdate": 1652650572275, "content": {"title": "A flexible coordinate descent method", "abstract": "We present a novel randomized block coordinate descent method for the minimization of a convex composite objective function. The method uses (approximate) partial second-order (curvature) information, so that the algorithm performance is more robust when applied to highly nonseparable or ill conditioned problems. We call the method Flexible Coordinate Descent (FCD). At each iteration of FCD, a block of coordinates is sampled randomly, a quadratic model is formed about that block and the model is minimized approximately/inexactly to determine the search direction. An inexpensive line search is then employed to ensure a monotonic decrease in the objective function and acceptance of large step sizes. We present several high probability iteration complexity results to show that convergence of FCD is guaranteed theoretically. Finally, we present numerical results on large-scale problems to demonstrate the practical performance of the method."}}
