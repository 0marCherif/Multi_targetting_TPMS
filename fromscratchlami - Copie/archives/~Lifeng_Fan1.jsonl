{"id": "wfzsvaDS7BC", "cdate": 1683945679936, "mdate": null, "content": {"title": "Artificial Social Intelligence: A Comparative and Holistic View", "abstract": "In  addition  to  a  physical  comprehension  of  the  world,  humans  possess  a  high  social  intelligence\u2014the  intelligence  that  senses\nsocial events, infers the goals and intents of others, and facilitates social interaction. Notably, humans are distinguished from their\nclosest primate cousins by their social cognitive skills as opposed to their physical counterparts. We believe that artificial social\nintelligence (ASI) will play a crucial role in shaping the future of artificial intelligence (AI). This article begins with a review of ASI\nfrom a cognitive science standpoint, including social perception, theory of mind (ToM), and social interaction. Next, we examine the\nrecently-emerged computational counterpart in the AI community. Finally, we provide an in-depth discussion on topics related to\nASI."}}
{"id": "qPb0m0NXt4j", "cdate": 1652737598293, "mdate": null, "content": {"title": "Emergent Graphical Conventions in a Visual Communication Game", "abstract": "Humans communicate with graphical sketches apart from symbolic languages. Primarily focusing on the latter, recent studies of emergent communication overlook the sketches; they do not account for the evolution process through which symbolic sign systems emerge in the trade-off between iconicity and symbolicity. In this work, we take the very first step to model and simulate this process via two neural agents playing a visual communication game; the sender communicates with the receiver by sketching on a canvas. We devise a novel reinforcement learning method such that agents are evolved jointly towards successful communication and abstract graphical conventions. To inspect the emerged conventions, we define three key properties -- iconicity, symbolicity, and semanticity -- and design evaluation methods accordingly. Our experimental results under different controls are consistent with the observation in studies of human graphical conventions. Of note, we find that evolved sketches can preserve the continuum of semantics under proper environmental pressures. More interestingly, co-evolved agents can switch between conventionalized and iconic communication based on their familiarity with referents. We hope the present research can pave the path for studying emergent communication with the modality of sketches."}}
{"id": "m1AG-naRd3", "cdate": 1580424735523, "mdate": null, "content": {"title": "Understanding Human Gaze Communication by Spatio-Temporal Graph Reasoning", "abstract": "This paper addresses a new problem of understanding human gaze communication in social videos from both\natomic-level and event-level, which is significant for studying human social interactions. To tackle this novel and challenging problem, we contribute a large-scale video dataset,\nVACATION, which covers diverse daily social scenes and\ngaze communication behaviors with complete annotations\nof objects and human faces, human attention, and communication structures and labels in both atomic-level and\nevent-level. Together with VACATION, we propose a spatiotemporal graph neural network to explicitly represent the\ndiverse gaze interactions in the social scenes and to infer atomic-level gaze communication by message passing. We further propose an event network with encoderdecoder structure to predict the event-level gaze communication. Our experiments demonstrate that the proposed\nmodel improves various baselines significantly in predicting the atomic-level and event-level gaze communications."}}
{"id": "Sy4f0pWOWr", "cdate": 1514764800000, "mdate": null, "content": {"title": "Inferring Shared Attention in Social Scene Videos", "abstract": "This paper addresses a new problem of inferring shared attention in third-person social scene videos. Shared attention is a phenomenon that two or more individuals simultaneously look at a common target in social scenes. Perceiving and identifying shared attention in videos plays crucial roles in social activities and social scene understanding. We propose a spatial-temporal neural network to detect shared attention intervals in videos and predict shared attention locations in frames. In each video frame, human gaze directions and potential target boxes are two key features for spatially detecting shared attention in the social scene. In temporal domain, a convolutional Long Short- Term Memory network utilizes the temporal continuity and transition constraints to optimize the predicted shared attention heatmap. We collect a new dataset VideoCoAtt from public TV show videos, containing 380 complex video sequences with more than 492,000 frames that include diverse social scenes for shared attention study. Experiments on this dataset show that our model can effectively infer shared attention in videos. We also empirically verify the effectiveness of different components in our model."}}
