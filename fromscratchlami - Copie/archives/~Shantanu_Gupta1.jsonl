{"id": "cneZfC4K7Ao", "cdate": 1668624957976, "mdate": 1668624957976, "content": {"title": "Passive Inter-Photon Imaging", "abstract": "Digital camera pixels measure image intensities by converting incident light energy into an analog electrical current, and then digitizing it into a fixed-width binary representation. This direct measurement method, while conceptually simple, suffers from limited dynamic range and poor\nperformance under extreme illumination \u2014 electronic noise\ndominates under low illumination, and pixel full-well capacity results in saturation under bright illumination. We\npropose a novel intensity cue based on measuring interphoton timing, defined as the time delay between detection of successive photons. Based on the statistics of interphoton times measured by a time-resolved single-photon\nsensor, we develop theory and algorithms for a scene\nbrightness estimator which works over extreme dynamic\nrange; we experimentally demonstrate imaging scenes with\na dynamic range of over ten million to one. The proposed\ntechniques, aided by the emergence of single-photon sensors such as single-photon avalanche diodes (SPADs) with\npicosecond timing resolution, will have implications for a\nwide range of imaging applications: robotics, consumer\nphotography, astronomy, microscopy and biomedical imaging.\n"}}
{"id": "ogvIYTt_37q", "cdate": 1609459200000, "mdate": 1669046932743, "content": {"title": "Passive Inter-Photon Imaging", "abstract": "Digital camera pixels measure image intensities by converting incident light energy into an analog electrical current, and then digitizing it into a fixed-width binary representation. This direct measurement method, while conceptually simple, suffers from limited dynamic range and poor performance under extreme illumination -- electronic noise dominates under low illumination, and pixel full-well capacity results in saturation under bright illumination. We propose a novel intensity cue based on measuring inter-photon timing, defined as the time delay between detection of successive photons. Based on the statistics of inter-photon times measured by a time-resolved single-photon sensor, we develop theory and algorithms for a scene brightness estimator which works over extreme dynamic range; we experimentally demonstrate imaging scenes with a dynamic range of over ten million to one. The proposed techniques, aided by the emergence of single-photon sensors such as single-photon avalanche diodes (SPADs) with picosecond timing resolution, will have implications for a wide range of imaging applications: robotics, consumer photography, astronomy, microscopy and biomedical imaging."}}
{"id": "Ouwzzezq8m", "cdate": 1609459200000, "mdate": 1669046932745, "content": {"title": "Passive Inter-Photon Imaging", "abstract": "Digital camera pixels measure image intensities by converting incident light energy into an analog electrical current, and then digitizing it into a fixed-width binary representation. This direct measurement method, while conceptually simple, suffers from limited dynamic range and poor performance under extreme illumination --- electronic noise dominates under low illumination, and pixel full-well capacity results in saturation under bright illumination. We propose a novel intensity cue based on measuring inter-photon timing, defined as the time delay between detection of successive photons. Based on the statistics of inter-photon times measured by a time-resolved single-photon sensor, we develop theory and algorithms for a scene brightness estimator which works over extreme dynamic range; we experimentally demonstrate imaging scenes with a dynamic range of over ten million to one. The proposed techniques, aided by the emergence of single-photon sensors such as single-photon avalanche diodes (SPADs) with picosecond timing resolution, will have implications for a wide range of imaging applications: robotics, consumer photography, astronomy, microscopy and biomedical imaging."}}
{"id": "pLf59ZULytS", "cdate": 1577836800000, "mdate": 1667421697072, "content": {"title": "Quanta burst photography", "abstract": "Single-photon avalanche diodes (SPADs) are an emerging sensor technology capable of detecting individual incident photons, and capturing their time-of-arrival with high timing precision. While these sensors were limited to singlepixel or low-resolution devices in the past, recently, large (up to 1 MPixel) SPAD arrays have been developed. These single-photon cameras (SPCs) are capable of capturing high-speed sequences of binary single-photon images with no read noise. We present quanta burst photography, a computational photography technique that leverages SPCs as passive imaging devices for photography in challenging conditions, including ultra low-light and fast motion. Inspired by recent success of conventional burst photography, we design algorithms that align and merge binary sequences captured by SPCs into intensity images with minimal motion blur and artifacts, high signal-to-noise ratio (SNR), and high dynamic range. We theoretically analyze the SNR and dynamic range of quanta burst photography, and identify the imaging regimes where it provides significant benefits. We demonstrate, via a recently developed SPAD array, that the proposed method is able to generate high-quality images for scenes with challenging lighting, complex geometries, high dynamic range and moving objects. With the ongoing development of SPAD arrays, we envision quanta burst photography finding applications in both consumer and scientific photography."}}
{"id": "S2yO6fEPjScz", "cdate": 1577836800000, "mdate": 1663769677421, "content": {"title": "Quanta Burst Photography", "abstract": "Single-photon avalanche diodes (SPADs) are an emerging sensor technology capable of detecting individual incident photons, and capturing their time-of-arrival with high timing precision. While these sensors were limited to single-pixel or low-resolution devices in the past, recently, large (up to 1 MPixel) SPAD arrays have been developed. These single-photon cameras (SPCs) are capable of capturing high-speed sequences of binary single-photon images with no read noise. We present quanta burst photography, a computational photography technique that leverages SPCs as passive imaging devices for photography in challenging conditions, including ultra low-light and fast motion. Inspired by recent success of conventional burst photography, we design algorithms that align and merge binary sequences captured by SPCs into intensity images with minimal motion blur and artifacts, high signal-to-noise ratio (SNR), and high dynamic range. We theoretically analyze the SNR and dynamic range of quanta burst photography, and identify the imaging regimes where it provides significant benefits. We demonstrate, via a recently developed SPAD array, that the proposed method is able to generate high-quality images for scenes with challenging lighting, complex geometries, high dynamic range and moving objects. With the ongoing development of SPAD arrays, we envision quanta burst photography finding applications in both consumer and scientific photography."}}
{"id": "nUP3_0yl7V4", "cdate": 1514764800000, "mdate": null, "content": {"title": "Fast and Generalisable License Plate Re-identification using Neural Embedding of Fisher Vectors", "abstract": "We consider the license plate re-identification task, treated here as a one-shot image retrieval problem. Our objective is to learn a feature representation for license plate images, such that a single training image of a given license plate (referred to as a template image) is sufficient to perform nearest-neighbour retrieval with high accuracy at test time. Also, the feature representation should ideally be generalisable across datasets and should be extractable in real-time on resource-constrained embedded hardware or a moderately powerful cellphone. We evaluate representations from person re-identification (re-id) literature, learned from a trained deep convolutional network as well with those derived from a trained Fisher vector. While the convolutional network features perform better than the Fisher vector, we obtain comparable results from a hybrid model projecting the Fisher vector into a lower-dimensional space via two fully connected layers called f2nn using the triplet loss. The proposed hybrid model f2nn generates features which outperform and generalise better than convolutional features on datasets dissimilar to the training corpus. The model can be trained in stages and takes significantly less time to extract features. Further, it uses much smaller feature dimensions for license plate images resulting in faster re-identification, and is therefore well-suited for resource-constrained platforms such as mobile devices."}}
{"id": "6_V05zZRSDN", "cdate": 1483228800000, "mdate": 1681674437715, "content": {"title": "Neural Signatures for Licence Plate Re-identification", "abstract": "The problem of vehicle licence plate re-identification is generally considered as a one-shot image retrieval problem. The objective of this task is to learn a feature representation (called a \"signature\") for licence plates. Incoming licence plate images are converted to signatures and matched to a previously collected template database through a distance measure. Then, the input image is recognized as the template whose signature is \"nearest\" to the input signature. The template database is restricted to contain only a single signature per unique licence plate for our problem. We measure the performance of deep convolutional net-based features adapted from face recognition on this task. In addition, we also test a hybrid approach combining the Fisher vector with a neural network-based embedding called \"f2nn\" trained with the Triplet loss function. We find that the hybrid approach performs comparably while providing computational benefits. The signature generated by the hybrid approach also shows higher generalizability to datasets more dissimilar to the training corpus."}}
