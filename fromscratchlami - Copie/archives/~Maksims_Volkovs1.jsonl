{"id": "wWg_Ee5q_W", "cdate": 1663850403837, "mdate": null, "content": {"title": "Speed Up Iterative Non-Autoregressive Transformers by Distilling Multiple Steps", "abstract": "The computational benefits of iterative non-autoregressive transformers decrease as the number of decoding steps increases. As a remedy, we introduce Distill Multiple Steps (DiMS), a simple yet effective distillation technique to decrease the number of required steps to reach a certain translation quality. The distilled model enjoys the computational benefits of early iterations while preserving the enhancements from several iterative steps. DiMS relies on two models namely student and teacher. The student is optimized to predict the output of the teacher after multiple decoding steps while the teacher follows the student via a slow-moving average. The moving average keeps the teacher's knowledge updated and enhances the quality of the labels provided by the teacher. During inference, the student is used for translation and no additional computation is added. We verify the effectiveness of DiMS on various models obtaining 7 and 12.9 BLEU points improvements on distilled and raw versions of WMT'14 De-En, respectively."}}
{"id": "HUCgU5EQluN", "cdate": 1663850207487, "mdate": null, "content": {"title": "Effective Self-Supervised Transformers For Sparse Time Series Data", "abstract": "Electronic health records (EHRs) typically contain a wide range of time series data that is characterized by high sparsity and irregular observations. Self-supervised Transformer architectures have shown outstanding performance in a variety of structured tasks in natural language processing and computer vision. However, their use in modelling sparse irregular time series with tabular data has not been widely explored. One of the major challenges is the quadratic scaling of self-attention layers that can significantly limit the input sequence length. In this work, we introduce TESS, Transformers for EHR data with Self Supervised learning, a self-supervised Transformer-based architecture designed to extract robust representations from EHR data. We propose an input binning scheme that aggregates the time series inputs and sparsity information into a regular sequence with fixed length, enabling the training of larger and deeper Transformers. We demonstrate that significant compression of EHR input data is possible without sacrificing useful information, likely due to the highly correlated nature of observations in small time bins. We then introduce self-supervised prediction tasks that provide rich and informative signals for model pre-training. TESS outperforms state-of-the-art deep learning models on multiple downstream tasks from the MIMIC-IV and PhysioNet-2012 EHR datasets."}}
{"id": "C0q9oBc3n4", "cdate": 1663850165796, "mdate": null, "content": {"title": "Temporal Dependencies in Feature Importance for Time Series Prediction", "abstract": "Time series data introduces two key challenges for explainability methods: firstly, observations of the same feature over subsequent time steps are not independent, and secondly, the same feature can have varying importance to model predictions over time. In this paper, we propose Windowed Feature Importance in Time (WinIT), a feature removal based explainability approach to address these issues. Unlike existing feature removal explanation methods, WinIT explicitly accounts for the temporal dependence between different observations of the same feature in the construction of its importance score. Furthermore, WinIT captures the varying importance of a feature over time, by summarizing its importance over a window of past time steps. We conduct an extensive empirical study on synthetic and real-world data, compare against a wide range of leading explainability methods, and explore the impact of various evaluation strategies. Our results show that WinIT achieves significant gains over existing methods, with more consistent performance across different evaluation metrics."}}
{"id": "I2Hw58KHp8O", "cdate": 1632875730666, "mdate": null, "content": {"title": "Improving Non-Autoregressive Translation Models Without Distillation", "abstract": "Transformer-based autoregressive (AR) machine translation models have achieved significant performance improvements, nearing human-level accuracy on some languages. The AR framework translates one token at a time which can be time consuming, especially for long sequences. To accelerate inference, recent work has been exploring non-autoregressive (NAR) approaches that translate blocks of tokens in parallel. Despite significant progress, leading NAR models still lag behind their AR counterparts, and only become competitive when trained with distillation. In this paper we investigate possible reasons behind this performance gap, namely, the indistinguishability of tokens, and mismatch between training and inference. We then propose the Conditional Masked Language Model with Correction (CMLMC) that addresses these problems. Empirically, we show that CMLMC achieves state-of-the-art NAR performance when trained on raw data without distillation and approaches AR performance on multiple datasets. Full code for this work will be released at the time of publication."}}
{"id": "AxFbOAoLByv", "cdate": 1617668255568, "mdate": null, "content": {"title": "Weakly Supervised Action Selection Learning in Video", "abstract": "Localizing actions in video is a core task in computer vision. \nThe weakly supervised temporal localization problem\ninvestigates whether this task can be adequately solved with\nonly video-level labels, significantly reducing the amount of\nexpensive and error-prone annotation that is required. A\ncommon approach is to train a frame-level classifier where\nframes with the highest class probability are selected to\nmake a video-level prediction. Frame-level activations are\nthen used for localization. However, the absence of frame-level\n annotations cause the classifier to impart class bias on\nevery frame. To address this, we propose the Action Selection\nLearning (ASL) approach to capture the general concept of action,\n a property we refer to as \u201cactionness\u201d. Under ASL, the model\nis trained with a novel class-agnostic task to predict which frames\nwill be selected by the classifier. Empirically, we show that ASL\noutperforms leading baselines on two popular benchmarks\n THUMOS-14 and ActivityNet-1.2, with 12.3% and 5.7% relative\n improvement respectively. We further analyze the properties of ASL\n and demonstrate the importance of actionness. The full code for\nthis work will be released at the time of publication.\n"}}
{"id": "Q4vfqczNVQD", "cdate": 1598658927135, "mdate": null, "content": {"title": "DropoutNet: Addressing Cold Start in Recommender Systems", "abstract": "Latent models have become the default choice for recommender systems due to\ntheir performance and scalability. However, research in this area has primarily focused on modeling user-item interactions, and few latent models have been developed for cold start. Deep learning has recently achieved remarkable success showing excellent results for diverse input types. Inspired by these results we propose a neural network based latent model called DropoutNet to address the cold start problem in recommender systems. Unlike existing approaches that incorporate additional content-based objective terms, we instead focus on the optimization and show that neural network models can be explicitly trained for cold start through\ndropout. Our model can be applied on top of any existing latent model effectively providing cold start capabilities, and full power of deep architectures. Empirically we demonstrate state-of-the-art accuracy on publicly available benchmarks. Code\nis available at https://github.com/layer6ai-labs/DropoutNet."}}
{"id": "otHRGNrc3wN", "cdate": 1598658799444, "mdate": null, "content": {"title": "Explore-Exploit Graph Traversal for Image Retrieval", "abstract": "We propose a novel graph-based approach for image retrieval. Given a nearest neighbor graph produced by the\nglobal descriptor model, we traverse it by alternating between exploit and explore steps. The exploit step maximally utilizes the immediate neighborhood of each vertex, while the explore step traverses vertices that are farther\naway in the descriptor space. By combining these two steps we can better capture the underlying image manifold, and successfully retrieve relevant images that are visually dissimilar to the query. Our traversal algorithm is conceptually simple, has few tunable parameters and can be implemented with basic data structures. This enables fast real-time inference for previously unseen queries\nwith minimal memory overhead. Despite relative simplicity, we show highly competitive results on multiple\npublic benchmarks, including the largest image retrieval dataset that is currently publicly available. Full code for\nthis work is available here: https://github.com/layer6ai-labs/egt."}}
{"id": "H7YD01mxu6r", "cdate": 1546300800000, "mdate": null, "content": {"title": "Explore-Exploit Graph Traversal for Image Retrieval.", "abstract": "We propose a novel graph-based approach for image retrieval. Given a nearest neighbor graph produced by the global descriptor model, we traverse it by alternating between exploit and explore steps. The exploit step maximally utilizes the immediate neighborhood of each vertex, while the explore step traverses vertices that are farther away in the descriptor space. By combining these two steps we can better capture the underlying image manifold, and successfully retrieve relevant images that are visually dissimilar to the query. Our traversal algorithm is conceptually simple, has few tunable parameters and can be implemented with basic data structures. This enables fast real-time inference for previously unseen queries with minimal memory overhead. Despite relative simplicity, we show highly competitive results on multiple public benchmarks, including the largest image retrieval dataset that is currently publicly available. Full code for this work is available here: https://github.com/layer6ai-labs/egt."}}
{"id": "ryHM_fbA-", "cdate": 1518730162477, "mdate": null, "content": {"title": "Learning Document Embeddings With CNNs", "abstract": "This paper proposes a new model for document embedding. Existing approaches either require complex inference or use recurrent neural networks that are difficult to parallelize. We take a different route and use recent advances in language modeling to develop a convolutional neural network embedding model. This allows us to train deeper architectures that are fully parallelizable. Stacking layers together increases the receptive filed allowing each successive layer to model increasingly longer range semantic dependences within the document. Empirically we demonstrate superior results on two publicly available benchmarks. Full code will be released with the final version of this paper."}}
{"id": "BJ4xGDWdbH", "cdate": 1483228800000, "mdate": null, "content": {"title": "DropoutNet: Addressing Cold Start in Recommender Systems", "abstract": "Latent models have become the default choice for recommender systems due to their performance and scalability. However, research in this area has primarily focused on modeling user-item interactions, and few latent models have been developed for cold start. Deep learning has recently achieved remarkable success showing excellent results for diverse input types. Inspired by these results we propose a neural network based latent model called DropoutNet to address the cold start problem in recommender systems. Unlike existing approaches that incorporate additional content-based objective terms, we instead focus on the optimization and show that neural network models can be explicitly trained for cold start through dropout. Our model can be applied on top of any existing latent model effectively providing cold start capabilities, and full power of deep architectures. Empirically we demonstrate state-of-the-art accuracy on publicly available benchmarks. Code is available at https://github.com/layer6ai-labs/DropoutNet."}}
