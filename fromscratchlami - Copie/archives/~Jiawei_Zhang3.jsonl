{"id": "joMQLb5UtK", "cdate": 1672531200000, "mdate": 1683917636716, "content": {"title": "Decoupling Graph Neural Network with Contrastive Learning for Fraud Detection", "abstract": "Recently, many fraud detection models introduced graph neural networks (GNNs) to improve the model performance. However, fraudsters often disguise themselves by camouflaging their features or relations. Due to the aggregation nature of GNNs, information from both input features and graph structure will be compressed for representation learning simultaneously. On the one hand, since not all neighbors provide useful information due to camouflage, aggregating information from all neighbors may potentially decrease the model performance. On the other hand, the structure including all neighbors is not reliable due to the relation camouflage. In this paper, we propose to decouple attribute learning and structure learning to avoid the mutual influence of feature and relation camouflage. Therefore, the model first learns its embedding seperately and then combine them together with label-guided contrastive losses to make predictions better. We conduct extensive experiments on two real-world datasets, and the results show the effectiveness of the proposed model."}}
{"id": "Kzq5QkFayrr", "cdate": 1672531200000, "mdate": 1683917636781, "content": {"title": "Graph Collaborative Signals Denoising and Augmentation for Recommendation", "abstract": "Graph collaborative filtering (GCF) is a popular technique for capturing high-order collaborative signals in recommendation systems. However, GCF's bipartite adjacency matrix, which defines the neighbors being aggregated based on user-item interactions, can be noisy for users/items with abundant interactions and insufficient for users/items with scarce interactions. Additionally, the adjacency matrix ignores user-user and item-item correlations, which can limit the scope of beneficial neighbors being aggregated. In this work, we propose a new graph adjacency matrix that incorporates user-user and item-item correlations, as well as a properly designed user-item interaction matrix that balances the number of interactions across all users. To achieve this, we pre-train a graph-based recommendation method to obtain users/items embeddings, and then enhance the user-item interaction matrix via top-K sampling. We also augment the symmetric user-user and item-item correlation components to the adjacency matrix. Our experiments demonstrate that the enhanced user-item interaction matrix with improved neighbors and lower density leads to significant benefits in graph-based recommendation. Moreover, we show that the inclusion of user-user and item-item correlations can improve recommendations for users with both abundant and insufficient interactions. The code is in \\url{https://github.com/zfan20/GraphDA}."}}
{"id": "iTKqzd4-fD", "cdate": 1640995200000, "mdate": 1675603494831, "content": {"title": "PERFECT: A Hyperbolic Embedding for Joint User and Community Alignment", "abstract": "Social network alignment shows fundamental importance in a wide spectrum of applications. To the best of our knowledge, existing studies mainly focus on network alignment at the individual user level, requiring abundant common information between shared individual users. For the networks that cannot meet such requirements, social community structures actually provide complementary and critical information at a slightly coarse-grained level, alignment of which will provide additional information for user alignment. In turn, user alignment also reveals more clues for community alignment. Hence, in this paper, we introduce the problem of joint social network alignment, which aims to align users and communities across social networks simultaneously. Key challenges lie in that 1) how to learn the representations of both users and communities, and 2) how to make user alignment and community alignment benefit from each other. To address these challenges, we first elaborate on the characteristics of real-world networks with the notion of delta-hyperbolicity, and show the superiority of hyperbolic space for representing social networks. Then, we present a novel hyperbolic embedding approach for the joint social network alignment, referred to as PERFECT, in a unified optimization. Extensive experiments on real-world datasets show the superiority of PERFECT in both user alignment and community alignment."}}
{"id": "h-f-qltRr3", "cdate": 1640995200000, "mdate": 1682459221332, "content": {"title": "Stage Evolving Graph Neural Network based Dynamic Recommendation with Life Cycles", "abstract": "Existing methods of dynamic recommender systems usually build neural networks or collaborative filtering models according to the absolute timeline, which fails to consider the preferences of users or characteristics of products in their life cycles. With the rise of graph neural networks, researchers have recently proposed methods based on graph neural networks to solve the recommendation problem. However, such models do not consider evolving stages in their life cycles. In this paper, we study the dynamic recommendation problem and propose a novel model named Stage Evolving Graph Neural Network (SEGNN). SEGNN learns the life stage representation by the Gated Stage Attention Unit (GSAU) and then uses a fully connected layer as the rating score predictor. GSAU adopts two types of attention layers to learn the preferences of users and products within one coupled life stage and discover the preferences over life stages, respectively. GSAU also utilizes a memory mechanism to ensure that the evolutionary patterns are maintained in the final representations of users and products. Due to the lack of information caused by data sparsity, SEGNN designs a masked loss function to train the model. Extensive experiments are done on real-world datasets, and the experimental results show the effectiveness of our proposed model."}}
{"id": "VObq9iwxCY3", "cdate": 1640995200000, "mdate": 1683773439481, "content": {"title": "Adaptive momentum with discriminative weight for neural network stochastic optimization", "abstract": "Optimization algorithms with momentum have been widely used for building deep learning models because of the fast convergence rate. Momentum helps accelerate Stochastic gradient descent in relevant d..."}}
{"id": "O1rq4mfIOU-", "cdate": 1640995200000, "mdate": 1675603494493, "content": {"title": "A Self-Supervised Mixed-Curvature Graph Neural Network", "abstract": "Graph representation learning received increasing attentions in recent years. Most of the existing methods ignore the complexity of the graph structures and restrict graphs in a single constant-curvature representation space, which is only suitable to particular kinds of graph structure indeed. Additionally, these methods follow the supervised or semi-supervised learning paradigm, and thereby notably limit their deployment on the unlabeled graphs in real applications. To address these aforementioned limitations, we take the first attempt to study the self-supervised graph representation learning in the mixed-curvature spaces. In this paper, we present a novel Self-Supervised Mixed-Curvature Graph Neural Network (SelfMGNN). To capture the complex graph structures, we construct a mixed-curvature space via the Cartesian product of multiple Riemannian component spaces, and design hierarchical attention mechanisms for learning and fusing graph representations across these component spaces. To enable the self-supervised learning, we propose a novel dual contrastive approach. The constructed mixed-curvature space actually provides multiple Riemannian views for the contrastive learning. We introduce a Riemannian projector to reveal these views, and utilize a well-designed Riemannian discriminator for the single-view and cross-view contrastive learning within and across the Riemannian views. Finally, extensive experiments show that SelfMGNN captures the complex graph structures and outperforms state-of-the-art baselines."}}
{"id": "F0Mq0ii1kYG", "cdate": 1640995200000, "mdate": 1683773439538, "content": {"title": "Measuring and sampling: A metric-guided subgraph learning framework for graph neural network", "abstract": "Graph neural networks (GNNs) have shown convincing performance in learning powerful node representations that preserve both node attributes and graph structural information. However, many GNNs encoun..."}}
{"id": "tuXFTbEU-Qh", "cdate": 1609459200000, "mdate": 1675603495151, "content": {"title": "A Self-supervised Mixed-curvature Graph Neural Network", "abstract": "Graph representation learning received increasing attentions in recent years. Most of existing methods ignore the complexity of the graph structures and restrict graphs in a single constant-curvature representation space, which is only suitable to particular kinds of graph structure indeed. Additionally, these methods follow the supervised or semi-supervised learning paradigm, and thereby notably limit their deployment on the unlabeled graphs in real applications. To address these aforementioned limitations, we take the first attempt to study the self-supervised graph representation learning in the mixed-curvature spaces. In this paper, we present a novel Self-supervised Mixed-curvature Graph Neural Network (SelfMGNN). Instead of working on one single constant-curvature space, we construct a mixed-curvature space via the Cartesian product of multiple Riemannian component spaces and design hierarchical attention mechanisms for learning and fusing the representations across these component spaces. To enable the self-supervisd learning, we propose a novel dual contrastive approach. The mixed-curvature Riemannian space actually provides multiple Riemannian views for the contrastive learning. We introduce a Riemannian projector to reveal these views, and utilize a well-designed Riemannian discriminator for the single-view and cross-view contrastive learning within and across the Riemannian views. Finally, extensive experiments show that SelfMGNN captures the complicated graph structures in reality and outperforms state-of-the-art baselines."}}
{"id": "s8LpaJpnZDk", "cdate": 1609459200000, "mdate": 1683917636884, "content": {"title": "Fake News Detection on News-Oriented Heterogeneous Information Networks through Hierarchical Graph Attention", "abstract": "The viral spread of fake news has caused great social harm, making fake news detection an urgent task. Current fake news detection methods rely heavily on text information by learning the extracted news content or writing style of internal knowledge. However, deliberate rumors can mask writing style, bypassing language models and invalidating simple text-based models. In fact, news articles and other related components (such as news creators and news topics) can be modeled as a heterogeneous information network (HIN for short). In this paper, we propose a novel fake news detection framework, namely Hierarchical Graph Attention Network (HGAT), which uses a novel hierarchical attention mechanism to perform node representation learning in HIN, and then detects fake news by classifying news article nodes. Experiments on two realworld fake news datasets show that HGAT can outperform text-based models and other network-based models. In addition, the experiments prove the expandability and generalizability of our for graph representation learning and other node classification related applications in heterogeneous graphs."}}
{"id": "owoTpXu1_wP", "cdate": 1609459200000, "mdate": 1683773439481, "content": {"title": "Label Contrastive Coding based Graph Neural Network for Graph Classification", "abstract": "Graph classification is a critical research problem in many applications from different domains. In order to learn a graph classification model, the most widely used supervision component is an output layer together with classification loss (e.g.,cross-entropy loss together with softmax or margin loss). In fact, the discriminative information among instances are more fine-grained, which can benefit graph classification tasks. In this paper, we propose the novel Label Contrastive Coding based Graph Neural Network (LCGNN) to utilize label information more effectively and comprehensively. LCGNN still uses the classification loss to ensure the discriminability of classes. Meanwhile, LCGNN leverages the proposed Label Contrastive Loss derived from self-supervised learning to encourage instance-level intra-class compactness and inter-class separability. To power the contrastive learning, LCGNN introduces a dynamic label memory bank and a momentum updated encoder. Our extensive evaluations with eight benchmark graph datasets demonstrate that LCGNN can outperform state-of-the-art graph classification models. Experimental results also verify that LCGNN can achieve competitive performance with less training data because LCGNN exploits label information comprehensively."}}
