{"id": "AUGBfDIV9rL", "cdate": 1632875458041, "mdate": null, "content": {"title": "Emergent Communication at Scale", "abstract": "Emergent communication aims for a better understanding of human language evolution and building more efficient representations. We posit that reaching these goals will require scaling up, in contrast to a significant amount of literature that focuses on setting up small-scale problems to tease out desired properties of the emergent languages. We focus on three independent aspects to scale up, namely the dataset, task complexity, and population size. We provide a first set of results for large populations solving complex tasks on realistic large-scale datasets, as well as an easy-to-use codebase to enable further experimentation. In more complex tasks and datasets, we find that RL training can become unstable, but responds well to established stabilization techniques.\nWe also identify the need for a different metric than topographic similarity, which does not correlate with the generalization performances when working with natural images. In this context, we probe ease-of-learnability and transfer methods to assess emergent languages. Finally, we observe that larger populations do not induce robust emergent protocols with high generalization performance, leading us to explore different ways to leverage population, through voting and imitation learning. "}}
{"id": "YmA86Zo-P_t", "cdate": 1601308100861, "mdate": null, "content": {"title": "What they do when in doubt: a study of inductive biases in seq2seq learners", "abstract": "Sequence-to-sequence (seq2seq) learners are widely used, but we still have only limited knowledge about what inductive biases shape the way they generalize. We address that by investigating how popular seq2seq learners generalize in tasks that have high ambiguity in the training data. We use four new tasks  to study learners' preferences for memorization, arithmetic, hierarchical, and compositional reasoning. Further, we connect to Solomonoff's theory of induction and propose to use description length as a principled and sensitive measure of inductive biases. In our experimental study, we find that LSTM-based learners can learn to perform counting, addition, and multiplication by a constant from a single training example. Furthermore, Transformer and LSTM-based learners show a bias toward the hierarchical induction over the linear one, while CNN-based learners prefer the opposite. The latter also show a bias toward a compositional generalization over memorization. Finally, across all our experiments, description length proved to be a sensitive measure of inductive biases."}}
{"id": "SylVJTNKDr", "cdate": 1569438939673, "mdate": null, "content": {"title": "Entropy Minimization In Emergent Languages", "abstract": "There is a growing interest in studying the languages emerging when neural agents are jointly trained to solve tasks requiring communication through a discrete channel.  We investigate here the information-theoretic complexity of such languages, focusing on the basic two-agent, one-exchange setup. We find that, under common training procedures, the emergent languages are subject to an entropy minimization pressure that has also been detected in human language, whereby the mutual information between the communicating agent's inputs and the messages is minimized, within the range afforded by the need for successful communication. This pressure is amplified as we increase communication channel discreteness. Further, we observe that stronger discrete-channel-driven entropy minimization leads to representations with increased robustness to overfitting and adversarial attacks. We conclude by discussing the implications of our findings for the study of natural and artificial communication systems."}}
{"id": "B1fesVBxLr", "cdate": 1567802520390, "mdate": null, "content": {"title": "Anti-efficient encoding in emergent communication", "abstract": "Despite renewed interest in emergent language simulations with   neural networks, little is known about the basic properties of the   induced code, and how they compare to human language. One   fundamental characteristic of the latter, known as Zipf's Law of   Abbreviation (ZLA), is that more frequent words are efficiently   associated to shorter strings. We study whether the same pattern   emerges when two neural networks, a ``speaker'' and a ``listener'',   are trained to play a signaling game. Surprisingly, we find that   networks develop an \\emph{anti-efficient} encoding scheme,    in which the most frequent inputs are associated to the longest messages,    and messages in general are skewed towards the maximum length threshold.    This anti-efficient code appears easier to discriminate for the listener,   and, unlike in human communication, the speaker does not impose a   contrasting least-effort pressure towards brevity. Indeed, when the   cost function includes a penalty for longer messages, the resulting   message distribution starts respecting ZLA. Our analysis stresses   the importance of studying the basic features of emergent   communication in a highly controlled setup, to ensure the latter   will not strand too far from human language. Moreover, we present a   concrete illustration of how different functional pressures can lead   to successful communication codes that lack basic properties of   human language, thus highlighting the role such pressures play in   the latter."}}
