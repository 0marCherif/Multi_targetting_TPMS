{"id": "ELkQiQFVtf", "cdate": 1672562652406, "mdate": 1672562652406, "content": {"title": "Linear Adversarial Concept Erasure", "abstract": "Modern neural models trained on textual data rely on pre-trained representations that emerge without direct supervision. As these representations are increasingly being used in real-world applications, the inability to \\emph{control} their content becomes an increasingly important problem.\nWe formulate the problem of identifying and erasing a linear subspace that corresponds to a given concept, in order to prevent linear predictors from recovering the concept. We model this problem as a constrained, linear minimax game, and show that existing solutions are generally not optimal for this task. We derive a closed-form solution for certain objectives, and propose a convex relaxation, R-LACE, that works well for others. When evaluated in the context of binary gender removal, the method recovers a low-dimensional subspace whose removal mitigates bias by intrinsic and extrinsic evaluation. We show that the method -- despite being linear -- is highly expressive, effectively mitigating bias in deep nonlinear classifiers while maintaining tractability and interpretability.\n"}}
{"id": "n_DMu2S7SFI", "cdate": 1609459200000, "mdate": 1636994251391, "content": {"title": "Amnesic Probing: Behavioral Explanation With Amnesic Counterfactuals", "abstract": "A growing body of work makes use of probing in order to investigate the working of neural models, often considered black boxes. Recently, an ongoing debate emerged surrounding the limitations of the probing paradigm. In this work, we point out the inability to infer behavioral conclusions from probing results, and offer an alternative method which focuses on how the information is being used, rather than on what information is encoded. Our method, Amnesic Probing, follows the intuition that the utility of a property for a given task can be assessed by measuring the influence of a causal intervention which removes it from the representation. Equipped with this new analysis tool, we can ask questions that were not possible before, e.g. is part-of-speech information important for word prediction?\u00a0 We perform a series of analyses on BERT to answer these types of questions. Our findings demonstrate that conventional probing performance is not correlated to task importance, and we call for increased scrutiny of claims that draw behavioral or causal conclusions from probing results."}}
{"id": "Ymq2LdKKTno", "cdate": 1609459200000, "mdate": 1636994251398, "content": {"title": "Contrastive Explanations for Model Interpretability", "abstract": "Alon Jacovi, Swabha Swayamdipta, Shauli Ravfogel, Yanai Elazar, Yejin Choi, Yoav Goldberg. Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing. 2021."}}
{"id": "V79l1XOwSWK", "cdate": 1609459200000, "mdate": 1637084449018, "content": {"title": "Ab Antiquo: Neural Proto-language Reconstruction", "abstract": "Carlo Meloni, Shauli Ravfogel, Yoav Goldberg. Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. 2021."}}
{"id": "MEYGRo4WGQN", "cdate": 1609459200000, "mdate": 1637084449048, "content": {"title": "Neural Extractive Search", "abstract": "Domain experts often need to extract structured information from large corpora. We advocate for a search paradigm called ``extractive search'', in which a search query is enriched with capture-slots, to allow for such rapid extraction. Such an extractive search system can be built around syntactic structures, resulting in high-precision, low-recall results. We show how the recall can be improved using neural retrieval and alignment. The goals of this paper are to concisely introduce the extractive-search paradigm; and to demonstrate a prototype neural retrieval system for extractive search and its benefits and potential. Our prototype is available at \\url{https://spike.neural-sim.apps.allenai.org/} and a video demonstration is available at \\url{https://vimeo.com/559586687}."}}
{"id": "9rMLUSfTgQF", "cdate": 1609459200000, "mdate": 1637084448808, "content": {"title": "BitFit: Simple Parameter-efficient Fine-tuning for Transformer-based Masked Language-models", "abstract": "We introduce BitFit, a sparse-finetuning method where only the bias-terms of the model (or a subset of them) are being modified. We show that with small-to-medium training data, applying BitFit on pre-trained BERT models is competitive with (and sometimes better than) fine-tuning the entire model. For larger data, the method is competitive with other sparse fine-tuning methods. Besides their practical utility, these findings are relevant for the question of understanding the commonly-used process of finetuning: they support the hypothesis that finetuning is mainly about exposing knowledge induced by language-modeling training, rather than learning new task-specific linguistic knowledge."}}
{"id": "-c4xW7GMfRS", "cdate": 1609459200000, "mdate": 1637077443481, "content": {"title": "Counterfactual Interventions Reveal the Causal Effect of Relative Clause Representations on Agreement Prediction", "abstract": "When language models process syntactically complex sentences, do they use their representations of syntax in a manner that is consistent with the grammar of the language? We propose AlterRep, an intervention-based method to address this question. For any linguistic feature of a given sentence, AlterRep generates counterfactual representations by altering how the feature is encoded, while leaving intact all other aspects of the original representation. By measuring the change in a model's word prediction behavior when these counterfactual representations are substituted for the original ones, we can draw conclusions about the causal effect of the linguistic feature in question on the model's behavior. We apply this method to study how BERT models of different sizes process relative clauses (RCs). We find that BERT variants use RC boundary information during word prediction in a manner that is consistent with the rules of English grammar; this RC boundary information generalizes to a considerable extent across different RC types, suggesting that BERT represents RCs as an abstract linguistic category."}}
{"id": "rSsXDgQCfsE", "cdate": 1577836800000, "mdate": 1637084448839, "content": {"title": "It's not Greek to mBERT: Inducing Word-Level Translations from Multilingual BERT", "abstract": "Hila Gonen, Shauli Ravfogel, Yanai Elazar, Yoav Goldberg. Proceedings of the Third BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP. 2020."}}
{"id": "nSAnOEkwt75", "cdate": 1577836800000, "mdate": 1637084449019, "content": {"title": "Unsupervised Distillation of Syntactic Information from Contextualized Word Representations", "abstract": "Shauli Ravfogel, Yanai Elazar, Jacob Goldberger, Yoav Goldberg. Proceedings of the Third BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP. 2020."}}
{"id": "isi2Fcei7V8", "cdate": 1577836800000, "mdate": 1637084449052, "content": {"title": "The Extraordinary Failure of Complement Coercion Crowdsourcing", "abstract": "Yanai Elazar, Victoria Basmov, Shauli Ravfogel, Yoav Goldberg, Reut Tsarfaty. Proceedings of the First Workshop on Insights from Negative Results in NLP. 2020."}}
