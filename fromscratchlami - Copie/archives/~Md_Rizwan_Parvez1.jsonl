{"id": "rt8eMOnQGQ5", "cdate": 1648667753591, "mdate": 1648667753591, "content": {"title": "Building Language Models for Text with Named Entities", "abstract": "Text in many domains involves a significant amount of named entities. Predicting the entity names is often challenging\nfor a language model as they appear less\nfrequent on the training corpus. In this\npaper, we propose a novel and effective\napproach to building a discriminative language model which can learn the entity\nnames by leveraging their entity type information. We also introduce two benchmark datasets based on recipes and Java\nprogramming codes, on which we evaluate the proposed model. Experimental results show that our model achieves 52.2%\nbetter perplexity in recipe generation and\n22.06% on code generation than the stateof-the-art language models."}}
{"id": "Bgg5VnQf7c", "cdate": 1648667698333, "mdate": 1648667698333, "content": {"title": "Evaluating the Values of Sources in Transfer Learning", "abstract": "Transfer learning that adapts a model trained\non data-rich sources to low-resource targets\nhas been widely applied in natural language\nprocessing (NLP). However, when training a\ntransfer model over multiple sources, not every\nsource is equally useful for the target. To better\ntransfer a model, it is essential to understand\nthe values of the sources. In this paper, we\ndevelop SEAL-Shap, an efficient source valuation framework for quantifying the usefulness of the sources (e.g., domains/languages)\nin transfer learning based on the Shapley value\nmethod. Experiments and comprehensive analyses on both cross-domain and cross-lingual\ntransfers demonstrate that our framework is\nnot only effective in choosing useful transfer\nsources but also the source values match the\nintuitive source-target similarity"}}
{"id": "lmhbwWJvB6Z", "cdate": 1634411781572, "mdate": 1634411781572, "content": {"title": "Retrieval Augmented Code Generation and Summarization", "abstract": "Software developers write a lot of source code and documentation during software development. Intrinsically, developers often recall parts of source code or code summaries that they had written in the past while implementing software or documenting them. To mimic developers' code or summary generation behavior, we propose a retrieval augmented framework, REDCODER, that retrieves relevant code or summaries from a retrieval database and provides them as a supplement to code generation or summarization models. REDCODER has a couple of uniqueness. First, it extends the state-of-the-art dense retrieval technique to search for relevant code or summaries. Second, it can work with retrieval databases that include unimodal (only code or natural language description) or bimodal instances (code-description pairs). We conduct experiments and extensive analysis on two benchmark datasets of code generation and summarization in Java and Python, and the promising results endorse the effectiveness of our proposed retrieval augmented framework."}}
{"id": "H1xLsjAqtX", "cdate": 1538087837680, "mdate": null, "content": {"title": "Robust Text Classifier on Test-Time Budgets", "abstract": "In this paper, we design a generic framework for learning a robust text classification model that achieves accuracy comparable to standard full models under test-time\nbudget constraints. We take a different approach from existing methods and learn to dynamically delete a large fraction of unimportant words by a low-complexity selector such that the high-complexity classifier only needs to process a small fraction of important words. In addition, we propose a new data aggregation method to train the classifier, allowing it to make accurate predictions even on fragmented sequence of words. Our end-to-end method achieves state-of-the-art performance while its computational complexity scales linearly with the small fraction of important words in the whole corpus. Besides, a single deep neural network classifier trained by our framework can be dynamically tuned to different budget levels at inference time."}}
