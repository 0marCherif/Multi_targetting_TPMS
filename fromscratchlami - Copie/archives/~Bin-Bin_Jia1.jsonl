{"id": "25s_4fl0fW", "cdate": 1701388800000, "mdate": 1705827074647, "content": {"title": "Learning label-specific features for decomposition-based multi-class classification", "abstract": "Multi-class classification can be solved by decomposing it into a set of binary classification problems according to some encoding rules, e.g., one-vs-one, one-vs-rest, error-correcting output codes. Existing works solve these binary classification problems in the original feature space, while it might be suboptimal as different binary classification problems correspond to different positive and negative examples. In this paper, we propose to learn label-specific features for each decomposed binary classification problem to consider the specific characteristics containing in its positive and negative examples. Specifically, to generate the label-specific features, clustering analysis is respectively conducted on the positive and negative examples in each decomposed binary data set to discover their inherent information and then label-specific features for one example are obtained by measuring the similarity between it and all cluster centers. Experiments clearly validate the effectiveness of learning label-specific features for decomposition-based multi-class classification."}}
{"id": "BiG2k4owjCe", "cdate": 1698796800000, "mdate": 1705827074651, "content": {"title": "Towards Enabling Binary Decomposition for Partial Multi-Label Learning", "abstract": "Partial multi-label learning (PML) is an emerging weakly supervised learning framework, where each training example is associated with multiple candidate labels which are only partially valid. To learn the multi-label predictive model from PML training examples, most existing approaches work by identifying valid labels within candidate label set via label confidence estimation. In this paper, a novel strategy towards partial multi-label learning is proposed by enabling binary decomposition for handling PML training examples. Specifically, the widely used error-correcting output codes (ECOC) techniques are adapted to transform the PML learning problem into a number of binary learning problems, which refrains from using the error-prone procedure of estimating labeling confidence of individual candidate label. In the encoding phase, a ternary encoding scheme is utilized to balance the <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">definiteness</i> and <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">adequacy</i> of the derived binary training set. In the decoding phase, a loss weighted scheme is applied to consider the empirical performance and predictive margin of derived binary classifiers. Extensive comparative studies against state-of-the-art PML learning approaches clearly show the performance advantage of the proposed binary decomposition strategy for partial multi-label learning."}}
{"id": "8vxW3aohcMB", "cdate": 1685577600000, "mdate": 1705827074656, "content": {"title": "Multi-dimensional multi-label classification: Towards encompassing heterogeneous label spaces and multi-label annotations", "abstract": ""}}
{"id": "_qWOrNGmGn", "cdate": 1672531200000, "mdate": 1705827074648, "content": {"title": "Progressive Label Propagation for Semi-Supervised Multi-Dimensional Classification", "abstract": "In multi-dimensional classification (MDC), each training example is associated with multiple class variables from different class spaces. However, it is rather costly to collect labeled MDC examples which have to be annotated from several dimensions (class spaces). To reduce the labeling cost, we attempt to deal with the MDC problem under the semi-supervised learning setting. Accordingly, a novel MDC approach named PLAP is proposed to solve the resulting semi-supervised MDC problem. Overall, PLAP works under the label propagation framework to utilize unlabeled data. To further consider dependencies among class spaces, PLAP deals with each class space in a progressive manner, where the previous propagation results will be used to initialize the current propagation procedure and all processed class spaces and the current one will be regarded as an entirety. Experiments validate the effectiveness of the proposed approach."}}
{"id": "5qTCAy_rFQ_", "cdate": 1672531200000, "mdate": 1680058119975, "content": {"title": "Multi-Dimensional Classification via Decomposed Label Encoding", "abstract": ""}}
{"id": "MVcyDDCplNA", "cdate": 1640995200000, "mdate": 1680058120003, "content": {"title": "Maximum Margin Multi-Dimensional Classification", "abstract": ""}}
{"id": "INUYZsXQrmd", "cdate": 1640995200000, "mdate": 1664714682768, "content": {"title": "Multi-dimensional Classification via Selective Feature Augmentation", "abstract": "In multi-dimensional classification (MDC), the semantics of objects are characterized by multiple class spaces from different dimensions. Most MDC approaches try to explicitly model the dependencies among class spaces in output space. In contrast, the recently proposed feature augmentation strategy, which aims at manipulating feature space, has also been shown to be an effective solution for MDC. However, existing feature augmentation approaches only focus on designing holistic augmented features to be appended with the original features, while better generalization performance could be achieved by exploiting multiple kinds of augmented features. In this paper, we propose the selective feature augmentation strategy that focuses on synergizing multiple kinds of augmented features. Specifically, by assuming that only part of the augmented features is pertinent and useful for each dimension\u2019s model induction, we derive a classification model which can fully utilize the original features while conduct feature selection for the augmented features. To validate the effectiveness of the proposed strategy, we generate three kinds of simple augmented features based on standard kNN, weighted kNN, and maximum margin techniques, respectively. Comparative studies show that the proposed strategy achieves superior performance against both state-of-the-art MDC approaches and its degenerated versions with either kind of augmented features."}}
{"id": "8QRp3RKubWU", "cdate": 1640995200000, "mdate": 1664714682753, "content": {"title": "Decomposition-Based Classifier Chains for Multi-Dimensional Classification", "abstract": "In multi-dimensional classification, the semantics of objects are characterized by multiple class variables from different dimensions. To model the dependencies among class variables, one natural strategy is to build a number of multiclass classifiers in a chaining structure, one per dimension, where the subsequent classifiers on the chain augment the feature space with all labeling information used by the preceding classifiers. However, it is shown that this strategy cannot compete with existing state-of-the-art approaches via comparative studies. One possible reason is that inaccurate predictions of preceding classifiers would degenerate the performance of subsequent ones. Besides, it is more difficult to learn a multiclass classifier than a binary one with the same accuracy, and better performance can be expected if the multi-dimensional classification problem can be solved by building multiple binary classifiers in a chaining structure. Based on these conjectures, this article proposes an approach, which builds a chain of binary classifiers to solve the multi-dimensional classification problem with the help of one-versus-one decomposition. To address the issue that different one-versus-one decomposed problems involve different training examples, the feature space is augmented with the binary predictions of preceding classifiers on the chain to train the subsequent ones. To alleviate the effect of the specified chaining order, the ensemble version of the proposed approach is further investigated. Comparative studies over 20 benchmark datasets clearly show the superiority of the proposed approach against the state-of-the-art multi-dimensional classification baselines."}}
{"id": "W3FswfJzqrO", "cdate": 1609459200000, "mdate": 1632874809280, "content": {"title": "Multi-Dimensional Classification via Sparse Label Encoding", "abstract": "In multi-dimensional classification (MDC), there are multiple class variables in the output space with each of them corresponding to one heterogeneous class space. Due to the heterogeneity of class..."}}
{"id": "lkUCUgwZqr", "cdate": 1577836800000, "mdate": null, "content": {"title": "Maximum Margin Multi-Dimensional Classification", "abstract": "Multi-dimensional classification (MDC) assumes heterogenous class spaces for each example, where class variables from different class spaces characterize semantics of the example along different dimensions. Due to the heterogeneity of class spaces, the major difficulty in designing margin-based MDC techniques lies in that the modeling outputs from different class spaces are not comparable to each other. In this paper, a first attempt towards maximum margin multi-dimensional classification is investigated. Following the one-vs-one decomposition within each class space, the resulting models are optimized by leveraging classification margin maximization on individual class variable and model relationship regularization across class variables. We derive convex formulation for the maximum margin MDC problem, which can be tackled with alternating optimization admitting QP or closed-form solution in either alternating step. Experimental studies over real-world MDC data sets clearly validate effectiveness of the proposed maximum margin MDC techniques."}}
