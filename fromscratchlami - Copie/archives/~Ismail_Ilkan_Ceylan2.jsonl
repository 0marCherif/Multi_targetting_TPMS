{"id": "mWzWvMxuFg1", "cdate": 1662812625097, "mdate": null, "content": {"title": "Shortest Path Networks for Graph Property Prediction", "abstract": "Most graph neural network models rely on a particular message passing paradigm, where the idea is to iteratively propagate node representations of a graph to each node in the direct neighborhood. While very prominent, this paradigm leads to information propagation bottlenecks, as information is repeatedly compressed at intermediary node representations, which causes loss of information, making it practically impossible to gather meaningful signals from distant nodes. To address this, we propose shortest path message passing neural networks, where the node representations of a graph are propagated to each node in the shortest path neighborhoods. In this setting, nodes can directly communicate between each other even if they are not neighbors, breaking the information bottleneck and hence leading to more adequately learned representations. Our framework generalizes message passing neural networks, resulting in a class of more expressive models, including some recent state-of-the-art models. We verify the capacity of a basic model of this framework on dedicated synthetic experiments, and on real-world graph classification and regression benchmarks, and obtain state-of-the art results."}}
{"id": "aHUTWq4Jc8A", "cdate": 1618599806368, "mdate": null, "content": {"title": "BoxE: A Box Embedding Model for Knowledge Base Completion", "abstract": "Knowledge base completion (KBC) aims to automatically infer missing facts by\nexploiting information already present in a knowledge base (KB). A promising\napproach for KBC is to embed knowledge into latent spaces and make predictions\nfrom learned embeddings. However, existing embedding models are subject to\nat least one of the following limitations: (1) theoretical inexpressivity, (2) lack of\nsupport for prominent inference patterns (e.g., hierarchies), (3) lack of support for\nKBC over higher-arity relations, and (4) lack of support for incorporating logical\nrules. Here, we propose a spatio-translational embedding model, called BoxE, that\nsimultaneously addresses all these limitations. BoxE embeds entities as points,\nand relations as a set of hyper-rectangles (or boxes), which spatially characterize\nbasic logical properties. This seemingly simple abstraction yields a fully expressive\nmodel offering a natural encoding for many desired logical properties. BoxE can\nboth capture and inject rules from rich classes of rule languages, going well beyond\nindividual inference patterns. By design, BoxE naturally applies to higher-arity\nKBs. We conduct a detailed experimental analysis, and show that BoxE achieves\nstate-of-the-art performance, both on benchmark knowledge graphs and on more\ngeneral KBs, and we empirically show the power of integrating logical rules."}}
{"id": "L7Irrt5sMQa", "cdate": 1601308199392, "mdate": null, "content": {"title": "The Surprising Power of Graph Neural Networks with Random Node Initialization", "abstract": "Graph neural networks (GNNs) are effective models for representation learning on graph-structured data. However, standard GNNs are limited in their expressive power, as they cannot distinguish graphs beyond the capability of the Weisfeiler-Leman (1-WL) graph isomorphism heuristic. This limitation motivated a large body of work, including higher-order GNNs, which are provably more powerful models. To  date, higher-order invariant and equivariant networks are the only models with known universality results, but these results are practically hindered by prohibitive computational complexity. Thus, despite their limitations, standard GNNs are commonly used, due to their strong practical performance. In practice, GNNs have shown a promising performance when enhanced with random node initialization (RNI), where the idea is to train and run the models with randomized initial node features. In this paper, we analyze the expressive power of GNNs with RNI, and pose the following question: are GNNs with RNI more expressive than GNNs? We prove that this is indeed the case, by showing that GNNs with RNI are universal, a first such result for GNNs not relying on computationally demanding higher-order properties. We then empirically analyze the effect of RNI on GNNs, based on carefully constructed datasets. Our empirical findings support the superior performance of GNNs with RNI over standard GNNs.  In fact, we demonstrate that the performance of GNNs with RNI is often comparable with or better than that of higher-order GNNs, while keeping the much lower memory requirements of standard GNNs. However, this improvement typically comes at the cost of slower model convergence. Somewhat surprisingly, we found that the convergence rate and the accuracy of the models can be improved by using only a partial random initialization regime."}}
{"id": "m0eak9-EqbG", "cdate": 1577836800000, "mdate": null, "content": {"title": "Explanations for Ontology-Mediated Query Answering in Description Logics", "abstract": "Ontology-mediated query answering is a paradigm that seeks to exploit the semantic knowledge expressed in terms of ontologies to improve query answers over incomplete data sources. In this paper, we focus on description logic ontologies, and study the problem of explaining why an ontology-mediated query is entailed from a given data source. Specifically, we view explanations as minimal sets of assertions from an ABox, which satisfy the ontology-mediated query. Based on such explanations, we study a variety of problems taken from the recent literature on explanations (studied for existential rules), such as recognizing all minimal explanations. Our results establish tight connections between intractable explanation problems and variants of propositional satisfiability problems. We provide insights on the inherent computational difficulty of deriving explanations for ontology-mediated queries."}}
{"id": "lTLzRrxCwuw", "cdate": 1577836800000, "mdate": null, "content": {"title": "A Dichotomy for Homomorphism-Closed Queries on Probabilistic Graphs", "abstract": "We study the problem of probabilistic query evaluation (PQE) over probabilistic graphs, namely, tuple-independent probabilistic databases (TIDs) on signatures of arity two. Our focus is the class of queries that is closed under homomorphisms, or equivalently, the infinite unions of conjunctive queries, denoted UCQ\u221e. Our main result states that all unbounded queries in UCQ\u221e are #P-hard for PQE. As bounded queries in UCQ\u221e are already classified by the dichotomy of Dalvi and Suciu [Dalvi and Suciu, 2012], our results and theirs imply a complete dichotomy on PQE for UCQ\u221e queries over probabilistic graphs. This dichotomy covers in particular all fragments in UCQ\u221e such as negation-free (disjunctive) Datalog, regular path queries, and a large class of ontology-mediated queries on arity-two signatures. Our result is shown by reducing from counting the valuations of positive partitioned 2-DNF formulae (#PP2DNF) for some queries, or from the source-to-target reliability problem in an undirected graph (#U-ST-CON) for other queries, depending on properties of minimal models."}}
{"id": "ih-N0VHcuZs", "cdate": 1577836800000, "mdate": null, "content": {"title": "BoxE: A Box Embedding Model for Knowledge Base Completion", "abstract": "Knowledge base completion (KBC) aims to automatically infer missing facts by exploiting information already present in a knowledge base (KB). A promising approach for KBC is to embed knowledge into latent spaces and make predictions from learned embeddings. However, existing embedding models are subject to at least one of the following limitations: (1) theoretical inexpressivity, (2) lack of support for prominent inference patterns (e.g., hierarchies), (3) lack of support for KBC over higher-arity relations, and (4) lack of support for incorporating logical rules. Here, we propose a spatio-translational embedding model, called BoxE, that simultaneously addresses all these limitations. BoxE embeds entities as points, and relations as a set of hyper-rectangles (or boxes), which spatially characterize basic logical properties. This seemingly simple abstraction yields a fully expressive model offering a natural encoding for many desired logical properties. BoxE can both capture and inject rules from rich classes of rule languages, going well beyond individual inference patterns. By design, BoxE naturally applies to higher-arity KBs. We conduct a detailed experimental analysis, and show that BoxE achieves state-of-the-art performance, both on benchmark knowledge graphs and on more general KBs, and we empirically show the power of integrating logical rules."}}
{"id": "ieoaLgFAF5m", "cdate": 1577836800000, "mdate": null, "content": {"title": "On the Approximability of Weighted Model Integration on DNF Structures", "abstract": "Weighted model counting (WMC) consists of computing the weighted sum of all satisfying assignments of a propositional formula. WMC is well-known to be #P-hard for exact solving, but admits a fully polynomial randomized approximation scheme (FPRAS) when restricted to DNF structures. In this work, we study weighted model integration, a generalization of weighted model counting which involves real variables in addition to propositional variables, and pose the following question: Does weighted model integration on DNF structures admit an FPRAS? Building on classical results from approximate volume computation and approximate weighted model counting, we show that weighted model integration on DNF structures can indeed be approximated for a class of weight functions. Our approximation algorithm is based on three subroutines, each of which can be a weak (i.e., approximate), or a strong (i.e., exact) oracle, and in all cases, comes along with accuracy guarantees. We experimentally verify our approach over randomly generated DNF instances of varying sizes, and show that our algorithm scales to large problem instances, involving up to 1K variables, which are currently out of reach for existing, general-purpose weighted model integration solvers."}}
{"id": "xnIIrG4hwD4X", "cdate": 1546300800000, "mdate": null, "content": {"title": "Learning to Reason: Leveraging Neural Networks for Approximate DNF Counting", "abstract": "Weighted model counting (WMC) has emerged as a prevalent approach for probabilistic inference. In its most general form, WMC is #P-hard. Weighted DNF counting (weighted #DNF) is a special case, where approximations with probabilistic guarantees are obtained in O(nm), where n denotes the number of variables, and m the number of clauses of the input DNF, but this is not scalable in practice. In this paper, we propose a neural model counting approach for weighted #DNF that combines approximate model counting with deep learning, and accurately approximates model counts in linear time when width is bounded. We conduct experiments to validate our method, and show that our model learns and generalizes very well to large-scale #DNF instances."}}
{"id": "Hogg4mZMl_6S", "cdate": 1546300800000, "mdate": null, "content": {"title": "Ontology-Mediated Query Answering over Log-Linear Probabilistic Data.", "abstract": "Large-scale knowledge bases are at the heart of modern information systems. Their knowledge is inherently uncertain, and hence they are often materialized as probabilistic databases. However, probabilistic database management systems typically lack the capability to incorporate implicit background knowledge and, consequently, fail to capture some intuitive query answers. Ontology-mediated query answering is a popular paradigm for encoding commonsense knowledge, which can provide more complete answers to user queries. We propose a new data model that integrates the paradigm of ontology-mediated query answering with probabilistic databases, employing a log-linear probability model. We compare our approach to existing proposals, and provide supporting computational results."}}
{"id": "5-cfSgzS67ZC", "cdate": 1546300800000, "mdate": null, "content": {"title": "Explanations for Query Answers under Existential Rules", "abstract": "Ontology-mediated query answering is an extensively studied paradigm, which aims at improving query answers with the use of a logical theory. As a form of logical entailment, ontology-mediated query answering is fully interpretable, which makes it possible to derive explanations for query answers. Surprisingly, however, explaining answers for ontology-mediated queries has received little attention for ontology languages based on existential rules. In this paper, we close this gap, and study the problem of explaining query answers in terms of minimal subsets of database facts. We provide a thorough complexity analysis for several decision problems associated with minimal explanations under existential rules."}}
