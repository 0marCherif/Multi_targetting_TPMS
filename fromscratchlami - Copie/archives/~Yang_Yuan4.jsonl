{"id": "uI8vqOg_Xra", "cdate": 1672531200000, "mdate": 1681652470590, "content": {"title": "Succinct Representations for Concepts", "abstract": ""}}
{"id": "k4D0RUybVp", "cdate": 1672531200000, "mdate": 1681652470390, "content": {"title": "Contrastive Learning Is Spectral Clustering On Similarity Graph", "abstract": ""}}
{"id": "YdFPHhzL38U", "cdate": 1672531200000, "mdate": 1681652470198, "content": {"title": "A Categorical Framework of General Intelligence", "abstract": ""}}
{"id": "vHgL7XYBiTd", "cdate": 1663850308374, "mdate": null, "content": {"title": "Finding Generalization Measures by Contrasting Signal and Noise", "abstract": "Generalization is one of the most fundamental challenges in deep learning, aiming to predict model performances on unseen data. Empirically, such predictions usually rely on a validation set, while recent works showed that an unlabeled validation set also works. Without validation sets, it is extremely difficult to obtain non-vacuous generalization bounds, which leads to a weaker task of finding generalization measures that monotonically relate to generalization error. In this paper, we propose a new generalization measure REF Complexity (RElative Fitting velocity between signal and noise), motivated by the intuition that a given model-algorithm pair may generalize well if it fits signal (e.g., true labels) fast while fitting noise (e.g., random labels) slow. Empirically, REF Complexity monotonically relates to test accuracy in real-world datasets without accessing additional validation sets, and achieves $-0.988$ correlation on CIFAR-10 and $-0.960$ correlation on CIFAR-100. We further theoretically verify the utility of REF Complexity under the regime of convex training with stochastic gradient descent.\n"}}
{"id": "mb7VM83DkyC", "cdate": 1663850089986, "mdate": null, "content": {"title": "On Uni-modal Feature Learning in Multi-modal Learning", "abstract": "We abstract the features of multi-modal data into 1) uni-modal features, which can be learned from uni-modal training, and 2) paired features, which can only be learned from cross-modal interaction. Multi-modal joint training is expected to benefit from cross-modal interaction on the basis of ensuring uni-modal feature learning. However, recent late-fusion training approaches still suffer from insufficient learning of uni-modal features on each modality and we prove that this phenomenon does hurt the model's generalization ability.\nGiven a multi-modal task, we propose to choose targeted late-fusion learning method from Uni-Modal Ensemble (UME) and the proposed Uni-Modal Teacher (UMT), according to the distribution of uni-modal and paired features. We demonstrate that, under a simple guiding strategy, we can achieve comparable results to other complex late-fusion or intermediate-fusion methods on multi-modal datasets, including VGG-Sound, Kinetics-400, UCF101, and ModelNet40."}}
{"id": "0uRm1YmFTu", "cdate": 1663850071755, "mdate": null, "content": {"title": "Predictive Inference with Feature Conformal Prediction", "abstract": "Conformal prediction is a distribution-free technique for establishing valid prediction intervals. Although conventionally people conduct conformal prediction in the output space, this is not the only possibility. In this paper, we propose feature conformal prediction, which extends the scope of conformal prediction to semantic feature spaces by leveraging the inductive bias of deep representation learning. From a theoretical perspective, we demonstrate that feature conformal prediction provably outperforms regular conformal prediction under mild assumptions. Our approach could be combined with not only vanilla conformal prediction, but also other adaptive conformal prediction methods. Apart from experiments on existing predictive inference benchmarks, we also demonstrate the state-of-the-art performance of the proposed methods on \\textit{large-scale} tasks such as ImageNet classification and Cityscapes image segmentation."}}
{"id": "7t3ggLCjl7G", "cdate": 1663849966480, "mdate": null, "content": {"title": "When Do Models Generalize? A Perspective From Data-Algorithm Compatibility", "abstract": "One of the major open problems in machine learning is to characterize generalization in the overparameterized regime, where most traditional generalization bounds become inconsistent (Nagarajan and Kolter, 2019). In many scenarios, their failure can be attributed to obscuring the crucial interplay between the training algorithm and the underlying data distribution. To address this issue, we propose a concept named compatibility, which quantitatively characterizes generalization in a both data-relevant and algorithm relevant manner. By considering the entire training trajectory and focusing on early-stopping iterates, compatibility exploits the data and the algorithm information and is therefore a more suitable notion for generalization. We validate this by theoretically studying compatibility under the setting of solving overparameterized linear regression with gradient descent. Specifically, we perform a data-dependent trajectory analysis and derive a sufficient condition for compatibility in such a setting. Our theoretical results demonstrate that in the sense of compatibility, generalization holds with significantly weaker restrictions on the problem instance than the previous last iterate analysis."}}
{"id": "YnVpYUjzVHC", "cdate": 1663849861278, "mdate": null, "content": {"title": "Consistent and Truthful Interpretation with Fourier Analysis", "abstract": "For many interdisciplinary fields, \nML interpretations need to be consistent with \\emph{what-if} scenarios related to the current case, i.e., if one factor changes, how does the model react?\nAlthough the attribution methods are supported by the elegant axiomatic systems, they mainly focus on individual inputs, \nand are generally inconsistent. \nTo support what-if scenarios, we introduce a new objective of consistency based on a notion called truthful interpretation. Towards this objective, \nwe apply Fourier analysis of Boolean functions to get \nconsistency guarantees. \nExperimental results show that \nfor neighborhoods with various radii, \nour method achieves $2$x - $50$x lower inconsistency compared with the other methods."}}
{"id": "zvTsaZ3V8ok", "cdate": 1640995200000, "mdate": 1681652470439, "content": {"title": "Consistent and Truthful Interpretation with Fourier Analysis", "abstract": ""}}
{"id": "c6iMrC4Rh5J", "cdate": 1640995200000, "mdate": 1681652470270, "content": {"title": "Anomaly Detection with Test Time Augmentation and Consistency Evaluation", "abstract": ""}}
