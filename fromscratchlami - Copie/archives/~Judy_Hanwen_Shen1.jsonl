{"id": "hzRSvYb0Soa", "cdate": 1640995200000, "mdate": 1682453128979, "content": {"title": "Leximax Approximations and Representative Cohort Selection", "abstract": "Finding a representative cohort from a broad pool of candidates is a goal that arises in many contexts such as choosing governing committees and consumer panels. While there are many ways to define the degree to which a cohort represents a population, a very appealing solution concept is lexicographic maximality (leximax) which offers a natural (pareto-optimal like) interpretation that the utility of no population can be increased without decreasing the utility of a population that is already worse off. However, finding a leximax solution can be highly dependent on small variations in the utility of certain groups. In this work, we explore new notions of approximate leximax solutions with three distinct motivations: better algorithmic efficiency, exploiting significant utility improvements, and robustness to noise. Among other definitional contributions, we give a new notion of an approximate leximax that satisfies a similarly appealing semantic interpretation and relate it to algorithmically-feasible approximate leximax notions. When group utilities are linear over cohort candidates, we give an efficient polynomial-time algorithm for finding a leximax distribution over cohort candidates in the exact as well as in the approximate setting. Furthermore, we show that finding an integer solution to leximax cohort selection with linear utilities is NP-Hard."}}
{"id": "-paTAN2bmx", "cdate": 1640995200000, "mdate": 1677868632265, "content": {"title": "Longitudinal Complex Dynamics of Labour Markets Reveal Increasing Polarisation", "abstract": ""}}
{"id": "WwZbupAKWo", "cdate": 1621630065121, "mdate": null, "content": {"title": "Fast and Memory Efficient Differentially Private-SGD via JL Projections", "abstract": "Differentially Private-SGD (DP-SGD) of Abadi et al. and its variations are the only known algorithms for private training of large scale neural networks. This algorithm requires computation of per-sample gradients norms which is extremely slow and memory intensive in practice. In this paper, we present a new framework to design differentially private optimizers called DP-SGD-JL and DP-Adam-JL. Our approach uses Johnson\u2013Lindenstrauss (JL) projections to quickly approximate the per-sample gradient norms without exactly computing them, thus making the training time and memory requirements of our optimizers closer to that of their non-DP versions. Unlike previous attempts to make DP-SGD faster which work only on a subset of network architectures or use compiler techniques, we propose an algorithmic solution which works for any network in a black-box manner which is the main contribution of this paper. To illustrate this, on IMDb dataset, we train a Recurrent Neural Network (RNN) to achieve good privacy-vs-accuracy tradeoff, while being significantly faster than DP-SGD and with a similar memory footprint as non-private SGD. "}}
{"id": "DcQ7KPjdQBu", "cdate": 1620503628265, "mdate": null, "content": {"title": "Human-centric dialog training via offline reinforcement learning", "abstract": "How can we train a dialog model to produce better conversations by learning from human feedback, without the risk of humans\nteaching it harmful chat behaviors? We start\nby hosting models online, and gather human\nfeedback from real-time, open-ended conversations, which we then use to train and improve the models using offline reinforcement\nlearning (RL). We identify implicit conversational cues including language similarity, elicitation of laughter, sentiment, and more, which\nindicate positive human feedback, and embed\nthese in multiple reward functions. A wellknown challenge is that learning an RL policy in an offline setting usually fails due to\nthe lack of ability to explore and the tendency\nto make over-optimistic estimates of future reward. These problems become even harder\nwhen using RL for language models, which\ncan easily have a 20,000 action vocabulary and\nmany possible reward functions. We solve\nthe challenge by developing a novel class of\noffline RL algorithms. These algorithms use\nKL-control to penalize divergence from a pretrained prior language model, and use a new\nstrategy to make the algorithm pessimistic, instead of optimistic, in the face of uncertainty.\nWe test the resulting dialog model with ratings from 80 users in an open-domain setting\nand find it achieves significant improvements\nover existing deep offline RL approaches. The\nnovel offline RL method is viable for improving any existing generative dialog model using\na static dataset of human feedback."}}
{"id": "z_80FXkfq2", "cdate": 1609459200000, "mdate": 1682453128969, "content": {"title": "Accuracy, Interpretability, and Differential Privacy via Explainable Boosting", "abstract": "We show that adding differential privacy to Explainable Boosting Machines (EBMs), a recent method for training interpretable ML models, yields state-of-the-art accuracy while protecting privacy. Our experiments on multiple classification and regression datasets show that DP-EBM models suffer surprisingly little accuracy loss even with strong differential privacy guarantees. In addition to high accuracy, two other benefits of applying DP to EBMs are: a) trained models provide exact global and local interpretability, which is often important in settings where differential privacy is needed; and b) the models can be edited after training without loss of privacy to correct errors which DP noise may have introduced."}}
{"id": "sPQ2Zw8znfN", "cdate": 1609459200000, "mdate": 1682453128978, "content": {"title": "Accuracy, Interpretability, and Differential Privacy via Explainable Boosting", "abstract": "We show that adding differential privacy to Explainable Boosting Machines (EBMs), a recent method for training interpretable ML models, yields state-of-the-art accuracy while protecting privacy. Ou..."}}
{"id": "m8XowUjBLAF", "cdate": 1609459200000, "mdate": 1682453128978, "content": {"title": "Fast and Memory Efficient Differentially Private-SGD via JL Projections", "abstract": "Differentially Private-SGD (DP-SGD) of Abadi et al. and its variations are the only known algorithms for private training of large scale neural networks. This algorithm requires computation of per-sample gradients norms which is extremely slow and memory intensive in practice. In this paper, we present a new framework to design differentially private optimizers called DP-SGD-JL and DP-Adam-JL. Our approach uses Johnson\u2013Lindenstrauss (JL) projections to quickly approximate the per-sample gradient norms without exactly computing them, thus making the training time and memory requirements of our optimizers closer to that of their non-DP versions. Unlike previous attempts to make DP-SGD faster which work only on a subset of network architectures or use compiler techniques, we propose an algorithmic solution which works for any network in a black-box manner which is the main contribution of this paper. To illustrate this, on IMDb dataset, we train a Recurrent Neural Network (RNN) to achieve good privacy-vs-accuracy tradeoff, while being significantly faster than DP-SGD and with a similar memory footprint as non-private SGD."}}
{"id": "k9Qr2nBKBGB", "cdate": 1609459200000, "mdate": null, "content": {"title": "Fast and Memory Efficient Differentially Private-SGD via JL Projections", "abstract": "Differentially Private-SGD (DP-SGD) of Abadi et al. (2016) and its variations are the only known algorithms for private training of large scale neural networks. This algorithm requires computation of per-sample gradients norms which is extremely slow and memory intensive in practice. In this paper, we present a new framework to design differentially private optimizers called DP-SGD-JL and DP-Adam-JL. Our approach uses Johnson-Lindenstrauss (JL) projections to quickly approximate the per-sample gradient norms without exactly computing them, thus making the training time and memory requirements of our optimizers closer to that of their non-DP versions. Unlike previous attempts to make DP-SGD faster which work only on a subset of network architectures or use compiler techniques, we propose an algorithmic solution which works for any network in a black-box manner which is the main contribution of this paper. To illustrate this, on IMDb dataset, we train a Recurrent Neural Network (RNN) to achieve good privacy-vs-accuracy tradeoff, while being significantly faster than DP-SGD and with a similar memory footprint as non-private SGD. The privacy analysis of our algorithms is more involved than DP-SGD, we use the recently proposed f-DP framework of Dong et al. (2019) to prove privacy."}}
{"id": "KaXBrXQDqDI", "cdate": 1609459200000, "mdate": 1682453128970, "content": {"title": "Differentially Private Set Union", "abstract": "We study the basic operation of set union in the global model of differential privacy. In this problem, we are given a universe $U$ of items, possibly of infinite size, and a database $D$ of users. Each user $i$ contributes a subset $W_i \\subseteq U$ of items. We want an ($\\epsilon$,$\\delta$)-differentially private algorithm which outputs a subset $S \\subset \\cup_i W_i$ such that the size of $S$ is as large as possible. The problem arises in countless real world applications; it is particularly ubiquitous in natural language processing (NLP) applications as vocabulary extraction. For example, discovering words, sentences, $n$-grams etc., from private text data belonging to users is an instance of the set union problem.Known algorithms for this problem proceed by collecting a subset of items from each user, taking the union of such subsets, and disclosing the items whose noisy counts fall above a certain threshold. Crucially, in the above process, the contribution of each individual user is always independent of the items held by other users, resulting in a wasteful aggregation process, where some item counts happen to be way above the threshold. We deviate from the above paradigm by allowing users to contribute their items in a {\\em dependent fashion}, guided by a {\\em policy}. In this new setting ensuring privacy is significantly delicate. We prove that any policy which has certain {\\em contractive} properties would result in a differentially private algorithm. We design two new algorithms for differentially private set union, one using Laplace noise and other Gaussian noise, which use $\\ell_1$-contractive and $\\ell_2$-contractive policies respectively and provide concrete examples of such policies. Our experiments show that the new algorithms in combination with our policies significantly outperform previously known mechanisms for the problem."}}
{"id": "uRs03aWPKT", "cdate": 1577836800000, "mdate": null, "content": {"title": "Human-centric dialog training via offline reinforcement learning", "abstract": "Natasha Jaques, Judy Hanwen Shen, Asma Ghandeharioun, Craig Ferguson, Agata Lapedriza, Noah Jones, Shixiang Gu, Rosalind Picard. Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP). 2020."}}
