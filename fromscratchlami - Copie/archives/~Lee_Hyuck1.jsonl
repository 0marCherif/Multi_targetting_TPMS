{"id": "TNve8-UKwv", "cdate": 1683935675942, "mdate": 1683935675942, "content": {"title": "Semi-Supervised Multi-Label Learning for Classification of Wafer Bin Maps With Mixed-Type Defect Patterns", "abstract": "After wafer fabrication, individual chips on the wafer are checked for defects by using multiple electrical tests. The test results can be represented by binary values for all individual chips, which form a spatial map called a wafer bin map (WBM). Different defect patterns in WBMs are related to different causes of process faults. Thus, it is important to classify WBMs according to their defect patterns to identify the root causes of process faults and correct the problems. Recently, with the increase in wafer size, the semiconductor manufacturing process has become more complicated and the probability of having mixed-type defect patterns in WBMs has increased. Previous studies for the classification of mixed-type defect patterns have mainly used labeled WBM data, although a much larger quantity of unlabeled data are often available in practice. To utilize both labeled and unlabeled data to achieve better classification performance, this study proposes the use of a semi-supervised deep convolutional generative model. In particular, we formulate the problem of classifying mixed-type defect patterns as a problem of multi-label classification and adopt multiple latent class variables, each for a distinct single pattern. As an inherent advantage of a generative model, we can also use the proposed model to generate new WBM data."}}
{"id": "8ODxY1-5I5", "cdate": 1683935544998, "mdate": 1683935544998, "content": {"title": "ABC: Auxiliary Balanced Classifier for Class-Imbalanced Semi-Supervised Learning", "abstract": "Existing semi-supervised learning (SSL) algorithms typically assume classbalanced datasets, although the class distributions of many real-world datasets\nare imbalanced. In general, classifiers trained on a class-imbalanced dataset are\nbiased toward the majority classes. This issue becomes more problematic for SSL\nalgorithms because they utilize the biased prediction of unlabeled data for training.\nHowever, traditional class-imbalanced learning techniques, which are designed for\nlabeled data, cannot be readily combined with SSL algorithms. We propose a scalable class-imbalanced SSL algorithm that can effectively use unlabeled data, while\nmitigating class imbalance by introducing an auxiliary balanced classifier (ABC)\nof a single layer, which is attached to a representation layer of an existing SSL algorithm. The ABC is trained with a class-balanced loss of a minibatch, while using\nhigh-quality representations learned from all data points in the minibatch using the\nbackbone SSL algorithm to avoid overfitting and information loss. Moreover, we\nuse consistency regularization, a recent SSL technique for utilizing unlabeled data\nin a modified way, to train the ABC to be balanced among the classes by selecting\nunlabeled data with the same probability for each class. The proposed algorithm\nachieves state-of-the-art performance in various class-imbalanced SSL experiments\nusing four benchmark datasets."}}
{"id": "1G6jPa9SKYG", "cdate": 1621629828022, "mdate": null, "content": {"title": "ABC: Auxiliary Balanced Classifier for Class-imbalanced Semi-supervised Learning", "abstract": "Existing semi-supervised learning (SSL) algorithms typically assume class-balanced datasets, although the class distributions of many real world datasets are imbalanced. In general, classifiers trained on a class-imbalanced dataset are biased toward the majority classes. This issue becomes more problematic for SSL algorithms because they utilize the biased prediction of unlabeled data for training. However, traditional class-imbalanced learning techniques, which are designed for labeled data, cannot be readily combined with SSL algorithms. We propose a scalable class-imbalanced SSL algorithm that can effectively use unlabeled data, while mitigating class imbalance by introducing an auxiliary balanced classifier (ABC) of a single layer, which is attached to a representation layer of an existing SSL algorithm. The ABC is trained with a class-balanced loss of a minibatch, while using high-quality representations learned from all data points in the minibatch using the backbone SSL algorithm to avoid overfitting and information loss. Moreover, we use consistency regularization, a recent SSL technique for utilizing unlabeled data in a modified way, to train the ABC to be balanced among the classes by selecting unlabeled data with the same probability for each class. The proposed algorithm achieves state-of-the-art performance in various class-imbalanced SSL experiments using four benchmark datasets."}}
