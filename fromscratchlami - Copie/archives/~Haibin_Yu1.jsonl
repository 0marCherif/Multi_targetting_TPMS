{"id": "A3XIP6MQRT", "cdate": 1683614620838, "mdate": 1683614620838, "content": {"title": "AdaTask: A Task-aware Adaptive Learning Rate Approach to Multi-task Learning", "abstract": "Multi-task learning (MTL) models have demonstrated impressive results in computer vision, natural language processing, and recommender systems. Even though many approaches have been proposed, how well these approaches balance different tasks on each parameter still remains unclear. In this paper, we propose to measure the task dominance degree of a parameter by the total updates of each task on this parameter. Specifically, we compute the total updates by the exponentially decaying Average of the squared Updates (AU) on a parameter from the corresponding task.Based on this novel metric, we observe that many parameters in existing MTL methods, especially those in the higher shared layers, are still dominated by one or several tasks. The dominance of AU is mainly due to the dominance of accumulative gradients from one or several tasks. Motivated by this, we propose a Task-wise Adaptive learning rate approach, AdaTask in short, to separate the \\emph{accumulative gradients} and hence the learning rate of each task for each parameter in adaptive learning rate approaches (e.g., AdaGrad, RMSProp, and Adam). Comprehensive experiments on computer vision and recommender system MTL datasets demonstrate that AdaTask significantly improves the performance of dominated tasks, resulting SOTA average task-wise performance. Analysis on both synthetic and real-world datasets shows AdaTask balance parameters in every shared layer well."}}
{"id": "idP4kbf5mhz", "cdate": 1683614418906, "mdate": 1683614418906, "content": {"title": "Convolutional Normalizing Flows for Deep Gaussian Processes", "abstract": "Deep Gaussian processes (DGPs), a hierarchical composition of GP models, have successfully boosted the expressive power of their single-layer counterpart. However, it is impossible to perform exact inference in DGPs, which has motivated the recent development of variational inference-based methods. Unfortunately, either these methods yield a biased posterior belief or it is difficult to evaluate their convergence. This paper introduces a new approach for specifying flexible, arbitrarily complex, and scalable approximate posterior distributions. The posterior distribution is constructed through a normalizing flow (NF) which transforms a simple initial probability into a more complex one through a sequence of invertible transformations. Moreover, a novel convolutional normalizing flow (CNF) is developed to improve the time efficiency and capture dependency between layers. Empirical evaluation shows that CNF DGP outperforms the state-of-the-art approximation methods for DGPs."}}
{"id": "BYIz5IIiql9", "cdate": 1646077521675, "mdate": null, "content": {"title": "On Provably Robust Meta-Bayesian Optimization", "abstract": "Bayesian optimization (BO) has become popular for sequential optimization of black-box functions. When BO is used to optimize a target function, we often have access to previous evaluations of potentially related functions. This begs the question as to whether we can leverage these previous experiences to accelerate the current BO task through meta-learning (meta-BO), while ensuring robustness against potentially harmful dissimilar tasks that could sabotage the convergence of BO. This paper introduces two scalable and provably robust meta-BO algorithms: robust meta-Gaussian process-upper confidence bound (RM-GP-UCB) and RM-GP-Thompson sampling (RM-GP-TS). We prove that both algorithms are asymptotically no-regret even when some or all previous tasks are dissimilar to the current task, and show that RM-GP-UCB enjoys a better theoretical robustness than RM-GP-TS. We also exploit the theoretical guarantees to optimize the weights assigned to individual previous tasks through regret minimization via online learning, which diminishes the impact of dissimilar tasks and hence further enhances the robustness. Empirical evaluations show that (a) RM-GP-UCB performs effectively and consistently across various applications, and (b) RM-GP-TS, despite being less robust than RM-GP-UCB both in theory and in practice, performs competitively in some scenarios with less dissimilar tasks and is more computationally efficient."}}
{"id": "pi2IZD3Gppx", "cdate": 1599614489913, "mdate": null, "content": {"title": "Stochastic Variational Inference for Bayesian Sparse Gaussian Process Regression", "abstract": "This paper presents a novel variational inference\nframework for deriving a family of Bayesian sparse Gaussian\nprocess regression (SGPR) models whose approximations are\nvariationally optimal with respect to the full-rank GPR model\nenriched with various corresponding correlation structures of the\nobservation noises. Our variational Bayesian SGPR (VBSGPR)\nmodels jointly treat both the distributions of the inducing variables and hyperparameters as variational parameters, which enables the decomposability of the variational lower bound that in\nturn can be exploited for stochastic optimization. Such a stochastic optimization involves iteratively following the stochastic gradient of the variational lower bound to improve its estimates of the optimal variational distributions of the inducing variables and hyperparameters (and hence the predictive distribution) ofour VBSGPR models and is guaranteed to achieve asymptotic convergence to them. We show that the stochastic gradient is an unbiased estimator of the exact gradient and can be computed\nin constant time per iteration, hence achieving scalability to big data. We empirically evaluate the performance of our proposed\nframework on two real-world, massive datasets."}}
{"id": "UCyGbBIU07f", "cdate": 1599614253732, "mdate": null, "content": {"title": "Implicit Posterior Variational Inference for Deep Gaussian Processes", "abstract": "A multi-layer deep Gaussian process (DGP) model is a hierarchical composition\nof GP models with a greater expressive power. Exact DGP inference is intractable,\nwhich has motivated the recent development of deterministic and stochastic approximation methods. Unfortunately, the deterministic approximation methods\nyield a biased posterior belief while the stochastic one is computationally costly.\nThis paper presents an implicit posterior variational inference (IPVI) framework\nfor DGPs that can ideally recover an unbiased posterior belief and still preserve\ntime efficiency. Inspired by generative adversarial networks, our IPVI framework\nachieves this by casting the DGP inference problem as a two-player game in which\na Nash equilibrium, interestingly, coincides with an unbiased posterior belief. This\nconsequently inspires us to devise a best-response dynamics algorithm to search for\na Nash equilibrium (i.e., an unbiased posterior belief). Empirical evaluation shows\nthat IPVI outperforms the state-of-the-art approximation methods for DGPs."}}
{"id": "HyEu_h-OZr", "cdate": 1546300800000, "mdate": null, "content": {"title": "Bayesian Optimization Meets Bayesian Optimal Stopping", "abstract": "Bayesian optimization (BO) is a popular paradigm for optimizing the hyperparameters of machine learning (ML) models due to its sample efficiency. Many ML models require running an iterative trainin..."}}
