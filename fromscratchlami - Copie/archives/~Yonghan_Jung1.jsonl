{"id": "QMGWz-B5E6J", "cdate": 1696532282471, "mdate": null, "content": {"title": "A Short Note on Finite Sample Analysis on Double/Debiased Machine Learning", "abstract": "This note provides learning guarantees for sample-splitting-based estimators, which include double/debiased machine learning (DML) (Chernozhukov et al., 2018) estimators. We prove consistency and Gaussian approximation of estimators using finite-sample arguments, extending the general asymptotic theory. Our work extends previous research (Chernozhukov et al., 2023; Quintas-Martinez, 2022) that studied learning guarantees for the expected linear functional in general sample-splitting-based estimators."}}
{"id": "q8vi4v_QgDf", "cdate": 1675441061251, "mdate": 1675441061251, "content": {"title": "On Measuring Causal Contributions via do-interventions", "abstract": "Causal contributions measure the strengths of different causes to a target quantity. Understanding causal contributions is important in empirical sciences and data-driven disciplines since it allows to answer practical queries like \u201cwhat are the contributions of each cause to the effect?\u201d In this paper, we develop a principled method for quantifying causal contributions. First, we provide desiderata of properties axioms that causal contribution measures should satisfy and propose the do-Shapley values (inspired by do-interventions [Pearl, 2000]) as a unique method satisfying these properties. Next, we develop a criterion under which the do-Shapley values can be efficiently inferred from non-experimental data. Finally, we provide do-Shapley estimators exhibiting consistency, computational feasibility, and statistical robustness. Simulation results corroborate with the theory.\n"}}
{"id": "r-7wVhpv1bL", "cdate": 1658283742693, "mdate": null, "content": {"title": "Understanding Shortcut Learning through the Lens of Causality and Robustness", "abstract": "Despite tremendous successes, modern machine learning models oftentimes fail to generalize for samples out of distributions where the models are trained. Such failure has been reported as shortcut learning [Geirhos et al., 2020], a phenomenon that ML models fail to generalize due to taking unintended features in establishing their decision rules. Notwithstanding that the shortcut learning problem is prevalent in practice, virtually no formal/unified understandings of notions of shortcut learning problems and approaches for addressing the biases have been presented. In this document, we provide an understanding of shortcut learning and present two common approaches for addressing the biases under the rubric of formal causal languages. Finally, we relate the approaches to the causal invariance property. We hope this document will pave the way toward a unified understanding of shortcut learning problems.  "}}
{"id": "UOqU5BS8nwz", "cdate": 1632750852004, "mdate": 1632750852004, "content": {"title": "Estimating Identifiable Causal Effects on Markov Equivalence Class through Double Machine Learning", "abstract": "General methods have been developed for estimating causal effects from observational data under causal assumptions encoded in the form of a causal graph. Most of this literature assumes that the underlying causal graph is completely specified. However, only observational data is available in most practical settings, which means that one can learn at most a Markov equivalence class (MEC) of the underlying causal graph. In this paper, we study the problem of causal estimation from a MEC represented by a partial ancestral graph (PAG), which is learnable from observational data. We develop a general estimator for any identifiable causal effects in a PAG. The result fills a gap for an end-to-end solution to causal inference from observational data to effects estimation. Specifically, we develop a complete identification algorithm that derives an influence function for any identifiable causal effects from PAGs. We then construct a double/debiased machine learning (DML) estimator that is robust to model misspecification and biases in nuisance function estimation, permitting the use of modern machine learning techniques. Simulation results corroborate with the theory.\n"}}
{"id": "x2Mr82GNFzp", "cdate": 1632750797757, "mdate": 1632750797757, "content": {"title": "Estimating Identifiable Causal Effects through Double Machine Learning", "abstract": "Identifying causal effects from observational data is a pervasive challenge found throughout the empirical sciences. Very general methods have been developed to decide the identifiability of a causal quantity from a combination of observational data and causal knowledge about the underlying system. In practice, however, there are still challenges to estimating identifiable causal functionals from finite samples. Recently, a method known as double/debiased machine learning (DML) (Chernozhukov et al. 2018) has been proposed to learn parameters leveraging modern machine learning techniques, which is both robust to model misspecification and bias-reducing. Still, DML has only been used for causal estimation in settings when the back-door condition (also known as conditional ignorability) holds. In this paper, we develop a new, general class of estimators for any identifiable causal functionals that exhibit DML properties, which we name DML-ID. In particular, we introduce a complete identification algorithm that returns an influence function (IF) for any identifiable causal functional. We then construct the DML estimator based on the derived IF. We show that DML-ID estimators hold the key properties of debiasedness and doubly robustness. Simulation results corroborate with the theory.\n"}}
{"id": "mSuBvrUJFsF", "cdate": 1621630296567, "mdate": null, "content": {"title": "Double Machine Learning Density Estimation for Local Treatment Effects with Instruments", "abstract": "Local treatment effects are a common quantity found throughout the empirical sciences that measure the treatment effect among those who comply with what they are assigned. Most of the literature is focused on estimating the average of such quantity, which is called the ``local average treatment effect (LATE)'' [Imbens and Angrist, 1994]). In this work, we study how to estimate the density of the local treatment effect, which is naturally more informative than its average. Specifically, we develop two families of methods for this task, namely, kernel-smoothing and model-based approaches. The kernel-smoothing-based approach estimates the density through some smooth kernel functions. The model-based approach estimates the density by projecting it onto a finite-dimensional density class. For both approaches, we derive the corresponding double/debiased machine learning-based estimators [Chernozhukov et al., 2018]. We further study the asymptotic convergence rates of the estimators and show that they are robust to the biases in nuisance function estimation. The use of the proposed methods is illustrated through both synthetic and a real dataset called 401(k)."}}
{"id": "kXIy8Fx1Ze2", "cdate": 1577836800000, "mdate": null, "content": {"title": "Learning Causal Effects via Weighted Empirical Risk Minimization", "abstract": "Learning causal effects from data is a fundamental problem across the sciences. Determining the identifiability of a target effect from a combination of the observational distribution and the causal graph underlying a phenomenon is well-understood in theory. However, in practice, it remains a challenge to apply the identification theory to estimate the identified causal functionals from finite samples. Although a plethora of effective estimators have been developed under the setting known as the back-door (also called conditional ignorability), there exists still no systematic way of estimating arbitrary causal functionals that are both computationally and statistically attractive. This paper aims to bridge this gap, from causal identification to causal estimation. We note that estimating functionals from limited samples based on the empirical risk minimization (ERM) principle has been pervasive in the machine learning literature, and these methods have been extended to causal inference under the back-door setting. In this paper, we develop a learning framework that marries two families of methods, benefiting from the generality of the causal identification theory and the effectiveness of the estimators produced based on the principle of ERM. Specifically, we develop a sound and complete algorithm that generates causal functionals in the form of weighted distributions that are amenable to the ERM optimization. We then provide a practical procedure for learning causal effects from finite samples and a causal graph. Finally, experimental results support the effectiveness of our approach."}}
{"id": "djh2O-_DrcI", "cdate": 1577836800000, "mdate": null, "content": {"title": "Estimating Causal Effects Using Weighting-Based Estimators", "abstract": "Causal effect identification is one of the most prominent and well-understood problems in causal inference. Despite the generality and power of the results developed so far, there are still challenges in their applicability to practical settings, arguably due to the finitude of the samples. Simply put, there is a gap between causal effect identification and estimation. One popular setting in which sample-efficient estimators from finite samples exist is when the celebrated back-door condition holds. In this paper, we extend weighting-based methods developed for the back-door case to more general settings, and develop novel machinery for estimating causal effects using the weighting-based method as a building block. We derive graphical criteria under which causal effects can be estimated using this new machinery and demonstrate the effectiveness of the proposed method through simulation studies."}}
