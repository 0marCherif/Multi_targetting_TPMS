{"id": "owzTyinv-tc", "cdate": 1640995200000, "mdate": 1672335947224, "content": {"title": "The Power of Two Matrices in Spectral Algorithms", "abstract": ""}}
{"id": "o3Qo9OaHpfX", "cdate": 1640995200000, "mdate": 1672335947205, "content": {"title": "Spectral recovery of binary censored block models", "abstract": ""}}
{"id": "cyTvQE7h97", "cdate": 1640995200000, "mdate": 1672335947184, "content": {"title": "Spectral Algorithms Optimally Recover (Censored) Planted Dense Subgraphs", "abstract": ""}}
{"id": "IFRt9VWQnvo", "cdate": 1640995200000, "mdate": 1672335946983, "content": {"title": "Local canonical labeling of Erd\u0151s-R\u00e9nyi random graphs", "abstract": ""}}
{"id": "DDtw0jZ1yvY", "cdate": 1640995200000, "mdate": 1672335946972, "content": {"title": "Community Detection in the Hypergraph SBM: Optimal Recovery Given the Similarity Matrix", "abstract": ""}}
{"id": "BYgeO015M-F", "cdate": 1640995200000, "mdate": 1672335947226, "content": {"title": "Exact Community Recovery in Correlated Stochastic Block Models", "abstract": ""}}
{"id": "6_XrC-B76cW", "cdate": 1640995200000, "mdate": 1672335946989, "content": {"title": "Exact Community Recovery in Correlated Stochastic Block Models", "abstract": ""}}
{"id": "1RsCVgnpK_i", "cdate": 1577836800000, "mdate": null, "content": {"title": "An improved lower bound for the Traveling Salesman constant", "abstract": "Let X 1 , X 2 , \u2026 , X n be independent uniform random variables on [ 0 , 1 ] 2 . Let L ( X 1 , \u2026 , X n ) be the length of the shortest Traveling Salesman tour through these points. Beardwood et al (1959) showed that there exists a constant \u03b2 such that lim n \u2192 \u221e L ( X 1 , \u2026 , X n ) n = \u03b2 almost surely. It was shown that \u03b2 \u2265 0 . 625 . Building upon an approach proposed by Steinerberger (2015), we improve the lower bound to \u03b2 \u2265 0 . 6277 ."}}
{"id": "Hkz29Brx8B", "cdate": 1567802772365, "mdate": null, "content": {"title": "Sparse High-Dimensional Isotonic Regression", "abstract": "We consider the problem of estimating an unknown coordinate-wise monotone function given noisy measurements, known as the isotonic regression problem. Often, only a small subset of the features affects the output. This motivates the sparse isotonic regression setting, which we consider here. We provide an upper bound on the expected VC entropy of the space of sparse coordinate-wise monotone functions, and identify the regime of statistical consistency of our estimator. We also propose a linear program to recover the active coordinates, and provide theoretical recovery guarantees. We close with experiments on cancer classification, and show that our method significantly outperforms standard methods."}}
{"id": "nDSnAHez_0S", "cdate": 1546300800000, "mdate": null, "content": {"title": "Exponential convergence rates for stochastically ordered Markov processes under perturbation", "abstract": "In this technical note we find computable exponential convergence rates for a large class of stochastically ordered Markov processes. We extend the result of Lund, Meyn, and Tweedie (1996), who found exponential convergence rates for stochastically ordered Markov processes starting from a fixed initial state, by allowing for a random initial condition that is also stochastically ordered. Our bounds are formulated in terms of moment-generating functions of hitting times. To illustrate our result, we find an explicit exponential convergence rate for an M/M/1 queue beginning in equilibrium and then experiencing a change in its arrival or departure rates, a setting which has not been studied to our knowledge."}}
