{"id": "2LXf6l0nWSM", "cdate": 1679903973237, "mdate": 1679903973237, "content": {"title": "An Accelerated Doubly Stochastic Gradient Method with Faster Explicit Model Identification", "abstract": "Sparsity regularized loss minimization problems play an important role in various fields including machine learning, data mining, and\nmodern statistics. Proximal gradient descent method and coordinate descent method are the most popular approaches to solving the\nminimization problem. Although existing methods can achieve implicit model identification, aka support set identification, in a finite\nnumber of iterations, these methods still suffer from huge computational costs and memory burdens in high-dimensional scenarios.\nThe reason is that the support set identification in these methods is implicit and thus cannot explicitly identify the low-complexity\nstructure in practice, namely, they cannot discard useless coefficients of the associated features to achieve algorithmic acceleration\nvia dimension reduction. To address this challenge, we propose a novel accelerated doubly stochastic gradient descent (ADSGD)\nmethod for sparsity regularized loss minimization problems, which can reduce the number of block iterations by eliminating inactive\ncoefficients during the optimization process and eventually achieve faster explicit model identification and improve the algorithm efficiency. Theoretically, we first prove that ADSGD can achieve a linear convergence rate and lower overall computational complexity. More importantly, we prove that ADSGD can achieve a linear rate of explicit model identification. Numerically, experimental results on benchmark datasets confirm the efficiency of our proposed method.\n"}}
{"id": "Ur1GcHLn-A1", "cdate": 1664731443921, "mdate": null, "content": {"title": "An Accuracy Guaranteed Online Solver for Learning in Dynamic Feature Space", "abstract": "We study the problem of adding or deleting features of data from machine learning models trained using empirical risk minimization. Our focus is on algorithms in an online manner which is capable for a more general regularization term, and present practical guides to two classical regularizers, i.e., the group Lasso and $\\ell_p$-norm regularizer. Across a variety of benchmark datasets, our algorithm improves upon the runtime of prior methods while maintaining the *same* generalization accuracy."}}
{"id": "7KdrFjpmJf7", "cdate": 1663850112076, "mdate": null, "content": {"title": "Learning Sampling Policy to Achieve Fewer  Queries for  Zeroth-Order Optimization", "abstract": "Zeroth-order (ZO) methods, which use the finite difference of two function evaluations (also called ZO gradient) to approximate first-order gradient, have attracted much attention recently in machine learning because of its broad applications.\nThe accurateness of ZO gradient highly depends on how many finite differences are averaged, which are intrinsically determined by the number of  perturbations randomly drawn from a distribution. \nExisting ZO methods try to learn a data-driven distribution for sampling the perturbations to improve the efficiency of ZO optimization (ZOO) algorithms. \nIn this paper, we explore  a  new and parallel direction, i.e. , learn an optimal sampling policy  instead of using totally random strategy  to generate perturbations based on the techniques of reinforcement\nlearning (RL), which makes it possible to  approximate the gradient  with only two function evaluations.  Specifically, we first formulate the problem of learning a sampling policy as a Markov decision process. Then, we propose our ZO-RL algorithm,  \\textit{i.e.}, using deep deterministic policy gradient, an actor-critic RL algorithm to  learn a  sampling policy which can guide the generation of perturbed vectors in getting ZO gradients as accurate as possible. Importantly, the existing ZOO algorithms of learning a distribution can be plugged in  to improve the exploration of  ZO-RL.\nExperimental results  with different ZO estimators show that our ZO-RL algorithm can effectively reduce the query complexity of ZOO algorithms  and converge faster than existing ZOO algorithms especially in the later stage of the  optimization process."}}
{"id": "KDhFkA6MQsW", "cdate": 1663850097931, "mdate": null, "content": {"title": "Faster Gradient-Free Methods for Escaping Saddle Points", "abstract": "Escaping from saddle points has become an important research topic in non-convex optimization. In this paper, we study the case when calculations of explicit gradients are expensive or even infeasible, and only function values are accessible. \nCurrently, there have  two types of gradient-free (zeroth-order) methods based on  random perturbation and negative curvature finding  proposed to escape saddle points  efficiently and converge to an $\\epsilon$-approximate second-order stationary point. \nNesterov's accelerated gradient descent (AGD) method can escape saddle points faster than gradient descent (GD) which have been verified in first-order algorithms. However, whether  AGD could accelerate the gradient-free methods is still unstudied. To  unfold this mystery, in this paper, we propose two accelerated  variants for the two types of gradient-free methods of escaping saddle points. We show that our algorithms can find an $\\epsilon$-approximate second-order stationary point with $\\tilde{\\mathcal{O}}(1/\\epsilon^{1.75})$ iteration complexity and $\\tilde{\\mathcal{O}}(d/\\epsilon^{1.75})$ oracle complexity, where $d$ is the problem dimension. Thus, our methods achieve a comparable convergence rate to their first-order counterparts and have fewer oracle complexity compared to prior derivative-free methods for finding second-order stationary points."}}
{"id": "gsU2MKneFy", "cdate": 1663850064748, "mdate": null, "content": {"title": "Efficient Method for Bi-level Optimization with Non-smooth Lower-Level Problem", "abstract": "Bi-level optimization plays a key role in a lot of machine learning applications. Existing state-of-the-art bi-level optimization methods are limited to smooth or some specific non-smooth lower-level problems. Therefore, achieving an efficient algorithm for the bi-level problems with a generalized non-smooth lower-level objective is still an open problem. To address this problem, in this paper, we propose a new bi-level optimization algorithm based on smoothing and penalty techniques. Using the theory of generalized directional derivative, we derive new conditions for the bilevel optimization problem with nonsmooth, perhaps non-Lipschitz lower-level problem, and prove our method can converge to the points satisfying these conditions. We also compare our method with existing state-of-the-art bi-level optimization methods and demonstrate that our method is superior to the others in terms of accuracy and efficiency."}}
{"id": "JX1OCjfABRj", "cdate": 1663850054087, "mdate": null, "content": {"title": "Self-Adaptive Perturbation Radii for Adversarial Training", "abstract": "Adversarial training has been shown to be the most popular and effective  technique to protect models from imperceptible adversarial samples. Despite its success, it also accompanies the significant performance degeneration to clean data. To achieve a good performance on both clean and adversarial samples, the main effort  is searching for an adaptive perturbation radius for each training sample, which essentially suffers from a  conflict between exact searching  and  computational overhead. To address this conflict, in this paper, firstly we show the superiority of adaptive perturbation radii intuitively and theoretically regarding the   accuracy and robustness respectively. Then we propose our novel self-adaptive adjustment framework for perturbation radii without tedious searching. We also discuss this framework on both deep neural networks (DNNs) and kernel support vector machines (SVMs).  Finally, extensive experimental results show that our framework can improve not only natural generalization performance but also adversarial robustness. It is also competitive with existing searching strategies in terms of running time."}}
{"id": "83piwkGNzOP", "cdate": 1663850016665, "mdate": null, "content": {"title": "A unified optimization framework of ANN-SNN Conversion: towards optimal mapping from activation values to firing rates", "abstract": "Spiking Neural Networks (SNNs) have attracted great attention as a primary candidate for running large-scale deep artificial neural networks (ANNs) in real-time due to their distinctive properties of energy-efficient and event-driven fast computation. Training an SNN directly from scratch is usually difficult because of the discreteness of spikes. Converting an ANN to an SNN, i.e., ANN-SNN conversion, is an alternative method to obtain deep SNNs.\nThe performance of the converted SNN is determined by both the ANN performance and the conversion error. The existing ANN-SNN conversion methods usually redesign the ANN with a new activation function instead of the regular ReLU, train the tailored ANN and convert it to an SNN. The performance loss between the regular ANN with ReLU and the tailored ANN has never been considered, which will be inherited to the converted SNN.  \nIn this work, we formulate the ANN-SNN conversion as a unified optimization problem which considers the performance loss between the regular ANN and the tailored ANN, as well as the conversion error simultaneously. Following the unified optimization framework, we propose the SlipReLU activation function to replace the regular ReLU activation function in the tailored ANN. The SlipReLU is a weighted sum of the threhold-ReLU and the step function, which improves the performance of either as an activation function alone.\nThe SlipReLU method covers a family of activation functions mapping from activation values in source ANNs to firing rates in target SNNs; most of the state-of-the-art optimal ANN-SNN conversion methods are special cases of our proposed SlipReLU method. We demonstrate through two theorems that the expected conversion error between SNNs and ANNs can theoretically be zero on a range of shift values $\\delta \\in [-\\frac{1}{2},\\frac{1}{2}]$ rather than a fixed shift term $\\frac{1}{2}$, enabling us to achieve converted SNNs with high accuracy and ultra-low latency. We evaluate our proposed SlipReLU method on CIFAR-10 dataset, and the results show that the SlipReLU outperforms the state-of-the-art ANN-SNN conversion in both accuracy and latency. To our knowledge, this is the first work to explore high-performance ANN-SNN conversion method considering the ANN performance and the conversion error simultaneously."}}
{"id": "pO7KggcbMiP", "cdate": 1663850005956, "mdate": null, "content": {"title": "BAMBI: Vertical Federated Bilevel Optimization with Privacy-Preserving and Computation Efficiency", "abstract": "Vertical federated learning (VFL) has shown promising in meeting the vast demands of multi-party privacy-preserving learning. However, existing VFL methods are not applicable to popular machine learning tasks falling under bilevel programming, such as  hyper-representation learning and hyperparameter tuning. A desirable solution is adopting bilevel optimization (BO) into VFL, but on-shelf BO methods are shackled by the difficulty in computing the hypergradients with privacy-preserving and computation-efficient under the setting of VFL. To address this challenge, this paper proposes a stochastic Bilevel optimizAtion Method with a desirable JacoBian estImator (BAMBI), which constructs a novel zeroth-order (ZO) estimator to locally approximate the Jacobian matrix. This approximation enables BAMBI to compute the hypergradients  in a privacy-preserving and computation-efficient manner.  We prove that BAMBI convergences in the rate of $\\mathcal{O}(1/\\sqrt{K})$ ($K$ is the total number of the upper-level iterations) under the nonconvex-strongly-convex setting which covers most practical scenarios. This convergence rate is comparable with the algorithms without ZO estimator, which justifies our advantage  in privacy preservation without sacrifice in convergence rate. Moreover, we design a BAMBI-DP method for further mitigating the concerns on label privacy by leveraging the differential privacy (DP) technique. Extensive experiments fully support our algorithms. The code will be released publicly. To our best knowledge, this is the first work on the bilevel optimization under the setting of VFL."}}
{"id": "0PH-P_FIqGD", "cdate": 1663849960743, "mdate": null, "content": {"title": "Compact Bilinear Pooling via General Bilinear Projection", "abstract": "Most factorized bilinear pooling (FBiP) employs Hadamard product-based bilinear projection to learn appropriate projecting directions to reduce the dimension of bilinear features. However, in this paper, we reveal that the Hadamard product-based bilinear projection makes FBiP miss a lot of possible projecting directions, which will significantly harm the performance of outputted compact bilinear features, including compactness and effectiveness. To address this issue, we propose a general matrix-based bilinear projection based on the rank-$k$ matrix base decomposition, where the Hadamard-based bilinear projection is a special case of our proposed one. Using the proposed bilinear projection, we design a novel low-rank factorized bilinear pooling (named RK-FBP), which does not miss any projecting directions. Thus, our RK-FBP can generate better compact bilinear features. To leverage high-order information in local features, we nest several RK-FBP modules together to formulate a multi-linear pooling that outputs compact multi-linear features. At last, we conduct experiments on several fine-grained image tasks to evaluate our models. The experiments show that our models achieve new state-of-the-art classification accuracy by the lowest dimension."}}
{"id": "2ZNPedOfwB", "cdate": 1652737490460, "mdate": null, "content": {"title": "Zeroth-Order Hard-Thresholding: Gradient Error vs. Expansivity", "abstract": "$\\ell_0$ constrained optimization is prevalent in machine learning, particularly for high-dimensional problems, because it is a fundamental approach to achieve sparse learning. Hard-thresholding gradient descent is a dominant technique to solve this problem. However, first-order gradients of the objective function may be either unavailable or expensive to calculate in a lot of real-world problems, where zeroth-order (ZO) gradients could be a good surrogate. Unfortunately, whether ZO gradients can work with the hard-thresholding operator is still an unsolved problem.\nTo solve this puzzle, in this paper, we focus on the $\\ell_0$ constrained black-box stochastic optimization problems, and propose a new stochastic zeroth-order gradient hard-thresholding (SZOHT) algorithm with  a general ZO gradient estimator powered by a novel random support sampling. We provide the convergence analysis of SZOHT under standard assumptions.   Importantly, we   reveal a conflict between  the deviation of  ZO estimators and  the expansivity of the hard-thresholding operator,  and provide a theoretical   minimal value of the number of random directions in ZO gradients. In addition,  we find that the query complexity of SZOHT is independent or weakly dependent on the dimensionality under different settings.  Finally, we illustrate the utility of our method on a portfolio optimization problem as well as black-box adversarial attacks."}}
