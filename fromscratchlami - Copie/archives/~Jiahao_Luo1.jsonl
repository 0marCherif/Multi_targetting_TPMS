{"id": "982B3FAYjgf", "cdate": 1672531200000, "mdate": 1709228372311, "content": {"title": "Disjoint Pose and Shape for 3D Face Reconstruction", "abstract": "Existing methods for 3D face reconstruction from a few casually captured images employ deep learning based models along with a 3D Morphable Model(3DMM) as face geometry prior. Structure From Motion(SFM), followed by Multi-View Stereo (MVS), on the other hand, uses dozens of high-resolution images to reconstruct accurate 3D faces. However, it produces noisy and stretched-out results with only two views available. In this paper, taking inspiration from both these methods, we propose an end-to-end pipeline that disjointly solves for pose and shape to make the optimization stable and accurate. We use a face shape prior to estimate face pose and use stereo matching followed by a 3DMM to solve for the shape. The proposed method achieves end-to-end topological consistency, enables iterative face pose refinement procedure, and show remarkable improvement on both quantitative and qualitative results over existing state-of-the-art methods."}}
{"id": "vwkGk3M-Fi3", "cdate": 1640995200000, "mdate": 1683925038719, "content": {"title": "Low-light Image Enhancement Using Chain-consistent Adversarial Networks", "abstract": "The capability to generate clear and bright images in low light situations is crucial for photographers, engineers, and researchers. When it is not possible to modify the imaging conditions, an algorithm to enhance images is needed. Traditional methods require manually adjusting parameters to tune the image. Supervised learning methods need to collect a large amount of paired data for training. In this paper, we demonstrate an semi-supervised method for low light image enhancement, using a chain of cycle consistent generators. We show the effectiveness of our method by comparing it to existing image enhancement methods, both using standard image quality metrics and by using human perceptual judgements. We include an ablation study for features in our model. Our proposed method is computationally efficient and does not require paired training data."}}
{"id": "knQ6_Jd_1X-", "cdate": 1640995200000, "mdate": 1668701876372, "content": {"title": "DuelGAN: A Duel Between Two Discriminators Stabilizes the GAN Training", "abstract": "In this paper, we introduce DuelGAN, a generative adversarial network (GAN) solution to improve the stability of the generated samples and to mitigate mode collapse. Built upon the Vanilla GAN\u2019s two-player game between the discriminator $$D_1$$ and the generator G, we introduce a peer discriminator $$D_2$$ to the min-max game. Similar to previous work using two discriminators, the first role of both $$D_1$$ , $$D_2$$ is to distinguish between generated samples and real ones, while the generator tries to generate high-quality samples which are able to fool both discriminators. Different from existing methods, we introduce a duel between $$D_1$$ and $$D_2$$ to discourage their agreement and therefore increase the level of diversity of the generated samples. This property alleviates the issue of early mode collapse by preventing $$D_1$$ and $$D_2$$ from converging too fast. We provide theoretical analysis for the equilibrium of the min-max game formed among $$G,D_1,D_2$$ . We offer convergence behavior of DuelGAN as well as stability of the min-max game. It\u2019s worth mentioning that DuelGAN operates in the unsupervised setting, and the duel between $$D_1$$ and $$D_2$$ does not need any label supervision. Experiments results on a synthetic dataset and on real-world image datasets (MNIST, Fashion MNIST, CIFAR-10, STL-10, CelebA, VGG) demonstrate that DuelGAN outperforms competitive baseline work in generating diverse and high-quality samples, while only introduces negligible computation cost. Our code is publicly available at https://github.com/UCSC-REAL/DuelGAN ."}}
{"id": "LM0o2ntECV", "cdate": 1640995200000, "mdate": 1668733393577, "content": {"title": "How much does input data type impact final face model accuracy?", "abstract": "Face models are widely used in image processing and other domains. The input data to create a 3D face model ranges from accurate laser scans to simple 2D RGB photographs. These input data types are typically deficient either due to missing regions, or because they are underconstrained. As a result, reconstruction methods include embedded priors encoding the valid domain of faces. System designers must choose a source of input data and then choose a reconstruction method to obtain a usable 3D face. If a particular application domain requires accuracy X, which kinds of input data are suitable? Does the input data need to be 3D, or will 2D data suffice? This paper takes a step toward answering these questions using synthetic data. A ground truth dataset is used to analyze accuracy obtainable from 2D landmarks, 3D landmarks, low quality 3D, high quality 3D, texture color, normals, dense 2D image data, and when regions of the face are missing. Since the data is synthetic it can be analyzed both with and without measurement error. This idealized synthetic analysis is then compared to real results from several methods for constructing 3D faces from 2D photographs. The experimental results suggest that accuracy is severely limited when only 2D raw input data exists."}}
{"id": "7rtL_9brHX", "cdate": 1640995200000, "mdate": 1709228372330, "content": {"title": "How Accurate Is Passive Stereo For 3d Face Reconstruction?", "abstract": "The highest quality 3D face reconstructions are produced using multi-view stereo methods, reporting errors below 0.5mm. Unfortunately, these methods typically employ dozens of high-resolution cameras in a large laboratory capture gantry. In contrast, monocular 3D face reconstruction using sophisticated deep learning models are suited for casual mobile phone imaging outside the lab and report a mean error of 1-2mm.This paper investigates whether classic stereo methods can be used in scenarios with only a few low-resolution images available. We expect to find that it cannot since multi-view stereo performs well only when many high-resolution images are provided. When only two low-resolution images are available, stereo produces very noisy results which are not directly usable. Surprisingly, however, our analysis shows that this visually noisy data has lower error than comparison state-of-the-art methods. We find that the visual artifacts from stereo can be removed using a morphable face model to constrain face shape."}}
{"id": "O0is8lbf0-", "cdate": 1609459200000, "mdate": 1668733393566, "content": {"title": "Face Models: How Good Does My Data Need To Be?", "abstract": "Face models are widely used in image processing and other domains. The input data to create a 3D face model ranges from accurate laser scans to simple 2D RGB photographs. System designers must choose a source of input data and then choose a reconstruction method to obtain a usable 3D face. If a particular application domain requires accuracy X, which kinds of input data are suitable? This paper takes a step toward answering this question. A variety of common input data types such as 2D landmarks and 3D scans are constructed from an existing high quality dataset. A morphable face model is then used to reconstruct 3D faces. By comparing to ground truth, an analysis of the relative error between different data types is obtained."}}
{"id": "90_aYezaDAm", "cdate": 1609459200000, "mdate": 1681767415467, "content": {"title": "PeerGAN: Generative Adversarial Networks with a Competing Peer Discriminator", "abstract": "In this paper, we introduce DuelGAN, a generative adversarial network (GAN) solution to improve the stability of the generated samples and to mitigate mode collapse. Built upon the Vanilla GAN's two-player game between the discriminator $D_1$ and the generator $G$, we introduce a peer discriminator $D_2$ to the min-max game. Similar to previous work using two discriminators, the first role of both $D_1$, $D_2$ is to distinguish between generated samples and real ones, while the generator tries to generate high-quality samples which are able to fool both discriminators. Different from existing methods, we introduce another game between $D_1$ and $D_2$ to discourage their agreement and therefore increase the level of diversity of the generated samples. This property alleviates the issue of early mode collapse by preventing $D_1$ and $D_2$ from converging too fast. We provide theoretical analysis for the equilibrium of the min-max game formed among $G, D_1, D_2$. We offer convergence behavior of DuelGAN as well as stability of the min-max game. It's worth mentioning that DuelGAN operates in the unsupervised setting, and the duel between $D_1$ and $D_2$ does not need any label supervision. Experiments results on a synthetic dataset and on real-world image datasets (MNIST, Fashion MNIST, CIFAR-10, STL-10, CelebA, VGG, and FFHQ) demonstrate that DuelGAN outperforms competitive baseline work in generating diverse and high-quality samples, while only introduces negligible computation cost."}}
