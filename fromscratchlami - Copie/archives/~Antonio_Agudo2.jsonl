{"id": "n9sxj3TKWm8", "cdate": 1684751145106, "mdate": null, "content": {"title": "Morphological symmetries in robot learning", "abstract": "This work studies the impact of morphological symmetries in learning applications in robotics. Morphological symmetries are a predominant feature in both biological and robotic systems, arising from the presence of planes/axis of symmetry in the system's morphology. This results in harmonious duplication and distribution of body parts  (e.g., humans' sagittal/left-right symmetry). Morphological symmetries become a significant learning prior as they extend to symmetries in the system's dynamics, optimal control policies, and in all proprioceptive and exteroceptive measurements, related to the system's dynamics evolution \\cite{ordonez2023discrete}. Exploiting these symmetries in learning applications offers several advantageous outcomes, such as the use of data augmentation to mitigate the cost and challenges of data collection, or the use of equivariant/invariant function approximation models (e.g., neural networks) to improve sample efficiency and generalization, while reducing the number of trainable parameters. Lastly, we provide a video presentation and an open access repository reproducing our experiments and allowing for rapid prototyping in robot learning applications exploiting morphological symmetries."}}
{"id": "TBOFHtBariC", "cdate": 1663850272295, "mdate": null, "content": {"title": "On discrete symmetries of robotics systems: A group-theoretic and data-driven analysis", "abstract": "In this work, we study the Morphological Symmetries of dynamical systems with one or more planes of symmetry, a predominant feature in animal biology and robotic systems, characterized by the duplication and balanced distribution of body parts. These morphological symmetries imply that the system's dynamics are symmetric (or approximately symmetric), which in turn imprints symmetries in optimal control policies and in all proprioceptive and exteroceptive measurements related to the evolution of the system's dynamics. For data-driven methods, symmetry represents an inductive bias that justifies data augmentation and the construction of symmetric function approximators. To this end, we use Group Theory to present a theoretical and practical framework allowing for (1) the identification of the system's morphological symmetry Group $\\G$, (2) the characterization of how the group acts upon the system state variables and any relevant measurement living in the Euclidean space, and (3) the exploitation of data symmetries through the use of $\\G$-equivariant/$\\G$-invariant Neural Networks, for which we present experimental results on synthetic and real-world applications, demonstrating how symmetry constraints lead to better sample efficiency and generalization while reducing the number of trainable parameters."}}
{"id": "4RyXRDhHFn", "cdate": 1581760902066, "mdate": null, "content": {"title": "Modal Space: A Physics-Based Model for Sequential Estimation of Time-Varying Shape from Monocular Video", "abstract": "This paper describes two sequential methods for\nrecovering the camera pose together with the 3D shape of\nhighly deformable surfaces from a monocular video. The\nnon-rigid 3D shape is modeled as a linear combination of\nmode shapes with time-varying weights that define the shape\nat each frame and are estimated on-the-fly. The low-rank\nconstraint is combined with standard smoothness priors to\noptimize the model parameters over a sliding window of\nimage frames. We propose to obtain a physics-based shape\nbasis using the initial frames on the video to code the timevarying shape along the sequence, reducing the problem from\ntrilinear to bilinear. To this end, the 3D shape is discretized\nby means of a soup of elastic triangular finite elements where\nwe apply a force balance equation. This equation is solved\nusing modal analysis via a simple eigenvalue problem to obtain a shape basis that encodes the modes of deformation.\nEven though this strategy can be applied in a wide variety\nof scenarios, when the observations are denser, the solution\ncan become prohibitive in terms of computational load. We\navoid this limitation by proposing two efficient coarse-tofine approaches that allow us to easily deal with dense 3D\nsurfaces. This results in a scalable solution that estimates\na small number of parameters per frame and could potentially run in real time. We show results on both synthetic\nand real videos with ground truth 3D data, while robustly\ndealing with artifacts such as noise and missing data"}}
{"id": "SYzF_3PRRm", "cdate": 1581760727545, "mdate": null, "content": {"title": "Shape Basis Interpretation for Monocular Deformable 3D Reconstruction", "abstract": "In this paper, we propose a novel interpretable shape model to encode object non-rigidity. We first use the initial frames of a\nmonocular video to recover a rest shape, used later to compute a dissimilarity measure based on a distance matrix measurement.\nSpectral analysis is then applied to this matrix to obtain a reduced shape basis, that in contrast to existing approaches, can be\nphysically interpreted. In turn, these pre-computed shape bases are used to linearly span the deformation of a wide variety of objects.\nWe introduce the low-rank basis into a sequential approach to recover both camera motion and non-rigid shape from the monocular\nvideo, by simply optimizing the weights of the linear combination using bundle adjustment. Since the number of parameters to optimize\nper frame is relatively small, specially when physical priors are considered, our approach is fast and can potentially run in real time.\nValidation is done in a wide variety of real-world objects, undergoing both inextensible and extensible deformations. Our approach\nachieves remarkable robustness to artifacts such as noisy and missing measurements and shows an improved performance to\ncompeting methods."}}
{"id": "Frj0DuV4st", "cdate": 1581760628553, "mdate": null, "content": {"title": "A scalable, efficient, and accurate solution to non-rigid structure from motion", "abstract": "Most Non-Rigid Structure from Motion (NRSfM) solutions are based on factorization approaches that\nallow reconstructing objects parameterized by a sparse set of 3D points. These solutions, however, are\nlow resolution and generally, they do not scale well to more than a few tens of points. While there have\nbeen recent attempts at bringing NRSfM to a dense domain, using for instance variational formulations,\nthese are computationally demanding alternatives which require certain spatial continuity of the data,\npreventing their use for articulated shapes with large deformations or situations with multiple discontinuous\nobjects. In this paper, we propose incorporating existing point trajectory low-rank models into a probabilistic\nframework for matrix normal distributions. With this formalism, we can then simultaneously learn shape and\npose parameters using expectation maximization, and easily exploit additional priors such as known point\ncorrelations. While similar frameworks have been used before to model distributions over shapes, here we\nshow that formulating the problem in terms of distributions over trajectories brings remarkable improvements,\nespecially in generality and efficiency. We evaluate the proposed approach in a variety of scenarios including\none or multiple objects, sparse or dense reconstructions, missing observations, mild or sharp deformations,\nand in all cases, with minimal prior knowledge and low computational cost."}}
{"id": "rsZWchrl_TS", "cdate": 1546300800000, "mdate": null, "content": {"title": "Robust Spatio-Temporal Clustering and Reconstruction of Multiple Deformable Bodies.", "abstract": "In this paper we present an approach to reconstruct the 3D shape of multiple deforming objects from a collection of sparse, noisy and possibly incomplete 2D point tracks acquired by a single monocular camera. Additionally, the proposed solution estimates the camera motion and reasons about the spatial segmentation (i.e., identifies each of the deforming objects in every frame) and temporal clustering (i.e., splits the sequence into motion primitive actions). This advances competing work, which mainly tackled the problem for one single object and non-occluded tracks. In order to handle several objects at a time from partial observations, we model point trajectories as a union of spatial and temporal subspaces, and optimize the parameters of both modalities, the non-observed point tracks, the camera motion, and the time-varying 3D shape via augmented Lagrange multipliers. The algorithm is fully unsupervised and does not require any training data at all. We thoroughly validate the method on challenging scenarios with several human subjects performing different activities which involve complex motions and close interaction. We show our approach achieves state-of-the-art 3D reconstruction results, while it also provides spatial and temporal segmentation."}}
{"id": "r1Nb2hZ_WS", "cdate": 1514764800000, "mdate": null, "content": {"title": "Image Collection Pop-Up: 3D Reconstruction and Clustering of Rigid and Non-Rigid Categories", "abstract": "This paper introduces an approach to simultaneously estimate 3D shape, camera pose, and object and type of deformation clustering, from partial 2D annotations in a multi-instance collection of images. Furthermore, we can indistinctly process rigid and non-rigid categories. This advances existing work, which only addresses the problem for one single object or, if multiple objects are considered, they are assumed to be clustered a priori. To handle this broader version of the problem, we model object deformation using a formulation based on multiple unions of subspaces, able to span from small rigid motion to complex deformations. The parameters of this model are learned via Augmented Lagrange Multipliers, in a completely unsupervised manner that does not require any training data at all. Extensive validation is provided in a wide variety of synthetic and real scenarios, including rigid and non-rigid categories with small and large deformations. In all cases our approach outperforms state-of-the-art in terms of 3D reconstruction accuracy, while also providing clustering results that allow segmenting the images into object instances and their associated type of deformation (or action the object is performing)."}}
{"id": "SybAKAZObB", "cdate": 1514764800000, "mdate": null, "content": {"title": "Geometry-Aware Network for Non-Rigid Shape Prediction From a Single View", "abstract": "We propose a method for predicting the 3D shape of a deformable surface from a single view. By contrast with previous approaches, we do not need a pre-registered template of the surface, and our method is robust to the lack of texture and partial occlusions. At the core of our approach is a geometry-aware deep architecture that tackles the problem as usually done in analytic solutions: first perform 2D detection of the mesh and then estimate a 3D shape that is geometrically consistent with the image. We train this architecture in an end-to-end manner using a large dataset of synthetic renderings of shapes under different levels of deformation, material properties, textures and lighting conditions. We evaluate our approach on a test split of this dataset and available real benchmarks, consistently improving state-of-the-art solutions with a significantly lower computational time."}}
{"id": "Skbyb6Wd-r", "cdate": 1514764800000, "mdate": null, "content": {"title": "Unsupervised Person Image Synthesis in Arbitrary Poses", "abstract": "We present a novel approach for synthesizing photo-realistic images of people in arbitrary poses using generative adversarial learning. Given an input image of a person and a desired pose represented by a 2D skeleton, our model renders the image of the same person under the new pose, synthesizing novel views of the parts visible in the input image and hallucinating those that are not seen. This problem has recently been addressed in a supervised manner, i.e., during training the ground truth images under the new poses are given to the network. We go beyond these approaches by proposing a fully unsupervised strategy. We tackle this challenging scenario by splitting the problem into two principal subtasks. First, we consider a pose conditioned bidirectional generator that maps back the initially rendered image to the original pose, hence being directly comparable to the input image without the need to resort to any training image. Second, we devise a novel loss function that incorporates content and style terms, and aims at producing images of high perceptual quality. Extensive experiments conducted on the DeepFashion dataset demonstrate that the images rendered by our model are very close in appearance to those obtained by fully supervised approaches."}}
{"id": "Hy442qWdZH", "cdate": 1514764800000, "mdate": null, "content": {"title": "GANimation: Anatomically-Aware Facial Animation from a Single Image", "abstract": "Recent advances in Generative Adversarial Networks (GANs) have shown impressive results for task of facial expression synthesis. The most successful architecture is StarGAN, that conditions GANs\u2019 generation process with images of a specific domain, namely a set of images of persons sharing the same expression. While effective, this approach can only generate a discrete number of expressions, determined by the content of the dataset. To address this limitation, in this paper, we introduce a novel GAN conditioning scheme based on Action Units (AU) annotations, which describes in a continuous manifold the anatomical facial movements defining a human expression. Our approach allows controlling the magnitude of activation of each AU and combine several of them. Additionally, we propose a fully unsupervised strategy to train the model, that only requires images annotated with their activated AUs, and exploit attention mechanisms that make our network robust to changing backgrounds and lighting conditions. Extensive evaluation show that our approach goes beyond competing conditional generators both in the capability to synthesize a much wider range of expressions ruled by anatomically feasible muscle movements, as in the capacity of dealing with images in the wild."}}
