{"id": "W32DP_2sW-b", "cdate": 1682899200000, "mdate": 1683903060170, "content": {"title": "Distributed Multiarmed Bandits", "abstract": "This article studies a distributed multiarmed bandit problem with heterogeneous observations of rewards. The problem is cooperatively solved by <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><tex-math notation=\"LaTeX\">$N$</tex-math></inline-formula> agents assuming each agent faces a common set of <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><tex-math notation=\"LaTeX\">$M$</tex-math></inline-formula> arms yet observes only local biased rewards of the arms. The goal of each agent is to minimize the cumulative expected regret with respect to the true rewards of the arms, where the mean of each arm's true reward equals the average of the means of all agents' observed biased rewards. Each agent recursively updates its decision by utilizing the information from its neighbors. Neighbor relationships are described by a time-dependent directed graph <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><tex-math notation=\"LaTeX\">$\\mathbb{G}(t)$</tex-math></inline-formula> whose vertices correspond to agents and whose arcs depict neighbor relationships. A fully distributed bandit algorithm is proposed, which couples the classical distributed averaging algorithm and the celebrated upper confidence bound bandit algorithm. It is shown that for any uniformly strongly connected sequence of <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><tex-math notation=\"LaTeX\">$\\mathbb{G}(t)$</tex-math></inline-formula> , the algorithm achieves guaranteed regret for each agent at the order of <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><tex-math notation=\"LaTeX\">$O(\\log T)$</tex-math></inline-formula> ."}}
{"id": "N7p6Er2YI6", "cdate": 1677628800000, "mdate": 1683903062136, "content": {"title": "Multilayer SIS Model With an Infrastructure Network", "abstract": "In this article, we develop a layered networked spread model for a susceptible-infected-susceptible pathogen-borne disease spreading over a human contact network and an infrastructure network, and refer to it as a layered networked susceptible-infected-water-susceptible model (SIWS). The \u201cW\u201d in SIWS represents any infrastructure network contamination, not necessarily restricted to a water distribution network. We identify sufficient conditions for the existence, uniqueness, and stability of various equilibria of the aforementioned model. Further, we study an observability problem, where, assuming that the measurements of the pathogen levels in the infrastructure network are available, we provide a necessary and sufficient condition for estimation of the sickness levels of the nodes in the human contact network. Our results are illustrated through an in-depth set of simulations."}}
{"id": "QzTPOfaEMn", "cdate": 1672531200000, "mdate": 1682358016600, "content": {"title": "A Resilient Distributed Algorithm for Solving Linear Equations", "abstract": "This paper presents a resilient distributed algorithm for solving a system of linear algebraic equations over a multi-agent network in the presence of Byzantine agents capable of arbitrarily introducing untrustworthy information in communication. It is shown that the algorithm causes all non-Byzantine agents' states to converge to the same least squares solution exponentially fast, provided appropriate levels of graph redundancy and objective redundancy are established. An explicit convergence rate is also provided."}}
{"id": "PRYW_fPPVkG", "cdate": 1672531200000, "mdate": 1683903060360, "content": {"title": "Information-Directed Policy Search in Sparse-Reward Settings via the Occupancy Information Ratio", "abstract": "This paper examines a new measure of the exploration/exploitation trade-off in reinforcement learning (RL) called the occupancy information ratio (OIR). To this end, the paper derives the Information-Directed Actor-Critic (IDAC) algorithm for solving the OIR problem, provides an overview of the rich theory underlying IDAC and related OIR policy gradient methods, and experimentally investigates the advantages of such methods. The central contribution of this paper is to provide empirical evidence that, due to the form of the OIR objective, IDAC enjoys superior performance over vanilla RL methods in sparse-reward environments."}}
{"id": "UjEqQnS5fLc", "cdate": 1667440633295, "mdate": null, "content": {"title": "Occupancy Information Ratio: Infinite-Horizon, Information-Directed, Parameterized Policy Search", "abstract": "We develop a new measure of the exploration/exploitation trade-off in infinite-horizon reinforcement learning (RL) problems called the occupancy information ratio (OIR), which is comprised of a ratio between the infinite-horizon average cost of a policy and the entropy of its induced long-term state occupancy measure. Modifying the classic RL objective in this way yields policies that strike an optimal balance between exploitation and exploration, providing a new tool for addressing the exploration/exploitation trade-off in RL. The paper develops for the first time policy gradient and actor-critic algorithms for OIR optimization based upon a new entropy gradient theorem, and establishes both asymptotic and non-asymptotic convergence results with global optimality guarantees. In experiments, these methodologies outperform several deep RL baselines in problems with sparse rewards, where many trajectories may be uninformative and skepticism about the environment is crucial to success."}}
{"id": "zi04yPCq1p", "cdate": 1640995200000, "mdate": 1683903062557, "content": {"title": "A hybrid observer for estimating the state of a distributed linear system", "abstract": ""}}
{"id": "xpJIdcRnsC", "cdate": 1640995200000, "mdate": 1683903062185, "content": {"title": "Distributed State Estimation for Linear Systems", "abstract": "This paper studies a distributed state estimation problem for both continuous- and discrete-time linear systems. A simply structured distributed estimator is first described for estimating the state of a continuous-time, jointly observable, input free, multi-channel linear system whose sensed outputs are distributed across a fixed multi-agent network. The estimator is then extended to non-stationary networks whose graphs switch according to a switching signal with a fixed dwell time or a variable but with fixed average dwell time, or switch arbitrarily under appropriate assumptions. The estimator is guaranteed to solve the problem, provided a network-widely shared gain is sufficiently large. As an alternative to sharing a common gain across the network, a fully distributed version of the estimator is thus studied in which each agent adaptively adjusts a local gain though the practicality of this approach is subject to a robustness issue common to adaptive control. A discrete-time version of the distributed state estimation problem is also studied, and a corresponding estimator is proposed for time-varying networks. For each scenario, it is explained how to construct the estimator so that its state estimation errors all converge to zero exponentially fast at a fixed but arbitrarily chosen rate, provided the network's graph is strongly connected for all time. This is accomplished by appealing to the ``split-spectrum'' approach and exploiting several well-known properties of invariant subspace. The proposed estimators are inherently resilient to abrupt changes in the number of agents and communication links in the inter-agent communication graph upon which the algorithms depend, provided the network is redundantly strongly connected and redundantly jointly observable."}}
{"id": "lkgmabP-pHa", "cdate": 1640995200000, "mdate": 1683903062874, "content": {"title": "Multi-Entanglement Routing Design over Quantum Networks", "abstract": "Quantum networks are considered as a promising future platform for quantum information exchange and quantum applications, which have capabilities far beyond the traditional communication networks. Remote quantum entanglement is an essential component of a quantum network. How to efficiently design a multi-routing entanglement protocol is a fundamental yet challenging problem. In this paper, we study a quantum entanglement routing problem to simultaneously maximize the number of quantum-user pairs and their expected throughput. Our approach is to formulate the problem as two sequential integer programming steps. We propose efficient entanglement routing algorithms for the two integer programming steps and analyze their time complexity and performance bounds. Results of evaluation highlight that our approach outperforms existing solutions in both served quantum-user pairs numbers and the network expected throughput."}}
{"id": "j1-gewKim1", "cdate": 1640995200000, "mdate": 1683903060711, "content": {"title": "Gossip over holonomic graphs", "abstract": ""}}
{"id": "dP6Od5-_E9y", "cdate": 1640995200000, "mdate": 1683903062856, "content": {"title": "Reaching a Consensus with Limited Information", "abstract": "In its simplest form the well known consensus problem for a networked family of autonomous agents is to devise a set of protocols or update rules, one for each agent, which can enable all of the agents to adjust or tune their \"agreement variable\" to the same value by utilizing real-time information obtained from their \"neighbors\" within the network. The aim of this paper is to study the problem of achieving a consensus in the face of limited information transfer between agents. By this it is meant that instead of each agent receiving an agreement variable or real-valued state vector from each of its neighbors, it receives a linear function of each state instead. The specific problem of interest is formulated and provably correct algorithms are developed for a number of special cases of the problem."}}
