{"id": "KUcZCDRUiiq", "cdate": 1672531200000, "mdate": 1681517138108, "content": {"title": "A Convergent Single-Loop Algorithm for Relaxation of Gromov-Wasserstein in Graph Data", "abstract": ""}}
{"id": "AGqhVfLEYpd", "cdate": 1672531200000, "mdate": 1681517138111, "content": {"title": "Outlier-Robust Gromov Wasserstein for Graph Data", "abstract": ""}}
{"id": "0jxPyVWmiiF", "cdate": 1663850089004, "mdate": null, "content": {"title": "A Convergent Single-Loop Algorithm for Relaxation of Gromov-Wasserstein in Graph Data ", "abstract": "In this work, we present the Bregman Alternating Projected Gradient (BAPG) method, a single-loop algorithm that offers an approximate solution to the Gromov-Wasserstein (GW) distance. \nWe introduce a novel relaxation technique that balances accuracy and computational efficiency, albeit with some compromises in the feasibility of the coupling map.  Our analysis is based on the observation that the GW problem satisfies the Luo-Tseng error bound condition, which relates to estimating the distance of a point to the critical point set of the GW problem based on the optimality residual.\nThis observation allows us to provide an approximation bound for the distance between the fixed-point set of BAPG and the critical point set of GW. Moreover, under a mild  technical assumption, we can  show that BAPG converges to its fixed point set.\nThe effectiveness of BAPG has been validated through comprehensive numerical experiments in graph alignment and partition tasks, where it outperforms existing methods in terms of both solution quality and wall-clock time."}}
{"id": "0Tvz54tKXCx", "cdate": 1640995200000, "mdate": 1671847091510, "content": {"title": "Fast and Provably Convergent Algorithms for Gromov-Wasserstein in Graph Learning", "abstract": "In this paper, we study the design and analysis of a class of efficient algorithms for computing the Gromov-Wasserstein (GW) distance tailored to large-scale graph learning tasks. Armed with the Luo-Tseng error bound condition~\\citep{luo1992error}, two proposed algorithms, called Bregman Alternating Projected Gradient (BAPG) and hybrid Bregman Proximal Gradient (hBPG) enjoy the convergence guarantees. Upon task-specific properties, our analysis further provides novel theoretical insights to guide how to select the best-fit method. As a result, we are able to provide comprehensive experiments to validate the effectiveness of our methods on a host of tasks, including graph alignment, graph partition, and shape matching. In terms of both wall-clock time and modeling performance, the proposed methods achieve state-of-the-art results."}}
