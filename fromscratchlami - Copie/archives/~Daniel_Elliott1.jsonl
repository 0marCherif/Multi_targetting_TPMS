{"id": "H1gupiC5KQ", "cdate": 1538087871734, "mdate": null, "content": {"title": "The wisdom of the crowd: reliable deep reinforcement learning through ensembles of Q-functions", "abstract": "Reinforcement learning agents learn by exploring the environment and then exploiting what they have learned.\nThis frees the human trainers from having to know the preferred action or intrinsic value of each encountered state.\nThe cost of this freedom is reinforcement learning is slower and more unstable than supervised learning.\nWe explore the possibility that ensemble methods can remedy these shortcomings and do so by investigating a novel technique which harnesses the wisdom of the crowds by bagging Q-function approximator estimates.\n\nOur results show that this proposed approach improves all three tasks and reinforcement learning approaches attempted.\nWe are able to demonstrate that this is a direct result of the increased stability of the action portion of the state-action-value function used by Q-learning to select actions and by policy gradient methods to train the policy.\n"}}
