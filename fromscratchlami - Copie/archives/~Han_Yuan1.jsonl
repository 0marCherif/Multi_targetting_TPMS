{"id": "_kk8KI8MiRE", "cdate": 1680443990470, "mdate": null, "content": {"title": "Human-Guided Design to Explain Deep Learning-based Pneumothorax Classifier", "abstract": "Pneumothorax (PTX) is an acute thoracic disease that can be diagnosed with chest radiographs. While deep learning (DL) models have proven effective in identifying PTX on radiographs, they have difficulties in gaining the trust of radiologists if the decision-making logic is unclear. Therefore, various methods have been proposed to explain the PTX diagnostic decision made by DL models. However, several studies indicate that the quality of DL model explanation is suboptimal. This paper introduces a human-guided approach to enhance the existing explanation method. Based on the IoU and Dice between the explanation of model-focusing regions and the ground truth lesion areas, we achieved an increase of 60.6% and 56.5% in Saliency Map, 69.0% and 66.7% in Grad-CAM, and 137.5% and 123.9% in Integrated Gradients."}}
{"id": "EVwbNcRa6Yf", "cdate": 1677713796905, "mdate": null, "content": {"title": "Error Analysis of Fitted Q-iteration with ReLU-activated Deep Neural Networks", "abstract": "Deep reinforcement learning (RL) has grown rapidly with the development of backbone feedforward neural networks (FNNs). However, there remains a theoretical gap when researchers conduct error analysis of the FNNs-based RL process. In this work, we provide an error analysis for deep-fitted $Q$-iteration applying  ReLU-activated FNNs for value function approximation. "}}
{"id": "L38bbHmRKx", "cdate": 1677713796493, "mdate": null, "content": {"title": "An Empirical Study of the Effect of Background Data Size on the Stability of SHapley Additive exPlanations (SHAP) for Deep Learning Models", "abstract": "SHapley Additive exPlanations (SHAP) is a popular method that requires a background dataset in uncovering the deduction mechanism of artificial neural networks (ANNs). Generally, a background dataset consists of instances randomly sampled from the training dataset. However, the sampling size and its effect on SHAP remain unexplored. In this work, we empirically explored the effect and illustrated several tips when applying SHAP. The code is publicly accessible at https://github.com/Han-Yuan-Med/shap-bg-size."}}
{"id": "RNlfw6KXJey", "cdate": 1677713796312, "mdate": null, "content": {"title": "Interpretable Machine Learning-Based Risk Scoring with Individual and Ensemble Model Selection for Clinical Decision Making", "abstract": "Clinical scores are highly interpretable and widely used in clinical risk stratification. AutoScore was previously developed as a clinical score generator, integrating the interpretability of clinical scores and the discriminability of machine learning. Although a basic framework has been established, AutoScore leaves room for enhancement: variable ranking via the random forest and manual model selection. In this work, we improved them with additional variable ranking methods and an automatic model selection. We demonstrated that these updates generate clinical scores with fewer variables and higher accuracy. The code is available at https://github.com/Han-Yuan-Med/comparison."}}
