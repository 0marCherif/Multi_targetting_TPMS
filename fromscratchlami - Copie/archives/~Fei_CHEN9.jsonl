{"id": "dipoGGbEr3", "cdate": 1230768000000, "mdate": 1683914343263, "content": {"title": "The Case for a Structured Approach to Managing Unstructured Data", "abstract": ""}}
{"id": "7E-y8KbwJKU", "cdate": 1230768000000, "mdate": 1683914343257, "content": {"title": "Optimizing complex extraction programs over evolving text data", "abstract": "Most information extraction (IE) approaches have considered only static text corpora, over which we apply IE only once. Many real-world text corpora however are dynamic. They evolve over time, and so to keep extracted information up to date we often must apply IE repeatedly, to consecutive corpus snapshots. Applying IE from scratch to each snapshot can take a lot of time. To avoid doing this, we have recently developed Cyclex, a system that recycles previous IE results to speed up IE over subsequent corpus snapshots. Cyclex clearly demonstrated the promise of the recycling idea. The work itself however is limited in that it considers only IE programs that contain a single IE ``blackbox.'' In practice, many IE programs are far more complex, containing multiple IE blackboxes connected in a compositional ``workflow.'' In this paper, we present Delex, a system that removes the above limitation. First we identify many difficult challenges raised by Delex, including modeling complex IE programs for recycling purposes, implementing the recycling process efficiently, and searching for an optimal execution plan in a vast plan space with different recycling alternatives. Next we describe our solutions to these challenges. Finally, we describe extensive experiments with both rule-based and learning-based IE programs over two real-world data sets, which demonstrate the utility of our approach."}}
{"id": "-SIauMB1g3", "cdate": 1230768000000, "mdate": 1683914343274, "content": {"title": "The Case for a Structured Approach to Managing Unstructured Data", "abstract": "The challenge of managing unstructured data represents perhaps the largest data management opportunity for our community since managing relational data. And yet we are risking letting this opportunity go by, ceding the playing field to other players, ranging from communities such as AI, KDD, IR, Web, and Semantic Web, to industrial players such as Google, Yahoo, and Microsoft. In this essay we explore what we can do to improve upon this situation. Drawing on the lessons learned while managing relational data, we outline a structured approach to managing unstructured data. We conclude by discussing the potential implications of this approach to managing other kinds of non-relational data, and to the identify of our field."}}
{"id": "qmdoflCJdx", "cdate": 1199145600000, "mdate": 1683914343281, "content": {"title": "Information extraction challenges in managing unstructured data", "abstract": "Over the past few years, we have been trying to build an end-to-end system at Wisconsin to manage unstructured data, using extraction, integration, and user interaction. This paper describes the key information extraction (IE) challenges that we have run into, and sketches our solutions. We discuss in particular developing a declarative IE language, optimizing for this language, generating IE provenance, incorporating user feedback into the IE process, developing a novel wiki-based user interface for feedback, best-effort IE, pushing IE into RDBMSs, and more. Our work suggests that IE in managing unstructured data can open up many interesting research challenges, and that these challenges can greatly benefit from the wealth of work on managing structured data that has been carried out by the database community."}}
{"id": "5gzp-KLXWMu", "cdate": 1199145600000, "mdate": 1683914343248, "content": {"title": "Efficient Information Extraction over Evolving Text Data", "abstract": "Most current information extraction (IE) approaches have considered only static text corpora, over which we typically have to apply IE only once. Many real-world text corpora however are dynamic. They evolve over time, and to keep extracted information up to date, we often must apply IE repeatedly, to consecutive corpus snapshots. We describe Cyclex, an approach that efficiently executes such repeated IE, by recycling previous IE efforts. Specifically, given a current corpus snapshot U, Cyclex identifies text portions of U that also appear in the previous corpus snapshot V. Since Cyclex has already executed IE over V, it can now recycle the IE results of these parts, by combining these results with the results of executing IE over the remaining parts of U, to produce the complete IE results for U. Realizing Cyclex raises many challenges, including modeling information extractors, exploring the trade-off between runtime and completeness in identifying overlapping text, and making informed, cost-based decisions between redoing IE from scratch and recycling previous IE results. We describe initial solutions to these challenges, and experiments over two real-world data sets that demonstrate the utility of our approach."}}
{"id": "cNwbBN7Lu7", "cdate": 1167609600000, "mdate": 1683914343264, "content": {"title": "Building Structured Web Community Portals: A Top-Down, Compositional, and Incremental Approach", "abstract": ""}}
{"id": "2zJuwy-A5aR", "cdate": 1167609600000, "mdate": 1683914343257, "content": {"title": "DBLife: A Community Information Management Platform for the Database Research Community (Demo)", "abstract": ""}}
{"id": "PieXeudtM1", "cdate": 1136073600000, "mdate": 1683914343276, "content": {"title": "Community Information Management", "abstract": ""}}
{"id": "mW9eo7P2fA-", "cdate": 1104537600000, "mdate": 1683914343271, "content": {"title": "PSORTb v.2.0: Expanded prediction of bacterial protein subcellular localization and insights gained from comparative proteome analysis", "abstract": "PSORTb v.1.1 is the most precise bacterial localization prediction tool available. However, the program's predictive coverage and recall are low and the method is only applicable to Gram-negative bacteria. The goals of the present work are as follows: increase PSORTb's coverage while maintaining the existing precision level, expand it to include Gram-positive bacteria and then carry out a comparative analysis of localization."}}
{"id": "H1bBBVWOWS", "cdate": 1041379200000, "mdate": null, "content": {"title": "Frequent-subsequence-based prediction of outer membrane proteins", "abstract": "A number of medically important disease-causing bacteria (collectively called Gram-negative bacteria) are noted for the extra \"outer\" membrane that surrounds their cell. Proteins resident in this membrane (outer membrane proteins, or OMPs) are of primary research interest for antibiotic and vaccine drug design as they are on the surface of the bacteria and so are the most accessible targets to develop new drugs against. With the development of genome sequencing technology and bioinformatics, biologists can now deduce all the proteins that are likely produced in a given bacteria and have attempted to classify where proteins are located in a bacterial cell. However such protein localization programs are currently least accurate when predicting OMPs, and so there is a current need for the development of a better OMP classifier. Data mining research suggests that the use of frequent patterns has good performance in aiding the development of accurate and efficient classification algorithms. In this paper, we present two methods to identify OMPs based on frequent subsequences and test them on all Gram-negative bacterial proteins whose localizations have been determined by biological experiments. One classifier follows an association rule approach, while the other is based on support vector machines (SVMs). We compare the proposed methods with the state-of-the-art methods in the biological domain. The results demonstrate that our methods are better both in terms of accurately identifying OMPs and providing biological insights that increase our understanding of the structures and functions of these important proteins."}}
