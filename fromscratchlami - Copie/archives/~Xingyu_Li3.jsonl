{"id": "BF4NpwMuei", "cdate": 1673287848213, "mdate": null, "content": {"title": "Whole-slide-imaging Cancer Metastases Detection and Localization with Limited Tumorous Data", "abstract": "Recently, various deep learning methods have shown significant successes in medical image analysis, especially in the detection of cancer metastases in hematoxylin and eosin (H&E) stained whole-slide images (WSIs). However, in order to obtain good performance, these research achievements rely on hundreds of well-annotated WSIs. In this study, we tackle the tumor localization and detection problem under the setting of few labeled whole slide images and introduce a patch-based analysis pipeline based on the latest reverse knowledge distillation architecture. To address the extremely unbalanced normal and tumorous samples in training sample collection, we applied the focal loss formula to the representation similarity metric for model optimization. Compared with prior arts, our method achieves similar performance by less than ten percent of training samples on the public Camelyon16 dataset. In addition, this is the first work that show the great potential of the knowledge distillation models in computational histopathology. The source code is publicly available at https://github.com/wollf2008/FW-RD."}}
{"id": "qNFBFo3bPh", "cdate": 1668022158187, "mdate": null, "content": {"title": "Generating Diverse and Natural 3D Human Motions from Text", "abstract": "Automated generation of 3D human motions from text is a challenging problem. The generated motions are expected to be sufficiently diverse to explore the text-grounded motion space, and more importantly, accurately depicting the content in prescribed text descriptions. Here we tackle this problem with a two-stage approach: text2length sampling and text2motion generation. Text2length involves sampling from the learned distribution function of motion lengths conditioned on the input text. This is followed by our text2motion module using temporal variational autoencoder to synthesize a diverse set of human motions of the sampled lengths. Instead of directly engaging with pose sequences, we propose motion snippet code as our internal motion representation, which captures local semantic motion contexts and is empirically shown to facilitate the generation of plausible motions faithful to the input text. Moreover, a large-scale dataset of scripted 3D Human motions, HumanML3D, is constructed, consisting of 14,616 motion clips and 44,970 text descriptions.\n"}}
{"id": "iDhZDauoXY", "cdate": 1640995200000, "mdate": 1667340590799, "content": {"title": "Self-supervised Anomaly Detection with Random-shape Pseudo-outliers", "abstract": "Anomaly detection in a medical image is a challenging yet essential task. It relies on learning patterns/distributions from health data only, and no abnormal samples are available during training. This study proposes a novel self-supervised learning method to precisely detect and localize anomalies in MRI medical images. We synthesize abnormal images by overlaying random pseudo-outliers onto normal samples and propose a discriminative model for anomaly detection. Unlike prior arts that generate abnormalities with pre-determined regular geometric shapes, we introduce a new outlier synthesis strategy capable of generating random-shape anomalies. By learning the disentanglement of pseudo-outliers and normal regions in the synthesized images, our model can capture natural anomalies in images at both the pixel level and sample level. We present our empirical experimentation on two publicly accessible datasets and demonstrate the proposed method's superiority over SOTA solutions on MRIs."}}
{"id": "d93rNH-DIWk", "cdate": 1640995200000, "mdate": 1667340590819, "content": {"title": "Adversarial Fine-tune with Dynamically Regulated Adversary", "abstract": "Adversarial training is an effective method to boost model robustness to malicious, adversarial attacks. However, such improvement in model robustness often leads to a significant sacrifice of standard performance on clean images. In many real-world applications such as health diagnosis and autonomous surgical robotics, the standard performance is more valued over model robustness against such extremely malicious attacks. This leads us to the question: to what extent can we improve the robustness of the model without sacrificing standard performance? This work tackles this problem and proposes a simple yet effective transfer learning based adversarial training strategy that disentangles the negative effects of adversarial samples on model's standard performance. In addition, we introduce a training-friendly adversarial attack algorithm, which facilitates the boost of adversarial robustness without introducing significant training complexity. Extensive experiments show that the proposed approach outperforms previous adversarial training algorithms with the following objective: to improve the robustness of the model while preserving model's standard accuracy on clean data."}}
{"id": "_D2qX0N9xp", "cdate": 1640995200000, "mdate": 1667340590793, "content": {"title": "Anomaly Detection via Reverse Distillation from One-Class Embedding", "abstract": "Knowledge distillation (KD) achieves promising results on the challenging problem of unsupervised anomaly detection (AD). The representation discrepancy of anomalies in the teacher-student (T-S) model provides essential evidence for AD. However, using similar or identical architectures to build the teacher and student models in previous studies hinders the diversity of anomalous representations. To tackle this problem, we propose a novel T-S model consisting of a teacher encoder and a student decoder and introduce a simple yet effective \u201creverse distillation\u201d paradigm accordingly. Instead of receiving raw images directly, the student network takes teacher model's one-class embedding as input and targets to restore the teacher's multi-scale representations. Inherently, knowledge distillation in this study starts from abstract, high-level presentations to low-level features. In addition, we introduce a trainable one-class bottleneck embedding (OCBE) module in our T-S model. The obtained compact embedding effectively preserves essential information on normal patterns, but aban-dons anomaly perturbations. Extensive experimentation on AD and one-class novelty detection benchmarks shows that our method surpasses SOTA performance, demonstrating our proposed approach's effectiveness and generalizability."}}
{"id": "ZMDX_Gzv6h", "cdate": 1640995200000, "mdate": 1667340590352, "content": {"title": "Anomaly Detection via Reverse Distillation from One-Class Embedding", "abstract": "Knowledge distillation (KD) achieves promising results on the challenging problem of unsupervised anomaly detection (AD).The representation discrepancy of anomalies in the teacher-student (T-S) model provides essential evidence for AD. However, using similar or identical architectures to build the teacher and student models in previous studies hinders the diversity of anomalous representations. To tackle this problem, we propose a novel T-S model consisting of a teacher encoder and a student decoder and introduce a simple yet effective \"reverse distillation\" paradigm accordingly. Instead of receiving raw images directly, the student network takes teacher model's one-class embedding as input and targets to restore the teacher's multiscale representations. Inherently, knowledge distillation in this study starts from abstract, high-level presentations to low-level features. In addition, we introduce a trainable one-class bottleneck embedding (OCBE) module in our T-S model. The obtained compact embedding effectively preserves essential information on normal patterns, but abandons anomaly perturbations. Extensive experimentation on AD and one-class novelty detection benchmarks shows that our method surpasses SOTA performance, demonstrating our proposed approach's effectiveness and generalizability."}}
{"id": "NiNCpe8U-0", "cdate": 1640995200000, "mdate": 1667340590357, "content": {"title": "Generating Diverse and Natural 3D Human Motions from Text", "abstract": "Automated generation of 3D human motions from text is a challenging problem. The generated motions are expected to be sufficiently diverse to explore the text-grounded motion space, and more importantly, accurately depicting the content in prescribed text descriptions. Here we tackle this problem with a two-stage approach: text2length sampling and text2motion generation. Text2length involves sampling from the learned distribution function of motion lengths conditioned on the input text. This is followed by our text2motion module using temporal variational autoen-coder to synthesize a diverse set of human motions of the sampled lengths. Instead of directly engaging with pose sequences, we propose motion snippet code as our internal motion representation, which captures local semantic motion contexts and is empirically shown to facilitate the generation of plausible motions faithful to the input text. Moreover, a large-scale dataset of scripted 3D Human motions, HumanML3D, is constructed, consisting of 14,616 motion clips and 44,970 text descriptions."}}
{"id": "JD6-Zm41he3", "cdate": 1640995200000, "mdate": 1667340590800, "content": {"title": "Adversarial Fine-tune with Dynamically Regulated Adversary", "abstract": "Adversarial training is an effective method to boost model robustness to malicious, adversarial attacks. However, such improvement in model robustness often leads to a significant sacrifice of standard performance on clean images. In many real-world applications such as health diagnosis and autonomous surgical robotics, the standard performance is more valued over model robustness against such extremely malicious attacks. This leads to the question: To what extent we can boost model robustness without sacrificing standard performance? This work tackles this problem and proposes a simple yet effective transfer learning-based adversarial training strategy that disentangles the negative effects of adversarial samples on model's standard performance. In addition, we introduce a training-friendly adversarial attack algorithm, which facilitates the boost of adversarial robustness without introducing significant training complexity. Extensive experimentation indicates that the proposed method outperforms previous adversarial training algorithms towards the target: to improve model robustness while preserving model's standard performance on clean data."}}
{"id": "5RwR3_9ASX", "cdate": 1640995200000, "mdate": 1667340590348, "content": {"title": "A Domain-Adapted Machine Learning Approach for Visual Evaluation and Interpretation of Robot-Assisted Surgery Skills", "abstract": "In this study, we present an intuitive machine learning-based approach to evaluate and interpret surgical skills level of a participant working with robotic platforms. The proposed method is domain-adapted, i.e., jointly utilizes an end-to-end learning approach for smoothness detection and domain knowledge-based metrics such as fluidity and economy of motion for extracting skills-related features within a given trajectory. An advantage of our approach compared to similar stochastic or deep learning models is its intuitive and transparent manner for extraction and visualization of skills-related features within the data. We illustrate the performance of our proposed method on trials of the JIGSAWS data set as well as our own experimental data gathered from Phantom Premium <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><tex-math notation=\"LaTeX\">$\\boldsymbol{1.5}$</tex-math></inline-formula> A Haptic Device. This approach utilized <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><tex-math notation=\"LaTeX\">$\\boldsymbol{t}\\text{-}{\\mathbf {SNE}}$</tex-math></inline-formula> technique and provides visualized low-dimensional representation for different trials that highlights nuanced information within the executive task and returns unusual or faulty trials as outliers far away from their normal skill or participant clusters. This information regarding the input trajectory can be used for evaluation and education applications such as learning curve analysis in surgical assessment and training programs."}}
{"id": "eDv-oxTinj", "cdate": 1609459200000, "mdate": 1667340591690, "content": {"title": "Surgical Skill Evaluation From Robot-Assisted Surgery Recordings", "abstract": "Quality and safety are critical elements in the performance of surgeries. Therefore, surgical trainees need to obtain the required degrees of expertise before operating on patients. Conventionally, a trainee\u2019s performance is evaluated by qualitative methods that are time-consuming and prone to bias. Using autonomous and quantitative surgical skill assessment improves the consistency, repeatability, and reliability of the evaluation. To this end, this paper proposes a video-based deep learning framework for surgical skill assessment. By incorporating prior knowledge on surgeon\u2019s activity in the system design, we decompose the complex task of spatio-temporal representation learning from video recordings into two independent, relatively-simple learning processes, which greatly reduces the model size. We evaluate the proposed framework using the publicly available JIGSAWS robotic surgery dataset and demonstrate its capability to learn the underlying features of surgical maneuvers and the dynamic interplay between sequences of actions effectively. The skill level classification accuracy of 97.27% on the public dataset demonstrates the superiority of the proposed model over prior video-based skill assessment methods. The code of this paper will be available on Github at link: ${\\color{blue}{\\text{sourceCode}}}$."}}
