{"id": "uBtxmeW5-LP", "cdate": 1672531200000, "mdate": 1708544909630, "content": {"title": "On Enhancing WiGig Communications With A UAV-Mounted RIS System: A Contextual Multi-Armed Bandit Approach", "abstract": "Recently emerging WiGig systems experience limited coverage and signal strength fluctuations due to strict line-of-sight (LoS) connectivity requirements. In this paper, we address these shortcomings of WiGig communication by exploiting two emerging technologies in tandem, namely the reconfigurable intelligent surface (RIS) and unmanned aerial vehicles (UAVs). In ultra-dense traffic sites (referred to as hotspots) where WiGig nodes or User Devices (UDs) experience complex propagation and non-line-of-sight (non-LoS) environment, we envision the deployment of a UAV-mounted RIS system to complement the WiGig base station (WGBS) to deliver services to the UDs. However, commercially available UAVs have limited energy (i.e., constrained flight time). Therefore, the trajectory of our considered UAV needs to be locally estimated to enable it to serve multiple hotspots while minimizing its energy consumption within the WGBS coverage boundaries. Since this tradeoff problem is computationally expensive for the resource-constrained UAV, we argue that sequential learning can be a lightweight yet effective solution to locally solve the problem with a low impact on the available energy on the UAV. We formally formulate this problem as a contextual multi-armed bandit (CMAB) game. Then, we develop the linear randomized upper confidence bound (Lin-RUCB) algorithm to solve the problem effectively. We regard the UAV as the bandit learner, which attempts to maximize its attainable rate (i.e., the reward) by serving distinct hotspots in its trajectory that we treat as the arms of the considered bandit. The context is defined as the hotspots\u2019 locations provided using GPS (global positioning system) service and the reward history of each hotspot. Our proposal accounts for the energy expenditure of the UAV in moving from one hotspot to another within its battery charge lifetime. We evaluate the performance of our proposal via extensive simulations that exhibit the superiority of our proposed Lin-RUCB algorithm over benchmarking methods."}}
{"id": "WZ5oEpwbJj", "cdate": 1672531200000, "mdate": 1708544909681, "content": {"title": "Pure exploration in multi-armed bandits with low rank structure using oblivious sampler", "abstract": "In this paper, we consider the low rank structure of the reward sequence of the pure exploration problems. Firstly, we propose the separated setting in pure exploration problem, where the exploration strategy cannot receive the feedback of its explorations. Due to this separation, it requires that the exploration strategy to sample the arms obliviously. By involving the kernel information of the reward vectors, we provide efficient algorithms for both time-varying and fixed cases with regret bound $O(d\\sqrt{(\\ln N)/n})$. Then, we show the lower bound to the pure exploration in multi-armed bandits with low rank sequence. There is an $O(\\sqrt{\\ln N})$ gap between our upper bound and the lower bound."}}
{"id": "Qn6uAb7CY3", "cdate": 1672531200000, "mdate": 1708544909629, "content": {"title": "An Improved Metarounding Algorithm via Frank-Wolfe", "abstract": "Metarounding is an approach to convert an approximation algorithm for linear optimization over some combinatorial classes to an online linear optimization algorithm for the same class. We propose a new metarounding algorithm under a natural assumption that a relax-based approximation algorithm exists for the combinatorial class. Our algorithm is much more efficient in both theoretical and practical aspects."}}
{"id": "LlJxIhMvpQ", "cdate": 1672531200000, "mdate": 1708544909616, "content": {"title": "Boosting-based Construction of BDDs for Linear Threshold Functions and Its Application to Verification of Neural Networks", "abstract": "Understanding the characteristics of neural networks is important but difficult due to their complex structures and behaviors. Some previous work proposes to transform neural networks into equivalent Boolean expressions and apply verification techniques for characteristics of interest. This approach is promising since rich results of verification techniques for circuits and other Boolean expressions can be readily applied. The bottleneck is the time complexity of the transformation. More precisely, (i) each neuron of the network, i.e., a linear threshold function, is converted to a Binary Decision Diagram (BDD), and (ii) they are further combined into some final form, such as Boolean circuits. For a linear threshold function with $n$ variables, an existing method takes $O(n2^{\\frac{n}{2}})$ time to construct an ordered BDD of size $O(2^{\\frac{n}{2}})$ consistent with some variable ordering. However, it is non-trivial to choose a variable ordering producing a small BDD among $n!$ candidates. We propose a method to convert a linear threshold function to a specific form of a BDD based on the boosting approach in the machine learning literature. Our method takes $O(2^n \\text{poly}(1/\\rho))$ time and outputs BDD of size $O(\\frac{n^2}{\\rho^4}\\ln{\\frac{1}{\\rho}})$, where $\\rho$ is the margin of some consistent linear threshold function. Our method does not need to search for good variable orderings and produces a smaller expression when the margin of the linear threshold function is large. More precisely, our method is based on our new boosting algorithm, which is of independent interest. We also propose a method to combine them into the final Boolean expression representing the neural network."}}
{"id": "J8KpZ8FbFJ", "cdate": 1672531200000, "mdate": 1682322092599, "content": {"title": "Load Balancing Multi-Player MAB Approaches for RIS-Aided mmWave User Association", "abstract": "In this paper, multiple reconfigurable intelligent surface (RIS) boards are deployed to enhance millimeter wave (mmWave) communication in a harsh blockage environment, where mmWave line-of-sight (LoS) link is completely blocked. Herein, RIS-user association should be considered to maximize the users\u2019 achievable data rate while assuring load balance among the installed RIS panels. However, maximum received power (MRP) based RIS-user association will overload some of the RIS boards while keeping others unloaded, which causes RIS load to unbalance and decreases the users\u2019 achievable data rate. Instead, in this paper, an online learning methodology using centralized multi-player multi-armed bandit (MP-MAB) with arms\u2019 load balancing is proposed. In this formulation, mmWave users, RIS boards, and achievable users\u2019 rates act as the bandit game players, arms, and rewards. During the MAB game, the users learn how to avoid associating with the heavily loaded RIS boards, maximizing their achievable data rates, and balancing the RIS loads. Three centralized MP-MAB algorithms with arms\u2019 load balancing are proposed from the family of upper confidence bound (UCB) MAB algorithms. These algorithms are UCB1, Kullback-Leibler divergence UCB (KLUCB), and Minimax optimal stochastic strategy (MOSS) with arms\u2019 load balancing, i.e., UCB1-LB, KLUCB-LB, and MOSS-LB. Numerical analysis ensures the superior performance of the proposed algorithms over MRP-based RIS-user association and other benchmarks."}}
{"id": "GwtBJV511eB", "cdate": 1672531200000, "mdate": 1708544909659, "content": {"title": "Extended Formulations via Decision Diagrams", "abstract": "We propose a general algorithm of constructing an extended formulation for any given set of linear constraints with integer coefficients. Our algorithm consists of two phases: first construct a decision diagram (V,\u00a0E) that somehow represents a given                                                                       $$m \\times n$$                                 constraint matrix, and then build an equivalent set of |E| linear constraints over                                                                       $$n+|V|$$                                 variables. That is, the size of the resultant extended formulation depends not explicitly on the number m of the original constraints, but on its decision diagram representation. Therefore, we may significantly reduce the computation time and space for optimization problems with integer constraint matrices by solving them under the extended formulations, especially when we obtain concise decision diagram representations for the matrices. We demonstrate the effectiveness of our extended formulations for mixed integer programming and the 1-norm regularized soft margin optimization tasks over synthetic and real datasets. Eligible for best student paper."}}
{"id": "DnTi4qRR_zB", "cdate": 1672531200000, "mdate": 1708544909649, "content": {"title": "Boosting-Based Construction of BDDs for Linear Threshold Functions and Its Application to Verification of Neural Networks", "abstract": "Understanding the characteristics of neural networks is important but difficult due to their complex structures and behaviors. Some previous work proposes to transform neural networks into equivalent Boolean expressions and apply verification techniques for characteristics of interest. This approach is promising since rich results of verification techniques for circuits and other Boolean expressions can be readily applied. The bottleneck is the time complexity of the transformation. More precisely, (i) each neuron of the network, i.e., a linear threshold function, is converted to a Binary Decision Diagram (BDD), and (ii) they are further combined into some final form, such as Boolean circuits. For a linear threshold function with n variables, an existing method takes $$O(n2^{\\frac{n}{2}})$$ time to construct an ordered BDD of size $$O(2^{\\frac{n}{2}})$$ consistent with some variable ordering. However, it is non-trivial to choose a variable ordering producing a small BDD among n! candidates. We propose a method to convert a linear threshold function to a specific form of a BDD based on the boosting approach in the machine learning literature. Our method takes $$O(2^n \\text {poly}(1/\\rho ))$$ time and outputs BDD of size $$O(\\frac{n^2}{\\rho ^4}\\ln {\\frac{1}{\\rho }})$$ , where $$\\rho $$ is the margin of some consistent linear threshold function. Our method does not need to search for good variable orderings and produces a smaller expression when the margin of the linear threshold function is large. More precisely, our method is based on our new boosting algorithm, which is of independent interest. We also propose a method to combine them into the final Boolean expression representing the neural network. In our experiments on verification tasks of neural networks, our methods produce smaller final Boolean expressions, on which the verification tasks are done more efficiently."}}
{"id": "3MaB4SYHqnm", "cdate": 1664731444722, "mdate": null, "content": {"title": "Boosting as Frank-Wolfe", "abstract": "Some boosting algorithms, such as LPBoost, ERLPBoost, and C-ERLPBoost, aim to solve the soft margin optimization problem with the $\\ell_1$-norm regularization. \nLPBoost rapidly converges to an $\\epsilon$-approximate solution in practice, \nbut it is known to take $\\Omega(m)$ iterations in the worst case, where $m$ is the sample size.\nOn the other hand, ERLPBoost and C-ERLPBoost are guaranteed to converge to an $\\epsilon$-approximate solution in $O(\\frac{1}{\\epsilon^2} \\ln \\frac{m}{\\nu})$ iterations. However, the computation per iteration is very high compared to LPBoost. \n\nTo address this issue, we propose a generic boosting scheme that combines the Frank-Wolfe algorithm and any secondary algorithm \nand switches one to the other iteratively. We show that the scheme retains the same convergence guarantee \nas ERLPBoost and C-ERLPBoost. One can incorporate any secondary algorithm to improve in practice.\nThis scheme comes from a unified view of boosting algorithms for soft margin optimization. \nMore specifically, we show that LPBoost, ERLPBoost, and C-ERLPBoost are instances \nof the Frank-Wolfe algorithm. In experiments on real datasets, \none of the instances of our scheme exploits the better updates of the second algorithm \nand performs comparably with LPBoost."}}
{"id": "BFZL7ULicg5", "cdate": 1646077515447, "mdate": null, "content": {"title": "Simplified and Unified Analysis of Various Learning Problems by Reduction to Multiple-Instance Learning", "abstract": "In statistical learning, many problem formulations have been proposed so far, such as multi-class learning, complementarily labeled learning, multi-label learning, multi-task learning, which provide theoretical models for various real-world tasks. Although they have been extensively studied, the relationship among them has not been fully investigated. In this work, we focus on a particular problem formulation called Multiple-Instance Learning (MIL), and show that various learning problems including all the problems mentioned above with some of new problems can be reduced to MIL with theoretically guaranteed generalization bounds, where the reductions are established under a new reduction scheme we provide as a by-product. The results imply that the MIL-reduction gives a simplified and unified framework for designing and analyzing algorithms for various learning problems. Moreover, we show that the MIL-reduction framework can be kernelized."}}
{"id": "sTEBRUoRv3", "cdate": 1640995200000, "mdate": 1682322092255, "content": {"title": "Extended Formulations via Decision Diagrams", "abstract": "We propose a general algorithm of constructing an extended formulation for any given set of linear constraints with integer coefficients. Our algorithm consists of two phases: first construct a decision diagram $(V,E)$ that somehow represents a given $m \\times n$ constraint matrix, and then build an equivalent set of $|E|$ linear constraints over $n+|V|$ variables. That is, the size of the resultant extended formulation depends not explicitly on the number $m$ of the original constraints, but on its decision diagram representation. Therefore, we may significantly reduce the computation time for optimization problems with integer constraint matrices by solving them under the extended formulations, especially when we obtain concise decision diagram representations for the matrices. We can apply our method to $1$-norm regularized hard margin optimization over the binary instance space $\\{0,1\\}^n$, which can be formulated as a linear programming problem with $m$ constraints with $\\{-1,0,1\\}$-valued coefficients over $n$ variables, where $m$ is the size of the given sample. Furthermore, introducing slack variables over the edges of the decision diagram, we establish a variant formulation of soft margin optimization. We demonstrate the effectiveness of our extended formulations for integer programming and the $1$-norm regularized soft margin optimization tasks over synthetic and real datasets."}}
