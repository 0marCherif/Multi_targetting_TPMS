{"id": "j9yxfHTsfc", "cdate": 1683882508809, "mdate": 1683882508809, "content": {"title": "Devon: Deformable Volume Network for Learning Optical Flow", "abstract": "State-of-the-art neural network models estimate large displacement optical flow in multi-resolution and use warping to propagate the estimation between two resolutions. Despite their impressive results, it is known that there are two problems with the approach. First, the multi-resolution estimation of optical flow fails in situations where small objects move fast. Second, warping creates artifacts when occlusion or dis-occlusion happens. In this paper, we propose a new neural network module, Deformable Cost Volume, which alleviates the two problems. Based on this module, we designed the Deformable Volume Network (Devon) which can estimate multi-scale optical flow in a single high resolution. Experiments show Devon is more suitable in handling small objects moving fast and achieves comparable results to the state-of-the-art methods in public benchmarks."}}
{"id": "uNrSvEr9Lqc", "cdate": 1677713825306, "mdate": null, "content": {"title": "Generalised Lookahead Optimiser", "abstract": "The vast majority of deep learning models are trained using SGD or one of its\nvariants. Zhang et al. (2019) suggested the Lookahead optimiser as an alternative\nwhich enjoys remarkable test performance on many established datasets and mod-\nels. In this work we investigate a generalisation of this optimisation method. We\nvalidate the method empirically, generally demonstrating better results and faster\nconvergence relative to the baselines of SGD and Lookahead"}}
{"id": "mNtFhoNRr4i", "cdate": 1652737397780, "mdate": null, "content": {"title": "Hierarchical classification at multiple operating points", "abstract": "Many classification problems consider classes that form a hierarchy. Classifiers that are aware of this hierarchy may be able to make confident predictions at a coarse level despite being uncertain at the fine-grained level. While it is generally possible to vary the granularity of predictions using a threshold at inference time, most contemporary work considers only leaf-node prediction, and almost no prior work has compared methods at multiple operating points. We present an efficient algorithm to produce operating characteristic curves for any method that assigns a score to every class in the hierarchy. Applying this technique to evaluate existing methods reveals that top-down classifiers are dominated by a naive flat softmax classifier across the entire operating range. We further propose two novel loss functions and show that a soft variant of the structured hinge loss is able to significantly outperform the flat baseline. Finally, we investigate the poor accuracy of top-down classifiers and demonstrate that they perform relatively well on unseen classes."}}
{"id": "_L0nSXXUDDR", "cdate": 1632875710674, "mdate": null, "content": {"title": "Learning with Neighbor Consistency for Noisy Labels", "abstract": "Recent advances in deep learning have relied on large, labelled datasets to train high-capacity models. However, collecting large datasets in a time- and cost-efficient manner often results in label noise. We present a method for learning from noisy labels that leverages similarities between training examples in feature space, encouraging the prediction of each example to be similar to its nearest neighbours. Compared to training algorithms that use multiple models or distinct stages, our approach takes the form of a simple, additional regularization term. It can be interpreted as an inductive version of the classical, transductive label propagation algorithm. We compare our approach to relevant baselines under both synthetic and realistic noise, and demonstrate that our simple approach achieves state-of-the-art accuracy under the realistic conditions of mini-ImageNet-Red, mini-WebVision and Clothing1M.\n\n"}}
{"id": "dYCeSKqL3uf", "cdate": 1609459200000, "mdate": 1663112818775, "content": {"title": "Local Metrics for Multi-Object Tracking", "abstract": "This paper introduces temporally local metrics for Multi-Object Tracking. These metrics are obtained by restricting existing metrics based on track matching to a finite temporal horizon, and provide new insight into the ability of trackers to maintain identity over time. Moreover, the horizon parameter offers a novel, meaningful mechanism by which to define the relative importance of detection and association, a common dilemma in applications where imperfect association is tolerable. It is shown that the historical Average Tracking Accuracy (ATA) metric exhibits superior sensitivity to association, enabling its proposed local variant, ALTA, to capture a wide range of characteristics. In particular, ALTA is better equipped to identify advances in association independent of detection. The paper further presents an error decomposition for ATA that reveals the impact of four distinct error types and is equally applicable to ALTA. The diagnostic capabilities of ALTA are demonstrated on the MOT 2017 and Waymo Open Dataset benchmarks."}}
{"id": "I4MW5BWhDU", "cdate": 1577836800000, "mdate": 1663112818793, "content": {"title": "Devon: Deformable Volume Network for Learning Optical Flow", "abstract": "State-of-the-art neural network models estimate large displacement optical flow in multi-resolution and use warping to propagate the estimation between two resolutions. Despite their impressive results, it is known that there are two problems with the approach. First, the multi-resolution estimation of optical flow fails in situations where small objects move fast. Second, warping creates artifacts when occlusion or dis-occlusion happens. In this paper, we propose a new neural network module, Deformable Cost Volume, which alleviates the two problems. Based on this module, we designed the Deformable Volume Network (Devon) which can estimate multi-scale optical flow in a single high resolution. Experiments show Devon is more suitable in handling small objects moving fast and achieves comparable results to the state-of-the-art methods in public benchmarks."}}
{"id": "ryWjsqZdZS", "cdate": 1514764800000, "mdate": null, "content": {"title": "Devon: Deformable Volume Network for Learning Optical Flow", "abstract": "We propose a new neural network module, Deformable Cost Volume, for learning large displacement optical flow. The module does not distort the original images or their feature maps and therefore avoids the artifacts associated with warping. Based on this module, a new neural network model is proposed. The full version of this paper can be found online ( https://arxiv.org/abs/1802.07351 )."}}
{"id": "BJEbVqZO-S", "cdate": 1514764800000, "mdate": null, "content": {"title": "Long-Term Tracking in the Wild: A Benchmark", "abstract": "We introduce the OxUvA dataset and benchmark for evaluating single-object tracking algorithms. Benchmarks have enabled great strides in the field of object tracking by defining standardized evaluations on large sets of diverse videos. However, these works have focused exclusively on sequences that are just tens of seconds in length and in which the target is always visible. Consequently, most researchers have designed methods tailored to this \u201cshort-term\u201d scenario, which is poorly representative of practitioners\u2019 needs. Aiming to address this disparity, we compile a long-term, large-scale tracking dataset of sequences with average length greater than two minutes and with frequent target object disappearance. The OxUvA dataset is much larger than the object tracking datasets of recent years: it comprises 366 sequences spanning 14\u00a0h of video. We assess the performance of several algorithms, considering both the ability to locate the target and to determine whether it is present or absent. Our goal is to offer the community a large and diverse benchmark to enable the design and evaluation of tracking methods ready to be used \u201cin the wild\u201d. The project website is oxuva.net ."}}
{"id": "jscEpyb3V9T", "cdate": 1483228800000, "mdate": 1663112818801, "content": {"title": "Kronecker-Markov Prior for Dynamic 3D Reconstruction", "abstract": "Recovering dynamic 3D structures from 2D image observations is highly under-constrained because of projection and missing data, motivating the use of strong priors to constrain shape deformation. In this paper, we empirically show that the spatiotemporal covariance of natural deformations is dominated by a Kronecker pattern. We demonstrate that this pattern arises as the limit of a spatiotemporal autoregressive process, and derive a Kronecker Markov Random Field as a prior distribution over dynamic structures. This distribution unifies shape and trajectory models of prior art and has the individual models as its marginals. The key assumption of the Kronecker MRF is that the spatiotemporal covariance is separable into the product of a temporal and a shape covariance, and can therefore be modeled using the matrix normal distribution. Analysis on motion capture data validates that this distribution is an accurate approximation with significantly fewer free parameters. Using the trace-norm, we present a convex method to estimate missing data from a single sequence when the marginal shape distribution is unknown. The Kronecker-Markov distribution, fit to a single sequence, outperforms state-of-the-art methods at inferring missing 3D data, and additionally provides covariance estimates of the uncertainty."}}
{"id": "SyWXsJMObH", "cdate": 1483228800000, "mdate": null, "content": {"title": "End-to-End Representation Learning for Correlation Filter Based Tracking", "abstract": "The Correlation Filter is an algorithm that trains a linear template to discriminate between images and their translations. It is well suited to object tracking because its formulation in the Fourier domain provides a fast solution, enabling the detector to be re-trained once per frame. Previous works that use the Correlation Filter, however, have adopted features that were either manually designed or trained for a different task. This work is the first to overcome this limitation by interpreting the Correlation Filter learner, which has a closed-form solution, as a differentiable layer in a deep neural network. This enables learning deep features that are tightly coupled to the Correlation Filter. Experiments illustrate that our method has the important practical benefit of allowing lightweight architectures to achieve state-of-the-art performance at high framerates."}}
