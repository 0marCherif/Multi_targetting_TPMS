{"id": "JDMcfp18Hg", "cdate": 1672531200000, "mdate": 1682357898654, "content": {"title": "Online Pen Testing", "abstract": "We study a \"pen testing\" problem, in which we are given n pens with unknown amounts of ink X\u2081, X\u2082, \u2026, X_n, and we want to choose a pen with the maximum amount of remaining ink in it. The challenge is that we cannot access each X_i directly; we only get to write with the i-th pen until either a certain amount of ink is used, or the pen runs out of ink. In both cases, this testing reduces the remaining ink in the pen and thus the utility of selecting it. Despite this significant lack of information, we show that it is possible to approximately maximize our utility up to an O(log n) factor. Formally, we consider two different setups: the \"prophet\" setting, in which each X_i is independently drawn from some distribution \ud835\udc9f_i, and the \"secretary\" setting, in which (X_i)_{i=1}^n is a random permutation of arbitrary a\u2081, a\u2082, \u2026, a_n. We derive the optimal competitive ratios in both settings up to constant factors. Our algorithms are surprisingly robust: (1) In the prophet setting, we only require one sample from each \ud835\udc9f_i, rather than a full description of the distribution; (2) In the secretary setting, the algorithm also succeeds under an arbitrary permutation, if an estimate of the maximum a_i is given. Our techniques include a non-trivial online sampling scheme from a sequence with an unknown length, as well as the construction of a hard, non-uniform distribution over permutations. Both might be of independent interest. We also highlight some immediate open problems and discuss several directions for future research."}}
{"id": "thirVlDJ2IL", "cdate": 1652737565991, "mdate": null, "content": {"title": "A Fourier Approach to Mixture Learning", "abstract": "We revisit the problem of learning mixtures of spherical Gaussians. Given samples from a mixture $\\frac{1}{k}\\sum_{j=1}^{k}\\mathcal{N}(\\mu_j, I_d)$, the goal is to estimate the means $\\mu_1, \\mu_2, \\ldots, \\mu_k \\in \\mathbb{R}^d$ up to a small error. The hardness of this learning problem can be measured by the \\emph{separation} $\\Delta$ defined as the minimum distance between all pairs of means. Regev and Vijayaraghavan (2017) showed that with $\\Delta = \\Omega(\\sqrt{\\log k})$ separation, the means can be learned using $\\mathrm{poly}(k, d)$ samples, whereas super-polynomially many samples are required if $\\Delta = o(\\sqrt{\\log k})$ and $d = \\Omega(\\log k)$. This leaves open the low-dimensional regime where $d = o(\\log k)$.\n    \nIn this work, we give an algorithm that efficiently learns the means in $d = O(\\log k/\\log\\log k)$ dimensions under separation $d/\\sqrt{\\log k}$ (modulo doubly logarithmic factors). This separation is strictly smaller than $\\sqrt{\\log k}$, and is also shown to be necessary. Along with the results of Regev and Vijayaraghavan (2017), our work almost pins down the critical separation threshold at which efficient parameter learning becomes possible for spherical Gaussian mixtures. More generally, our algorithm runs in time $\\mathrm{poly}(k)\\cdot f(d, \\Delta, \\epsilon)$, and is thus fixed-parameter tractable in parameters $d$, $\\Delta$ and $\\epsilon$.\n    \nOur approach is based on estimating the Fourier transform of the mixture at carefully chosen frequencies, and both the algorithm and its analysis are simple and elementary. Our positive results can be easily extended to learning mixtures of non-Gaussian distributions, under a mild condition on the Fourier spectrum of the distribution."}}
{"id": "VxYec-90K-", "cdate": 1640995200000, "mdate": 1682357898502, "content": {"title": "A Fourier Approach to Mixture Learning", "abstract": "We revisit the problem of learning mixtures of spherical Gaussians. Given samples from mixture $\\frac{1}{k}\\sum_{j=1}^{k}\\mathcal{N}(\\mu_j, I_d)$, the goal is to estimate the means $\\mu_1, \\mu_2, \\ldots, \\mu_k \\in \\mathbb{R}^d$ up to a small error. The hardness of this learning problem can be measured by the separation $\\Delta$ defined as the minimum distance between all pairs of means. Regev and Vijayaraghavan (2017) showed that with $\\Delta = \\Omega(\\sqrt{\\log k})$ separation, the means can be learned using $\\mathrm{poly}(k, d)$ samples, whereas super-polynomially many samples are required if $\\Delta = o(\\sqrt{\\log k})$ and $d = \\Omega(\\log k)$. This leaves open the low-dimensional regime where $d = o(\\log k)$. In this work, we give an algorithm that efficiently learns the means in $d = O(\\log k/\\log\\log k)$ dimensions under separation $d/\\sqrt{\\log k}$ (modulo doubly logarithmic factors). This separation is strictly smaller than $\\sqrt{\\log k}$, and is also shown to be necessary. Along with the results of Regev and Vijayaraghavan (2017), our work almost pins down the critical separation threshold at which efficient parameter learning becomes possible for spherical Gaussian mixtures. More generally, our algorithm runs in time $\\mathrm{poly}(k)\\cdot f(d, \\Delta, \\epsilon)$, and is thus fixed-parameter tractable in parameters $d$, $\\Delta$ and $\\epsilon$. Our approach is based on estimating the Fourier transform of the mixture at carefully chosen frequencies, and both the algorithm and its analysis are simple and elementary. Our positive results can be easily extended to learning mixtures of non-Gaussian distributions, under a mild condition on the Fourier spectrum of the distribution."}}
{"id": "PSg8cjFKmab", "cdate": 1640995200000, "mdate": 1682357898666, "content": {"title": "Open Problem: Properly learning decision trees in polynomial time?", "abstract": "The authors recently gave an $n^{O(\\log\\log n)}$ time membership query algorithm for properly learning decision trees under the uniform distribution (Blanc et al., 2021). The previous fastest algorithm for this problem ran in $n^{O(\\log n)}$ time, a consequence of Ehrenfeucht and Haussler (1989)'s classic algorithm for the distribution-free setting. In this article we highlight the natural open problem of obtaining a polynomial-time algorithm, discuss possible avenues towards obtaining it, and state intermediate milestones that we believe are of independent interest."}}
{"id": "I0aWnWrkQoO", "cdate": 1640995200000, "mdate": 1682357898531, "content": {"title": "Properly Learning Decision Trees in almost Polynomial Time", "abstract": "We give an nO(log log n)-time membership query algorithm for properly and agnostically learning decision trees under the uniform distribution over { \u00b1 1}n. Even in the realizable setting, the previous fastest runtime was nO(log n), a consequence of a classic algorithm of Ehrenfeucht and Haussler.                                                                                                                                                                                           Our algorithm shares similarities with practical heuristics for learning decision trees, which we augment with additional ideas to circumvent known lower bounds against these heuristics. To analyze our algorithm, we prove a new structural result for decision trees that strengthens a theorem of O\u2019Donnell, Saks, Schramm, and Servedio. While the OSSS theorem says that every decision tree has an influential variable, we show how every decision tree can be \u201cpruned\u201d so that every variable in the resulting tree is influential."}}
{"id": "rX8rQuoTWS", "cdate": 1609459200000, "mdate": 1682357898538, "content": {"title": "Exponential Weights Algorithms for Selective Learning", "abstract": "We study the selective learning problem introduced by Qiao and Valiant (2019), in which the learner observes $n$ labeled data points one at a time. At a time of its choosing, the learner selects a ..."}}
{"id": "f9ud7oX_6-b", "cdate": 1609459200000, "mdate": 1682357898948, "content": {"title": "Decision Tree Heuristics Can Fail, Even in the Smoothed Setting", "abstract": "Greedy decision tree learning heuristics are mainstays of machine learning practice, but theoretical justification for their empirical success remains elusive. In fact, it has long been known that there are simple target functions for which they fail badly (Kearns and Mansour, STOC 1996). Recent work of Brutzkus, Daniely, and Malach (COLT 2020) considered the smoothed analysis model as a possible avenue towards resolving this disconnect. Within the smoothed setting and for targets f that are k-juntas, they showed that these heuristics successfully learn f with depth-k decision tree hypotheses. They conjectured that the same guarantee holds more generally for targets that are depth-k decision trees. We provide a counterexample to this conjecture: we construct targets that are depth-k decision trees and show that even in the smoothed setting, these heuristics build trees of depth 2^{\u03a9(k)} before achieving high accuracy. We also show that the guarantees of Brutzkus et al. cannot extend to the agnostic setting: there are targets that are very close to k-juntas, for which these heuristics build trees of depth 2^{\u03a9(k)} before achieving high accuracy."}}
{"id": "Qbl6VOsWQ5", "cdate": 1609459200000, "mdate": 1682357898663, "content": {"title": "Properly learning decision trees in almost polynomial time", "abstract": "We give an <tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$n^{O(\\log\\log n)}$</tex> -time membership query algorithm for properly and agnostically learning decision trees under the uniform distribution over <tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$\\{\\pm 1\\}^{n}$</tex> . Even in the realizable setting, the previous fastest runtime was <tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$n^{O(\\log n)}$</tex> , a consequence of a classic algorithm of Ehrenfeucht and Haussler. Our algorithm shares similarities with practical heuristics for learning decision trees, which we augment with additional ideas to circumvent known lower bounds against these heuristics. To analyze our algorithm, we prove a new structural result for decision trees that strengthens a theorem of O'Donnell, Saks, Schramm, and Servedio. While the OSSS theorem says that every decision tree has an influential variable, we show how every decision tree can be \u201cpruned\u201d so that every variable in the resulting tree is influential."}}
{"id": "H52mXlqI1Lp", "cdate": 1609459200000, "mdate": 1682357898648, "content": {"title": "Stronger calibration lower bounds via sidestepping", "abstract": "We consider an online binary prediction setting where a forecaster observes a sequence of T bits one by one. Before each bit is revealed, the forecaster predicts the probability that the bit is 1. The forecaster is called well-calibrated if for each p \u2208 [0, 1], among the np bits for which the forecaster predicts probability p, the actual number of ones, mp, is indeed equal to p \u00b7 np. The calibration error, defined as \u2211p |mp \u2212 p np|, quantifies the extent to which the forecaster deviates from being well-calibrated. It has long been known that an O(T2/3) calibration error is achievable even when the bits are chosen adversarially, and possibly based on the previous predictions. However, little is known on the lower bound side, except an \u03a9(\u221aT) bound that follows from the trivial example of independent fair coin flips. In this paper, we prove an \u03a9(T0.528) bound on the calibration error, which is the first super-\u221aT lower bound for this setting to the best of our knowledge. The technical contributions of our work include two lower bound techniques, early stopping and sidestepping, which circumvent the obstacles that have previously hindered strong calibration lower bounds. We also propose an abstraction of the prediction setting, termed the Sign-Preservation game, which may be of independent interest. This game has a much smaller state space than the full prediction setting and allows simpler analyses. The \u03a9(T0.528) lower bound follows from a general reduction theorem that translates lower bounds on the game value of Sign-Preservation into lower bounds on the calibration error."}}
{"id": "DZA7CH-8X8U", "cdate": 1577836800000, "mdate": 1682357898539, "content": {"title": "On Generalization Error Bounds of Noisy Gradient Methods for Non-Convex Learning", "abstract": "Generalization error (also known as the out-of-sample error) measures how well the hypothesis learned from training data generalizes to previously unseen data. Proving tight generalization error bounds is a central question in statistical learning theory. In this paper, we obtain generalization error bounds for learning general non-convex objectives, which has attracted significant attention in recent years. We develop a new framework, termed Bayes-Stability, for proving algorithm-dependent generalization error bounds. The new framework combines ideas from both the PAC-Bayesian theory and the notion of algorithmic stability. Applying the Bayes-Stability method, we obtain new data-dependent generalization bounds for stochastic gradient Langevin dynamics (SGLD) and several other noisy gradient methods (e.g., with momentum, mini-batch and acceleration, Entropy-SGD). Our result recovers (and is typically tighter than) a recent result in Mou et al. (2018) and improves upon the results in Pensia et al. (2018). Our experiments demonstrate that our data-dependent bounds can distinguish randomly labelled data from normal data, which provides an explanation to the intriguing phenomena observed in Zhang et al. (2017a). We also study the setting where the total loss is the sum of a bounded loss and an additiona l`2 regularization term. We obtain new generalization bounds for the continuous Langevin dynamic in this setting by developing a new Log-Sobolev inequality for the parameter distribution at any time. Our new bounds are more desirable when the noise level of the processis not very small, and do not become vacuous even when T tends to infinity."}}
