{"id": "AzQy8kwxlSg", "cdate": 1698709739735, "mdate": 1698709739735, "content": {"title": "Pointersect: Neural Rendering with Cloud-Ray Intersection", "abstract": "We propose a novel method that renders point clouds as if they are surfaces. The proposed method is differentiable and requires no scene-specific optimization. This unique capabil- ity enables, out-of-the-box, surface normal estimation, ren- dering room-scale point clouds, inverse rendering, and ray tracing with global illumination. Unlike existing work that focuses on converting point clouds to other representations\u2014 e.g., surfaces or implicit functions\u2014our key idea is to directly infer the intersection of a light ray with the underlying sur- face represented by the given point cloud. Specifically, we train a set transformer that, given a small number of local neighbor points along a light ray, provides the intersection point, the surface normal, and the material blending weights, which are used to render the outcome of this light ray. Lo- calizing the problem into small neighborhoods enables us to train a model with only 48 meshes and apply it to un- seen point clouds. Our model achieves higher estimation accuracy than state-of-the-art surface reconstruction and point-cloud rendering methods on three test sets. When ap- plied to room-scale point clouds, without any scene-specific optimization, the model achieves competitive quality with the state-of-the-art novel-view rendering methods. Moreover, we demonstrate ability to render and manipulate Lidar-scanned point clouds such as lighting control and object insertion."}}
{"id": "syKlPUGjbO_", "cdate": 1609459200000, "mdate": 1666152639165, "content": {"title": "Reference Wave Design for Wavefront Sensing", "abstract": "One of the classical results in wavefront sensing is phase-shifting point diffraction interferometry (PS-PDI), where the phase of a wavefront is measured by interfering it with a planar reference created from the incident wave itself. The limiting drawback of this approach is that the planar reference, often created by passing light through a narrow pinhole, is dim and noise sensitive. We address this limitation with a novel approach called ReWave that uses a non-planar reference that is designed to be brighter. The reference wave is designed in a specific way that would still allow for analytic phase recovery, exploiting ideas of sparse phase retrieval algorithms. ReWave requires only four image intensity measurements and is significantly more robust to noise compared to PS-PDI. We validate the robustness and applicability of our approach using a suite of simulated and real results."}}
{"id": "mfoC32PpPcw", "cdate": 1546300800000, "mdate": null, "content": {"title": "Transfer Neural Trees: Semi-Supervised Heterogeneous Domain Adaptation and Beyond", "abstract": "Heterogeneous domain adaptation (HDA) addresses the task of associating data not only across dissimilar domains but also described by different types of features. Inspired by the recent advances of neural networks and deep learning, we propose a deep leaning model of transfer neural trees (TNT), which jointly solves cross-domain feature mapping, adaptation, and classification in a unified architecture. As the prediction layer in TNT, we introduce transfer neural decision forest (transfer-NDF), which is able to learn the neurons in TNT for adaptation by stochastic pruning. In order to handle semi-supervised HDA, a unique embedding loss term is introduced to TNT for preserving prediction and structural consistency between labeled and unlabeled target-domain data. Furthermore, we show that our TNT can be extended to zero shot learning for associating image and attribute data with promising performance. Finally, experiments on different classification tasks across features, datasets, and modalities would verify the effectiveness of our TNT."}}
{"id": "_JsJXqoqPK9u", "cdate": 1546300800000, "mdate": 1663094300589, "content": {"title": "A Closer Look at Few-shot Classification", "abstract": "Few-shot classi\ufb01cation aims to learn a classi\ufb01er to recognize unseen classes during training with limited labeled examples. While signi\ufb01cant progress has been made, the growing complexity of network designs, meta-learning algorithms, and differences in implementation details make a fair comparison dif\ufb01cult. In this paper, we present 1) a consistent comparative analysis of several representative few-shot classi\ufb01cation algorithms, with results showing that deeper backbones signi\ufb01cantly reduce the gap across methods including the baseline, 2) a slightly modi\ufb01ed baseline method that surprisingly achieves competitive performance when compared with the state-of-the-art on both the mini-ImageNet and the CUB datasets, and 3) a new experimental setting for evaluating the cross-domain generalization ability for few-shot classi\ufb01cation algorithms. Our results reveal that reducing intra-class variation is an important factor when the feature backbone is shallow, but not as critical when using deeper backbones. In a realistic, cross-domain evaluation setting, we show that a baseline method with a standard \ufb01ne-tuning practice compares favorably against other state-of-the-art few-shot learning algorithms."}}
{"id": "HkxLXnAcFQ", "cdate": 1538087965960, "mdate": null, "content": {"title": "A Closer Look at Few-shot Classification", "abstract": "Few-shot classi\ufb01cation aims to learn a classi\ufb01er to recognize unseen classes during training with limited labeled examples. While signi\ufb01cant progress has been made, the growing complexity of network designs, meta-learning algorithms, and differences in implementation details make a fair comparison dif\ufb01cult. In this paper, we present 1) a consistent comparative analysis of several representative few-shot classi\ufb01cation algorithms, with results showing that deeper backbones signi\ufb01cantly reduce the gap across methods including the baseline, 2) a slightly modi\ufb01ed baseline method that surprisingly achieves competitive performance when compared with the state-of-the-art on both the mini-ImageNet and the CUB datasets, and 3) a new experimental setting for evaluating the cross-domain generalization ability for few-shot classi\ufb01cation algorithms. Our results reveal that reducing intra-class variation is an important factor when the feature backbone is shallow, but not as critical when using deeper backbones. In a realistic, cross-domain evaluation setting, we show that a baseline method with a standard \ufb01ne-tuning practice compares favorably against other state-of-the-art few-shot learning algorithms."}}
{"id": "BJ-wB-MOWS", "cdate": 1483228800000, "mdate": null, "content": {"title": "No More Discrimination: Cross City Adaptation of Road Scene Segmenters", "abstract": "Despite the recent success of deep-learning based semantic segmentation, deploying a pre-trained road scene segmenter to a city whose images are not presented in the training set would not achieve satisfactory performance due to dataset biases. Instead of collecting a large number of annotated images of each city of interest to train or refine the segmenter, we propose an unsupervised learning approach to adapt road scene segmenters across different cities. By utilizing Google Street View and its time-machine feature, we can collect unannotated images for each road scene at different times, so that the associated static-object priors can be extracted accordingly. By advancing a joint global and class-specific domain adversarial learning framework, adaptation of pre-trained segmenters to that city can be achieved without the need of any user annotation or interaction. We show that our method improves the performance of semantic segmentation in multiple cities across continents, while it performs favorably against state-of-the-art approaches requiring annotated training data."}}
{"id": "HkZNTtbdZB", "cdate": 1451606400000, "mdate": null, "content": {"title": "Transfer Neural Trees for Heterogeneous Domain Adaptation", "abstract": "Heterogeneous domain adaptation (HDA) addresses the task of associating data not only across dissimilar domains but also described by different types of features. Inspired by the recent advances of neural networks and deep learning, we propose Transfer Neural Trees (TNT) which jointly solves cross-domain feature mapping, adaptation, and classification in a NN-based architecture. As the prediction layer in TNT, we further propose Transfer Neural Decision Forest (Transfer-NDF), which effectively adapts the neurons in TNT for adaptation by stochastic pruning. Moreover, to address semi-supervised HDA, a unique embedding loss term for preserving prediction and structural consistency between target-domain data is introduced into TNT. Experiments on classification tasks across features, datasets, and modalities successfully verify the effectiveness of our TNT."}}
{"id": "ByWW8AedZB", "cdate": 1451606400000, "mdate": null, "content": {"title": "Domain-Constraint Transfer Coding for Imbalanced Unsupervised Domain Adaptation", "abstract": "Unsupervised domain adaptation (UDA) deals with the task that labeled training and unlabeled test data collected from source and target domains, respectively. In this paper, we particularly address the practical and challenging scenario of imbalanced cross-domain data. That is, we do not assume the label numbers across domains to be the same, and we also allow the data in each domain to be collected from multiple datasets/sub-domains. To solve the above task of imbalanced domain adaptation, we propose a novel algorithm of Domain-constraint Transfer Coding (DcTC). Our DcTC is able to exploit latent subdomains within and across data domains, and learns a common feature space for joint adaptation and classification purposes. Without assuming balanced cross-domain data as most existing UDA approaches do, we show that our method performs favorably against state-of-the-art methods on multiple cross-domain visual classification tasks."}}
{"id": "SJWVQbGuWS", "cdate": 1420070400000, "mdate": null, "content": {"title": "Unsupervised Domain Adaptation with Imbalanced Cross-Domain Data", "abstract": "We address a challenging unsupervised domain adaptation problem with imbalanced cross-domain data. For standard unsupervised domain adaptation, one typically obtains labeled data in the source domain and only observes unlabeled data in the target domain. However, most existing works do not consider the scenarios in which either the label numbers across domains are different, or the data in the source and/or target domains might be collected from multiple datasets. To address the aforementioned settings of imbalanced cross-domain data, we propose Closest Common Space Learning (CCSL) for associating such data with the capability of preserving label and structural information within and across domains. Experiments on multiple cross-domain visual classification tasks confirm that our method performs favorably against state-of-the-art approaches, especially when imbalanced cross-domain data are presented."}}
