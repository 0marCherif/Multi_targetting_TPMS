{"id": "QeeKCJB6jzI", "cdate": 1699349775212, "mdate": 1699349775212, "content": {"title": "Similarity- and Quality-Guided Relation Learning for Joint Detection and Tracking", "abstract": "Joint detection and tracking, which solves two fundamental vision challenges in a unified manner, is a challenging topic in computer vision. In this area, the proper use of spatial-temporal information in videos can help reduce local defects and improve the quality of feature representations. Although modeling low-level (usually pixel-wise) spatial-temporal information has been studied, instance-level spatial-temporal correlations (i.e., relations between semantic regions in which instances have occurred) have not been fully exploited. In comparison, modeling instance-level correlation is a more flexible and reasonable way to enhance feature representations. However, we have found that conventional instance-level relation learning that works for the separate tasks of detection or tracking is not effective in joint tasks in which a variety of scenarios may be presented. To try to resolve this problem, in this study, we effectively exploited instance-level spatial-temporal semantic information for joint detection and tracking via a joint relation learning pipeline with a novel relation learning mechanism called Similarity- and Quality-Guided Attention (SQGA). Specifically, we added task-specific SQGA relation modules before the corresponding task prediction heads to refine the instance feature representation using features of other reference instances in the neighboring frames; these features are aggregated on the basis of relational affinities. In particular, in SQGA, relational affinities were factorized to similarity and quality terms so that fine-grained supervision rules could be applied. Then we added task-specific attention losses for each SQGA relation module, resulting in a better feature aggregation for the corresponding task. Quantitative experiments based on several challenging multi-object tracking benchmarks showed that our approach was more effective than the baselines and provided competitive results compared with recent state-of-the-art methods."}}
{"id": "Bjf8wE55mpe", "cdate": 1683906482021, "mdate": 1683906482021, "content": {"title": "A Knowledge-Driven Memory System for Traffic Flow Prediction", "abstract": "Traffic flow prediction is critical for intelligent transportation systems. Recent studies indicate that performance improvement by designing new models is becoming marginal. Instead, we argue that the improvement can be achieved by using traffic-related facts or laws, which is termed exogenous knowledge. To this end, we propose a knowledge-driven memory system that can be seamlessly integrated into GCN-based traffic forecasting models. Specifically, the memory system includes three components: access interface, memory module, and feedback interface. The access interface based on the attention mechanism and the feedback interface based on the gate mechanism are used to guide the model to extract useful patterns and integrate these patterns into the model to enhance spatiotemporal representation respectively. The memory module is used to learn specific knowledge-based patterns, and this is achieved by constraining the learning process with unsupervised loss functions formulated inspired by exogenous knowledge. We construct three kinds of memory modules driven by different exogenous knowledge: the long-term trend memory to learn periodic patterns, the hierarchical effect memory to capture coarse-grained region patterns, and the representative pattern memory to extract representative patterns. Experiments combined with multiple existing models demonstrate the effectiveness of the memory system."}}
{"id": "lIW4pyWFkX3", "cdate": 1683882515608, "mdate": 1683882515608, "content": {"title": "Knowledge Expansion and Consolidation for Continual Traffic Prediction With Expanding Graphs", "abstract": "Accurate traffic prediction plays a vital role in intelligent transport managements and applications. However, in the vast majority of existing works, the focus is mainly on modeling spatiotemporal correlations in static traffic networks. Thus, the continuous expansion and evolution of traffic networks are ignored. In this work, we study the problem of traffic prediction with expanding road network structures under the continual learning paradigm. Considering the model prediction performance, efficiency, and data accessibility, a SpatioTemporal Knowledge Expansion and Consolidation (STKEC) framework is proposed. This framework contains an influence-based knowledge expansion strategy to help the spatiotemporal learning model integrate new spatiotemporal traffic patterns and a memory-augmented knowledge consolidation mechanism to preserve the learned spatiotemporal patterns without accessing the data in previous graphs. Extensive experiments are conducted on a large-scale dataset and verify the superior performance of STKEC in continual traffic prediction."}}
{"id": "xgKr4dfQ4CI", "cdate": 1683704061759, "mdate": null, "content": {"title": "FEND: A Future Enhanced Distribution-Aware Contrastive Learning Framework for Long-tail Trajectory Prediction", "abstract": "Predicting the future trajectories of the traffic agents is a gordian technique in autonomous driving. However, trajectory prediction suffers from data imbalance in the prevalent datasets, and the tailed data is often more complicated and safety-critical. In this paper, we focus on dealing with the long-tail phenomenon in trajectory prediction. Previous methods dealing with long-tail data did not take into account the variety of motion patterns in the tailed data. In this paper, we put forward a future enhanced contrastive learning framework to recognize tail trajectory patterns and form a feature space with separate pattern clusters. Furthermore, a distribution aware hyper predictor is brought up to better utilize the shaped feature space. Our method is a model-agnostic framework and can be plugged into many well-known baselines. Experimental results show that our framework outperforms the state-of-the-art long-tail prediction method on tailed samples by 9.5% on ADE and 8.5% on FDE, while maintaining or slightly improving the averaged performance. Our method also surpasses many longtail techniques on trajectory prediction task."}}
{"id": "T1HGLZC8W5J", "cdate": 1681881728503, "mdate": 1681881728503, "content": {"title": "Long-tailed Time Series Classification via Feature Space Rebalancing", "abstract": "Learning unbiased decision boundaries is crucial for time series classification. Real-world datasets typically exhibit long-tailed natures of class distributions, which results in an imbalanced feature space after training, i.e., decision boundaries will be easily biased towards dominant classes that dominate the feature space. However, existing methods mostly train models from artificially balanced datasets, making it still unclear how to deal with the long-tailed natures of time series data in real-world scenarios. Motivated by this question, we analyze the similarities and differences between long-tailed time series classification and general long-tailed recognition, and propose a Feature Space Rebalancing (FSR) strategy for time series classification, which works jointly from both representation and data perspectives. Specifically, from the representation perspective, we design Balanced Contrastive Learning (BCL), which avoids excessive intra-class compaction of tail classes by introducing a balanced supervised contrastive loss with hierarchical prototypes, resulting in a balanced feature space and better generalization. From the data perspective, we explore the effectiveness of traditional data augmentation on long-tailed distributions and propose an Adaptive Temporal Augmentation (ATA) to rebalance the potential feature space at the temporal level. Extensive experiments on multiple long-tailed time series datasets demonstrate its superiority, including different class distributions and imbalance ratios."}}
{"id": "RKMbC8Tslx", "cdate": 1663850324676, "mdate": null, "content": {"title": "A GENERAL SCENARIO-AGNOSTIC REINFORCEMENT LEARNING FOR TRAFFIC SIGNAL CONTROL", "abstract": "Reinforcement learning has been recently adopted to revolutionize and optimize traditional traffic signal control systems. Existing methods are either based on a single scenario or multiple independent scenarios, where each scenario has a separate simulation environment with predefined road network topology and traffic signal settings. These models implement training and testing in the same scenario, thus being strictly tied up with the specific setting and sacrificing model generalization heavily. While a few recent models could be trained by multiple scenarios, they require a huge amount of manual labor to label the intersection structure, hindering the model\u2019s generalization. In this work, we aim at a general framework that could eliminate heavy labeling and model a variety of scenarios simultaneously. To this end, we propose a GEneral Scenario-Agnostic (GESA) reinforcement learning framework for traffic signal control with: (1) A general plug-in module to map all different intersections into a unified structure, freeing us from the heavy manual labor to specify the structure of intersections; (2) A unified state and action space to keep the model input and output consistently structured; (3) A large-scale co-training with multiple scenarios, leading to a generic traffic signal control algorithm. In experiments, we demonstrate our algorithm as the first one that can be co-trained with seven different scenarios without manual annotation, and get 17.20% higher rewards than benchmarks. When dealing with a new scenario, our model can still achieve 10.36% higher rewards. The code and scenarios will be released upon acceptance."}}
{"id": "8duT3mi_5n", "cdate": 1663849937230, "mdate": null, "content": {"title": "GReTo: Remedying dynamic graph topology-task discordance via target homophily", "abstract": "Dynamic graphs are ubiquitous across disciplines where observations usually change over time. Regressions on dynamic graphs often contribute to diverse critical tasks, such as climate early-warning and traffic controlling. Existing homophily Graph Neural Networks (GNNs) adopt physical connections or feature similarity as adjacent matrix to perform node-level aggregations. However, on dynamic graphs with diverse node-wise relations, exploiting a pre-defined fixed topology for message passing inevitably leads to the aggregations of target-deviated neighbors. We designate such phenomenon as the topology-task discordance, which naturally challenges the homophily assumption. In this work, we revisit node-wise relationships and explore novel homophily measurements on dynamic graphs with both signs and distances, capturing multiple node-level spatial relations and temporal evolutions. We discover that advancing homophily aggregations to signed target-oriented message passing can effectively resolve the discordance and promote aggregation capacity. Therefore, a GReTo is proposed, which performs signed message passing in immediate neighborhood, and exploits both local environments and target awareness to realize high-order message propagation. Empirically, our solution achieves significant improvements against best baselines, notably improving 24.79% on KnowAir and 3.60% on Metr-LA. "}}
{"id": "wC98X1qpDBA", "cdate": 1663849884962, "mdate": null, "content": {"title": " Cycle-consistent Masked AutoEncoder for Unsupervised Domain Generalization", "abstract": "Self-supervised learning methods undergo undesirable performance drops when there exists a significant domain gap between training and testing scenarios. Therefore, unsupervised domain generalization (UDG) is proposed to tackle the problem, which requires the model to be trained on several different domains without supervision and generalize well on unseen test domains. Existing methods either rely on a cross-domain and semantically consistent image pair in contrastive methods or the reconstruction pair in generative methods, while the precious image pairs are not available without semantic labels. In this paper, we propose a cycle cross-domain reconstruction task for unsupervised domain generalization in the absence of paired images. The cycle cross-domain reconstruction task converts a masked image from one domain to another domain and then reconstructs the original image from the converted images. To preserve the divergent domain knowledge of decoders in the cycle reconstruction task, we propose a novel domain-contrastive loss to regularize the domain information in reconstructed images encoded with the desirable domain style. Qualitative results on extensive datasets illustrate our method improves the state-of-the-art unsupervised domain generalization methods by average $\\textbf{+5.59\\%}, \\textbf{+4.52\\%}, \\textbf{+4.22\\%}, \\textbf{+7.02\\%}$ on $1\\%, 5\\%, 10\\%, 100\\%$ PACS, and $\\textbf{+5.08\\%}, \\textbf{+6.49\\%}, \\textbf{+1.79\\%}, \\textbf{+0.53\\%}$ on $1\\%, 5\\%, 10\\%, 100\\%$ DomainNet, respectively."}}
{"id": "CTqkruS5Bb", "cdate": 1652737365135, "mdate": null, "content": {"title": "Unsupervised Object Detection Pretraining with Joint Object Priors Generation and Detector Learning", "abstract": "Unsupervised pretraining methods for object detection aim to learn object discrimination and localization ability from large amounts of images. Typically, recent works design pretext tasks that supervise the detector to predict the defined object priors. They normally leverage heuristic methods to produce object priors, \\emph{e.g.,} selective search, which separates the prior generation and detector learning and leads to sub-optimal solutions. In this work, we propose a novel object detection pretraining framework that could generate object priors and learn detectors jointly by generating accurate object priors from the model itself. Specifically, region priors are extracted by attention maps from the encoder, which highlights foregrounds. Instance priors are the selected high-quality output bounding boxes of the detection decoder. By assuming objects as instances in the foreground, we can generate object priors with both region and instance priors. Moreover, our object priors are jointly refined along with the detector optimization. With better object priors as supervision, the model could achieve better detection capability, which in turn promotes the object priors generation. Our method improves the competitive approaches by \\textbf{+1.3 AP}, \\textbf{+1.7 AP} in 1\\% and 10\\% COCO low-data regimes object detection. \n"}}
{"id": "mBko2S9vJQ1", "cdate": 1640995200000, "mdate": 1668067391561, "content": {"title": "An Empirical Study of Pseudo-Labeling for Image-based 3D Object Detection", "abstract": "Image-based 3D detection is an indispensable component of the perception system for autonomous driving. However, it still suffers from the unsatisfying performance, one of the main reasons for which is the limited training data. Unfortunately, annotating the objects in the 3D space is extremely time/resource-consuming, which makes it hard to extend the training set arbitrarily. In this work, we focus on the semi-supervised manner and explore the feasibility of a cheaper alternative, i.e. pseudo-labeling, to leverage the unlabeled data. For this purpose, we conduct extensive experiments to investigate whether the pseudo-labels can provide effective supervision for the baseline models under varying settings. The experimental results not only demonstrate the effectiveness of the pseudo-labeling mechanism for image-based 3D detection (e.g. under monocular setting, we achieve 20.23 AP for moderate level on the KITTI-3D testing set without bells and whistles, improving the baseline model by 6.03 AP), but also show several interesting and noteworthy findings (e.g. the models trained with pseudo-labels perform better than that trained with ground-truth annotations based on the same training data). We hope this work can provide insights for the image-based 3D detection community under a semi-supervised setting. The codes, pseudo-labels, and pre-trained models will be publicly available."}}
