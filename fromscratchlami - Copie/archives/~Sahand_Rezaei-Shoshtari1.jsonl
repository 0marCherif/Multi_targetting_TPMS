{"id": "Adl-fs-8OzL", "cdate": 1652737730611, "mdate": null, "content": {"title": "Continuous MDP Homomorphisms and Homomorphic Policy Gradient", "abstract": "Abstraction has been widely studied as a way to improve the efficiency and generalization of reinforcement learning algorithms. In this paper, we study abstraction in the continuous-control setting. We extend the definition of MDP homomorphisms to encompass continuous actions in continuous state spaces.  We derive a policy gradient theorem on the abstract MDP, which allows us to leverage approximate symmetries of the environment for policy optimization. Based on this theorem, we propose an actor-critic algorithm that is able to learn the policy and the MDP homomorphism map simultaneously, using the lax bisimulation metric.  We demonstrate the effectiveness of our method on benchmark tasks in the DeepMind Control Suite.  Our method's ability to utilize MDP homomorphisms for representation learning leads to improved performance when learning from pixel observations."}}
{"id": "-2DovtS4-_", "cdate": 1640995200000, "mdate": 1672715693523, "content": {"title": "Hypernetworks for Zero-shot Transfer in Reinforcement Learning", "abstract": ""}}
{"id": "rphiF6i90y", "cdate": 1609459200000, "mdate": 1672715693533, "content": {"title": "Learning Intuitive Physics with Multimodal Generative Models", "abstract": ""}}
{"id": "GTzF1qTYvYo", "cdate": 1609459200000, "mdate": 1672715774630, "content": {"title": "Seeing Through your Skin: Recognizing Objects with a Novel Visuotactile Sensor", "abstract": ""}}
{"id": "350gVOt3A2", "cdate": 1577836800000, "mdate": 1672715774637, "content": {"title": "Learning the Latent Space of Robot Dynamics for Cutting Interaction Inference", "abstract": ""}}
{"id": "Kprd5SkWkB6", "cdate": 1546300800000, "mdate": 1672715774618, "content": {"title": "Cascaded Gaussian Processes for Data-efficient Robot Dynamics Learning", "abstract": ""}}
