{"id": "3jdD8wwHYw", "cdate": 1695410786878, "mdate": 1695410786878, "content": {"title": "Supervised mixture of expert models for population health", "abstract": "We propose a machine learning driven approach to derive insights from observational healthcare data to improve public health outcomes. Our goal is to simultaneously identify patient subpopulations with differing health risks and to find those risk factors within each subpopulation. We develop two supervised mixture of experts models: a Supervised Gaussian Mixture model (SGMM) for general features and a Supervised Bernoulli Mixture model (SBMM) tailored to binary features. We demonstrate the two approaches on an analysis of high cost drivers of Medicaid expenditures for inpatient stays. We focus on the three diagnostic categories that accounted for the highest percentage of inpatient expenditures in New York State (NYS) in 2016. When compared with state-of-the-art learning methods (random forests, boosting, neural networks), our approaches provide comparable prediction performance while also extracting insightful subpopulation structure and risk factors. For problems with binary features the proposed SBMM provides as good or better performance than alternative methods while offering insightful explanations. Our results indicate the promise of such approaches for extracting population health insights from electronic health care records."}}
{"id": "kN2uXXPkCcC", "cdate": 1695410519715, "mdate": 1695410519715, "content": {"title": "Match2: Hybrid Self-Organizing Map and Deep Learning Strategies for Treatment Effect Estimation", "abstract": "Estimating treatment effects from observational data through covariate matching remains an active research area in causal inference.\nAlthough existing methods may provide accurate results on simulated datasets, knowing how to tune the parameters to accurately\nestimate treatments in practice can be a challenge, since the ground\ntruth is not known. We provide an explainable hybrid neural network and self-organizing map (SOM) approach, Match2. Using a\nsupervised learning paradigm, our method simultaneously learns\na meaningful latent representation with respect to treatment assignment and a nonlinear neighborhood preserving mapping via\nSOM in the latent space. To select the appropriate latent dimension, we propose a data-driven strategy based on the minimum\nvalidation loss for the treatment classification subproblem. Unlike\nother matching methods, the hybrid SOM-neural network can be\nused as the basis for visualizing and quantifying the quality of the\nmatches. The user can understand the quality of the matches to\nprovide confidence in the results and detect any potential problems.\nWe design a novel metric to examine the overall quality of matching\nalong with the visualization. We demonstrate strong performance\non four benchmark datasets compared to non-neural-network baselines. Integrating a SOM component may potentially benefit other\nstate-of-the-art neural network models for causal effect estimation\nby gaining interpretability while retaining prediction/estimation\naccuracy."}}
{"id": "WYD9euxpZi", "cdate": 1684356933741, "mdate": 1684356933741, "content": {"title": "Score-Based Learning of Graphical Event Models with Background Knowledge Augmentation", "abstract": "Graphical event models (GEMs) are representations of temporal point process dynamics between different event types. Many real-world applications however involve limited event stream data, making it challenging to learn GEMs from data alone. In this paper, we introduce approaches that can work together in a score-based learning paradigm, to augment data with potentially different types of background knowledge. We propose novel scores for learning an important parametric class of GEMs; in particular, we propose a Bayesian score for leveraging prior information as well as a more practical simplification that involves fewer parameters, analogous to Bayesian networks. We also introduce a framework for incorporating easily assessed qualitative background knowledge from domain experts, in the form of statements such as `event X depends on event Y' or `event Y makes event X more likely'. The proposed framework has Bayesian interpretations and can be deployed by any score-based learner. Through an extensive empirical investigation, we demonstrate the practical benefits of background knowledge augmentation while learning GEMs for applications in the low-data regime."}}
{"id": "WZyWtUmP_v", "cdate": 1684356719670, "mdate": 1684356719670, "content": {"title": "Concurrent Multi-Label Prediction in Event Streams", "abstract": "Streams of irregularly occurring events are commonly modeled as a marked temporal point process. Many real-world\ndatasets such as e-commerce transactions and electronic\nhealth records often involve events where multiple event\ntypes co-occur, e.g. multiple items purchased or multiple\ndiseases diagnosed simultaneously. In this paper, we tackle\nmulti-label prediction in such a problem setting, and propose\na novel Transformer-based Conditional Mixture of Bernoulli\nNetwork (TCMBN) that leverages neural density estimation\nto capture complex temporal dependence as well as probabilistic dependence between concurrent event types. We also\npropose potentially incorporating domain knowledge in the\nobjective by regularizing the predicted probability. To represent probabilistic dependence of concurrent event types\ngraphically, we design a two-step approach that first learns\nthe mixture of Bernoulli network and then solves a least squares semi-definite constrained program to numerically approximate the sparse precision matrix from a learned covariance matrix. This approach proves to be effective for event\nprediction while also providing an interpretable and possibly\nnon-stationary structure for insights into event co-occurrence.\nWe demonstrate the superior performance of our approach\ncompared to existing baselines on multiple synthetic and real\nbenchmarks."}}
{"id": "O6lke-lyluT", "cdate": 1667393654455, "mdate": null, "content": {"title": "Influence-Aware Attention for Multivariate Temporal Point Processes", "abstract": "Identifying the subset of events that influence events of interest from continuous time datasets is of great interest in various applications. Existing methods however often fail to produce accurate and interpretable results in a time-efficient manner. In this paper, we propose a neural model \u2013 Influence-Aware Attention for Multivariate Temporal Point Processes (IAA-MTPPs) \u2013 which leverages the powerful attention mechanism in transformers to capture temporal dynamics between event types, which is different from existing instance-to-instance attentions, using variational inference while maintaining interpretability. Given event sequences and a prior influence matrix, IAA-MTPP efficiently learns an approximate posterior by an Attention-to-Influence mechanism, and subsequently models the conditional likelihood of the sequences given a sampled influence through an Influence-to-Attention formulation. Both steps are completed efficiently inside a B-block multi-head self-attention layer, thus our end-to-end training with parallelizable transformer architecture enables faster training compared to sequential models such as RNNs. We demonstrate strong empirical performance compared to existing baselines on multiple synthetic and real benchmarks, including qualitative analysis for an application in decentralized finance."}}
{"id": "DbLtChzghG", "cdate": 1663850440006, "mdate": null, "content": {"title": "Event-former: A Self-supervised Learning Paradigm for Temporal Point Processes", "abstract": "Self-supervision is one of the hallmarks of representation learning in the increasingly popular suite of foundation models including large language models such as BERT and GPT-3, but it has not been pursued in the context of multivariate event streams, to the best of our knowledge. We introduce a new paradigm for self-supervised learning for temporal point processes using a transformer encoder. Specifically, we design a novel pre-training strategy for the encoder where we not only mask random event epochs but also insert randomly sampled \u2018void\u2019 epochs where an event does not occur; this differs from the typical discrete-time pretext tasks such as word-masking in BERT but expands the effectiveness of masking to better capture continuous-time dynamics. The pre-trained model can subsequently be fine-tuned on a potentially much smaller event dataset, similar to other foundation models. We demonstrate the effectiveness of our proposed paradigm on the next-event prediction task using synthetic datasets and 3 real applications, observing a relative performance boost of as high as up to 15% compared to state-of-the art models."}}
{"id": "x8qirBbT9xp", "cdate": 1621630140802, "mdate": null, "content": {"title": "Causal Inference for Event Pairs in Multivariate Point Processes", "abstract": "Causal inference and discovery from observational data has been extensively studied across multiple fields. However, most prior work has focused on independent and identically distributed (i.i.d.) data. In this paper, we propose a formalization for causal inference between pairs of event variables in multivariate recurrent event streams by extending Rubin's framework for the average treatment effect (ATE) and propensity scores to multivariate point processes. Analogous to a joint probability distribution representing i.i.d. data, a multivariate point process represents data involving asynchronous and irregularly spaced occurrences of various types of events over a common timeline. We theoretically justify our point process causal framework and show how to obtain unbiased estimates of the proposed measure. We conduct an experimental investigation using synthetic and real-world event datasets, where our proposed causal inference framework is shown to exhibit superior performance against a set of baseline pairwise causal association scores."}}
