{"id": "qgphLsDSSH", "cdate": 1420070400000, "mdate": 1699213885683, "content": {"title": "Cumulative Differential Gabor Features for Facial Expression Classification", "abstract": "Emotions are written all over our faces. Facial expressions of emotions can be possibly read by computer vision and machine learning system. Regarding the evidence in cognitive science, the percept..."}}
{"id": "y6W9roiSCg", "cdate": 1388534400000, "mdate": 1699213885710, "content": {"title": "Fusion of Visible Images and Thermal Image Sequences for Automated Facial Emotion Estimation", "abstract": ""}}
{"id": "ohZYaXNo5B", "cdate": 1388534400000, "mdate": 1699213885797, "content": {"title": "Extraction of Discriminative Patterns from Skeleton Sequences for Accurate Action Recognition", "abstract": "Emergence of novel techniques devices e.g., MS Kinect, enables reliable extraction of human skeletons from action videos. Taking skeleton data as inputs, we propose an approach to extract the discriminative patterns for efficient human action recognition. Each action is considered to consist of a sequence of unit actions, each of which is represented by a pattern. Given a skeleton sequence, we first automatically extract the key-frames, and then categorize them into different patterns. We further use a statistical metric to evaluate the discriminative capability of patterns, and define them as local features for action recognition. Experimental results show that the extracted local descriptors could provide very high accuracy in the action recognition, which demonstrate the efficiency of our method in extracting discriminative unit actions."}}
{"id": "h46OLWOLnm", "cdate": 1388534400000, "mdate": 1699213885696, "content": {"title": "Resource Allocation for Personalized Video Summarization", "abstract": "We propose a hybrid personalized summarization framework that combines adaptive fast-forwarding and content truncation to generate comfortable and compact video summaries. We formulate video summarization as a discrete optimization problem, where the optimal summary is determined by adopting Lagrangian relaxation and convex-hull approximation to solve a resource allocation problem. To trade-off playback speed and perceptual comfort we consider information associated to the still content of the scene, which is essential to evaluate the relevance of a video, and information associated to the scene activity, which is more relevant for visual comfort. We perform clip-level fast-forwarding by selecting the playback speeds from discrete options, which naturally include content truncation as special case with infinite playback speed. We demonstrate the proposed summarization framework in two use cases, namely summarization of broadcasted soccer videos and surveillance videos. Objective and subjective experiments are performed to demonstrate the relevance and efficiency of the proposed method."}}
{"id": "ap9rX55oj0", "cdate": 1388534400000, "mdate": 1699213885711, "content": {"title": "Automatic extraction of semantic features for real-time action recognition using depth architecture networks", "abstract": "Motion analysis automatically captures, recognizes and predicts ongoing human activities, which can be widely applied to various useful domains such as security surveillance in public spaces, including shopping centers and airports. With the development of the technologies like 3D specialized markers, we could capture the moving signals from marker joints and create a huge set of 3D motion capture (MOCAP) data. We propose in this work a method to automatically extract the action features which can be used for action recognition. We create an depth architecture model by combining multilevel networks which can focus on the recognizing objects in detail. These networks can learn the extracted features and perform action recognition. This propose model not only can extract the semantic action features from 3D MOCAP data, but also can apply for the real-time action recognition."}}
{"id": "Ddv3sygTFW-", "cdate": 1388534400000, "mdate": 1699213885686, "content": {"title": "Human Emotion Estimation Using Wavelet Transform and t-ROIs for Fusion of Visible Images and Thermal Image Sequences", "abstract": "Most studies in human emotion estimation focus on visible image-based analysis which is sensitive to illumination changes. Under uncontrolled operating conditions, estimation accuracy degrades significantly. In this paper, we integrate both visible images and thermal image sequences. First, to address limitations of thermal infrared (IR) images, such as being opaque to eyeglasses, we apply thermal Regions of Interest (t-ROIs) to sequences of thermal images. Then, wavelet transform is applied to visible images. Second, features are selected and fused from visible features and thermal features. Third, fusion decision using Principal Component Analysis (PCA), Eigen-space Method based on class-features (EMC), PCA-EMC is applied. Experiments on the Kotani Thermal Facial Emotion (KTFE) database show the effectiveness of proposed methods."}}
{"id": "5-uEMorI2ai", "cdate": 1388534400000, "mdate": 1699213885697, "content": {"title": "Independent Subspace of Dynamic Gabor Features for Facial Expression Classification", "abstract": "In this paper, the Gabor filter is studied and further expanded for temporal facial expression analysis. Originally, the Gabor feature describes both spatial and frequency characteristics of 2D images. The prominent of the theorem has been validated in research communities for a decade due to its similarity to the human perception system. The performance of the filter in the existing research gives convincing results on recognizing the human emotions by using a still image. However, the previous research neglects the fact that the understanding of human facial expression of emotions is associated by the dynamic relation, which the motion of expression must be witnessed. Therefore, we propose the novel temporal features by deriving the dynamic of Gabor features in the temporal template representations. Then, we decompose the features onto discriminative subspace for estimating the emotion class."}}
{"id": "uVleOsSyjN", "cdate": 1356998400000, "mdate": 1699213885686, "content": {"title": "Detecting group interactions by online association of trajectory data", "abstract": "We propose a method for detecting group interactions for groups of varying number of objects. We model each object as a moving agent with a direction-aware interest map and group interactions as mutual interests between objects. After grouping objects into unit interactions individually in each frame, we solve the temporal association problem by tracking group interaction over consecutive frames. Optimal grouping is obtained by finding the maximum weight spanning tree of a directed graph formed by objects and their potential interactions. Experimental results show that our method obtained around 80% recalling rates on two publicly available datasets."}}
{"id": "tGM4-gh2Ph-", "cdate": 1356998400000, "mdate": 1699213885700, "content": {"title": "Personalized Summarization of Broadcasted Soccer Videos with Adaptive Fast-Forwarding", "abstract": "We propose a hybrid personalized summarization framework that combines adaptive fast-forwarding and content truncation to generate comfortable and compact video summaries. We formulate video summarization as a discrete optimization problem, where the optimal summary is determined by adopting Lagrangian relaxation and convex-hull approximation to solve a resource allocation problem. Subjective experiments are performed to demonstrate the relevance and efficiency of the proposed method."}}
{"id": "dozuabKOW8t", "cdate": 1356998400000, "mdate": 1699213885744, "content": {"title": "An Apriori-like algorithm for automatic extraction of the common action characteristics", "abstract": "With the development of the technology like 3D specialized markers, we could capture the moving signals from marker joints and create a huge set of 3D action MoCap data. The more we understand the human action, the better we could apply it to applications like security, analysis of sports, game etc. In order to find the semantically representative features of human actions, we extract the sets of action characteristics which appear frequently in the database. We then propose an Apriori-like algorithm to automatically extract the common sets shared by different action classes. The extracted representative action characteristics are defined in the semantic level, so that it better describes the intrinsic differences between various actions. In our experiments, we show that the knowledge extracted by this method achieves high accuracy of over 80% in recognizing actions on both training and testing data."}}
