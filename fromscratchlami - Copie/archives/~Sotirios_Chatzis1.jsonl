{"id": "zESX_pZdFSt", "cdate": 1640995200000, "mdate": 1681649673443, "content": {"title": "Competing Mutual Information Constraints with Stochastic Competition-Based Activations for Learning Diversified Representations", "abstract": ""}}
{"id": "nCaqdFg5Kc", "cdate": 1640995200000, "mdate": 1681649673324, "content": {"title": "Competing Mutual Information Constraints with Stochastic Competition-based Activations for Learning Diversified Representations", "abstract": ""}}
{"id": "docbUI1G0S", "cdate": 1640995200000, "mdate": 1681649673319, "content": {"title": "Stochastic Deep Networks with Linear Competing Units for Model-Agnostic Meta-Learning", "abstract": ""}}
{"id": "IJif3CFVvZ", "cdate": 1640995200000, "mdate": 1681649673325, "content": {"title": "Rethinking Bayesian Learning for Data Analysis: The Art of Prior and Inference in Sparsity-Aware Modeling", "abstract": ""}}
{"id": "Htg09wejDg", "cdate": 1640995200000, "mdate": 1681649673323, "content": {"title": "Key factors driving the adoption of behavioral biometrics and continuous authentication technology: an empirical research", "abstract": ""}}
{"id": "Ew9DuD6C4N", "cdate": 1640995200000, "mdate": 1681649673415, "content": {"title": "Rethinking Bayesian Learning for Data Analysis: The art of prior and inference in sparsity-aware modeling", "abstract": ""}}
{"id": "7WFrxATmWZ", "cdate": 1640995200000, "mdate": 1681649673320, "content": {"title": "BioGames: a new paradigm and a behavioral biometrics collection tool for research purposes", "abstract": ""}}
{"id": "2BGIBl115fV", "cdate": 1640995200000, "mdate": 1681649673434, "content": {"title": "Stochastic Deep Networks with Linear Competing Units for Model-Agnostic Meta-Learning", "abstract": ""}}
{"id": "-arOgCYcCNe", "cdate": 1640995200000, "mdate": 1681649673442, "content": {"title": "A Deep Learning Approach for Dynamic Balance Sheet Stress Testing", "abstract": ""}}
{"id": "FFGDKzLasUa", "cdate": 1632875424840, "mdate": null, "content": {"title": "Stochastic Deep Networks with Linear Competing Units for Model-Agnostic Meta-Learning", "abstract": "This work addresses meta-learning (ML) by considering deep networks with stochastic local winner-takes-all (LWTA) activations. This type of network units result in sparse representations from each model layer, as the units are organized into blocks where only one unit generates a non-zero output. The main operating principle of the introduced units lies on stochastic arguments, as the network performs posterior sampling over competing units to select the winner. Therefore, the proposed networks are explicitly designed to extract input data representations of sparse stochastic nature, as opposed to the currently standard deterministic representation paradigm. We posit that these modeling arguments, inspired from Bayesian statistics, allow for more robust modeling when uncertainty is high due to the limited availability of task-related training data; this is exactly the case with ML, which is the focus of this work. At training time, we rely on the reparameterization trick for Discrete distributions to perform reliable training via Monte-Carlo sampling. At inference time, we rely on Bayesian Model Averaging, which effectively averages over a number of sampled representations. As we experimentally show, our approach produces state-of-the-art predictive accuracy on standard few-shot image classification benchmarks; this is achieved without compromising computational efficiency."}}
