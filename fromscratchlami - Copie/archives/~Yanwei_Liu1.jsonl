{"id": "65uYnXz1d4", "cdate": 1698625456950, "mdate": 1698625456950, "content": {"title": "Viewport-oriented Panoramic Image Inpainting", "abstract": "Panoramic images are usually viewed through Head Mounted\nDisplays (HMDs), which renders only a narrow field of view\nfrom the raw panoramic image. This distinctive viewing feature has largely been ignored when inpainting panoramic images. To address this issue, we propose a viewport-oriented\ngenerative adversarial panoramic image inpainting network\nin this paper. For capturing the distorted features accurately\nin the generating process of equirectangular projection (ERP)\npanoramic image, a latitude-adaptive feature fusion module\nis devised to aggregate the latitude-level features in ERP image and less-distorted patch-level viewport-domain features.\nFurthermore, a novel cross-domain discriminator is proposed\nto force the inpainting network to generate more plausible\nresults in viewports. Extensive experiments show that our\nmodel achieves better performance compared to the baseline\nmethods, especially in the viewport images"}}
{"id": "3GHM60j6vPq", "cdate": 1698625406023, "mdate": 1698625406023, "content": {"title": "SP ATTACK: SINGLE-PERSPECTIVE ATTACK FOR GENERATING ADVERSARIAL OMNIDIRECTIONAL IMAGES", "abstract": "The safety of Deep Neural Networks (DNNs) processing omnidirectional images (ODIs) is an under-researched topic. In\nthis paper, we propose a novel sparse attack, named SinglePerspective (SP) Attack, towards fooling these models by\nperturbing only one perspective image (PI) rendered from\nthe target ODI. The attack is launched from the perspective\ndomain, and finally the perturbation is transferred to the original ODI. To this end, we propose an effective PI position\nsearching algorithm based on Bayesian Optimization, and\nthen corrupt the PI centered on the desirable position with\nunconstrained/constrained perturbations. Extensive experiments on synthetic and real-world omnidirectional datasets\ndemonstrate that SP Attack can overcome the projection\ndeformation of ODIs, and mislead the neural networks by\nlimiting the perturbations in a single patch on the target ODI"}}
{"id": "CBrhs-G5h9O", "cdate": 1698625322222, "mdate": 1698625322222, "content": {"title": "360-degree VR Video Watermarking based on Spherical Wavelet Transform", "abstract": "Similar to conventional video, the increasingly popular 360\u25e6\nvirtual reality (VR) video requires\ncopyright protection mechanisms. The classic approach for copyright protection is the introduction\nof a digital watermark into the video sequence. Due to the nature of spherical panorama, traditional\nwatermarking schemes that are dedicated to planar media cannot work efficiently for 360\u25e6 VR video.\nIn this paper, we propose a spherical wavelet watermarking scheme to accommodate 360\u25e6 VR video.\nWith our scheme, the watermark is first embedded into the spherical wavelet transform domain of\nthe 360\u25e6 VR video. The spherical geometry of the 360\u25e6 VR video is used as the host space for the\nwatermark so that the proposed watermarking scheme is compatible with the multiple projection\nformats of 360\u25e6 VR video. Second, the just noticeable difference model, suitable for head-mounted\ndisplays (HMDs), is used to control the imperceptibility of the watermark on the viewport. Third,\nbesides detecting the watermark from the spherical projection, the proposed watermarking scheme\nalso supports detecting watermarks robustly from the viewport projection. The watermark in the\nspherical domain can protect not only the 360\u25e6 VR video but also its corresponding viewports.\nThe experimental results show that the embedded watermarks are reliably extracted both from the\nspherical and the viewport projections of the 360\u25e6 VR video, and the robustness of the proposed\nscheme to various copyright attacks is significantly better than that of the competing planar-domain\napproaches when detecting the watermark from viewport projection"}}
{"id": "stm3JDx4xq", "cdate": 1698625168858, "mdate": 1698625168858, "content": {"title": "Perspectively Equivariant Keypoint Learning for Omnidirectional Images", "abstract": "obust keypoint detection on omnidirectional images against large perspective variations, is a key problem\nin many computer vision tasks. In this paper, we propose a\nperspectively equivariant keypoint learning framework named\nOmniKL for addressing this problem. Specifically, the framework\nis composed of a perspective module and a spherical module, each\none including a keypoint detector specific to the type of the input\nimage and a shared descriptor providing uniform description\nfor omnidirectional and perspective images. In these detectors,\nwe propose a differentiable candidate position sorting operation\nfor localizing keypoints, which directly sorts the scores of the\ncandidate positions in a differentiable manner and returns the\nglobally top-K keypoints on the image. This approach does not\nbreak the differentiability of the two modules, thus they are endto-end trainable. Moreover, we design a novel training strategy\ncombining the self-supervised and co-supervised methods to train\nthe framework without any labeled data. Extensive experiments\non synthetic and real-world 360\u25e6\nimage datasets demonstrate the\neffectiveness of OmniKL in detecting perspectively equivariant\nkeypoints on omnidirectional images. Our source code are available online at https://github.com/vandeppce/sphkpt."}}
{"id": "4HcnI3rIgO", "cdate": 1668558407145, "mdate": 1668558407145, "content": {"title": "360-Attack: Distortion-Aware Perturbations from Perspective-Views", "abstract": "The application of deep neural networks (DNNs) on 360-degree images has achieved remarkable progress in the recent years. However, DNNs have been demonstrated to be vulnerable to well-crafted adversarial examples, which may trigger severe safety problems in the real-world applications based on 360-degree images. In this paper, we propose an adversarial attack targeting spherical images,\ncalled 360-attactk, that transfers adversarial perturbations from perspective-view (PV) images to a final adversarial\nspherical image. Given a target spherical image, we first represent it with a set of planar PV images, and then perform 2D attacks on them to obtain adversarial PV images. Considering the issue of the projective distortion between spherical and PV images, we propose a distortion-aware attack to reduce the negative impact of distortion on attack. Moreover, to reconstruct the final adversarial spherical image with high aggressiveness, we calculate the spherical saliency map with a novel spherical spectrum method and next propose a saliency-aware fusion strategy that merges multiple inverse perspective projections for the same position on the spherical image. Extensive experimental results show that 360-attack is effective for disturbing spherical images in the black-box setting. Our attack also proves the presence of adversarial transferability from Z2 to SO(3) groups."}}
