{"id": "twk5x30Axg", "cdate": 1672531200000, "mdate": 1681918195167, "content": {"title": "Enhancing Vulnerability Prioritization: Data-Driven Exploit Predictions with Community-Driven Insights", "abstract": "The number of disclosed vulnerabilities has been steadily increasing over the years. At the same time, organizations face significant challenges patching their systems, leading to a need to prioritize vulnerability remediation in order to reduce the risk of attacks. Unfortunately, existing vulnerability scoring systems are either vendor-specific, proprietary, or are only commercially available. Moreover, these and other prioritization strategies based on vulnerability severity are poor predictors of actual vulnerability exploitation because they do not incorporate new information that might impact the likelihood of exploitation. In this paper we present the efforts behind building a Special Interest Group (SIG) that seeks to develop a completely data-driven exploit scoring system that produces scores for all known vulnerabilities, that is freely available, and which adapts to new information. The Exploit Prediction Scoring System (EPSS) SIG consists of more than 170 experts from around the world and across all industries, providing crowd-sourced expertise and feedback. Based on these collective insights, we describe the design decisions and trade-offs that lead to the development of the next version of EPSS. This new machine learning model provides an 82\\% performance improvement over past models in distinguishing vulnerabilities that are exploited in the wild and thus may be prioritized for remediation."}}
{"id": "ch9KKkmJY2e", "cdate": 1514764800000, "mdate": 1623854347355, "content": {"title": "Characterizing the Internet Host Population Using Deep Learning: A Universal and Lightweight Numerical Embedding", "abstract": "In this paper, we present a framework to characterize Internet hosts using deep learning, using Internet scan data to produce numerical and lightweight (low-dimensional) representations of hosts. To do so we first develop a novel method for extracting binary tags from structured texts, the format of the scan data. We then use a variational autoencoder, an unsupervised neural network model, to construct low-dimensional embeddings of our high-dimensional binary representations. We show that these lightweight embeddings retain most of the information in our binary representations, while drastically reducing memory and computational requirements for large-scale analysis. These embeddings are also universal, in that the process used to generate them is unsupervised and does not rely on specific applications. This universality makes the embeddings broadly applicable to a variety of learning tasks whereby they can be used as input features. We present two such examples, (1) detecting and predicting malicious hosts, and (2) unmasking hidden host attributes, and compare the trained models in their performance, speed, robustness, and interpretability. We show that our embeddings can achieve high accuracy (>95%) for these learning tasks, while being fast enough to enable host-level analysis at scale."}}
{"id": "XuG-SKhIL74", "cdate": 1514764800000, "mdate": 1623854347513, "content": {"title": "From Patching Delays to Infection Symptoms: Using Risk Profiles for an Early Discovery of Vulnerabilities Exploited in the Wild", "abstract": ""}}
{"id": "jQvbl2GDJ5", "cdate": 1483228800000, "mdate": 1623854347503, "content": {"title": "Patch Me If You Can: A Study on the Effects of Individual User Behavior on the End-Host Vulnerability State", "abstract": "In this paper we study the implications of end-user behavior in applying software updates and patches on information-security vulnerabilities. To this end we tap into a large data set of measurements conducted on more than 400,000 Windows machines over four client-side applications, and separate out the impact of user and vendor behavior on the vulnerability states of hosts. Our modeling of users and the empirical evaluation of this model over vulnerability states of hosts reveal a peculiar relationship between vendors and end-users: the users\u2019 promptness in applying software patches, and vendors\u2019 policies in facilitating the installation of updates, while both contributing to the hosts\u2019 security posture, are overshadowed by other characteristics such as the frequency of vulnerability disclosures and the vendors\u2019 swiftness in deploying patches."}}
{"id": "Ie8Q59RPzd0", "cdate": 1451606400000, "mdate": 1623854347375, "content": {"title": "Risky business: Fine-grained data breach prediction using business profiles", "abstract": "This article aims to understand if, and to what extent, business details about an organization can help to assess a company\u2019s risk in experiencing data breach incidents, as well its distribution of risk over multiple incident types, in order to provide guidelines to effectively protect, detect, and recover from different forms of security incidents. Existing work on prediction of data breach mainly focuses on network incidents, and studies that analyze the distribution of risk across different incident categories, most notably Verizon\u2019s latest Data Breach Investigations Report, provide recommendations based solely on business sector information. In this article, we leverage a broader set of publicly available business details to provide a more fine-grained analysis on incidents involving any form of data breach and data loss. Specifically, we use reports collected in the VERIS Community Database (VCDB), as well as data from Alexa Web Information Service (AWIS), the Open Directory Project (ODP), and Neustar Inc., to train and test a sequence of classifiers/predictors. Our results show that our feature set can distinguish between victims of data breaches, and nonvictims, with a 90% true positive rate, and 11% false positive rate, making them an effective tool in evaluating an entity\u2019s cyber-risk. Furthermore, we show that compared to using business sector information alone, our method can derive a more accurate risk distribution for specific incident types, and allow organizations to focus on a sparser set of incidents, thus achieving the same level of protection by spending less resources on security through more judicious prioritization."}}
{"id": "ryWtqb5HSW", "cdate": 1420070400000, "mdate": 1623854347364, "content": {"title": "Cloudy with a Chance of Breach: Forecasting Cyber Security Incidents", "abstract": ""}}
{"id": "ezI0LW4kaf8", "cdate": 1420070400000, "mdate": 1623854347348, "content": {"title": "Predicting Cyber Security Incidents Using Feature-Based Characterization of Network-Level Malicious Activities", "abstract": "This study offers a first step toward understanding the extent to which we may be able to predict cyber security incidents (which can be of one of many types) by applying machine learning techniques and using externally observed malicious activities associated with network entities, including spamming, phishing, and scanning, each of which may or may not have direct bearing on a specific attack mechanism or incident type. Our hypothesis is that when viewed collectively, malicious activities originating from a network are indicative of the general cleanness of a network and how well it is run, and that furthermore, collectively they exhibit fairly stable and thus predictive behavior over time. To test this hypothesis, we utilize two datasets in this study: (1) a collection of commonly used IP address-based/host reputation blacklists (RBLs) collected over more than a year, and (2) a set of security incident reports collected over roughly the same period. Specifically, we first aggregate the RBL data at a prefix level and then introduce a set of features that capture the dynamics of this aggregated temporal process. A comparison between the distribution of these feature values taken from the incident dataset and from the general population of prefixes shows distinct differences, suggesting their value in distinguishing between the two while also highlighting the importance of capturing dynamic behavior (second order statistics) in the malicious activities. These features are then used to train a support vector machine (SVM) for prediction. Our preliminary results show that we can achieve reasonably good prediction performance over a forecasting window of a few months."}}
{"id": "boNQyI_RGkf", "cdate": 1420070400000, "mdate": 1623854347490, "content": {"title": "Prioritizing Security Spending: A Quantitative Analysis of Risk Distributions for Different Business Profiles", "abstract": ""}}
{"id": "d_2JtInc6aL", "cdate": 1388534400000, "mdate": 1623854347359, "content": {"title": "Can Less Be More? A Game-Theoretic Analysis of Filtering vs. Investment", "abstract": "In this paper we consider a single resource-constrained strategic adversary, who can arbitrarily distribute his resources over a set of nodes controlled by a single defender. The defender can (1) instruct nodes to filter incoming traffic from another node to reduce the chances of being compromised due to malicious traffic originating from that node, or (2) choose an amount of investment in security for each node in order to directly reduce loss, regardless of the origin of malicious traffic; leading to a filtering and an investment game, respectively. We shall derive and compare the Nash equilibria of both games for different resource constraints on the attacker. Our analysis and simulation results show that from either the attacker or the defender\u2019s point of view, none of the games perform uniformly better than the other, as utilities drawn at the equilibria are dependent on the costs associated with each action and the amount of resources available to the attacker. More interestingly, in games with highly resourceful attackers, not only the defender sustains higher loss, but the adversary is also at a disadvantage compared to less resourceful attackers."}}
