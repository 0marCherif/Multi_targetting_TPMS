{"id": "6Li1Z7VQHx", "cdate": 1672531200000, "mdate": 1699629455519, "content": {"title": "Making Vision Transformers Truly Shift-Equivariant", "abstract": "For computer vision tasks, Vision Transformers (ViTs) have become one of the go-to deep net architectures. Despite being inspired by Convolutional Neural Networks (CNNs), ViTs remain sensitive to small shifts in the input image. To address this, we introduce novel designs for each of the modules in ViTs, such as tokenization, self-attention, patch merging, and positional encoding. With our proposed modules, we achieve truly shift-equivariant ViTs on four well-established models, namely, Swin, SwinV2, MViTv2, and CvT, both in theory and practice. Empirically, we tested these models on image classification and semantic segmentation, achieving competitive performance across three different datasets while maintaining 100% shift consistency."}}
{"id": "dT0eNsO2YLu", "cdate": 1652737423131, "mdate": null, "content": {"title": "Learnable Polyphase Sampling for Shift Invariant and Equivariant Convolutional Networks", "abstract": "We propose learnable polyphase sampling (LPS), a pair of learnable down/upsampling layers that enable truly shift-invariant and equivariant convolutional networks. LPS can be trained end-to-end from data and generalizes existing handcrafted downsampling layers. It is widely applicable as it can be integrated into any convolutional network by replacing down/upsampling layers. We evaluate LPS on image classification and semantic segmentation. Experiments show that LPS is on-par with or outperforms existing methods in both performance and shift consistency. For the first time, we achieve true shift-equivariance on semantic segmentation (PASCAL VOC), i.e., 100% shift consistency, outperforming baselines by an absolute 3.3%."}}
{"id": "sDlkwXJT-cR", "cdate": 1640995200000, "mdate": 1699629455519, "content": {"title": "Learnable Polyphase Sampling for Shift Invariant and Equivariant Convolutional Networks", "abstract": "We propose learnable polyphase sampling (LPS), a pair of learnable down/upsampling layers that enable truly shift-invariant and equivariant convolutional networks. LPS can be trained end-to-end from data and generalizes existing handcrafted downsampling layers. It is widely applicable as it can be integrated into any convolutional network by replacing down/upsampling layers. We evaluate LPS on image classification and semantic segmentation. Experiments show that LPS is on-par with or outperforms existing methods in both performance and shift consistency. For the first time, we achieve true shift-equivariance on semantic segmentation (PASCAL VOC), i.e., 100% shift consistency, outperforming baselines by an absolute 3.3%."}}
{"id": "SWsXfihAsns", "cdate": 1640995200000, "mdate": 1668625912817, "content": {"title": "Physics-Consistent Data-Driven Waveform Inversion With Adaptive Data Augmentation", "abstract": "Seismic full-waveform inversion (FWI) is a nonlinear computational imaging technique that can provide detailed estimates of subsurface geophysical properties. Solving the FWI problem can be challenging due to its ill-posedness and high computational cost. In this work, we develop a new hybrid computational approach to solve FWI that combines physics-based models with data-driven methodologies. In particular, we develop a data augmentation strategy that can not only improve the representativity of the training set but also incorporate important governing physics into the training process and, therefore, improve the inversion accuracy. To validate the performance, we apply our method to synthetic elastic seismic waveform data generated from a subsurface geologic model built on a carbon sequestration site at Kimberlina, California. We compare our physics-consistent data-driven inversion method to both purely physics-based and purely data-driven approaches and observe that our method yields higher accuracy and greater generalization ability."}}
{"id": "9xW1x2911_", "cdate": 1640995200000, "mdate": 1668625774263, "content": {"title": "Learnable Polyphase Sampling for Shift Invariant and Equivariant Convolutional Networks", "abstract": "We propose learnable polyphase sampling (LPS), a pair of learnable down/upsampling layers that enable truly shift-invariant and equivariant convolutional networks. LPS can be trained end-to-end from data and generalizes existing handcrafted downsampling layers. It is widely applicable as it can be integrated into any convolutional network by replacing down/upsampling layers. We evaluate LPS on image classification and semantic segmentation. Experiments show that LPS is on-par with or outperforms existing methods in both performance and shift consistency. For the first time, we achieve true shift-equivariance on semantic segmentation (PASCAL VOC), i.e., 100% shift consistency, outperforming baselines by an absolute 3.3%."}}
{"id": "-KuAWwbWpB1", "cdate": 1640995200000, "mdate": 1699629455535, "content": {"title": "Inverting Adversarially Robust Networks for Image Synthesis", "abstract": "Despite unconditional feature inversion being the foundation of many image synthesis applications, training an inverter demands a high computational budget, large decoding capacity and imposing conditions such as autoregressive priors. To address these limitations, we propose the use of adversarially robust representations as a perceptual primitive for feature inversion. We train an adversarially robust encoder to extract disentangled and perceptually-aligned image representations, making them easily invertible. By training a simple generator with the mirror architecture of the encoder, we achieve superior reconstruction quality and generalization over standard models. Based on this, we propose an adversarially robust autoencoder and demonstrate its improved performance on style transfer, image denoising and anomaly detection tasks. Compared to recent ImageNet feature inversion methods, our model attains improved performance with significantly less complexity. Code available at https://github.com/renanrojasg/adv_robust_autoencoder ."}}
{"id": "_RQdkAKkG6", "cdate": 1609459200000, "mdate": 1668625774257, "content": {"title": "Inverting Adversarially Robust Networks for Image Synthesis", "abstract": "Despite unconditional feature inversion being the foundation of many image synthesis applications, training an inverter demands a high computational budget, large decoding capacity and imposing conditions such as autoregressive priors. To address these limitations, we propose the use of adversarially robust representations as a perceptual primitive for feature inversion. We train an adversarially robust encoder to extract disentangled and perceptually-aligned image representations, making them easily invertible. By training a simple generator with the mirror architecture of the encoder, we achieve superior reconstruction quality and generalization over standard models. Based on this, we propose an adversarially robust autoencoder and demonstrate its improved performance on style transfer, image denoising and anomaly detection tasks. Compared to recent ImageNet feature inversion methods, our model attains improved performance with significantly less complexity."}}
{"id": "ZInHtjx9cKP", "cdate": 1577836800000, "mdate": 1668625912826, "content": {"title": "Physics-Consistent Data-driven Waveform Inversion with Adaptive Data Augmentation", "abstract": "Seismic full-waveform inversion (FWI) is a nonlinear computational imaging technique that can provide detailed estimates of subsurface geophysical properties. Solving the FWI problem can be challenging due to its ill-posedness and high computational cost. In this work, we develop a new hybrid computational approach to solve FWI that combines physics-based models with data-driven methodologies. In particular, we develop a data augmentation strategy that can not only improve the representativity of the training set but also incorporate important governing physics into the training process and therefore improve the inversion accuracy. To validate the performance, we apply our method to synthetic elastic seismic waveform data generated from a subsurface geologic model built on a carbon sequestration site at Kimberlina, California. We compare our physics-consistent data-driven inversion method to both purely physics-based and purely data-driven approaches and observe that our method yields higher accuracy and greater generalization ability."}}
{"id": "TQMKOmA42B", "cdate": 1483228800000, "mdate": 1668625866341, "content": {"title": "Learning optimal parameters for binary sensing image reconstruction algorithms", "abstract": ""}}
{"id": "bxo6lhkxezU", "cdate": 1325376000000, "mdate": 1668625912826, "content": {"title": "MIxed gaussian-impulse noise image restoration via total variation", "abstract": ""}}
