{"id": "UChRu22RFs", "cdate": 1696118400000, "mdate": 1699142550112, "content": {"title": "Convergence Analysis of Leapfrog for Geodesics", "abstract": "Geodesics are of fundamental interest in mathematics, physics, computer science, and many other subjects. The so-called leapfrog algorithm was proposed in [L. Noakes, J. Aust. Math. Soc., 65 (1998), pp. 37\u201350] (but not named there as such) to find geodesics joining two given points and on a path-connected complete Riemannian manifold. The basic idea is to choose some junctions between and that can be joined by geodesics locally and then adjust these junctions. It was proved that the sequence of piecewise geodesics generated by this algorithm converges to a geodesic joining and . The present paper investigates leapfrog\u2019s convergence rate of ith junction depending on the manifold M. A relationship is found with the maximal root of a polynomial of degree , where n is the number of geodesic segments. That is, the minimal is upper bounded by , where is a sufficiently small positive constant depending on the curvature of the manifold M. Moreover, we show that increases as n increases. These results are illustrated by implementing leapfrog on two Riemannian manifolds: the unit 2-sphere and the manifold of all symmetric positive definite matrices."}}
{"id": "rrZToK2PtE0", "cdate": 1677628800000, "mdate": 1695951243300, "content": {"title": "Unsupervised Learning for Maximum Consensus Robust Fitting: A Reinforcement Learning Approach", "abstract": "Robust model fitting is a core algorithm in several computer vision applications. Despite being studied for decades, solving this problem efficiently for datasets that are heavily contaminated by outliers is still challenging: due to the underlying computational complexity. A recent focus has been on <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">learning-based</i> algorithms. However, most of these approaches are supervised (which require a large amount of labelled training data). In this paper, we introduce a novel unsupervised learning framework: that learns to directly (without labelled data) solve robust model fitting. Moreover, <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">unlike other learning-based methods</i> , our work is agnostic to the underlying input features, and can be easily generalized to a wide variety of LP-type problems with quasi-convex residuals. We empirically show that our method outperforms existing (un)supervised learning approaches, and also achieves competitive results compared to traditional (non-learning-based) methods. Our approach is designed to try to maximise consensus (MaxCon), similar to the popular RANSAC. The basis of our approach, is to adopt a Reinforcement Learning framework. This requires designing appropriate reward functions, and state encodings. We provide a family of reward functions, tunable by choice of a parameter. We also investigate the application of different basic and enhanced Q-learning components."}}
{"id": "mU60NygNloj", "cdate": 1672531200000, "mdate": 1668771036592, "content": {"title": "Finding extremals of Lagrangian actions", "abstract": ""}}
{"id": "MjaROj4BOwk", "cdate": 1652737628674, "mdate": null, "content": {"title": "Sparse Hypergraph Community Detection Thresholds in Stochastic Block Model", "abstract": "Community detection in random graphs or hypergraphs is an interesting fundamental problem in statistics, machine learning and computer vision. When the hypergraphs are generated by a {\\em stochastic block model}, the existence of a sharp threshold on the model parameters for community detection was conjectured by Angelini et al. 2015. In this paper, we confirm the positive part of the conjecture, the possibility of non-trivial reconstruction above the threshold, for the case of two blocks. We do so by comparing the hypergraph stochastic block model with its Erd{\\\"o}s-R{\\'e}nyi counterpart. We also obtain estimates for the parameters of the hypergraph stochastic block model. The methods developed in this paper are generalised from the study of sparse random graphs by Mossel et al. 2015 and are motivated by the work of Yuan et al. 2022. Furthermore, we present some discussion on the negative part of the conjecture, i.e., non-reconstruction of community structures."}}
{"id": "s9CN1PsFuF", "cdate": 1640995200000, "mdate": 1668771036639, "content": {"title": "Maximum Consensus by Weighted Influences of Monotone Boolean Functions", "abstract": "Maximisation of Consensus (MaxCon) is one of the most widely used robust criteria in computer vision. Tennakoon et al. (CVPR2021), made a connection between MaxCon and estimation of influences of a Monotone Boolean function. In such, there are two distributions involved: the distribution defining the influence measure; and the distribution used for sampling to estimate the influence measure. This paper studies the concept of weighted influences for solving MaxCon. In particular, we study the Bernoulli measures. Theoretically, we prove the weighted influences, under this measure, of points belonging to larger structures are smaller than those of points belonging to smaller structures in general. We also consider another \u201cnatural\u201d family of weighting strategies: sampling with uniform measure concentrated on a particular (Hamming) level of the cube. One can choose to have matching distributions: the same for defining the measure as for implementing the sampling. This has the advantage that the sampler is an unbiased estimator of the measure. Based on weighted sampling, we modify the algorithm of Tennakoon et al., and test on both synthetic and real datasets. We show some modest gains of Bernoulli sampling, and we illuminate some of the interactions between structure in data and weighted measures and weighted sampling."}}
{"id": "ajFEeJ4DFy", "cdate": 1640995200000, "mdate": 1668771036639, "content": {"title": "Finding geodesics joining given points", "abstract": "Finding a geodesic joining two given points in a complete path-connected Riemannian manifold requires much more effort than determining a geodesic from initial data. This is because it is much harder to solve boundary value problems than initial value problems. Shooting methods attempt to solve boundary value problems by solving a sequence of initial value problems, and usually need a good initial guess to succeed. The present paper finds a geodesic $$\\gamma :[0,1]\\rightarrow M$$ \u03b3 : [ 0 , 1 ] \u2192 M on the Riemannian manifold M with \u03b3(0) = x0 and \u03b3(1) = x1 by dividing the interval [0,1] into several sub-intervals, preferably just enough to enable a good initial guess for the boundary value problem on each subinterval. Then a geodesic joining consecutive endpoints (local junctions) is found by single shooting. Our algorithm then adjusts the junctions, either (1) by minimizing the total squared norm of the differences between associated geodesic velocities using Riemannian gradient descent, or (2) by solving a nonlinear system of equations using Newton\u2019s method. Our algorithm is compared with the known leapfrog algorithm by numerical experiments on a 2-dimensional ellipsoid Ell(2) and on a left-invariant 3-dimensional special orthogonal group SO(3). We find Newton\u2019s method (2) converges much faster than leapfrog when more junctions are needed, and that a good initial guess can be found for (2) by starting with Riemannian gradient descent method (1)."}}
{"id": "MtA5UBaOwLx", "cdate": 1623732525916, "mdate": null, "content": {"title": "Consensus Maximisation Using Influences of Monotone Boolean Functions", "abstract": "Consensus maximisation (MaxCon), which is widely used for robust fitting in computer vision, aims to find the largest subset of data that fits the model within some tol- erance level. In this paper, we outline the connection be- tween MaxCon problem and the abstract problem of finding the maximum upper zero of a Monotone Boolean Function (MBF) defined over the Boolean Cube. Then, we link the concept of influences (in a MBF) to the concept of outlier (in MaxCon) and show that influences of points belonging to the largest structure in data would generally be smaller under certain conditions. Based on this observation, we present an iterative algorithm to perform consensus max- imisation. Results for both synthetic and real visual data experiments show that the MBF based algorithm is capa- ble of generating a near optimal solution relatively quickly. This is particularly important where there are large number of outliers (gross or pseudo) in the observed data.\n"}}
{"id": "seE1efgSkbx", "cdate": 1623732378779, "mdate": null, "content": {"title": "Unsupervised Learning for Robust Fitting: A Reinforcement Learning Approach", "abstract": "Robust model fitting is a core algorithm in a large num- ber of computer vision applications. Solving this prob- lem efficiently for datasets highly contaminated with out- liers is, however, still challenging due to the underlying computational complexity. Recent literature has focused on learning-based algorithms. However, most approaches are supervised (which require a large amount of labelled training data). In this paper, we introduce a novel unsuper- vised learning framework that learns to directly solve robust model fitting. Unlike other methods, our work is agnostic to the underlying input features, and can be easily gener- alized to a wide variety of LP-type problems with quasi- convex residuals. We empirically show that our method out- performs existing unsupervised learning approaches, and achieves competitive results compared to traditional meth- ods on several important computer vision problems"}}
{"id": "uec9x4sQP-X", "cdate": 1609459200000, "mdate": 1668771036638, "content": {"title": "Maximum Consensus by Weighted Influences of Monotone Boolean Functions", "abstract": "Robust model fitting is a fundamental problem in computer vision: used to pre-process raw data in the presence of outliers. Maximisation of Consensus (MaxCon) is one of the most popular robust criteria and widely used. Recently (Tennakoon et al. CVPR2021), a connection has been made between MaxCon and estimation of influences of a Monotone Boolean function. Equipping the Boolean cube with different measures and adopting different sampling strategies (two sides of the same coin) can have differing effects: which leads to the current study. This paper studies the concept of weighted influences for solving MaxCon. In particular, we study endowing the Boolean cube with the Bernoulli measure and performing biased (as opposed to uniform) sampling. Theoretically, we prove the weighted influences, under this measure, of points belonging to larger structures are smaller than those of points belonging to smaller structures in general. We also consider another \"natural\" family of sampling/weighting strategies, sampling with uniform measure concentrated on a particular (Hamming) level of the cube. Based on weighted sampling, we modify the algorithm of Tennakoon et al., and test on both synthetic and real datasets. This paper is not promoting a new approach per se, but rather studying the issue of weighted sampling. Accordingly, we are not claiming to have produced a superior algorithm: rather we show some modest gains of Bernoulli sampling, and we illuminate some of the interactions between structure in data and weighted sampling."}}
{"id": "uVsh4lhBKT", "cdate": 1609459200000, "mdate": 1668771036640, "content": {"title": "Consensus Maximisation Using Influences of Monotone Boolean Functions", "abstract": "Consensus maximisation (MaxCon), widely used for robust fitting in computer vision, aims to find the largest subset of data that fits the model within some tolerance level. In this paper, we outline the connection between MaxCon problem and the abstract problem of finding the maximum upper zero of a Monotone Boolean Function (MBF) defined over the Boolean Cube. Then, we link the concept of influences (in a MBF) to the concept of outlier (in MaxCon) and show that influences of points belonging to the largest structure in data would be the smallest under certian conditions. Based on this observation, we present an iterative algorithm to perform consensus maximisation. Results for both synthetic and real visual data experiments show that the MBF based algorithm is capable of generating a near optimal solution relatively quickly. This is particularly important where there are large number of outliers (gross or pseudo) in the observed data."}}
