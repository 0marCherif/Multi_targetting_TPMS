{"id": "aLZJ4qFF8u", "cdate": 1676472361546, "mdate": null, "content": {"title": "Zero redundancy distributed learning with differential privacy", "abstract": "Deep learning with large models have achieved amazing success in a wide range of domains, but the optimization on billions of parameters is challenging in terms of the training speed, memory cost, and communication efficiency, especially under the differential privacy (DP) regime. On the one hand, DP optimization has comparable efficiency to the standard non-private optimization on a single device, but existing DP distributed learning (such as data/pipeline parallel) has significant limitations in efficiency. On the other hand, the Zero Redundancy Optimizer (ZeRO) is a state-of-the-art solution to optimize memory and improve the training efficiency on large models under the standard regime, but it encounters technical challenges to work compatibly with DP. In this work, we develop a new systematic solution, DP-ZeRO, to scale up the model size and obtain almost the same computation and communication efficiency as the standard distributed learning, in both the full and mixed precision. Our DP-ZeRO, like the standard ZeRO, has the potential to train models with arbitrary size and is evaluated on DP models that has the world's largest number of trainable parameters."}}
{"id": "Kf8vYKLhHuW", "cdate": 1675659621788, "mdate": 1675659621788, "content": {"title": "Coarse-to-Fine Sparse Sequential Recommendation", "abstract": "Sequential recommendation aims to model dynamic user behavior from historical interactions. Self-attentive methods have proven effective at capturing short-term dynamics and long-term preferences. Despite their success, these approaches still struggle to model sparse data, on which they struggle to learn high-quality item representations. We propose to model user dynamics from shopping intents and interacted items simultaneously. The learned intents are coarse-grained and work as prior knowledge for item recommendation. To this end, we present a coarse-to-fine self-attention framework, namely CaFe, which explicitly learns coarse-grained and fine-grained sequential dynamics. Specifically, CaFe first learns intents from coarse-grained sequences which are dense and hence provide high-quality user intent representations. Then, CaFe fuses intent representations into item encoder outputs to obtain improved item representations. Finally, we infer recommended items based on representations of items and corresponding intents. Experiments on sparse datasets show that CaFe outperforms state-of-the-art self-attentive recommenders by 44.03% NDCG@5 on average."}}
{"id": "eKD9KnVuhIg", "cdate": 1674954735560, "mdate": 1674954735560, "content": {"title": "RecWalk: Nearly Uncoupled Random Walks for Top-N Recommendation", "abstract": "Random walks can provide a powerful tool for harvesting the rich\nnetwork of interactions captured within item-based models for top-\nn recommendation. They can exploit indirect relations between\nthe items, mitigate the effects of sparsity, ensure wider itemspace\ncoverage, as well as increase the diversity of recommendation lists.\nTheir potential however, is hindered by the tendency of the walks to\nrapidly concentrate towards the central nodes of the graph, thereby\nsignificantly restricting the range of K-step distributions that can\nbe exploited for personalized recommendations. In this work we\nintroduce RecWalk; a novel random walk-based method that lever-\nages the spectral properties of nearly uncoupled Markov chains to\nprovably lift this limitation and prolong the influence of users\u2019\npast preferences on the successive steps of the walk\u2014allowing the\nwalker to explore the underlying network more fruitfully. A com-\nprehensive set of experiments on real-world datasets verify the\ntheoretically predicted properties of the proposed approach and\nindicate that they are directly linked to significant improvements\nin top-n recommendation accuracy. They also highlight RecWalk\u2019s\npotential in providing a framework for boosting the performance of\nitem-based models. RecWalk achieves state-of-the-art top-n recom-\nmendation quality outperforming several competing approaches,\nincluding recently proposed methods that rely on deep neural net-\nworks."}}
{"id": "6Bo1vhoHolh", "cdate": 1665069632529, "mdate": null, "content": {"title": "Differentially Private Bias-Term only Fine-tuning of Foundation Models", "abstract": "We study the problem of differentially private (DP) fine-tuning of large pre-trained models \u2014 a recent privacy-preserving approach suitable for solving downstream tasks with sensitive data. Existing work has demonstrated that high accuracy is possible under strong privacy constraint, yet requires significant computational overhead or modifications to the network architecture.\n\nWe propose differentially private bias-term fine-tuning (DP-BiTFiT), which matches the state-of-the-art accuracy for DP algorithms and the efficiency of the standard BiTFiT. DP-BiTFiT is model agnostic (not modifying the network architecture), parameter efficient (only training about $0.1\\%$ of the parameters), and computation efficient (almost removing the overhead caused by DP, in both the time and space complexity). On a wide range of tasks, DP-BiTFiT is $2\\sim 30\\times$ faster and uses $2\\sim 8\\times$ less memory than DP full fine-tuning, even faster than the standard full fine-tuning. This amazing efficiency enables us to conduct DP fine-tuning on language and vision tasks with long-sequence texts and high-resolution images, which were computationally difficult using existing methods."}}
{"id": "YUbpFNrREOd", "cdate": 1664815571404, "mdate": null, "content": {"title": "Variational Causal Inference", "abstract": "Estimating an individual's potential outcomes under counterfactual treatments is a challenging task for traditional causal inference and supervised learning approaches when the outcome is high-dimensional (e.g. gene expressions, impulse responses, human faces) and covariates are relatively limited. In this case, to construct one's outcome under a counterfactual treatment, it is crucial to leverage individual information contained in its observed factual outcome on top of the covariates. We propose a deep variational Bayesian framework that rigorously integrates two main sources of information for outcome construction under a counterfactual treatment: one source is the individual features embedded in the high-dimensional factual outcome; the other source is the response distribution of similar subjects (subjects with the same covariates) that factually received this treatment of interest."}}
{"id": "0TUa6mo164", "cdate": 1664248829085, "mdate": null, "content": {"title": "Conditional Invariances for Conformer Invariant Protein Representations", "abstract": "Representation learning for proteins is an emerging area in geometric deep learning. Recent works have factored in both the relational (atomic bonds) and the geometric aspects (atomic positions) of the task, notably bringing together graph neural networks (GNNs) with neural networks for point clouds. The equivariances and invariances to geometric transformations (group actions such as rotations and translations) so far treats large molecules as rigid structures. However, in many important settings, proteins can co-exist as an ensemble of multiple stable conformations. The conformations of a protein, however, cannot be described as input-independent transformations of the protein: Two proteins may require different sets of transformations in order to describe their set of viable conformations. To address this limitation, we introduce the concept of conditional transformations (CT). CT can capture protein structure, while respecting the restrictions posed by constraints on dihedral (torsion) angles and steric repulsions between atoms. We then introduce a Markov chain Monte Carlo framework to learn representations that are invariant to these conditional transformations. Our results show that endowing existing baseline models with these conditional transformations helps improve their performance without sacrificing computational cost."}}
{"id": "RgFkEoXF_nn", "cdate": 1664046172429, "mdate": null, "content": {"title": "Sequence-Graph Duality: Unifying User Modeling with Self-Attention for Sequential Recommendation", "abstract": "User modeling is of great importance in personalization services. Many existing methods treat users as interaction sequences to capture users' evolving interests. Another line of research models each user as a user graph in which the users' interactions are modeled as nodes. Nodes (interactions) in user graphs are connected via edges that reflect certain relations such as item similarity. The graph-based user modeling can flexibly store item relationships. In this work, we introduce a novel user representation, Heterogeneous User Graph (HUG), which unifies sequence- and graph-based user modeling to take advantage of both methods. A HUG is associated with two types of edges: sequential edges that preserve the order of interactions and collaborative edges that connect collaboratively similar items (i.e., items interacted by similar sets of users). To learn latent user representations for recommendation tasks, we propose a multi-head attention-based architecture called Heterogeneous User Graph Transformer (HUGT). HUGT is developed on the basis of SASRec and can concurrently capture the sequential pattern and graph topology encoded in HUGs. We conduct experiments on four real-world datasets from three different application domains. Experimental results show that (1) jointly modeling users as sequences and graphs with HUG provides better recommendation performance over sequence-only and graph-only user modeling; (2) HUGT is effective in learning user latent representations from HUGs; (3) HUGT outperforms the baselines by up to 10\\% on datasets with long sequences and aligns with the state-of-the-art performance on datasets with short sequences. "}}
{"id": "VFIH17qfUlH", "cdate": 1663873729905, "mdate": 1663873729905, "content": {"title": "TGL: A General Framework for Temporal GNN Training on Billion-Scale Graphs", "abstract": "Many real world graphs contain time domain information. Temporal Graph Neural Networks capture temporal information as well as structural and contextual information in the generated dynamic node embeddings. Researchers have shown that these embeddings achieve state-of-the-art performance in many different tasks. In this work, we propose TGL, a unified framework for large-scale offline Temporal Graph Neural Network training where users can compose various Temporal Graph Neural Networks with simple configuration files. TGL comprises five main components, a temporal sampler, a mailbox, a node memory module, a memory updater, and a message passing engine. We design a Temporal-CSR data structure and a parallel sampler to efficiently sample temporal neighbors to formtraining mini-batches. We propose a novel random chunk scheduling technique that mitigates the problem of obsolete node memory when training with a large batch size. To address the limitations of current TGNNs only being evaluated on small-scale datasets, we introduce two large-scale real-world datasets with 0.2 and 1.3 billion temporal edges. We evaluate the performance of TGL on four small-scale datasets with a single GPU and the two large datasets with multiple GPUs for both link prediction and node classification tasks. We compare TGL with the open-sourced code of five methods and show that TGL achieves similar or better accuracy with an average of 13x speedup. Our temporal parallel sampler achieves an average of 173x speedup on a multi-core CPU compared with the baselines. On a 4-GPU machine, TGL can train one epoch of more than one billion temporal edges within 1-10 hours. To the best of our knowledge, this is the first work that proposes a general framework for large-scale Temporal Graph Neural Networks training on multiple GPUs."}}
{"id": "zoTUH3Fjup", "cdate": 1663850119631, "mdate": null, "content": {"title": "Differentially private Bias-Term Only Fine-tuning of Foundation Models", "abstract": "We study the problem of differentially private (DP) fine-tuning of large pre-trained models \u2014 a recent privacy-preserving approach suitable for solving downstream tasks with sensitive data. Existing work has demonstrated that high accuracy is possible under strong privacy constraint, yet requires significant computational overhead or modifications to the network architecture.\n\nWe propose differentially private bias-term fine-tuning (DP-BiTFiT), which matches the state-of-the-art accuracy for DP algorithms and the efficiency of the standard BiTFiT. DP-BiTFiT is model agnostic (not modifying the network architecture), parameter efficient (only training about $0.1\\%$ of the parameters), and computation efficient (almost removing the overhead caused by DP, in both the time and space complexity). On a wide range of tasks, DP-BiTFiT is $2\\sim 30\\times$ faster and uses $2\\sim 8\\times$ less memory than DP full fine-tuning, even faster than the standard full fine-tuning. This amazing efficiency enables us to conduct DP fine-tuning on language and vision tasks with long-sequence texts and high-resolution images, which were computationally difficult using existing methods."}}
{"id": "XfQlcpWESqV", "cdate": 1663850119145, "mdate": null, "content": {"title": "Differentially Private Optimization on Large Model at Small Cost", "abstract": "Differentially private (DP) optimization is the  standard paradigm to learn large neural networks that are accurate and privacy-preserving. The computational cost for DP deep learning, however, is notoriously heavy due to the per-sample gradient clipping. Existing DP implementations are $2-1000\\times$ more costly in time and space complexity than the standard (non-private) training. In this work, we develop a novel Book-Keeping (BK) technique that implements existing DP optimizers (thus achieving the same accuracy), with a substantial improvement on the computational cost. Specifically, BK enables DP training on large models and high dimensional data to be roughly as efficient as the standard training, whereas previous DP algorithms can be inefficient or incapable of training due to memory error. The computational advantage of BK is supported by the complexity analysis as well as extensive experiments on vision and language tasks. Our implementation achieves state-of-the-art (SOTA) accuracy with very small extra cost: on GPT2 and at the same memory cost, BK has 1.0$\\times$ the time complexity of the standard training (0.75$\\times$ training speed in practice), and 0.6$\\times$ the time complexity of the most efficient DP implementation (1.24$\\times$ training speed in practice). We will open-source the codebase for the BK algorithm."}}
