{"id": "lCFeHQteHL", "cdate": 1672531200000, "mdate": 1681517138111, "content": {"title": "Variance-Reduced Stochastic Quasi-Newton Methods for Decentralized Learning", "abstract": ""}}
{"id": "a_W-O12wKy", "cdate": 1640995200000, "mdate": 1671847091525, "content": {"title": "Variance-Reduced Stochastic Quasi-Newton Methods for Decentralized Learning: Part I", "abstract": "In this work, we investigate stochastic quasi-Newton methods for minimizing a finite sum of cost functions over a decentralized network. In Part I, we develop a general algorithmic framework that incorporates stochastic quasi-Newton approximations with variance reduction so as to achieve fast convergence. At each time each node constructs a local, inexact quasi-Newton direction that asymptotically approaches the global, exact one. To be specific, (i) A local gradient approximation is constructed by using dynamic average consensus to track the average of variance-reduced local stochastic gradients over the entire network; (ii) A local Hessian inverse approximation is assumed to be positive definite with bounded eigenvalues, and how to construct it to satisfy these assumptions will be given in Part II. Compared to the existing decentralized stochastic first-order methods, the proposed general framework introduces the second-order curvature information without incurring extra sampling or communication. With a fixed step size, we establish the conditions under which the proposed general framework linearly converges to an exact optimal solution."}}
{"id": "x6ytakmBIIq", "cdate": 1609459200000, "mdate": 1671847091517, "content": {"title": "A Penalty Alternating Direction Method of Multipliers for Convex Composite Optimization Over Decentralized Networks", "abstract": "Consider the problem of minimizing a sum of convex composite functions over a decentralized network, where each agent in the network holds a private function consisting of a smooth part and a nonsmooth part, and it can only exchange information with its neighbors during the optimization process. One approach to tackling this problem is to study its penalized approximation. Although such an approximation becomes more accurate as the penalty parameter becomes smaller, it is well known that the penalized objective will also become more ill-conditioned, thereby causing the popular proximal gradient descent method to slow down substantially. To break this accuracy-speed tradeoff, we propose to solve the penalized approximation with the alternating direction method of multipliers (ADMM). We also exploit the composite structure of the private functions by linearizing the smooth parts and handling the nonsmooth parts with proximal operators, which allows us to further reduce the computational costs. The proposed penalty ADMM (abbreviated as PAD) is proven to be sublinearly convergent when the private functions are convex, and linearly convergent when in addition the smooth parts are strongly convex. We present numerical results to corroborate the theoretical analyses and to further demonstrate the advantages of PAD over existing state-of-the-art algorithms such as DL-ADMM, PG-EXTRA, and NIDS."}}
{"id": "Tza1Zgtgt6", "cdate": 1609459200000, "mdate": 1671847091508, "content": {"title": "A Newton Tracking Algorithm With Exact Linear Convergence for Decentralized Consensus Optimization", "abstract": "This paper considers the problem of decentralized consensus optimization over a network, where each node holds a strongly convex and twice-differentiable local objective function. Our goal is to minimize the sum of the local objective functions and find the exact optimal solution using only local computation and neighboring communication. We propose a novel Newton tracking algorithm, which updates the local variable in each node along a local Newton direction modified with neighboring and historical information. We investigate the connections between the proposed Newton tracking algorithm and several existing methods, including gradient tracking and primal-dual methods. We prove that the proposed algorithm converges to the exact optimal solution at a linear rate. Furthermore, when the iterate is close to the optimal solution, we show that the proposed algorithm requires <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><tex-math notation=\"LaTeX\">$O(\\max \\lbrace \\kappa _f \\sqrt{\\kappa _g} + \\kappa _f^2, \\frac{\\kappa _g^{3/2}}{\\kappa _f} + \\kappa _f\\sqrt{\\kappa _g} \\rbrace \\log {\\frac{1}{\\Delta }})$</tex-math></inline-formula> iterations to find a <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><tex-math notation=\"LaTeX\">$\\Delta$</tex-math></inline-formula> -optimal solution, where <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><tex-math notation=\"LaTeX\">$\\kappa _f$</tex-math></inline-formula> and <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><tex-math notation=\"LaTeX\">$\\kappa _g$</tex-math></inline-formula> are condition numbers of the objective function and the graph, respectively. Our numerical results demonstrate the efficacy of Newton tracking and validate the theoretical findings."}}
{"id": "s2XyC2xdFfj", "cdate": 1577836800000, "mdate": 1671847091520, "content": {"title": "A Newton Tracking Algorithm with Exact Linear Convergence Rate for Decentralized Consensus Optimization", "abstract": "This paper considers the decentralized consensus optimization problem defined over a network where each node holds a twice continuously differentiable local objective function. Our goal is to minimize the summation of local objective functions and find the exact optimal solution using only local computation and neighboring communications. We propose a novel Newton tracking algorithm, in which each node updates its local variable along a local Newton direction modified with neighboring and historical information. We investigate the connections between the proposed Newton tracking algorithm and several existing methods, including gradient tracking and second-order algorithms. Under the strong convexity assumption, we prove that our proposed algorithm converges to the exact optimal solution at a linear rate. We also present numerical results to demonstrate the efficacy of Newton tracking and validate the theoretical findings."}}
{"id": "IA-lgOK8vaD", "cdate": 1577836800000, "mdate": 1671847091527, "content": {"title": "A Penalty Alternating Direction Method of Multipliers for Decentralized Composite Optimization", "abstract": "This paper proposes a penalty alternating direction method of multipliers (ADMM) to minimize the summation of convex composite functions over a decentralized network. Each agent in the network holds a private function consisting of a smooth part and a nonsmooth part, and can only exchange information with its neighbors during the optimization process. We consider a penalized approximation of the decentralized optimization problem; but unlike the existing penalty methods, here the penalty parameter can be very small such that the approximation error is negligible. On the other hand, the small penalty parameter makes the penalized objective ill-conditioned, such that the popular proximal gradient descent method has to use a small step size, and is hence slow. To address this issue, we propose to solve the penalized formulation with ADMM. We further utilize the composite structures of the private functions through linearizing the smooth parts so as to reduce computational costs, and handling the nonsmooth parts with proximal operators. The proposed penalty ADMM (abbreviated as PAD) is provably convergent when the private functions are convex, and linearly convergent when the smooth parts are further strongly convex. Numerical experiments corroborate the theoretical analyses, and demonstrate the advantages of PAD over existing state-of-the-art algorithms, such as DL-ADMM, PG-EXTRA and NIDS."}}
{"id": "GP7azx4sbI", "cdate": 1577836800000, "mdate": 1682320140195, "content": {"title": "Quantum State Filter With Disturbance and Noise", "abstract": "A quantum state filter (QSF) is proposed in this paper to estimate a low-rank quantum density matrix from informationally incomplete and contaminated measurements. There exist sparse disturbances on the quantum density matrix and Gaussian noise in the measurements. A proximal Jacobian variant of the alternating direction method of multipliers (PJ-ADMM) is proposed to design the QSF. The closed-form solutions to three resulting subproblems are given and the iterative QSF is developed. The proposed QSF is proved to be convergent and its superiority is demonstrated in the numerical illustrations compared with different state-of-the-art methods."}}
{"id": "Gp_9RCQu--V", "cdate": 1546300800000, "mdate": 1682320140151, "content": {"title": "An Efficient and Fast Quantum State Estimator With Sparse Disturbance", "abstract": "A pure or nearly pure quantum state can be described as a low-rank density matrix, which is a positive semidefinite and unit-trace Hermitian. We consider the problem of recovering such a low-rank density matrix contaminated by sparse components, from a small set of linear measurements. This quantum state estimation task can be formulated as a robust principal component analysis (RPCA) problem subject to positive semidefinite and unit-trace Hermitian constraints. We propose an efficient and fast inexact alternating direction method of multipliers (I-ADMM), in which the subproblems are solved inexactly and hence have closed-form solutions. We prove global convergence of the proposed I-ADMM, and the theoretical result provides a guideline for parameter setting. Numerical experiments show that the proposed I-ADMM can recover state density matrices of 5 qubits on a laptop in 0.69 s, with 6 \u00d7 10 <sup xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">-4</sup> accuracy (99.38% fidelity) using 30% compressive sensing measurements, which outperforms existing algorithms."}}
{"id": "oKqTJj5Fi5", "cdate": 1483228800000, "mdate": 1682320140201, "content": {"title": "Fast algorithm of high-dimensional quantum state estimation via low measurement rates", "abstract": ""}}
{"id": "2tpsUfghiC", "cdate": 1483228800000, "mdate": 1682320140201, "content": {"title": "Efficient reconstruction of density matrices for high dimensional quantum state tomography", "abstract": ""}}
