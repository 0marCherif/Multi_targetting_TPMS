{"id": "RSNMAMiPFTM", "cdate": 1664310937345, "mdate": null, "content": {"title": "Convergence in KL and R\u00e9nyi Divergence of the Unadjusted Langevin Algorithm Using Estimated Score", "abstract": "We study Inexact Langevin Algorithm (ILA) for sampling using an estimated score function when the target distribution satisfies log-Sobolev inequality (LSI), motivated by Score-based Generative Modeling (SGM). We prove convergence in Kullback-Leibler (KL) divergence under a sufficient assumption on the error of score estimator called bounded Moment Generating Function (MGF) assumption. Our assumption is weaker than the previous assumption which requires the error has finite $L^\\infty$ norm everywhere. Under the $L^\\infty$ error assumption, we also prove convergence in R\\'enyi divergence, which is stronger than KL divergence. On the other hand, under $L^p$ error assumption for any $1 \\leq p < \\infty$ which is weaker than bounded MGF assumption, we show that the stationary distribution of Langevin dynamics with an $L^p$-accurate score estimator can be far away from the desired distribution. Thus having an $L^p$-accurate score estimator cannot guarantee convergence. Our results suggest controlling mean squared error which is the form of commonly used loss function when using neural network to estimate score function is not enough to guarantee the upstream algorithm will converge, hence in order to get a theoretical guarantee we need a stronger control over the error in score matching. Despite requiring an exponentially decaying error probability, we give an example to demonstrate the bounded MGF assumption is achievable when using Kernel Density Estimation (KDE)-based score estimator.\n"}}
{"id": "FJXf1FXN8C", "cdate": 1663850417411, "mdate": null, "content": {"title": "Towards Understanding GD with Hard and Conjugate Pseudo-labels for Test-Time Adaptation", "abstract": "We consider a setting that a model needs to adapt to a new domain under distribution shifts, given that only unlabeled test samples from the new domain are accessible at test time. A common idea in most of the related works is constructing pseudo-labels for the unlabeled test samples and applying gradient descent (GD) to a loss function with the pseudo-labels. Recently, Goyal et al. (2022) propose conjugate labels, which is a new kind of pseudo-labels for self-training at test time. They empirically show that the conjugate label outperforms other ways of pseudo-labeling on many domain adaptation benchmarks. However, provably showing that GD with conjugate labels learns a good classifier for test-time adaptation remains open. In this work, we aim at theoretically understanding GD with hard and conjugate labels for a binary classification problem. We show that for square loss, GD with conjugate labels converges to an $\\epsilon$-optimal predictor under a Gaussian model for any arbitrarily small $\\epsilon$, while GD with hard pseudo-labels fails in this task. We also analyze them under different loss functions for the update. Our results shed lights on understanding when and why GD with hard labels or conjugate labels works in test-time adaptation."}}
{"id": "FbRY1XVfwK", "cdate": 1663850363019, "mdate": null, "content": {"title": "Accelerating Hamiltonian Monte Carlo via Chebyshev Integration Time", "abstract": "Hamiltonian Monte Carlo (HMC) is a popular method in sampling. While there are quite a few works of studying this method on various aspects, an interesting question is how to choose its integration time to achieve acceleration. In this work, we consider accelerating the process of sampling from a distribution $\\pi(x) \\propto \\exp(-f(x))$ via HMC via time-varying integration time. When the potential $f$ is $L$-smooth and $m$-strongly convex, i.e. for sampling from a log-smooth and strongly log-concave target distribution $\\pi$, it is known that under a constant integration time, the number of iterations that ideal HMC takes to get an $\\epsilon$ Wasserstein-2 distance to the target $\\pi$ is $O( \\kappa \\log \\frac{1}{\\epsilon} )$, where $\\kappa := \\frac{L}{m}$ is the condition number. We propose a scheme of time-varying integration time based on the roots of Chebyshev polynomials. We show that in the case of quadratic potential $f$, i.e. when the target $\\pi$ is a Gaussian distribution, ideal HMC with this choice of integration time only takes $O( \\sqrt{\\kappa} \\log \\frac{1}{\\epsilon} )$ number of iterations to reach Wasserstein-2 distance less than $\\epsilon$; this improvement on the dependence on condition number is akin to acceleration in optimization. The design and analysis of HMC with the proposed integration time is built on the tools of Chebyshev polynomials. Experiments find the advantage of adopting our scheme of time-varying integration time even for sampling from distributions with smooth strongly convex potentials that are not quadratic. \n"}}
{"id": "yYbhKqdi7Hz", "cdate": 1663850037073, "mdate": null, "content": {"title": "Continuized Acceleration for Quasar Convex Functions  in Non-Convex Optimization", "abstract": "Quasar convexity is a condition that allows some first-order methods to efficiently minimize a function even when the optimization landscape is non-convex. Previous works develop near-optimal accelerated algorithms for minimizing this class of functions, however, they require a subroutine of binary search which results in multiple calls to gradient evaluations in each iteration, and consequently the total number of gradient evaluations does not match a known lower bound. In this work, we show that a recently proposed continuized Nesterov acceleration can be applied to minimizing quasar convex functions and achieves the optimal bound with a high probability. Furthermore, we find that the objective functions of training generalized linear models (GLMs) satisfy quasar convexity, which broadens the applicability of the relevant algorithms, while known practical examples of quasar convexity in non-convex learning are sparse in the literature. We also show that if a smooth and one-point strongly convex, Polyak-Lojasiewicz, or quadratic-growth function satisfies quasar convexity, then attaining an accelerated linear rate for minimizing the function is possible under certain conditions, while acceleration is not known in general for these classes of functions.\n"}}
{"id": "w4X7GLThiuJ", "cdate": 1652737545363, "mdate": null, "content": {"title": "Alternating Mirror Descent for Constrained Min-Max Games", "abstract": "In this paper we study two-player bilinear zero-sum games with constrained strategy spaces. An instance of natural occurrences of such constraints is when mixed strategies are used, which correspond to a probability simplex constraint. We propose and analyze the alternating mirror descent algorithm, in which each player takes turns to take action following the mirror descent algorithm for constrained optimization. We interpret alternating mirror descent as an alternating discretization of a skew-gradient flow in the dual space, and use tools from convex optimization and modified energy function to establish an $O(K^{-2/3})$ bound on its average regret after $K$ iterations. This quantitatively verifies the algorithm's  better behavior than the simultaneous version of mirror descent algorithm, which is known to diverge and yields an $O(K^{-1/2})$ average regret bound. In the special case of an unconstrained setting, our results recover the behavior of alternating gradient descent algorithm for zero-sum games which was studied in (Bailey et al., COLT 2020)."}}
{"id": "SylGpT4FPS", "cdate": 1569439161582, "mdate": null, "content": {"title": "Last-iterate convergence rates for min-max optimization", "abstract": "While classic work in convex-concave min-max optimization relies on average-iterate convergence results, the emergence of nonconvex applications such as training Generative Adversarial Networks has led to renewed interest in last-iterate convergence guarantees. Proving last-iterate convergence is challenging because many natural algorithms, such as Simultaneous Gradient Descent/Ascent, provably diverge or cycle even in simple convex-concave min-max settings, and previous work on global last-iterate convergence rates has been limited to the bilinear and convex-strongly concave settings. In this work, we show that the Hamiltonian Gradient Descent (HGD) algorithm achieves linear convergence in a variety of more general settings, including convex-concave problems that satisfy a \u201csufficiently bilinear\u201d condition. We also prove similar convergence rates for some parameter settings of the Consensus Optimization (CO) algorithm of Mescheder et al. 2017."}}
{"id": "BkxXpVSxUS", "cdate": 1567802555083, "mdate": null, "content": {"title": "Rapid Convergence of the Unadjusted Langevin Algorithm: Isoperimetry Suffices", "abstract": "We study the Unadjusted Langevin Algorithm (ULA) for sampling from a probability distribution $\\nu = e^{-f}$ on $\\R^n$. We prove a convergence guarantee in Kullback-Leibler (KL) divergence assuming $\\nu$ satisfies a log-Sobolev inequality and the Hessian of $f$ is bounded. Notably, we do not assume convexity or bounds on higher derivatives. We also prove a convergence guarantee in R\\'enyi divergence of order $q > 1$ assuming the limit of ULA satisfies the log-Sobolev inequality. "}}
{"id": "H1EvzKbOZS", "cdate": 1388534400000, "mdate": null, "content": {"title": "Concavity of reweighted Kikuchi approximation", "abstract": "We analyze a reweighted version of the Kikuchi approximation for estimating the log partition function of a product distribution defined over a region graph. We establish sufficient conditions for the concavity of our reweighted objective function in terms of weight assignments in the Kikuchi expansion, and show that a reweighted version of the sum product algorithm applied to the Kikuchi region graph will produce global optima of the Kikuchi approximation whenever the algorithm converges. When the region graph has two layers, corresponding to a Bethe approximation, we show that our sufficient conditions for concavity are also necessary. Finally, we provide an explicit characterization of the polytope of concavity in terms of the cycle structure of the region graph. We conclude with simulations that demonstrate the advantages of the reweighted Kikuchi approach."}}
{"id": "rk4Y-YZdZr", "cdate": 1356998400000, "mdate": null, "content": {"title": "How to Hedge an Option Against an Adversary: Black-Scholes Pricing is Minimax Optimal", "abstract": "We consider a popular problem in finance, option pricing, through the lens of an online learning game between Nature and an Investor. In the Black-Scholes option pricing model from 1973, the Investor can continuously hedge the risk of an option by trading the underlying asset, assuming that the asset's price fluctuates according to Geometric Brownian Motion (GBM). We consider a worst-case model, in which Nature chooses a sequence of price fluctuations under a cumulative quadratic volatility constraint, and the Investor can make a sequence of hedging decisions. Our main result is to show that the value of our proposed game, which is the regret'' of hedging strategy, converges to the Black-Scholes option price. We use significantly weaker assumptions than previous work---for instance, we allow large jumps in the asset price---and show that the Black-Scholes hedging strategy is near-optimal for the Investor even in this non-stochastic framework.\""}}
{"id": "ByW2x_b_br", "cdate": 1356998400000, "mdate": null, "content": {"title": "Streaming Variational Bayes", "abstract": "We present SDA-Bayes, a framework for (S)treaming, (D)istributed, (A)synchronous computation of a Bayesian posterior. The framework makes streaming updates to the estimated posterior according to a user-specified approximation primitive function. We demonstrate the usefulness of our framework, with variational Bayes (VB) as the primitive, by fitting the latent Dirichlet allocation model to two large-scale document collections. We demonstrate the advantages of our algorithm over stochastic variational inference (SVI), both in the single-pass setting SVI was designed for and in the streaming setting, to which SVI does not apply."}}
