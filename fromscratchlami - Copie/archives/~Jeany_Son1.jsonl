{"id": "7ET7rBhABf0", "cdate": 1680307200000, "mdate": 1699855083304, "content": {"title": "Deep AI military staff: cooperative battlefield situation awareness for commander's decision making", "abstract": "There are many studies adopting artificial intelligence (AI) to develop core technologies for the future army but they are still at the level of basic research. It is expected that military power will be negatively affected by aging and declining population. In addition, as more than 500,000 agents will be dispatched to monitor combat scenes, the data sensed by each agent should be managed simultaneously recognize and evaluate the situation on the battlefield in real time. Despite increased complexity in the battlefield, current command system entirely rely on the experience and expertise of individual commanders, which severely restricts defense capabilities. Therefore, AI based military staff needs to be developed to identify potential threats that commanders are likely to miss, to develop smart command systems, and to provide data-driven rationale for commander\u2019s decisions. In this paper, we propose a deep AI military staff to support commander decision-making. Our proposed model is composed of four key parts: multi-agent based manned-unmanned collaboration architecture (MACA), robust tactical map fusion technology in poor environments (RTMF), hypergraph based representation learning (HRL) and space-time multi layer model for battlefields recognition (STBR). We design an architecture and generate dataset for training the core network. Simulation results are provided to demonstrate the performance of Deep AI military staff."}}
{"id": "ftDWNSr15Da", "cdate": 1672531200000, "mdate": 1682520359135, "content": {"title": "Zero-shot Referring Image Segmentation with Global-Local Context Features", "abstract": "Referring image segmentation (RIS) aims to find a segmentation mask given a referring expression grounded to a region of the input image. Collecting labelled datasets for this task, however, is notoriously costly and labor-intensive. To overcome this issue, we propose a simple yet effective zero-shot referring image segmentation method by leveraging the pre-trained cross-modal knowledge from CLIP. In order to obtain segmentation masks grounded to the input text, we propose a mask-guided visual encoder that captures global and local contextual information of an input image. By utilizing instance masks obtained from off-the-shelf mask proposal techniques, our method is able to segment fine-detailed Istance-level groundings. We also introduce a global-local text encoder where the global feature captures complex sentence-level semantics of the entire input expression while the local feature focuses on the target noun phrase extracted by a dependency parser. In our experiments, the proposed method outperforms several zero-shot baselines of the task and even the weakly supervised referring expression segmentation method with substantial margins. Our code is available at https://github.com/Seonghoon-Yu/Zero-shot-RIS."}}
{"id": "MNN3iG2okwp", "cdate": 1672531200000, "mdate": 1699855083323, "content": {"title": "Unsupervised Object Localization with Representer Point Selection", "abstract": "We propose a novel unsupervised object localization method that allows us to explain the predictions of the model by utilizing self-supervised pre-trained models without additional finetuning. Existing unsupervised and self-supervised object localization methods often utilize class-agnostic activation maps or self-similarity maps of a pre-trained model. Although these maps can offer valuable information for localization, their limited ability to explain how the model makes predictions remains challenging. In this paper, we propose a simple yet effective unsupervised object localization method based on representer point selection, where the predictions of the model can be represented as a linear combination of representer values of training points. By selecting representer points, which are the most important examples for the model predictions, our model can provide insights into how the model predicts the foreground object by providing relevant examples as well as their importance. Our method outperforms the state-of-the-art unsupervised and self-supervised object localization methods on various datasets with significant margins and even outperforms recent weakly supervised and few-shot methods."}}
{"id": "zwcmr1zsFn", "cdate": 1640995200000, "mdate": 1667355116962, "content": {"title": "Contrastive Learning for Space-time Correspondence via Self-cycle Consistency", "abstract": "We propose a novel probabilistic method employing Bayesian Model Averaging and self-cycle regularization for spatio-temporal correspondence learning in videos within a self-supervised learning framework. Most existing methods for self-supervised correspondence learning suffer from noisy labels that come with the data for free, and the presence of occlusion exacerbates the problem. We tackle this issue within a probabilistic framework that handles model uncertainty inherent in the path selection problem built on a complete graph. We propose a self-cycle regularization to consider a cycle-consistency property on individual edges in order to prevent converging on noisy matching or trivial solutions. We also utilize a mixture of sequential Bayesian filters to estimate posterior distribution for targets. In addition, we present a domain contrastive loss to learn discriminative representation among videos. Our algorithm is evaluated on various datasets for video label propagation tasks including DAVIS2017, VIP and JHMDB, and shows outstanding performances compared to the state-of-the-art self-supervised learning based video correspondence algorithms. Moreover, our method converges significantly faster than previous methods."}}
{"id": "1MGJMNwtfb8", "cdate": 1623571860892, "mdate": null, "content": {"title": "Weakly Supervised Instance Segmentation by Deep Community Learning", "abstract": "We present a weakly supervised instance segmentation algorithm based on deep community learning with multiple tasks. This task is formulated as a combination of weakly supervised object detection and semantic segmentation, where individual objects of the same class are identified and segmented separately. We address this problem by designing a unified deep neural network architecture, which has a positive feedback loop of object detection with bounding box regression, instance mask generation, instance segmentation, and feature extraction. Each component of the network makes active interactions with others to improve accuracy, and the end-to-end trainability of our model makes our results more robust and reproducible. The proposed algorithm achieves state-of-the-art performance in the weakly supervised setting without any additional training such as Fast R-CNN and Mask R\u0002CNN on the standard benchmark dataset. The implementation of our algorithm is available on the project webpage: https://cv.snu.ac.kr/research/WSIS_CL.\n"}}
{"id": "HSODaljr9TN", "cdate": 1609459200000, "mdate": 1667355116961, "content": {"title": "Weakly Supervised Instance Segmentation by Deep Community Learning", "abstract": "We present a weakly supervised instance segmentation algorithm based on deep community learning with multiple tasks. This task is formulated as a combination of weakly supervised object detection and semantic segmentation, where individual objects of the same class are identified and segmented separately. We address this problem by designing a unified deep neural network architecture, which has a positive feedback loop of object detection with bounding box regression, instance mask generation, instance segmentation, and feature extraction. Each component of the network makes active interactions with others to improve accuracy, and the end-to-end trainability of our model makes our results more robust and reproducible. The proposed algorithm achieves state-of-the-art performance in the weakly supervised setting without any additional training such as Fast R-CNN and Mask R-CNN on the standard benchmark dataset. The implementation of our algorithm is available on the project webpage: https://cv.snu.ac.kr/research/WSIS_CL."}}
{"id": "xg488ecxBw", "cdate": 1577836800000, "mdate": 1667355116962, "content": {"title": "Weakly Supervised Instance Segmentation by Deep Multi-Task Community Learning", "abstract": "We present a weakly supervised instance segmentation algorithm based on deep community learning with multiple tasks. This task is formulated as a combination of weakly supervised object detection and semantic segmentation, where individual objects of the same class are identified and segmented separately. We address this problem by designing a unified deep neural network architecture, which has a positive feedback loop of object detection with bounding box regression, instance mask generation, instance segmentation, and feature extraction. Each component of the network makes active interactions with others to improve accuracy, and the end-to-end trainability of our model makes our results more robust and reproducible. The proposed algorithm achieves state-of-the-art performance in the weakly supervised setting without any additional training such as Fast R-CNN and Mask R-CNN on the standard benchmark dataset. The implementation of our algorithm is available on the project webpage: https://cv.snu.ac.kr/research/WSIS_CL."}}
{"id": "UcKdJZsxKTJ", "cdate": 1514764800000, "mdate": 1667355116962, "content": {"title": "Real-Time MDNet", "abstract": "We present a fast and accurate visual tracking algorithm based on the multi-domain convolutional neural network (MDNet). The proposed approach accelerates feature extraction procedure and learns more discriminative models for instance classification; it enhances representation quality of target and background by maintaining a high resolution feature map with a large receptive field per activation. We also introduce a novel loss term to differentiate foreground instances across multiple domains and learn a more discriminative embedding of target objects with similar semantics. The proposed techniques are integrated into the pipeline of a well known CNN-based visual tracking algorithm, MDNet. We accomplish approximately 25 times speed-up with almost identical accuracy compared to MDNet. Our algorithm is evaluated in multiple popular tracking benchmark datasets including OTB2015, UAV123, and TempleColor, and outperforms the state-of-the-art real-time tracking methods consistently even without dataset-specific parameter tuning."}}
{"id": "Sg3qdspvJO", "cdate": 1514764800000, "mdate": 1667355116962, "content": {"title": "Forget and Diversify: Regularized Refinement for Weakly Supervised Object Detection", "abstract": "We study weakly supervised learning for object detectors, where training images have image-level class labels only. This problem is often addressed by multiple instance learning, where pseudo-labels of proposals are constructed from image-level weak labels and detectors are learned from the potentially noisy labels. Since existing methods train models in a discriminative manner, they typically suffer from collapsing into salient parts and also fail in localizing multiple instances within an image. To alleviate such limitations, we propose simple yet effective regularization techniques, weight reinitialization and labeling perturbations, which prevent overfitting to noisy labels by forgetting biased weights. We also introduce a graph-based mode-seeking technique that identifies multiple object instances in a principled way. The combination of the two proposed techniques reduces overfitting observed frequently in weakly supervised setting, and greatly improves object localization performance in standard benchmarks."}}
{"id": "F-LY9Um4Wb", "cdate": 1293840000000, "mdate": 1667355116961, "content": {"title": "Dynamic Resource Allocation by Ranking SVM for Particle Filter Tracking", "abstract": ""}}
