{"id": "mj5eFSP0MMp", "cdate": 1668684316553, "mdate": 1668684316553, "content": {"title": "Single-image Full-body Human Relighting", "abstract": "We present a single-image data-driven method to automatically relight images with full-body humans in them. Our framework is based on a realistic scene decomposition leveraging precomputed radiance transfer (PRT) and spherical harmonics (SH) lighting. In contrast to previous work, we lift the assumptions on Lambertian materials and explicitly model diffuse and specular reflectance in our data. Moreover, we introduce an additional light-dependent residual term that accounts for errors in the PRT-based image reconstruction. We propose a new deep learning architecture, tailored to the decomposition performed in PRT, that is trained using a combination of L1, logarithmic, and rendering losses. Our model outperforms the state of the art for full-body human relighting both with synthetic images and photographs."}}
{"id": "icRyOwP1zXS", "cdate": 1664144742519, "mdate": 1664144742519, "content": {"title": "Contact and Human Dynamics from Monocular Video", "abstract": "Existing deep models predict 2D and 3D kinematic poses from video that are approximately accurate, but contain visible errors that violate physical constraints, such as feet penetrating the ground and bodies leaning at extreme angles. In this paper, we present a physics-based method for inferring 3D human motion from video sequences that takes initial 2D and 3D pose estimates as input. We first estimate ground contact timings with a novel prediction network which is trained without hand-labeled data. A physics-based trajectory optimization then solves for a physically-plausible motion, based on the inputs. We show this process produces motions that are significantly more realistic than those from purely kinematic methods, substantially improving quantitative measures of both kinematic and dynamic plausibility. We demonstrate our method on character animation and pose estimation tasks on dynamic motions of dancing and sports with complex contact patterns.\n\n"}}
{"id": "70V1ZYgOnm", "cdate": 1621107606070, "mdate": null, "content": {"title": "HuMoR: 3D Human Motion Model for Robust Pose Estimation", "abstract": "We introduce HuMoR: a 3D Human Motion Model for Robust Estimation of temporal pose and shape. Though substantial progress has been made in estimating 3D human motion and shape from dynamic observations, recovering plausible pose sequences in the presence of noise and occlusions remains a challenge. For this purpose, we propose an expressive generative model in the form of a conditional variational autoencoder, which learns a distribution of the change in pose at each step of a motion sequence. Furthermore, we introduce a flexible optimization-based approach that leverages HuMoR as a motion prior to robustly estimate plausible pose and shape from ambiguous observations. Through extensive evaluations, we demonstrate that our model generalizes to diverse motions and body shapes after training on a large motion capture dataset, and enables motion reconstruction from multiple input modalities including 3D keypoints and RGB(-D) videos."}}
{"id": "lMW9KtpMRn8", "cdate": 1620334047497, "mdate": null, "content": {"title": "Learning to Sit: Synthesizing Human-Chair Interactions via Hierarchical Control", "abstract": "Recent progress on physics-based character animation has shown impressive breakthroughs on human motion synthesis, through imitating motion capture data via deep reinforcement learning. However, results have mostly been demonstrated on imitating a single distinct motion pattern, and do not generalize to interactive tasks that require flexible motion patterns due to varying human-object spatial configurations. To bridge this gap, we focus on one class of interactive tasks -- sitting onto a chair. We propose a hierarchical reinforcement learning framework which relies on a collection of subtask controllers trained to imitate simple, reusable mocap motions, and a meta controller trained to execute the subtasks properly to complete the main task. We experimentally demonstrate the strength of our approach over different non-hierarchical and hierarchical baselines. We also show that our approach can be applied to motion prediction given an image input. A supplementary video can be found at  https://youtu.be/3CeN0OGz2cA."}}
{"id": "xWf7U1wbpR0", "cdate": 1596118220434, "mdate": null, "content": {"title": "Multimodal Style Transfer via Graph Cuts", "abstract": "An assumption widely used in recent neural style transfer methods is that image styles can be described by global\nstatics of deep features like Gram or covariance matrices.\nAlternative approaches have represented styles by decomposing them into local pixel or neural patches. Despite the\nrecent progress, most existing methods treat the semantic\npatterns of style image uniformly, resulting unpleasing results on complex styles. In this paper, we introduce a more\nflexible and general universal style transfer technique: multimodal style transfer (MST). MST explicitly considers the\nmatching of semantic patterns in content and style images.\nSpecifically, the style image features are clustered into substyle components, which are matched with local content features under a graph cut formulation. A reconstruction network is trained to transfer each sub-style and render the final stylized result. We also generalize MST to improve some\nexisting methods. Extensive experiments demonstrate the\nsuperior effectiveness, robustness, and flexibility of MST"}}
{"id": "OQ1kMvxOPJ", "cdate": 1582301638387, "mdate": null, "content": {"title": "Salient Color Names for Person Re-identification", "abstract": "Color naming, which relates colors with color names, can\nhelp people with a semantic analysis of images in many computer vision\napplications. In this paper, we propose a novel salient color names based\ncolor descriptor (SCNCD) to describe colors. SCNCD utilizes salient color names to guarantee that a higher probability will be assigned\nto the color name which is nearer to the color. Based on SCNCD, color distributions over color names in different color spaces are then obtained and fused to generate a feature representation. Moreover, the\neffect of background information is employed and analyzed for person\nre-identification. With a simple metric learning method, the proposed\napproach outperforms the state-of-the-art performance (without user\u2019s\nfeedback optimization) on two challenging datasets (VIPeR and PRID\n450S). More importantly, the proposed feature can be obtained very fast\nif we compute SCNCD of each color in advance."}}
{"id": "C3A-7Q8Yw", "cdate": 1580440280824, "mdate": null, "content": {"title": "ON THE CONTINUITY OF ROTATION REPRESENTATIONS IN NEURAL NETWORKS ", "abstract": "In neural networks, it is often desirable to work with various representations of the same space. For example, 3D rotations can be represented with quaternions or Euler angles. In this paper, we advance a definition of a continuous representation, which can be helpful for training deep neural networks. We relate this to topological concepts such as homeomorphism and embedding. We then investigate what are continuous and discontinuous representations for 2D, 3D, and n-dimensional rotations. We demonstrate that for 3D rotations, all representations are discontinuous in the real Euclidean spaces of four or fewer dimensions. Thus, widely used representations such as quaternions and Euler angles are discontinuous and difficult for neural networks to learn. We show that the 3D rotations have continuous representations in 5D and 6D, which are more suitable for learning. We also present continuous representations for the general case of the n-dimensional rotation group SO(n). While our main focus is on rotations, we also show that our constructions apply to other groups such as the orthogonal group and similarity transforms. We finally present empirical results, which show that our continuous rotation representations outperform discontinuous ones for several practical problems in graphics and vision, including a simple autoencoder sanity test, a rotation estimator for 3D point clouds, and an inverse kinematics solver for 3D human poses. "}}
{"id": "HylvlaVtwr", "cdate": 1569438959172, "mdate": null, "content": {"title": "Learning to Sit: Synthesizing Human-Chair Interactions via Hierarchical Control", "abstract": "Recent progress on physics-based character animation has shown impressive breakthroughs on human motion synthesis, through imitating motion capture data via deep reinforcement learning. However, results have mostly been demonstrated on imitating a single distinct motion pattern, and do not generalize to interactive tasks that require flexible motion patterns due to varying human-object spatial configurations. To bridge this gap, we focus on one class of interactive tasks---sitting onto a chair. We propose a hierarchical reinforcement learning framework which relies on a collection of subtask controllers trained to imitate simple, reusable mocap motions, and a meta controller trained to execute the subtasks properly to complete the main task. We experimentally demonstrate the strength of our approach over different single level and hierarchical baselines. We also show that our approach can be applied to motion prediction given an image input. A video highlight can be found at https://youtu.be/XWU3wzz1ip8/.\n"}}
{"id": "BmYZsJXg_pS", "cdate": 1546300800000, "mdate": null, "content": {"title": "Foreground-Aware Image Inpainting.", "abstract": "Existing image inpainting methods typically fill holes by borrowing information from surrounding pixels. They often produce unsatisfactory results when the holes overlap with or touch foreground objects due to lack of information about the actual extent of foreground and background regions within the holes. These scenarios, however, are very important in practice, especially for applications such as distracting object removal. To address the problem, we propose a foreground-aware image inpainting system that explicitly disentangles structure inference and content completion. Specifically, our model learns to predict the foreground contour first, and then inpaints the missing region using the predicted contour as guidance. We show that by such disentanglement, the contour completion model predicts reasonable contours of objects, and further substantially improves the performance of image inpainting. Experiments show that our method significantly outperforms existing methods and achieves superior inpainting results on challenging cases with complex compositions."}}
{"id": "Bm0WEQ7euTr", "cdate": 1546300800000, "mdate": null, "content": {"title": "On the Continuity of Rotation Representations in Neural Networks.", "abstract": "In neural networks, it is often desirable to work with various representations of the same space. For example, 3D rotations can be represented with quaternions or Euler angles. In this paper, we advance a definition of a continuous representation, which can be helpful for training deep neural networks. We relate this to topological concepts such as homeomorphism and embedding. We then investigate what are continuous and discontinuous representations for 2D, 3D, and n-dimensional rotations. We demonstrate that for 3D rotations, all representations are discontinuous in the real Euclidean spaces of four or fewer dimensions. Thus, widely used representations such as quaternions and Euler angles are discontinuous and difficult for neural networks to learn. We show that the 3D rotations have continuous representations in 5D and 6D, which are more suitable for learning. We also present continuous representations for the general case of the n-dimensional rotation group SO(n). While our main focus is on rotations, we also show that our constructions apply to other groups such as the orthogonal group and similarity transforms. We finally present empirical results, which show that our continuous rotation representations outperform discontinuous ones for several practical problems in graphics and vision, including a simple autoencoder sanity test, a rotation estimator for 3D point clouds, and an inverse kinematics solver for 3D human poses."}}
