{"id": "7EBJG7VT36", "cdate": 1698565955154, "mdate": 1698565955154, "content": {"title": "Image-Consistent Detection of Road Anomalies As Unpredictable Patches", "abstract": "We propose a novel method for anomaly detection primarily aiming at autonomous driving. The design of the method, called DaCUP (Detection of anomalies as Consistent Unpredictable Patches), is based on two general properties of anomalous objects: an anomaly is (i) not from a class that could be modelled and (ii) it is not similar (in appearance) to non-anomalous objects in the image. To this end, we propose a novel embedding bottleneck in an auto-encoder like architecture that enables modelling of a diverse, multi-modal known class appearance (e.g. road). Secondly, we introduce novel image-conditioned distance features that allow known class identification in a nearest-neighbour manner on-the-fly, greatly increasing its ability to distinguish true and false positives. Lastly, an inpainting module is utilized to model the uniqueness of detected anomalies and significantly reduce false positives by filtering regions that are similar, thus reconstructable from their neighbourhood. We demonstrate that filtering of regions based on their similarity to neighbour regions, using e.g. an inpainting module, is general and can be used with other methods for reduction of false positives. The proposed method is evaluated on several publicly available datasets for road anomaly detection and on a maritime benchmark for obstacle avoidance. The method achieves state-of-the-art performance in both tasks with the same hyper-parameters with no domain specific design."}}
{"id": "GEn5yrQ5DgS", "cdate": 1672531200000, "mdate": 1698565826039, "content": {"title": "Calibrated Out-of-Distribution Detection with a Generic Representation", "abstract": "Out-of-distribution detection is a common issue in deploying vision models in practice and solving it is an essential building block in safety critical applications. Most of the existing OOD detection solutions focus on improving the OOD robustness of a classification model trained exclusively on in-distribution (ID) data. In this work, we take a different approach and propose to leverage generic pre-trained representation. We propose a novel OOD method, called GROOD, that formulates the OOD detection as a Neyman-Pearson task with well calibrated scores and which achieves excellent performance, predicated by the use of a good generic representation. Only a trivial training process is required for adapting GROOD to a particular problem. The method is simple, general, efficient, calibrated and with only a few hyper-parameters. The method achieves state-of-the-art performance on a number of OOD benchmarks, reaching near perfect performance on several of them. The source code is available at https://github.com/vojirt/GROOD."}}
{"id": "bD3SXk7Kmz", "cdate": 1667377254842, "mdate": 1667377254842, "content": {"title": "A Novel Performance Evaluation Methodology for Single-Target Trackers", "abstract": "This paper addresses the problem of single-target tracker performance evaluation. We consider the performance\nmeasures, the dataset and the evaluation system to be the most important components of tracker evaluation and propose\nrequirements for each of them. The requirements are the basis of a new evaluation methodology that aims at a simple and\neasily interpretable tracker comparison. The ranking-based methodology addresses tracker equivalence in terms of statistical\nsignificance and practical differences. A fully-annotated dataset with per-frame annotations with several visual attributes is\nintroduced. The diversity of its visual properties is maximized in a novel way by clustering a large number of videos according to\ntheir visual attributes. This makes it the most sophistically constructed and annotated dataset to date. A multi-platform evaluation\nsystem allowing easy integration of third-party trackers is presented as well. The proposed evaluation methodology was tested\non the VOT2014 challenge on the new dataset and 38 trackers, making it the largest benchmark to date. Most of the tested\ntrackers are indeed state-of-the-art since they outperform the standard baselines, resulting in a highly-challenging benchmark.\nAn exhaustive analysis of the dataset from the perspective of tracking difficulty is carried out. To facilitate tracker comparison a\nnew performance visualization technique is proposed."}}
{"id": "lnGbR8XNDcG", "cdate": 1667377026927, "mdate": 1667377026927, "content": {"title": "Discriminative Correlation Filter with Channel and Spatial Reliability", "abstract": "Short-term tracking is an open and challenging problem for which discriminative correlation filters (DCF) have\nshown excellent performance.We introduce the channel and\nspatial reliability concepts to DCF tracking and provide a\nnovel learning algorithm for its efficient and seamless integration in the filter update and the tracking process. The\nspatial reliability map adjusts the filter support to the part of\nthe object suitable for tracking. This both allows to enlarge\nthe search region and improves tracking of non-rectangular\nobjects. Reliability scores reflect channel-wise quality of\nthe learned filters and are used as feature weighting coefficients in localization. Experimentally, with only two simple\nstandard features, HoGs and Colornames, the novel CSRDCF method \u2013 DCF with Channel and Spatial Reliability\n\u2013 achieves state-of-the-art results on VOT 2016, VOT 2015\nand OTB100. The CSR-DCF runs in real-time on a CPU"}}
{"id": "kQXgte05mi", "cdate": 1667376840266, "mdate": 1667376840266, "content": {"title": "FuCoLoT\u2013a fully-correlational long-term tracker", "abstract": "We propose FuCoLoT \u2013 a Fully Correlational Long-term\nTracker. It exploits the novel DCF constrained filter learning method\nto design a detector that is able to re-detect the target in the whole\nimage efficiently. FuCoLoT maintains several correlation filters trained\non different time scales that act as the detector components. A novel\nmechanism based on the correlation response is used for tracking failure estimation. FuCoLoT achieves state-of-the-art results on standard\nshort-term benchmarks and it outperforms the current best-performing\ntracker on the long-term UAV20L benchmark by over 19%. It has an\norder of magnitude smaller memory footprint than its best-performing\ncompetitors and runs at 15fps in a single CPU thread."}}
{"id": "l7bTCvyHOC", "cdate": 1667376672088, "mdate": 1667376672088, "content": {"title": "Large scale joint semantic re-localisation and scene understanding via globally unique instance coordinate regression", "abstract": "In this work we present a novel approach to joint semantic localisation and scene\nunderstanding. Our work is motivated by the need for localisation algorithms which not\nonly predict 6-DoF camera pose but also simultaneously recognise surrounding objects\nand estimate 3D geometry. Such capabilities are crucial for computer vision guided systems which interact with the environment: autonomous driving, augmented reality and\nrobotics. In particular, we propose a two step procedure. During the first step we train\na convolutional neural network to jointly predict per-pixel globally unique instance labels [7] and corresponding local coordinates for each instance of a static object (e.g. a\nbuilding). During the second step we obtain scene coordinates [32] by combining object center coordinates and local coordinates and use them to perform 6-DoF camera\npose estimation. We evaluate our approach on real world (CamVid-360) and artificial\n(SceneCity) autonomous driving datasets [7]. We obtain smaller mean distance and angular errors than state-of-the-art 6-DoF pose estimation algorithms based on direct pose\nregression [14, 15] and pose estimation from scene coordinates [3] on all datasets. Our\ncontributions include: (i) a novel formulation of scene coordinate regression as two separate tasks of object instance recognition and local coordinate regression and a demonstration that our proposed solution allows to predict accurate 3D geometry of static objects\nand estimate 6-DoF pose of camera on (ii) maps larger by several orders of magnitude\nthan previously attempted by scene coordinate regression methods [3, 4, 20, 32], as well\nas on (iii) lightweight, approximate 3D maps built from 3D primitives such as buildingaligned cuboids."}}
{"id": "GhmHhbdiQzD", "cdate": 1667376570158, "mdate": 1667376570158, "content": {"title": "Performance Evaluation Methodology for Long-Term Single-Object Tracking", "abstract": "A long-term visual object tracking performance evaluation methodology and a benchmark are proposed. Performance measures are designed by following a long-term tracking definition to maximize the analysis probing strength. The new measures outperform existing ones in interpretation potential and in better distinguishing between different tracking behaviors. We show that these measures generalize the short-term performance measures, thus linking the two tracking problems. Furthermore, the new measures are highly robust to temporal annotation sparsity and allow annotation of sequences hundreds of times longer than in the current datasets without increasing manual annotation labor. A new challenging dataset of carefully selected sequences with many target disappearances is proposed. A new tracking taxonomy is proposed to position trackers on the short-term/long-term spectrum. The benchmark contains an extensive evaluation of the largest number of long-term trackers and comparison to state-of-the-art short-term trackers. We analyze the influence of tracking architecture implementations to long-term performance and explore various redetection strategies as well as the influence of visual model update strategies to long-term tracking drift. The methodology is integrated in the VOT toolkit to automate experimental analysis and benchmarking and to facilitate the future development of long-term trackers."}}
{"id": "RHUpJ_7uKOd", "cdate": 1667376399042, "mdate": 1667376399042, "content": {"title": "Efficient Large-Scale Semantic Visual Localization in 2D Maps", "abstract": "With the emergence of autonomous navigation systems, imagebased localization is one of the essential tasks to be tackled. However,\nmost of the current algorithms struggle to scale to city-size environments\nmainly because of the need to collect large (semi-)annotated datasets for\nCNN training and create databases for test environment of images, keypoint level features or image embeddings. This data acquisition is not\nonly expensive and time-consuming but also may cause privacy concerns.\nIn this work, we propose a novel framework for semantic visual localization in city-scale environments which alleviates the aforementioned\nproblem by using freely available 2D maps such as OpenStreetMap. Our\nmethod does not require any images or image-map pairs for training\nor test environment database collection. Instead, a robust embedding is\nlearned from a depth and building instance label information of a particular location in the 2D map. At test time, this embedding is extracted\nfrom a panoramic building instance label and depth images. It is then\nused to retrieve the closest match in the database.\nWe evaluate our localization framework on two large-scale datasets consisting of Cambridge and San Francisco cities with a total length of\ndrivable roads spanning over 500 km and including approximately 110k\nunique locations. To the best of our knowledge, this is the first large-scale\nsemantic localization method which works on par with approaches that\nrequire the availability of images at train time or for test environment\ndatabase creation."}}
{"id": "rWUfjvBdkO", "cdate": 1667376330477, "mdate": 1667376330477, "content": {"title": "Road Anomaly Detection by Partial Image Reconstruction With Segmentation Coupling", "abstract": "We present a novel approach to the detection of unknown\nobjects in the context of autonomous driving. The problem\nis formulated as anomaly detection, since we assume that\nthe unknown stuff or object appearance cannot be learned.\nTo that end, we propose a reconstruction module that can be\nused with many existing semantic segmentation networks,\nand that is trained to recognize and reconstruct road (drivable) surface from a small bottleneck. We postulate that\npoor reconstruction of the road surface is due to areas that\nare outside of the training distribution, which is a strong indicator of an anomaly. The road structural similarity error\nis coupled with the semantic segmentation to incorporate\ninformation from known classes and produce final per-pixel\nanomaly scores. The proposed JSR-Net was evaluated on\nfour datasets, Lost-and-found, Road Anomaly, Road Obstacles, and FishyScapes, achieving state-of-art performance\non all, reducing the false positives significantly, while typically having the highest average precision for wide range\nof operation points."}}
{"id": "PHSG1xD4Q1I", "cdate": 1609459200000, "mdate": 1668021898346, "content": {"title": "Road Anomaly Detection by Partial Image Reconstruction with Segmentation Coupling", "abstract": "We present a novel approach to the detection of unknown objects in the context of autonomous driving. The problem is formulated as anomaly detection, since we assume that the unknown stuff or object appearance cannot be learned. To that end, we propose a reconstruction module that can be used with many existing semantic segmentation networks, and that is trained to recognize and reconstruct road (drivable) surface from a small bottleneck. We postulate that poor reconstruction of the road surface is due to areas that are outside of the training distribution, which is a strong indicator of an anomaly. The road structural similarity error is coupled with the semantic segmentation to incorporate information from known classes and produce final per-pixel anomaly scores. The proposed JSR-Net was evaluated on four datasets, Lost-and-found, Road Anomaly, Road Obstacles, and FishyScapes, achieving state-of-art performance on all, reducing the false positives significantly, while typically having the highest average precision for wide range of operation points."}}
