{"id": "CQX7GnyYYja", "cdate": 1672531200000, "mdate": 1681657005707, "content": {"title": "Improved Exact and Heuristic Algorithms for Maximum Weight Clique", "abstract": "We propose improved exact and heuristic algorithms for solving the maximum weight clique problem, a well-known problem in graph theory with many applications. Our algorithms interleave successful techniques from related work with novel data reduction rules that use local graph structure to identify and remove vertices and edges while retaining the optimal solution. We evaluate our algorithms on a range of synthetic and real-world graphs, and find that they outperform the current state of the art on most inputs. Our data reductions always produce smaller reduced graphs than existing data reductions alone. As a result, our exact algorithm, MWCRedu, finds solutions orders of magnitude faster on naturally weighted, medium-sized map labeling graphs and random hyperbolic graphs. Our heuristic algorithm, MWCPeel, outperforms its competitors on these instances, but is slightly less effective on extremely dense or large instances."}}
{"id": "fe1DEN1nds", "cdate": 1662812636961, "mdate": null, "content": {"title": "Gradual Weisfeiler-Leman: Slow and Steady Wins the Race", "abstract": "The classical Weisfeiler-Leman algorithm aka color refinement is fundamental for graph learning with kernels and neural networks. Originally developed for graph isomorphism testing, the algorithm iteratively refines vertex colors. On many datasets, the stable coloring is reached after a few iterations and the optimal number of iterations for machine learning tasks is typically even lower. This suggests that the colors diverge too fast, defining a similarity that is too coarse. We generalize the concept of color refinement and propose a framework for gradual neighborhood refinement, which allows a slower convergence to the stable coloring and thus provides a more fine-grained refinement hierarchy and vertex similarity. We assign new colors by clustering vertex neighborhoods, replacing the original injective color assignment function. Our approach is used to derive new variants of existing graph kernels and to approximate the graph edit distance via optimal assignments regarding vertex similarity. We show that in both tasks, our method outperforms the original color refinement with only a moderate increase in running time advancing the state of the art."}}
{"id": "0qq0j5phKrE", "cdate": 1655704390117, "mdate": null, "content": {"title": "A Temporal Graphlet Kernel for Classifying Dissemination in Evolving Networks", "abstract": "We introduce the \\emph{temporal graphlet kernel} for classifying dissemination processes in labeled temporal graphs. Such dissemination processes can be spreading (fake) news, infectious diseases, or computer viruses in dynamic networks. The networks are modeled as labeled temporal graphs, in which the edges exist at specific points in time, and node labels change over time. The classification problem asks to discriminate dissemination processes of different origins or parameters, e.g., infectious diseases with different infection probabilities.  \nOur new kernel represents labeled temporal graphs in the feature space of temporal graphlets, i.e., small subgraphs distinguished by their structure, time-dependent node labels, and chronological order of edges.\nWe introduce variants of our kernel based on classes of graphlets that are efficiently countable.\nFor the case of temporal wedges, we propose a highly efficient approximative kernel with low error in expectation.\nWe show that our kernels are faster to compute and provide better accuracy than state-of-the-art methods."}}
{"id": "Inj9ed0mzQb", "cdate": 1652737572610, "mdate": null, "content": {"title": "Weisfeiler and Leman Go Walking: Random Walk Kernels Revisited", "abstract": "Random walk kernels have been introduced in seminal work on graph learning and were later largely superseded by kernels based on the Weisfeiler-Leman test for graph isomorphism. We give a unified view on both classes of graph kernels. We study walk-based node refinement methods and formally relate them to several widely-used techniques, including Morgan's algorithm for molecule canonization and the Weisfeiler-Leman test. We define corresponding walk-based kernels on nodes that allow fine-grained parameterized neighborhood comparison, reach Weisfeiler-Leman expressiveness, and are computed using the kernel trick. From this we show that classical random walk kernels with only minor modifications regarding definition and computation are as expressive as the widely-used Weisfeiler-Leman subtree kernel but support non-strict neighborhood comparison. We verify experimentally that walk-based kernels reach or even surpass the accuracy of Weisfeiler-Leman kernels in real-world classification tasks."}}
{"id": "dsZS4xiZKlh", "cdate": 1640995200000, "mdate": 1672818120734, "content": {"title": "Temporal Walk Centrality: Ranking Nodes in Evolving Networks", "abstract": ""}}
{"id": "bAASI0bVE-j", "cdate": 1640995200000, "mdate": 1681657005399, "content": {"title": "EmbAssi: embedding assignment costs for similarity search in large graph databases", "abstract": "The graph edit distance is an intuitive measure to quantify the dissimilarity of graphs, but its computation is $$\\mathsf {NP}$$ NP -hard and challenging in practice. We introduce methods for answering nearest neighbor and range queries regarding this distance efficiently for large databases with up to millions of graphs. We build on the filter-verification paradigm, where lower and upper bounds are used to reduce the number of exact computations of the graph edit distance. Highly effective bounds for this involve solving a linear assignment problem for each graph in the database, which is prohibitive in massive datasets. Index-based approaches typically provide only weak bounds leading to high computational costs verification. In this work, we derive novel lower bounds for efficient filtering from restricted assignment problems, where the cost function is a tree metric. This special case allows embedding the costs of optimal assignments isometrically into $$\\ell _1$$ \u2113 1 space, rendering efficient indexing possible. We propose several lower bounds of the graph edit distance obtained from tree metrics reflecting the edit costs, which are combined for effective filtering. Our method termed EmbAssi can be integrated into existing filter-verification pipelines as a fast and effective pre-filtering step. Empirically we show that for many real-world graphs our lower bounds are already close to the exact graph edit distance, while our index construction and search scales to very large databases."}}
{"id": "UaOGX0YmBsh", "cdate": 1640995200000, "mdate": 1681657005581, "content": {"title": "Graph-Based Methods for Rational Drug Design", "abstract": "Rational drug design deals with computational methods to accelerate the development of new drugs. Among other tasks, it is necessary to analyze huge databases of small molecules. Since a direct relationship between the structure of these molecules and their effect (e.g., toxicity) can be assumed in many cases, a wide set of methods is based on the modeling of the molecules as graphs with attributes. Here, we discuss our results concerning structural molecular similarity searches and molecular clustering and put them into the wider context of graph similarity search. In particular, we discuss algorithms for computing graph similarity w.r.t.\u00a0maximum common subgraphs and their extension to domain specific requirements."}}
{"id": "-p0wc3fzdG", "cdate": 1640995200000, "mdate": 1681657005483, "content": {"title": "Gradual Weisfeiler-Leman: Slow and Steady Wins the Race", "abstract": "The classical Weisfeiler-Leman algorithm aka color refinement is fundamental for graph learning with kernels and neural networks. Originally developed for graph isomorphism testing, the algorithm i..."}}
{"id": "aBPWSqRMd4", "cdate": 1609459200000, "mdate": 1681657005344, "content": {"title": "The Power of the Weisfeiler-Leman Algorithm for Machine Learning with Graphs", "abstract": "In recent years, algorithms and neural architectures based on the Weisfeiler-Leman algorithm, a well-known heuristic for the graph isomorphism problem, emerged as a powerful tool for (supervised) machine learning with graphs and relational data. Here, we give a comprehensive overview of the algorithm's use in a machine learning setting. We discuss the theoretical background, show how to use it for supervised graph- and node classification, discuss recent extensions, and its connection to neural architectures. Moreover, we give an overview of current applications and future directions to stimulate research."}}
{"id": "NcAj-ZzrXIV", "cdate": 1609459200000, "mdate": null, "content": {"title": "Fixed-parameter algorithms for the weighted Max-Cut problem on embedded 1-planar graphs", "abstract": "We propose two fixed-parameter tractable algorithms for the weighted Max-Cut problem on embedded 1-planar graphs parameterized by the crossing number k of the given embedding. A graph is called 1-planar if it can be drawn in the plane with at most one crossing per edge. Our algorithms recursively reduce a 1-planar graph to at most 3 k planar graphs, using edge removal and node contraction. Our main algorithm then solves the Max-Cut problem for the planar graphs using the FCE-MaxCut introduced by Liers and Pardella [23]. In the case of non-negative edge weights, we suggest a variant that allows to solve the planar instances with any planar Max-Cut algorithm. We show that a maximum cut in the given 1-planar graph can be derived from the solutions for the planar graphs. Our algorithms compute a maximum cut in an embedded weighted 1-planar graph with n nodes and k edge crossings in time O ( 3 k \u22c5 n 3 / 2 log \u2061 n ) ."}}
