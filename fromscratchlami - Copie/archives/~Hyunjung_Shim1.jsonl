{"id": "gpmnDy75lc", "cdate": 1682899200000, "mdate": 1681695196814, "content": {"title": "CoMix: Collaborative filtering with mixup for implicit datasets", "abstract": ""}}
{"id": "pS5e1JZkZO", "cdate": 1672531200000, "mdate": 1677844299367, "content": {"title": "Evaluation for Weakly Supervised Object Localization: Protocol, Metrics, and Datasets", "abstract": ""}}
{"id": "WZvGYnGkrJg", "cdate": 1672531200000, "mdate": 1681695196855, "content": {"title": "HybridMatch: Semi-Supervised Facial Landmark Detection via Hybrid Heatmap Representations", "abstract": "Facial landmark detection is an essential task in face-processing techniques. Traditional methods, however, require expensive pixel-level labels. Semi-supervised facial landmark detection has been explored as an alternative, but previous approaches only focus on training-oriented issues (e.g., noisy pseudo-labels in semi-supervised learning), neglecting task-oriented issues (i.e., the quantization error in landmark detection). We argue that semi-supervised landmark detectors should resolve the two technical issues simultaneously. Through a simple experiment, we found that task- and training-oriented solutions may negatively influence each other, thus eliminating their negative interactions is important. To this end, we devise a new heatmap regression framework via hybrid representation, namely HybridMatch. We utilize both 1-D and 2-D heatmap representations. Here, the 1-D and 2-D heatmaps help alleviate the task-oriented and training-oriented issues, respectively. To exploit the advantages of our hybrid representation, we introduce curriculum learning; relying more on the 2-D heatmap at the early training stage and gradually increasing the effects of the 1-D heatmap. By resolving the two issues simultaneously, we can capture more precise landmark points than existing methods with only a few annotated data. Extensive experiments show that HybridMatch achieves state-of-the-art performance on three benchmark datasets, especially showing 26.3% NME improvement over the existing method in the 300-W full set at 5% data ratio. Surprisingly, our method records a comparable performance, 5.04 (challenging set in the 300-W) to the fully-supervised facial landmark detector 5.03. The remarkable performance of HybridMatch shows its potential as a practical alternative to the fully-supervised model."}}
{"id": "-N9jH73x8n5", "cdate": 1669819383145, "mdate": null, "content": {"title": "Cell Segmentation in Multi-modality High-Resolution Microscopy Images with Cellpose", "abstract": "Deep learning has achieved great results in microscopy image processing in the field of Biology. However, a generalized model is needed which can solve overfitting and produce good performance for test images and unseen classes. The reason why it is difficult to make a generalized model is because of the diversity of modality, staining methods, cell shapes and resolution of microscopy images. The dataset of the \"Weakly Supervised Cell Segmentation in Multi-modality High-Resolution Microscopy Images\" challenge consists of images with these diverse characteristics. Therefore, we trained cellpose to perform instance segmentation well on dataset having various characteristics. In order to apply the cellpose model to the challenge dataset, we designated model to always use green and blue channels for any type of images. What\u2019s more we newly created the size estimation model predicting diameter of cell to operate on various resolutions. As a result, we could achieve F1 score 0.7607 for the validation (Tuning) set."}}
{"id": "m26O3Cx4UhM", "cdate": 1668594693188, "mdate": 1668594693188, "content": {"title": "Face Generation for Low-shot Learning using Generative Adversarial Networks", "abstract": "Recently, low-shot learning has been proposed for handling the lack of training data in machine learning. Despite of the importance of this issue, relatively less efforts have been made to study this problem. In this paper, we aim to increase the size of training dataset in various ways to improve the accuracy and robustness of face recognition. In detail, we adapt a generator from the Generative Adversarial Network (GAN) to increase the size of training dataset, which includes a base set, a widely available dataset, and a novel set, a given limited dataset, while adopting transfer learning as a backend. Based on extensive experimental study, we conduct the analysis on various data augmentation methods, observing how each affects the identification accuracy. Finally, we conclude that the proposed algorithm for generating faces is effective in improving the identification accuracy and coverage at the precision of 99% using both the base and novel set."}}
{"id": "oon0bbZKEFp", "cdate": 1668594515030, "mdate": 1668594515030, "content": {"title": "Threshold Matters in WSSS: Manipulating the Activation for the Robust and Accurate Segmentation Model Against Thresholds", "abstract": "Weakly-supervised semantic segmentation (WSSS) has recently gained much attention for its promise to train segmentation models only with image-level labels. Existing WSSS methods commonly argue that the sparse coverage of CAM incurs the performance bottleneck of WSSS. This paper provides analytical and empirical evidence that the actual bottleneck may not be sparse coverage but a global\nthresholding scheme applied after CAM. Then, we show that this issue can be mitigated by satisfying two conditions; 1)\nreducing the imbalance in the foreground activation and 2) increasing the gap between the foreground and the background activation. Based on these findings, we propose a novel activation manipulation network with a per-pixel classification loss and a label conditioning module. Per-pixel classification naturally induces two-level activation in activation maps, which can penalize the most discriminative parts, promote the less discriminative parts, and deactivate the background regions. Label conditioning imposes that the output label of pseudo-masks should be any of true image-level labels; it penalizes the wrong activation assigned to non-target classes. Based on extensive analysis and evaluations, we demonstrate that each component helps produce accurate pseudo-masks, achieving the robustness against the choice of the global threshold. Finally, our model achieves state-of-the-art records on both PASCAL VOC 2012 and MS COCO 2014 datasets. The code is available at https://github.com/gaviotas/AMN."}}
{"id": "N7mnNY31EOX", "cdate": 1664816287623, "mdate": null, "content": {"title": "Generic and Privacy-free Synthetic Data Generation for Pretraining GANs", "abstract": "Transfer learning for GANs successfully improves low-shot generation performance. However, existing studies show that the pretrained model using a single benchmark dataset is not generalized to various datasets. More importantly, the pretrained model can be vulnerable to copyright or privacy risks. To resolve both issues, we propose an effective and unbiased data synthesizer, namely Primitives-PS, inspired by the generic characteristics of natural images. \nSince Primitives-PS only considers the generic properties of natural images, the images are free from copyright and privacy issues. In addition, the single model pretrained on our dataset can be transferred to various target datasets. Extensive analysis demonstrates that each component of our data synthesizer is effective, and provides insights on the desirable nature of the pretrained model for the transferability of GANs. For better reproducibility and implementation details we provide the source code at https://github.com/FriedRonaldo/Primitives-PS."}}
{"id": "7BSqGYzm5PT", "cdate": 1664154170357, "mdate": 1664154170357, "content": {"title": "Few-shot Font Generation with Weakly Supervised Localized Representations", "abstract": "Automatic few-shot font generation aims to solve a well-defined, real-world problem because manual font designs are expensive and sensitive to the expertise of designers. Existing methods learn to disentangle style and content elements by developing a universal style representation for each font style. However, this approach limits the model in representing diverse local styles, because it is unsuitable for complicated letter systems, for example, Chinese, whose characters consist of a varying number of components (often called \"radical\") -- with a highly complex structure. In this paper, we propose a novel font generation method that learns localized styles, namely component-wise style representations, instead of universal styles. The proposed style representations enable the synthesis of complex local details in text designs. However, learning component-wise styles solely from a few reference glyphs is infeasible when a target script has a large number of components, for example, over 200 for Chinese. To reduce the number of required reference glyphs, we represent component-wise styles by a product of component and style factors, inspired by low-rank matrix factorization. Owing to the combination of strong representation and a compact factorization strategy, our method shows remarkably better few-shot font generation results (with only eight reference glyphs) than other state-of-the-art methods. Moreover, strong locality supervision, for example, location of each component, skeleton, or strokes, was not utilized. The source code is available at this https URL and this https URL.\n"}}
{"id": "aP0GcsTyUwB", "cdate": 1664154110450, "mdate": null, "content": {"title": "Multiple Heads are Better than One: Few-shot Font Generation with Multiple Localized Experts", "abstract": "A few-shot font generation (FFG) method has to satisfy two objectives: the generated images should preserve the underlying global structure of the target character and present the diverse local reference style. Existing FFG methods aim to disentangle content and style either by extracting a universal representation style or extracting multiple component-wise style representations. However, previous methods either fail to capture diverse local styles or cannot be generalized to a character with unseen components, e.g., unseen language systems. To mitigate the issues, we propose a novel FFG method, named Multiple Localized Experts Few-shot Font Generation Network (MX-Font). MX-Font extracts multiple style features not explicitly conditioned on component labels, but automatically by multiple experts to represent different local concepts, e.g., left-side sub-glyph. Owing to the multiple experts, MX-Font can capture diverse local concepts and show the generalizability to unseen languages. During training, we utilize component labels as weak supervision to guide each expert to be specialized for different local concepts. We formulate the component assign problem to each expert as the graph matching problem, and solve it by the Hungarian algorithm. We also employ the independence loss and the content-style adversarial loss to impose the content-style disentanglement. In our experiments, MX-Font outperforms previous state-of-the-art FFG methods in the Chinese generation and cross-lingual, e.g., Chinese to Korean, generation. Source code is available at this https URL.\n"}}
{"id": "zEvfmJdTFjC", "cdate": 1640995200000, "mdate": 1668048773814, "content": {"title": "Threshold Matters in WSSS: Manipulating the Activation for the Robust and Accurate Segmentation Model Against Thresholds", "abstract": ""}}
