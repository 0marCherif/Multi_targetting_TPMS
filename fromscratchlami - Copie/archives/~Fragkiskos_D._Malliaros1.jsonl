{"id": "UJ9_wmscwk", "cdate": 1632875667876, "mdate": null, "content": {"title": "Learning Graph Representations for Influence Maximization", "abstract": "As the field of machine learning for combinatorial optimization advances, traditional problems are resurfaced and readdressed through this new perspective. The overwhelming majority of the literature focuses on small graph problems, while several real-world problems are devoted to large graphs. Here, we focus on two such problems: influence estimation, a #P-hard counting problem, and influence maximization, an NP-hard problem. We develop Glie, a Graph Neural Network (GNN) that inherently parameterizes an upper bound of influence estimation and train it on small simulated graphs. Experiments show that Glie provides accurate influence estimation for real graphs up to 10 times larger than the train set. More importantly, it can be used for influence maximization on considerably larger graphs, as the predictions ranking is not affected by the drop of accuracy. We develop a version of Cost Effective Lazy Forward optimization with Glie instead of simulated influence estimation, surpassing the benchmark for influence maximization, although with a computational overhead. To balance the time complexity and quality of influence, we propose two different approaches. The first is a Q-network that learns to choose seeds sequentially using Glie's predictions. The second defines a provably submodular function based on Glie's representations to rank nodes fast while building the seed set. The latter provides the best combination of time efficiency and influence spread, outperforming SOTA benchmarks."}}
{"id": "EmAG9XMiFMe", "cdate": 1609459200000, "mdate": null, "content": {"title": "GraphSVX: Shapley Value Explanations for Graph Neural Networks", "abstract": "Graph Neural Networks (GNNs) achieve significant performance for various learning tasks on geometric data due to the incorporation of graph structure into the learning of node representations, which renders their comprehension challenging. In this paper, we first propose a unified framework satisfied by most existing GNN explainers. Then, we introduce GraphSVX, a post hoc local model-agnostic explanation method specifically designed for GNNs. GraphSVX is a decomposition technique that captures the \"fair\" contribution of each feature and node towards the explained prediction by constructing a surrogate model on a perturbed dataset. It extends to graphs and ultimately provides as explanation the Shapley Values from game theory. Experiments on real-world and synthetic datasets demonstrate that GraphSVX achieves state-of-the-art performance compared to baseline models while presenting core theoretical and human-centric properties."}}
{"id": "ArZBNebrPua", "cdate": 1609459200000, "mdate": null, "content": {"title": "Topic-aware latent models for representation learning on networks", "abstract": "Highlights \u2022 We introduce TNE which is a novel topic-aware network representation learning model. \u2022 We show how latent community models can be utilized to learn topical representations. \u2022 We illustrate the flexibility of the TNE framework to use latent community models. \u2022 We evaluate the performance of models in node classification and link prediction. Abstract Network representation learning (NRL) methods have received significant attention over the last years thanks to their success in several graph analysis problems, including node classification, link prediction and clustering. Such methods aim to map each vertex of the network into a low dimensional space in a way that the structural information of the network is preserved. Of particular interest are methods based on random walks; such methods transform the network into a collection of node sequences, aiming to learn node representations by predicting the context of each node within the sequence. In this paper, we introduce TNE, a generic framework to enhance the embeddings of nodes acquired by means of random walk-based approaches with topic-based information. Similar to the concept of topical word embeddings in Natural Language Processing, the proposed model first assigns each node to a latent community with the favor of various statistical graph models and community detection methods, and then learns the enhanced topic-aware representations. We evaluate our methodology in two downstream tasks: node classification and link prediction. The experimental results demonstrate that by incorporating node and community embeddings, we are able to outperform widely-known baseline NRL models."}}
{"id": "yGi36QsBfvI", "cdate": 1577836800000, "mdate": null, "content": {"title": "Exponential Family Graph Embeddings", "abstract": "Representing networks in a low dimensional latent space is a crucial task with many interesting applications in graph learning problems, such as link prediction and node classification. A widely applied network representation learning paradigm is based on the combination of random walks for sampling context nodes and the traditional Skip-Gram model to capture center-context node relationships. In this paper, we emphasize on exponential family distributions to capture rich interaction patterns between nodes in random walk sequences. We introduce the generic exponential family graph embedding model, that generalizes random walk-based network representation learning techniques to exponential family conditional distributions. We study three particular instances of this model, analyzing their properties and showing their relationship to existing unsupervised learning models. Our experimental evaluation on real-world datasets demonstrates that the proposed techniques outperform well-known baseline methods in two downstream machine learning tasks."}}
{"id": "tRAwJec_7q", "cdate": 1577836800000, "mdate": null, "content": {"title": "The core decomposition of networks: theory, algorithms and applications", "abstract": "The core decomposition of networks has attracted significant attention due to its numerous applications in real-life problems. Simply stated, the core decomposition of a network (graph) assigns to each graph node v, an integer number c(v) (the core number), capturing how well v is connected with respect to its neighbors. This concept is strongly related to the concept of graph degeneracy, which has a long history in graph theory. Although the core decomposition concept is extremely simple, there is an enormous interest in the topic from diverse application domains, mainly because it can be used to analyze a network in a simple and concise manner by quantifying the significance of graph nodes. Therefore, there exists a respectable number of research works that either propose efficient algorithmic techniques under different settings and graph types or apply the concept to another problem or scientific area. Based on this large interest in the topic, in this survey, we perform an in-depth discussion of core decomposition, focusing mainly on: (i) the basic theory and fundamental concepts, (ii) the algorithmic techniques proposed for computing it efficiently under different settings, and (iii) the applications that can benefit significantly from it."}}
{"id": "ljrel2okaIF", "cdate": 1577836800000, "mdate": null, "content": {"title": "Influence Maximization Using Influence and Susceptibility Embeddings", "abstract": "Finding a set of users that can maximize the spread of information in a social network is an important problem in social media analysis \u2014 being a critical part of several real-world applications such as viral marketing, political advertising and epidemiology. Although influence maximization has been studied extensively in the past, the majority of works focus on the algorithmic aspect of the problem, overlooking several practical improvements that can be derived by data-driven observations or the inclusion of machine learning. The main challenges of realistic influence maximization is on the one hand the computational demand of the diffusion models' repetitive simulations, and on the other the accuracy of the estimated influence spread. In this work, we propose Celfie, an influence maximization method that utilizes learnt influence representations from diffusion cascades to overcome the use of diffusion models. It comprises of two parts. The first is based on Inf2vec, an unsupervised learning model that embeds influence relationships between nodes from a set of diffusion cascades. We create a new version of the model, based on observations from influence analysis on a large scale dataset, to match the scalability needs and the purpose of influence maximization. The second part capitalizes on the learned representations to redefine the traditional live-edge model sampling for the computation of the marginal gain. For evaluation, we apply our method in the Sina Weibo and Microsoft Academic Graph datasets, two large scale networks accompanied by diffusion cascades. We observe that our algorithm outperforms various baseline methods in terms of seed set quality and speed. In addition, the proposed Inf2vec modification for influence maximization provides substantial computational advantages in the price of a minuscule loss in the influence spread."}}
{"id": "YXh_eyBe_Kk", "cdate": 1577836800000, "mdate": null, "content": {"title": "NodeSig: Random Walk Diffusion meets Hashing for Scalable Graph Embeddings", "abstract": "Graph Representation Learning (GRL) has become a key paradigm in network analysis, with a plethora of interdisciplinary applications. As the scale of networks increases, most of the widely used learning-based graph representation models also face computational challenges. While there is a recent effort toward designing algorithms that solely deal with scalability issues, most of them behave poorly in terms of accuracy on downstream tasks. In this paper, we aim to study models that balance the trade-off between efficiency and accuracy. In particular, we propose NodeSig, a scalable model that computes binary node representations. NodeSig exploits random walk diffusion probabilities via stable random projections towards efficiently computing embeddings in the Hamming space. Our extensive experimental evaluation on various networks has demonstrated that the proposed model achieves a good balance between accuracy and efficiency compared to well-known baseline models on the node classification and link prediction tasks."}}
{"id": "zbVpvAjrXo3", "cdate": 1546300800000, "mdate": null, "content": {"title": "Kernel Node Embeddings", "abstract": "Learning representations of nodes in a low dimensional space is a crucial task with many interesting applications in network analysis, including link prediction and node classification. Two popular approaches for this problem include matrix factorization and random walk-based models. In this paper, we aim to bring together the best of both worlds, towards learning latent node representations. In particular, we propose a weighted matrix factorization model which encodes random walk-based information about the nodes of the graph. The main benefit of this formulation is that it allows to utilize kernel functions on the computation of the embeddings. We perform an empirical evaluation on real-world networks, showing that the proposed model outperforms baseline node embedding algorithms in two downstream machine learning tasks."}}
{"id": "dtg9k1UAFS_", "cdate": 1546300800000, "mdate": null, "content": {"title": "Perturb and combine to identify influential spreaders in real-world networks", "abstract": "Some of the most effective influential spreader detection algorithms are unstable to small perturbations of the network structure. Inspired by bagging in Machine Learning, we propose the first Perturb and Combine (P&C) procedure for networks. It (1) creates many perturbed versions of a given graph, (2) applies a node scoring function separately to each graph, and (3) combines the results. Experiments conducted on real-world networks of various sizes with the k-core, generalized k-core, and PageRank algorithms reveal that P&C brings substantial improvements. Moreover, this performance boost can be obtained at almost no extra cost through parallelization. Finally, a bias-variance analysis suggests that P&C works mainly by reducing bias, and that therefore, it should be capable of improving the performance of all vertex scoring functions, including stable ones. An extended version of this paper is provided by [1]."}}
{"id": "ateIb2e3t0p", "cdate": 1546300800000, "mdate": null, "content": {"title": "Exponential Family Graph Embeddings", "abstract": "Representing networks in a low dimensional latent space is a crucial task with many interesting applications in graph learning problems, such as link prediction and node classification. A widely applied network representation learning paradigm is based on the combination of random walks for sampling context nodes and the traditional \\textit{Skip-Gram} model to capture center-context node relationships. In this paper, we emphasize on exponential family distributions to capture rich interaction patterns between nodes in random walk sequences. We introduce the generic \\textit{exponential family graph embedding} model, that generalizes random walk-based network representation learning techniques to exponential family conditional distributions. We study three particular instances of this model, analyzing their properties and showing their relationship to existing unsupervised learning models. Our experimental evaluation on real-world datasets demonstrates that the proposed techniques outperform well-known baseline methods in two downstream machine learning tasks."}}
