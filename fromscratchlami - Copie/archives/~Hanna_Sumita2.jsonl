{"id": "BjVnPkS3TY0", "cdate": 1640995200000, "mdate": 1653057326637, "content": {"title": "Fair and Truthful Mechanism with Limited Subsidy", "abstract": ""}}
{"id": "70kx7GrTUFs", "cdate": 1640995200000, "mdate": 1653057326633, "content": {"title": "Online Scheduling on Identical Machines with a Metric State Space", "abstract": "This paper introduces an online scheduling problem on m identical machines with a metric state space, which generalizes the classical online scheduling problem on identical machines, the online traveling salesman problem, and the online dial-a-ride problem. Each job is associated with a source state, a destination state, a processing time, and a release time. Each machine can process a job on and after its release time. Before processing a job, a machine needs to change its state to the source state (in a time corresponding to the distance), and after the process of the job, the machine\u2019s state becomes the destination state. While related research deals with a model in which only release times are unknown to the algorithm, this paper focuses on a general model in which destination states and processing times are also unknown. The main result of this paper is to propose a O(log m/log log m)-competitive online algorithm for the problem, which is best possible. A key approach is to divide the difficulty of the problem. To cope with unknown release times, we provide frameworks to produce a min{2\u03c1+1/2, \u03c1+2}-competitive algorithm using a \u03c1-competitive algorithm for a basic case where all jobs are released at time 0. Then, focusing on unknown destination states and processing times, we construct an O(log m/log log m)-competitive algorithm for the basic case. We also provide improved algorithms for some special cases."}}
{"id": "2kf1DVaT-9Z", "cdate": 1640995200000, "mdate": 1653057326635, "content": {"title": "Online Task Assignment Problems with Reusable Resources", "abstract": "We study online task assignment problem with reusable resources, motivated by practical applications such as ridesharing, crowdsourcing and job hiring. In the problem, we are given a set of offline vertices (agents), and, at each time, an online vertex (task) arrives randomly according to a known time-dependent distribution. Upon arrival, we assign the task to agents immediately and irrevocably. The goal of the problem is to maximize the expected total profit produced by completed tasks. The key features of our problem are (1) an agent is reusable, i.e., an agent comes back to the market after completing the assigned task, (2) an agent may reject the assigned task to stay the market, and (3) a task may accommodate multiple agents. The setting generalizes that of existing work in which an online task is assigned to one agent under (1). In this paper, we propose an online algorithm that is $1/2$-competitive for the above setting, which is tight. Moreover, when each agent can reject assigned tasks at most $\\Delta$ times, the algorithm is shown to have the competitive ratio $\\Delta/(3\\Delta-1)\\geq 1/3$. We also evaluate our proposed algorithm with numerical experiments."}}
{"id": "pSgdYWOI6S6", "cdate": 1609459200000, "mdate": 1653057326634, "content": {"title": "Online Max-min Fair Allocation", "abstract": "We study an online version of the max-min fair allocation problem for indivisible items. In this problem, items arrive one by one, and each item must be allocated irrevocably on arrival to one of $n$ agents, who have additive valuations for the items. Our goal is to make the least happy agent as happy as possible. In research on the topic of online allocation, this is a fundamental and natural problem. Our main result is to reveal the asymptotic competitive ratios of the problem for both the adversarial and i.i.d. input models. We design a polynomial-time deterministic algorithm that is asymptotically $1/n$-competitive for the adversarial model, and we show that this guarantee is optimal. To this end, we present a randomized algorithm with the same competitive ratio first and then derandomize it. A natural derandomization fails to achieve the competitive ratio of $1/n$. We instead build the algorithm by introducing a novel technique. When the items are drawn from an unknown identical and independent distribution, we construct a simple polynomial-time deterministic algorithm that outputs a nearly optimal allocation. We analyze the strict competitive ratio and show almost tight bounds for the solution. We further mention some implications of our results on variants of the problem."}}
{"id": "eWS-KNcIDJv", "cdate": 1609459200000, "mdate": 1653057326633, "content": {"title": "Near-Optimal Regret Bounds for Contextual Combinatorial Semi-Bandits with Linear Payoff Functions", "abstract": "The contextual combinatorial semi-bandit problem with linear payoff functions is a decision-making problem in which a learner chooses a set of arms with the feature vectors in each round under given constraints so as to maximize the sum of rewards of arms. Several existing algorithms have regret bounds that are optimal with respect to the number of rounds T. However, there is a gap of \u00d5(max(\u221ad, \u221ak)) between the current best upper and lower bounds, where d is the dimension of the feature vectors, k is the number of the chosen arms in a round, and \u00d5(\u00b7) ignores the logarithmic factors. The dependence of k and d is of practical importance because k may be larger than T in real-world applications such as recommender systems. In this paper, we fill the gap by improving the upper and lower bounds. More precisely, we show that the C2UCB algorithm proposed by Qin, Chen, and Zhu (2014) has the optimal regret bound \u00d5(d\u221akT + dk) for the partition matroid constraints. For general constraints, we propose an algorithm that modifies the reward estimates of arms in the C2UCB algorithm and demonstrate that it enjoys the optimal regret bound for a more general problem that can take into account other objectives simultaneously. We also show that our technique would be applicable to related problems. Numerical experiments support our theoretical results and considerations."}}
{"id": "aiiYxJnnGcR", "cdate": 1609459200000, "mdate": 1653057326752, "content": {"title": "Near-Optimal Regret Bounds for Contextual Combinatorial Semi-Bandits with Linear Payoff Functions", "abstract": "The contextual combinatorial semi-bandit problem with linear payoff functions is a decision-making problem in which a learner chooses a set of arms with the feature vectors in each round under given constraints so as to maximize the sum of rewards of arms. Several existing algorithms have regret bounds that are optimal with respect to the number of rounds $T$. However, there is a gap of $\\tilde{O}(\\max(\\sqrt{d}, \\sqrt{k}))$ between the current best upper and lower bounds, where $d$ is the dimension of the feature vectors, $k$ is the number of the chosen arms in a round, and $\\tilde{O}(\\cdot)$ ignores the logarithmic factors. The dependence of $k$ and $d$ is of practical importance because $k$ may be larger than $T$ in real-world applications such as recommender systems. In this paper, we fill the gap by improving the upper and lower bounds. More precisely, we show that the C${}^2$UCB algorithm proposed by Qin, Chen, and Zhu (2014) has the optimal regret bound $\\tilde{O}(d\\sqrt{kT} + dk)$ for the partition matroid constraints. For general constraints, we propose an algorithm that modifies the reward estimates of arms in the C${}^2$UCB algorithm and demonstrate that it enjoys the optimal regret bound for a more general problem that can take into account other objectives simultaneously. We also show that our technique would be applicable to related problems. Numerical experiments support our theoretical results and considerations."}}
{"id": "Oak_KU-20m", "cdate": 1609459200000, "mdate": 1653057326636, "content": {"title": "A Parameter-Free Algorithm for Misspecified Linear Contextual Bandits", "abstract": "We investigate the misspecified linear contextual bandit (MLCB) problem, which is a generalization of the linear contextual bandit (LCB) problem. The MLCB problem is a decision-making problem in which a learner observes $d$-dimensional feature vectors, called arms, chooses an arm from $K$ arms, and then obtains a reward from the chosen arm in each round. The learner aims to maximize the sum of the rewards over $T$ rounds. In contrast to the LCB problem, the rewards in the MLCB problem may not be represented by a linear function in feature vectors; instead, it is approximated by a linear function with additive approximation parameter $\\varepsilon \\geq 0$. In this paper, we propose an algorithm that achieves $\\tilde{O}(\\sqrt{dT\\log(K)} + \\varepsilon\\sqrt{d}T)$ regret, where $\\tilde{O}(\\cdot)$ ignores polylogarithmic factors in $d$ and $T$. This is the first algorithm that guarantees a high-probability regret bound for the MLCB problem without knowledge of the approximation parameter $\\varepsilon$."}}
{"id": "EEwrlBMByYT", "cdate": 1609459200000, "mdate": 1653057326777, "content": {"title": "Optimal Matroid Partitioning Problems", "abstract": "This paper studies optimal matroid partitioning problems for various objective functions. In the problem, we are given k weighted-matroids on the same ground set. Our goal is to find a feasible partition that minimizes (maximizes) the value of an objective function. A typical objective is the maximum over all subsets of the total weights of the elements in a subset, which is extensively studied in the scheduling literature. Likewise, as an objective function, we handle the maximum/minimum/sum over all subsets of the maximum/minimum/total weight(s) of the elements in a subset. In this paper, we determine the computational complexity of the optimal partitioning problem with the above-described objective functions. Namely, for each objective function, we either provide a polynomial time algorithm or prove NP-hardness. We also discuss the approximability for the NP-hard cases."}}
{"id": "DzB-UWyi8b7", "cdate": 1609459200000, "mdate": 1653057326633, "content": {"title": "Fair and Truthful Mechanism with Limited Subsidy", "abstract": "The notion of \\emph{envy-freeness} is a natural and intuitive fairness requirement in resource allocation. With indivisible goods, such fair allocations are unfortunately not guaranteed to exist. Classical works have avoided this issue by introducing an additional divisible resource, i.e., money, to subsidize envious agents. In this paper, we aim to design a truthful allocation mechanism of indivisible goods to achieve both fairness and efficiency criteria with a limited amount of subsidy. Following the work of Halpern and Shah, our central question is as follows: to what extent do we need to rely on the power of money to accomplish these objectives? For general valuations, the impossibility theorem of combinatorial auction translates to our setting: even if an arbitrarily large amount of money is available for use, no mechanism can achieve truthfulness, envy-freeness, and utilitarian optimality simultaneously when agents have general monotone submodular valuations. By contrast, we show that, when agents have matroidal valuations, there is a truthful allocation mechanism that achieves envy-freeness and utilitarian optimality by subsidizing each agent with at most $1$, the maximum marginal contribution of each item for each agent. The design of the mechanism rests crucially on the underlying matroidal M-convexity of the Lorenz dominating allocations."}}
{"id": "bm9PV-SqtBN", "cdate": 1577836800000, "mdate": 1653057326633, "content": {"title": "Delay and Cooperation in Nonstochastic Linear Bandits", "abstract": "This paper offers a nearly optimal algorithm for online linear optimization with delayed bandit feedback. Online linear optimization with bandit feedback, or nonstochastic linear bandits, provides a generic framework for sequential decision-making problems with limited information. This framework, however, assumes that feedback can be observed just after choosing the action, and, hence, does not apply directly to many practical applications, in which the feedback can often only be obtained after a while. To cope with such situations, we consider problem settings in which the feedback can be observed $d$ rounds after the choice of an action, and propose an algorithm for which the expected regret is $\\tilde{O}( \\sqrt{m (m + d) T} )$, ignoring logarithmic factors in $m$ and $T$, where $m$ and $T$ denote the dimensionality of the action set and the number of rounds, respectively. This algorithm achieves nearly optimal performance, as we are able to show that arbitrary algorithms suffer the regret of $\\Omega(\\sqrt{m (m+d) T})$ in the worst case. To develop the algorithm, we introduce a technique we refer to as \\textit{distribution truncation}, which plays an essential role in bounding the regret. We also apply our approach to cooperative bandits, as studied by Cesa-Bianchi et al. [17] and Bar-On and Mansour [12], and extend their results to the linear bandits setting."}}
