{"id": "vOQct7S52a", "cdate": 1640995200000, "mdate": 1668148199108, "content": {"title": "Efficient Video Instance Segmentation via Tracklet Query and Proposal", "abstract": ""}}
{"id": "sJiJz2IwiBs", "cdate": 1640995200000, "mdate": 1668148199109, "content": {"title": "ForestDet: Large-Vocabulary Long-Tailed Object Detection and Instance Segmentation", "abstract": ""}}
{"id": "qt8CivoZIzP", "cdate": 1640995200000, "mdate": 1668148199116, "content": {"title": "Personalized Prediction of Indoor Comfort Using Graph Convolutional Matrix Completion", "abstract": ""}}
{"id": "H5ToA0sixq", "cdate": 1640995200000, "mdate": 1668148199132, "content": {"title": "Deformable VisTR: Spatio Temporal Deformable Attention for Video Instance Segmentation", "abstract": ""}}
{"id": "97ZdLO32n93", "cdate": 1640995200000, "mdate": 1682110724520, "content": {"title": "GRiT: A Generative Region-to-text Transformer for Object Understanding", "abstract": "This paper presents a Generative RegIon-to-Text transformer, GRiT, for object understanding. The spirit of GRiT is to formulate object understanding as <region, text> pairs, where region locates objects and text describes objects. For example, the text in object detection denotes class names while that in dense captioning refers to descriptive sentences. Specifically, GRiT consists of a visual encoder to extract image features, a foreground object extractor to localize objects, and a text decoder to generate open-set object descriptions. With the same model architecture, GRiT can understand objects via not only simple nouns, but also rich descriptive sentences including object attributes or actions. Experimentally, we apply GRiT to object detection and dense captioning tasks. GRiT achieves 60.4 AP on COCO 2017 test-dev for object detection and 15.5 mAP on Visual Genome for dense captioning. Code is available at https://github.com/JialianW/GRiT"}}
{"id": "qYL5KAg737", "cdate": 1609459200000, "mdate": 1668148199135, "content": {"title": "Handling Difficult Labels for Multi-label Image Classification via Uncertainty Distillation", "abstract": ""}}
{"id": "W8ezLmEEBF", "cdate": 1609459200000, "mdate": 1668148199117, "content": {"title": "Track To Detect and Segment: An Online Multi-Object Tracker", "abstract": ""}}
{"id": "M8DDVfizcNb", "cdate": 1609459200000, "mdate": 1668148199119, "content": {"title": "Stacked Homography Transformations for Multi-View Pedestrian Detection", "abstract": ""}}
{"id": "EpD14WJglP", "cdate": 1609459200000, "mdate": 1668148199131, "content": {"title": "Robust Knowledge Transfer via Hybrid Forward on the Teacher-Student Model", "abstract": ""}}
{"id": "eDky5WYytt", "cdate": 1577836800000, "mdate": 1668148199136, "content": {"title": "Forest R-CNN: Large-Vocabulary Long-Tailed Object Detection and Instance Segmentation", "abstract": ""}}
