{"id": "xnI37HyfoP", "cdate": 1652737875652, "mdate": null, "content": {"title": "Nonnegative Tensor Completion via Integer Optimization", "abstract": "Unlike matrix completion, tensor completion does not have an algorithm that is known to achieve the information-theoretic sample complexity rate. This paper develops a new algorithm for the special case of completion for nonnegative tensors. We prove that our algorithm converges in a linear (in numerical tolerance) number of oracle steps, while achieving the information-theoretic rate. Our approach is to define a new norm for nonnegative tensors using the gauge of a particular 0-1 polytope; integer linear programming can, in turn, be used to solve linear separation problems over this polytope. We combine this insight with a variant of the Frank-Wolfe algorithm to construct our numerical algorithm, and we demonstrate its effectiveness and scalability through computational experiments using a laptop on tensors with up to one-hundred million entries."}}
{"id": "tge0BZv1Ay", "cdate": 1632875719414, "mdate": null, "content": {"title": "PDQN - A Deep Reinforcement Learning Method for Planning with Long Delays: Optimization of Manufacturing Dispatching", "abstract": "Scheduling is an important component in Semiconductor Manufacturing systems, where decisions must be made as to how to prioritize the use of finite machine resources to complete operations on parts in a timely manner. Traditionally, Operations Research methods have been used for simple, less complex systems. However, due to the complexity of this scheduling problem, simple dispatching rules such as Critical Ratio, and First-In-First-Out, are often used in practice in the industry for these more complex factories. This paper proposes a novel method based on Deep Reinforcement Learning for developing dynamic scheduling policies through interaction with simulated stochastic manufacturing systems. We experiment with simulated systems based on a complex Western Digital semiconductor plant. Our method builds upon DeepMind\u2019s Deep Q-network, and predictron methods to create a novel algorithm, Predictron Deep Q-network, which utilizes a predictron model as a trained planning model to create training targets for a Deep Q-Network based policy. In recent years, Deep Reinforcement Learning methods have shown state of the art performance on sequential decision-making processes in complex games such as Go. Semiconductor manufacturing systems, however, provide significant additional challenges due to complex dynamics, stochastic transitions, and long time horizons with the associated delayed rewards. In addition, dynamic decision policies need to account for uncertainties such as machine downtimes. Experimental results demonstrate that, in our simulated environments, the Predictron Deep Q-network outperforms the Deep Q-network, Critical Ratio, and First-In-First-Out dispatching policies on the task of minimizing lateness of parts."}}
{"id": "pRLNNCLTi73", "cdate": 1609459200000, "mdate": 1649283312066, "content": {"title": "Protecting Anonymous Speech: A Generative Adversarial Network Methodology for Removing Stylistic Indicators in Text", "abstract": "With Internet users constantly leaving a trail of text, whether through blogs, emails, or social media posts, the ability to write and protest anonymously is being eroded because artificial intelligence, when given a sample of previous work, can match text with its author out of hundreds of possible candidates. Existing approaches to authorship anonymization, also known as authorship obfuscation, often focus on protecting binary demographic attributes rather than identity as a whole. Even those that do focus on obfuscating identity require manual feedback, lose the coherence of the original sentence, or only perform well given a limited subset of authors. In this paper, we develop a new approach to authorship anonymization by constructing a generative adversarial network that protects identity and optimizes for three different losses corresponding to anonymity, fluency, and content preservation. Our fully automatic method achieves comparable results to other methods in terms of content preservation and fluency, but greatly outperforms baselines in regards to anonymization. Moreover, our approach is able to generalize well to an open-set context and anonymize sentences from authors it has not encountered before."}}
{"id": "kCpVDgukrUs", "cdate": 1609459200000, "mdate": 1649283312065, "content": {"title": "Sensor Switching Control Under Attacks Detectable by Finite Sample Dynamic Watermarking Tests", "abstract": "Control system security is enhanced by the ability to detect malicious attacks on sensor measurements. Dynamic watermarking can detect such attacks on linear time-invariant systems. However, existing theory focuses on attack detection and not on the use of watermarking in conjunction with attack mitigation strategies. In this article, we study the problem of switching between two sets of sensors: One set of sensors has high accuracy but is vulnerable to attack, whereas the second set of sensors has low accuracy but cannot be attacked. The problem is to design a sensor switching strategy based on attack detection by dynamic watermarking. This requires new theory because existing results are not adequate to control or bound the behavior of sensor switching strategies that use finite data. To overcome this, we develop new finite sample hypothesis tests for dynamic watermarking in the case of bounded disturbances, using the modern theory of concentration of measure for random matrices. Our resulting switching strategy is validated with a simulation analysis in an autonomous driving setting, which demonstrates the strong performance of our proposed policy."}}
{"id": "cpIiHDahthd", "cdate": 1609459200000, "mdate": 1649283311940, "content": {"title": "Logarithmic sample bounds for Sample Average Approximation with capacity- or budget-constraints", "abstract": ""}}
{"id": "ayq47DgjLoV", "cdate": 1609459200000, "mdate": 1649283311941, "content": {"title": "Detecting Generalized Replay Attacks via Time-Varying Dynamic Watermarking", "abstract": "Cyber-physical systems (CPS) often rely on external communication for supervisory control or sensing. Unfortunately, these communications render the system vulnerable to cyber attacks. Attacks that alter messages, such as replay attacks that record measurement signals, and then play them back to the system can cause devastating effects. Dynamic Watermarking methods, which inject a private excitation into control inputs to secure resulting measurement signals, have begun addressing the challenges of detecting these attacks, but have been restricted to linear time-invariant (LTI) systems. Though LTI models are sufficient for some applications, other CPS, such as autonomous vehicles, require more complex models. This article develops a linear time-varying (LTV) extension to previous dynamic watermarking methods by designing a matrix normalization factor to accommodate the temporal changes in the system. Implementable tests are provided with considerations for real-world systems. The proposed method is then shown to be able to detect generalized replay attacks both in theory and in simulation using an LTV vehicle model."}}
{"id": "_7HD3uQqa4l", "cdate": 1609459200000, "mdate": 1649283311941, "content": {"title": "Dynamic regret convergence analysis and an adaptive regularization algorithm for on-policy robot imitation learning", "abstract": "On-policy imitation learning algorithms such as DAgger evolve a robot control policy by executing it, measuring performance (loss), obtaining corrective feedback from a supervisor, and generating the next policy. As the loss between iterations can vary unpredictably, a fundamental question is under what conditions this process will eventually achieve a converged policy. If one assumes the underlying trajectory distribution is static (stationary), it is possible to prove convergence for DAgger. However, in more realistic models for robotics, the underlying trajectory distribution is dynamic because it is a function of the policy. Recent results show it is possible to prove convergence of DAgger when a regularity condition on the rate of change of the trajectory distributions is satisfied. In this article, we reframe this result using dynamic regret theory from the field of online optimization and show that dynamic regret can be applied to any on-policy algorithm to analyze its convergence and optimality. These results inspire a new algorithm, Adaptive On-Policy Regularization (Aor), that ensures the conditions for convergence. We present simulation results with cart\u2013pole balancing and locomotion benchmarks that suggest Aor can significantly decrease dynamic regret and chattering as the robot learns. To the best of the authors\u2019 knowledge, this is the first application of dynamic regret theory to imitation learning."}}
{"id": "U6Ei2Od6L-S", "cdate": 1609459200000, "mdate": 1649283312067, "content": {"title": "Resilient Control of Platooning Networked Robitic Systems via Dynamic Watermarking", "abstract": "Networked robotic systems, such as connected vehicle platoons, can improve the safety and efficiency of transportation networks by allowing for high-speed coordination. To enable such coordination, these systems rely on networked communications. This can make them susceptible to cyber attacks. Though security methods such as encryption or specially designed network topologies can increase the difficulty of successfully executing such an attack, these techniques are unable to guarantee secure communication against an attacker. More troublingly, these security methods are unable to ensure that individual agents are able to detect attacks that alter the content of specific messages. To ensure resilient behavior under such attacks, this paper formulates a networked linear time-varying version of dynamic watermarking in which each agent generates and adds a private excitation to the input of its corresponding robotic subsystem. This paper demonstrates that such a method can enable each agent in a networked robotic system to detect cyber attacks. By altering measurements sent between vehicles, this paper illustrates that an attacker can create unstable behavior within a platoon. By utilizing the dynamic watermarking method proposed in this paper, the attack is detected, allowing the vehicles in the platoon to gracefully degrade to a non-communicative control strategy that maintains safety across a variety of scenarios."}}
{"id": "NTmkL-KwOSn", "cdate": 1609459200000, "mdate": 1649283312023, "content": {"title": "Nonnegative Tensor Completion via Integer Optimization", "abstract": "Unlike matrix completion, tensor completion does not have an algorithm that is known to achieve the information-theoretic sample complexity rate. This paper develops a new algorithm for the special case of completion for nonnegative tensors. We prove that our algorithm converges in a linear (in numerical tolerance) number of oracle steps, while achieving the information-theoretic rate. Our approach is to define a new norm for nonnegative tensors using the gauge of a particular 0-1 polytope; integer linear programming can, in turn, be used to solve linear separation problems over this polytope. We combine this insight with a variant of the Frank-Wolfe algorithm to construct our numerical algorithm, and we demonstrate its effectiveness and scalability through computational experiments using a laptop on tensors with up to one-hundred million entries."}}
{"id": "J3kFaTfOwwC", "cdate": 1609459200000, "mdate": 1649283312070, "content": {"title": "Regret Analysis of Learning-Based MPC with Partially-Unknown Cost Function", "abstract": "The exploration/exploitation trade-off is an inherent challenge in data-driven and adaptive control. Though this trade-off has been studied for multi-armed bandits, reinforcement learning (RL) for finite Markov chains, and RL for linear control systems; it is less well-studied for learning-based control of nonlinear control systems. A significant theoretical challenge in the nonlinear setting is that, unlike the linear case, there is no explicit characterization of an optimal controller for a given set of cost and system parameters. We propose in this paper the use of a finite-horizon oracle controller with perfect knowledge of all system parameters as a reference for optimal control actions. First, this allows us to propose a new regret notion with respect to this oracle finite-horizon controller. Second, this allows us to develop learning-based policies that we prove achieve low regret (i.e., square-root regret up to a log-squared factor) with respect to this oracle finite-horizon controller. This policy is developed in the context of learning-based model predictive control (LBMPC). We conduct a statistical analysis to prove finite sample concentration bounds for the estimation step of our policy, and then we perform a control-theoretic analysis using techniques from MPC- and optimization-theory to show this policy ensures closed-loop stability and achieves low regret. We conclude with numerical experiments on a model of heating, ventilation, and air-conditioning (HVAC) systems that show the low regret of our policy in a setting where the cost function is partially-unknown to the controller."}}
