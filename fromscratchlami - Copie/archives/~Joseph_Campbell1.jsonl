{"id": "dNGxmwRpFyG", "cdate": 1676472362605, "mdate": null, "content": {"title": "Predicting Out-of-Distribution Error with Confidence Optimal Transport", "abstract": "Out-of-distribution (OOD) data poses serious challenges in deployed machine learning models as even subtle changes could incur significant performance drops. Being able to estimate a model's performance on test data is important in practice as it indicates when to trust a model's decisions. We present a simple yet effective method to predict a model's performance on an unknown distribution without any additional annotation. Our approach is rooted in the Optimal Transport theory, viewing test samples' output softmax scores from deep neural networks as empirical samples from an unknown distribution. We show that our method, Confidence Optimal Transport (COT), provides robust estimates of a model's performance on a target domain. Despite its simplicity, our method achieves state-of-the-art results on three benchmark datasets and outperforms existing methods by a large margin. "}}
{"id": "2Yx4oUdIsUj", "cdate": 1672531200000, "mdate": 1681693455268, "content": {"title": "Predicting Out-of-Distribution Error with Confidence Optimal Transport", "abstract": "Out-of-distribution (OOD) data poses serious challenges in deployed machine learning models as even subtle changes could incur significant performance drops. Being able to estimate a model's performance on test data is important in practice as it indicates when to trust to model's decisions. We present a simple yet effective method to predict a model's performance on an unknown distribution without any addition annotation. Our approach is rooted in the Optimal Transport theory, viewing test samples' output softmax scores from deep neural networks as empirical samples from an unknown distribution. We show that our method, Confidence Optimal Transport (COT), provides robust estimates of a model's performance on a target domain. Despite its simplicity, our method achieves state-of-the-art results on three benchmark datasets and outperforms existing methods by a large margin."}}
{"id": "TAgVKiF2O8p", "cdate": 1655376344343, "mdate": null, "content": {"title": "Concept Learning for Interpretable Multi-Agent Reinforcement Learning", "abstract": "Multi-agent robotic systems are increasingly operating in real-world environments in close proximity to humans, yet are largely controlled by policy models with inscrutable deep neural network representations. We introduce a method for incorporating interpretable concepts from a domain expert into models trained through multi-agent reinforcement learning, by requiring the model to first predict such concepts then utilize them for decision making. This allows an expert to both reason about the resulting concept policy models in terms of these high-level concepts at run-time, as well as intervene and correct mispredictions to improve performance. We show that this yields improved interpretability and training stability, with benefits to policy performance and sample efficiency in a simulated and real-world cooperative-competitive multi-agent game."}}
{"id": "XiQ19Y3vx7", "cdate": 1640995200000, "mdate": 1681922560360, "content": {"title": "Learning and Blending Robot Hugging Behaviors in Time and Space", "abstract": "We introduce an imitation learning-based physical human-robot interaction algorithm capable of predicting appropriate robot responses in complex interactions involving a superposition of multiple interactions. Our proposed algorithm, Blending Bayesian Interaction Primitives (B-BIP) allows us to achieve responsive interactions in complex hugging scenarios, capable of reciprocating and adapting to a hugs motion and timing. We show that this algorithm is a generalization of prior work, for which the original formulation reduces to the particular case of a single interaction, and evaluate our method through both an extensive user study and empirical experiments. Our algorithm yields significantly better quantitative prediction error and more-favorable participant responses with respect to accuracy, responsiveness, and timing, when compared to existing state-of-the-art methods."}}
{"id": "NdvHfIFlxd", "cdate": 1640995200000, "mdate": 1681922560336, "content": {"title": "Concept Learning for Interpretable Multi-Agent Reinforcement Learning", "abstract": "Multi-agent robotic systems are increasingly operating in real-world environments in close proximity to humans, yet are largely controlled by policy models with inscrutable deep neural network repr..."}}
{"id": "Itr9pRlzxTe", "cdate": 1640995200000, "mdate": 1681922560341, "content": {"title": "Explainable Action Advising for Multi-Agent Reinforcement Learning", "abstract": "Action advising is a knowledge transfer technique for reinforcement learning based on the teacher-student paradigm. An expert teacher provides advice to a student during training in order to improve the student's sample efficiency and policy performance. Such advice is commonly given in the form of state-action pairs. However, it makes it difficult for the student to reason with and apply to novel states. We introduce Explainable Action Advising, in which the teacher provides action advice as well as associated explanations indicating why the action was chosen. This allows the student to self-reflect on what it has learned, enabling advice generalization and leading to improved sample efficiency and learning performance - even in environments where the teacher is sub-optimal. We empirically show that our framework is effective in both single-agent and multi-agent scenarios, yielding improved policy returns and convergence rates when compared to state-of-the-art methods"}}
{"id": "pZIknq5RQ2Q", "cdate": 1577836800000, "mdate": 1655352205342, "content": {"title": "Learning Predictive Models for Ergonomic Control of Prosthetic Devices", "abstract": "We present Model-Predictive Interaction Primitives \u2013 a robot learning framework for assistive motion in human-machine collaboration tasks which explicitly accounts for biomechanical impact on the h..."}}
{"id": "kk0IUH9uFq6", "cdate": 1577836800000, "mdate": 1655352205383, "content": {"title": "Learning Whole-Body Human-Robot Haptic Interaction in Social Contexts", "abstract": "This paper presents a learning-from-demonstration (LfD) framework for teaching human-robot social interactions that involve whole-body haptic interaction, i.e. direct human-robot contact over the full robot body. The performance of existing LfD frameworks suffers in such interactions due to the high dimensionality and spatiotemporal sparsity of the demonstration data. We show that by leveraging this sparsity, we can reduce the data dimensionality without incurring a significant accuracy penalty, and introduce three strategies for doing so. By combining these techniques with an LfD framework for learning multimodal human-robot interactions, we can model the spatiotemporal relationship between the tactile and kinesthetic information during whole-body haptic interactions. Using a teleoperated bimanual robot equipped with 61 force sensors, we experimentally demonstrate that a model trained with 121 sample hugs from 4 participants generalizes well to unseen inputs and human partners."}}
{"id": "jAdmatL9TPt", "cdate": 1577836800000, "mdate": 1655352205348, "content": {"title": "Predictive Modeling of Periodic Behavior for Human-Robot Symbiotic Walking", "abstract": "We propose in this paper Periodic Interaction Primitives - a probabilistic framework that can be used to learn compact models of periodic behavior. Our approach extends existing formulations of Interaction Primitives to periodic movement regimes, i.e., walking. We show that this model is particularly well-suited for learning data-driven, customized models of human walking, which can then be used for generating predictions over future states or for inferring latent, biomechanical variables. We also demonstrate how the same framework can be used to learn controllers for a robotic prosthesis using an imitation learning approach. Results in experiments with human participants indicate that Periodic Interaction Primitives efficiently generate predictions and ankle angle control signals for a robotic prosthetic ankle, with MAE of 2.21\u00b0 in 0.0008s per inference. Performance degrades gracefully in the presence of noise or sensor fall outs. Compared to alternatives, this algorithm functions 20 times faster and performed 4.5 times more accurately on test subjects."}}
{"id": "RrCv7ZELcMQ", "cdate": 1577836800000, "mdate": 1655352205345, "content": {"title": "Language-Conditioned Imitation Learning for Robot Manipulation Tasks", "abstract": "Imitation learning is a popular approach for teaching motor skills to robots. However, most approaches focus on extracting policy parameters from execution traces alone (i.e., motion trajectories and perceptual data). No adequate communication channel exists between the human expert and the robot to describe critical aspects of the task, such as the properties of the target object or the intended shape of the motion. Motivated by insights into the human teaching process, we introduce a method for incorporating unstructured natural language into imitation learning. At training time, the expert can provide demonstrations along with verbal descriptions in order to describe the underlying intent (e.g., \"go to the large green bowl\"). The training process then interrelates these two modalities to encode the correlations between language, perception, and motion. The resulting language-conditioned visuomotor policies can be conditioned at runtime on new human commands and instructions, which allows for more fine-grained control over the trained policies while also reducing situational ambiguity. We demonstrate in a set of simulation experiments how our approach can learn language-conditioned manipulation policies for a seven-degree-of-freedom robot arm and compare the results to a variety of alternative methods."}}
