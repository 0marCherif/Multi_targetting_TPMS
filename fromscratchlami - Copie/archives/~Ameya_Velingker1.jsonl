{"id": "8Tr3v4ueNd7", "cdate": 1663850530872, "mdate": null, "content": {"title": "Exphormer: Scaling Graph Transformers with Expander Graphs", "abstract": "Graph transformers have emerged as a promising architecture for a variety of graph learning and representation tasks. Despite their successes, it remains challenging to scale graph transformers to large graphs while maintaining accuracy competitive with message-passing networks. In this paper, we introduce Exphormer,  a framework for building powerful and scalable graph transformers.  Exphormer consists of a sparse attention mechanism based on expander graphs, whose mathematical characteristics, such as spectral expansion, and sparsity, yield graph transformers with complexity only linear in the size of the graph, while allowing us to prove desirable theoretical properties of the resulting transformer models. We show that incorporating Exphormer into the recently-proposed GraphGPS framework produces models with competitive empirical results on a wide variety of graph datasets, including state-of-the-art results on three datasets. We also show that Exphormer can scale to datasets on larger graphs than shown in previous graph transformer architectures."}}
{"id": "p9zz7hLzH-4", "cdate": 1663850317510, "mdate": null, "content": {"title": "Affinity-Aware Graph Networks", "abstract": "Graph Neural Networks (GNNs) have emerged as a powerful technique for learning on relational data. Owing to the relatively limited number of message passing steps they perform\u2014and hence a smaller receptive field\u2014there has been significant interest in improving their expressivity by incorporating structural aspects of the underlying graph. In this paper, we explore the use of affinity measures as features in graph neural networks, in particular measures arising from random walks, including effective resistance, hitting and commute times. We propose message passing networks based on these features and evaluate their performance on a variety of node and graph property prediction tasks."}}
{"id": "GNv-TyWu3PY", "cdate": 1601308041978, "mdate": null, "content": {"title": "Robust Learning for Congestion-Aware Routing", "abstract": "We consider the problem of routing users through a network with unknown congestion functions over an infinite time horizon. On each time step $t$, the algorithm receives a routing request and must select a valid path. For each edge $e$ in the selected path, the algorithm incurs a cost $c_e^t = f_e(x_e^t) + \\eta_e^t$, where $x_e^t$ is the flow on edge $e$ at time $t$, $f_e$ is the congestion function, and $\\eta_e^t$ is a noise sample drawn from an unknown distribution. The algorithm observes $c_e^t$, and can use this observation in future routing decisions. The routing requests are supplied adversarially. \n\nWe present an algorithm with cumulative regret $\\tilde{O}(|E| t^{2/3})$, where the regret on each time step is defined as the difference between the total cost incurred by our chosen path and the minimum cost among all valid paths. Our algorithm has space complexity $O(|E| t^{1/3})$ and time complexity $O(|E| \\log t)$. We also validate our algorithm empirically using graphs from New York City road networks."}}
{"id": "rk-GEsbubH", "cdate": 1483228800000, "mdate": null, "content": {"title": "Random Fourier Features for Kernel Ridge Regression: Approximation Bounds and Statistical Guarantees", "abstract": "Random Fourier features is one of the most popular techniques for scaling up kernel methods, such as kernel ridge regression. However, despite impressive empirical results, the statistical properti..."}}
