{"id": "hba2kc52a6X", "cdate": 1640995200000, "mdate": 1679969228168, "content": {"title": "RESUS: Warm-Up Cold Users via Meta-Learning Residual User Preferences in CTR Prediction", "abstract": ""}}
{"id": "-5Pys_eY3D", "cdate": 1609459200000, "mdate": 1679969228162, "content": {"title": "Dual-Embedding based Deep Latent Factor Models for Recommendation", "abstract": ""}}
{"id": "czneUTZJ8qZ", "cdate": 1577836800000, "mdate": null, "content": {"title": "Differentiable Neural Input Search for Recommender Systems", "abstract": "Latent factor models are the driving forces of the state-of-the-art recommender systems, with an important insight of vectorizing raw input features into dense embeddings. The dimensions of different feature embeddings are often set to a same value empirically, which limits the predictive performance of latent factor models. Existing works have proposed heuristic or reinforcement learning-based methods to search for mixed feature embedding dimensions. For efficiency concern, these methods typically choose embedding dimensions from a restricted set of candidate dimensions. However, this restriction will hurt the flexibility of dimension selection, leading to suboptimal performance of search results. In this paper, we propose Differentiable Neural Input Search (DNIS), a method that searches for mixed feature embedding dimensions in a more flexible space through continuous relaxation and differentiable optimization. The key idea is to introduce a soft selection layer that controls the significance of each embedding dimension, and optimize this layer according to model's validation performance. DNIS is model-agnostic and thus can be seamlessly incorporated with existing latent factor models for recommendation. We conduct experiments with various architectures of latent factor models on three public real-world datasets for rating prediction, Click-Through-Rate (CTR) prediction, and top-k item recommendation. The results demonstrate that our method achieves the best predictive performance compared with existing neural input search approaches with fewer embedding parameters and less time cost."}}
{"id": "YydYRTbV3eb", "cdate": 1577836800000, "mdate": null, "content": {"title": "Adaptive Factorization Network: Learning Adaptive-Order Feature Interactions", "abstract": "Various factorization-based methods have been proposed to leverage second-order, or higher-order cross features for boosting the performance of predictive models. They generally enumerate all the cross features under a predefined maximum order, and then identify useful feature interactions through model training, which suffer from two drawbacks. First, they have to make a trade-off between the expressiveness of higher-order cross features and the computational cost, resulting in suboptimal predictions. Second, enumerating all the cross features, including irrelevant ones, may introduce noisy feature combinations that degrade model performance. In this work, we propose the Adaptive Factorization Network (AFN), a new model that learns arbitrary-order cross features adaptively from data. The core of AFN is a logarithmic transformation layer that converts the power of each feature in a feature combination into the coefficient to be learned. The experimental results on four real datasets demonstrate the superior predictive performance of AFN against the state-of-the-arts."}}
{"id": "8Hib9Z8hrZY", "cdate": 1546300800000, "mdate": null, "content": {"title": "Incorporating Interpretability into Latent Factor Models via Fast Influence Analysis", "abstract": "Latent factor models (LFMs) such as matrix factorization have achieved the state-of-the-art performance among various collaborative filtering approaches for recommendation. Despite the high recommendation accuracy of LFMs, a critical issue to be resolved is their lack of interpretability. Extensive efforts have been devoted to interpreting the prediction results of LFMs. However, they either rely on auxiliary information which may not be available in practice, or sacrifice recommendation accuracy for interpretability. Influence functions, stemming from robust statistics, have been developed to understand the effect of training points on the predictions of black-box models. Inspired by this, we propose a novel explanation method named FIA (Fast Influence Analysis) to understand the prediction of trained LFMs by tracing back to the training data with influence functions. We present how to employ influence functions to measure the impact of historical user-item interactions on the prediction results of LFMs and provide intuitive neighbor-style explanations based on the most influential interactions. Our proposed FIA exploits the characteristics of two important LFMs, matrix factorization and neural collaborative filtering, and is capable of accelerating the overall influence analysis process. We provide a detailed complexity analysis for FIA over LFMs and conduct extensive experiments to evaluate its performance using real-world datasets. The results demonstrate the effectiveness and efficiency of FIA, and the usefulness of the generated explanations for the recommendation results."}}
{"id": "6Wz7kAIvhD", "cdate": 1546300800000, "mdate": 1679969228165, "content": {"title": "Adaptive Factorization Network: Learning Adaptive-Order Feature Interactions", "abstract": ""}}
{"id": "67yivUunr6k", "cdate": 1546300800000, "mdate": 1679969228165, "content": {"title": "LADD: A Length-Adaptive Approach to Detecting Taxi Anomalous Detours", "abstract": ""}}
{"id": "rkbfQy-dZB", "cdate": 1514764800000, "mdate": null, "content": {"title": "A Neural Attention Model for Urban Air Quality Inference: Learning the Weights of Monitoring Stations", "abstract": "Urban air pollution has attracted much attention these years for its adverse impacts on human health. While monitoring stations have been established to collect pollutant statistics, the number of stations is very limited due to the high cost. Thus, inferring fine-grained urban air quality information is becoming an essential issue for both government and people. In this paper, we propose a generic neural approach, named ADAIN, for urban air quality inference. We leverage both the information from monitoring stations and urban data that are closely related to air quality, including POIs, road networks and meteorology. ADAIN combines feedforward and recurrent neural networks for modeling static and sequential features as well as capturing deep feature interactions effectively. A novel attempt of ADAIN is an attention-based pooling layer that automatically learns the weights of features from different monitoring stations, to boost the performance. We conduct experiments on a real-world air quality dataset and our approach achieves the highest performance compared with various state-of-the-art solutions."}}
{"id": "HN9hdbmuiC", "cdate": 1514764800000, "mdate": 1679969228164, "content": {"title": "Explaining Latent Factor Models for Recommendation with Influence Functions", "abstract": ""}}
{"id": "BJV8v4zu-B", "cdate": 1514764800000, "mdate": null, "content": {"title": "DELF: A Dual-Embedding based Deep Latent Factor Model for Recommendation", "abstract": "Among various recommendation methods, latent factor models are usually considered to be state-of-the-art techniques, which aim to learn user and item embeddings for predicting user-item preferences. When applying latent factor models to recommendation with implicit feedback, the quality of embeddings always suffers from inadequate positive feedback and noisy negative feedback. Inspired by the idea of NSVD that represents users based on their interacted items, this paper proposes a dual-embedding based deep latent factor model named DELF for recommendation with implicit feedback. In addition to learning a single embedding for a user (resp. item), we represent each user (resp. item) with an additional embedding from the perspective of the interacted items (resp. users). We employ an attentive neural method to discriminate the importance of interacted users/items for dual-embedding learning. We further introduce a neural network architecture to incorporate dual embeddings for recommendation. A novel attempt of DELF is to model each user-item interaction with four deep representations that are subtly fused for preference prediction. We conducted extensive experiments on real-world datasets. The results verify the effectiveness of user/item dual embeddings and the superior performance of DELF on item recommendation."}}
