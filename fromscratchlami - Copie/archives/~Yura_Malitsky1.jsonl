{"id": "GNFcszMtYvV", "cdate": 1621630277838, "mdate": null, "content": {"title": "Convergence of adaptive algorithms for constrained weakly convex optimization", "abstract": "We analyze the adaptive first order algorithm AMSGrad, for solving a constrained stochastic optimization problem with a weakly convex objective. We prove the $\\mathcal{\\tilde O}(t^{-1/2})$ rate of convergence for the squared norm of the gradient of Moreau envelope, which is the standard stationarity measure for this class of problems. It matches the known rates that adaptive algorithms enjoy for the specific case of unconstrained smooth nonconvex stochastic optimization. Our analysis works with mini-batch size of $1$, constant first and second order moment parameters, and possibly unbounded optimization domains. Finally, we illustrate the applications and extensions of our results to specific problems and algorithms."}}
{"id": "DtXBYsSOxCD", "cdate": 1621630249728, "mdate": null, "content": {"title": "A first-order primal-dual method with adaptivity to local smoothness", "abstract": "We consider the problem of finding a saddle point for the convex-concave objective $\\min_x \\max_y f(x) + \\langle Ax, y\\rangle - g^*(y)$, where $f$ is a convex function with locally Lipschitz gradient and $g$ is convex and possibly non-smooth. We propose an adaptive version of the Condat-V\u0169 algorithm, which alternates between primal gradient steps and dual proximal steps. The method achieves stepsize adaptivity through a simple rule involving $\\|A\\|$ and the norm of recently computed gradients of $f$. Under standard assumptions, we prove an $\\mathcal{O}(k^{-1})$ ergodic convergence rate. Furthermore, when $f$ is also locally strongly convex and $A$ has full row rank we show that our method converges with a linear rate. Numerical experiments are provided for illustrating the practical performance of the algorithm."}}
{"id": "JejJJRpOhF", "cdate": 1601651937844, "mdate": null, "content": {"title": "Convergence of adaptive algorithms for weakly convex constrained optimization", "abstract": "We analyze the adaptive first order algorithm AMSGrad, for solving a constrained stochastic optimization problem with a weakly convex objective. We prove the $\\tilde{O}(t^{\u22121/4})$ rate of convergence for the norm of the gradient of Moreau envelope, which is the standard stationarity measure for this class of problems. It matches the known rates that adaptive algorithms enjoy for the specific case of unconstrained smooth stochastic optimization. Our analysis works with mini-batch size of 1, constant first and second order moment parameters, and possibly unbounded optimization domains. Finally, we illustrate the applications and extensions of our results to specific problems and algorithms."}}
{"id": "u2r2MYOC-_c", "cdate": 1577836800000, "mdate": null, "content": {"title": "Convergence of adaptive algorithms for weakly convex constrained optimization", "abstract": "We analyze the adaptive first order algorithm AMSGrad, for solving a constrained stochastic optimization problem with a weakly convex objective. We prove the $\\mathcal{\\tilde O}(t^{-1/4})$ rate of convergence for the norm of the gradient of Moreau envelope, which is the standard stationarity measure for this class of problems. It matches the known rates that adaptive algorithms enjoy for the specific case of unconstrained smooth stochastic optimization. Our analysis works with mini-batch size of $1$, constant first and second order moment parameters, and possibly unbounded optimization domains. Finally, we illustrate the applications and extensions of our results to specific problems and algorithms."}}
{"id": "VORy8ofHFwz", "cdate": 1577836800000, "mdate": null, "content": {"title": "A Forward-Backward Splitting Method for Monotone Inclusions Without Cocoercivity", "abstract": "In this work, we propose a simple modification of the forward-backward splitting method for finding a zero in the sum of two monotone operators. Our method converges under the same assumptions as Tseng's forward-backward-forward method, namely, it does not require cocoercivity of the single-valued operator. Moreover, each iteration only uses one forward evaluation rather than two as is the case for Tseng's method. Variants of the method incorporating a linesearch, relaxation and inertia, or a structured three operator inclusion are also discussed."}}
{"id": "MusLM7hy4SH", "cdate": 1577836800000, "mdate": null, "content": {"title": "A new regret analysis for Adam-type algorithms.", "abstract": "In this paper, we focus on a theory-practice gap for Adam and its variants (AMSgrad, AdamNC, etc.). In practice, these algorithms are used with a constant first-order moment parameter $\\beta_{1}$ (typically between $0.9$ and $0.99$). In theory, regret guarantees for online convex optimization require a rapidly decaying $\\beta_{1}\\to0$ schedule. We show that this is an artifact of the standard analysis and propose a novel framework that allows us to derive optimal, data-dependent regret bounds with a constant $\\beta_{1}$, without further assumptions. We also demonstrate the flexibility of our analysis on a wide range of different algorithms and settings."}}
{"id": "rJWGLi-u-B", "cdate": 1546300800000, "mdate": null, "content": {"title": "Model Function Based Conditional Gradient Method with Armijo-like Line Search", "abstract": "The Conditional Gradient Method is generalized to a class of non-smooth non-convex optimization problems with many applications in machine learning. The proposed algorithm iterates by minimizing so..."}}
{"id": "fQd1tIqc4t", "cdate": 1546300800000, "mdate": null, "content": {"title": "Revisiting Stochastic Extragradient", "abstract": "We fix a fundamental issue in the stochastic extragradient method by providing a new sampling strategy that is motivated by approximating implicit updates. Since the existing stochastic extragradient algorithm, called Mirror-Prox, of (Juditsky et al., 2011) diverges on a simple bilinear problem when the domain is not bounded, we prove guarantees for solving variational inequality that go beyond existing settings. Furthermore, we illustrate numerically that the proposed variant converges faster than many other methods on bilinear saddle-point problems. We also discuss how extragradient can be applied to training Generative Adversarial Networks (GANs) and how it compares to other methods. Our experiments on GANs demonstrate that the introduced approach may make the training faster in terms of data passes, while its higher iteration complexity makes the advantage smaller."}}
{"id": "1a3sXUW-pG", "cdate": 1546300800000, "mdate": null, "content": {"title": "Adaptive gradient descent without descent", "abstract": "We present a strikingly simple proof that two rules are sufficient to automate gradient descent: 1) don't increase the stepsize too fast and 2) don't overstep the local curvature. No need for functional values, no line search, no information about the function except for the gradients. By following these rules, you get a method adaptive to the local geometry, with convergence guarantees depending only on the smoothness in a neighborhood of a solution. Given that the problem is convex, our method converges even if the global smoothness constant is infinity. As an illustration, it can minimize arbitrary continuously twice-differentiable convex function. We examine its performance on a range of convex and nonconvex problems, including logistic regression and matrix factorization."}}
{"id": "tJhFoPeadiI", "cdate": 1514764800000, "mdate": null, "content": {"title": "A First-Order Primal-Dual Algorithm with Linesearch", "abstract": "The paper proposes a linesearch for a primal-dual method. Each iteration of the linesearch requires an update of only the dual (or primal) variable. For many problems, in particular for regularized least squares, the linesearch does not require any additional matrix-vector multiplications. We prove convergence of the proposed method under standard assumptions. We also show an ergodic $O(1/N)$ rate of convergence for our method. In the case when one or both of the prox-functions are strongly convex, we modify our basic method to get a better convergence rate. Finally, we propose a linesearch for a saddle-point problem with an additional smooth term. Several numerical experiments confirm the efficiency of our proposed methods."}}
