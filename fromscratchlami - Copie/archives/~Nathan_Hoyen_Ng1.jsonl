{"id": "3rGLfR0dqp", "cdate": 1663850343578, "mdate": null, "content": {"title": "Predicting Out-of-Domain Generalization with Local Manifold Smoothness", "abstract": "Understanding how machine learning models generalize to new environments is a critical part of their safe deployment. Recent work has proposed a variety of complexity measures that directly predict or theoretically bound the generalization capacity of a model. However, these methods rely on a strong set of assumptions that in practice are not always satisfied. Motivated by the limited settings in which existing measures can be applied, we propose a novel complexity measure based on the local manifold smoothness of a classifier. We define local manifold smoothness as a classifier's output sensitivity to perturbations in the manifold neighborhood around a given test point. Intuitively, a classifier that is less sensitive to these perturbations should generalize better. To estimate smoothness we sample points using data augmentation and measure the fraction of these points classified into the majority class. Our method only requires selecting a data augmentation method and makes no other assumptions about the model or data distributions, meaning it can be applied even in out-of-domain (OOD) settings where existing methods cannot. In experiments on robustness benchmarks in image classification, sentiment analysis, and natural language inference, we demonstrate a strong and robust correlation between our manifold smoothness measure and actual OOD generalization on over 4,000 models evaluated on over 100 train/test domain pairs."}}
{"id": "hzbguA9zMJ", "cdate": 1652737611565, "mdate": null, "content": {"title": "If Influence Functions are the Answer, Then What is the Question?", "abstract": "Influence functions efficiently estimate the effect of removing a single training data point on a model's learned parameters. While influence estimates align well with leave-one-out retraining for linear models, recent works have shown this alignment is often poor in neural networks. In this work, we investigate the specific factors that cause this discrepancy by decomposing it into five separate terms. We study the contributions of each term on a variety of architectures and datasets and how they vary with factors such as network width and training time. While practical influence function estimates may be a poor match to leave-one-out retraining for nonlinear networks, we show that they are often a good approximation to a different object we term the proximal Bregman response function (PBRF). Since the PBRF can still be used to answer many of the questions motivating influence functions, such as identifying influential or mislabeled examples, our results suggest that current algorithms for influence function estimation give more informative results than previous error analyses would suggest."}}
{"id": "xDfNvHNnBB", "cdate": 1640995200000, "mdate": 1681661681027, "content": {"title": "If Influence Functions are the Answer, Then What is the Question?", "abstract": "Influence functions efficiently estimate the effect of removing a single training data point on a model's learned parameters. While influence estimates align well with leave-one-out retraining for linear models, recent works have shown this alignment is often poor in neural networks. In this work, we investigate the specific factors that cause this discrepancy by decomposing it into five separate terms. We study the contributions of each term on a variety of architectures and datasets and how they vary with factors such as network width and training time. While practical influence function estimates may be a poor match to leave-one-out retraining for nonlinear networks, we show they are often a good approximation to a different object we term the proximal Bregman response function (PBRF). Since the PBRF can still be used to answer many of the questions motivating influence functions, such as identifying influential or mislabeled examples, our results suggest that current algorithms for influence function estimation give more informative results than previous error analyses would suggest."}}
{"id": "klp57bJmaFN", "cdate": 1640995200000, "mdate": 1680275488915, "content": {"title": "Predicting Out-of-Domain Generalization with Local Manifold Smoothness", "abstract": ""}}
{"id": "SxNRTNrpk5", "cdate": 1577836800000, "mdate": 1645200582419, "content": {"title": "SSMBA: Self-Supervised Manifold Based Data Augmentation for Improving Out-of-Domain Robustness", "abstract": "Nathan Ng, Kyunghyun Cho, Marzyeh Ghassemi. Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP). 2020."}}
{"id": "CK4YZvkDXQs", "cdate": 1577836800000, "mdate": 1681661681159, "content": {"title": "Improving Dialogue Breakdown Detection with Semi-Supervised Learning", "abstract": "Building user trust in dialogue agents requires smooth and consistent dialogue exchanges. However, agents can easily lose conversational context and generate irrelevant utterances. These situations are called dialogue breakdown, where agent utterances prevent users from continuing the conversation. Building systems to detect dialogue breakdown allows agents to recover appropriately or avoid breakdown entirely. In this paper we investigate the use of semi-supervised learning methods to improve dialogue breakdown detection, including continued pre-training on the Reddit dataset and a manifold-based data augmentation method. We demonstrate the effectiveness of these methods on the Dialogue Breakdown Detection Challenge (DBDC) English shared task. Our submissions to the 2020 DBDC5 shared task place first, beating baselines and other submissions by over 12\\% accuracy. In ablations on DBDC4 data from 2019, our semi-supervised learning methods improve the performance of a baseline BERT model by 2\\% accuracy. These methods are applicable generally to any dialogue task and provide a simple way to improve model performance."}}
{"id": "B0gzJA4rTk5", "cdate": 1577836800000, "mdate": 1645200583289, "content": {"title": "SSMBA: Self-Supervised Manifold Based Data Augmentation for Improving Out-of-Domain Robustness", "abstract": "Models that perform well on a training domain often fail to generalize to out-of-domain (OOD) examples. Data augmentation is a common method used to prevent overfitting and improve OOD generalization. However, in natural language, it is difficult to generate new examples that stay on the underlying data manifold. We introduce SSMBA, a data augmentation method for generating synthetic training examples by using a pair of corruption and reconstruction functions to move randomly on a data manifold. We investigate the use of SSMBA in the natural language domain, leveraging the manifold assumption to reconstruct corrupted text with masked language models. In experiments on robustness benchmarks across 3 tasks and 9 datasets, SSMBA consistently outperforms existing data augmentation methods and baseline models on both in-domain and OOD data, achieving gains of 0.8% accuracy on OOD Amazon reviews, 1.8% accuracy on OOD MNLI, and 1.4 BLEU on in-domain IWSLT14 German-English."}}
{"id": "j8-WuF57vg8", "cdate": 1546300800000, "mdate": null, "content": {"title": "Simple and Effective Noisy Channel Modeling for Neural Machine Translation", "abstract": "Previous work on neural noisy channel modeling relied on latent variable models that incrementally process the source and target sentence. This makes decoding decisions based on partial source prefixes even though the full source is available. We pursue an alternative approach based on standard sequence to sequence models which utilize the entire source. These models perform remarkably well as channel models, even though they have neither been trained on, nor designed to factor over incomplete target sentences. Experiments with neural language models trained on billions of words show that noisy channel models can outperform a direct model by up to 3.2 BLEU on WMT'17 German-English translation. We evaluate on four language-pairs and our channel models consistently outperform strong alternatives such right-to-left reranking models and ensembles of direct models."}}
{"id": "hMaGC_WnXEO", "cdate": 1546300800000, "mdate": null, "content": {"title": "Embryo Staging with Weakly-Supervised Region Selection and Dynamically-Decoded Predictions", "abstract": "To optimize clinical outcomes, fertility clinics must strategically select which embryos to transfer. Common selection heuristics are formulas expressed in terms of the durations required to reach ..."}}
{"id": "_1Z-usBJhda", "cdate": 1546300800000, "mdate": 1681661681093, "content": {"title": "Facebook FAIR's WMT19 News Translation Task Submission", "abstract": ""}}
