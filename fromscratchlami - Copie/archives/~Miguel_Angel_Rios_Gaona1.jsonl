{"id": "eegtTFDVvHn", "cdate": 1620328103672, "mdate": null, "content": {"title": "Mortality Prediction Models with Clinical Notes Using Sparse Attention at the Word and Sentence Levels", "abstract": "Intensive Care in-hospital mortality prediction has various clinical applications. Neural prediction models, especially when capitalising on clinical notes, have been put forward as improvement on currently existing models. However, to be acceptable these models should be performant and transparent. This work studies different attention mechanisms for clinical neural prediction models in terms of their discrimination and calibration. Specifically, we investigate sparse attention as an alternative to dense attention weights in the task of in hospital mortality prediction from clinical\nnotes. We evaluate the attention mechanisms based on: i) local self-attention over words in a sentence, and ii) global self-attention with a transformer architecture across sentences. We demonstrate that the sparse mechanism approach outperforms the dense one for the local self-attention in terms of predictive performance with a publicly available dataset, and puts higher\nattention to prespecified relevant directive words. The performance at the sentence level, however, deteriorates as sentences including the influential directive words tend to be dropped all together."}}
{"id": "kEGkAQRcRij", "cdate": 1601052042715, "mdate": null, "content": {"title": "Improving Chunk-based Semantic Role Labeling with Lexical Features", "abstract": "We present an approach for Semantic Role Labeling (SRL) using Conditional Random Fields in a joint identification/classification step. The approach\nis based on shallow syntactic information\n(chunks) and a number of lexicalized features such as selectional preferences and\nautomatically inferred similar words, extracted using lexical databases and distributional similarity metrics. We use semantic annotations from the Proposition\nBank for training and evaluate the system\nusing CoNLL-2005 test sets. The additional lexical information led to improvements of 15% (in-domain evaluation) and\n12% (out-of-domain evaluation) on overall semantic role classification in terms of\nF-measure. The gains come mostly from a\nbetter recall, which suggests that the addition of richer lexical information can improve the coverage of existing SRL models even when very little syntactic knowledge is available."}}
{"id": "MGy5jnfuG_", "cdate": 1601051988326, "mdate": null, "content": {"title": "UOW: Semantically Informed Text Similarity", "abstract": "The UOW submissions to the Semantic Textual Similarity task at SemEval-2012 use a\nsupervised machine learning algorithm along\nwith features based on lexical, syntactic and\nsemantic similarity metrics to predict the semantic equivalence between a pair of sentences. The lexical metrics are based on word overlap. A shallow syntactic metric is based\non the overlap of base-phrase labels. The\nsemantically informed metrics are based on\nthe preservation of named entities and on the\nalignment of verb predicates and the overlap\nof argument roles using inexact matching. Our\nsubmissions outperformed the official baseline, with our best system ranked above average, but the contribution of the semantic metrics was not conclusive."}}
{"id": "cSZKg4NB73t", "cdate": 1601051922174, "mdate": null, "content": {"title": "UoW: Multi-task Learning Gaussian Process for Semantic Textual Similarity", "abstract": "We report results obtained by the UoW\nmethod in SemEval-2014\u2019s Task 10 \u2013 Multilingual Semantic Textual Similarity. We\npropose to model Semantic Textual Similarity in the context of Multi-task Learning\nin order to deal with inherent challenges of\nthe task such as unbalanced performance\nacross domains and the lack of training\ndata for some domains (i.e. unknown\ndomains). We show that the Multi-task\nLearning approach outperforms previous\nwork on the 2012 dataset, achieves a robust performance on the 2013 dataset and\ncompetitive results on the 2014 dataset.\nWe highlight the importance of the challenge of unknown domains, as it affects\noverall performance substantially."}}
{"id": "l5JKGQVsjN", "cdate": 1601051755077, "mdate": null, "content": {"title": "Statistical Relational Learning to Recognise Textual Entailment", "abstract": "We propose a novel approach to recognise\ntextual entailment (RTE) following a twostage architecture \u2013 alignment and decision \u2013 where both stages are based on semantic representations. In the alignment\nstage the entailment candidate pairs are\nrepresented and aligned using predicateargument structures. In the decision stage,\na Markov Logic Network (MLN) is learnt\nusing rich relational information from the\nalignment stage to predict an entailment\ndecision. We evaluate this approach using the RTE Challenge datasets. It shows\ncomparable results against the average\nperformance across participating systems,\nand very promising results for a subset of\nthe datasets for which a semantic alignment can be found, evidencing the potential of MLNs for RTE"}}
{"id": "eWmiHKcC7_1", "cdate": 1601051698329, "mdate": null, "content": {"title": "Large Scale Translation Quality Estimation", "abstract": "This study explores methods for developing a large scale Quality Estimation framework for Machine Translation. We expand existing resources for Quality Estimation across related languages\nby using different transfer learning methods. The transfer learning methods are: Transductive\nSVM, Label Propagation and Self-taught Learning. We use transfer learning methods on the\navailable labelled datasets, e.g. en-es, to produce a range of Quality Estimation models for Romance languages, while also adapting for subtitling as a new domain. The Self-taught Learning\nmethod shows the most promising results among the used techniques."}}
{"id": "8YZe0OJpZHf", "cdate": 1601051557720, "mdate": null, "content": {"title": "The QT21 Combined Machine Translation System for English to Latvian", "abstract": "This paper describes the joint submission of the QT21 projects for the\nEnglish\u2192Latvian translation task of the\nEMNLP 2017 Second Conference on Machine Translation (WMT 2017). The submission is a system combination which\ncombines seven different statistical machine translation systems provided by the\ndifferent groups.\nThe systems are combined using either\nRWTH\u2019s system combination approach,\nor USFD\u2019s consensus-based systemselection approach. The final submission\nshows an improvement of 0.5 BLEU\ncompared to the best single system on\nnewstest2017."}}
{"id": "NyURAOcLBxv", "cdate": 1601051383140, "mdate": null, "content": {"title": "Deep Generative Model for Joint Alignment and Word Representation", "abstract": "This work exploits translation data as a source\nof semantically relevant learning signal for\nmodels of word representation. In particular,\nwe exploit equivalence through translation as\na form of distributed context and jointly learn\nhow to embed and align with a deep generative model. Our EMBEDALIGN model embeds words in their complete observed context\nand learns by marginalisation of latent lexical\nalignments. Besides, it embeds words as posterior probability densities, rather than point\nestimates, which allows us to compare words\nin context using a measure of overlap between\ndistributions (e.g. KL divergence). We investigate our model\u2019s performance on a range of\nlexical semantics tasks achieving competitive\nresults on several standard benchmarks including natural language inference, paraphrasing,\nand text similarity."}}
{"id": "aRpOEBrlwQl", "cdate": 1601051296218, "mdate": null, "content": {"title": "Latent Variable Model for Multi-modal Translation", "abstract": "In this work, we propose to model the interaction between visual and textual features\nfor multi-modal neural machine translation\n(MMT) through a latent variable model. This\nlatent variable can be seen as a multi-modal\nstochastic embedding of an image and its description in a foreign language. It is used\nin a target-language decoder and also to predict image features. Importantly, our model\nformulation utilises visual and textual inputs\nduring training but does not require that images be available at test time. We show\nthat our latent variable MMT formulation improves considerably over strong baselines, including a multi-task learning approach (Elliottand Kad\u00b4 ar\u00b4 , 2017) and a conditional variational\nauto-encoder approach (Toyama et al., 2016).\nFinally, we show improvements due to (i) predicting image features in addition to only conditioning on them, (ii) imposing a constraint\non the minimum amount of information encoded in the latent variable, and (iii) by training on additional target-language image descriptions (i.e. synthetic data)."}}
{"id": "uWEbMSVSC8s", "cdate": 1514764800000, "mdate": null, "content": {"title": "Latent Visual Cues for Neural Machine Translation", "abstract": "In this work, we propose to model the interaction between visual and textual features for multi-modal neural machine translation (MMT) through a latent variable model. This latent variable can be seen as a multi-modal stochastic embedding of an image and its description in a foreign language. It is used in a target-language decoder and also to predict image features. Importantly, our model formulation utilises visual and textual inputs during training but does not require that images be available at test time. We show that our latent variable MMT formulation improves considerably over strong baselines, including a multi-task learning approach (Elliott and K\\'ad\\'ar, 2017) and a conditional variational auto-encoder approach (Toyama et al., 2016). Finally, we show improvements due to (i) predicting image features in addition to only conditioning on them, (ii) imposing a constraint on the minimum amount of information encoded in the latent variable, and (iii) by training on additional target-language image descriptions (i.e. synthetic data)."}}
