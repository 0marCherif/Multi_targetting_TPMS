{"id": "e9pjD8CWqM5", "cdate": 1677628800000, "mdate": 1683722602535, "content": {"title": "HINChip: Heterogeneous Information Network Representation with Community Hierarchy Preserving", "abstract": ""}}
{"id": "C8Y8zMtgsw", "cdate": 1677628800000, "mdate": 1683772451028, "content": {"title": "Hierarchical Representation Learning for Attributed Networks", "abstract": "Network representation learning, also called network embedding, aiming to learn low dimensional vectors for nodes while preserving essential properties of the network, benefits plenty of practical applications. However, how to do representation learning on the network quickly and effectively is a meaningful and challenging task, especially for the attributed networks. In this paper, we propose HANE, a <bold xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">H</b> ierarchical <bold xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">A</b> ttributed <bold xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">N</b> etwork <bold xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">E</b> mbedding framework, which is a fast and effective method by quickly constructing a hierarchical attributed network of different granularities to learn nodes representations. Specifically, for an attributed network, HANE first builds a hierarchy of successively smaller attributed network from fine to coarse by the fast granulation strategy fusing topological structure and node attributes. After using any unsupervised network embedding method to learn nodes representations of the coarsest network, HANE refines the nodes representations of the hierarchical attributed network from coarse to fine. HANE improves the speed of network representation learning while maintaining its performance and the representation learning method of the coarsest network is flexible. We conduct extensive evaluations for the proposed framework HANE on six datasets and two benchmark applications. Experimental results demonstrate that HANE achieves significant improvements over previous state-of-the-art network embedding methods in efficiency and effectiveness."}}
{"id": "Jev6I8UgL5", "cdate": 1672531200000, "mdate": 1683772451351, "content": {"title": "Adaptive social recommendation combined with the multi-domain influence", "abstract": ""}}
{"id": "5lsc4qtrGe", "cdate": 1672531200000, "mdate": 1683772451074, "content": {"title": "Robust semi-supervised clustering via data transductive warping", "abstract": "In practical applications, we are more likely to face semi-supervised data with a small amount of independent class label or constraint information and many unlabeled instances. For semi-supervised clustering, taking advantage of the small portion of preliminary label information can significantly improve the discriminability of representations. Spectral clustering has the benefits of handling any shape data distribution and converging to the optimal global solution but is susceptible to noisy data. However, it is inevitable to contain noise for real-world applications that significantly reduce clustering performance. Motivated by this, we propose a novel Robust Semi-supervised Spectral Clustering method (named RSSC) to address clustering on noise semi-supervised datasets. Specifically, in terms of data transductive warping, we map the entire semi-supervised dataset into a new data space where labeled data is close to the canonical coordinate system, and unlabeled data with similar characteristics should be close to those labeled data. The noise data is close to the origin of the coordinate and form the noise cluster because there is no guidance. Finally, samples in the same cluster are close, and different clusters are separated. Extensive experimental results on sixteen real-world datasets demonstrate that RSSC outperforms other state-of-the-art clustering methods on performance and robustness."}}
{"id": "0XWSOkZWNt", "cdate": 1672531200000, "mdate": 1683772451269, "content": {"title": "Understanding the Robustness of 3D Object Detection with Bird's-Eye-View Representations in Autonomous Driving", "abstract": "3D object detection is an essential perception task in autonomous driving to understand the environments. The Bird's-Eye-View (BEV) representations have significantly improved the performance of 3D detectors with camera inputs on popular benchmarks. However, there still lacks a systematic understanding of the robustness of these vision-dependent BEV models, which is closely related to the safety of autonomous driving systems. In this paper, we evaluate the natural and adversarial robustness of various representative models under extensive settings, to fully understand their behaviors influenced by explicit BEV features compared with those without BEV. In addition to the classic settings, we propose a 3D consistent patch attack by applying adversarial patches in the 3D space to guarantee the spatiotemporal consistency, which is more realistic for the scenario of autonomous driving. With substantial experiments, we draw several findings: 1) BEV models tend to be more stable than previous methods under different natural conditions and common corruptions due to the expressive spatial representations; 2) BEV models are more vulnerable to adversarial noises, mainly caused by the redundant BEV features; 3) Camera-LiDAR fusion models have superior performance under different settings with multi-modal inputs, but BEV fusion model is still vulnerable to adversarial noises of both point cloud and image. These findings alert the safety issue in the applications of BEV detectors and could facilitate the development of more robust models."}}
{"id": "zQvJ2mejLks", "cdate": 1640995200000, "mdate": 1683772451220, "content": {"title": "Multi-granular attributed network representation learning", "abstract": "In recent years, increasing attention has been paid to network representation learning, which aims to map nodes into low dimensional vectors while preserving topology and node attribute information, which are both backbone information of the network. Existing studies mainly focus on fusing structure and node attributes on single granularity for the attributed network. However, many complex networks present multi-granular characteristics. In this paper, we propose MultI-granular attributed network Representation Learning (MIRL), an algorithm that captures the relationship between different granular attributed networks. Firstly, topological structure and attributes are fused from fine to coarse under different granularities to mine the node potential relationship between different granular networks. The coarser-grained node is composed of a number of fine-grained nodes that are similar in structure and attributes. For the attributed network at the coarsest granularity which is much smaller than the original attributed network, one of the existing network representation learning methods can be used to learn the representation of the coarsest granularity. To obtain more accurate representation of the original network, we train a graph convolutional neural network (GCN) at the coarsest granulation. The parameters of GCN passing from coarse to fine are shared between two adjacent granularities, so as to trade off time consumption and embedding performance. We evaluate our algorithm on three real-world datasets and two benchmark applications. Our experimental results demonstrate that MIRL significantly increases effectiveness compared to state-of-art network representation methods."}}
{"id": "lSwLKd29-G", "cdate": 1640995200000, "mdate": 1683772451151, "content": {"title": "A classified feature representation three-way decision model for sentiment analysis", "abstract": "Binary sentiment analysis uses sentiment dictionaries, TF-IDF, word2vec, and BERT to convert text documents such as product and movie reviews into vectors. Dimensionality reduction by feature selection can effectively reduce the complexity of sentiment analysis. Existing feature selection methods put all samples together and ignore the difference in the feature representation between different categories. For binary sentiment analysis, there are some reviews with uncertain sentiment polarity, three-way decision divides samples into positive (POS) region, negative (NEG) region, and uncertain region (UNC). The model based on the three-way decision is beneficial to process the UNC and improve the effect of binary sentiment analysis. However, how to obtain the optimal feature representation in certain regions respectively to process the uncertain samples is a challenge. In this paper, a classified feature representation three-way decision model is proposed to obtain the optimal feature representation of the positive and negative domains for sentiment analysis. In the positive domain and the negative domain, m- and n-layer feature representations are obtained. The optimal layer with the best performance is selected as the optimal feature representation. The POS region and the NEG region in the testing set are processed by the optimal feature representation, the UNC region is processed by the original feature representation. Experiments on IMDB and Amazon show that the performance of our proposed method in terms of classification accuracy in sentiment analysis is significantly higher than that of the chi-square, principal component analysis, and mutual information methods."}}
{"id": "ee9cxtdeQi2", "cdate": 1640995200000, "mdate": 1683772451063, "content": {"title": "Using User's Expression Propensity for Sarcasm Detection Based on Sequential Three-Way Decision", "abstract": "Sarcasm detection is mainly to distinguish whether the target comment is sarcasm that can help identify the actual sentiment. The previous sarcasm detection mainly focused on text features using vocabulary, grammar, and semantics. But users\u2019 expression propensity is ignored which is helpful to distinguish some comments with uncertain sarcasm polarity in sarcasm detection. However, how to use the user\u2019s expression propensity for sarcasm detection effectively is a challenge. Based on the ideas of granular computing and three-way decisions, we propose a sarcasm detection model based on the sequential three-way decision (S3WD) to integrate text features and users\u2019 expression propensity. The S3WD divides the comments into the sarcasm (SAR) region, non-sarcasm (NSAR) region, and boundary region (BND), and then gradually divides the uncertain BND region into a clear SAR region and NSAR region. We firstly construct a sequential structure through analysis sentiment of comments\u2019 chunks. Second, text features and users\u2019 expression propensity are fed into different sequential layers for fusion that can guide the comment classification more effectively. Finally, contextual information is further applied to consider sentiment context during sarcasm detection. The experimental results on a large Reddit corpus show that our model improves sarcasm classification performance effectively."}}
{"id": "ddFZ9mIi9A", "cdate": 1640995200000, "mdate": 1683772451019, "content": {"title": "Online Scalable Streaming Feature Selection via Dynamic Decision", "abstract": "Feature selection is one of the core concepts in machine learning, which hugely impacts the model\u2019s performance. For some real-world applications, features may exist in a stream mode that arrives one by one over time, while we cannot know the exact number of features before learning. Online streaming feature selection aims at selecting optimal stream features at each timestamp on the fly. Without the global information of the entire feature space, most of the existing methods select stream features in terms of individual feature information or the comparison of features in pairs. This article proposes a new online scalable streaming feature selection framework from the dynamic decision perspective that is scalable on running time and selected features by dynamic threshold adjustment. Regarding the philosophy of \u201cThinking-in-Threes\u201d, we classify each new arrival feature as selecting, discarding, or delaying, aiming at minimizing the overall decision risks. With the dynamic updating of global statistical information, we add the selecting features into the candidate feature subset, ignore the discarding features, cache the delaying features into the undetermined feature subset, and wait for more information. Meanwhile, we perform the redundancy analysis for the candidate features and uncertainty analysis for the undetermined features. Extensive experiments on eleven real-world datasets demonstrate the efficiency and scalability of our new framework compared with state-of-the-art algorithms."}}
{"id": "cZ3NWCm8oH", "cdate": 1640995200000, "mdate": 1683772451269, "content": {"title": "A Joint Learning Sentiment Analysis Method Incorporating Emoji-Augmentation", "abstract": "Social media is the platform for most people to share their opinions, emojis are also widely used to express moods, emotions, and feelings on social media. There have been many researched on emojis and sentiment analysis. However, existing methods mainly face two limitations. First, since deep learning relies on large amounts of labeled data, the training samples of emoji are not enough to achieve the training effect. Second, they consider the sentiment of emojis and texts separately, not fully exploring the impact of emojis on the sentiment polarity of texts. In this paper, we propose a joint learning sentiment analysis method incorporating emoji-augmentation, and the method has two advantages compared with the existing work. First, We optimize the easy data augmentation method so that the newly generated sentences can also preserve the semantic information of emojis, which relieves the problem of insufficient training data with emojis. Second, it fuses emojis and text features to allow the model to better learn the mutual emotional semantics between text and emojis, jointly training emojis and words to obtain the sentence representations containing more semantic information of both emojis and text. Our experimental results show that the proposed method can significantly improve the performance compared with several baselines on two datasets."}}
