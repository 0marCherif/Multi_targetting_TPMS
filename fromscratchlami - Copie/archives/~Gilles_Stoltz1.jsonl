{"id": "HkD0_G9JMQo", "cdate": 1672531200000, "mdate": 1681649728920, "content": {"title": "On Best-Arm Identification with a Fixed Budget in Non-Parametric Multi-Armed Bandits", "abstract": ""}}
{"id": "OoN6TVb4Vkq", "cdate": 1652737410404, "mdate": null, "content": {"title": "Contextual Bandits with Knapsacks for a Conversion Model", "abstract": "We consider contextual bandits with knapsacks, with an underlying structure between rewards generated and cost vectors suffered. We do so motivated by sales with commercial discounts. At each round, given the stochastic i.i.d.\\ context $\\mathbf{x}_t$ and the arm picked $a_t$ (corresponding, e.g., to a discount level), a customer conversion may be obtained, in which case a reward $r(a,\\mathbf{x}_t)$ is gained and vector costs $\\mathbf{c}(a_t,\\mathbf{x}_t)$ are suffered (corresponding, e.g., to losses of earnings). Otherwise, in the absence of a conversion, the reward and costs are null. The reward and costs achieved are thus coupled through the binary variable measuring conversion or the absence thereof. This underlying structure between rewards and costs is different from the linear structures considered by Agrawal and Devanur [2016] (but we show that the techniques introduced in the present article may also be applied to the case of these linear structures). The adaptive policies exhibited in this article solve at each round a linear program based on upper-confidence estimates of the probabilities of conversion given $a$ and $\\mathbf{x}$. This kind of policy is most natural and achieves a regret bound of the typical order $(\\mathrm{OPT}/B) \\smash{\\sqrt{T}}$, where $B$ is the total budget allowed, $\\mathrm{OPT}$ is the optimal expected reward achievable by a static policy, and $T$ is the number of rounds. "}}
{"id": "xTjr967iH8k", "cdate": 1640995200000, "mdate": 1681649728926, "content": {"title": "Contextual Bandits with Knapsacks for a Conversion Model", "abstract": ""}}
{"id": "7tySiKteZ5W", "cdate": 1640995200000, "mdate": 1681649728814, "content": {"title": "On Best-Arm Identification with a Fixed Budget in Non-Parametric Multi-Armed Bandits", "abstract": ""}}
{"id": "vMWHOumNj5", "cdate": 1621630182424, "mdate": null, "content": {"title": "A Unified Approach to Fair Online Learning via Blackwell Approachability", "abstract": "We provide a setting and a general approach to fair online learning with stochastic sensitive and non-sensitive contexts.\nThe setting is a repeated game between the Player and Nature, where at each stage both pick actions based on the contexts. Inspired by the notion of unawareness, we assume that the Player can only access the non-sensitive context before making a decision, while we discuss both cases of Nature accessing the sensitive contexts and Nature unaware of the sensitive contexts. Adapting Blackwell's approachability theory to handle the case of an unknown contexts' distribution, we provide a general necessary and sufficient condition for learning objectives to be compatible with some fairness constraints. This condition is instantiated on (group-wise) no-regret and (group-wise) calibration objectives, and on demographic parity as an additional constraint. When the objective is not compatible with the constraint, the provided framework permits to characterise the optimal trade-off between the two."}}
{"id": "_dIb-A7nth9", "cdate": 1609459200000, "mdate": 1681649728882, "content": {"title": "A Unified Approach to Fair Online Learning via Blackwell Approachability", "abstract": ""}}
{"id": "4lI_0engNm", "cdate": 1609459200000, "mdate": 1681649728851, "content": {"title": "A Unified Approach to Fair Online Learning via Blackwell Approachability", "abstract": ""}}
{"id": "mHPF2xDQVR", "cdate": 1577836800000, "mdate": 1681649728926, "content": {"title": "Diversity-Preserving K-Armed Bandits, Revisited", "abstract": ""}}
{"id": "oRxPQJbhF0J", "cdate": 1546300800000, "mdate": 1681649728931, "content": {"title": "Target Tracking for Contextual Bandits: Application to Demand Side Management", "abstract": ""}}
{"id": "jPS3Hkn4_Q-", "cdate": 1546300800000, "mdate": 1681649728864, "content": {"title": "Uniform regret bounds over Rd for the sequential linear regression problem with the square loss", "abstract": ""}}
