{"id": "7qsyRc30yD", "cdate": 1672531200000, "mdate": 1683878767872, "content": {"title": "Addressing bias in online selection with limited budget of comparisons", "abstract": "Consider a hiring process with candidates coming from different universities. It is easy to order candidates who have the same background, yet it can be challenging to compare them otherwise. The latter case requires additional costly assessments and can result in sub-optimal hiring decisions. Given an assigned budget, what would be an optimal strategy to select the most qualified candidate? We model the above problem by introducing a new variant of the secretary problem in which sequentially observed candidates are split into two distinct groups. For each new candidate, the decision maker observes its rank among already seen candidates from the same group and can access its rank among all observed candidates at some fixed cost. To tackle this new problem, we introduce and study the family of Dynamic Double Threshold (DDT) algorithms. We show that, with well-chosen parameters, their success probability converges rapidly to 1/e as the budget grows, recovering the optimal success probability from the usual secretary problem. Finally, focusing on the class of memory-less algorithms, we propose an optimal algorithm in the non-asymptotic regime and show that it belongs to the DDT family when the number of candidates is large."}}
{"id": "1PRnYiuJkQx", "cdate": 1652737695018, "mdate": null, "content": {"title": "A gradient estimator via L1-randomization for online zero-order optimization with two point feedback", "abstract": "This work studies online zero-order optimization of convex and Lipschitz functions. We present  a novel gradient estimator based on two function evaluations and randomization on the $\\ell_1$-sphere. Considering different geometries of feasible sets and Lipschitz assumptions we analyse online dual averaging algorithm with our estimator in place of the usual gradient. We consider two types of  assumptions on the noise of the zero-order oracle: canceling noise and adversarial noise. We provide an anytime and completely data-driven algorithm, which is adaptive to all parameters of the problem. In the case of canceling noise that was previously studied in the literature, our guarantees are either comparable or better than state-of-the-art bounds obtained by~\\citet{duchi2015} and \\citet{Shamir17} for non-adaptive algorithms. Our analysis is based on deriving a new weighted Poincar\u00e9 type inequality for the uniform measure on the $\\ell_1$-sphere with explicit constants, which may be of independent interest."}}
{"id": "nvQQco8bqPO", "cdate": 1640995200000, "mdate": 1681745592074, "content": {"title": "Fair learning with Wasserstein barycenters for non-decomposable performance measures", "abstract": "This work provides several fundamental characterizations of the optimal classification function under the demographic parity constraint. In the awareness framework, akin to the classical unconstrained classification case, we show that maximizing accuracy under this fairness constraint is equivalent to solving a corresponding regression problem followed by thresholding at level $1/2$. We extend this result to linear-fractional classification measures (e.g., ${\\rm F}$-score, AM measure, balanced accuracy, etc.), highlighting the fundamental role played by the regression problem in this framework. Our results leverage recently developed connection between the demographic parity constraint and the multi-marginal optimal transport formulation. Informally, our result shows that the transition between the unconstrained problems and the fair one is achieved by replacing the conditional expectation of the label by the solution of the fair regression problem. Finally, leveraging our analysis, we demonstrate an equivalence between the awareness and the unawareness setups in the case of two sensitive groups."}}
{"id": "7qdwTL3bnMy", "cdate": 1640995200000, "mdate": 1683878767811, "content": {"title": "A gradient estimator via L1-randomization for online zero-order optimization with two point feedback", "abstract": "This work studies online zero-order optimization of convex and Lipschitz functions. We present a novel gradient estimator based on two function evaluations and randomization on the $\\ell_1$-sphere. Considering different geometries of feasible sets and Lipschitz assumptions we analyse online dual averaging algorithm with our estimator in place of the usual gradient. We consider two types of assumptions on the noise of the zero-order oracle: canceling noise and adversarial noise. We provide an anytime and completely data-driven algorithm, which is adaptive to all parameters of the problem. In the case of canceling noise that was previously studied in the literature, our guarantees are either comparable or better than state-of-the-art bounds obtained by~\\citet{duchi2015} and \\citet{Shamir17} for non-adaptive algorithms. Our analysis is based on deriving a new weighted Poincar\u00e9 type inequality for the uniform measure on the $\\ell_1$-sphere with explicit constants, which may be of independent interest."}}
{"id": "vMWHOumNj5", "cdate": 1621630182424, "mdate": null, "content": {"title": "A Unified Approach to Fair Online Learning via Blackwell Approachability", "abstract": "We provide a setting and a general approach to fair online learning with stochastic sensitive and non-sensitive contexts.\nThe setting is a repeated game between the Player and Nature, where at each stage both pick actions based on the contexts. Inspired by the notion of unawareness, we assume that the Player can only access the non-sensitive context before making a decision, while we discuss both cases of Nature accessing the sensitive contexts and Nature unaware of the sensitive contexts. Adapting Blackwell's approachability theory to handle the case of an unknown contexts' distribution, we provide a general necessary and sufficient condition for learning objectives to be compatible with some fairness constraints. This condition is instantiated on (group-wise) no-regret and (group-wise) calibration objectives, and on demographic parity as an additional constraint. When the objective is not compatible with the constraint, the provided framework permits to characterise the optimal trade-off between the two."}}
{"id": "v34M7mss-iT", "cdate": 1609459200000, "mdate": 1683878767691, "content": {"title": "Classification with abstention but without disparities", "abstract": "Classification with abstention has gained a lot of attention in recent years as it allows to incorporate human decision-makers in the process. Yet, abstention can potentially amplify disparities and lead to discriminatory predictions. The goal of this work is to build a general purpose classification algorithm, which is able to abstain from prediction, while avoiding disparate impact. We formalize this problem as risk minimization under fairness and abstention constraints for which we derive the form of the optimal classifier. Building on this result, we propose a post-processing classification algorithm, which is able to modify any off-the-shelf score-based classifier using only unlabeled sample. We establish finite sample risk, fairness, and abstention guarantees for the proposed algorithm. In particular, it is shown that fairness and abstention constraints can be achieved independently from the initial classifier as long as sufficiently many unlabeled data is available. The risk guarantee is established in terms of the quality of the initial classifier. Our post-processing scheme reduces to a sparse linear program allowing for an efficient implementation, which we provide. Finally, we validate our method empirically showing that moderate abstention rates allow to bypass the risk-fairness trade-off."}}
{"id": "alhhxbv4Q-", "cdate": 1609459200000, "mdate": 1683878767767, "content": {"title": "Classification with abstention but without disparities", "abstract": "Classification with abstention has gained a lot of attention in recent years as it allows to incorporate human decision-makers in the process. Yet, abstention can potentially amplify disparities an..."}}
{"id": "_dIb-A7nth9", "cdate": 1609459200000, "mdate": 1681649728882, "content": {"title": "A Unified Approach to Fair Online Learning via Blackwell Approachability", "abstract": ""}}
{"id": "YkOPQKUf0Fq", "cdate": 1609459200000, "mdate": 1683878767733, "content": {"title": "Set-valued classification - overview via a unified framework", "abstract": "Multi-class classification problem is among the most popular and well-studied statistical frameworks. Modern multi-class datasets can be extremely ambiguous and single-output predictions fail to deliver satisfactory performance. By allowing predictors to predict a set of label candidates, set-valued classification offers a natural way to deal with this ambiguity. Several formulations of set-valued classification are available in the literature and each of them leads to different prediction strategies. The present survey aims to review popular formulations using a unified statistical framework. The proposed framework encompasses previously considered and leads to new formulations as well as it allows to understand underlying trade-offs of each formulation. We provide infinite sample optimal set-valued classification strategies and review a general plug-in principle to construct data-driven algorithms. The exposition is supported by examples and pointers to both theoretical and practical contributions. Finally, we provide experiments on real-world datasets comparing these approaches in practice and providing general practical guidelines."}}
{"id": "4lI_0engNm", "cdate": 1609459200000, "mdate": 1681649728851, "content": {"title": "A Unified Approach to Fair Online Learning via Blackwell Approachability", "abstract": ""}}
