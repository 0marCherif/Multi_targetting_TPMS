{"id": "xDMSAe0jif", "cdate": 1640995200000, "mdate": 1672071367462, "content": {"title": "The Randomized k-Server Conjecture is False!", "abstract": "We prove a few new lower bounds on the randomized competitive ratio for the $k$-server problem and other related problems, resolving some long-standing conjectures. In particular, for metrical task systems (MTS) we asympotically settle the competitive ratio and obtain the first improvement to an existential lower bound since the introduction of the model 35 years ago (in 1987). More concretely, we show: 1. There exist $(k+1)$-point metric spaces in which the randomized competitive ratio for the $k$-server problem is $\\Omega(\\log^2 k)$. This refutes the folklore conjecture (which is known to hold in some families of metrics) that in all metric spaces with at least $k+1$ points, the competitive ratio is $\\Theta(\\log k)$. 2. Consequently, there exist $n$-point metric spaces in which the randomized competitive ratio for MTS is $\\Omega(\\log^2 n)$. This matches the upper bound that holds for all metrics. The previously best existential lower bound was $\\Omega(\\log n)$ (which was known to be tight for some families of metrics). 3. For all $k<n\\in\\mathbb N$, for *all* $n$-point metric spaces the randomized $k$-server competitive ratio is at least $\\Omega(\\log k)$, and consequently the randomized MTS competitive ratio is at least $\\Omega(\\log n)$. These universal lower bounds are asymptotically tight. The previous bounds were $\\Omega(\\log k/\\log\\log k)$ and $\\Omega(\\log n/\\log \\log n)$, respectively. 4. The randomized competitive ratio for the $w$-set metrical service systems problem, and its equivalent width-$w$ layered graph traversal problem, is $\\Omega(w^2)$. This slightly improves the previous lower bound and matches the recently discovered upper bound. 5. Our results imply improved lower bounds for other problems like $k$-taxi, distributed paging and metric allocation. These lower bounds share a common thread, and other than the third bound, also a common construction."}}
{"id": "ZnJKRVYeNUf", "cdate": 1640995200000, "mdate": 1672071367510, "content": {"title": "Learning-Augmented Weighted Paging", "abstract": "We consider a natural semi-online model for weighted paging, where at any time the algorithm is given predictions, possibly with errors, about the next arrival of each page. The model is inspired by Belady's classic optimal offline algorithm for unweighted paging, and extends the recently studied model for learning-augmented paging [45, 50, 52] to the weighted setting. For the case of perfect predictions, we provide an \u2113-competitive deterministic and an O(log \u2113)-competitive randomized algorithm, where \u2113 is the number of distinct weight classes. Both these bounds are tight, and imply an O(log W)- and O(log log W)-competitive ratio, respectively, when the page weights lie between 1 and W. Previously, it was not known how to use these predictions in the weighted setting and only bounds of k and O(log k) were known, where k is the cache size. Our results also generalize to the interleaved paging setting and to the case of imperfect predictions, with the competitive ratios degrading smoothly from O(\u2113) and O(log \u2113) to O(k) and O(log k), respectively, as the prediction error increases. Our results are based on several insights on structural properties of Belady's algorithm and the sequence of page arrival predictions, and novel potential functions that incorporate these predictions. For the case of unweighted paging, the results imply a very simple potential function based proof of the optimality of Belady's algorithm, which may be of independent interest."}}
{"id": "LD545GbNQE", "cdate": 1640995200000, "mdate": 1672071367452, "content": {"title": "Online Metric Allocation and Time-Varying Regularization", "abstract": "We introduce a general online allocation problem that connects several of the most fundamental problems in online optimization. Let M be an n-point metric space. Consider a resource that can be allocated in arbitrary fractions to the points of M. At each time t, a convex monotone cost function c_t: [0,1] \u2192 \u211d_+ appears at some point r_t \u2208 M. In response, an algorithm may change the allocation of the resource, paying movement cost as determined by the metric and service cost c_t(x_{r_t}), where x_{r_t} is the fraction of the resource at r_t at the end of time t. For example, when the cost functions are c_t(x) = \u03b1 x, this is equivalent to randomized MTS, and when the cost functions are c_t(x) = \u221e\u22c51_{x < 1/k}, this is equivalent to fractional k-server. Because of an inherent scale-freeness property of the problem, existing techniques for MTS and k-server fail to achieve similar guarantees for metric allocation. To handle this, we consider a generalization of the online multiplicative update method where we decouple the rate at which a variable is updated from its value, resulting in interesting new dynamics. We use this to give an O(log n)-competitive algorithm for weighted star metrics. We then show how this corresponds to an extension of the online mirror descent framework to a setting where the regularizer is time-varying. Using this perspective, we further refine the guarantees of our algorithm. We also consider the case of non-convex cost functions. Using a simple \ud835\udcc1\u2082\u00b2-regularizer, we give tight bounds of \u0398(n) on tree metrics, which imply deterministic and randomized competitive ratios of O(n\u00b2) and O(nlog n) respectively on arbitrary metrics."}}
{"id": "E5ZWYhuQnf", "cdate": 1640995200000, "mdate": 1672071367581, "content": {"title": "Competitive Algorithms for Block-Aware Caching", "abstract": "Motivated by the design of real system storage hierarchies, we study the block-aware caching problem, a generalization of classic caching in which fetching (or evicting) pages from the same block incurs the same cost as fetching (or evicting) just one page from the block. Given a cache of size k, and a sequence of requests from n pages partitioned into given blocks of size \u03b2 \u2264 k, the goal is to minimize the total cost of fetching to (or evicting from) cache. This problem captures generalized caching as a special case, which is already NP-hard offline. We show the following suite of results: For the eviction cost model, we show an O(log k)-approximate offline algorithm, a k-competitive deterministic online algorithm, and an O(log2 k)-competitive randomized online algorithm. For the fetching cost model, we show an integrality gap of \u03a9(\u03b2) for the natural LP relaxation of the problem, and an \u03a9(\u03b2 +log k) lower bound for randomized online algorithms. The strategy of ignoring the block-structure and running a classical paging algorithm trivially achieves an O(\u03b2) approximation and an O(\u03b2 log k) competitive ratio respectively for the offline and online-randomized setting. For both fetching and eviction models, we show improved bounds for the (h, k)-bicriteria version of the problem. In particular, when k = 2h, we match the performance of classical caching algorithms up to constant factors. Our results establish a strong separation between the tractability of the fetching and eviction cost models, which is interesting since fetching/eviction costs are the same up to an additive term for the classic caching problem. Previous work of Beckmann et al. (SPAA 21) only studied online deterministic algorithms for the fetching cost model when k > h. Our insight is to relax the block-aware caching problem to a submodular covering linear program. The main technical challenge is to maintain a competitive fractional solution to this LP, and to round it with bounded loss, as the constraints of this LP are revealed online. We hope that this framework is useful going forward for other problems that can be captured as submodular cover."}}
{"id": "5FBHVUIJcU", "cdate": 1640995200000, "mdate": 1672071367579, "content": {"title": "Shortest Paths without a Map, but with an Entropic Regularizer", "abstract": "In a 1989 paper titled \"shortest paths without a map\", Papadimitriou and Yannakakis introduced an online model of searching in a weighted layered graph for a target node, while attempting to minimize the total length of the path traversed by the searcher. This problem, later called layered graph traversal, is parametrized by the maximum cardinality $k$ of a layer of the input graph. It is an online setting for dynamic programming, and it is known to be a rather general and fundamental model of online computing, which includes as special cases other acclaimed models. The deterministic competitive ratio for this problem was soon discovered to be exponential in $k$, and it is now nearly resolved: it lies between $\\Omega(2^k)$ and $O(k2^k)$. Regarding the randomized competitive ratio, in 1993 Ramesh proved, surprisingly, that this ratio has to be at least $\\Omega(k^2 / \\log^{1+\\epsilon} k)$ (for any constant $\\epsilon > 0$). In the same paper, Ramesh also gave an $O(k^{13})$-competitive randomized online algorithm. Since 1993, no progress has been reported on the randomized competitive ratio of layered graph traversal. In this work we show how to apply the mirror descent framework on a carefully selected evolving metric space, and obtain an $O(k^2)$-competitive randomized online algorithm, nearly matching the known lower bound on the randomized competitive ratio."}}
{"id": "xkQ4MhLv52X", "cdate": 1621629840196, "mdate": null, "content": {"title": "Learning-Augmented Dynamic Power Management with Multiple States via New Ski Rental Bounds", "abstract": "We study the online problem of minimizing power consumption in systems with multiple power-saving states. During idle periods of unknown lengths, an algorithm has to choose between power-saving states of different energy consumption and wake-up costs. We develop a learning-augmented online algorithm that makes decisions based on (potentially inaccurate) predicted lengths of the idle periods. The algorithm's performance is near-optimal when predictions are accurate and degrades gracefully with increasing prediction error, with a worst-case guarantee almost identical to the optimal classical online algorithm for the problem. A key ingredient in our approach is a new algorithm for the online ski-rental problem in the learning augmented setting with tight dependence on the prediction error. We support our theoretical findings with experiments."}}
{"id": "EX1drMVwl3O", "cdate": 1621629840196, "mdate": null, "content": {"title": "Learning-Augmented Dynamic Power Management with Multiple States via New Ski Rental Bounds", "abstract": "We study the online problem of minimizing power consumption in systems with multiple power-saving states. During idle periods of unknown lengths, an algorithm has to choose between power-saving states of different energy consumption and wake-up costs. We develop a learning-augmented online algorithm that makes decisions based on (potentially inaccurate) predicted lengths of the idle periods. The algorithm's performance is near-optimal when predictions are accurate and degrades gracefully with increasing prediction error, with a worst-case guarantee almost identical to the optimal classical online algorithm for the problem. A key ingredient in our approach is a new algorithm for the online ski-rental problem in the learning augmented setting with tight dependence on the prediction error. We support our theoretical findings with experiments."}}
{"id": "ZbP0cfr_dG", "cdate": 1609459200000, "mdate": 1672071367505, "content": {"title": "The Infinite Server Problem", "abstract": "We study a variant of the k-server problem, the infinite server problem, in which infinitely many servers reside initially at a particular point of the metric space and serve a sequence of requests. In the framework of competitive analysis, we show a surprisingly tight connection between this problem and the resource augmentation version of the k-server problem, also known as the (h,k)-server problem, in which an online algorithm with k servers competes against an offline algorithm with h servers. Specifically, we show that the infinite server problem has bounded competitive ratio if and only if the (h,k)-server problem has bounded competitive ratio for some k=O(h). We give a lower bound of 3.146 for the competitive ratio of the infinite server problem, which holds even for the line and some simple weighted stars. It implies the same lower bound for the (h,k)-server problem on the line, even when k/h \u2192 \u221e, improving on the previous known bounds of 2 for the line and 2.4 for general metrics. For weighted trees and layered graphs, we obtain upper bounds, although they depend on the depth. Of particular interest is the infinite server problem on the line, which we show to be equivalent to the seemingly easier case in which all requests are in a fixed bounded interval. This is a special case of a more general reduction from arbitrary metric spaces to bounded subspaces. Unfortunately, classical approaches (double coverage and generalizations, work function algorithm, balancing algorithms) fail even for this special case."}}
{"id": "Oi0yJbACnjo", "cdate": 1609459200000, "mdate": 1672071367515, "content": {"title": "Towards the k-Server Conjecture: A Unifying Potential, Pushing the Frontier to the Circle", "abstract": "The k-server conjecture, first posed by Manasse, McGeoch and Sleator in 1988, states that a k-competitive deterministic algorithm for the k-server problem exists. It is conjectured that the work function algorithm (WFA) achieves this guarantee, a multi-purpose algorithm with applications to various online problems. This has been shown for several special cases: k = 2, (k+1)-point metrics, (k+2)-point metrics, the line metric, weighted star metrics, and k = 3 in the Manhattan plane. The known proofs of these results are based on potential functions tied to each particular special case, thus requiring six different potential functions for the six cases. We present a single potential function proving k-competitiveness of WFA for all these cases. We also use this potential to show k-competitiveness of WFA on multiray spaces and for k = 3 on trees. While the DoubleCoverage algorithm was known to be k-competitive for these latter cases, it has been open for WFA. Our potential captures a type of lazy adversary and thus shows that in all settled cases, the worst-case adversary is lazy. Chrobak and Larmore conjectured in 1992 that a potential capturing the lazy adversary would resolve the k-server conjecture. To our major surprise, this is not the case, as we show (using connections to the k-taxi problem) that our potential fails for three servers on the circle. Thus, our potential highlights laziness of the adversary as a fundamental property that is shared by all settled cases but violated in general. On the one hand, this weakens our confidence in the validity of the k-server conjecture. On the other hand, if the k-server conjecture holds, then we believe it can be proved by a variant of our potential."}}
{"id": "5hYmSrVs9cb", "cdate": 1609459200000, "mdate": null, "content": {"title": "Metrical Service Systems with Transformations", "abstract": "We consider a generalization of the fundamental online metrical service systems (MSS) problem where the feasible region can be transformed between requests. In this problem, which we call T-MSS, an algorithm maintains a point in a metric space and has to serve a sequence of requests. Each request is a map (transformation) f_t: A_t \u2192 B_t between subsets A_t and B_t of the metric space. To serve it, the algorithm has to go to a point a_t \u2208 A_t, paying the distance from its previous position. Then, the transformation is applied, modifying the algorithm\u2019s state to f_t(a_t). Such transformations can model, e.g., changes to the environment that are outside of an algorithm\u2019s control, and we therefore do not charge any additional cost to the algorithm when the transformation is applied. The transformations also allow to model requests occurring in the k-taxi problem. We show that for \u03b1-Lipschitz transformations, the competitive ratio is \u0398(\u03b1)^{n-2} on n-point metrics. Here, the upper bound is achieved by a deterministic algorithm and the lower bound holds even for randomized algorithms. For the k-taxi problem, we prove a competitive ratio of \u00d5((nlog k)\u00b2). For chasing convex bodies, we show that even with contracting transformations no competitive algorithm exists. The problem T-MSS has a striking connection to the following deep mathematical question: Given a finite metric space M, what is the required cardinality of an extension M\u0302 \u2287 M where each partial isometry on M extends to an automorphism? We give partial answers for special cases."}}
