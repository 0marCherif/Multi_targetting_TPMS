{"id": "5dHQyEcYDgA", "cdate": 1652737664640, "mdate": null, "content": {"title": "Additive MIL: Intrinsically Interpretable Multiple Instance Learning for Pathology", "abstract": "Multiple Instance Learning (MIL) has been widely applied in pathology towards solving critical problems such as automating cancer diagnosis and grading, predicting patient prognosis, and therapy response. Deploying these models in a clinical setting requires careful inspection of these black boxes during development and deployment to identify failures and maintain physician trust. In this work, we propose a simple formulation of MIL models, which enables interpretability while maintaining similar predictive performance. Our Additive MIL models enable spatial credit assignment such that the contribution of each region in the image can be exactly computed and visualized. We show that our spatial credit assignment coincides with regions used by pathologists during diagnosis and improves upon classical attention heatmaps from attention MIL models. We show that any existing MIL model can be made additive with a simple change in function composition. We also show how these models can debug model failures, identify spurious features, and highlight class-wise regions of interest, enabling their use in high-stakes environments such as clinical decision-making."}}
{"id": "zxnWfLThDVb", "cdate": 1640995200000, "mdate": 1667342073192, "content": {"title": "Rethinking Machine Learning Model Evaluation in Pathology", "abstract": ""}}
{"id": "ffqGcpst7H", "cdate": 1640995200000, "mdate": 1667342073235, "content": {"title": "Additive MIL: Intrinsic Interpretability for Pathology", "abstract": ""}}
{"id": "Vf7dLnniVfW", "cdate": 1640995200000, "mdate": 1667342083744, "content": {"title": "Additive MIL: Intrinsic Interpretability for Pathology", "abstract": "Multiple Instance Learning (MIL) has been widely applied in pathology towards solving critical problems such as automating cancer diagnosis and grading, predicting patient prognosis, and therapy response. Deploying these models in a clinical setting requires careful inspection of these black boxes during development and deployment to identify failures and maintain physician trust. In this work, we propose a simple formulation of MIL models, which enables interpretability while maintaining similar predictive performance. Our Additive MIL models enable spatial credit assignment such that the contribution of each region in the image can be exactly computed and visualized. We show that our spatial credit assignment coincides with regions used by pathologists during diagnosis and improves upon classical attention heatmaps from attention MIL models. We show that any existing MIL model can be made additive with a simple change in function composition. We also show how these models can debug model failures, identify spurious features, and highlight class-wise regions of interest, enabling their use in high-stakes environments such as clinical decision-making."}}
{"id": "C4PvhuAuEp", "cdate": 1640995200000, "mdate": 1667342083722, "content": {"title": "Rethinking Machine Learning Model Evaluation in Pathology", "abstract": "Machine Learning has been applied to pathology images in research and clinical practice with promising outcomes. However, standard ML models often lack the rigorous evaluation required for clinical decisions. Machine learning techniques for natural images are ill-equipped to deal with pathology images that are significantly large and noisy, require expensive labeling, are hard to interpret, and are susceptible to spurious correlations. We propose a set of practical guidelines for ML evaluation in pathology that address the above concerns. The paper includes measures for setting up the evaluation framework, effectively dealing with variability in labels, and a recommended suite of tests to address issues related to domain shift, robustness, and confounding variables. We hope that the proposed framework will bridge the gap between ML researchers and domain experts, leading to wider adoption of ML techniques in pathology and improving patient outcomes."}}
{"id": "cQtvK2ZXrze", "cdate": 1577836800000, "mdate": 1667342073218, "content": {"title": "Embodied Language Grounding With 3D Visual Feature Representations", "abstract": ""}}
{"id": "DK4bAGvqNCq", "cdate": 1577836800000, "mdate": 1667342083744, "content": {"title": "CineFilter: Unsupervised Filtering for Real Time Autonomous Camera Systems", "abstract": "Autonomous camera systems are often subjected to an optimization operation to smoothen and stabilize the rough trajectory estimates. Most common filtering techniques do reduce the irregularities in data; however, they fail to mimic the behavior of a human cameraman. Global filtering methods modeling human camera operators have been successful; however, they are limited to offline settings. In this paper, we propose two online filtering methods called Cinefilters, which produce smooth camera trajectories that are motivated by cinematographic principles. The first filter (CineConvex) uses a sliding windowbased convex optimization formulation, and the second (CineCNN) is a CNN based encoder-decoder model. We evaluate the proposed filters in two different settings, namely a basketball dataset and a stage performance dataset. Our models outperform previous methods and baselines on quantitative metrics. The CineConvex and CineCNN filters operate at about 250fps and 1000fps, respectively, with a minor latency (half a second), making them apt for a variety of real-time applications."}}
{"id": "DG3i1ZszSk", "cdate": 1577836800000, "mdate": 1667342083746, "content": {"title": "Embodied Language Grounding With 3D Visual Feature Representations", "abstract": "We propose associating language utterances to 3D visual abstractions of the scene they describe. The 3D visual abstractions are encoded as 3-dimensional visual feature maps. We infer these 3D visual scene feature maps from RGB images of the scene via view prediction: when the generated 3D scene feature map is neurally projected from a camera viewpoint, it should match the corresponding RGB image. We present generative models that condition on the dependency tree of an utterance and generate a corresponding visual 3D feature map as well as reason about its plausibility, and detector models that condition on both the dependency tree of an utterance and a related image and localize the object referents in the 3D feature map inferred from the image. Our model outperforms models of language and vision that associate language with 2D CNN activations or 2D images by a large margin in a variety of tasks, such as, classifying plausibility of utterances, detecting referential expressions, and supplying rewards for trajectory optimization of object placement policies from language instructions. We perform numerous ablations and show the improved performance of our detectors is due to its better generalization across camera viewpoints and lack of object interferences in the inferred 3D feature space, and the improved performance of our generators is due to their ability to spatially reason about objects and their configurations in 3D when mapping from language to scenes."}}
{"id": "04_0AwJl34", "cdate": 1577836800000, "mdate": 1667342073223, "content": {"title": "CineFilter: Unsupervised Filtering for Real Time Autonomous Camera Systems", "abstract": ""}}
{"id": "SJgAURVtPH", "cdate": 1569439318145, "mdate": null, "content": {"title": "Embodied Language Grounding with Implicit 3D Visual Feature Representations", "abstract": "Consider the utterance \u201cthe tomato is to the left of the pot\u201d. Humans can answer numerous questions about the situation described, as well as reason through counterfactuals and alternatives, such as, \u201cis the pot larger than the tomato?\u201d, \u201ccan we move to a viewpoint from which the tomato is completely hidden behind the pot?\u201d, \u201ccan we have an object that is both to the left of the tomato and to the right of the pot?\u201d, \u201cwould the tomato fit inside the pot?\u201d, and so on. Such reasoning capability remains elusive from current computational models of language understanding. To link language processing with spatial reasoning, we propose associating natural language utterances to a mental workspace of their meaning, encoded as 3-dimensional visual feature representations of the world scenes they describe. We learn such 3-dimensional visual representations\u2014we call them visual imaginations\u2014  by predicting images a mobile agent sees while moving around in the 3D world.  The input image streams the agent collects are unprojected into egomotion-stable 3D scene feature maps of the scene, and projected from novel viewpoints to match the observed RGB image views in an end-to-end differentiable manner.  We then train modular neural models to generate such 3Dfeature representations given language utterances,  to localize the objects an utterance mentions in the 3D feature representation inferred from an image, and to predict the desired 3D object locations given a manipulation instruction.  We empirically show the proposed models outperform by a large margin existing 2D models in spatial reasoning, referential object detection and instruction following, and generalize better across camera viewpoints and object arrangements."}}
