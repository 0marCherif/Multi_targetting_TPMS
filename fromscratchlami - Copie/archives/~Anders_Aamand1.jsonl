{"id": "NgwrhCBPTVk", "cdate": 1652737823656, "mdate": null, "content": {"title": "(Optimal) Online Bipartite Matching with Degree Information", "abstract": "We propose a model for online graph problems where algorithms are given access to an oracle that predicts (e.g., based on modeling assumptions or past data) the degrees of nodes in the graph. Within this model, we study the classic problem of online bipartite matching, and a natural greedy matching algorithm called MinPredictedDegree, which uses predictions of the degrees of offline nodes. For the bipartite version of a stochastic graph model due to Chung, Lu, and Vu where the expected values of the offline degrees are known and used as predictions, we show that MinPredictedDegree stochastically dominates any other online algorithm, i.e., it is optimal for graphs drawn from this model. Since the \"symmetric\" version of the model, where all online nodes are identical, is a special case of the well-studied \"known i.i.d. model\", it follows that the competitive ratio of MinPredictedDegree on such inputs is at least 0.7299. For the special case of graphs with power law degree distributions, we show that MinPredictedDegree frequently produces matchings almost as large as the true maximum matching on such graphs. We complement these results with an extensive empirical evaluation showing that MinPredictedDegree compares favorably to state-of-the-art online algorithms for online matching.  "}}
{"id": "AyGJDpN2eR6", "cdate": 1652737741823, "mdate": null, "content": {"title": "Exponentially Improving the Complexity of Simulating the Weisfeiler-Lehman Test with Graph Neural Networks", "abstract": "Recent work shows that the expressive power of Graph Neural Networks (GNNs) in distinguishing non-isomorphic graphs is exactly the same as that of the Weisfeiler-Lehman (WL) graph test. In particular, they show that the WL test can be simulated by GNNs. However, those simulations involve neural networks for the \u201ccombine\u201d function of size polynomial or even exponential in the number of graph nodes $n$, as well as feature vectors of length linear in $n$. \n\nWe present an improved simulation of the WL test on GNNs with {\\em exponentially} lower complexity. In particular,  the neural network implementing the  combine function  in each node has only $\\mathrm{polylog}(n)$ parameters, and the feature vectors exchanged by the nodes of GNN consists of only $O(\\log n)$ bits. We also give logarithmic lower bounds for the feature vector length and the size of the neural networks, showing the (near)-optimality of our construction. "}}
