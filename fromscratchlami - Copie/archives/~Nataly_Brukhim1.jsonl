{"id": "jLX7Rr_olo", "cdate": 1673375504035, "mdate": 1673375504035, "content": {"title": "Projection-free Adaptive Regret with Membership Oracles", "abstract": "In the framework of online convex optimization, most iterative algorithms require the computation of projections onto convex sets, which can be computationally expensive. To tackle this problem Hazan and Kale (2012) proposed the study of projection-free methods that replace projections with less expensive computations. The most common approach is based on the Frank-Wolfe method, that uses linear optimization computation in lieu of projections. Recent work by Garber and Kretzu (2022) gave sublinear adaptive regret guarantees with projection free algorithms based on the Frank Wolfe approach.\nIn this work we give projection-free algorithms that are based on a different technique, inspired by Mhammedi (2022), that replaces projections by set-membership computations. We propose a simple lazy gradient-based algorithm with a Minkowski regularization that attains near-optimal adaptive regret bounds. For general convex loss functions we improve previous adaptive regret bounds from $O(T^{3/4})$ to $O(\\sqrt{T})$, and further to tight interval dependent bound $\\tilde{O}(\\sqrt{I})$ where I denotes the interval length. For strongly convex functions we obtain the first poly-logarithmic adaptive regret bounds using a projection-free algorithm."}}
{"id": "GNHyNOR8Sn", "cdate": 1652737764987, "mdate": null, "content": {"title": "A Boosting Approach to Reinforcement Learning", "abstract": "Reducing reinforcement learning to supervised learning is a well-studied and effective approach that leverages the benefits of compact function approximation to deal with large-scale Markov decision processes. Independently, the boosting methodology (e.g. AdaBoost) has proven to be indispensable in designing efficient and accurate classification algorithms by combining rough and inaccurate rules-of-thumb.\n\nIn this paper, we take a further step: we reduce reinforcement learning to a sequence of weak learning problems. Since weak learners perform only marginally better than random guesses, such subroutines constitute a weaker assumption than the availability of an accurate supervised learning oracle. We prove that the sample complexity and running time bounds of the proposed method do not explicitly depend on the number of states.\n\nWhile existing results on boosting operate on convex losses, the value function over policies is non-convex. We show how to use a non-convex variant of the Frank-Wolfe method for boosting, that additionally improves upon the known sample complexity and running time bounds even for reductions to supervised learning."}}
{"id": "zsfazpciAx", "cdate": 1640995200000, "mdate": 1681593528900, "content": {"title": "A Characterization of Multiclass Learnability", "abstract": ""}}
{"id": "MhXA8lxmHG", "cdate": 1640995200000, "mdate": 1681593528886, "content": {"title": "A Characterization of Multiclass Learnability", "abstract": ""}}
{"id": "-gdTu2dgBzp", "cdate": 1640995200000, "mdate": 1681593528883, "content": {"title": "A Characterization of Multiclass Learnability", "abstract": ""}}
{"id": "xspalMXAB0M", "cdate": 1632875755822, "mdate": null, "content": {"title": "A Boosting Approach to Reinforcement Learning", "abstract": "We study efficient algorithms for reinforcement learning in Markov decision processes, whose complexity is independent of the number of states. This formulation succinctly captures large scale problems, but is also known to be computationally hard in its general form.\n    Previous approaches attempt to circumvent the computational hardness by assuming structure in either transition function or the value function, or by relaxing the solution guarantee to a local optimality condition.\n\n    We consider the methodology of boosting, borrowed from supervised learning, for converting weak learners into an effective policy. The notion of weak learning we study is that of sampled-based approximate optimization of linear functions over policies. Under this assumption of weak learnability, we give an efficient algorithm that is capable of improving the accuracy of such weak learning methods iteratively. We prove sample complexity and running time bounds on our method, that are polynomial in the natural parameters of the problem: approximation guarantee, discount factor, distribution mismatch and number of actions. In particular, our bound does not explicitly depend on the number of states.\n\n    A technical difficulty in applying previous boosting results, is that the value function over policy space is not convex. We show how to use a non-convex variant of the Frank-Wolfe method, coupled with recent advances in gradient boosting that allow incorporating a weak learner with multiplicative approximation guarantee, to overcome the non-convexity and attain global optimality guarantees."}}
{"id": "fJWmx5i5lOv", "cdate": 1621630187908, "mdate": null, "content": {"title": "Multiclass Boosting and the Cost of Weak Learning", "abstract": "Boosting is an algorithmic approach which is based on the idea \n    of combining weak and moderately inaccurate hypotheses to a strong and accurate one. \n    In this work we study multiclass boosting with a possibly large number of classes or categories.\n    Multiclass boosting can be formulated in various ways.\n    Here, we focus on an especially natural formulation in which the weak hypotheses\n    are assumed to belong to an ''easy-to-learn'' base class, and\n    the weak learner is an agnostic PAC learner for that class\n    with respect to the standard classification loss.\n    This is in contrast with other, more complicated losses as have often been considered in the past.\n    The goal of the overall boosting algorithm\n    is then to learn a combination of weak hypotheses\n    by repeatedly calling the weak learner.\n\n\nWe study the resources required for boosting, especially how they\ndepend on the number of classes $k$, for both the booster and weak learner.\nWe find that the boosting algorithm itself only requires $O(\\log k)$\nsamples, as we show by analyzing a variant of AdaBoost for our\nsetting. In stark contrast, assuming typical limits on the number of weak-learner calls,\nwe prove that the number of samples required by a \nweak learner is at least polynomial in $k$, exponentially more than the\nnumber of samples needed by the booster.\nAlternatively, we prove that the weak learner's accuracy parameter\nmust be smaller  than an inverse polynomial in $k$, showing that the returned weak\nhypotheses must be nearly the best in their class when $k$ is large.\nWe also prove a trade-off between number of oracle calls and the\nresources required of the weak learner, meaning that the fewer calls to the\nweak learner the more that is demanded on each call."}}
{"id": "1lDxnonFKm9", "cdate": 1621630187908, "mdate": null, "content": {"title": "Multiclass Boosting and the Cost of Weak Learning", "abstract": "Boosting is an algorithmic approach which is based on the idea \n    of combining weak and moderately inaccurate hypotheses to a strong and accurate one. \n    In this work we study multiclass boosting with a possibly large number of classes or categories.\n    Multiclass boosting can be formulated in various ways.\n    Here, we focus on an especially natural formulation in which the weak hypotheses\n    are assumed to belong to an ''easy-to-learn'' base class, and\n    the weak learner is an agnostic PAC learner for that class\n    with respect to the standard classification loss.\n    This is in contrast with other, more complicated losses as have often been considered in the past.\n    The goal of the overall boosting algorithm\n    is then to learn a combination of weak hypotheses\n    by repeatedly calling the weak learner.\n\n\nWe study the resources required for boosting, especially how they\ndepend on the number of classes $k$, for both the booster and weak learner.\nWe find that the boosting algorithm itself only requires $O(\\log k)$\nsamples, as we show by analyzing a variant of AdaBoost for our\nsetting. In stark contrast, assuming typical limits on the number of weak-learner calls,\nwe prove that the number of samples required by a \nweak learner is at least polynomial in $k$, exponentially more than the\nnumber of samples needed by the booster.\nAlternatively, we prove that the weak learner's accuracy parameter\nmust be smaller  than an inverse polynomial in $k$, showing that the returned weak\nhypotheses must be nearly the best in their class when $k$ is large.\nWe also prove a trade-off between number of oracle calls and the\nresources required of the weak learner, meaning that the fewer calls to the\nweak learner the more that is demanded on each call."}}
{"id": "mHF2S-LTe6", "cdate": 1609459200000, "mdate": 1683818241178, "content": {"title": "Online Boosting with Bandit Feedback", "abstract": "We consider the problem of online boosting for regression tasks, when only limited information is available to the learner. This setting is motivated by applications in reinforcement learning, in w..."}}
{"id": "WANRKeyBgBn", "cdate": 1577836800000, "mdate": null, "content": {"title": "Boosting for Control of Dynamical Systems", "abstract": "We study the question of how to aggregate controllers for dynamical systems in order to improve their performance. To this end, we propose a framework of boosting for online control. Our main resul..."}}
