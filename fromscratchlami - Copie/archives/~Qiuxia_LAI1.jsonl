{"id": "PQXP4WZNcM", "cdate": 1663850008191, "mdate": null, "content": {"title": "Bringing Saccades and Fixations into Self-supervised Video Representation Learning", "abstract": "In this paper, we propose a self-supervised video representation learning (video SSL) method by taking inspiration from cognitive science and neuroscience on human visual perception. Different from previous methods that mainly start from the inherent properties of videos, we argue that humans learn to perceive the world through the self-awareness of the semantic change or consistency in the input stimuli in the absence of labels, accompanied by representation reorganization during the post-learning rest periods. To this end, we first exploit the presence of saccades as an indicator of semantic change in a contrastive learning framework to mimic the self-awareness in human representation learning, where the saccades are generated without eye-tracking data. Second, we model the semantic consistency by minimizing the prediction error between the predicted and the true state of another time point during a fixation. Third, we later incorporate prototypical contrastive learning to reorganize the learned representations such that perceptually similar representations would be associated closer. Compared to previous counterparts, our method can capture finer-grained semantics from video instances, and the associations among similar ones are further strengthened. Experiments show that the proposed bio-inspired video SSL method significantly improves the Top-1 video retrieval accuracy on UCF101 and achieves superior performance on downstream tasks such as action recognition under comparable settings."}}
{"id": "ep_8uwxouZO", "cdate": 1663849836100, "mdate": null, "content": {"title": "DeepSAT: An EDA-Driven Learning Framework for SAT", "abstract": "We present DeepSAT, a novel end-to-end learning framework for the Boolean satisfiability (SAT) problem. Unlike existing solutions trained on random SAT instances with relatively weak supervision, we propose applying the knowledge of the well-developed electronic design automation (EDA) field for SAT solving. Specifically, we first resort to logic synthesis algorithms to pre-process SAT instances into optimized and-inverter graphs (AIGs). By doing so, the distribution diversity among various SAT instances can be dramatically reduced, which facilitates improving the generalization capability of the learned model. Next, we regard the distribution of SAT solutions being a product of conditional Bernoulli distributions. Based on this observation, we approximate the SAT solving procedure with a conditional generative model, leveraging a novel directed acyclic graph neural network (DAGNN) with two polarity prototypes for conditional SAT modeling. To effectively train the generative model,  with the help of logic simulation tools, we obtain the probabilities of nodes in the AIG being logic \u20181\u2019 as rich supervision. We conduct comprehensive experiments on various SAT problems. Our results show that, DeepSAT achieves significant accuracy improvements over state-of-the-art learning-based SAT solutions, especially when generalized to SAT instances that are relatively large or with diverse distributions. "}}
{"id": "AyajSjTAzmg", "cdate": 1652737679544, "mdate": null, "content": {"title": "SCINet: Time Series Modeling and Forecasting with Sample Convolution and Interaction", "abstract": "One unique property of time series is that the temporal relations are largely preserved after downsampling into two sub-sequences. By taking advantage of this property, we propose a novel neural network architecture that conducts sample convolution and interaction for temporal modeling and forecasting, named SCINet. Specifically, SCINet is a recursive downsample-convolve-interact architecture. In each layer, we use multiple convolutional filters to extract distinct yet valuable temporal features from the downsampled sub-sequences or features. By combining these rich features aggregated from multiple resolutions, SCINet effectively models time series with complex temporal dynamics. Experimental results show that SCINet achieves significant forecasting accuracy improvements over both existing convolutional models and Transformer-based solutions across various real-world time series forecasting datasets. Our codes and data are available at https://github.com/cure-lab/SCINet."}}
{"id": "F_r8jbPIj4", "cdate": 1640995200000, "mdate": 1681196966077, "content": {"title": "Weakly Supervised Visual Saliency Prediction", "abstract": ""}}
{"id": "8bFAcvVV40_", "cdate": 1640995200000, "mdate": 1681196966139, "content": {"title": "Salient Object Detection in the Deep Learning Era: An In-Depth Survey", "abstract": ""}}
{"id": "U4uFaLyg7PV", "cdate": 1632875555044, "mdate": null, "content": {"title": "T-WaveNet: A Tree-Structured Wavelet Neural Network for Time Series Signal Analysis", "abstract": "Time series signal analysis plays an essential role in many applications, e.g., activity recognition and healthcare monitoring.\nRecently, features extracted with deep neural networks (DNNs) have shown to be more effective than conventional hand-crafted ones.\nHowever, most existing solutions rely solely on the network to extract information carried in the raw signal, regardless of its inherent physical and statistical properties, leading to sub-optimal performance particularly under a limited amount of training data.\nIn this work, we propose a novel tree-structured wavelet neural network for time series signal analysis, namely \\emph{T-WaveNet}, taking advantage of an inherent property of various types of signals, known as the \\emph{dominant frequency range}. Specifically, with \\emph{T-WaveNet}, we first conduct frequency spectrum energy analysis of the signals to get a set of dominant frequency subbands. Then, we construct a tree-structured network that iteratively decomposes the input signal into various frequency subbands with similar energies. Each node on the tree is built with an invertible neural network (INN) based wavelet transform unit. Such a disentangled representation learning method facilitates a more effective extraction of the discriminative features, as demonstrated with the comprehensive experiments on various real-life time series classification datasets. "}}
{"id": "W-agFo22-TS", "cdate": 1621630102351, "mdate": null, "content": {"title": "TestRank: Bringing Order into Unlabeled Test Instances for Deep Learning Tasks", "abstract": "Deep learning (DL) systems are notoriously difficult to test and debug due to the lack of correctness proof and the huge test input space to cover. Given the ubiquitous unlabeled test data and high labeling cost, in this paper, we propose a novel test prioritization technique, namely TestRank, which aims at revealing more model failures with less labeling effort. TestRank brings order into the unlabeled test data according to their likelihood of being a failure, i.e., their failure-revealing capabilities. Different from existing solutions, TestRank leverages both intrinsic and contextual attributes of the unlabeled test data when prioritizing them. To be specific, we first build a similarity graph on both unlabeled test samples and labeled samples (e.g., training or previously labeled test samples). Then, we conduct graph-based semi-supervised learning to extract contextual features from the correctness of similar labeled samples. For a particular test instance, the contextual features extracted with the graph neural network and the intrinsic features obtained with the DL model itself are combined to predict its failure-revealing capability. Finally, TestRank prioritizes unlabeled test inputs in descending order of the above probability value. We evaluate TestRank on three popular image classification datasets, and results show that TestRank significantly outperforms existing test prioritization techniques. \n  "}}
{"id": "wxxoaxl2Qjb", "cdate": 1609459200000, "mdate": 1681196966078, "content": {"title": "Understanding More About Human and Machine Attention in Deep Neural Networks", "abstract": ""}}
{"id": "WNcw03-lffz", "cdate": 1609459200000, "mdate": 1681196966129, "content": {"title": "Information Bottleneck Approach to Spatial Attention Learning", "abstract": ""}}
{"id": "9BuTdoUre8I", "cdate": 1577836800000, "mdate": 1681196966078, "content": {"title": "Video Saliency Prediction Using Spatiotemporal Residual Attentive Networks", "abstract": ""}}
