{"id": "q2SXALVuu_", "cdate": 1704067200000, "mdate": 1708518815767, "content": {"title": "Proximal Causal Inference With Text Data", "abstract": "Recent text-based causal methods attempt to mitigate confounding bias by including unstructured text data as proxies of confounding variables that are partially or imperfectly measured. These approaches assume analysts have supervised labels of the confounders given text for a subset of instances, a constraint that is not always feasible due to data privacy or cost. Here, we address settings in which an important confounding variable is completely unobserved. We propose a new causal inference method that splits pre-treatment text data, infers two proxies from two zero-shot models on the separate splits, and applies these proxies in the proximal g-formula. We prove that our text-based proxy method satisfies identification conditions required by the proximal g-formula while other seemingly reasonable proposals do not. We evaluate our method in synthetic and semi-synthetic settings and find that it produces estimates with low bias. This combination of proximal causal inference and zero-shot classifiers is novel (to our knowledge) and expands the set of text-specific causal methods available to practitioners."}}
{"id": "14CKmKNZyU", "cdate": 1677628800000, "mdate": 1708525793671, "content": {"title": "Searching for explanations: testing social scientific methods in synthetic ground-truthed worlds", "abstract": "A scientific model\u2019s usefulness relies on its ability to explain phenomena, predict how such phenomena will be impacted by future interventions, and prescribe actions to achieve desired outcomes. We study methods for learning causal models that explain the behaviors of simulated \u201chuman\u201d populations. Through the Ground Truth project, we solved a series of Challenges where our explanations, predictions and prescriptions were scored against ground truth information. We describe the processes that emerged for applying causal discovery, network analysis, agent-based modeling and other analytical methods to inform solutions to Challenge tasks. We present our team\u2019s overall performance results on these Challenges and discuss implications for future efforts to validate social scientific research using simulation-based challenges."}}
{"id": "DrGiy3l4r27", "cdate": 1676827101276, "mdate": null, "content": {"title": "On Testability and Goodness of Fit Tests in Missing Data Models", "abstract": "Significant progress has been made in developing identification and estimation techniques for missing data problems where modeling assumptions can be described via a directed acyclic graph. The validity of results using such techniques rely on the assumptions encoded by the graph holding true; however, verification of these assumptions has not received sufficient attention in prior work. In this paper, we provide new insights on the testable implications of three broad classes of missing data graphical models, and design goodness-of-fit tests for them. The classes of models explored are: sequential missing-at-random and  missing-not-at-random models which can be used for modeling longitudinal studies with dropout/censoring, and a  no self-censoring model which can be applied to cross-sectional studies and surveys."}}
{"id": "XAkGGAzjMM", "cdate": 1676827093667, "mdate": null, "content": {"title": "Causal Inference With Outcome-Dependent Missingness And Self-Censoring", "abstract": "We consider missingness in the context of causal inference when the outcome of interest may be missing. If the outcome directly affects its own missingness status, i.e., it is \"self-censoring\", this may lead to severely biased causal effect estimates. Miao et al. [2015] proposed the shadow variable method to correct for bias due to self-censoring; however, verifying the required model assumptions can be difficult. Here, we propose a test based on a randomized incentive variable offered to encourage reporting of the outcome that can be used to verify identification assumptions that are sufficient to correct for both self-censoring and confounding bias. Concretely, the test confirms whether a given set of pre-treatment covariates is sufficient to block all backdoor paths between the treatment and outcome as well as all paths between the treatment and missingness indicator after conditioning on the outcome. We show that under these conditions, the causal effect is identified by using the treatment as a shadow variable, and it leads to an intuitive inverse probability weighting estimator that uses a product of the treatment and response weights. We evaluate the efficacy of our test and downstream estimator via simulations."}}
{"id": "viBdRuqfMBU", "cdate": 1672531200000, "mdate": 1708525793690, "content": {"title": "RCT Rejection Sampling for Causal Estimation Evaluation", "abstract": "Confounding is a significant obstacle to unbiased estimation of causal effects from observational data. For settings with high-dimensional covariates -- such as text data, genomics, or the behavioral social sciences -- researchers have proposed methods to adjust for confounding by adapting machine learning methods to the goal of causal estimation. However, empirical evaluation of these adjustment methods has been challenging and limited. In this work, we build on a promising empirical evaluation strategy that simplifies evaluation design and uses real data: subsampling randomized controlled trials (RCTs) to create confounded observational datasets while using the average causal effects from the RCTs as ground-truth. We contribute a new sampling algorithm, which we call RCT rejection sampling, and provide theoretical guarantees that causal identification holds in the observational data to allow for valid comparisons to the ground-truth RCT. Using synthetic data, we show our algorithm indeed results in low bias when oracle estimators are evaluated on the confounded samples, which is not always the case for a previously proposed algorithm. In addition to this identification result, we highlight several finite data considerations for evaluation designers who plan to use RCT rejection sampling on their own datasets. As a proof of concept, we implement an example evaluation pipeline and walk through these finite data considerations with a novel, real-world RCT -- which we release publicly -- consisting of approximately 70k observations and text data as high-dimensional covariates. Together, these contributions build towards a broader agenda of improved empirical evaluation for causal estimation."}}
{"id": "rvrWrnbw_I3", "cdate": 1672531200000, "mdate": 1708525793680, "content": {"title": "Ananke: A Python Package For Causal Inference Using Graphical Models", "abstract": "We implement Ananke: an object-oriented Python package for causal inference with graphical models. At the top of our inheritance structure is an easily extensible Graph class that provides an interface to several broadly useful graph-based algorithms and methods for visualization. We use best practices of object-oriented programming to implement subclasses of the Graph superclass that correspond to types of causal graphs that are popular in the current literature. This includes directed acyclic graphs for modeling causally sufficient systems, acyclic directed mixed graphs for modeling unmeasured confounding, and chain graphs for modeling data dependence and interference. Within these subclasses, we implement specialized algorithms for common statistical and causal modeling tasks, such as separation criteria for reading conditional independence, nonparametric identification, and parametric and semiparametric estimation of model parameters. Here, we present a broad overview of the package and example usage for a problem with unmeasured confounding. Up to date documentation is available at \\url{https://ananke.readthedocs.io/en/latest/}."}}
{"id": "SSgEgDUscgc", "cdate": 1646077528264, "mdate": null, "content": {"title": "On Testability of the Front-Door Model via Verma Constraints", "abstract": "The front-door criterion can be used to identify and compute causal effects despite the existence of unmeasured confounders between a treatment and outcome. However, the key assumptions -- (i) the existence of a variable (or set of variables) that fully mediates the effect of the treatment on the outcome, and (ii) which simultaneously does not suffer from similar issues of confounding as the treatment-outcome pair -- are often deemed implausible. This paper explores the testability of these assumptions. We show that under mild conditions involving an auxiliary variable, the assumptions encoded in the front-door model (and simple extensions of it) may be tested via generalized equality constraints a.k.a Verma constraints. We propose two goodness-of-fit tests based on this observation, and evaluate the efficacy of our proposal on real and synthetic data. We also provide theoretical and empirical comparisons to instrumental variable approaches to handling unmeasured confounding."}}
{"id": "uwQwYHQNCV", "cdate": 1640995200000, "mdate": 1708525793672, "content": {"title": "On testability of the front-door model via Verma constraints", "abstract": "The front-door criterion can be used to identify and compute causal effects despite the existence of unmeasured confounders between a treatment and outcome. However, the key assumptions \u2013 (i) the e..."}}
{"id": "VUjXzNbc9mk", "cdate": 1640995200000, "mdate": 1708525793680, "content": {"title": "Causal and counterfactual views of missing data models", "abstract": "It is often said that the fundamental problem of causal inference is a missing data problem -- the comparison of responses to two hypothetical treatment assignments is made difficult because for every experimental unit only one potential response is observed. In this paper, we consider the implications of the converse view: that missing data problems are a form of causal inference. We make explicit how the missing data problem of recovering the complete data law from the observed law can be viewed as identification of a joint distribution over counterfactual variables corresponding to values had we (possibly contrary to fact) been able to observe them. Drawing analogies with causal inference, we show how identification assumptions in missing data can be encoded in terms of graphical models defined over counterfactual and observed variables. We review recent results in missing data identification from this viewpoint. In doing so, we note interesting similarities and differences between missing data and causal identification theories."}}
{"id": "9iZtzGPXCw", "cdate": 1640995200000, "mdate": 1708525793715, "content": {"title": "Semiparametric Inference For Causal Effects In Graphical Models With Hidden Variables", "abstract": "Identification theory for causal effects in causal models associated with hidden variable directed acyclic graphs (DAGs) is well studied. However, the corresponding algorithms are underused due to the complexity of estimating the identifying functionals they output. In this work, we bridge the gap between identification and estimation of population-level causal effects involving a single treatment and a single outcome. We derive influence function based estimators that exhibit double robustness for the identified effects in a large class of hidden variable DAGs where the treatment satisfies a simple graphical criterion; this class includes models yielding the adjustment and front-door functionals as special cases. We also provide necessary and sufficient conditions under which the statistical model of a hidden variable DAG is nonparametrically saturated and implies no equality constraints on the observed data distribution. Further, we derive an important class of hidden variable DAGs that imply observed data distributions observationally equivalent (up to equality constraints) to fully observed DAGs. In these classes of DAGs, we derive estimators that achieve the semiparametric efficiency bounds for the target of interest where the treatment satisfies our graphical criterion. Finally, we provide a sound and complete identification algorithm that directly yields a weight based estimation strategy for any identifiable effect in hidden variable causal models."}}
