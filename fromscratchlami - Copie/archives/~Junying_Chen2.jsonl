{"id": "VNYOybTdjD8", "cdate": 1672531200000, "mdate": 1684126626720, "content": {"title": "Phoenix: Democratizing ChatGPT across Languages", "abstract": "This paper presents our efforts to democratize ChatGPT across language. We release a large language model \"Phoenix\", achieving competitive performance among open-source English and Chinese models while excelling in languages with limited resources (covering both Latin and non-Latin languages). We believe this work will be beneficial to make ChatGPT more accessible, especially in countries where people cannot use ChatGPT due to restrictions from OpenAI or local goverments. Our data, code, and models are available at https://github.com/FreedomIntelligence/LLMZoo."}}
{"id": "BlPiWaLRPb6", "cdate": 1672531200000, "mdate": 1687181783132, "content": {"title": "HuatuoGPT, towards Taming Language Model to Be a Doctor", "abstract": ""}}
{"id": "oePBPIfje5", "cdate": 1640995200000, "mdate": 1687181783137, "content": {"title": "SeDR: Segment Representation Learning for Long Documents Dense Retrieval", "abstract": ""}}
{"id": "WMXOW98fVx", "cdate": 1640995200000, "mdate": 1687181783136, "content": {"title": "Retrieval-Then-Parsing: A Two-Stage Model for SQL Generation in Financial Domain", "abstract": "Querying financial databases with natural language has been a strong requirement for financial company staff in recent years. The common method for this task is to transform the natural language into structured query language (SQL), which is referred to as semantic parsing. In this paper, we propose a two-stage model for semantic parsing in large financial databases. The two-stage model consists of an integrated table retriever that is used to retrieve related tables from a large database and a knowledge-enhanced semantic parser that utilizes a knowledge base for SQL generation. Experimental results show that our model achieves decent performance, which ranks the first place on both development and test datasets of CCKS 2022 evaluation task 11."}}
{"id": "WH2F7hAGIv", "cdate": 1640995200000, "mdate": 1687181783139, "content": {"title": "Diaformer: Automatic Diagnosis via Symptoms Sequence Generation", "abstract": "Automatic diagnosis has attracted increasing attention but remains challenging due to multi-step reasoning. Recent works usually address it by reinforcement learning methods. However, these methods show low efficiency and require task-specific reward functions. Considering the conversation between doctor and patient allows doctors to probe for symptoms and make diagnoses, the diagnosis process can be naturally seen as the generation of a sequence including symptoms and diagnoses. Inspired by this, we reformulate automatic diagnosis as a symptoms Sequence Generation (SG) task and propose a simple but effective automatic Diagnosis model based on Transformer (Diaformer). We firstly design the symptom attention framework to learn the generation of symptom inquiry and the disease diagnosis. To alleviate the discrepancy between sequential generation and disorder of implicit symptoms, we further design three orderless training mechanisms. Experiments on three public datasets show that our model outperforms baselines on disease diagnosis by 1%, 6% and 11.5% with the highest training efficiency. Detailed analysis on symptom inquiry prediction demonstrates that the potential of applying symptoms sequence generation for automatic diagnosis."}}
{"id": "1Dxn04FHJF", "cdate": 1609459200000, "mdate": 1687181846164, "content": {"title": "Leveraging Capsule Routing to Associate Knowledge with Medical Literature Hierarchically", "abstract": ""}}
{"id": "kp9gTq_Ff2M", "cdate": 1577836800000, "mdate": 1683882303507, "content": {"title": "MedWriter: Knowledge-Aware Medical Text Generation", "abstract": ""}}
