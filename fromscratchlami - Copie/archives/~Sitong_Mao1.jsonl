{"id": "e6epZLRf6sZ", "cdate": 1577836800000, "mdate": null, "content": {"title": "Against Adversarial Learning: Naturally Distinguish Known and Unknown in Open Set Domain Adaptation", "abstract": "Open set domain adaptation refers to the scenario that the target domain contains categories that do not exist in the source domain. It is a more common situation in the reality compared with the typical closed set domain adaptation where the source domain and the target domain contain the same categories. The main difficulty of open set domain adaptation is that we need to distinguish which target data belongs to the unknown classes when machine learning models only have concepts about what they know. In this paper, we propose an \"against adversarial learning\" method that can distinguish unknown target data and known data naturally without setting any additional hyper parameters and the target data predicted to the known classes can be classified at the same time. Experimental results show that the proposed method can make significant improvement in performance compared with several state-of-the-art methods."}}
{"id": "ZeUXfG4RBmY", "cdate": 1577836800000, "mdate": null, "content": {"title": "Deep Adversarial Domain Adaptation Based on Multi-layer Joint Kernelized Distance", "abstract": "Domain adaptation refers to the learning scenario that a model learned from the source data is applied on the target data which have the same categories but different distribution. While it has been widely applied, the distribution discrepancy between source data and target data can substantially affect the adaptation performance. The problem has been recently addressed by employing adversarial learning and distinctive adaptation performance has been reported. In this paper, a deep adversarial domain adaptation model based on a multi-layer joint kernelized distance metric is proposed. By utilizing the abstract features extracted from deep networks, the multi-layer joint kernelized distance (MJKD) between the $j$th target data predicted as the $m$th category and all the source data of the $m'$th category is computed. Base on MJKD, a class-balanced selection strategy is utilized in each category to select target data that are most likely to be classified correctly and treat them as labeled data using their pseudo labels. Then an adversarial architecture is used to draw the newly generated labeled training data and the remaining target data close to each other. In this way, the target data itself provide valuable information to enhance the domain adaptation. An analysis of the proposed method is also given and the experimental results demonstrate that the proposed method can achieve a better performance than a number of state-of-the-art methods."}}
{"id": "H3nX28Qqxur", "cdate": 1577836800000, "mdate": null, "content": {"title": "Mixed Set Domain Adaptation", "abstract": "In the settings of conventional domain adaptation, categories of the source dataset are from the same domain (or domains for multi-source domain adaptation), which is not always true in reality. In this paper, we propose \\textbf{\\textit{Mixed Set Domain Adaptation} (MSDA)}. Under the settings of MSDA, different categories of the source dataset are not all collected from the same domain(s). For instance, category $1\\sim k$ are collected from domain $\\alpha$ while category $k+1\\sim c$ are collected from domain $\\beta$. Under such situation, domain adaptation performance will be further influenced because of the distribution discrepancy inside the source data. A feature element-wise weighting (FEW) method that can reduce distribution discrepancy between different categories is also proposed for MSDA. Experimental results and quality analysis show the significance of solving MSDA problem and the effectiveness of the proposed method."}}
{"id": "GcSSaIhMPF", "cdate": 1577836800000, "mdate": null, "content": {"title": "Cross-Network Learning With Fuzzy Labels for Seed Selection and Graph Sparsification in Influence Maximization", "abstract": "To maximize the influence across multiple heterogeneous networks, we propose an innovative cross-network learning model to study the influence maximization problem from two perspectives, namely, seed selection and graph sparsification. On one hand, we consider seed selection as a cross-network node prediction task, by leveraging the greedy seed selection knowledge prelearned in a smaller source network, to heuristically select the nodes most likely to act as seed for the target networks. On the other hand, we consider graph sparsification as a cross-network edge prediction problem, by adapting the influence propagation knowledge previously acquired in the source network to remove the edges least likely to contribute to influence propagation in the target networks. To address domain discrepancy, a fuzzy self-learning algorithm is proposed to iteratively train the prediction model by leveraging not only the fully labeled data in the source network, but also the most confident predicted instances with their predicted fuzzy labels in the target network. With such fuzzy labels, we can differentiate the confident levels of predictions generated by different self-training iterations, thus lowering the negative effects caused by less confident predictions. The performance of the proposed model is benchmarked with the popular influence maximization algorithms for seed selection; and also competed with several graph sparsification algorithms for inactive edge prediction. Experimental results on the real-world datasets show that the proposed cross-network learning model can achieve a good tradeoff between the efficiency and effectiveness of the influence maximization task in the target networks."}}
{"id": "Skb66B-uWH", "cdate": 1514764800000, "mdate": null, "content": {"title": "Deep Domain Adaptation Based on Multi-layer Joint Kernelized Distance", "abstract": "Domain adaptation refers to the learning scenario where a model learned from the source data is applied on the target data which have the same categories but different distributions. In information retrieval, there exist application scenarios like cross domain recommendation characterized similarly. In this paper, by utilizing deep features extracted from the deep networks, we proposed to compute the multi-layer joint kernelized mean distance between the k th target data predicted as the i th category and all the source data of the j th category $d_ij ^k$. Then, target data $T_m$ that are most likely to belong to the i th category can be found by calculating the relative distance $d_ii ^k/\\sum_j d_ij ^k$. By iteratively adding $T_m$ to the training data, the finetuned deep model can adapt on the target data progressively. Our results demonstrate that the proposed method can achieve a better performance compared to a number of state-of-the-art methods."}}
{"id": "ryVOiH-OWS", "cdate": 1483228800000, "mdate": null, "content": {"title": "Leveraging Cross-Network Information for Graph Sparsification in Influence Maximization", "abstract": "When tackling large-scale influence maximization (IM) problem, one effective strategy is to employ graph sparsification as a pre-processing step, by removing a fraction of edges to make original networks become more concise and tractable for the task. In this work, a Cross-Network Graph Sparsification (CNGS) model is proposed to leverage the influence backbone knowledge pre-detected in a source network to predict and remove the edges least likely to contribute to the influence propagation in the target networks. Experimental results demonstrate that conducting graph sparsification by the proposed CNGS model can obtain a good trade-off between efficiency and effectiveness of IM, i.e., existing IM greedy algorithms can run more efficiently, while the loss of influence spread can be made as small as possible in the sparse target networks."}}
