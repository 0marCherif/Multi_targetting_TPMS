{"id": "zjeOL_ED6N", "cdate": 1672531200000, "mdate": 1695949495907, "content": {"title": "FedGrad: Mitigating Backdoor Attacks in Federated Learning Through Local Ultimate Gradients Inspection", "abstract": "Federated learning (FL) enables multiple clients to train a model without compromising sensitive data. The decentralized nature of FL makes it susceptible to adversarial attacks, especially backdoor insertion during training. Recently, the edge-case backdoor attack employing the tail of the data distribution has been proposed as a powerful one, raising questions about the shortfall in current defenses' robustness guarantees. Specifically, most existing defenses cannot eliminate edge-case backdoor attacks or suffer from a trade-off between backdoor-defending effectiveness and overall performance on the primary task. To tackle this challenge, we propose FedGrad, a novel backdoor-resistant defense for FL that is resistant to cutting-edge backdoor attacks, including the edge-case attack, and performs effectively under heterogeneous client data and a large number of compromised clients. FedGrad is designed as a two-layer filtering mechanism that thoroughly analyzes the ultimate layer's gradient to identify suspicious local updates and remove them from the aggregation process. We evaluate FedGrad under different attack scenarios and show that it significantly outperforms state-of-the-art defense mechanisms. Notably, FedGrad can almost 100% correctly detect the malicious participants, thus providing a significant reduction in the backdoor effect (e.g., backdoor accuracy is less than 8%) while not reducing main accuracy on the primary task."}}
{"id": "mf4Xky6x9K", "cdate": 1672531200000, "mdate": 1683803129915, "content": {"title": "Backdoor Attacks and Defenses in Federated Learning: Survey, Challenges and Future Research Directions", "abstract": "Federated learning (FL) is a machine learning (ML) approach that allows the use of distributed data without compromising personal privacy. However, the heterogeneous distribution of data among clients in FL can make it difficult for the orchestration server to validate the integrity of local model updates, making FL vulnerable to various threats, including backdoor attacks. Backdoor attacks involve the insertion of malicious functionality into a targeted model through poisoned updates from malicious clients. These attacks can cause the global model to misbehave on specific inputs while appearing normal in other cases. Backdoor attacks have received significant attention in the literature due to their potential to impact real-world deep learning applications. However, they have not been thoroughly studied in the context of FL. In this survey, we provide a comprehensive survey of current backdoor attack strategies and defenses in FL, including a comprehensive analysis of different approaches. We also discuss the challenges and potential future directions for attacks and defenses in the context of FL."}}
{"id": "P_bsI9T5Ls", "cdate": 1672531200000, "mdate": 1683803129916, "content": {"title": "FedGrad: Mitigating Backdoor Attacks in Federated Learning Through Local Ultimate Gradients Inspection", "abstract": "Federated learning (FL) enables multiple clients to train a model without compromising sensitive data. The decentralized nature of FL makes it susceptible to adversarial attacks, especially backdoor insertion during training. Recently, the edge-case backdoor attack employing the tail of the data distribution has been proposed as a powerful one, raising questions about the shortfall in current defenses' robustness guarantees. Specifically, most existing defenses cannot eliminate edge-case backdoor attacks or suffer from a trade-off between backdoor-defending effectiveness and overall performance on the primary task. To tackle this challenge, we propose FedGrad, a novel backdoor-resistant defense for FL that is resistant to cutting-edge backdoor attacks, including the edge-case attack, and performs effectively under heterogeneous client data and a large number of compromised clients. FedGrad is designed as a two-layer filtering mechanism that thoroughly analyzes the ultimate layer's gradient to identify suspicious local updates and remove them from the aggregation process. We evaluate FedGrad under different attack scenarios and show that it significantly outperforms state-of-the-art defense mechanisms. Notably, FedGrad can almost 100% correctly detect the malicious participants, thus providing a significant reduction in the backdoor effect (e.g., backdoor accuracy is less than 8%) while not reducing the main accuracy on the primary task."}}
{"id": "HQ5KhJx-Vu6", "cdate": 1672531200000, "mdate": 1683803129714, "content": {"title": "Personalized Privacy-Preserving Framework for Cross-Silo Federated Learning", "abstract": "Federated learning (FL) is recently surging as a promising decentralized deep learning (DL) framework that enables DL-based approaches trained collaboratively across clients without sharing private data. However, in the context of the central party being active and dishonest, the data of individual clients might be perfectly reconstructed, leading to the high possibility of sensitive information being leaked. Moreover, FL also suffers from the nonindependent and identically distributed (non-IID) data among clients, resulting in the degradation in the inference performance on local clients' data. In this paper, we propose a novel framework, namely Personalized Privacy-Preserving Federated Learning (PPPFL), with a concentration on cross-silo FL to overcome these challenges. Specifically, we introduce a stabilized variant of the Model-Agnostic Meta-Learning (MAML) algorithm to collaboratively train a global initialization from clients' synthetic data generated by Differential Private Generative Adversarial Networks (DP-GANs). After reaching convergence, the global initialization will be locally adapted by the clients to their private data. Through extensive experiments, we empirically show that our proposed framework outperforms multiple FL baselines on different datasets, including MNIST, Fashion-MNIST, CIFAR-10, and CIFAR-100."}}
{"id": "GTwCVXlxat", "cdate": 1672531200000, "mdate": 1695949496119, "content": {"title": "An Empirical Study of Federated Learning on IoT-Edge Devices: Resource Allocation and Heterogeneity", "abstract": "Nowadays, billions of phones, IoT and edge devices around the world generate data continuously, enabling many Machine Learning (ML)-based products and applications. However, due to increasing privacy concerns and regulations, these data tend to reside on devices (clients) instead of being centralized for performing traditional ML model training. Federated Learning (FL) is a distributed approach in which a single server and multiple clients collaboratively build an ML model without moving data away from clients. Whereas existing studies on FL have their own experimental evaluations, most experiments were conducted using a simulation setting or a small-scale testbed. This might limit the understanding of FL implementation in realistic environments. In this empirical study, we systematically conduct extensive experiments on a large network of IoT and edge devices (called IoT-Edge devices) to present FL real-world characteristics, including learning performance and operation (computation and communication) costs. Moreover, we mainly concentrate on heterogeneous scenarios, which is the most challenging issue of FL. By investigating the feasibility of on-device implementation, our study provides valuable insights for researchers and practitioners, promoting the practicality of FL and assisting in improving the current design of real FL systems."}}
{"id": "YA6aOvisayv", "cdate": 1640995200000, "mdate": 1683803129904, "content": {"title": "Toward Efficient Hierarchical Federated Learning Design Over Multi-Hop Wireless Communications Networks", "abstract": "Federated learning (FL) has recently received considerable attention and is becoming a popular machine learning (ML) framework that allows clients to train machine learning models in a decentralized fashion without sharing any private dataset. In the FL framework, data for learning tasks are acquired and processed locally at the edge node, and only the updated ML parameters are transmitted to the central server for aggregation. However, because local FL parameters and the global FL model are transmitted over wireless links, wireless network performance will affect FL training performance. In particular, the number of resource blocks is limited; thus, the number of devices participating in FL is limited. Furthermore, edge nodes often have substantial constraints on their resources, such as memory, computation power, communication, and energy, severely limiting their capability to train large models locally. This paper proposes a two-hop communication protocol with a dynamic resource allocation strategy to investigate the possibility of bandwidth allocation from a limited network resource to the maximum number of clients participating in FL. In particular, we utilize an ordinary hierarchical FL with an adaptive grouping mechanism to select participating clients and elect a leader for each group based on its capability to upload the aggregated parameters to the central server. Our experimental results demonstrate that the proposed solution outperforms the baseline algorithm in terms of communication cost and model accuracy."}}
{"id": "Y6LiWT3F3o", "cdate": 1640995200000, "mdate": 1683803129919, "content": {"title": "Emerging Privacy and Trust Issues for Autonomous Vehicle Systems", "abstract": "In the awakening of cutting-edge technology, companies such as Apple, Waymo, and Tesla are racing to launch the industry\u2019s first fully autonomous car. Besides the technical challenges such as safety and infrastructure, privacy and data protection have attracted the autonomous vehicle industry and researchers\u2019 attention. In particular, it is hard for autonomous vehicle manufacturers to impose substantive privacy and security protections when different vendors and suppliers are involved in vehicle production. Although we know how much data autonomous vehicles will generate per day, there is a lack of knowledge of how the collected data will be used (e.g., real-time broadcasting and offline analytic). The privacy risks associated with data collection raise individual concerns in autonomous vehicle systems. For instance, when location information is combined with personal information, a person\u2019s details such as wealth status, profession, sexual association, and religion can be deduced. The misuse of present and historical travel patterns also puts someone susceptible to physical harm or stalking. Driven by mutual benefits or regulations, specific data must be shared in real-time or published for analysis or research purposes. This paper discusses the emerging privacy and trust issues that are essential to motivate the acceptance of autonomous vehicles operating on public roads."}}
{"id": "U86SUEpABk", "cdate": 1640995200000, "mdate": 1683803129925, "content": {"title": "Benchmarking full version of GureKDDCup, UNSW-NB15, and CIDDS-001 NIDS datasets using rolling-origin resampling", "abstract": "Network intrusion detection system (NIDS) is a system that analyses network traffic to flag malicious traffic or suspicious activities. Several recent NIDS datasets have been published, however, th..."}}
{"id": "MBAfj86U6v", "cdate": 1640995200000, "mdate": 1683803129921, "content": {"title": "A Survey on Deep Learning Advances and Emerging Issues in Pneumonia and COVID19 Prediction", "abstract": "As the COVID19 pandemic evolves and coronavirus mutates to different variants, a high workload falls on the shoulders of doctors and radiologists. Identifying COVID19 through X-ray and Computed Tomography (CT) scanning in a short amount of time is vital because it helps doctors start the COVID19 treatment in the early stages. Deep Learning algorithms showed tremendous results in automating COVID19 detection using X-ray and CT scans. As there are not many survey papers on COVID19 detection using deep learning techniques, the goal of this paper is (1) to give a thorough discussion of COVID19 prediction considering Computer Vision problems like COVID19/pneumonia classification, detection, and segmentation, (2) to address new advances in deep learning like Transformers, GANs, and LSTMs, and (3) to cover technical issues like data security and data scarcity of X-ray and CT scans in COVID19."}}
{"id": "JpMRrvMz1B", "cdate": 1640995200000, "mdate": 1683803129901, "content": {"title": "FedDCT: Federated Learning of Large Convolutional Neural Networks on Resource Constrained Devices using Divide and Co-Training", "abstract": "We introduce FedDCT, a novel distributed learning paradigm that enables the usage of large, high-performance CNNs on resource-limited edge devices. As opposed to traditional FL approaches, which require each client to train the full-size neural network independently during each training round, the proposed FedDCT allows a cluster of several clients to collaboratively train a large deep learning model by dividing it into an ensemble of several small sub-models and train them on multiple devices in parallel while maintaining privacy. In this co-training process, clients from the same cluster can also learn from each other, further improving their ensemble performance. In the aggregation stage, the server takes a weighted average of all the ensemble models trained by all the clusters. FedDCT reduces the memory requirements and allows low-end devices to participate in FL. We empirically conduct extensive experiments on standardized datasets, including CIFAR-10, CIFAR-100, and two real-world medical datasets HAM10000 and VAIPE. Experimental results show that FedDCT outperforms a set of current SOTA FL methods with interesting convergence behaviors. Furthermore, compared to other existing approaches, FedDCT achieves higher accuracy and substantially reduces the number of communication rounds (with $4-8$ times fewer memory requirements) to achieve the desired accuracy on the testing dataset without incurring any extra training cost on the server side."}}
