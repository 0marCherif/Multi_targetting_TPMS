{"id": "9XAxGtK5cdN", "cdate": 1621629782178, "mdate": null, "content": {"title": "Private learning implies quantum stability", "abstract": "Learning an unknown n-qubit quantum state rho is a fundamental challenge in quantum computing. Information-theoretically, it is known that tomography requires exponential in n many copies of rho to estimate its entries. Motivated by learning theory, Aaronson et al. introduced many (weaker) learning models: the PAC model of learning states (Proceedings of Royal Society A'07), shadow tomography (STOC'18) for learning ``shadows\" of a state, a model that also requires learners to be differentially private (STOC'19) and the online model of learning states (NeurIPS'18). In these models it was shown that an unknown state can be learned ``approximately\" using linear in n many copies of rho. But is there any relationship between these models? In this paper we prove a sequence of (information-theoretic) implications from differentially-private PAC learning to online learning and then to quantum stability.\n\nOur main result generalizes the recent work of Bun, Livni and Moran (Journal of the ACM'21) who showed that finite Littlestone dimension (of Boolean-valued concept classes) implies PAC learnability in the (approximate) differentially private (DP) setting. We first consider their work in the real-valued setting and further extend to their techniques to the setting of learning quantum states. Key to our results is our generic quantum online learner, Robust Standard Optimal Algorithm (RSOA), which is robust to adversarial imprecision. We then show information-theoretic implications between DP learning quantum states in the PAC model, learnability of quantum states in the one-way communication model, online learning of quantum states, quantum stability (which is our conceptual contribution), various combinatorial parameters and give further applications to gentle shadow tomography and noisy quantum state learning."}}
{"id": "sXsCSVYhrw7", "cdate": 1577836800000, "mdate": null, "content": {"title": "Quantum statistical query learning.", "abstract": "We propose a learning model called the quantum statistical learning QSQ model, which extends the SQ learning model introduced by Kearns to the quantum setting. Our model can be also seen as a restriction of the quantum PAC learning model: here, the learner does not have direct access to quantum examples, but can only obtain estimates of measurement statistics on them. Theoretically, this model provides a simple yet expressive setting to explore the power of quantum examples in machine learning. From a practical perspective, since simpler operations are required, learning algorithms in the QSQ model are more feasible for implementation on near-term quantum devices. We prove a number of results about the QSQ learning model. We first show that parity functions, (log n)-juntas and polynomial-sized DNF formulas are efficiently learnable in the QSQ model, in contrast to the classical setting where these problems are provably hard. This implies that many of the advantages of quantum PAC learning can be realized even in the more restricted quantum SQ learning model. It is well-known that weak statistical query dimension, denoted by WSQDIM(C), characterizes the complexity of learning a concept class C in the classical SQ model. We show that log(WSQDIM(C)) is a lower bound on the complexity of QSQ learning, and furthermore it is tight for certain concept classes C. Additionally, we show that this quantity provides strong lower bounds for the small-bias quantum communication model under product distributions. Finally, we introduce the notion of private quantum PAC learning, in which a quantum PAC learner is required to be differentially private. We show that learnability in the QSQ model implies learnability in the quantum private PAC model. Additionally, we show that in the private PAC learning setting, the classical and quantum sample complexities are equal, up to constant factors."}}
{"id": "nXRqJ3RDut", "cdate": 1577836800000, "mdate": null, "content": {"title": "Sample-efficient learning of quantum many-body systems.", "abstract": "We study the problem of learning the Hamiltonian of a quantum many-body system given samples from its Gibbs (thermal) state. The classical analog of this problem, known as learning graphical models or Boltzmann machines, is a well-studied question in machine learning and statistics. In this work, we give the first sample-efficient algorithm for the quantum Hamiltonian learning problem. In particular, we prove that polynomially many samples in the number of particles (qudits) are necessary and sufficient for learning the parameters of a spatially local Hamiltonian in l_2-norm. Our main contribution is in establishing the strong convexity of the log-partition function of quantum many-body systems, which along with the maximum entropy estimation yields our sample-efficient algorithm. Classically, the strong convexity for partition functions follows from the Markov property of Gibbs distributions. This is, however, known to be violated in its exact form in the quantum case. We introduce several new ideas to obtain an unconditional result that avoids relying on the Markov property of quantum systems, at the cost of a slightly weaker bound. In particular, we prove a lower bound on the variance of quasi-local operators with respect to the Gibbs state, which might be of independent interest. Our work paves the way toward a more rigorous application of machine learning techniques to quantum many-body problems."}}
{"id": "Gf0Ev8iPcK", "cdate": 1577836800000, "mdate": null, "content": {"title": "Quantum Boosting.", "abstract": "Suppose we have a weak learning algorithm $\\mathcal{A}$ for a Boolean-valued problem: $\\mathcal{A}$ produces hypotheses whose bias $\\gamma$ is small, only slightly better than random guessing (this could, for instance, be due to implementing $\\mathcal{A}$ on a noisy device), can we boost the performance of $\\mathcal{A}$ so that $\\mathcal{A}$'s output is correct on $2/3$ of the inputs? Boosting is a technique that converts a weak and inaccurate machine learning algorithm into a strong accurate learning algorithm. The AdaBoost algorithm by Freund and Schapire (for which they were awarded the G\\\"odel prize in 2003) is one of the widely used boosting algorithms, with many applications in theory and practice. Suppose we have a $\\gamma$-weak learner for a Boolean concept class $C$ that takes time $R(C)$, then the time complexity of AdaBoost scales as $VC(C)\\cdot poly(R(C), 1/\\gamma)$, where $VC(C)$ is the $VC$-dimension of $C$. In this paper, we show how quantum techniques can improve the time complexity of classical AdaBoost. To this end, suppose we have a $\\gamma$-weak quantum learner for a Boolean concept class $C$ that takes time $Q(C)$, we introduce a quantum boosting algorithm whose complexity scales as $\\sqrt{VC(C)}\\cdot poly(Q(C),1/\\gamma);$ thereby achieving a quadratic quantum improvement over classical AdaBoost in terms of $VC(C)$."}}
{"id": "CrXrudG105z", "cdate": 1577836800000, "mdate": null, "content": {"title": "Improved Bounds on Fourier Entropy and Min-Entropy.", "abstract": "Given a Boolean function f:{-1,1}\u207f\u2192 {-1,1}, define the Fourier distribution to be the distribution on subsets of [n], where each S \u2286 [n] is sampled with probability f\u0302(S)\u00b2. The Fourier Entropy-Influence (FEI) conjecture of Friedgut and Kalai [E. Friedgut and G. Kalai, 1996] seeks to relate two fundamental measures associated with the Fourier distribution: does there exist a universal constant C>0 such that \u210d(f\u0302\u00b2)\u2264 C\u22c5 Inf(f), where \u210d(f\u0302\u00b2) is the Shannon entropy of the Fourier distribution of f and Inf(f) is the total influence of f? In this paper we present three new contributions towards the FEI conjecture: ii) Our first contribution shows that \u210d(f\u0302\u00b2) \u2264 2\u22c5 aUC^\u2295(f), where aUC^\u2295(f) is the average unambiguous parity-certificate complexity of f. This improves upon several bounds shown by Chakraborty et al. [S. Chakraborty et al., 2016]. We further improve this bound for unambiguous DNFs. iii) We next consider the weaker Fourier Min-entropy-Influence (FMEI) conjecture posed by O'Donnell and others [R. O'Donnell et al., 2011; R. O'Donnell, 2014] which asks if \u210d_{\u221e}(f\u0302\u00b2) \u2264 C\u22c5 Inf(f), where \u210d_{\u221e}(f\u0302\u00b2) is the min-entropy of the Fourier distribution. We show \u210d_{\u221e}(f\u0302\u00b2) \u2264 2\u22c5\ud835\udda2_{min}^\u2295(f), where \ud835\udda2_{min}^\u2295(f) is the minimum parity certificate complexity of f. We also show that for all \u03b5 \u2265 0, we have \u210d_{\u221e}(f\u0302\u00b2) \u2264 2log (\u2016f\u0302\u2016_{1,\u03b5}/(1-\u03b5)), where \u2016f\u0302\u2016_{1,\u03b5} is the approximate spectral norm of f. As a corollary, we verify the FMEI conjecture for the class of read-k DNFs (for constant k). iv) Our third contribution is to better understand implications of the FEI conjecture for the structure of polynomials that 1/3-approximate a Boolean function on the Boolean cube. We pose a conjecture: no flat polynomial (whose non-zero Fourier coefficients have the same magnitude) of degree d and sparsity 2^\u03c9(d) can 1/3-approximate a Boolean function. This conjecture is known to be true assuming FEI and we prove the conjecture unconditionally (i.e., without assuming the FEI conjecture) for a class of polynomials. We discuss an intriguing connection between our conjecture and the constant for the Bohnenblust-Hille inequality, which has been extensively studied in functional analysis."}}
{"id": "2r2DRvk0-l", "cdate": 1577836800000, "mdate": null, "content": {"title": "Quantum Coupon Collector.", "abstract": "We study how efficiently a $k$-element set $S\\subseteq[n]$ can be learned from a uniform superposition $|S\\rangle$ of its elements. One can think of $|S\\rangle=\\sum_{i\\in S}|i\\rangle/\\sqrt{|S|}$ as the quantum version of a uniformly random sample over $S$, as in the classical analysis of the ``coupon collector problem.'' We show that if $k$ is close to $n$, then we can learn $S$ using asymptotically fewer quantum samples than random samples. In particular, if there are $n-k=O(1)$ missing elements then $O(k)$ copies of $|S\\rangle$ suffice, in contrast to the $\\Theta(k\\log k)$ random samples needed by a classical coupon collector. On the other hand, if $n-k=\\Omega(k)$, then $\\Omega(k\\log k)$ quantum samples are~necessary. More generally, we give tight bounds on the number of quantum samples needed for every $k$ and $n$, and we give efficient quantum learning algorithms. We also give tight bounds in the model where we can additionally reflect through $|S\\rangle$. Finally, we relate coupon collection to a known example separating proper and improper PAC learning that turns out to show no separation in the quantum case."}}
{"id": "xFyKDaMgMCe", "cdate": 1546300800000, "mdate": null, "content": {"title": "Quantum hardness of learning shallow classical circuits.", "abstract": "In this paper we study the quantum learnability of constant-depth classical circuits under the uniform distribution and in the distribution-independent framework of PAC learning. In order to attain our results, we establish connections between quantum learning and quantum-secure cryptosystems. We then achieve the following results. 1) Hardness of learning AC$^0$ and TC$^0$ under the uniform distribution. Our first result concerns the concept class TC$^0$ (resp. AC$^0$), the class of constant-depth and polynomial-sized circuits with unbounded fan-in majority gates (resp. AND, OR, NOT gates). We show that if there exists no quantum polynomial-time (resp. strong sub-exponential time) algorithm to solve the Ring Learning with Errors (RLWE) problem, then there exists no polynomial-time quantum learning algorithm for TC$^0$ (resp. AC$^0$) under the uniform distribution (even with access to quantum membership queries). The main technique in this result uses explicit pseudo-random functions that are believed to be quantum-secure to construct concept classes that are hard to learn quantumly under the uniform distribution. 2) Hardness of learning TC$^0_2$ in the PAC setting. Our second result shows that if there exists no quantum polynomial time algorithm for the LWE problem, then there exists no polynomial time quantum PAC learning algorithm for the class TC$^0_2$, i.e., depth-2 TC$^0$ circuits. The main technique in this result is to establish a connection between the quantum security of public-key cryptosystems and the learnability of a concept class that consists of decryption functions of the cryptosystem. This gives a strong (conditional) negative answer to one of the \"Ten Semi-Grand Challenges for Quantum Computing Theory\" raised by Aaronson [Aar05], who asked if AC$^0$ and TC$^0$ can be PAC-learned in quantum polynomial time."}}
{"id": "nh_edMIceOR", "cdate": 1546300800000, "mdate": null, "content": {"title": "Quantum hardness of learning shallow classical circuits.", "abstract": "Neuromodulators are signaling molecules that induce long-lasting or network-wide changes in electrical activity, canonically through metabotropic G-coupled protein receptors. In contrast to classical..."}}
{"id": "SQcYKTom1Ft", "cdate": 1546300800000, "mdate": null, "content": {"title": "Quantum Query Algorithms Are Completely Bounded Forms.", "abstract": "We prove a characterization of $t$-query quantum algorithms in terms of the unit ball of a space of degree-$(2t)$ polynomials. Based on this, we obtain a refined notion of approximate polynomial degree that equals the quantum query complexity, answering a question of Aaronson et al. [``Polynomials, Quantum Query Complexity, and Grothendieck's Inequality,\u201d in Proceedings of the 31st Conference on Computational Complexity, CCC 2016, Schloss Dagstuh, 2016, pp. 25:1--25:19]. Our proof is based on a fundamental result of Christensen and Sinclair [J. Funct. Anal., 72 (1987), pp. 151--181] that generalizes the well-known Stinespring representation for quantum channels to multilinear forms. Using our characterization, we show that many polynomials of degree four are far from those coming from two-query quantum algorithms. We also give a simple and short proof of one of the results of Aaronson et al. showing an equivalence between one-query quantum algorithms and bounded quadratic polynomials."}}
{"id": "Gh1XIiaXn1w", "cdate": 1546300800000, "mdate": null, "content": {"title": "Two New Results About Quantum Exact Learning.", "abstract": "We present two new results about exact learning by quantum computers. First, we show how to exactly learn a k-Fourier-sparse n-bit Boolean function from O(k^{1.5}(log k)^2) uniform quantum examples for that function. This improves over the bound of Theta~(kn) uniformly random classical examples (Haviv and Regev, CCC'15). Our main tool is an improvement of Chang's lemma for sparse Boolean functions. Second, we show that if a concept class {C} can be exactly learned using Q quantum membership queries, then it can also be learned using O ({Q^2}/{log Q} * log|C|) classical membership queries. This improves the previous-best simulation result (Servedio-Gortler, SICOMP'04) by a log Q-factor."}}
