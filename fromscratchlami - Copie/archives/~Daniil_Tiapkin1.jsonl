{"id": "_URtzVoU58m", "cdate": 1672531200000, "mdate": 1695548487722, "content": {"title": "Orthogonal Directions Constrained Gradient Method: from non-linear equality constraints to Stiefel manifold", "abstract": "We consider the problem of minimizing a non-convex function over a smooth manifold M. We propose a novel algorithm, the Orthogonal Directions Constrained Gradient Method (ODCGM), which only require..."}}
{"id": "gvwDosudtyA", "cdate": 1652737692707, "mdate": null, "content": {"title": "Optimistic Posterior Sampling for Reinforcement Learning with Few Samples and Tight Guarantees", "abstract": "We consider reinforcement learning in an environment modeled by an episodic, tabular, step-dependent Markov decision process of horizon $H$ with $S$ states, and $A$ actions.  The performance of an agent is measured by the regret after interacting with the environment for $T$ episodes. We propose an optimistic posterior sampling algorithm for reinforcement learning (OPSRL), a simple variant of posterior sampling that only needs a number of posterior samples logarithmic in $H$, $S$, $A$, and $T$ per state-action pair. For OPSRL we guarantee a high-probability regret bound of order at most $O(\\sqrt{H^3SAT})$ ignoring $\\text{poly}\\log(HSAT)$ terms. The key novel technical ingredient is a new sharp anti-concentration inequality for linear forms of a Dirichlet random vector which may be of independent interest. Specifically, we extend the normal approximation-based lower bound for Beta distributions by Alfers and Dinges (1984) to Dirichlet distributions. Our bound matches the lower bound of order $\\Omega(\\sqrt{H^3SAT})$, thereby answering the open problems raised by Agrawal and Jia (2017) for the episodic setting. "}}
{"id": "TdoyWdRKWI7", "cdate": 1640995200000, "mdate": 1683924377083, "content": {"title": "Primal-Dual Stochastic Mirror Descent for MDPs", "abstract": "We consider the problem of learning the optimal policy for infinite-horizon Markov decision processes (MDPs). For this purpose, some variant of Stochastic Mirror Descent is proposed for convex programming problems with Lipschitz-continuous functionals. An important detail is the ability to use inexact values of functional constraints and compute the value of dual variables. We analyze this algorithm in a general case and obtain an estimate of the convergence rate that does not accumulate errors during the operation of the method. Using this algorithm, we get the first parallel algorithm for mixing average-reward MDPs with a generative model without reduction to discounted MDP. One of the main features of the presented method is low communication costs in a distributed centralized setting, even with very large networks."}}
{"id": "N54x-0JHxt", "cdate": 1640995200000, "mdate": 1683924377151, "content": {"title": "Stochastic saddle-point optimization for the Wasserstein barycenter problem", "abstract": "We consider the population Wasserstein barycenter problem for random probability measures supported on a finite set of points and generated by an online stream of data. This leads to a complicated stochastic optimization problem where the objective is given as an expectation of a function given as a solution to a random optimization problem. We employ the structure of the problem and obtain a convex\u2013concave stochastic saddle-point reformulation of this problem. In the setting when the distribution of random probability measures is discrete, we propose a stochastic optimization algorithm and estimate its complexity. The second result, based on kernel methods, extends the previous one to the arbitrary distribution of random probability measures. Moreover, this new algorithm has a total complexity better than the Stochastic Approximation approach combined with the Sinkhorn algorithm in many cases. We also illustrate our developments by a series of numerical experiments."}}
{"id": "Ezfaw5PM_B", "cdate": 1640995200000, "mdate": 1683879382425, "content": {"title": "From Dirichlet to Rubin: Optimistic Exploration in RL without Bonuses", "abstract": "We propose the Bayes-UCBVI algorithm for reinforcement learning in tabular, stage-dependent, episodic Markov decision process: a natural extension of the Bayes-UCB algorithm by Kaufmann et al. 2012..."}}
{"id": "ZjgYIKbc1-7", "cdate": 1609459200000, "mdate": 1683924377098, "content": {"title": "Improved Complexity Bounds in Wasserstein Barycenter Problem", "abstract": "In this paper, we focus on computational aspects of the Wasserstein barycenter problem. We propose two algorithms to compute Wasserstein barycenters of $m$ discrete measures of size $n$ with accuracy $\\e$. The first algorithm, based on mirror prox with a specific norm, meets the complexity of celebrated accelerated iterative Bregman projections (IBP), namely $\\widetilde O(mn^2\\sqrt n/\\e)$, however, with no limitations in contrast to the (accelerated) IBP, which is numerically unstable under small regularization parameter. The second algorithm, based on area-convexity and dual extrapolation, improves the previously best-known convergence rates for the Wasserstein barycenter problem enjoying $\\widetilde O(mn^2/\\e)$ complexity."}}
