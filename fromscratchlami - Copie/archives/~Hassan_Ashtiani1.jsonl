{"id": "jwOg8J1yZ-a", "cdate": 1652737787150, "mdate": null, "content": {"title": "Adversarially Robust Learning with Tolerance", "abstract": "We initiate the study of tolerant adversarial PAC learning with respect to metric perturbation sets. In adversarial PAC learning, an adversary is allowed to replace a test point $x$ with an arbitrary point in a closed ball of radius $r$ centered at $x$. In the tolerant version, the error of the learner is compared with the best achievable error with respect to a slightly larger perturbation radius $(1+\\gamma)r$. This simple tweak helps us bridge the gap between theory and practice and obtain the first PAC-type guarantees for algorithmic techniques that are popular in practice. Furthermore, our sample complexity bounds improve exponentially over best known (non-tolerant) bounds in terms of the VC dimension of the hypothesis class. In particular, for perturbation sets with doubling dimension $d$, we show that a variant of the  ``perturb-and-smooth'' algorithm PAC learns any hypothesis class $H$ with VC dimension $v$ in the $\\gamma$-tolerant adversarial setting with $O\\left(\\frac{v(1+1/\\gamma)^{O(d)}}{\\varepsilon}\\right)$ samples. This guarantee holds in the tolerant robust realizable setting. We extend this to the agnostic case by designing a novel sample compression scheme based on the perturb-and-smooth approach. This compression-based algorithm has a linear dependence on the doubling dimension as well as the VC-dimension. "}}
{"id": "rO6UExXrFzz", "cdate": 1652737775807, "mdate": null, "content": {"title": "Benefits of Additive Noise in Composing Classes with Bounded Capacity", "abstract": "We observe that given two (compatible) classes of functions $\\mathcal{F}$ and $\\mathcal{H}$ with small capacity as measured by their uniform covering numbers, the capacity of the composition class $\\mathcal{H} \\circ \\mathcal{F}$ can become prohibitively large or even unbounded. We then show that adding a small amount of Gaussian noise to the output of $\\mathcal{F}$ before composing it with $\\mathcal{H}$ can effectively control the capacity of $\\mathcal{H} \\circ \\mathcal{F}$, offering a general recipe for modular design. To prove our results, we define new notions of uniform covering number of random functions with respect to the total variation and Wasserstein distances. We instantiate our results for the case of multi-layer sigmoid neural networks. Preliminary empirical results on MNIST dataset indicate that the amount of noise required to improve over existing uniform bounds can be numerically negligible (i.e., element-wise i.i.d. Gaussian noise with standard deviation $10^{-240}$)"}}
{"id": "QbYS4dXH0dD", "cdate": 1621629766478, "mdate": null, "content": {"title": "Privately Learning Mixtures of Axis-Aligned Gaussians", "abstract": "We consider the problem of learning multivariate Gaussians under the constraint of approximate differential privacy. We prove that $\\widetilde{O}(k^2 d \\log^{3/2}(1/\\delta) / \\alpha^2 \\varepsilon)$ samples are sufficient to learn a mixture of $k$ axis-aligned Gaussians in $\\mathbb{R}^d$ to within total variation distance $\\alpha$ while satisfying $(\\varepsilon, \\delta)$-differential privacy. This is the first result for privately learning mixtures of unbounded axis-aligned (or even unbounded univariate) Gaussians. If the covariance matrices of each of the Gaussians is the identity matrix, we show that $\\widetilde{O}(kd/\\alpha^2 + kd \\log(1/\\delta) / \\alpha \\varepsilon)$ samples are sufficient.\nTo prove our results, we design a new technique for privately learning mixture distributions.  A class of distributions $\\mathcal{F}$ is said to be list-decodable if there is an algorithm that, given \"heavily corrupted\" samples from $f \\in \\mathcal{F}$, outputs a list of distributions one of which approximates $f$. We show that if $\\mathcal{F}$ is privately list-decodable then we can learn mixtures of distributions in $\\mathcal{F}$. Finally, we show axis-aligned Gaussian distributions are privately list-decodable, thereby proving mixtures of such distributions are privately learnable.\n\n"}}
{"id": "fCjU41ok0Qx", "cdate": 1620835541257, "mdate": null, "content": {"title": "Black-box Certification and Learning under Adversarial Perturbations", "abstract": "We formally study the problem of classification under adversarial perturbations from a learner\u2019s perspective as well as a third-party who aims at certifying the robustness of a given black-box classifier. We analyze a PAC-type framework of semi-supervised learning and identify possibility and impossibility results for proper learning of VC-classes in this setting. We further introduce a new setting of black-box certification under limited query budget, and analyze this for various classes of predictors and perturbation. We also consider the viewpoint of a black-box adversary that aims at finding adversarial examples, showing that the existence of an adversary with polynomial query complexity can imply the existence of a sample efficient robust learner. "}}
{"id": "sRW0tmt-pUW", "cdate": 1577836800000, "mdate": null, "content": {"title": "On the Sample Complexity of Learning Sum-Product Networks", "abstract": "Sum-Product Networks (SPNs) can be regarded as a form of deep graphical models that compactly represent deeply factored and mixed distributions. An SPN is a rooted directed acyclic graph (DAG) cons..."}}
{"id": "rjud_p9nE20", "cdate": 1577836800000, "mdate": null, "content": {"title": "On the Sample Complexity of Privately Learning Unbounded High-Dimensional Gaussians", "abstract": "We provide sample complexity upper bounds for agnostically learning multivariate Gaussians under the constraint of approximate differential privacy. These are the first finite sample upper bounds for general Gaussians which do not impose restrictions on the parameters of the distribution. Our bounds are near-optimal in the case when the covariance is known to be the identity, and conjectured to be near-optimal in the general case. From a technical standpoint, we provide analytic tools for arguing the existence of global \"locally small\" covers from local covers of the space. These are exploited using modifications of recent techniques for differentially private hypothesis selection. Our techniques may prove useful for privately learning other distribution classes which do not possess a finite cover."}}
{"id": "pQytdFT9tlxw", "cdate": 1577836800000, "mdate": null, "content": {"title": "Black-box Certification and Learning under Adversarial Perturbations", "abstract": "We formally study the problem of classification under adversarial perturbations from a learner's perspective as well as a third-party who aims at certifying the robustness of a given black-box classifier. We analyze a PAC-type framework of semi-supervised learning and identify possibility and impossibility results for proper learning of VC-classes in this setting. We further introduce a new setting of black-box certification under limited query budget, and analyze this for various classes of predictors and perturbation. We also consider the viewpoint of a black-box adversary that aims at finding adversarial examples, showing that the existence of an adversary with polynomial query complexity can imply the existence of a sample efficient robust learner."}}
{"id": "JJ71nZNwU-K", "cdate": 1577836800000, "mdate": null, "content": {"title": "Near-optimal Sample Complexity Bounds for Robust Learning of Gaussian Mixtures via Compression Schemes", "abstract": "We introduce a novel technique for distribution learning based on a notion of sample compression. Any class of distributions that allows such a compression scheme can be learned with few samples. Moreover, if a class of distributions has such a compression scheme, then so do the classes of products and mixtures of those distributions. As an application of this technique, we prove that \u02dc\u0398(kd2/\u03b52) samples are necessary and sufficient for learning a mixture of k Gaussians in Rd, up to error \u03b5 in total variation distance. This improves both the known upper bounds and lower bounds for this problem. For mixtures of axis-aligned Gaussians, we show that \u00d5(kd/\u03b52) samples suffice, matching a known lower bound. Moreover, these results hold in an agnostic learning (or robust estimation) setting, in which the target distribution is only approximately a mixture of Gaussians. Our main upper bound is proven by showing that the class of Gaussians in Rd admits a small compression scheme."}}
{"id": "_-P9to4TJ01", "cdate": 1546300800000, "mdate": null, "content": {"title": "On the Sample Complexity of Learning Sum-Product Networks", "abstract": "Sum-Product Networks (SPNs) can be regarded as a form of deep graphical models that compactly represent deeply factored and mixed distributions. An SPN is a rooted directed acyclic graph (DAG) consisting of a set of leaves (corresponding to base distributions), a set of sum nodes (which represent mixtures of their children distributions) and a set of product nodes (representing the products of its children distributions). In this work, we initiate the study of the sample complexity of PAC-learning the set of distributions that correspond to SPNs. We show that the sample complexity of learning tree structured SPNs with the usual type of leaves (i.e., Gaussian or discrete) grows at most linearly (up to logarithmic factors) with the number of parameters of the SPN. More specifically, we show that the class of distributions that corresponds to tree structured Gaussian SPNs with $k$ mixing weights and $e$ ($d$-dimensional Gaussian) leaves can be learned within Total Variation error $\\epsilon$ using at most $\\widetilde{O}(\\frac{ed^2+k}{\\epsilon^2})$ samples. A similar result holds for tree structured SPNs with discrete leaves. We obtain the upper bounds based on the recently proposed notion of distribution compression schemes. More specifically, we show that if a (base) class of distributions $\\mathcal{F}$ admits an \"efficient\" compression, then the class of tree structured SPNs with leaves from $\\mathcal{F}$ also admits an efficient compression."}}
{"id": "3PP_tnkRdpL", "cdate": 1546300800000, "mdate": null, "content": {"title": "Disentangled behavioural representations", "abstract": "Individual characteristics in human decision-making are often quantified by fitting a parametric cognitive model to subjects' behavior and then studying differences between them in the associated parameter space. However, these models often fit behavior more poorly than recurrent neural networks (RNNs), which are more flexible and make fewer assumptions about the underlying decision-making processes. Unfortunately, the parameter and latent activity spaces of RNNs are generally high-dimensional and uninterpretable, making it hard to use them to study individual differences. Here, we show how to benefit from the flexibility of RNNs while representing individual differences in a low-dimensional and interpretable space. To achieve this, we propose a novel end-to-end learning framework in which an encoder is trained to map the behavior of subjects into a low-dimensional latent space. These low-dimensional representations are used to generate the parameters of individual RNNs corresponding to the decision-making process of each subject. We introduce terms into the loss function that ensure that the latent dimensions are informative and disentangled, i.e., encouraged to have distinct effects on behavior. This allows them to align with separate facets of individual differences. We illustrate the performance of our framework on synthetic data as well as a dataset including the behavior of patients with psychiatric disorders."}}
