{"id": "YrxOdjYd1j8", "cdate": 1663850478373, "mdate": null, "content": {"title": "Latent Topology Induction for Understanding Contextualized Representations", "abstract": "Recently, there has been considerable interests in understanding pretrained language models. This work studies the hidden geometry of the representation space of language models from a unique topological perspective. We hypothesize that there exist a network of latent anchor states summarizing the topology (neighbors and connectivity) of the representation space. we infer this latent network in a fully unsupervised way using a structured variational autoencoder. We show that such network exists in pretrained representations, but not in baseline random or positional embeddings. We connect the discovered topological structure to their linguistic interpretations. In this latent network, leave nodes can be grounded to word surface forms, anchor states can be grounded to linguistic categories, and connections between nodes and states can be grounded to phrase constructions and syntactic templates. We further show how such network evolves as the embeddings become more contextualized, with observational and statistical evidence demonstrating how contextualization helps words \u201creceive meaning\u201d from their topological neighbors via the anchor states. We demonstrate these insights with extensive experiments and visualizations."}}
{"id": "_nGgzQjzaRy", "cdate": 1663850458506, "mdate": null, "content": {"title": "Decomposed Prompting: A Modular Approach for Solving Complex Tasks", "abstract": "Few-shot prompting is a surprisingly powerful way to use Large Language Models (LLMs) to solve various tasks. However, this approach struggles as the task complexity increases or when the individual reasoning steps of the task themselves are hard to learn, especially when embedded in more complex tasks. To address this, we propose Decomposed Prompting, a new approach to solve complex tasks by decomposing them (via prompting) into simpler sub-tasks that can be delegated to a library of prompting-based LLMs dedicated to these sub-tasks. This modular structure allows each prompt to be optimized for its specific sub-task, further decomposed if necessary, and even easily replaced with more effective prompts, trained models, or symbolic functions if desired.\nWe show that the flexibility and modularity of Decomposed Prompting allows it to outperform prior work on few-shot prompting using GPT3. On symbolic reasoning tasks, we can further decompose sub-tasks that are hard for LLMs into even simpler solvable sub-tasks. When the complexity comes from the input length, we can recursively decompose the task into the same task but with smaller inputs. We also evaluate our approach on textual multi-step reasoning tasks: on long-context multi-hop QA task, we can more effectively teach the sub-tasks via our separate sub-tasks prompts; and on open-domain multi-hop QA, we can incorporate a symbolic information retrieval within our decomposition framework, leading to improved performance on both tasks. Datasets, Code and Prompts available at https://github.com/allenai/DecomP."}}
{"id": "yf1icZHC-l9", "cdate": 1663850255918, "mdate": null, "content": {"title": "Complexity-Based Prompting for Multi-step Reasoning", "abstract": "We study the task of prompting large-scale language models to perform multi-step reasoning. Existing work shows that when prompted with a chain of thoughts (CoT), sequences of short sentences describing intermediate reasoning steps towards a final answer, large language models can generate new reasoning chains and predict answers for new inputs. A central question is which reasoning examples make the most effective prompts. In this work, we propose complexity-based prompting, a simple and effective example selection scheme for multi-step reasoning. We show that prompts with higher reasoning complexity, i.e., chains with more reasoning steps, achieve substantially better performance on math word reasoning tasks over strong baselines. We further extend our complexity-based criteria from prompting (selecting inputs) to decoding (selecting outputs), where we sample multiple reasoning chains from the model, then choose the majority\nof generated answers from complex reasoning chains (over simple chains). When used to prompt GPT-3, our approach substantially improves multi-step reasoning accuracy, with an 8.6% absolute improvement on GSM8K, and 6.4% on MathQA. Compared with existing example selection schemes like manual tuning or retrieval-based selection, selection based on reasoning complexity is intuitive, easy to implement, and annotation-efficient. Further results demonstrate the robustness of performance gains from complex prompts under format perturbation and distribution shift."}}
{"id": "_2CLeIIYMPd", "cdate": 1632875442920, "mdate": null, "content": {"title": "Discovering Latent Network Topology in Contextualized Representations with Randomized Dynamic Programming", "abstract": "The discovery of large-scale discrete latent structures is crucial for understanding the fundamental generative processes of language. In this work, we use structured latent variables to study the representation space of contextualized embeddings and gain insight into the hidden topology of pretrained language models. However, existing methods are severely limited by issues of scalability and efficiency as working with large combinatorial spaces requires expensive memory consumption. We address this challenge by proposing a Randomized Dynamic Programming (RDP) algorithm for the approximate inference of structured models with DP-style exact computation (e.g., Forward-Backward). Our technique samples a subset of DP paths reducing memory complexity to as small as one percent. We use RDP to analyze the representation space of pretrained language models, discovering a large-scale latent network in a fully unsupervised way. The induced latent states not only serve as anchors marking the topology of the space (neighbors and connectivity), but also reveal linguistic properties related to syntax, morphology, and semantics. We also show that traversing this latent network yields unsupervised paraphrase generation."}}
{"id": "ho-3nroGS6r", "cdate": 1617899922677, "mdate": null, "content": {"title": "Nested Named Entity Recognition with Partially Observed TreeCRFs", "abstract": "Named entity recognition (NER) is a well-studied task in natural language processing. However, the widely-used sequence labeling framework is difficult to detect entities with nested structures. In this work, we view nested NER as constituency parsing with partially-observed trees and model it with partially-observed TreeCRFs. Specifically, we view all labeled entity spans as observed nodes in a constituency tree, and other spans as latent nodes. With the TreeCRF we achieve a uniform way to jointly model the observed and the latent nodes. To compute the probability of partial trees with partial marginalization, we propose a variant of the Inside algorithm, the \\textsc{Masked Inside} algorithm, that supports different inference operations for different nodes (evaluation for the observed, marginalization for the latent, and rejection for nodes incompatible with the observed) with efficient parallelized implementation, thus significantly speeding up training and inference. Experiments show that our approach achieves the state-of-the-art (SOTA) F1 scores on the ACE2004, ACE2005 dataset, and shows comparable performance to SOTA models on the GENIA dataset."}}
{"id": "f20nFi84q1", "cdate": 1617899814754, "mdate": null, "content": {"title": "Rethinking Text Attribute Transfer: A Lexical Analysis", "abstract": "Text attribute transfer is modifying certain linguistic attributes (e.g. sentiment, style, authorship, etc.) of a sentence and transforming them from one type to another. In this paper, we aim to analyze and interpret what is changed during the transfer process. We start from the observation that in many existing models and datasets, certain words within a sentence play important roles in determining the sentence attribute class. These words are referred to as \\textit{the Pivot Words}. Based on these pivot words, we propose a lexical analysis framework, \\textit{the Pivot Analysis}, to quantitatively analyze the effects of these words in text attribute classification and transfer. We apply this framework to existing datasets and models and show that: (1) the pivot words are strong features for the classification of sentence attributes; (2) to change the attribute of a sentence, many datasets only requires to change certain pivot words; (3) consequently, many transfer models only perform the lexical-level modification, while leaving higher-level sentence structures unchanged. Our work provides an in-depth understanding of linguistic attribute transfer and further identifies the future requirements and challenges of this task"}}
{"id": "oVkiyxYnYqD", "cdate": 1617899704157, "mdate": null, "content": {"title": "Natural Answer Generation with Heterogeneous Memory", "abstract": "Memory augmented encoder-decoder framework has achieved promising progress for natural language generation tasks. Such frameworks enable a decoder to retrieve from a memory during generation. However, less research has been done to take care of the memory contents from different sources, which are often of heterogeneous formats. In this work, we propose a novel attention mechanism to encourage the decoder to actively interact with the memory by taking its heterogeneity into account. Our solution attends across the generated history and memory to explicitly avoid repetition, and introduce related knowledge to enrich our generated sentences. Experiments on the answer sentence generation task show that our method can effectively explore heterogeneous memory to produce readable and meaningful answer sentences while maintaining high coverage for given answer information."}}
{"id": "aCgLmfhIy_f", "cdate": 1601308176026, "mdate": null, "content": {"title": "Prototypical Representation Learning for Relation Extraction", "abstract": "Recognizing relations between entities is a pivotal task of relational learning.  \nLearning relation representations from distantly-labeled datasets is difficult because of the abundant label noise and complicated expressions in human language.  \nThis paper aims to learn predictive, interpretable, and robust relation representations from distantly-labeled data that are effective in different settings, including supervised, distantly supervised, and few-shot learning. \nInstead of solely relying on the supervision from noisy labels, we propose to learn prototypes for each relation from contextual information to best explore the intrinsic semantics of relations. \nPrototypes are representations in the feature space abstracting the essential semantics of relations between entities in sentences.\nWe learn prototypes based on objectives with clear geometric interpretation, where the prototypes are unit vectors uniformly dispersed in a unit ball, and statement embeddings are centered at the end of their corresponding prototype vectors on the surface of the ball. \nThis approach allows us to learn meaningful, interpretable prototypes for the final classification.\nResults on several relation learning tasks show that our model significantly outperforms the previous state-of-the-art models.\nWe further demonstrate the robustness of the encoder and the interpretability of prototypes with extensive experiments."}}
{"id": "17VnwXYZyhH", "cdate": 1601308093576, "mdate": null, "content": {"title": "Probing BERT in Hyperbolic Spaces", "abstract": "Recently, a variety of probing tasks are proposed to discover linguistic properties learned in contextualized word embeddings. Many of these works implicitly assume these embeddings lay in certain metric spaces, typically the Euclidean space. This work considers a family of geometrically special spaces, the hyperbolic spaces, that exhibit better inductive biases for hierarchical structures and may better reveal linguistic hierarchies encoded in contextualized representations. We introduce a $\\textit{Poincar\u00e9 probe}$, a structural probe projecting these embeddings into a Poincar\u00e9 subspace with explicitly defined hierarchies. We focus on two probing objectives: (a) dependency trees where the hierarchy is defined as head-dependent structures; (b) lexical sentiments where the hierarchy is defined as the polarity of words (positivity and negativity). We argue that a key desideratum of a probe is its sensitivity to the existence of linguistic structures. We apply our probes on BERT, a typical contextualized embedding model. In a syntactic subspace, our probe better recovers tree structures than Euclidean probes, revealing the possibility that the geometry of BERT syntax may not necessarily be Euclidean. In a sentiment subspace, we reveal two possible meta-embeddings for positive and negative sentiments and show how lexically-controlled contextualization would change the geometric localization of embeddings. We demonstrate the findings with our Poincar\u00e9 probe via extensive experiments and visualization. Our results can be reproduced at https://github.com/FranxYao/PoincareProbe"}}
{"id": "HJxiirHe8r", "cdate": 1567802786967, "mdate": null, "content": {"title": "Paraphrase Generation with Latent Bag of Words", "abstract": "  Paraphrase generation is a longstanding important problem in natural language processing.    Recent progress in deep generative models has shown promising results on discrete latent variables for text generation.    Inspired by variational autoencoders with discrete latent structures,    in this work, we propose a latent bag of words (BOW) model for paraphrase generation.   We ground the semantics of a discrete latent variable by the target BOW.    We use this latent variable to build a fully differentiable content planning and surface realization pipeline.    Specifically, we use source words to predict their neighbors and model the target BOW with a mixture of softmax.    We use gumbel top-k reparameterization to perform differentiable subset sampling from the predicted BOW distribution.   We retrieve the sampled word embeddings and use them to augment the decoder and guide its generation search space.    Our latent BOW model not only enhances the decoder, but also exhibits clear interpretability.   We show the model interpretability with regard to (1). unsupervised learning of word neighbors (2). the step-by-step generation procedure.    Extensive experiments demonstrate the model's transparent and effective generation process. "}}
