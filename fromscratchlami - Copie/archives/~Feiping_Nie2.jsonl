{"id": "fCQ-E5VKKk", "cdate": 1668843043756, "mdate": 1668843043756, "content": {"title": "Re-Weighted Discriminatively Embedded K-Means for Multi-View Clustering", "abstract": "Recent years, more and more multi-view data are widely used in many real-world applications. This kind of data (such as image data) is high dimensional and obtained from different feature extractors, which represents distinct perspectives of the data. How to cluster such data efficiently is a challenge. In this paper, we propose a novel multi-view clustering framework, called re-weighted discriminatively embedded K-means, for this task. The proposed method is a multiview least-absolute residual model, which induces robustness to efficiently mitigates the influence of outliers and realizes dimension reduction during multi-view clustering. Specifically, the proposed model is an unsupervised optimization scheme, which utilizes iterative re-weighted least squares to solve least-absolute residual and adaptively controls the distribution of multiple weights in a re-weighted manner only based on its own low-dimensional subspaces and a common clustering indicator matrix. Furthermore, theoretical analysis (including optimality and convergence analysis) and the optimization algorithm are also presented. Compared with several state-of-the-art multi-view clustering methods, the proposed method substantially improves the accuracy of the clustering results on widely used benchmark data sets, which demonstrates the superiority of the proposed work."}}
{"id": "tC7lF9bNj1D", "cdate": 1668842655165, "mdate": null, "content": {"title": "Discriminatively embedded k-means for multi-view clustering", "abstract": "In real world applications, more and more data, for example, image/video data, are high dimensional and represented by multiple views which describe different perspectives of the data. Efficiently clustering such data is a challenge. To address this problem, this paper proposes a novel multi-view clustering method called Discriminatively Embedded K-Means (DEKM), which embeds the synchronous learning of multiple discriminative subspaces into multi-view K-Means clustering to construct a unified framework, and adaptively control the intercoordinations between these subspaces simultaneously. In this framework, we firstly design a weighted multi-view Linear Discriminant Analysis (LDA), and then develop an unsupervised optimization scheme to alternatively learn the common clustering indicator, multiple discriminative subspaces and weights for heterogeneous features with convergence. Comprehensive evaluations on three benchmark datasets and comparisons with several state-of-the-art multi-view clustering algorithms demonstrate the superiority of the proposed work."}}
{"id": "0PH-P_FIqGD", "cdate": 1663849960743, "mdate": null, "content": {"title": "Compact Bilinear Pooling via General Bilinear Projection", "abstract": "Most factorized bilinear pooling (FBiP) employs Hadamard product-based bilinear projection to learn appropriate projecting directions to reduce the dimension of bilinear features. However, in this paper, we reveal that the Hadamard product-based bilinear projection makes FBiP miss a lot of possible projecting directions, which will significantly harm the performance of outputted compact bilinear features, including compactness and effectiveness. To address this issue, we propose a general matrix-based bilinear projection based on the rank-$k$ matrix base decomposition, where the Hadamard-based bilinear projection is a special case of our proposed one. Using the proposed bilinear projection, we design a novel low-rank factorized bilinear pooling (named RK-FBP), which does not miss any projecting directions. Thus, our RK-FBP can generate better compact bilinear features. To leverage high-order information in local features, we nest several RK-FBP modules together to formulate a multi-linear pooling that outputs compact multi-linear features. At last, we conduct experiments on several fine-grained image tasks to evaluate our models. The experiments show that our models achieve new state-of-the-art classification accuracy by the lowest dimension."}}
{"id": "KG2RTUXXU7", "cdate": 1621629743328, "mdate": null, "content": {"title": "Local $K$-means: An Efficient Optimization Algorithm And Its Generalization", "abstract": "Until now, $k$-means is still one of the most popular clustering algorithms because of its simplicity and efficiency, although it has been proposed for a long time.\nIn this paper, we considered a variant of $k$-means that takes the $k$-nearest neighbor ($k$-NN) graph as input and proposed a novel clustering algorithm called Local K-Means (LKM).\nWe also developed a general model that unified LKM, KSUMS, and SC, and discussed the connection among them.\nIn addition, we proposed an efficient optimization algorithm for the unified model. \nThus, not only LKM but also SC can be optimized with a linear time complexity with respect to the number of samples. \nSpecifically, the computational overhead is $O(nk)$, where $n$ and $k$ are denote the number of samples and nearest neighbors, respectively.\nExtensive experiments have been conducted on 11 synthetic and 16 benchmark datasets from the literature. \nThe effectiveness, efficiency, and robustness to outliers of the proposed method have been verified by the experimental results."}}
{"id": "Hye190VKvH", "cdate": 1569439366746, "mdate": null, "content": {"title": "Longitudinal Enrichment of Imaging Biomarker Representations for Improved Alzheimer's Disease Diagnosis", "abstract": "Longitudinal data is often available inconsistently across individuals resulting in ignoring of additionally available data. Alzheimer's Disease (AD) is a progressive disease that affects over 5 million patients in the US alone, and is the 6th leading cause of death. Early detection of AD can significantly improve or extend a patient's life so it is critical to use all available information about patients. \nWe propose an unsupervised method to learn a consistent representation by utilizing inconsistent data through minimizing the ratio of $p$-Order Principal Components Analysis (PCA) and Locality Preserving Projections (LPP). Our method's representation can outperform the use of consistent data alone and does not require the use of complex tensor-specific approaches. We run experiments on patient data from the Alzheimer\u2019s Disease Neuroimaging Initiative (ADNI), which consists of inconsistent data, to predict patients' diagnosis."}}
