{"id": "jeXuQEHLyV", "cdate": 1672531200000, "mdate": 1708568848806, "content": {"title": "Clustered-patch Element Connection for Few-shot Learning", "abstract": "Weak feature representation problem has influenced the performance of few-shot classification task for a long time. To alleviate this problem, recent researchers build connections between support and query instances through embedding patch features to generate discriminative representations. However, we observe that there exists semantic mismatches (foreground/ background) among these local patches, because the location and size of the target object are not fixed. What is worse, these mismatches result in unreliable similarity confidences, and complex dense connection exacerbates the problem. According to this, we propose a novel Clustered-patch Element Connection (CEC) layer to correct the mismatch problem. The CEC layer leverages Patch Cluster and Element Connection operations to collect and establish reliable connections with high similarity patch features, respectively. Moreover, we propose a CECNet, including CEC layer based attention module and distance metric. The former is utilized to generate a more discriminative representation benefiting from the global clustered-patch features, and the latter is introduced to reliably measure the similarity between pair-features. Extensive experiments demonstrate that our CECNet outperforms the state-of-the-art methods on classification benchmark. Furthermore, our CEC approach can be extended into few-shot segmentation and detection tasks, which achieves competitive performances."}}
{"id": "e86oNG8BBp", "cdate": 1672531200000, "mdate": 1708568848809, "content": {"title": "SpatialFormer: Semantic and Target Aware Attentions for Few-Shot Learning", "abstract": "Recent Few-Shot Learning (FSL) methods put emphasis on generating a discriminative embedding features to precisely measure the similarity between support and query sets. Current CNN-based cross-attention approaches generate discriminative representations via enhancing the mutually semantic similar regions of support and query pairs. However, it suffers from two problems: CNN structure produces inaccurate attention map based on local features, and mutually similar backgrounds cause distraction. To alleviate these problems, we design a novel SpatialFormer structure to generate more accurate attention regions based on global features. Different from the traditional Transformer modeling intrinsic instance-level similarity which causes accuracy degradation in FSL, our SpatialFormer explores the semantic-level similarity between pair inputs to boost the performance. Then we derive two specific attention modules, named SpatialFormer Semantic Attention (SFSA) and SpatialFormer Target Attention (SFTA), to enhance the target object regions while reduce the background distraction. Particularly, SFSA highlights the regions with same semantic information between pair features, and SFTA finds potential foreground object regions of novel feature that are similar to base categories. Extensive experiments show that our methods are effective and achieve new state-of-the-art results on few-shot classification benchmarks."}}
{"id": "bhej1bpCgh", "cdate": 1672531200000, "mdate": 1708568848805, "content": {"title": "MatchDet: A Collaborative Framework for Image Matching and Object Detection", "abstract": "Image matching and object detection are two fundamental and challenging tasks, while many related applications consider them two individual tasks (i.e. task-individual). In this paper, a collaborative framework called MatchDet (i.e. task-collaborative) is proposed for image matching and object detection to obtain mutual improvements. To achieve the collaborative learning of the two tasks, we propose three novel modules, including a Weighted Spatial Attention Module (WSAM) for Detector, and Weighted Attention Module (WAM) and Box Filter for Matcher. Specifically, the WSAM highlights the foreground regions of target image to benefit the subsequent detector, the WAM enhances the connection between the foreground regions of pair images to ensure high-quality matches, and Box Filter mitigates the impact of false matches. We evaluate the approaches on a new benchmark with two datasets called Warp-COCO and miniScanNet. Experimental results show our approaches are effective and achieve competitive improvements."}}
{"id": "a4rwzu-lTY", "cdate": 1668511725130, "mdate": 1668511725130, "content": {"title": "Rethinking the Metric in Few-shot Learning: From an Adaptive Multi-Distance Perspective", "abstract": "Few-shot learning problem focuses on recognizing unseen classes\ngiven a few labeled images. In recent effort, more attention is paid\nto fine-grained feature embedding, ignoring the relationship among\ndifferent distance metrics. In this paper, for the first time, we investigate\nthe contributions of different distance metrics, and propose\nan adaptive fusion scheme, bringing significant improvements in\nfew-shot classification. We start from a naive baseline of confidence\nsummation and demonstrate the necessity of exploiting the\ncomplementary property of different distance metrics. By finding\nthe competition problem among them, built upon the baseline, we\npropose an Adaptive Metrics Module (AMM) to decouple metrics\nfusion into metric-prediction fusion and metric-losses fusion. The\nformer encourages mutual complementary, while the latter alleviates\nmetric competition via multi-task collaborative learning. Based\non AMM, we design a few-shot classification framework AMTNet,\nincluding the AMM and the Global Adaptive Loss (GAL), to\njointly optimize the few-shot task and auxiliary self-supervised\ntask, making the embedding features more robust. In the experiment,\nthe proposed AMM achieves 2% higher performance than\nthe naive metrics fusion module, and our AMTNet outperforms the\nstate-of-the-arts on multiple benchmark datasets."}}
{"id": "dVXO3Orjmxk", "cdate": 1652737282353, "mdate": null, "content": {"title": "Decoupling Classifier for Boosting Few-shot Object Detection and Instance Segmentation", "abstract": "This paper focus on few-shot object detection~(FSOD) and instance segmentation~(FSIS), which requires a model to quickly adapt to novel classes with a few labeled instances. The existing methods severely suffer from bias classification because of the missing label issue which naturally exists in an instance-level few-shot scenario and is first formally proposed by us. Our analysis suggests that the standard classification head of most FSOD or FSIS models needs to be decoupled to mitigate the bias classification. Therefore, we propose an embarrassingly simple but effective method that decouples the standard classifier into two heads. Then, these two individual heads are capable of independently addressing clear positive samples and noisy negative samples which are caused by the missing label. In this way, the model can effectively learn novel classes while mitigating the effects of noisy negative samples. Without bells and whistles, our model without any additional computation cost and parameters consistently outperforms its baseline and state-of-the-art by a large margin on PASCAL VOC and MS-COCO benchmarks for FSOD and FSIS tasks.\\footnote{\\url{https://csgaobb.github.io/Projects/DCFS}.}"}}
{"id": "uXO1ZEElhfk", "cdate": 1640995200000, "mdate": 1666921622422, "content": {"title": "tSF: Transformer-Based Semantic Filter for Few-Shot Learning", "abstract": "Few-Shot Learning (FSL) alleviates the data shortage challenge via embedding discriminative target-aware features among plenty seen (base) and few unseen (novel) labeled samples. Most feature embedding modules in recent FSL methods are specially designed for corresponding learning tasks (e.g., classification, segmentation, and object detection), which limits the utility of embedding features. To this end, we propose a light and universal module named transformer-based Semantic Filter (tSF), which can be applied for different FSL tasks. The proposed tSF redesigns the inputs of a transformer-based structure by a semantic filter, which not only embeds the knowledge from whole base set to novel set but also filters semantic features for target category. Furthermore, the parameters of tSF is equal to half of a standard transformer block (less than 1M). In the experiments, our tSF is able to boost the performances in different classic few-shot learning tasks (about $$2\\%$$ improvement), especially outperforms the state-of-the-arts on multiple benchmark datasets in few-shot classification task."}}
{"id": "pkOjHsEMhxy", "cdate": 1640995200000, "mdate": 1666921622423, "content": {"title": "Rethinking the Metric in Few-shot Learning: From an Adaptive Multi-Distance Perspective", "abstract": "Few-shot learning problem focuses on recognizing unseen classes given a few labeled images. In recent effort, more attention is paid to fine-grained feature embedding, ignoring the relationship among different distance metrics. In this paper, for the first time, we investigate the contributions of different distance metrics, and propose an adaptive fusion scheme, bringing significant improvements in few-shot classification. We start from a naive baseline of confidence summation and demonstrate the necessity of exploiting the complementary property of different distance metrics. By finding the competition problem among them, built upon the baseline, we propose an Adaptive Metrics Module (AMM) to decouple metrics fusion into metric-prediction fusion and metric-losses fusion. The former encourages mutual complementary, while the latter alleviates metric competition via multi-task collaborative learning. Based on AMM, we design a few-shot classification framework AMTNet, including the AMM and the Global Adaptive Loss (GAL), to jointly optimize the few-shot task and auxiliary self-supervised task, making the embedding features more robust. In the experiment, the proposed AMM achieves 2% higher performance than the naive metrics fusion module, and our AMTNet outperforms the state-of-the-arts on multiple benchmark datasets."}}
{"id": "P4lha_o-wk", "cdate": 1640995200000, "mdate": 1708568848808, "content": {"title": "Decoupling Classifier for Boosting Few-shot Object Detection and Instance Segmentation", "abstract": "This paper focus on few-shot object detection~(FSOD) and instance segmentation~(FSIS), which requires a model to quickly adapt to novel classes with a few labeled instances. The existing methods severely suffer from bias classification because of the missing label issue which naturally exists in an instance-level few-shot scenario and is first formally proposed by us. Our analysis suggests that the standard classification head of most FSOD or FSIS models needs to be decoupled to mitigate the bias classification. Therefore, we propose an embarrassingly simple but effective method that decouples the standard classifier into two heads. Then, these two individual heads are capable of independently addressing clear positive samples and noisy negative samples which are caused by the missing label. In this way, the model can effectively learn novel classes while mitigating the effects of noisy negative samples. Without bells and whistles, our model without any additional computation cost and parameters consistently outperforms its baseline and state-of-the-art by a large margin on PASCAL VOC and MS-COCO benchmarks for FSOD and FSIS tasks.\\footnote{\\url{https://csgaobb.github.io/Projects/DCFS}.}"}}
{"id": "Nqp6gNq9j4k", "cdate": 1640995200000, "mdate": 1666921622425, "content": {"title": "nVFNet-RDC: Replay and Non-Local Distillation Collaboration for Continual Object Detection", "abstract": "Continual Learning (CL) focuses on developing algorithms with the ability to adapt to new environments and learn new skills. This very challenging task has generated a lot of interest in recent years, with new solutions appearing rapidly. In this paper, we propose a nVFNet-RDC approach for continual object detection. Our nVFNet-RDC consists of teacher-student models, and adopts replay and feature distillation strategies. As the 1st place solutions, we achieve 55.94% and 54.65% average mAP on the 3rd CLVision Challenge Track 2 and Track 3, respectively."}}
{"id": "JRtz-wRyePG", "cdate": 1577836800000, "mdate": 1666921622471, "content": {"title": "Fast and robust template matching with majority neighbour similarity and annulus projection transformation", "abstract": ""}}
