{"id": "7XgfQy0QyFg", "cdate": 1685577600000, "mdate": 1701880427583, "content": {"title": "Efficient and generalizable tuning strategies for stochastic gradient MCMC", "abstract": "Stochastic gradient Markov chain Monte Carlo (SGMCMC) is a popular class of algorithms for scalable Bayesian inference. However, these algorithms include hyperparameters such as step size or batch size that influence the accuracy of estimators based on the obtained posterior samples. As a result, these hyperparameters must be tuned by the practitioner and currently no principled and automated way to tune them exists. Standard Markov chain Monte Carlo tuning methods based on acceptance rates cannot be used for SGMCMC, thus requiring alternative tools and diagnostics. We propose a novel bandit-based algorithm that tunes the SGMCMC hyperparameters by minimizing the Stein discrepancy between the true posterior and its Monte Carlo approximation. We provide theoretical results supporting this approach and assess various Stein-based discrepancies. We support our results with experiments on both simulated and real datasets, and find that this method is practical for a wide range of applications."}}
{"id": "i-y_VsVC_qn", "cdate": 1672531200000, "mdate": 1701880427561, "content": {"title": "Coin Sampling: Gradient-Based Bayesian Inference without Learning Rates", "abstract": "In recent years, particle-based variational inference (ParVI) methods such as Stein variational gradient descent (SVGD) have grown in popularity as scalable methods for Bayesian inference. Unfortun..."}}
{"id": "_L1VFYrjuq", "cdate": 1672531200000, "mdate": 1701880427609, "content": {"title": "Preferential Subsampling for Stochastic Gradient Langevin Dynamics", "abstract": "Stochastic gradient MCMC (SGMCMC) offers a scalable alternative to traditional MCMC, by constructing an unbiased estimate of the gradient of the log-posterior with a small, uniformly-weighted subsa..."}}
{"id": "PeFBGw8qlO", "cdate": 1672531200000, "mdate": 1683879161885, "content": {"title": "Coin Sampling: Gradient-Based Bayesian Inference without Learning Rates", "abstract": "In recent years, particle-based variational inference (ParVI) methods such as Stein variational gradient descent (SVGD) have grown in popularity as scalable methods for Bayesian inference. Unfortunately, the properties of such methods invariably depend on hyperparameters such as the learning rate, which must be carefully tuned by the practitioner in order to ensure convergence to the target measure at a suitable rate. In this paper, we introduce a suite of new particle-based methods for scalable Bayesian inference based on coin betting, which are entirely learning-rate free. We illustrate the performance of our approach on a range of numerical examples, including several high-dimensional models and datasets, demonstrating comparable performance to other ParVI algorithms with no need to tune a learning rate."}}
{"id": "9_k9Z6jNoAo", "cdate": 1672531200000, "mdate": 1701880427601, "content": {"title": "Learning Rate Free Bayesian Inference in Constrained Domains", "abstract": "We introduce a suite of new particle-based algorithms for sampling on constrained domains which are entirely learning rate free. Our approach leverages coin betting ideas from convex optimisation, and the viewpoint of constrained sampling as a mirrored optimisation problem on the space of probability measures. Based on this viewpoint, we also introduce a unifying framework for several existing constrained sampling algorithms, including mirrored Langevin dynamics and mirrored Stein variational gradient descent. We demonstrate the performance of our algorithms on a range of numerical examples, including sampling from targets on the simplex, sampling with fairness constraints, and constrained sampling problems in post-selection inference. Our results indicate that our algorithms achieve competitive performance with existing constrained sampling methods, without the need to tune any hyperparameters."}}
{"id": "5lr6OIZipxo", "cdate": 1672531200000, "mdate": 1701880427558, "content": {"title": "Transport Elliptical Slice Sampling", "abstract": "We propose a new framework for efficiently sampling from complex probability distributions using a combination of normalizing flows and elliptical slice sampling (Murray et al., 2010). The central ..."}}
{"id": "5AgQ3d31Fxe", "cdate": 1672531200000, "mdate": 1683893557399, "content": {"title": "Sequential estimation of temporally evolving latent space network models", "abstract": ""}}
{"id": "-c50Nd-F53", "cdate": 1672531200000, "mdate": 1701880427599, "content": {"title": "CoinEM: Tuning-Free Particle-Based Variational Inference for Latent Variable Models", "abstract": "We introduce two new particle-based algorithms for learning latent variable models via marginal maximum likelihood estimation, including one which is entirely tuning-free. Our methods are based on the perspective of marginal maximum likelihood estimation as an optimization problem: namely, as the minimization of a free energy functional. One way to solve this problem is to consider the discretization of a gradient flow associated with the free energy. We study one such approach, which resembles an extension of the popular Stein variational gradient descent algorithm. In particular, we establish a descent lemma for this algorithm, which guarantees that the free energy decreases at each iteration. This method, and any other obtained as the discretization of the gradient flow, will necessarily depend on a learning rate which must be carefully tuned by the practitioner in order to ensure convergence at a suitable rate. With this in mind, we also propose another algorithm for optimizing the free energy which is entirely learning rate free, based on coin betting techniques from convex optimization. We validate the performance of our algorithms across a broad range of numerical experiments, including several high-dimensional settings. Our results are competitive with existing particle-based methods, without the need for any hyperparameter tuning."}}
{"id": "UBfVVOhrG1", "cdate": 1640995200000, "mdate": 1682670087547, "content": {"title": "Preferential Subsampling for Stochastic Gradient Langevin Dynamics", "abstract": "Stochastic gradient MCMC (SGMCMC) offers a scalable alternative to traditional MCMC, by constructing an unbiased estimate of the gradient of the log-posterior with a small, uniformly-weighted subsample of the data. While efficient to compute, the resulting gradient estimator may exhibit a high variance and impact sampler performance. The problem of variance control has been traditionally addressed by constructing a better stochastic gradient estimator, often using control variates. We propose to use a discrete, non-uniform probability distribution to preferentially subsample data points that have a greater impact on the stochastic gradient. In addition, we present a method of adaptively adjusting the subsample size at each iteration of the algorithm, so that we increase the subsample size in areas of the sample space where the gradient is harder to estimate. We demonstrate that such an approach can maintain the same level of accuracy while substantially reducing the average subsample size that is used."}}
{"id": "Pq4W35pu3E", "cdate": 1640995200000, "mdate": 1683893557486, "content": {"title": "SGMCMCJax: a lightweight JAX library for stochastic gradient Markov chain Monte Carlo algorithms", "abstract": "Coullon et al., (2022). SGMCMCJax: a lightweight JAX library for stochastic gradient Markov chain Monte Carlo algorithms. Journal of Open Source Software, 7(72), 4113, https://doi.org/10.21105/joss.04113"}}
