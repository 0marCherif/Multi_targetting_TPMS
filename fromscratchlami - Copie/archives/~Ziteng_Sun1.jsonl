{"id": "_SxV6IkxPx1", "cdate": 1622151651876, "mdate": null, "content": {"title": "Estimating Sparse Discrete Distributions Under Privacy and Communication Constraints", "abstract": "We consider the problem of estimating sparse discrete distributions under local differential privacy (LDP) and communication constraints. We characterize the sample complexity for sparse estimation under LDP constraints up to a constant factor, and the sample complexity under communication constraints up to a logarithmic factor. Our upper bounds under LDP are based on the Hadamard Response, a private coin scheme that requires only one bit of communication per user. Under communication constraints we propose public coin schemes based on random hashing functions. Our tight lower bounds are based on recently proposed method of chi squared contractions."}}
{"id": "OGPb-AWo9s_", "cdate": 1622151525356, "mdate": null, "content": {"title": "Interactive Inference under Information Constraints", "abstract": "We study the role of interactivity in distributed statistical inference under information constraints, e.g., communication constraints and local differential privacy. We focus on the tasks of goodness-of-fit testing and estimation of discrete distributions. From prior work, these tasks are well understood under noninteractive protocols. Extending these approaches directly for interactive protocols is difficult due to correlations that can build due to interactivity; in fact, gaps can be found in prior claims of tight bounds of distribution estimation using interactive protocols.\nWe propose a new approach to handle this correlation and establish a unified method to establish lower bounds for both tasks. As an application, we obtain optimal bounds for both estimation and testing under local differential privacy and communication constraints. We also provide an example of a natural testing problem where interactivity helps."}}
{"id": "G1jmxFOtY_", "cdate": 1621630106418, "mdate": null, "content": {"title": "Learning with User-Level Privacy", "abstract": "We propose and analyze algorithms to solve a range of learning tasks under user-level differential privacy constraints. Rather than guaranteeing only the privacy of individual samples, user-level DP protects a user's entire contribution ($m \\ge 1$ samples), providing more stringent but more realistic protection against information leaks.  We show that for high-dimensional mean\nestimation, empirical risk minimization with smooth losses, stochastic convex optimization, and learning hypothesis classes with finite metric entropy, the privacy cost decreases as $O(1/\\sqrt{m})$ as users provide more samples. In contrast, when increasing the number of users $n$, the privacy cost decreases at a faster $O(1/n)$ rate.  We complement these results with lower bounds showing the minimax optimality of our algorithms for mean estimation and stochastic convex optimization. Our algorithms rely on novel techniques for private mean estimation in arbitrary dimension with error scaling as the concentration radius $\\tau$ of the distribution rather than the entire range."}}
{"id": "GfVeFihyLRe", "cdate": 1621629917000, "mdate": null, "content": {"title": "Distributed Estimation with Multiple Samples per User: Sharp Rates and Phase Transition", "abstract": "We obtain tight minimax rates for the problem of distributed estimation of discrete distributions under communication constraints, where $n$ users observing $m $ samples each can broadcast only $\\ell$  bits. Our main result is a tight characterization (up to logarithmic factors) of the error rate as a function of $m$, $\\ell$, the domain size, and the number of users under most regimes of interest. While previous work focused on the setting where each user only holds one sample, we show that as $m$ grows the $\\ell_1$ error rate gets reduced by a factor of $\\sqrt{m}$ for small $m$. However, for large $m$ we observe an interesting phase transition: the dependence of the error rate on the communication constraint $\\ell$ changes from $1/\\sqrt{2^{\\ell}}$ to $1/\\sqrt{\\ell}$."}}
{"id": "Bk4xp9ZdZS", "cdate": 1546300800000, "mdate": null, "content": {"title": "Communication Complexity in Locally Private Distribution Estimation and Heavy Hitters", "abstract": "We consider the problems of distribution estimation, and heavy hitter (frequency) estimation under privacy, and communication constraints. While the constraints have been studied separately, optima..."}}
{"id": "SJWBKiW_bH", "cdate": 1514764800000, "mdate": null, "content": {"title": "INSPECTRE: Privately Estimating the Unseen", "abstract": "We develop differentially private methods for estimating various distributional properties. Given a sample from a discrete distribution p, some functional f, and accuracy and privacy parameters alp..."}}
{"id": "Hk4TGvb_Zr", "cdate": 1514764800000, "mdate": null, "content": {"title": "Differentially Private Testing of Identity and Closeness of Discrete Distributions", "abstract": "We study the fundamental problems of identity testing (goodness of fit), and closeness testing (two sample test) of distributions over $k$ elements, under differential privacy. While the problems have a long history in statistics, finite sample bounds for these problems have only been established recently. In this work, we derive upper and lower bounds on the sample complexity of both the problems under $(\\varepsilon, \\delta)$-differential privacy. We provide optimal sample complexity algorithms for identity testing problem for all parameter ranges, and the first results for closeness testing. Our closeness testing bounds are optimal in the sparse regime where the number of samples is at most $k$. Our upper bounds are obtained by privatizing non-private estimators for these problems. The non-private estimators are chosen to have small sensitivity. We propose a general framework to establish lower bounds on the sample complexity of statistical tasks under differential privacy. We show a bound on differentially private algorithms in terms of a coupling between the two hypothesis classes we aim to test. By constructing carefully chosen priors over the hypothesis classes, and using Le Cam's two point theorem we provide a general mechanism for proving lower bounds. We believe that the framework can be used to obtain strong lower bounds for other statistical tasks under privacy."}}
