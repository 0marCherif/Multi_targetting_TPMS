{"id": "UdgtTVTdswg", "cdate": 1652737766832, "mdate": null, "content": {"title": "DataMUX: Data Multiplexing for Neural Networks", "abstract": "In this paper, we introduce \\emph{data multiplexing} (DataMUX), a technique that enables deep neural networks to process multiple inputs simultaneously using a single compact representation. DataMUX demonstrates that neural networks are  capable of generating accurate predictions over \\emph{mixtures} of inputs, resulting in increased inference throughput with minimal extra memory requirements. Our approach uses two key components -- 1) a multiplexing layer that performs a fixed linear transformation to each input before combining them to create a \"mixed\" representation of the same size as a single input, which is then processed by the base network, and 2) a demultiplexing layer that converts the base network's output back into independent representations before producing predictions for each input. We show the viability of DataMUX for different architectures (Transformers, and to a much lesser extent MLPs and CNNs) across six different tasks spanning sentence classification, named entity recognition and image classification. For instance, DataMUX for Transformers can multiplex up to 20x/40x inputs, achieving up to 11x/18x increase in inference throughput with absolute performance drops of $<2\\%$ and $<4\\%$ respectively compared to a vanilla Transformer on MNLI, a natural language inference task. We also provide a theoretical construction for multiplexing in self-attention networks and analyze the effect of various design elements in DataMUX."}}
{"id": "5b3ntAI6ZU4", "cdate": 1609459200000, "mdate": 1648844960391, "content": {"title": "Improving Dialog Systems for Negotiation with Personality Modeling", "abstract": "Runzhe Yang, Jingxiao Chen, Karthik Narasimhan. Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers). 2021."}}
{"id": "B1lR3HBeUB", "cdate": 1567802806073, "mdate": null, "content": {"title": "A Generalized Algorithm for Multi-Objective Reinforcement Learning and Policy Adaptation", "abstract": "We introduce a new algorithm for multi-objective reinforcement learning (MORL) with linear preferences, with the goal of enabling few-shot adaptation to new tasks. In MORL, the aim is to learn policies over multiple competing objectives whose relative importance (preferences) is unknown to the agent. While this alleviates dependence on scalar reward design, the expected return of a policy can change significantly with varying preferences, making it challenging to learn a single model to produce optimal policies under different preference conditions. We propose a generalized version of the Bellman equation to learn a single parametric representation for optimal policies over the space of all possible preferences. After this initial learning phase, our agent can quickly adapt to any given preference, or automatically infer an underlying preference with very few samples. Experiments across four different domains demonstrate the effectiveness of our approach."}}
{"id": "vXBbwSmQpbs", "cdate": 1546300800000, "mdate": 1648844960392, "content": {"title": "Imitation Refinement for X-ray Diffraction Signal Processing", "abstract": "Many real-world tasks involve identifying signals from data satisfying background or prior knowledge. In domains like materials discovery, due to the flaws and biases in raw experimental data, the identification of X-ray diffraction (XRD) signals often requires significant (manual) expert work to find refined signals that are similar to the ideal theoretical ones. Automatically refining the raw XRD signals utilizing simulated theoretical data is thus desirable. We propose imitation refinement, a novel approach to refine imperfect input signals, guided by a pre-trained classifier incorporating prior knowledge from simulated theoretical data, such that the refined signals imitate the ideal ones. The classifier is trained on the ideal simulated data to classify signals and learns an embedding space where each class is represented by a prototype. The refiner learns to refine the imperfect signals with small modifications, such that their embeddings are closer to the corresponding prototypes. We show that the refiner can be trained in both supervised and unsupervised fashions. We further illustrate the effectiveness of the proposed approach both qualitatively and quantitatively in an X-ray diffraction signal refinement task in materials discovery."}}
{"id": "hMhrSJ1TEP", "cdate": 1546300800000, "mdate": 1648844960395, "content": {"title": "Unsupervised learning by a \"softened\" correlation game: duality and convergence", "abstract": "Neural networks with Hebbian excitation and anti-Hebbian inhibition form an interesting class of biologically plausible unsupervised learning algorithms. It has recently been shown that such networks can be regarded as online gradient descent-ascent algorithms for solving min-max problems that are dual to unsupervised learning principles formulated with no explicit reference to neural networks. Here we generalize one such formulation, the correlation game, by replacing a hard constraint with a soft penalty function. Our \"softened\" correlation game contains the nonnegative similarity matching principle as a special case. For solving the primal problem, we derive a projected gradient ascent algorithm that achieves speed through sorting. For solving the dual problem, we derive a projected gradient descent-ascent algorithm, the stochastic online variant of which can be interpreted as a neural network algorithm. We prove strong duality when the inhibitory connection matrix is positive definite, a condition that also prohibits multistability of neural activity dynamics. We show empirically that the neural net algorithm can converge when inhibitory plasticity is faster than excitatory plasticity, and may fail to converge in the opposing case. This is intuitively interpreted using the structure of the min-max problem."}}
{"id": "SJNqPfMOZH", "cdate": 1483228800000, "mdate": null, "content": {"title": "Agent-Aware Dropout DQN for Safe and Efficient On-line Dialogue Policy Learning", "abstract": ""}}
{"id": "D9g33FQ81j3", "cdate": 1483228800000, "mdate": 1648844960385, "content": {"title": "On-line Dialogue Policy Learning with Companion Teaching", "abstract": "Lu Chen, Runzhe Yang, Cheng Chang, Zihao Ye, Xiang Zhou, Kai Yu. Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 2, Short Papers. 2017."}}
{"id": "BJWHSMMO-B", "cdate": 1483228800000, "mdate": null, "content": {"title": "Affordable On-line Dialogue Policy Learning", "abstract": ""}}
