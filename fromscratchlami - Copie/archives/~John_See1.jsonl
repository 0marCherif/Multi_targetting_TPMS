{"id": "gnWceIX-Bg", "cdate": 1672531200000, "mdate": 1681567229199, "content": {"title": "ERNet: An Efficient and Reliable Human-Object Interaction Detection Network", "abstract": ""}}
{"id": "WXPQc7F9FnJ", "cdate": 1672531200000, "mdate": 1681567229176, "content": {"title": "FatigueView: A Multi-Camera Video Dataset for Vision-Based Drowsiness Detection", "abstract": ""}}
{"id": "SS-BMSlFLe", "cdate": 1672531200000, "mdate": 1681567229380, "content": {"title": "Spatio-Temporal Point Process for Multiple Object Tracking", "abstract": ""}}
{"id": "J8OX45KtFLf", "cdate": 1672531200000, "mdate": 1681567228884, "content": {"title": "Spot-then-Recognize: A Micro-Expression Analysis Network for Seamless Evaluation of Long Videos", "abstract": ""}}
{"id": "0DamWKcOUm", "cdate": 1672531200000, "mdate": 1681567229116, "content": {"title": "Doing More With Moir\u00e9 Pattern Detection in Digital Photos", "abstract": ""}}
{"id": "wgjsF4PnTNG", "cdate": 1656074971647, "mdate": null, "content": {"title": "FME'21: 1st Workshop on Facial Micro-Expression: Advanced Techniques for Facial Expressions Generation and Spotting", "abstract": "Facial micro-expressions (FMEs) are involuntary facial movements that occur spontaneously when a person experiences an emotion but tries to suppress or repress the facial expression and usually occur in high-risk situations. Thus, FMEs are very short in duration, an important feature that distinguishes them from ordinary facial expressions. And MEs are considered to be one of the most valuable cues for complex human emotion understanding and lie detection. Since 2014, the computational analysis and automation of MEs have been an emerging area of face research. The workshop will explore various dimensions of the human mind through emotion understanding and FME analysis, as well as extended research based on multi modal approaches."}}
{"id": "vIULw1RECt", "cdate": 1640995200000, "mdate": 1668073520952, "content": {"title": "Controllable Augmentations for Video Representation Learning", "abstract": "This paper focuses on self-supervised video representation learning. Most existing approaches follow the contrastive learning pipeline to construct positive and negative pairs by sampling different clips. However, this formulation tends to bias to static background and have difficulty establishing global temporal structures. The major reason is that the positive pairs, i.e., different clips sampled from the same video, have limited temporal receptive field, and usually share similar background but differ in motions. To address these problems, we propose a framework to jointly utilize local clips and global videos to learn from detailed region-level correspondence as well as general long-term temporal relations. Based on a set of controllable augmentations, we achieve accurate appearance and motion pattern alignment through soft spatio-temporal region contrast. Our formulation is able to avoid the low-level redundancy shortcut by mutual information minimization to improve the generalization. We also introduce local-global temporal order dependency to further bridge the gap between clip-level and video-level representations for robust temporal modeling. Extensive experiments demonstrate that our framework is superior on three video benchmarks in action recognition and video retrieval, capturing more accurate temporal dynamics."}}
{"id": "tb3YQSQaa1", "cdate": 1640995200000, "mdate": 1681567228939, "content": {"title": "BadmintonDB: A Badminton Dataset for Player-specific Match Analysis and Prediction", "abstract": ""}}
{"id": "s9njCRjDyS", "cdate": 1640995200000, "mdate": 1681567229180, "content": {"title": "BlumNet: Graph Component Detection for Object Skeleton Extraction", "abstract": ""}}
{"id": "hwSPr2I9_S", "cdate": 1640995200000, "mdate": 1668595577755, "content": {"title": "Exploring the Semi-Supervised Video Object Segmentation Problem from a Cyclic Perspective", "abstract": "Modern video object segmentation (VOS) algorithms have achieved remarkably high performance in a sequential processing order, while most of currently prevailing pipelines still show some obvious inadequacy like accumulative error, unknown robustness or lack of proper interpretation tools. In this paper, we place the semi-supervised video object segmentation problem into a cyclic workflow and find the defects above can be collectively addressed via the inherent cyclic property of semi-supervised VOS systems. Firstly, a cyclic mechanism incorporated to the standard sequential flow can produce more consistent representations for pixel-wise correspondance. Relying on the accurate reference mask in the starting frame, we show that the error propagation problem can be mitigated. Next, a simple gradient correction module, which naturally extends the offline cyclic pipeline to an online manner, can highlight the high-frequent and detailed part of results to further improve the segmentation quality while keeping feasible computation cost. Meanwhile such correction can protect the network from severe performance degration resulted from interference signals. Finally we develop cycle effective receptive field (cycle-ERF) based on gradient correction process to provide a new perspective into analyzing object-specific regions of interests. We conduct comprehensive comparison and detailed analysis on challenging benchmarks of DAVIS16, DAVIS17 and Youtube-VOS, demonstrating that the cyclic mechanism is helpful to enhance segmentation quality, improve the robustness of VOS systems, and further provide qualitative comparison and interpretation on how different VOS algorithms work. The code of this project can be found at https://github.com/lyxok1/STM-Training ."}}
