{"id": "k-M1G_lllf8", "cdate": 1681837111652, "mdate": 1681837111652, "content": {"title": "STM-GAIL: Spatial-Temporal Meta-GAIL for Learning Diverse Human Driving Strategies", "abstract": "With  large  amounts  of  human-generated  spatial-temporalurban  data  (e.g.,  GPS  trajectories  of  vehicles,  passengers\u2019trip data on buses and trains,etc.), human urban strategyanalysis has become an important problem in many urbanscenarios.   This  problem  is  hard  to  solve  due  to  two  ma-jor  challenges:   (1)  data  scarcity  (i.e.,  each  human  agentcan only provide limited observations) and (2) data hetero-geneity (i.e., having mixed observations from many differenthuman  agents).   Most  of  the  existing  works  on  this  prob-lem usually require a large amount of historical observationsaiming to correctly infer a human agent\u2019s urban strategy andthus  fail  to  properly  address  both  challenges  at  the  sametime.   To  solve  the  human  urban  strategy  analysis  prob-lem in case of data scarcity and data heterogeneity, we de-sign a novel learning paradigm \u2014 Spatial-Temporal Meta-GAIL(STM-GAIL), which can successfully learn diverse hu-man urban strategies from heterogeneous human-generatedspatial-temporal  urban  data.   STM-GAIL  models  the  hu-man  decision  processes  as  variable  length  Markov  decisionprocesses (VLMDPs) and incorporates the surrounding spa-tial feature patterns (e.g., traffic volume patterns,etc.)  intostates to better capture the spatial-temporal dependencies ofhuman decisions.  Besides, STM-GAIL learns diverse humanurban  strategies  from  the  meta-learning  perspective,  andcan  distinguish  various  human  urban  strategies  by  addingan  inference  network  on  top  of  the  standard  GAIL.  STM-GAIL can be quickly adapted to a new human expert\u2019s ur-ban strategy with a single trajectory.  Extensive experimentson real-world human-generated spatial-temporal dataset areperformed."}}
{"id": "1XNYhA9WF6", "cdate": 1667401821432, "mdate": 1667401821432, "content": {"title": "Robust Object Detection With Inaccurate Bounding Boxes", "abstract": "Learning accurate object detectors often requires large-scale training data with precise object bounding boxes. However, labeling such data is expensive and time-consuming. As the crowd-sourcing labeling process and the ambiguities of the objects may raise noisy bounding box annotations, the object detectors will suffer from the degenerated training data. In this work, we aim to address the challenge of learning robust object detectors with inaccurate bounding boxes. Inspired by the fact that localization precision suffers significantly from inaccurate bounding boxes while classification accuracy is less affected, we propose leveraging classification as a guidance signal for refining localization results. Specifically, by treating an object as a bag of instances, we introduce an Object-Aware Multiple Instance Learning approach (OA-MIL), featured with object-aware instance selection and object-aware instance extension. The former aims to select accurate instances for training, instead of directly using inaccurate box annotations. The latter focuses on generating high-quality instances for selection. Extensive experiments on synthetic noisy datasets (i.e., noisy PASCAL VOC and MS-COCO) and a real noisy wheat head dataset demonstrate the effectiveness of our OA-MIL. Code is available at this https URL."}}
{"id": "sWySMANVC0", "cdate": 1667338485624, "mdate": 1667338485624, "content": {"title": "Unsupervised Deep Feature Transfer for Low Resolution Image Classification", "abstract": "In this paper, we propose a simple while effective unsupervised deep feature transfer algorithm for low resolution\nimage classification. No fine-tuning on convenet filters is\nrequired in our method. We use pre-trained convenet to\nextract features for both high- and low-resolution images,\nand then feed them into a two-layer feature transfer network\nfor knowledge transfer. A SVM classifier is learned directly\nusing these transferred low resolution features. Our network can be embedded into the state-of-the-art deep neural\nnetworks as a plug-in feature enhancement module. It preserves data structures in feature space for high resolution\nimages, and transfers the distinguishing features from a wellstructured source domain (high resolution features space) to\na not well-organized target domain (low resolution features\nspace). Extensive experiments on VOC2007 test set show\nthat the proposed method achieves significant improvements\nover the baseline of using feature extraction.\n"}}
{"id": "xmqdTJo2cW", "cdate": 1667338402088, "mdate": null, "content": {"title": "Self-Orthogonality Module: A Network Architecture Plug-in for Learning Orthogonal Filters", "abstract": "In this paper, we investigate the empirical impact of orthogonality regularization (OR) in deep learning, either solo\nor collaboratively. Recent works on OR showed some promising results on the accuracy. In our ablation study, however,\nwe do not observe such significant improvement from existing OR techniques compared with the conventional training\nbased on weight decay, dropout, and batch normalization.\nTo identify the real gain from OR, inspired by the locality\nsensitive hashing (LSH) in angle estimation, we propose to\nintroduce an implicit self-regularization into OR to push the\nmean and variance of filter angles in a network towards\n90\u25e6 and 0\u25e6 simultaneously to achieve (near) orthogonality\namong the filters, without using any other explicit regularization. Our regularization can be implemented as an architectural plug-in and integrated with an arbitrary network.\nWe reveal that OR helps stabilize the training process and\nleads to faster convergence and better generalization."}}
{"id": "WePih5bXsNB", "cdate": 1663850223735, "mdate": null, "content": {"title": "Deep Contrastive Learning Approximates Ensembles of One-Class SVMs with Neural Tangent Kernels", "abstract": "To demystify the (self-supervised) contrastive learning in representation learning, in the paper we show that a model learned by deep contrastive learning with a family of loss functions such as InfoNCE essentially approximates an ensemble of one-class support vector machines (SVMs) with neural tangent kernels (NTKs). This result comes from the fact that each gradient for network weight update in contrastive learning can be interpreted approximately as the primal solution for a one-class SVM with contrastive gradients as input. From the dual perspective, the Lagrange multipliers provide unique insights into the importance of the anchor-positive-negative triplet samples. In this way, we further propose a novel sequential convex programming (SCP) algorithm for contrastive learning, where each sub-problem is a one-class SVM. Empirically we demonstrate that our approach can learn better gradients than conventional contrastive learning approaches that significantly improve performance."}}
{"id": "HpEfFkzHUgt", "cdate": 1663849996384, "mdate": null, "content": {"title": "Auto-Encoding Adversarial Imitation Learning", "abstract": "Reinforcement learning (RL) provides a powerful framework for decision-making, but its application in practice often requires a carefully designed reward function. Adversarial Imitation Learning (AIL) sheds light on automatic policy acquisition without access to the reward signal from the environment. In this work, we propose Auto-Encoding Adversarial Imitation Learning (AEAIL), a robust and scalable AIL framework. To induce expert policies from demonstrations, AEAIL utilizes the reconstruction error of an auto-encoder as a reward signal, which provides more information for optimizing policies than the prior discriminator-based ones. Subsequently, we use the derived objective functions to train the auto-encoder and the agent policy. Experiments show that our AEAIL performs superior compared to state-of-the-art methods in the MuJoCo environments. More importantly, AEAIL shows much better robustness when the expert demonstrations are noisy. Specifically, our method achieves $11\\%$ and $50.7\\%$ relative improvement overall compared to the best baseline GAIL and PWIL on clean and noisy expert data, respectively. Video results, open-source code and dataset are available in supplementary materials. "}}
{"id": "NHHM1jjrH1", "cdate": 1632875669488, "mdate": null, "content": {"title": "An Optimization Perspective on Realizing Backdoor Injection Attacks on Deep Neural Networks in Hardware", "abstract": "State-of-the-art deep neural networks (DNNs) have been proven to be vulnerable to adversarial manipulation and backdoor attacks. Backdoored models deviate from expected behavior on inputs with predefined triggers while retaining performance on clean data. Recent works focus on software simulation of backdoor injection during the inference phase by modifying network weights, which we find often unrealistic in practice due to the hardware restriction such as bit allocation in memory. In contrast, in this work, we investigate the viability of backdoor injection attacks in real-life deployments of DNNs on hardware and address such practical issues in hardware implementation from a novel optimization perspective. \nWe are motivated by the fact that the vulnerable memory locations are very rare, device-specific, and sparsely distributed. Consequently, we propose a novel network training algorithm based on constrained optimization for realistic backdoor injection attack in hardware. By modifying parameters uniformly across the convolutional and fully-connected layers as well as optimizing the trigger pattern together, we achieve the state-of-the-art attack performance with fewer bit flips. For instance, our method on a hardware-deployed ResNet-20 model trained on CIFAR-10 can achieve over 91\\% test accuracy and 94\\% attack success rate by flipping only 10 bits out of 2.2 million bits.  "}}
{"id": "TJF4wbKTxJf", "cdate": 1632875484078, "mdate": null, "content": {"title": "Learning Lightweight Neural Networks via Channel-Split Recurrent Convolution", "abstract": "Lightweight neural networks refer to deep networks with small numbers of parameters, which are allowed to be implemented in resource-limited hardware such as embedded systems. To learn such lightweight networks effectively and efficiently, in this paper we propose a novel convolutional layer, namely {\\em Channel-Split Recurrent Convolution (CSR-Conv)}, where we split the output channels to generate data sequences with length $T$ as the input to the recurrent layers with shared weights. As a consequence, we can construct lightweight convolutional networks by simply replacing (some) linear convolutional layers with CSR-Conv layers. We prove that under mild conditions the model size decreases with the rate of $O(\\frac{1}{T^2})$. Empirically we demonstrate the state-of-the-art performance using VGG-16, ResNet-50, ResNet-56, ResNet-110, DenseNet-40, MobileNet, and EfficientNet as backbone networks on CIFAR-10 and ImageNet."}}
{"id": "_fLxZ6VpXTH", "cdate": 1632875482268, "mdate": null, "content": {"title": "Stabilized Likelihood-based Imitation Learning via Denoising Continuous Normalizing Flow", "abstract": "State-of-the-art imitation learning (IL) approaches, e.g, GAIL, apply adversarial training to minimize the discrepancy between expert and learner behaviors, which is prone to unstable training and mode collapse. In this work, we propose SLIL \u2013 Stabilized Likelihood-based Imitation Learning \u2013 a novel IL approach that directly maximizes the likelihood of observing the expert demonstrations. SLIL is a two-stage optimization framework, where in stage one the expert state distribution is estimated via a new method for denoising continuous normalizing flow, and in stage two the learner policy is trained to match both the expert\u2019s policy and state distribution. Experimental evaluation of SLIL compared with several baselines in ten different physics-based control tasks reveals superior results in terms of learner policy performance, training stability, and mode distribution preservation."}}
{"id": "OCgCYv7KGZe", "cdate": 1632875479720, "mdate": null, "content": {"title": "Auto-Encoding Inverse Reinforcement Learning", "abstract": "Reinforcement learning (RL) provides a powerful framework for decision-making, but its application in practice often requires a carefully designed reward function. Inverse Reinforcement Learning (IRL) has shed light on automatic reward acquisition, but it is still difficult to apply IRL to solve real-world tasks. In this work, we propose Auto-Encoding Inverse Reinforcement Learning (AEIRL), a robust and scalable IRL framework, which belongs to the adversarial imitation learning class. To recover reward functions from expert demonstrations, AEIRL utilizes the reconstruction error of an auto-encoder as the learning signal, which provides more information for optimizing policies, compared to the binary logistic loss. Subsequently, we use the derived objective functions to train the reward function and the RL agent. Experiments show that AEIRL performs superior in comparison with state-of-the-art methods in the MuJoCo environments. More importantly, in more realistic settings, AEIRL shows much better robustness when the expert demonstrations are noisy. Specifically, our method achieves $16\\%$ relative improvement compared to the best baseline FAIRL on clean expert data and $38\\%$ relative improvement compared to the best baseline PWIL on noisy expert data both with the metric overall averaged scaled rewards. "}}
