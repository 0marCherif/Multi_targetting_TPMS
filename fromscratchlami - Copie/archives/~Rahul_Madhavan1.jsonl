{"id": "TYrEFkFnCi", "cdate": 1676827089396, "mdate": null, "content": {"title": "Learning Good Interventions in Causal Graphs via Covering", "abstract": "We study the causal bandit problem that entails identifying a near-optimal intervention from a specified set $\\cal{A}$ of (possibly non-atomic) interventions over a given causal graph. Here, an optimal intervention in $\\cal{A}$ is one that maximizes the expected value for a designated reward variable in the graph, and we use the standard notion of simple regret to quantify near optimality. \nConsidering Bernoulli random variables and for causal graphs on $N$ vertices with constant in-degree, prior work has achieved a worst case guarantee of $\\widetilde{O} (N/\\sqrt{T})$ for simple regret. The current work utilizes the idea of covering interventions (which are not necessarily contained within $\\cal{A}$) and establishes a simple regret guarantee of $\\widetilde{O}(\\sqrt{N/T})$. Notably, and in contrast to prior work, our simple regret bound depends only on explicit parameters of the problem instance. We also go beyond prior work and achieve a simple regret guarantee for causal graphs with unobserved variables. Further, we perform experiments to show improvements over baselines in this setting."}}
{"id": "RIF1PsZ2T7", "cdate": 1609459200000, "mdate": 1682334366930, "content": {"title": "Scale Invariant Solutions for Overdetermined Linear Systems with Applications to Reinforcement Learning", "abstract": "We study the feature-scaled version of the Monte Carlo algorithm with linear function approximation. This algorithm converges to a scale-invariant solution, which is not unduly affected by states having feature vectors with large norms. The usual versions of the MCMC algorithm, obtained by minimizing the least-squares criterion, do not produce solutions that give equal importance to all states irrespective of feature-vector norm -- a requirement that may be critical in many reinforcement learning contexts. To speed up convergence in our algorithm, we introduce an adaptive step-size based on the curvature of the iterate convergence path -- a novelty that may be useful in more general optimization contexts as well. A key contribution of this paper is to prove convergence, in the presence of adaptive curvature based step-size and heavy-ball momentum. We provide rigorous theoretical guarantees and use simulations to demonstrate the efficacy of our ideas."}}
{"id": "NYujNvMqoL7", "cdate": 1609459200000, "mdate": 1681222384592, "content": {"title": "Intervention Efficient Algorithm for Two-Stage Causal MDPs", "abstract": ""}}
