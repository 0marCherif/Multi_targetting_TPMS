{"id": "xsz_FlOBmu", "cdate": 1672531200000, "mdate": 1690902799488, "content": {"title": "(Local) Differential Privacy has NO Disparate Impact on Fairness", "abstract": "In recent years, Local Differential Privacy (LDP), a robust privacy-preserving methodology, has gained widespread adoption in real-world applications. With LDP, users can perturb their data on their devices before sending it out for analysis. However, as the collection of multiple sensitive information becomes more prevalent across various industries, collecting a single sensitive attribute under LDP may not be sufficient. Correlated attributes in the data may still lead to inferences about the sensitive attribute. This paper empirically studies the impact of collecting multiple sensitive attributes under LDP on fairness. We propose a novel privacy budget allocation scheme that considers the varying domain size of sensitive attributes. This generally led to a better privacy-utility-fairness trade-off in our experiments than the state-of-art solution. Our results show that LDP leads to slightly improved fairness in learning problems without significantly affecting the performance of the models. We conduct extensive experiments evaluating three benchmark datasets using several group fairness metrics and seven state-of-the-art LDP protocols. Overall, this study challenges the common belief that differential privacy necessarily leads to worsened fairness in machine learning."}}
{"id": "qq-QFqs_kd", "cdate": 1672531200000, "mdate": 1682511694195, "content": {"title": "Frequency Estimation of Evolving Data Under Local Differential Privacy", "abstract": ""}}
{"id": "HlynClwZPrE", "cdate": 1672531200000, "mdate": 1682511694196, "content": {"title": "On the Risks of Collecting Multidimensional Data Under Local Differential Privacy", "abstract": ""}}
{"id": "CK6BtxbGgy", "cdate": 1672531200000, "mdate": 1690902799496, "content": {"title": "On the Utility Gain of Iterative Bayesian Update for Locally Differentially Private Mechanisms", "abstract": "This paper investigates the utility gain of using Iterative Bayesian Update (IBU) for private discrete distribution estimation using data obfuscated with Locally Differentially Private (LDP) mechanisms. We compare the performance of IBU to Matrix Inversion (MI), a standard estimation technique, for seven LDP mechanisms designed for one-time data collection and for other seven LDP mechanisms designed for multiple data collections (e.g., RAPPOR). To broaden the scope of our study, we also varied the utility metric, the number of users n, the domain size k, and the privacy parameter $$\\epsilon $$ , using both synthetic and real-world data. Our results suggest that IBU can be a useful post-processing tool for improving the utility of LDP mechanisms in different scenarios without any additional privacy cost. For instance, our experiments show that IBU can provide better utility than MI, especially in high privacy regimes (i.e., when $$\\epsilon $$ is small). Our paper provides insights for practitioners to use IBU in conjunction with existing LDP mechanisms for more accurate and privacy-preserving data analysis. Finally, we implemented IBU for all fourteen LDP mechanisms into the state-of-the-art multi-freq-ldpy Python package ( https://pypi.org/project/multi-freq-ldpy/ ) and open-sourced all our code used for the experiments as tutorials."}}
{"id": "iYsEoNcBjr9", "cdate": 1640995200000, "mdate": 1679127774138, "content": {"title": "Multi-Freq-LDPy: Multiple Frequency Estimation Under Local Differential Privacy in Python", "abstract": ""}}
{"id": "ZFT_n963GN6", "cdate": 1640995200000, "mdate": 1679127774091, "content": {"title": "Differentially private multivariate time series forecasting of aggregated human mobility with deep learning: Input or gradient perturbation?", "abstract": ""}}
{"id": "WF9d80884hH", "cdate": 1640995200000, "mdate": 1679127774103, "content": {"title": "Frequency Estimation of Evolving Data Under Local Differential Privacy", "abstract": ""}}
{"id": "78Io-MnPFY", "cdate": 1640995200000, "mdate": 1679127774113, "content": {"title": "Privacy-Preserving Prediction of Victim's Mortality and Their Need for Transportation to Health Facilities", "abstract": ""}}
{"id": "3sZoQij9Zc", "cdate": 1640995200000, "mdate": 1679127774100, "content": {"title": "Production of Categorical Data Verifying Differential Privacy: Conception and Applications to Machine Learning", "abstract": ""}}
{"id": "0NOt03ASlhj", "cdate": 1640995200000, "mdate": 1679127774118, "content": {"title": "Production of categorical data verifying differential privacy: conception and applications to machine learning. (Production de donn\u00e9es cat\u00e9gorielles respectant la confidentialit\u00e9 diff\u00e9rentielle: conception et applications au apprentissage automatique)", "abstract": ""}}
