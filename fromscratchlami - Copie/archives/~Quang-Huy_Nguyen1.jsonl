{"id": "O15TzpZLA7", "cdate": 1672531200000, "mdate": 1698376078046, "content": {"title": "Enhancing Few-Shot Image Classification With Cosine Transformer", "abstract": "This paper addresses the few-shot image classification problem, where the classification task is performed on unlabeled query samples given a small amount of labeled support samples only. One major challenge of the few-shot learning problem is the large variety of object visual appearances that prevents the support samples to represent that object comprehensively. This might result in a significant difference between support and query samples, therefore undermining the performance of few-shot algorithms. In this paper, we tackle the problem by proposing Few-shot Cosine Transformer (FS-CT), where the relational map between supports and queries is effectively obtained for the few-shot tasks. The FS-CT consists of two parts, a learnable prototypical embedding network to obtain categorical representations from support samples with hard cases, and a transformer encoder to effectively achieve the relational map from two different support and query samples. We introduce Cosine Attention, a more robust and stable attention module that enhances the transformer module significantly and therefore improves FS-CT performance from 5% to over 20% in accuracy compared to the default scaled dot-product mechanism. Our method performs competitive results in mini -ImageNet, CUB-200, and CIFAR-FS on 1-shot learning and 5-shot learning tasks across backbones and few-shot configurations. We also developed a custom few-shot dataset for Yoga pose recognition to demonstrate the potential of our algorithm for practical application. Our FS-CT with cosine attention is a lightweight, simple few-shot algorithm that can be applied for a wide range of applications, such as healthcare, medical, and security surveillance. The official implementation code of our Few-shot Cosine Transformer is available at <uri xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">https://github.com/vinuni-vishc/Few-Shot-Cosine-Transformer</uri> ."}}
{"id": "atSY6iIFEz", "cdate": 1577836800000, "mdate": 1698376078050, "content": {"title": "Additional Learning on Object Detection: A Novel Approach in Pornography Classification", "abstract": "In this paper, we proposed a new approach for pornographic classification by recognizing sensitive objects on images. To handle the misdetection and wrong judgment, a novel training strategy named additional learning was developed to help object detection model learns from mistakes, therefore increasing the method performance. Furthermore, a separate SVM classifier was trained to classify pornography and benign images from sexual object detected using Mask R-CNN model. Benchmarked by the NPDI-800 dataset, our proposed method achieved an accuracy of 84.625% and 90.125%, before and after applying additional learning strategy respectively. Besides, our proposed model also improves the false positive rate from 22.16% to 3.56% in our manually collected dataset."}}
{"id": "51kL2waX4G", "cdate": 1577836800000, "mdate": 1698376078050, "content": {"title": "Multi-level detector for pornographic content using CNN models", "abstract": "This paper focuses on detecting and classifying pornographic content (images and videos) by using a multi-level CNN model with some supportive models. The main approaching method is to determine the images (keyframes extracted from videos) containing sensitives content or not by applying object detection model Mask R-CNN, which is the completely new approaching method in pornographic recognition. Moreover, the proposed model also adapts some other methods such as feature extraction and classifying based on CNN to increase the accuracy of the adaptive methods and ignore non-pornographic images and videos. Experimental results using the Pornography-800 and Pornography-2K datasets, performance of our method is reaching the accuracy of 92.13% and 90.40% respectively, show the effectiveness of the proposed method."}}
