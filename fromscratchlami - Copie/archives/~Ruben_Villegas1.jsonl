{"id": "mj5eFSP0MMp", "cdate": 1668684316553, "mdate": 1668684316553, "content": {"title": "Single-image Full-body Human Relighting", "abstract": "We present a single-image data-driven method to automatically relight images with full-body humans in them. Our framework is based on a realistic scene decomposition leveraging precomputed radiance transfer (PRT) and spherical harmonics (SH) lighting. In contrast to previous work, we lift the assumptions on Lambertian materials and explicitly model diffuse and specular reflectance in our data. Moreover, we introduce an additional light-dependent residual term that accounts for errors in the PRT-based image reconstruction. We propose a new deep learning architecture, tailored to the decomposition performed in PRT, that is trained using a combination of L1, logarithmic, and rendering losses. Our model outperforms the state of the art for full-body human relighting both with synthetic images and photographs."}}
{"id": "icRyOwP1zXS", "cdate": 1664144742519, "mdate": 1664144742519, "content": {"title": "Contact and Human Dynamics from Monocular Video", "abstract": "Existing deep models predict 2D and 3D kinematic poses from video that are approximately accurate, but contain visible errors that violate physical constraints, such as feet penetrating the ground and bodies leaning at extreme angles. In this paper, we present a physics-based method for inferring 3D human motion from video sequences that takes initial 2D and 3D pose estimates as input. We first estimate ground contact timings with a novel prediction network which is trained without hand-labeled data. A physics-based trajectory optimization then solves for a physically-plausible motion, based on the inputs. We show this process produces motions that are significantly more realistic than those from purely kinematic methods, substantially improving quantitative measures of both kinematic and dynamic plausibility. We demonstrate our method on character animation and pose estimation tasks on dynamic motions of dancing and sports with complex contact patterns.\n\n"}}
{"id": "vOEXS39nOF", "cdate": 1663850374506, "mdate": null, "content": {"title": "Phenaki: Variable Length Video Generation from Open Domain Textual Descriptions", "abstract": "We present Phenaki, a model capable of realistic video synthesis given a sequence of textual prompts. Generating videos from text is particularly challenging due to the computational cost, limited quantities of high quality text-video data and variable length of videos. To address these issues, we introduce a new causal model for learning video representation which compresses the video to a small discrete tokens representation. This tokenizer is auto-regressive in time, which allows it to work with video representations of different length. \nTo generate video tokens from text we are using a bidirectional masked transformer conditioned on pre-computed text tokens. The generated video tokens are subsequently de-tokenized to create the actual video. To address data issues, we demonstrate how joint training on a large corpus of image-text pairs as well as a smaller number of video-text examples can result in generalization beyond what is available in the video datasets. Compared to the previous video generation methods, Phenaki can generate arbitrary long videos conditioned on a sequence of prompts (i.e. time variable text or story) in open domain. To the best of our knowledge, this is the first time a paper studies generating videos from time variable prompts."}}
{"id": "r1gt7Vrg8r", "cdate": 1567802401179, "mdate": null, "content": {"title": "High Fidelity Video Prediction with Large Stochastic Recurrent Neural Networks", "abstract": "Predicting future video frames is extremely challenging, as there are many factors of variation that make up the dynamics of how frames change through time. Previously proposed solutions require complex network architectures and highly specialized computation, including segmentation masks, optical flow, and foreground and background separation. In this work, we question if such handcrafted architectures are necessary and instead propose a different approach: maximizing the capacity of a neural network without such specialized layers. We perform the first large-scale empirical study of the effect of capacity on video prediction models. We also investigate the importance of recurrent connections and modeling stochasticity. We experimentally demonstrate our results on three different datasets: one for modeling object interactions, one for modeling human motion, and one for modeling car driving."}}
{"id": "rk4rAcb_WB", "cdate": 1546300800000, "mdate": null, "content": {"title": "Learning Latent Dynamics for Planning from Pixels", "abstract": "Planning has been very successful for control tasks with known environment dynamics. To leverage planning in unknown environments, the agent needs to learn the dynamics from interactions with the w..."}}
{"id": "S1VEkqbdZS", "cdate": 1514764800000, "mdate": null, "content": {"title": "MT-VAE: Learning Motion Transformations to Generate Multimodal Human Dynamics", "abstract": "Long-term human motion can be represented as a series of motion modes\u2014motion sequences that capture short-term temporal dynamics\u2014with transitions between them. We leverage this structure and present a novel Motion Transformation Variational Auto-Encoders (MT-VAE) for learning motion sequence generation. Our model jointly learns a feature embedding for motion modes (that the motion sequence can be reconstructed from) and a feature transformation that represents the transition of one motion mode to the next motion mode. Our model is able to generate multiple diverse and plausible motion sequences in the future from the same input. We apply our approach to both facial and full body motion, and demonstrate applications like analogy-based motion transfer and video synthesis."}}
{"id": "H1Z7RyGd-S", "cdate": 1514764800000, "mdate": null, "content": {"title": "Neural Kinematic Networks for Unsupervised Motion Retargetting", "abstract": "We propose a recurrent neural network architecture with a Forward Kinematics layer and cycle consistency based adversarial training objective for unsupervised motion retargetting. Our network captures the high-level properties of an input motion by the forward kinematics layer, and adapts them to a target character with different skeleton bone lengths (e.g., shorter, longer arms etc.). Collecting paired motion training sequences from different characters is expensive. Instead, our network utilizes cycle consistency to learn to solve the Inverse Kinematics problem in an unsupervised manner. Our method works online, i.e., it adapts the motion sequence on-the-fly as new frames are received. In our experiments, we use the Mixamo animation data to test our method for a variety of motions and characters and achieve state-of-the-art results. We also demonstrate motion retargetting from monocular human videos to 3D characters using an off-the-shelf 3D pose estimator."}}
{"id": "ByEa39-_ZH", "cdate": 1514764800000, "mdate": null, "content": {"title": "Hierarchical Long-term Video Prediction without Supervision", "abstract": "Much of recent research has been devoted to video prediction and generation, yet most of the previous works have demonstrated only limited success in generating videos on short-term horizons. The h..."}}
{"id": "Sk-ppq-_bB", "cdate": 1483228800000, "mdate": null, "content": {"title": "Learning to Generate Long-term Future via Hierarchical Prediction", "abstract": "We propose a hierarchical approach for making long-term predictions of future frames. To avoid inherent compounding errors in recursive pixel-level prediction, we propose to first estimate high-lev..."}}
{"id": "B1bb7aZuZH", "cdate": 1420070400000, "mdate": null, "content": {"title": "Improving object detection with deep convolutional networks via Bayesian optimization and structured prediction", "abstract": "Object detection systems based on the deep convolutional neural network (CNN) have recently made ground-breaking advances on several object detection benchmarks. While the features learned by these high-capacity neural networks are discriminative for categorization, inaccurate localization is still a major source of error for detection. Building upon high-capacity CNN architectures, we address the localization problem by 1) using a search algorithm based on Bayesian optimization that sequentially proposes candidate regions for an object bounding box, and 2) training the CNN with a structured loss that explicitly penalizes the localization inaccuracy. In experiments, we demonstrate that each of the proposed methods improves the detection performance over the baseline method on PASCAL VOC 2007 and 2012 datasets. Furthermore, two methods are complementary and significantly outperform the previous state-of-the-art when combined."}}
