{"id": "DO_p75AE4rv", "cdate": 1546300800000, "mdate": null, "content": {"title": "Predicting Emerging and Frontier Stock Markets Using Deep Neural Networks", "abstract": "Investors, researchers and finance practitioners are continuously looking for the best technique that can assist them in accurately predicting the stock markets. The ability to predict stock prices contradicts the efficient market hypothesis (EMH) and can yield substantial monetary rewards for investors. Various stock price prediction techniques are used to predict the stock market and they range from statistical to machine learning methods. Statistical models fall short in handling nonlinear data which characterizes most stock markets. Artificial Neural Networks (ANNs), one of the widely used techniques are able to handle nonlinear data but have low prediction accuracy due to their inability to handle long term dependencies and memory capacity handling. Prediction models that have an ability to learn long-term dependency information are ideal for stock market prediction. The current study uses deep learning techniques, namely, Long Short Term Memory (LSTM), Recurrent Neural Networks (RNNs), Gated Recurrent Units (GRUs), Bidirectional LSTM (BLSTM), Bidirectional RNN (BRNN), Bidirectional GRU (BGRU) to predict stock markets in ten sub-Saharan African countries. The prediction techniques were run on a python 3.5 environment using Theano and Keras libraries. Limited computing capacity was of great concern. However, for the purpose of this study, access to high performance computing facilities was granted in order to run the experiments. Experimental results show that both unidirectional and bidirectional architectures greatly improved prediction accuracy in this research. However, both architectures were found not to be significantly different in predicting the stock markets of the ten African countries. In general, LSTMs followed by BGRUs proved to be the best models in predicting the African stock markets."}}
{"id": "D5M_8wa7Oncn", "cdate": 1546300800000, "mdate": null, "content": {"title": "Detecting Learning Affect in E-Learning Platform Using Facial Emotion Expression", "abstract": "Recent trends in education have shifted from traditional classroom learning to an online learning setting; however, research has indicated a high drop out rate among e-learners. Boredom, lack of motivation are among the factors that led to this decline. This study develops a platform that provides feedback to learners in real-time while engaging in an online learning video. The platform detects, predicts and analyses the facial emotions of a learner using Convolutional Neural Network (CNN), and further maps the emotion to a learning affect. The feedback generated provides a reasonable understanding of the comprehension level of the learner."}}
{"id": "tAjSbWyoZzM", "cdate": 1483228800000, "mdate": null, "content": {"title": "Better feature acquisition through the use of infrared imaging for human detection systems", "abstract": "Human detection on static images remains a challenging research problem. This work evaluates the significance of using infrared imaging (IIR) over several human detection systems. Larger complexities arise when detecting people in colour images due to the possibility of random colour patterns on the image backgrounds and clothes of pedestrians. In most cases, the colour clutter contributes negatively to image representation methods that solely rely on edge information. The basis of our supposition is that the choice of information has a large impact on the robustness of statistical learning systems. To test this supposition, we created and published a new infrared-based pedestrian dataset called \"SIGNI\" [9]. Several datasets of the same size were prepared and tested on three different classifiers. The classifiers are first trained with popular colour datasets to determine the optimal parameters that obtain high classification rates on unseen samples. Once satisfactory results are obtained, the same parameters are used for training the classifiers with infrared samples. The conventional use of support vector machines (SVM) on HOG features is tested against extreme learning machines (ELM) and convolutional neural networks (CNN). The results obtained show that the reduction of noise clutter improves the quality of acquired HOG features. As slight performance gains were observed during the classification of infrared samples over the use of visual samples."}}
{"id": "4AoWeOZrg0n", "cdate": 1483228800000, "mdate": null, "content": {"title": "Deformable part models with CNN features for facial landmark detection under occlusion", "abstract": "Detecting and localizing facial regions in images is a fundamental building block of many applications in the field of affective computing and human-computer interaction. This allows systems to do a variety of higher level analysis such as facial expression recognition. Facial expression recognition is based on the effective extraction of relevant facial features. Many techniques have been proposed to deal with the robust extraction of these features under a wide variety of poses and occlusion conditions. These techniques include Deformable Part Models (DPM's), and more recently deep Convolutional neural networks (CNN's). Recently, hybrid models based on DPMs and CNNs have been proposed considering the generalization properties of CNNs and DPMs. In this work we propose a combined system, using CNN's as features for a DPM with a focus on dealing with occlusion. We also propose a method of face detection allowing occluded regions to be detected and explicitly ignored during the detection step. The resulting system is quite robust to a wide variety of occlusions achieving accuracies comparable to that of other state of the art systems."}}
{"id": "LvMtx0pQzvZ", "cdate": 1451606400000, "mdate": null, "content": {"title": "Indoor Sign Recognition for the Blind", "abstract": "Blind people face difficulties when navigating unfamiliar environments. The information displayed on indoor signs and notice boards is of no use to them. In order to assist them with this challenge, we propose a real time system that can recognise a selection of indoor navigational signs placed over clear backgrounds. The selection of signs will consist of common samples from several different types of indoor signs. Given a captured image, the approach is to use image processing techniques to find the region of interest(ROI) that contains the sign and then extract this region for classification. Using sliding windows for searching the ROI can be time consuming and can lead to many false classifications, hence we used a more explicit approach that is faster and more reliable. We first segment the signs by colour, and then by shape recognition. The sign-type classification is done using a tree search structure that enables the use of iterative contour descriptors like the speeded-up-robust-features(SURF). Once a sign has been detected, this information is communicated to the user via stereo headsets. To evaluate the system's performance, several random pictures with and without signs were used to determine the system's detection rate. The user-feedback performance was evaluated by testing the system's usability score with volunteers."}}
{"id": "0YlSyMfD-HH", "cdate": 1388534400000, "mdate": null, "content": {"title": "Facial action unit intensity estimation using rotation invariant features and regression analysis", "abstract": "There has been quite a lot of research done in the field of Facial Expression Recognition, yet there has not been so much development in Facial Action Coding System Action Unit intensity detection. In Automated Facial Expression Recognition, intensity recognition of the Facial Action Coding System Action Units is a crucial part for it would give much broad information about the facial expression of an individual. In this research, a computationally efficient yet effective logistic regression based method that operates on a novel feature vector extracted from geometric relations between facial feature points is presented. Said method uses angles between facial feature points which are rotation invariant. The method was trained and tested on DISFA database and gave state of the art results."}}
{"id": "_L4kADw8OJ_", "cdate": 1230768000000, "mdate": null, "content": {"title": "Facial Action Unit Recognition Using Recurrent Neural Networks", "abstract": ""}}
