{"id": "0nneuL3bSLt", "cdate": 1675785563814, "mdate": null, "content": {"title": "MphayaNER: Named Entity Recognition for Tshivenda", "abstract": "Named Entity Recognition (NER) plays a vital role in various Natural Language Processing tasks such as information retrieval, text classification, and question answering. However, NER can be challenging, especially in low-resource languages with limited annotated datasets and tools. This paper adds to the effort of addressing these challenges by introducing MphayaNER, the first Tshivenda NER  corpus in the news domain. We establish NER baselines by fine-tuning state-of-the-art models on MphayaNER. The study also explores zero-shot transfer between Tshivenda and other related Bantu languages, with Setswana, chiShona and Kiswahili showing the best results. Augmenting MphayaNER with Setwana data was also found to improve model performance significantly. Both MphayaNER and the baseline models are made publicly available."}}
{"id": "5ybmJiXmIC", "cdate": 1675785563741, "mdate": null, "content": {"title": "FINE-TUNING MULTILINGUAL PRETRAINED AFRICAN LANGUAGE MODELS", "abstract": "With the recent increase in low-resource African language text corpora , there have been advancements which have led to development of multilingual pre-trained language models (PLMs), based on African languages. These PLMS include AfriBerta \\citep{ogueji2021-afriberta}, Afro-XLMR \\citep{alabi-etal-2022-adapting-afro-xlmr} and AfroLM \\citep{afrolm} ,  which perform significantly well. The downstream tasks of these models range from text classification , name-entity-recognition and sentiment analysis. By exploring the idea of fine-tuning the different PLMs, these models can be trained on different African language datasets. This could lead to multilingual models that can perform well on the new data for the  required downstream task of classification. This leads to the question we are attempting to answer: Can these PLMs be fine-tuned to perform similarly well on different African language data?"}}
{"id": "jIsCQEpo1O", "cdate": 1609459200000, "mdate": null, "content": {"title": "Practical Approach on Implementation of WordNets for South African Languages", "abstract": "This paper proposes the implementation of WordNets for five South African languages, namely, Sepedi, Setswana, Tshivenda, isiZulu and isiXhosa to be added to open multilingual WordNets (OMW) on natural language toolkit (NLTK). The African WordNets are converted from Princeton WordNet (PWN) 2.0 to 3.0 to match the synsets in PWN 3.0. After conversion, there were 7157, 11972, 1288, 6380, and 9460 lemmas for Sepedi, Setswana, Tshivenda, isiZulu and isiX- hosa respectively. Setswana, isiXhosa, Sepedi contains more lemmas compared to 8 languages in OMW and isiZulu contains more lemmas compared to 7 languages in OMW. A library has been published for continuous development of African WordNets in OMW using NLTK."}}
{"id": "7crFSfnwvb", "cdate": 1609459200000, "mdate": null, "content": {"title": "Digital forensics supported by machine learning for the detection of online sexual predatory chats", "abstract": "Highlights \u2022 Digital forensic investigation. \u2022 Cybersecurity. \u2022 Machine Learning. \u2022 Cyber safety. \u2022 Online sexual predatory conversation Identification. Abstract Chat-logs are informative digital footprints available on Social Media Platforms (SMPs). With the rise of cybercrimes targeting children, chat-logs can be used to discover and flag harmful behaviour for the attention of law enforcement units. This can make an important contribution to the safety of minors on SMPs from being exploited by online predators. The problem is that digital forensic investigation is mostly manual. Thus, a daunting task for forensic investigators because of the sheer volume and variety of data. The solution that is proposed in this paper employs a Digital Forensic Process Model that is supported by Machine Learning (ML) methods to facilitate the automatic discovery of harmful conversations in chat-logs. ML has already been successfully applied in the domain of text analysis for the discovery of online sexual predatory chats. However, there is an absence of approaches that show how ML can contribute to a digital forensic investigation. Thus, the contribution of this paper is to indicate how the tasks in a digital forensic investigation process can be organised so to obtain useable ML results when investigating online predators."}}
{"id": "5Dvu9sij2dD", "cdate": 1609459200000, "mdate": null, "content": {"title": "Transformer-based Machine Translation for Low-resourced Languages embedded with Language Identification", "abstract": "Recent research on the development of machine translation (MT) models has resulted in state-of-the-art performance for many resourced European languages. However, there has been a little focus on applying these MT services to low-resourced languages. This paper presents the development of neural machine translation (NMT) for low-resourced languages of South Africa. Two MT models, JoeyNMT and transformer NMT with self-attention are trained and evaluated using BLEU score. The transformer NMT with self-attention obtained state-of-the-art performance on isiNdebele, SiSwati, Setswana, Tshivenda, isiXhosa, and Sepedi while JoeyNMT performed well on isiZulu. The MT models are embedded with language identification (LID) model that presets the language for translation models. The LID models are trained using logistic regression and multinomial naive Bayes (MNB). MNB classifier obtained an accuracy of 99% outperforming logistic regression which obtained the lowest accuracy of 97%."}}
{"id": "4CDR4H03zSQ", "cdate": 1609459200000, "mdate": null, "content": {"title": "AI4D - African Language Program", "abstract": "Advances in speech and language technologies enable tools such as voice-search, text-to-speech, speech recognition and machine translation. These are however only available for high resource languages like English, French or Chinese. Without foundational digital resources for African languages, which are considered low-resource in the digital context, these advanced tools remain out of reach. This work details the AI4D - African Language Program, a 3-part project that 1) incentivised the crowd-sourcing, collection and curation of language datasets through an online quantitative and qualitative challenge, 2) supported research fellows for a period of 3-4 months to create datasets annotated for NLP tasks, and 3) hosted competitive Machine Learning challenges on the basis of these datasets. Key outcomes of the work so far include 1) the creation of 9+ open source, African language datasets annotated for a variety of ML tasks, and 2) the creation of baseline models for these datasets through hosting of competitive ML challenges."}}
{"id": "zel0vfR-qeW", "cdate": 1577836800000, "mdate": null, "content": {"title": "AI4D - African Language Dataset Challenge", "abstract": "As language and speech technologies become more advanced, the lack of fundamental digital resources for African languages, such as data, spell checkers and Part of Speech taggers, means that the digital divide between these languages and others keeps growing. This work details the organisation of the AI4D - African Language Dataset Challenge, an effort to incentivize the creation, organization and discovery of African language datasets through a competitive challenge. We particularly encouraged the submission of annotated datasets which can be used for training task-specific supervised machine learning models."}}
{"id": "wNe3PeOzFMr", "cdate": 1577836800000, "mdate": null, "content": {"title": "1st AfricaNLP Workshop Proceedings, 2020", "abstract": "Proceedings of the 1st AfricaNLP Workshop held on 26th April alongside ICLR 2020, Virtual Conference, Formerly Addis Ababa Ethiopia."}}
{"id": "sh9FNDWD1S2", "cdate": 1577836800000, "mdate": null, "content": {"title": "Mapping the South African health landscape in response to COVID-19", "abstract": "When the COVID-19 disease pandemic infiltrated the world, there was an immediate need for accurate information. As with any outbreak, the outbreak follows a clear trajectory, and subsequently, the supporting information for that outbreak needs to address the needs associated with that stage of the outbreak. At first, there was a need to inform the public of the information related to the initial situation related to the \"who\" of the COVID-19 disease. However, as time continued, the \"where\", \"when\" and \"how to\" related questions started to emerge in relation to the public healthcare system themselves. Questions surrounding the health facilities including COVID-19 hospital bed capacity, locations of designated COVID-19 facilities, and general information related to these facilities were not easily accessible to the general public. Furthermore, the available information was found to be outdated, fragmented across several platforms, and still had gaps in the data related to these facilities. To rectify this problem, a group of volunteers working on the covid19za project stepped in to assist. Each member leading a part of the project chose to focus on one of four problems related to the challenges associated with the Hospital information including: data quality, data completeness, data source validation and data visualisation capacity. As the project developed, so did the sophistication of the data, visualisation and core function of the project. The future prospects of this project relate to a Progressive Web Application that will avail this information for the public as well as healthcare workers through comprehensive mapping and data quality."}}
{"id": "pX-CwPY28uz", "cdate": 1577836800000, "mdate": null, "content": {"title": "Extracting and categorising the reactions to COVID-19 by the South African public - A social media study", "abstract": "Social Media can be used to extract discussion topics during a disaster. With the COVID-19 pandemic impact on South Africa, we need to understand how the law and regulation promulgated by the government in response to the pandemic contrasts with discussion topics social media users have been engaging in. In this work, we expand on traditional media analysis by using Social Media discussions driven by or directed to South African government officials. We find topics that are similar as well as different in some cases. The findings can inform further study into social media during disaster settings in South Africa and beyond. This paper sets a framework for future analysis in understanding the opinions of the public during a pandemic and how these opinions can be distilled [in a semi-automated approach] to inform government communication in the future."}}
