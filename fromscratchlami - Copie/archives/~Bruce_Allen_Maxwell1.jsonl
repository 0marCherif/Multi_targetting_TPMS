{"id": "W7aZ460aF", "cdate": 1580416843139, "mdate": null, "content": {"title": "Real-time Physics-based Removal of Shadows and Shading from Road Surfaces", "abstract": "We present a real-time physics-based system for gener- ating an illumination free representation of road surfaces that maintains the distinction between asphalt and painted road markings. Cast shadows on road surfaces can cre- ate false features and modify the color of road markings, potentially masking important information for vehicle vi- sion systems. We demonstrate a novel method for identi- fying the relative spectral properties of the direct and am- bient illumination conditions and for using that to create an illumination-free 2D chromaticity space in log RGB. We then show how that representation can be used to gener- ate an illumination-free greyscale representation that dis- tinguishes road, white paint, and yellow paint, making it suitable for further analysis and classification. The entire process runs faster than 30Hz on 1 mega-pixel images using current automotive-grade embedded processing systems.\nWe evaluate the system on a paint detection task, com- paring two types of learned classifiers, random forests and convolutional neural networks. For each type, one classifier is trained on the original images, and the other is trained on the illumination-free greyscale output. The classifiers are of identical complexity and trained on the same size data set. For both types, the classifier trained on the illumination- free outputs performs better, even on images with no cast shadows. The gap in performance is indicative of the cost of forcing a classifier to learn a task in the presence of the confounding illumination signal."}}
{"id": "whyvxIx7D_y", "cdate": 1546300800000, "mdate": 1667347363812, "content": {"title": "Real-Time Physics-Based Removal of Shadows and Shading From Road Surfaces", "abstract": "We present a real-time physics-based system for generating an illumination free representation of road surfaces that maintains the distinction between asphalt and painted road markings. Cast shadows on road surfaces can create false features and modify the color of road markings, potentially masking important information for vehicle vision systems. We demonstrate a novel method for identifying the relative spectral properties of the direct and ambient illumination conditions and for using that to create an illumination-free 2D chromaticity space in log RGB. We then show how that representation can be used to generate an illumination-free greyscale representation that distinguishes road, white paint, and yellow paint, making it suitable for further analysis and classification. The entire process runs faster than 30Hz on current automotive-grade embedded processing systems. We evaluate the system on a paint detection task, comparing two types of learned classifiers, random forests and convolutional neural networks. For each type, one classifier is trained on the original images, and the other is trained on the illumination-free greyscale output. The classifiers are of identical complexity and trained on the same size data set. For both types, the classifier trained on the illumination-free outputs performs better, even on images with no cast shadows. The gap in performance is indicative of the cost of forcing a classifier to learn a task in the presence of the confounding illumination signal."}}
{"id": "Bo8E8Afl_6H", "cdate": 1546300800000, "mdate": null, "content": {"title": "Real-Time Physics-Based Removal of Shadows and Shading From Road Surfaces.", "abstract": "We present a real-time physics-based system for generating an illumination free representation of road surfaces that maintains the distinction between asphalt and painted road markings. Cast shadows on road surfaces can create false features and modify the color of road markings, potentially masking important information for vehicle vision systems. We demonstrate a novel method for identifying the relative spectral properties of the direct and ambient illumination conditions and for using that to create an illumination-free 2D chromaticity space in log RGB. We then show how that representation can be used to generate an illumination-free greyscale representation that distinguishes road, white paint, and yellow paint, making it suitable for further analysis and classification. The entire process runs faster than 30Hz on current automotive-grade embedded processing systems. We evaluate the system on a paint detection task, comparing two types of learned classifiers, random forests and convolutional neural networks. For each type, one classifier is trained on the original images, and the other is trained on the illumination-free greyscale output. The classifiers are of identical complexity and trained on the same size data set. For both types, the classifier trained on the illumination-free outputs performs better, even on images with no cast shadows. The gap in performance is indicative of the cost of forcing a classifier to learn a task in the presence of the confounding illumination signal."}}
{"id": "zD-jy3T8_A", "cdate": 1514764800000, "mdate": 1667418074704, "content": {"title": "Writing in CS: Why and How?", "abstract": "The importance of written communication and critical thinking in Computer Science is widely acknowledged. It was called out specifically in the curriculum guidelines ACM CS2013 [6] and has been the topic of a number of previous SIGCSE papers, for example [1-4]. Moreover, writing as a pedagogical practice can help make CS more accessible for a broader population. However, special challenges may arise for students who are English-language learners or have writing-specific learning differences."}}
{"id": "zVrZRrYg9C", "cdate": 1483228800000, "mdate": 1667347363941, "content": {"title": "Comparing Outcomes Across Different Contexts in CS1", "abstract": "Context-based CS1 courses focusing on Media Computation, Robotics, Games, or Art have been shown to improve outcomes such as retention and gender balance, both important factors in CS education. Colby College has offered a Visual Media focused CS1 course since 2008, and in response to faculty and student feedback, we expanded our curriculum to include a second context-based CS1 course focused on Science applications. Our goal was to have completely different projects but teach the same fundamental concepts. In order to measure whether students in each version were learning the same concepts, and to reduce confounding factors, the same professors co-taught both versions of CS1 and students completed the same homework, quizzes, and final exam. Our analysis of the quiz, final exam, and final overall performance showed no statistically significant difference by context or by gender. There was also no difference by context or gender in whether students took additional CS courses in the following two semesters. Furthermore, as a percentage of the students eligible to take the next offering of CS2, Data Structures and Algorithms, 48% of the students in these two offerings of CS1 registered for CS2, with no significant difference between contexts. Our conclusion is that we were successful in achieving similar outcomes, and the benefits of context-based CS1 courses, in both the Visual Media and Science versions of the course."}}
{"id": "B1YQrYZi9lc", "cdate": 1293840000000, "mdate": 1667347363821, "content": {"title": "Context-aware video compression for mobile robots", "abstract": "Operating robots across networks with unknown, bandwidth, latency and other conditions presents difficulty when the operation depends on real-time feedback and control. Standard video compression methods do a good job compressing arbitrary video, but do not take domain knowledge into account when more information about the video is known beforehand. We have incorporated robot odometry into the video pipeline, allowing video quality to be selectively reduced at times when odometry suggests that such a reduction will not adversely affect task performance of human operators. We found that selectively reducing video quality significantly reduced bandwidth usage, increasing the robot's responsiveness and controllability, while having no measurable effect on task performance."}}
{"id": "B1NswkGO-H", "cdate": 1199145600000, "mdate": null, "content": {"title": "A bi-illuminant dichromatic reflection model for understanding images", "abstract": "This paper presents a new model for understanding the appearance of objects that exhibit both body and surface reflection under realistic illumination. Specifically, the model represents the appearance of surfaces that interact with a dominant illuminant and a non-negligible ambient illuminant that may have different spectral power distributions. Real illumination environments usually have an ambient illuminant, and the current dynamic range of consumer cameras is sufficient to capture significant information in shadows. The bi-illuminant dichromatic reflection model explains numerous empirical findings in the literature and has implications for commonly used chromaticity spaces that claim to be illumination invariant but are not in many natural situations. One outcome of the model is the first 2-D chromaticity space for an RGB image that is robust to illumination change given dominant and ambient illuminants with different spectral power distributions."}}
{"id": "0cW568HOpq", "cdate": 1167609600000, "mdate": 1667347364061, "content": {"title": "Building robot systems to interact with people in real environments", "abstract": ""}}
{"id": "Eh_SjjI1L7", "cdate": 1136073600000, "mdate": 1667347364090, "content": {"title": "Design of a Social Mobile Robot Using Emotion-Based Decision Mechanisms", "abstract": "In this paper, we describe a robot that interacts with humans in a crowded conference environment. The robot detects faces, determines the shirt color of onlooking conference attendants, and reacts with a combination of speech, musical, and movement responses. It continuously updates an internal emotional state, modeled realistically after human psychology research. Using empirically-determined mapping functions, the robot's state in the emotion space is translated to a particular set of sound and movement responses. We successfully demonstrate this system at the AAAI '05 Open Interaction Event, showing the potential for emotional modeling to improve human-robot interaction."}}
{"id": "f_A5Tb-aMG", "cdate": 1104537600000, "mdate": 1667347364097, "content": {"title": "Interactive vector fields for painterly rendering", "abstract": "We present techniques for generating and manipulating vector fields for use in the creation of painterly images and animations. Our aim is to enable casual users to create results evocative of expressionistic art. Rather than defining stroke alignment fields globally, we divide input images into regions using a colorspace clustering algorithm. Users interactively assign characteristic brush stroke alignment fields and stroke rendering parameters to each region. By combining vortex dynamics and semi-Lagrangian fluid simulation we are able to create stable, easily controlled vector fields. In addition to fluid simulations, users can align strokes in a given region using more conventional field models such as smoothed gradient fields and optical flow, or hybrid fields that combine the desirable features of fluid simulations and smoothed gradient information."}}
