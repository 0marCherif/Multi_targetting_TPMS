{"id": "pslIKdjXcXO", "cdate": 1672531200000, "mdate": 1683768464536, "content": {"title": "Interpretable and Robust AI in EEG Systems: A Survey", "abstract": "The close coupling of artificial intelligence (AI) and electroencephalography (EEG) has substantially advanced human-computer interaction (HCI) technologies in the AI era. Different from traditional EEG systems, the interpretability and robustness of AI-based EEG systems are becoming particularly crucial. The interpretability clarifies the inner working mechanisms of AI models and thus can gain the trust of users. The robustness reflects the AI's reliability against attacks and perturbations, which is essential for sensitive and fragile EEG signals. Thus the interpretability and robustness of AI in EEG systems have attracted increasing attention, and their research has achieved great progress recently. However, there is still no survey covering recent advances in this field. In this paper, we present the first comprehensive survey and summarize the interpretable and robust AI techniques for EEG systems. Specifically, we first propose a taxonomy of interpretability by characterizing it into three types: backpropagation, perturbation, and inherently interpretable methods. Then we classify the robustness mechanisms into four classes: noise and artifacts, human variability, data acquisition instability, and adversarial attacks. Finally, we identify several critical and unresolved challenges for interpretable and robust AI in EEG systems and further discuss their future directions."}}
{"id": "eVZlnHbkcf", "cdate": 1672531200000, "mdate": 1683768464420, "content": {"title": "An EEG Channel Selection Framework for Driver Drowsiness Detection via Interpretability Guidance", "abstract": "Drowsy driving has a crucial influence on driving safety, creating an urgent demand for driver drowsiness detection. Electroencephalogram (EEG) signal can accurately reflect the mental fatigue state and thus has been widely studied in drowsiness monitoring. However, the raw EEG data is inherently noisy and redundant, which is neglected by existing works that just use single-channel EEG data or full-head channel EEG data for model training, resulting in limited performance of driver drowsiness detection. In this paper, we are the first to propose an Interpretability-guided Channel Selection (ICS) framework for the driver drowsiness detection task. Specifically, we design a two-stage training strategy to progressively select the key contributing channels with the guidance of interpretability. We first train a teacher network in the first stage using full-head channel EEG data. Then we apply the class activation mapping (CAM) to the trained teacher model to highlight the high-contributing EEG channels and further propose a channel voting scheme to select the top N contributing EEG channels. Finally, we train a student network with the selected channels of EEG data in the second stage for driver drowsiness detection. Experiments are designed on a public dataset, and the results demonstrate that our method is highly applicable and can significantly improve the performance of cross-subject driver drowsiness detection."}}
{"id": "CkuiNlpcdX", "cdate": 1672531200000, "mdate": 1695952801708, "content": {"title": "Teacher Assistant-Based Knowledge Distillation Extracting Multi-level Features on Single Channel Sleep EEG", "abstract": "Sleep stage classification is of great significance to the diagnosis of sleep disorders. However, existing sleep stage classification models based on deep learning are usually relatively large in size (wider and deeper), which makes them hard to be deployed on wearable devices. Therefore, it is a challenge to lighten the existing sleep stage classification models. In this paper, we propose a novel general knowledge distillation framework for sleep stage classification tasks called SleepKD. Our SleepKD, composed of the multi-level module, teacher assistant module, and other knowledge distillation modules, aims to lighten large-scale sleep stage classification models. Specifically, the multi-level module is able to transfer the multi-level knowledge extracted from sleep signals by the teacher model (large-scale model) to the student model (lightweight model). Moreover, the teacher assistant module bridges the large gap between the teacher and student network, and further improves the distillation. We evaluate our method on two public sleep datasets (Sleep-EDF and ISRUC-III). Compared to the baseline methods, the results show that our knowledge distillation framework achieves state-of-the-art performance. SleepKD can significantly lighten the sleep model while maintaining its classification performance. The source code is available at https://github.com/HychaoWang/SleepKD."}}
{"id": "ZxdkjTgK_Dl", "cdate": 1663850127129, "mdate": null, "content": {"title": "BSTT: A Bayesian Spatial-Temporal Transformer for Sleep Staging", "abstract": "Sleep staging is helpful in assessing sleep quality and diagnosing sleep disorders. However, how to adequately capture the temporal and spatial relations of the brain during sleep remains a challenge. In particular, existing methods cannot adaptively infer spatial-temporal relations of the brain under different sleep stages. In this paper, we propose a novel Bayesian spatial-temporal relation inference neural network, named Bayesian spatial-temporal transformer (BSTT), for sleep staging. Our model is able to adaptively infer brain spatial-temporal relations during sleep for spatial-temporal feature modeling through a well-designed Bayesian relation inference component. Meanwhile, our model also includes a spatial transformer for extracting brain spatial features and a temporal transformer for capturing temporal features. Experiments show that our BSTT outperforms state-of-the-art baselines on ISRUC and MASS datasets. In addition, the visual analysis shows that the spatial-temporal relations obtained by BSTT inference have certain interpretability for sleep staging.\n"}}
{"id": "u-aZrUMvrO", "cdate": 1640995200000, "mdate": 1695952801707, "content": {"title": "Multi-Level Spatial-Temporal Adaptation Network for Motor Imagery Classification", "abstract": "Electroencephalogram (EEG) signals for motor imagery (MI) are easily influenced by the environment and the state of the subject, which exhibit temporal and spatial variance. And this variance is more significant across subjects and sessions, which imposes limitations on the cross-domain MI tasks. To address this problem, we propose a Multi-level Spatial-Temporal Adaptation Network (MSTAN), extracting domain-invariant multi-level spatial-temporal features to overcome domain differences. First, stacked spatial-temporal graph convolution (STGCN) layers and an attention-based readout module are designed to extract spatial-temporal patterns of EEGs at multiple levels. An adaptation scheme is then introduced to narrow domain differences: 1) Individual graph parameters for the source and target domains are designed at each STGCN layer to capture the domain-specific brain region dynamic relationships; 2) The differences of spatial-temporal features between the source and target domain are reduced by minimizing the distribution distance. Experiments are conducted to evaluate the proposed method on a public dataset and the results show that our method achieves state-of-the-art performance in cross-domain motor imagery classification."}}
{"id": "pL-HV19tJ-", "cdate": 1640995200000, "mdate": 1695952801665, "content": {"title": "Hybrid spiking neural network for sleep electroencephalogram signals", "abstract": "Sleep staging is important for assessing sleep quality. So far, many scholars have tried to achieve automatic sleep staging by using neural networks. However, most researchers only perform sleep staging based on artificial neural networks and their variant models, which can not fully mine and model the bio-electrical signals. In this paper, we propose a new hybrid spiking neural network (HSNN) model for automatic sleep staging. Specifically, we use a spiking neural network to classify sleep EEG signals. In addition, we adopt a hybrid macro/micro back propagation algorithm, aiming to overcome the limitations of existing error back propagation methods for spiking neural network. In order to verify the effectiveness of HSNN, we evaluate it on the public sleep dataset ISRUC-SLEEP (Institute of Systems and Robotics, University of Coimbra-Sleep). The results show that the proposed method achieves satisfactory performance on ISRUC-SLEEP."}}
{"id": "RqxJ_Ag__Dj", "cdate": 1620448659081, "mdate": null, "content": {"title": "SleepPrintNet: A Multivariate Multimodal Neural Network based on Physiological Time-series for Automatic Sleep Staging", "abstract": "Sleep is one of the most fundamental physiological activities of human beings. Sleep assessment based on physiological time-series can efficiently assist human experts to diagnose the sleep health of people. However, most of the existing methods only considered one or two kinds of time-domain, frequency-domain, and spatial-domain information from electroencephalogram (EEG). Besides, existing deep learning methods share the feature extraction module of EEG with other modalities, which ignore the discriminative features of electrooculogram (EOG) and electromyography (EMG). Therefore, how to make full use of the complementarity of different features of EEG and capture the discriminative features from other modalities is challenging. To tackle this challenge, we design SleepPrintNet to capture the SleepPrint in physiological time-series, which represents the complementarity among different features of EEG and discriminative features from other modalities in different sleep stages. SleepPrintNet consists of an EEG temporal feature extraction module, an EEG spectral-spatial feature extraction module for the temporal-spectral-spatial representation of EEG signals, and two multimodal feature extraction modules including EOG and EMG feature extraction module. To the best of our knowledge, it is the first attempt to integrate EEG temporal-spectral-spatial as well as the multimodal features simultaneously in a unified model for sleep staging. Experiments on the benchmark dataset MASS-SS3 demonstrate that SleepPrintNet outperforms all baseline models. The code of SleepPrintNet will be open source in the future."}}
{"id": "syRjjxJs54s", "cdate": 1620448516593, "mdate": null, "content": {"title": "Refined Nonuniform Embedding for Coupling Detection in Multivariate Time Series", "abstract": "State-space reconstruction is essential to analyze the dynamics and internal interactions of complex systems. However, it is difficult to estimate high-dimensional conditional mutual information and select the optimal time delays in most existing nonuniform state-space reconstruction methods. Therefore, we propose a nonuniform embedding method framed in information theory for state-space reconstruction. We use a low-dimensional approximation of conditional mutual information criterion for time delay selection, which is effectively solved by the particle swarm optimization algorithm. The obtained embedded vector has relatively strong independence and low redundancy, which better characterizes multivariable complex systems and detects coupling within complex systems. In addition, the proposed nonuniform embedding method exhibits good performance in coupling detection of linear stochastic, nonlinear stochastic, chaotic systems. In the actual application, the importance of small airports that cause delay propagation has been demonstrated by constructing the delay propagation network.\n\n"}}
{"id": "mHYk-TxmnM", "cdate": 1609459200000, "mdate": 1695952801730, "content": {"title": "Multi-View Spatial-Temporal Graph Convolutional Networks with Domain Generalization for Sleep Stage Classification", "abstract": "Sleep stage classification is essential for sleep assessment and disease diagnosis. Although previous attempts to classify sleep stages have achieved high classification performance, several challenges remain open: 1) How to effectively utilize time-varying spatial and temporal features from multi-channel brain signals remains challenging. Prior works have not been able to fully utilize the spatial topological information among brain regions. 2) Due to the many differences found in individual biological signals, how to overcome the differences of subjects and improve the generalization of deep neural networks is important. 3) Most deep learning methods ignore the interpretability of the model to the brain. To address the above challenges, we propose a multi-view spatial-temporal graph convolutional networks (MSTGCN) with domain generalization for sleep stage classification. Specifically, we construct two brain view graphs for MSTGCN based on the functional connectivity and physical distance proximity of the brain regions. The MSTGCN consists of graph convolutions for extracting spatial features and temporal convolutions for capturing the transition rules among sleep stages. In addition, attention mechanism is employed for capturing the most relevant spatial-temporal information for sleep stage classification. Finally, domain generalization and MSTGCN are integrated into a unified framework to extract subject-invariant sleep features. Experiments on two public datasets demonstrate that the proposed model outperforms the state-of-the-art baselines."}}
{"id": "YUKTgHewQ1m", "cdate": 1609459200000, "mdate": 1695952801728, "content": {"title": "HetEmotionNet: Two-Stream Heterogeneous Graph Recurrent Neural Network for Multi-modal Emotion Recognition", "abstract": "The research on human emotion under multimedia stimulation based on physiological signals is an emerging field, and important progress has been achieved for emotion recognition based on multi-modal signals. However, it is challenging to make full use of the complementarity among spatial-spectral-temporal domain features for emotion recognition, as well as model the heterogeneity and correlation among multi-modal signals. In this paper, we propose a novel two-stream heterogeneous graph recurrent neural network, named HetEmotionNet, fusing multi-modal physiological signals for emotion recognition. Specifically, HetEmotionNet consists of the spatial-temporal stream and the spatial-spectral stream, which can fuse spatial-spectral-temporal domain features in a unified framework. Each stream is composed of the graph transformer network for modeling the heterogeneity, the graph convolutional network for modeling the correlation, and the gated recurrent unit for capturing the temporal domain or spectral domain dependency. Extensive experiments on two real-world datasets demonstrate that our proposed model achieves better performance than state-of-the-art baselines."}}
