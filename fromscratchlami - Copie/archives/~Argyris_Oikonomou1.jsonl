{"id": "SfjzfqUAsiw", "cdate": 1664731445174, "mdate": null, "content": {"title": "Accelerated Algorithms for Monotone Inclusion and Constrained Nonconvex-Nonconcave Min-Max Optimization", "abstract": "We study monotone inclusions and monotone variational inequalities, as well as their generalizations to non-monotone settings. We first show that the \\emph{Extra Anchored Gradient (EAG)} algorithm, originally proposed by [Yoon and Ryu, 2021] for unconstrained convex-concave min-max optimization, can be applied to solve the more general problem of Lipschitz monotone inclusion. More specifically, we prove that the EAG solves Lipschitz monotone inclusion problems with an \\emph{accelerated convergence rate} of $O(\\frac{1}{T})$, which is \\emph{optimal among all first-order methods} [Diakonikolas, 2020, Yoon and Ryu, 2021]. Our second result is an {accelerated forward-backward splitting algorithm (AS),} which not only achieves the accelerated $O(\\frac{1}{T})$ convergence rate for all monotone inclusion problems, but also exhibits the same accelerated rate for a family of general (non-monotone) inclusion problems that concern negative comonotone operators. As a special case of our second result, AS enjoys the $O(\\frac{1}{T})$ convergence rate for solving a non-trivial class of nonconvex-nonconcave min-max optimization problems. Our analyses are based on simple potential function arguments, which might be useful for analysing other accelerated algorithms."}}
{"id": "snUOkDdJypm", "cdate": 1652737840991, "mdate": null, "content": {"title": "Finite-Time Last-Iterate Convergence for Learning in Multi-Player Games", "abstract": "We study the question of last-iterate convergence rate of the extragradient algorithm by Korpelevich [1976] and the optimistic gradient algorithm by Popov [1980] in multi-player games. We show that both algorithms with constant step-size have last-iterate convergence rate of $O(\\frac{1}{\\sqrt{T}})$ to a Nash equilibrium in terms of the gap function in smooth monotone games, where each player's action set is an arbitrary convex set. Previous results only study the unconstrained setting, where each player's action set is the entire Euclidean space.  Our results address an open question raised in several recent work by Hsieh et al. [2019], Golowich et al. [2020a,b], who ask for last-iterate convergence rate of either the extragradient or the optimistic gradient algorithm in the constrained setting. Our convergence rates for both algorithms are tight and match the lower bounds by Golowich et al. [2020a,b]. At the core of our results lies a new notion -- the tangent residual, which we use to measure the proximity to equilibrium. We use the tangent residual (or a slight variation of the tangent residual) as the the potential function in our analysis of the extragradient algorithm (or the optimistic gradient algorithm) and prove that it is non-increasing between two consecutive iterates."}}
{"id": "jL4_NM6lRM", "cdate": 1640995200000, "mdate": 1684283601011, "content": {"title": "Finite-Time Last-Iterate Convergence for Learning in Multi-Player Games", "abstract": "We study the question of last-iterate convergence rate of the extragradient algorithm by Korpelevich [1976] and the optimistic gradient algorithm by Popov [1980] in multi-player games. We show that both algorithms with constant step-size have last-iterate convergence rate of $O(\\frac{1}{\\sqrt{T}})$ to a Nash equilibrium in terms of the gap function in smooth monotone games, where each player's action set is an arbitrary convex set. Previous results only study the unconstrained setting, where each player's action set is the entire Euclidean space. Our results address an open question raised in several recent work by Hsieh et al. [2019], Golowich et al. [2020a,b], who ask for last-iterate convergence rate of either the extragradient or the optimistic gradient algorithm in the constrained setting. Our convergence rates for both algorithms are tight and match the lower bounds by Golowich et al. [2020a,b]. At the core of our results lies a new notion -- the tangent residual, which we use to measure the proximity to equilibrium. We use the tangent residual (or a slight variation of the tangent residual) as the the potential function in our analysis of the extragradient algorithm (or the optimistic gradient algorithm) and prove that it is non-increasing between two consecutive iterates."}}
{"id": "U0w2YGr1Zs_", "cdate": 1640995200000, "mdate": 1684283601088, "content": {"title": "Computing simple mechanisms: Lift-and-round over marginal reduced forms", "abstract": "We study revenue maximization in multi-item multi-bidder auctions under the natural item-independence assumption \u2013 a classical problem in Multi-Dimensional Bayesian Mechanism Design. One of the biggest challenges in this area is developing algorithms to compute (approximately) optimal mechanisms that are not brute-force in the size of the bidder type space, which is usually exponential in the number of items in multi-item auctions. Unfortunately, such algorithms were only known for basic settings of our problem when bidders have unit-demand or additive valuations. In this paper, we significantly improve the previous results and design the first algorithm that runs in time polynomial in the number of items and the number of bidders to compute mechanisms that are O(1)-approximations to the optimal revenue when bidders have XOS valuations, resolving an open problem raised by Chawla, Miller and Cai, Zhao. Moreover, the computed mechanism has a simple structure: It is either a posted price mechanism or a two-part tariff mechanism. As a corollary of our result, we show how to compute an approximately optimal and simple mechanism efficiently using only sample access to the bidders\u2019 value distributions. Our algorithm builds on two innovations that allow us to search over the space of mechanisms efficiently: (i) a new type of succinct representation of mechanisms \u2013 the marginal reduced forms, and (ii) a novel Lift-and-Round procedure that concavifies the problem."}}
{"id": "NhTz4XB6ZF", "cdate": 1640995200000, "mdate": 1684283601013, "content": {"title": "Tight Last-Iterate Convergence of the Extragradient Method for Constrained Monotone Variational Inequalities", "abstract": "The monotone variational inequality is a central problem in mathematical programming that unifies and generalizes many important settings such as smooth convex optimization, two-player zero-sum games, convex-concave saddle point problems, etc. The extragradient algorithm by Korpelevich [1976] and the optimistic gradient descent-ascent algorithm by Popov [1980] are arguably the two most classical and popular methods for solving monotone variational inequalities. Despite their long histories, the following major problem remains open. What is the last-iterate convergence rate of the extragradient algorithm or the optimistic gradient descent-ascent algorithm for monotone and Lipschitz variational inequalities with constraints? We resolve this open problem by showing that both the extragradient algorithm and the optimistic gradient descent-ascent algorithm have a tight $O\\left(\\frac{1}{\\sqrt{T}}\\right)$ last-iterate convergence rate for arbitrary convex feasible sets, which matches the lower bound by Golowich et al. [2020a,b]. Our rate is measured in terms of the standard gap function. At the core of our results lies a non-standard performance measure -- the tangent residual, which can be viewed as an adaptation of the norm of the operator that takes the local constraints into account. We use the tangent residual (or a slight variation of the tangent residual) as the the potential function in our analysis of the extragradient algorithm (or the optimistic gradient descent-ascent algorithm) and prove that it is non-increasing between two consecutive iterates."}}
{"id": "M76bRHBgHVY", "cdate": 1640995200000, "mdate": 1684283600959, "content": {"title": "Accelerated Algorithms for Monotone Inclusions and Constrained Nonconvex-Nonconcave Min-Max Optimization", "abstract": "We study monotone inclusions and monotone variational inequalities, as well as their generalizations to non-monotone settings. We first show that the Extra Anchored Gradient (EAG) algorithm, originally proposed by Yoon and Ryu [2021] for unconstrained convex-concave min-max optimization, can be applied to solve the more general problem of Lipschitz monotone inclusion. More specifically, we prove that the EAG solves Lipschitz monotone inclusion problems with an accelerated convergence rate of $O(\\frac{1}{T})$, which is optimal among all first-order methods [Diakonikolas, 2020, Yoon and Ryu, 2021]. Our second result is an accelerated forward-backward splitting algorithm (AS), which not only achieves the accelerated $O(\\frac{1}{T})$ convergence rate for all monotone inclusion problems, but also exhibits the same accelerated rate for a family of general (non-monotone) inclusion problems that concern negative comonotone operators. As a special case of our second result, AS enjoys the $O(\\frac{1}{T})$ convergence rate for solving a non-trivial class of nonconvex-nonconcave min-max optimization problems. Our analyses are based on simple potential function arguments, which might be useful for analysing other accelerated algorithms."}}
{"id": "grrbttVOkN", "cdate": 1609459200000, "mdate": 1684283601060, "content": {"title": "Computing Simple Mechanisms: Lift-and-Round over Marginal Reduced Forms", "abstract": "We study revenue maximization in multi-item multi-bidder auctions under the natural item-independence assumption - a classical problem in Multi-Dimensional Bayesian Mechanism Design. One of the biggest challenges in this area is developing algorithms to compute (approximately) optimal mechanisms that are not brute-force in the size of the bidder type space, which is usually exponential in the number of items in multi-item auctions. Unfortunately, such algorithms were only known for basic settings of our problem when bidders have unit-demand [CHMS10,CMS15] or additive valuations [Yao15]. In this paper, we significantly improve the previous results and design the first algorithm that runs in time polynomial in the number of items and the number of bidders to compute mechanisms that are $O(1)$-approximations to the optimal revenue when bidders have XOS valuations, resolving an open problem raised in [CM16,CZ17]. Moreover, the computed mechanism has a simple structure: It is either a posted price mechanism or a two-part tariff mechanism. As a corollary of our result, we show how to compute an approximately optimal and simple mechanism efficiently using only sample access to the bidders' value distributions. Our algorithm builds on two innovations that allow us to search over the space of mechanisms efficiently: (i) a new type of succinct representation of mechanisms - the marginal reduced forms, and (ii) a novel Lift-and-Round procedure that concavifies the problem."}}
{"id": "Y9F4A7t0s_b", "cdate": 1609459200000, "mdate": 1681758512493, "content": {"title": "An Efficient \u220a-BIC to BIC Transformation and Its Application to Black-Box Reduction in Revenue Maximization", "abstract": "We consider the black-box reduction from multidimensional revenue maximization to virtual welfare maximization. Cai et al. [12, 13, 14, 15] show a polynomial-time approximation-preserving reduction, however, the mechanism produced by their reduction is only approximately Bayesian incentive compatible (\u220a-BIC). We provide two new polynomial time transformations that convert any \u220a-BIC mechanism to an exactly BIC mechanism with only a negligible revenue loss. Our first transformation applies to any mechanism design setting with downward-closed outcome space and only requires sample access to the agents' type distributions. Our second transformation applies to the fully general outcome space, removing the downward-closed assumption, but requires full access to the agents' type distributions. Both transformations only require query access to the original \u220a-BIC mechanism. Other \u220a-BIC to BIC transformations for revenue exist in the literature [23, 36, 18] but all require exponential time to run in both of the settings we consider. As an application of our transformations, we improve the reduction by Cai et al. [12, 13, 14, 15] to generate an exactly BIC mechanism."}}
{"id": "Vrz5wyy_TQ", "cdate": 1609459200000, "mdate": 1684283600906, "content": {"title": "On Simple Mechanisms for Dependent Items", "abstract": "We study the problem of selling n heterogeneous items to a single buyer, whose values for different items are dependent. Under arbitrary dependence, Hart and Nisan[30] show that no simple mechanism can achieve a non-negligible fraction of the optimal revenue even with only two items. We consider the setting where the buyer's type is drawn from a correlated distribution that can be captured by a Markov Random Field, one of the most prominent frameworks for modeling high-dimensional distributions with structure.                                                                                                                                                                               If the buyer's valuation is additive or unit-demand, we extend the result to all MRFs and show that $\\max\\srev,brev\\ $ can achieve an \u00d8mega(1/eO(\u0394))-fraction of the optimal revenue, where \u0394 is a parameter of the MRF that is determined by how much the value of an item can be influenced by the values of the other items. We further show that the exponential dependence on \u0394 is unavoidable for our approach and a polynomial dependence on \u0394 is unavoidable for any approach. When the buyer has a XOS valuation, we show that max(SRev,BRev) achieves at least an $\u00d8mega(1/eO(\u0394) + 1/\u221an\u03b3)-fraction of the optimal revenue, where \u03b3 is the spectral gap of the Glauber dynamics of the MRF. Note that the values of \u0394 and 1/n\u03b3 increase as the dependence between items strengthens. In the special case of independently distributed items, \u0394=0 and 1/n\u03b3 \u2265 1, and our results recover the known constant factor approximations for a XOS buyer[41]. We further extend our parametric approximation to several other well-studied dependency measures such as the Dobrushin coefficient [27] and the inverse temperature. In particular, we show that if the MRF is in the high temperature regime, max(SRev,BRev) is still a constant factor approximation to the optimal revenue even for a XOS buyer. Our results are based on the Duality-Framework by Cai et al.[14] and a new concentration inequality for XOS functions over dependent random variables."}}
{"id": "66R5Aat9DY", "cdate": 1609459200000, "mdate": 1684283600968, "content": {"title": "On Simple Mechanisms for Dependent Items", "abstract": "We study the problem of selling $n$ heterogeneous items to a single buyer, whose values for different items are dependent. Under arbitrary dependence, Hart and Nisan show that no simple mechanism can achieve a non-negligible fraction of the optimal revenue even with only two items. We consider the setting where the buyer's type is drawn from a correlated distribution that can be captured by a Markov Random Field, one of the most prominent frameworks for modeling high-dimensional distributions with structure.   If the buyer's valuation is additive or unit-demand, we extend the result to all MRFs and show that max(SRev,BRev) can achieve an $\\Omega\\left(\\frac{1}{e^{O(\\Delta)}}\\right)$-fraction of the optimal revenue, where $\\Delta$ is a parameter of the MRF that is determined by how much the value of an item can be influenced by the values of the other items. We further show that the exponential dependence on $\\Delta$ is unavoidable for our approach and a polynomial dependence on $\\Delta$ is unavoidable for any approach. When the buyer has a XOS valuation, we show that max(Srev,Brev) achieves at least an $\\Omega\\left(\\frac{1}{e^{O(\\Delta)}+\\frac{1}{\\sqrt{n\\gamma}}}\\right)$-fraction of the optimal revenue, where $\\gamma$ is the spectral gap of the Glauber dynamics of the MRF. Note that in the special case of independently distributed items, $\\Delta=0$ and $\\frac{1}{n\\gamma}\\leq 1$, and our results recover the known constant factor approximations for a XOS buyer. We further extend our parametric approximation to several other well-studied dependency measures such as the Dobrushin coefficient and the inverse temperature. Our results are based on the Duality-Framework by Cai et al. and a new concentration inequality for XOS functions over dependent random variables."}}
