{"id": "8etgts_b1Xh", "cdate": 1640995200000, "mdate": 1682338372427, "content": {"title": "Autoencoders on field-programmable gate arrays for real-time, unsupervised new physics detection at 40 MHz at the Large Hadron Collider", "abstract": ""}}
{"id": "3ZURBAr5s6", "cdate": 1640995200000, "mdate": 1682338372498, "content": {"title": "Author Correction: Autoencoders on field-programmable gate arrays for real-time, unsupervised new physics detection at 40 MHz at the Large Hadron Collider", "abstract": ""}}
{"id": "o6cWXCPR9KA", "cdate": 1609459200000, "mdate": 1683769916146, "content": {"title": "Analysis-Specific Fast Simulation at the LHC with Deep Learning", "abstract": "We present a fast-simulation application based on a deep neural network, designed to create large analysis-specific datasets. Taking as an example the generation of W + jet events produced in $$\\sqrt{s}=$$ s = 13 TeV proton\u2013proton collisions, we train a neural network to model detector resolution effects as a transfer function acting on an analysis-specific set of relevant features, computed at generation level, i.e., in absence of detector effects. Based on this model, we propose a novel fast-simulation workflow that starts from a large amount of generator-level events to deliver large analysis-specific samples. The adoption of this approach would result in about an order-of-magnitude reduction in computing and storage requirements for the collision simulation workflow. This strategy could help the high energy physics community to face the computing challenges of the future High-Luminosity LHC."}}
{"id": "h2YlzSuZPj", "cdate": 1577836800000, "mdate": 1683769916156, "content": {"title": "Data Augmentation at the LHC through Analysis-specific Fast Simulation with Deep Learning", "abstract": "We present a fast simulation application based on a Deep Neural Network, designed to create large analysis-specific datasets. Taking as an example the generation of W+jet events produced in sqrt(s)= 13 TeV proton-proton collisions, we train a neural network to model detector resolution effects as a transfer function acting on an analysis-specific set of relevant features, computed at generation level, i.e., in absence of detector effects. Based on this model, we propose a novel fast-simulation workflow that starts from a large amount of generator-level events to deliver large analysis-specific samples. The adoption of this approach would result in about an order-of-magnitude reduction in computing and storage requirements for the collision simulation workflow. This strategy could help the high energy physics community to face the computing challenges of the future High-Luminosity LHC."}}
{"id": "RjNyILW6dhm", "cdate": 1577836800000, "mdate": 1683769916146, "content": {"title": "Adversarially Learned Anomaly Detection on CMS Open Data: re-discovering the top quark", "abstract": "We apply an Adversarially Learned Anomaly Detection (ALAD) algorithm to the problem of detecting new physics processes in proton-proton collisions at the Large Hadron Collider. Anomaly detection based on ALAD matches performances reached by Variational Autoencoders, with a substantial improvement in some cases. Training the ALAD algorithm on 4.4 fb-1 of 8 TeV CMS Open Data, we show how a data-driven anomaly detection and characterization would work in real life, re-discovering the top quark by identifying the main features of the t-tbar experimental signature at the LHC."}}
{"id": "ZBKWQECZ6e", "cdate": 1514764800000, "mdate": 1683769916157, "content": {"title": "Variational Autoencoders for New Physics Mining at the Large Hadron Collider", "abstract": "Using variational autoencoders trained on known physics processes, we develop a one-sided threshold test to isolate previously unseen processes as outlier events. Since the autoencoder training does not depend on any specific new physics signature, the proposed procedure doesn't make specific assumptions on the nature of new physics. An event selection based on this algorithm would be complementary to classic LHC searches, typically based on model-dependent hypothesis testing. Such an algorithm would deliver a list of anomalous events, that the experimental collaborations could further scrutinize and even release as a catalog, similarly to what is typically done in other scientific domains. Event topologies repeating in this dataset could inspire new-physics model building and new experimental searches. Running in the trigger system of the LHC experiments, such an application could identify anomalous events that would be otherwise lost, extending the scientific reach of the LHC."}}
{"id": "LFXizHwy9os", "cdate": 1514764800000, "mdate": 1683769916157, "content": {"title": "Topology classification with deep learning to improve real-time event selection at the LHC", "abstract": "We show how event topology classification based on deep learning could be used to improve the purity of data samples selected in real time at at the Large Hadron Collider. We consider different data representations, on which different kinds of multi-class classifiers are trained. Both raw data and high-level features are utilized. In the considered examples, a filter based on the classifier's score can be trained to retain ~99% of the interesting events and reduce the false-positive rate by as much as one order of magnitude for certain background processes. By operating such a filter as part of the online event selection infrastructure of the LHC experiments, one could benefit from a more flexible and inclusive selection strategy while reducing the amount of downstream resources wasted in processing false positives. The saved resources could be translated into a reduction of the detector operation cost or into an effective increase of storage and processing capabilities, which could be reinvested to extend the physics reach of the LHC experiments."}}
