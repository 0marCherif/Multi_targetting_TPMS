{"id": "Sb8cn7hopxB", "cdate": 1676556367289, "mdate": 1676556367289, "content": {"title": "Self-Attentive Sequential Recocommendation", "abstract": "Sequential dynamics are a key feature of many modern recommender systems, which seek to capture the \u2018con- text\u2019 of users\u2019 activities on the basis of actions they have performed recently. To capture such patterns, two approaches have proliferated: Markov Chains (MCs) and Recurrent Neural Networks (RNNs). Markov Chains assume that a user\u2019s next action can be predicted on the basis of just their last (or last few) actions, while RNNs in principle allow for longer-term semantics to be uncovered. Generally speaking, MC-based methods perform best in extremely sparse datasets, where model parsimony is critical, while RNNs perform better in denser datasets where higher model complexity is affordable. The goal of our work is to balance these two goals, by proposing a self-attention based sequential model (SASRec) that allows us to capture long-term semantics (like an RNN), but, using an attention mechanism, makes its predictions based on relatively few actions (like an MC). At each time step, SASRec seeks to identify which items are \u2018relevant\u2019 from a user\u2019s action history, and use them to predict the next item. Extensive empirical studies show that our method outperforms various state-of-the-art sequential models (including MC/CNN/RNN-based approaches) on both sparse and dense datasets. Moreover, the model is an order of magnitude more efficient than comparable CNN/RNN-based models. Visual- izations on attention weights also show how our model adaptively handles datasets with various density, and uncovers meaningful patterns in activity sequences."}}
{"id": "yJPuWm973k1", "cdate": 1609459200000, "mdate": 1631431539399, "content": {"title": "Learning to Embed Categorical Features without Embedding Tables for Recommendation", "abstract": "Embedding learning of categorical features (e.g. user/item IDs) is at the core of various recommendation models. The standard approach creates an embedding table where each row represents a dedicated embedding vector for every unique feature value. However, this method fails to efficiently handle high-cardinality features and unseen feature values (e.g. new video ID) that are prevalent in real-world recommendation systems. In this paper, we propose an alternative embedding framework Deep Hash Embedding (DHE), replacing embedding tables by a deep embedding network to compute embeddings on the fly. DHE first encodes the feature value to a unique identifier vector with multiple hashing functions and transformations, and then applies a DNN to convert the identifier vector to an embedding. The encoding module is deterministic, non-learnable, and free of storage, while the embedding network is updated during the training time to learn embedding generation. Empirical results show that DHE achieves comparable AUC against the standard one-hot full embedding, with smaller model sizes. Our work sheds light on the design of DNN-based alternative embedding schemes for categorical features without using embedding table lookup."}}
{"id": "k2if3j871eu", "cdate": 1577836800000, "mdate": 1631431539457, "content": {"title": "Deep Hash Embedding for Large-Vocab Categorical Feature Representations", "abstract": "Embedding learning of categorical features (e.g. user/item IDs) is at the core of various recommendation models including matrix factorization and neural collaborative filtering. The standard approach creates an embedding table where each row represents a dedicated embedding vector for every unique feature value. However, this method fails to efficiently handle high-cardinality features and unseen feature values (e.g. new video ID) that are prevalent in real-world recommendation systems. In this paper, we propose an alternative embedding framework Deep Hash Embedding (DHE), replacing embedding tables by a deep embedding network to compute embeddings on the fly. DHE first encodes the feature value to a unique identifier vector with multiple hashing functions and transformations, and then applies a DNN to convert the identifier vector to an embedding. The encoding module is deterministic, non-learnable, and free of storage, while the embedding network is updated during the training time to learn embedding generation. Empirical results show that DHE achieves comparable AUC against the standard one-hot full embedding, with smaller model sizes. Our work sheds light on the design of DNN-based alternative embedding schemes for categorical features without using embedding table lookup."}}
{"id": "g-aw0EMXu8e", "cdate": 1577836800000, "mdate": 1631431539550, "content": {"title": "Learning Multi-granular Quantized Embeddings for Large-Vocab Categorical Features in Recommender Systems", "abstract": "Recommender system models often represent various sparse features like users, items, and categorical features via embeddings. A standard approach is to map each unique feature value to an embedding vector. The size of the produced embedding table grows linearly with the size of the vocabulary. Therefore, a large vocabulary inevitably leads to a gigantic embedding table, creating two severe problems: (i) making model serving intractable in resource-constrained environments; (ii) causing overfitting problems. In this paper, we seek to learn highly compact embeddings for large-vocab sparse features in recommender systems (recsys). First, we show that the novel Differentiable Product Quantization (DPQ) approach can generalize to recsys problems. In addition, to better handle the power-law data distribution commonly seen in recsys, we propose a Multi-Granular Quantized Embeddings (MGQE) technique which learns more compact embeddings for infrequent items. We seek to provide a new angle to improve recommendation performance with compact model sizes. Extensive experiments on three recommendation tasks and two datasets show that we can achieve on par or better performance, with only ~20% of the original model size."}}
{"id": "eb0zhjIMJmc", "cdate": 1577836800000, "mdate": 1631431539657, "content": {"title": "Learning Multi-granular Quantized Embeddings for Large-Vocab Categorical Features in Recommender Systems", "abstract": "Recommender system models often represent various sparse features like users, items, and categorical features via embeddings. A standard approach is to map each unique feature value to an embedding vector. The size of the produced embedding table grows linearly with the size of the vocabulary. Therefore, a large vocabulary inevitably leads to a gigantic embedding table, creating two severe problems: (i) making model serving intractable in resource-constrained environments; (ii) causing overfitting problems. In this paper, we seek to learn highly compact embeddings for large-vocab sparse features in recommender systems (recsys). First, we show that the novel Differentiable Product Quantization (DPQ) approach can generalize to recsys problems. In addition, to better handle the power-law data distribution commonly seen in recsys, we propose a Multi-Granular Quantized Embeddings (MGQE) technique which learns more compact embeddings for infrequent items. We seek to provide a new angle to improve recommendation performance with compact model sizes. Extensive experiments on three recommendation tasks and two datasets show that we can achieve on par or better performance, with only \u223c 20% of the original model size."}}
{"id": "CNEsTP2iTb", "cdate": 1577836800000, "mdate": 1682449466907, "content": {"title": "Building Visually-aware, Dynamic, and Efficient Recommender Systems", "abstract": "Author(s): Kang, Wangcheng | Advisor(s): McAuley, Julian | Abstract: Conventional recommendation models often use the user-item interaction matrix (e.g. ratings) to predict user preferences and generate recommendations. However, it ignores abundant signals and context (e.g. visual signals or temporal context) existing in real-world applications. Moreover, efficiency becomes an essential factor when building large-scale recommendation engines. In this thesis, we seek to extend the conventional recommendation frameworks to adapt new and large-scale application scenarios. Specifically, this thesis includes three directions: (i) Visually-aware Recommendation: we extend recommendation models to visual domains. We develop CNN-based end-to-end learning approaches to make personalized image recommendations and complementary product recommendations. Moreover, beyond recommending existing products, we develop GAN-based preference models to generate new products that are preferred by users; (ii) Dynamic Recommendation: we adapt recommendation models to dynamic environments where user preferences constantly shift. We develop Markov-chain-based and self-attention-based sequential models to respond to the change of users' interests quickly and make more accurate recommendations. (iii) Efficient Recommendation: we consider both time efficiency and space efficiency, where the former seeks to optimize the serving latency, and the latter seeks to reduce the memory consumption of recommendation models."}}
{"id": "wirciIyJBjW", "cdate": 1546300800000, "mdate": null, "content": {"title": "CosRec: 2D Convolutional Neural Networks for Sequential Recommendation", "abstract": "Sequential patterns play an important role in building modern recommender systems. To this end, several recommender systems have been built on top of Markov Chains and Recurrent Models (among others). Although these sequential models have proven successful at a range of tasks, they still struggle to uncover complex relationships nested in user purchase histories. In this paper, we argue that modeling pairwise relationships directly leads to an efficient representation of sequential features and captures complex item correlations. Specifically, we propose a 2D convolutional network for sequential recommendation (CosRec). It encodes a sequence of items into a three-way tensor; learns local features using 2D convolutional filters; and aggregates high-order interactions in a feedforward manner. Quantitative results on two public datasets show that our method outperforms both conventional methods and recent sequence-based approaches, achieving state-of-the-art performance on various evaluation metrics."}}
{"id": "ruZGz-B7257", "cdate": 1546300800000, "mdate": null, "content": {"title": "Candidate Generation with Binary Codes for Large-Scale Top-N Recommendation", "abstract": "Generating the Top-N recommendations from a large corpus is computationally expensive to perform at scale. Candidate generation and re-ranking based approaches are often adopted in industrial settings to alleviate efficiency problems. However it remains to be fully studied how well such schemes approximate complete rankings (or how many candidates are required to achieve a good approximation), or to develop systematic approaches to generate high-quality candidates efficiently. In this paper, we seek to investigate these questions via proposing a candidate generation and re-ranking based framework (CIGAR), which first learns a preference-preserving binary embedding for building a hash table to retrieve candidates, and then learns to re-rank the candidates using real-valued ranking models with a candidate-oriented objective. We perform a comprehensive study on several large-scale real-world datasets consisting of millions of users/items and hundreds of millions of interactions. Our results show that CIGAR significantly boosts the Top-N accuracy against state-of-the-art recommendation models, while reducing the query time by orders of magnitude. We hope that this work could draw more attention to the candidate generation problem in recommender systems."}}
{"id": "axF8EOYC--Q", "cdate": 1546300800000, "mdate": null, "content": {"title": "Candidate Generation with Binary Codes for Large-Scale Top-N Recommendation", "abstract": "Generating the Top-N recommendations from a large corpus is computationally expensive to perform at scale. Candidate generation and re-ranking based approaches are often adopted in industrial settings to alleviate efficiency problems. However it remains to be fully studied how well such schemes approximate complete rankings (or how many candidates are required to achieve a good approximation), or to develop systematic approaches to generate high-quality candidates efficiently. In this paper, we seek to investigate these questions via proposing a candidate generation and re-ranking based framework (CIGAR), which first learns a preference-preserving binary embedding for building a hash table to retrieve candidates, and then learns to re-rank the candidates using real-valued ranking models with a candidate-oriented objective. We perform a comprehensive study on several large-scale real-world datasets consisting of millions of users/items and hundreds of millions of interactions. Our results show that CIGAR significantly boosts the Top-N accuracy against state-of-the-art recommendation models, while reducing the query time by orders of magnitude. We hope that this work could draw more attention to the candidate generation problem in recommender systems."}}
{"id": "TMvLajTT2vI", "cdate": 1546300800000, "mdate": null, "content": {"title": "CosRec: 2D Convolutional Neural Networks for Sequential Recommendation", "abstract": "Sequential patterns play an important role in building modern recommender systems. To this end, several recommender systems have been built on top of Markov Chains and Recurrent Models (among others). Although these sequential models have proven successful at a range of tasks, they still struggle to uncover complex relationships nested in user purchase histories. In this paper, we argue that modeling pairwise relationships directly leads to an efficient representation of sequential features and captures complex item correlations. Specifically, we propose a 2D convolutional network for sequential recommendation (CosRec). It encodes a sequence of items into a three-way tensor; learns local features using 2D convolutional filters; and aggregates high-order interactions in a feedforward manner. Quantitative results on two public datasets show that our method outperforms both conventional methods and recent sequence-based approaches, achieving state-of-the-art performance on various evaluation metrics."}}
