{"id": "NgmHFEUhQyD", "cdate": 1672531200000, "mdate": 1700153692890, "content": {"title": "Communication-Efficient Collaborative Best Arm Identification", "abstract": "We investigate top-m arm identification, a basic problem in bandit theory, in a multi-agent learning model in which agents collaborate to learn an objective function. We are interested in designing collaborative learning algorithms that achieve maximum speedup (compared to single-agent learning algorithms) using minimum communication cost, as communication is frequently the bottleneck in multi-agent learning. We give both algorithmic and impossibility results, and conduct a set of experiments to demonstrate the effectiveness of our algorithms."}}
{"id": "EJfvu-gaRn", "cdate": 1672531200000, "mdate": 1675572481989, "content": {"title": "Collaborative Regret Minimization in Multi-Armed Bandits", "abstract": "In this paper, we study the collaborative learning model, which concerns the tradeoff between parallelism and communication overhead in multi-agent reinforcement learning. For a fundamental problem in bandit theory, regret minimization in multi-armed bandits, we present the first and almost tight tradeoffs between the number of rounds of communication between the agents and the regret of the collaborative learning process."}}
{"id": "o_VpzyLuYz4", "cdate": 1640995200000, "mdate": 1674507779540, "content": {"title": "Instance-Sensitive Algorithms for Pure Exploration in Multinomial Logit Bandit", "abstract": "Motivated by real-world applications such as fast fashion retailing and online advertising, the Multinomial Logit Bandit (MNL-bandit) is a popular model in online learning and operations research, and has attracted much attention in the past decade. In this paper, we give efficient algorithms for pure exploration in MNL-bandit. Our algorithms achieve instance-sensitive pull complexities. We also complement the upper bounds by an almost matching lower bound."}}
{"id": "biRZJbyMHV", "cdate": 1640995200000, "mdate": 1674507779717, "content": {"title": "SyncSignature: A Simple, Efficient, Parallelizable Framework for Tree Similarity Joins", "abstract": ""}}
{"id": "A7Ug5PTZj-G", "cdate": 1640995200000, "mdate": 1674507779654, "content": {"title": "Communication-Efficient Collaborative Best Arm Identification", "abstract": "We investigate top-$m$ arm identification, a basic problem in bandit theory, in a multi-agent learning model in which agents collaborate to learn an objective function. We are interested in designing collaborative learning algorithms that achieve maximum speedup (compared to single-agent learning algorithms) using minimum communication cost, as communication is frequently the bottleneck in multi-agent learning. We give both algorithmic and impossibility results, and conduct a set of experiments to demonstrate the effectiveness of our algorithms."}}
{"id": "2uoYCWKPwp4", "cdate": 1640995200000, "mdate": 1674507779662, "content": {"title": "Collaborative Best Arm Identification with Limited Communication on Non-IID Data", "abstract": "In this paper, we study the tradeoffs between the time speedup and the round complexity in the collaborative learning model with non-IID data, where multiple agents interact with possibly different environments and they want to learn an objective in the aggregated environment. We use a basic problem in bandit theory called best arm identification in multi-armed bandits as a vehicle to deliver the following conceptual message: collaborative learning on non-IID data is provably more difficult than that on IID data. In particular, we show the following: 1) Learning time speedup in the non-IID data setting can be much smaller than $1$ (that is, a slowdown). When the number of rounds $R = O(1)$, we will need at least a polynomial number of agents (in terms of the number of arms) to achieve a speedup $\\tilde{\\Omega}(1)$. This is in stark contrast to the IID data setting, where the speedup is always $\\tilde{\\Omega}(1)$ regardless of $R$ and the number of agents $K$. 2) Local adaptivity of the agents cannot help much in the non-IID data setting. This is in contrast with the IID data setting, in which to achieve the same speedup, the best non-adaptive algorithm requires a significantly larger number of rounds than the best adaptive algorithm."}}
{"id": "6dUmvYKjj4a", "cdate": 1609459200000, "mdate": 1675572481939, "content": {"title": "Batched Thompson Sampling for Multi-Armed Bandits", "abstract": "We study Thompson Sampling algorithms for stochastic multi-armed bandits in the batched setting, in which we want to minimize the regret over a sequence of arm pulls using a small number of policy changes (or, batches). We propose two algorithms and demonstrate their effectiveness by experiments on both synthetic and real datasets. We also analyze the proposed algorithms from the theoretical aspect and obtain almost tight regret-batches tradeoffs for the two-arm case."}}
{"id": "qEaoSa3mHLv", "cdate": 1577836800000, "mdate": 1675572481943, "content": {"title": "Instance-Sensitive Algorithms for Pure Exploration in Multinomial Logit Bandit", "abstract": "Motivated by real-world applications such as fast fashion retailing and online advertising, the Multinomial Logit Bandit (MNL-bandit) is a popular model in online learning and operations research, and has attracted much attention in the past decade. However, it is a bit surprising that pure exploration, a basic problem in bandit theory, has not been well studied in MNL-bandit so far. In this paper we give efficient algorithms for pure exploration in MNL-bandit. Our algorithms achieve instance-sensitive pull complexities. We also complement the upper bounds by an almost matching lower bound."}}
{"id": "MlSczWFffso", "cdate": 1577836800000, "mdate": 1674507779713, "content": {"title": "Batched Coarse Ranking in Multi-Armed Bandits", "abstract": "We study the problem of coarse ranking in the multi-armed bandits (MAB) setting, where we have a set of arms each of which is associated with an unknown distribution. The task is to partition the arms into clusters of predefined sizes, such that the mean of any arm in the $i$-th cluster is larger than that of any arm in the $j$-th cluster for any $j &gt; i$. Coarse ranking generalizes a number of basic problems in MAB (e.g., best arm identification) and has many real-world applications. We initiate the study of the problem in the batched model where we can only have a small number of policy changes. We study both the fixed budget and fixed confidence variants in MAB, and propose algorithms and prove impossibility results which together give almost tight tradeoffs between the total number of arms pulls and the number of policy changes. We have tested our algorithms in both real and synthetic data; our experimental results have demonstrated the efficiency of the proposed methods."}}
{"id": "FAtMWAolSG", "cdate": 1577836800000, "mdate": 1674507779653, "content": {"title": "Collaborative Top Distribution Identifications with Limited Interaction (Extended Abstract)", "abstract": "We consider the following problem in this paper: given a set of <tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$n$</tex> distributions, find the top- <tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$m$</tex> ones with the largest means. This problem is also called top- <tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$m$</tex> arm identifications in the literature of reinforcement learning, and has numerous applications. We study the problem in the collaborative learning model where we have multiple agents who can draw samples from the <tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$n$</tex> distributions in parallel. Our goal is to characterize the tradeoffs between the running time of learning process and the number of rounds of interaction between agents, which is very expensive in various scenarios. We give optimal time-round tradeoffs, as well as demonstrate complexity separations between top-1 arm identification and top- <tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$m$</tex> arm identifications for general <tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$m$</tex> and between fixed-time and fixed-confidence variants. As a byproduct, we also give an algorithm for selecting the distribution with the <tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$m$</tex> -th largest mean in the collaborative learning model."}}
