{"id": "0ypEbqNd2ji", "cdate": 1704067200000, "mdate": 1707285842301, "content": {"title": "Learning Whole-Body Manipulation for Quadrupedal Robot", "abstract": "We propose a learning-based system for enabling quadrupedal robots to manipulate large, heavy objects using their whole body. Our system is based on a hierarchical control strategy that uses the deep latent variable embedding which captures manipulation-relevant information from interactions, proprioception, and action history, allowing the robot to implicitly understand object properties. We evaluate our framework in both simulation and real-world scenarios. In the simulation, it achieves a success rate of 93.6 <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><tex-math notation=\"LaTeX\">$\\%$</tex-math></inline-formula> in accurately re-positioning and re-orienting various objects within a tolerance of 0.03 <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><tex-math notation=\"LaTeX\">$\\text{m}$</tex-math></inline-formula> and 5 <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><tex-math notation=\"LaTeX\">$^\\circ$</tex-math></inline-formula> . Real-world experiments demonstrate the successful manipulation of objects such as a 19.2 <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><tex-math notation=\"LaTeX\">$\\text{kg}$</tex-math></inline-formula> water-filled drum and a 15.3 <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><tex-math notation=\"LaTeX\">$\\text{kg}$</tex-math></inline-formula> plastic box filled with heavy objects while the robot weighs 27 <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><tex-math notation=\"LaTeX\">$\\text{kg}$</tex-math></inline-formula> . Unlike previous works that focus on manipulating small and light objects using prehensile manipulation, our framework illustrates the possibility of using quadrupeds for manipulating large and heavy objects that are ungraspable with the robot's entire body. Our method does not require explicit object modeling and offers significant computational efficiency compared to optimization-based methods."}}
{"id": "09UL1dCqf2n", "cdate": 1686324880107, "mdate": null, "content": {"title": "Preference learning for guiding the tree search in continuous POMDPs", "abstract": "A robot operating in a partially observable environment must perform sensing actions to achieve a goal, such as clearing the objects in front of a shelf to better localize a target object at the back, and estimate its shape for grasping. A POMDP is a principled framework for enabling robots to perform such information-gathering actions. Unfortunately, while robot manipulation domains involve high-dimensional and continuous observation and action spaces, most  POMDP solvers are limited to discrete spaces. Recently, POMCPOW has been proposed for continuous POMDPs, which handles continuity using sampling and progressive widening. However, for robot manipulation problems involving camera observations and multiple objects, POMCPOW is too slow to be practical. We take inspiration from the recent work in learning to guide task and motion planning to propose a framework that learns to guide POMCPOW from past planning experience. Our method uses preference learning that utilizes both success and failure trajectories, where the preference label is given by the results of the tree search. We demonstrate the efficacy of our framework in several continuous partially observable robotics domains, including real-world manipulation, where our framework explicitly reasons about the uncertainty in off-the-shelf segmentation and pose estimation algorithms."}}
{"id": "wZP1Sroa7-", "cdate": 1672531200000, "mdate": 1707285842299, "content": {"title": "Pre- and post-contact policy decomposition for non-prehensile manipulation with zero-shot sim-to-real transfer", "abstract": "We present a system for non-prehensile manipulation that require a significant number of contact mode transitions and the use of environmental contacts to successfully manipulate an object to a target location. Our method is based on deep reinforcement learning which, unlike state-of-the-art planning algorithms, does not require apriori knowledge of the physical parameters of the object or environment such as friction coefficients or centers of mass. The planning time is reduced to the simple feed-forward prediction time on a neural network. We propose a computational structure, action space design, and curriculum learning scheme that facilitates efficient exploration and sim-to-real transfer. In challenging real-world non-prehensile manipulation tasks, we show that our method can generalize over different objects, and succeed even for novel objects not seen during training. Project website: https://sites.google.com/view/nonprenehsile-decomposition"}}
{"id": "Ufo63Qa1iBkh", "cdate": 1672531200000, "mdate": 1699606162949, "content": {"title": "Open X-Embodiment: Robotic Learning Datasets and RT-X Models", "abstract": "Large, high-capacity models trained on diverse datasets have shown remarkable successes on efficiently tackling downstream applications. In domains from NLP to Computer Vision, this has led to a consolidation of pretrained models, with general pretrained backbones serving as a starting point for many applications. Can such a consolidation happen in robotics? Conventionally, robotic learning methods train a separate model for every application, every robot, and even every environment. Can we instead train generalist X-robot policy that can be adapted efficiently to new robots, tasks, and environments? In this paper, we provide datasets in standardized data formats and models to make it possible to explore this possibility in the context of robotic manipulation, alongside experimental results that provide an example of effective X-robot policies. We assemble a dataset from 22 different robots collected through a collaboration between 21 institutions, demonstrating 527 skills (160266 tasks). We show that a high-capacity model trained on this data, which we call RT-X, exhibits positive transfer and improves the capabilities of multiple robots by leveraging experience from other platforms. More details can be found on the project website $\\href{https://robotics-transformer-x.github.io}{\\text{robotics-transformer-x.github.io}}$."}}
{"id": "NUy9RbC3nN", "cdate": 1672531200000, "mdate": 1707285842285, "content": {"title": "Pre-and Post-Contact Policy Decomposition for Non-Prehensile Manipulation with Zero-Shot Sim-To-Real Transfer", "abstract": "We present a system for non-prehensile manipulation that require a significant number of contact mode transitions and the use of environmental contacts to successfully manipulate an object to a target location. Our method is based on deep reinforcement learning which, unlike state-of-the-art planning algorithms, does not require apriori knowledge of the physical parameters of the object or environment such as friction coefficients or centers of mass. The planning time is reduced to the simple feed-forward prediction time on a neural network. We propose a computational structure, action space design, and curriculum learning scheme that facilitates efficient exploration and sim-to-real transfer. In challenging real-world non-prehensile manipulation tasks, we show that our method can generalize over different objects, and succeed even for novel objects not seen during training. Project website: https://sites.google.com/view/nonprenehsile-decomposition"}}
{"id": "Ah9N7sfTOR", "cdate": 1672531200000, "mdate": 1707285842289, "content": {"title": "Local object crop collision network for efficient simulation of non-convex objects in GPU-based simulators", "abstract": ""}}
{"id": "yOJ0A79ozG", "cdate": 1640995200000, "mdate": 1654849767554, "content": {"title": "Representation, learning, and planning algorithms for geometric task and motion planning", "abstract": "We present a framework for learning to guide geometric task and motion planning (GTAMP). GTAMP is a subclass of task and motion planning in which the goal is to move multiple objects to target regions among movable obstacles. A standard graph search algorithm is not directly applicable, because GTAMP problems involve hybrid search spaces and expensive action feasibility checks. To handle this, we introduce a novel planner that extends basic heuristic search with random sampling and a heuristic function that prioritizes feasibility checking on promising state action pairs. The main drawback of such pure planners is that they lack the ability to learn from planning experience to improve their efficiency. We propose two learning algorithms to address this. The first is an algorithm for learning a rank function that guides the discrete task level search, and the second is an algorithm for learning a sampler that guides the continuous motionlevel search. We propose design principles for designing data efficient algorithms for learning from planning experience and representations for effective generalization. We evaluate our framework in challenging GTAMP problems, and show that we can improve both planning and data efficiency"}}
{"id": "l9G4LhScuO", "cdate": 1640995200000, "mdate": 1695412752565, "content": {"title": "Representation, learning, and planning algorithms for geometric task and motion planning", "abstract": "We present a framework for learning to guide geometric task-and-motion planning (G-TAMP). G-TAMP is a subclass of task-and-motion planning in which the goal is to move multiple objects to target re..."}}
{"id": "CP61gnPoim", "cdate": 1640995200000, "mdate": 1707285842297, "content": {"title": "\u03a92: Optimal Hierarchical Planner for Object Search in Large Environments via Mobile Manipulation", "abstract": "We propose a hierarchical planning algorithm that efficiently computes an optimal plan for finding a target object in large environments where a robot must simultaneously consider both navigation and manipulation. One key challenge that arises from large domains is the substantial increase in search space complexity that stems from considering mobile manipulation actions and the increase in number of objects. We offer a hierarchical planning solution that effectively handles such large problems by decomposing the problem into a set of low-level intra-container planning problems and a high-level key place planning problem that utilizes the low-level plans. To plan optimally, we propose a novel admissible heuristic function that, unlike previous methods, accounts for both navigation and manipulation costs. We propose two algorithms: one based on standard A* that returns the optimal solution, and the other based on Anytime Repairing A* (ARA*) which can trade-off computation time and solution quality, and prove they are optimal even when we use hierarchy. We show our method outperforms existing algorithms in simulated domains involving up to 6 times more number of objects than previously handled."}}
{"id": "b8e8lzHLVv-", "cdate": 1596121678232, "mdate": null, "content": {"title": "Learning to guide task and motion planning using score-space representation", "abstract": "In this paper, we propose a learning algorithm that speeds up the search in task and motion planning problems. Our\nalgorithm proposes solutions to three different challenges that arise in learning to improve planning efficiency: what to\npredict, how to represent a planning problem instance, and how to transfer knowledge from one problem instance to\nanother. We propose a method that predicts constraints on the search space based on a generic representation of a\nplanning problem instance, called score-space, where we represent a problem instance in terms of the performance of\na set of solutions attempted so far. Using this representation, we transfer knowledge, in the form of constraints, from\nprevious problems based on the similarity in score space. We design a sequential algorithm that efficiently predicts\nthese constraints, and evaluate it in three different challenging task and motion planning problems. Results indicate\nthat our approach performs orders of magnitudes faster than an unguided planner."}}
