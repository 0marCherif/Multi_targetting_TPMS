{"id": "yEvznV_y5Of", "cdate": 1609459200000, "mdate": 1635872840755, "content": {"title": "DomiKnowS: A Library for Integration of Symbolic Domain Knowledge in Deep Learning", "abstract": "We demonstrate a library for the integration of domain knowledge in deep learning architectures. Using this library, the structure of the data is expressed symbolically via graph declarations and the logical constraints over outputs or latent variables can be seamlessly added to the deep models. The domain knowledge can be defined explicitly, which improves the models' explainability in addition to the performance and generalizability in the low-data regime. Several approaches for such an integration of symbolic and sub-symbolic models have been introduced; however, there is no library to facilitate the programming for such an integration in a generic way while various underlying algorithms can be used. Our library aims to simplify programming for such an integration in both training and inference phases while separating the knowledge representation from learning algorithms. We showcase various NLP benchmark tasks and beyond. The framework is publicly available at Github(https://github.com/HLR/DomiKnowS)."}}
{"id": "tFZqtUYkPdk", "cdate": 1609459200000, "mdate": 1635872840751, "content": {"title": "Latent Alignment of Procedural Concepts in Multimodal Recipes", "abstract": "We propose a novel alignment mechanism to deal with procedural reasoning on a newly released multimodal QA dataset, named RecipeQA. Our model is solving the textual cloze task which is a reading comprehension on a recipe containing images and instructions. We exploit the power of attention networks, cross-modal representations, and a latent alignment space between instructions and candidate answers to solve the problem. We introduce constrained max-pooling which refines the max-pooling operation on the alignment matrix to impose disjoint constraints among the outputs of the model. Our evaluation result indicates a 19\\% improvement over the baselines."}}
{"id": "pzdkgJjkwMM", "cdate": 1609459200000, "mdate": 1635872840755, "content": {"title": "Time-Stamped Language Model: Teaching Language Models to Understand The Flow of Events", "abstract": "Hossein Rajaby Faghihi, Parisa Kordjamshidi. Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. 2021."}}
{"id": "kP0suLVRpvD", "cdate": 1609459200000, "mdate": 1636851176137, "content": {"title": "Time-Stamped Language Model: Teaching Language Models to Understand the Flow of Events", "abstract": "Tracking entities throughout a procedure described in a text is challenging due to the dynamic nature of the world described in the process. Firstly, we propose to formulate this task as a question answering problem. This enables us to use pre-trained transformer-based language models on other QA benchmarks by adapting those to the procedural text understanding. Secondly, since the transformer-based language models cannot encode the flow of events by themselves, we propose a Time-Stamped Language Model~(TSLM model) to encode event information in LMs architecture by introducing the timestamp encoding. Our model evaluated on the Propara dataset shows improvements on the published state-of-the-art results with a $3.1\\%$ increase in F1 score. Moreover, our model yields better results on the location prediction task on the NPN-Cooking dataset. This result indicates that our approach is effective for procedural text understanding in general."}}
{"id": "hKbJGIqlDeb", "cdate": 1609459200000, "mdate": 1636851176136, "content": {"title": "Zero-Shot Compositional Concept Learning", "abstract": "In this paper, we study the problem of recognizing compositional attribute-object concepts within the zero-shot learning (ZSL) framework. We propose an episode-based cross-attention (EpiCA) network which combines merits of cross-attention mechanism and episode-based training strategy to recognize novel compositional concepts. Firstly, EpiCA bases on cross-attention to correlate concept-visual information and utilizes the gated pooling layer to build contextualized representations for both images and concepts. The updated representations are used for a more in-depth multi-modal relevance calculation for concept recognition. Secondly, a two-phase episode training strategy, especially the transductive phase, is adopted to utilize unlabeled test examples to alleviate the low-resource learning problem. Experiments on two widely-used zero-shot compositional learning (ZSCL) benchmarks have demonstrated the effectiveness of the model compared with recent approaches on both conventional and generalized ZSCL settings."}}
{"id": "a-YXBLSpsDi", "cdate": 1609459200000, "mdate": 1636851173625, "content": {"title": "Relational Gating for \"What If\" Reasoning", "abstract": "This paper addresses the challenge of learning to do procedural reasoning over text to answer \"What if...\" questions. We propose a novel relational gating network that learns to filter the key entities and relationships and learns contextual and cross representations of both procedure and question for finding the answer. Our relational gating network contains an entity gating module, relation gating module, and contextual interaction module. These modules help in solving the \"What if...\" reasoning problem. We show that modeling pairwise relationships helps to capture higher-order relations and find the line of reasoning for causes and effects in the procedural descriptions. Our proposed approach achieves the state-of-the-art results on the WIQA dataset."}}
{"id": "WhpCeh8WCGd", "cdate": 1609459200000, "mdate": 1636851173972, "content": {"title": "Relational Gating for \"What If\" Reasoning", "abstract": "This paper addresses the challenge of learning to do procedural reasoning over text to answer \"What if...\" questions. We propose a novel relational gating network that learns to filter the key entities and relationships and learns contextual and cross representations of both procedure and question for finding the answer. Our relational gating network contains an entity gating module, relation gating module, and contextual interaction module. These modules help in solving the \"What if...\" reasoning problem. We show that modeling pairwise relationships helps to capture higher-order relations and find the line of reasoning for causes and effects in the procedural descriptions. Our proposed approach achieves the state-of-the-art results on the WIQA dataset."}}
{"id": "S20jomSFK7B", "cdate": 1609459200000, "mdate": 1635872840751, "content": {"title": "SPARTQA: A Textual Question Answering Benchmark for Spatial Reasoning", "abstract": "Roshanak Mirzaee, Hossein Rajaby Faghihi, Qiang Ning, Parisa Kordjamshidi. Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. 2021."}}
{"id": "0rVliVcXKjd", "cdate": 1609459200000, "mdate": 1635872840754, "content": {"title": "SpartQA: : A Textual Question Answering Benchmark for Spatial Reasoning", "abstract": "This paper proposes a question-answering (QA) benchmark for spatial reasoning on natural language text which contains more realistic spatial phenomena not covered by prior work and is challenging for state-of-the-art language models (LM). We propose a distant supervision method to improve on this task. Specifically, we design grammar and reasoning rules to automatically generate a spatial description of visual scenes and corresponding QA pairs. Experiments show that further pretraining LMs on these automatically generated data significantly improves LMs' capability on spatial understanding, which in turn helps to better solve two external datasets, bAbI, and boolQ. We hope that this work can foster investigations into more sophisticated models for spatial reasoning over text."}}
{"id": "0RCnc84AR0W", "cdate": 1609459200000, "mdate": 1636851173439, "content": {"title": "Towards Navigation by Reasoning over Spatial Configurations", "abstract": "We deal with the navigation problem where the agent follows natural language instructions while observing the environment. Focusing on language understanding, we show the importance of spatial semantics in grounding navigation instructions into visual perceptions. We propose a neural agent that uses the elements of spatial configurations and investigate their influence on the navigation agent's reasoning ability. Moreover, we model the sequential execution order and align visual objects with spatial configurations in the instruction. Our neural agent improves strong baselines on the seen environments and shows competitive performance on the unseen environments. Additionally, the experimental results demonstrate that explicit modeling of spatial semantic elements in the instructions can improve the grounding and spatial reasoning of the model."}}
