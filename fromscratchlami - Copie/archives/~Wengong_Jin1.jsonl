{"id": "LI2bhrE_2A", "cdate": 1632875537465, "mdate": null, "content": {"title": "Iterative Refinement Graph Neural Network for Antibody Sequence-Structure Co-design", "abstract": "Antibodies are versatile proteins that bind to pathogens like viruses and stimulate the adaptive immune system. The specificity of antibody binding is determined by complementarity-determining regions (CDRs) at the tips of these Y-shaped proteins. In this paper, we propose a generative model to automatically design the CDRs of antibodies with enhanced binding specificity or neutralization capabilities. Previous generative approaches formulate protein design as a structure-conditioned sequence generation task, assuming the desired 3D structure is given a priori. In contrast, we propose to co-design the sequence and 3D structure of CDRs as graphs. Our model unravels a sequence autoregressively while iteratively refining its predicted global structure. The inferred structure in turn guides subsequent residue choices. For efficiency, we model the conditional dependence between residues inside and outside of a CDR in a coarse-grained manner. Our method achieves superior log-likelihood on the test set and outperforms previous baselines in designing antibodies capable of neutralizing the SARS-CoV-2 virus.\n"}}
{"id": "JywMsiz_NtO", "cdate": 1601308218920, "mdate": null, "content": {"title": "Enforcing Predictive Invariance across Structured Biomedical Domains", "abstract": "Many biochemical applications such as molecular property prediction require models to generalize beyond their training domains (environments). Moreover, natural environments in these tasks are structured, defined by complex descriptors such as molecular scaffolds or protein families. Therefore, most environments are either never seen during training, or contain only a single training example. To address these challenges, we propose a new regret minimization (RGM) algorithm and its extension for structured environments. RGM builds from invariant risk minimization (IRM) by recasting simultaneous optimality condition in terms of predictive regret, finding a representation that enables the predictor to compete against an oracle with hindsight access to held-out environments. The structured extension adaptively highlights variation due to complex environments via specialized domain perturbations. We evaluate our method on multiple applications: molecular property prediction, protein homology and stability prediction and show that RGM significantly outperforms previous state-of-the-art baselines."}}
{"id": "rylztAEYvr", "cdate": 1569439354402, "mdate": null, "content": {"title": "Iterative Target Augmentation for Effective Conditional Generation", "abstract": "Many challenging prediction problems, from molecular optimization to program synthesis, involve creating complex structured objects as outputs. However, available training data may not be sufficient for a generative model to learn all possible complex transformations. By leveraging the idea that evaluation is easier than generation, we show how a simple, broadly applicable, iterative target augmentation scheme can be surprisingly effective in guiding the training and use of such models. Our scheme views the generative model as a prior distribution, and employs a separately trained filter as the likelihood. In each augmentation step, we filter the model's outputs to obtain additional prediction targets for the next training epoch. Our method is applicable in the supervised as well as semi-supervised settings. We demonstrate that our approach yields significant gains over strong baselines both in molecular optimization and program synthesis. In particular, our augmented model outperforms the previous state-of-the-art in molecular optimization by over 10% in absolute gain. "}}
{"id": "rJeeKTNKDB", "cdate": 1569439096258, "mdate": null, "content": {"title": "Hierarchical Graph-to-Graph Translation for Molecules", "abstract": "The problem of accelerating drug discovery relies heavily on automatic tools to optimize precursor molecules to afford them with better biochemical properties. Our work in this paper substantially extends prior state-of-the-art on graph-to-graph translation methods for molecular optimization. In particular, we realize coherent multi-resolution representations by interweaving the encoding of substructure components with the atom-level encoding of the original molecular graph. Moreover, our graph decoder is fully autoregressive, and interleaves each step of adding a new substructure with the process of resolving its attachment to the emerging molecule. We evaluate our model on multiple molecular optimization tasks and show that our model significantly outperforms previous state-of-the-art baselines."}}
{"id": "rJxP6VuMYE", "cdate": 1554314431004, "mdate": null, "content": {"title": "Junction Tree Variational Autoencoder for Molecular Graph Generation", "abstract": ""}}
{"id": "S1eLYVufYV", "cdate": 1554314366292, "mdate": null, "content": {"title": "Predicting Organic Reaction Outcomes with Weisfeiler-Lehman Network", "abstract": ""}}
{"id": "rJgAMV_GK4", "cdate": 1554314262444, "mdate": null, "content": {"title": "Deriving Neural Architectures from Sequence and Graph Kernels", "abstract": ""}}
{"id": "By-7e2b_-S", "cdate": 1546300800000, "mdate": null, "content": {"title": "Functional Transparency for Structured Data: a Game-Theoretic Approach", "abstract": "We provide a new approach to training neural models to exhibit transparency in a well-defined, functional manner. Our approach naturally operates over structured data and tailors the predictor, fun..."}}
{"id": "B1xJAsA5F7", "cdate": 1538087878834, "mdate": null, "content": {"title": "Learning Multimodal Graph-to-Graph Translation for Molecule Optimization", "abstract": "We view molecule optimization as a graph-to-graph translation problem. The goal is to learn to map from one molecular graph to another with better properties based on an available corpus of paired molecules. Since molecules can be optimized in different ways, there are multiple viable translations for each input graph. A key challenge is therefore to model diverse translation outputs. Our primary contributions include a junction tree encoder-decoder for learning diverse graph translations along with a novel adversarial training method for aligning distributions of molecules. Diverse output distributions in our model are explicitly realized by low-dimensional latent vectors that modulate the translation process. We evaluate our model on multiple molecule optimization tasks and show that our model outperforms previous state-of-the-art baselines by a significant margin. \n"}}
{"id": "BJ-1Aj-OZB", "cdate": 1514764800000, "mdate": null, "content": {"title": "Junction Tree Variational Autoencoder for Molecular Graph Generation", "abstract": "We seek to automate the design of molecules based on specific chemical properties. In computational terms, this task involves continuous embedding and generation of molecular graphs. Our primary co..."}}
