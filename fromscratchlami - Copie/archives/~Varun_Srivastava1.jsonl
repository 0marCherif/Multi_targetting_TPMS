{"id": "XEBHPi6k_7R", "cdate": 1695553180279, "mdate": 1695553180279, "content": {"title": "Mode matching in GANs through latent space learning and inversion", "abstract": "Generative adversarial networks (GANs) have shown re-\nmarkable success in generation of unstructured data, such\nas, natural images. However, discovery and separation of\nmodes in the generated space, essential for several tasks\nbeyond naive data generation, is still a challenge. In this\npaper, we address the problem of imposing desired modal\nproperties on the generated space using a latent distribu-\ntion, engineered in accordance with the modal properties of\nthe true data distribution. This is achieved by training a la-\ntent space inversion network in tandem with the generative\nnetwork using a divergence loss. The latent space is made\nto follow a continuous multimodal distribution generated by\nreparameterization of a pair of continuous and discrete ran-\ndom variables. In addition, the modal priors of the latent\ndistribution are learned to match with the true data distri-\nbution using minimal-supervision with negligible increment\nin number of learnable parameters. We validate our method\non multiple tasks such as mode separation, conditional gen-\neration, and attribute discovery on multiple real world im-\nage datasets and demonstrate its ef\ufb01cacy over other state-\nof-the-art methods."}}
{"id": "mX9OCsQ0TrS", "cdate": 1546300800000, "mdate": 1668098827816, "content": {"title": "Detection of Glottal Closure Instants from Raw Speech Using Convolutional Neural Networks", "abstract": "Glottal Closure Instants (GCIs) correspond to the temporal locations of significant excitation to the vocal tract occurring during the production of voiced speech. GCI detection from speech signals is a well-studied problem given its importance in speech processing. Most of the existing approaches for GCI detection adopt a two-stage approach (i) Transformation of speech signal into a representative signal where GCIs are localized better, (ii) extraction of GCIs using the representative signal obtained in first stage. The former stage is accomplished using signal processing techniques based on the principles of speech production and the latter with heuristic-algorithms such as dynamic-programming and peak-picking. These methods are thus task-specific and rely on the methods used for representative signal extraction. However in this paper, we formulate the GCI detection problem from a representation learning perspective where appropriate representation is implicitly learned from the raw-speech data samples. Specifically, GCI detection is cast as a supervised multi-task learning problem solved using a deep convolutional neural network jointly optimizing a classification and regression cost. The learning capability is demonstrated with several experiments on standard datasets. The results compare well with the state-of- the-art algorithms while performing better in the case of presence of real-world non-stationary noise."}}
{"id": "C3vyerXBoP", "cdate": 1546300800000, "mdate": 1695554254598, "content": {"title": "Adversarial Approximate Inference for Speech to Electroglottograph Conversion", "abstract": "Speech produced by human vocal apparatus conveys substantial non-semantic information including the gender of the speaker, voice quality, affective state, abnormalities in the vocal apparatus etc. Such information is attributed to the properties of the voice source signal, which is usually estimated from the speech signal. However, most of the source estimation techniques depend heavily on the goodness of the model assumptions and are prone to noise. A popular alternative is to indirectly obtain the source information through the Electroglottographic (EGG) signal that measures the electrical admittance around the vocal folds using dedicated hardware. In this paper, we address the problem of estimating the EGG signal directly from the speech signal, devoid of any hardware. Sampling from the intractable conditional distribution of the EGG signal given the speech signal is accomplished through optimization of an evidence lower bound. This is constructed via minimization of the KL-divergence between the true and the approximated posteriors of a latent variable learned using a deep neural auto-encoder that serves an informative prior. We demonstrate the efficacy of the method at generating the EGG signal by conducting several experiments on datasets comprising multiple speakers, voice qualities, noise settings and speech pathologies. The proposed method is evaluated on many benchmark metrics and is found to agree with the gold standard while proving better than the state-of-the-art algorithms on a few tasks such as epoch extraction."}}
