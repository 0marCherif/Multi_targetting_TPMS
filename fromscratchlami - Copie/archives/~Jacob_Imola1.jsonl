{"id": "mA3vVbQDDP", "cdate": 1671901888808, "mdate": null, "content": {"title": "Differentially Private Triangle and 4-Cycle Counting in the Shuffle Model", "abstract": "Subgraph counting is fundamental for analyzing connection pat-\nterns or clustering tendencies in graph data. Recent studies have\napplied LDP (Local Differential Privacy) to subgraph counting to\nprotect user privacy even against a data collector in social net-\nworks. However, existing local algorithms suffer from extremely\nlarge estimation errors or assume multi-round interaction between\nusers and the data collector, which requires a lot of user effort and\nsynchronization.\nIn this paper, we focus on a one-round of interaction and propose\naccurate subgraph counting algorithms by introducing a recently\nstudied shuffle model. We first propose a basic technique called\nwedge shuffling to send wedge information, the main component of\nseveral subgraphs, with small noise. Then we apply our wedge shuf-\nfling to counting triangles and 4-cycles \u2013 basic subgraphs for analyz-\ning clustering tendencies \u2013 with several additional techniques. We\nalso show upper bounds on the estimation error for each algorithm.\nWe show through comprehensive experiments that our one-round\nshuffle algorithms significantly outperform the one-round local al-\ngorithms in terms of accuracy and achieve small estimation errors\nwith a reasonable privacy budget, e.g., smaller than 1 in edge DP."}}
{"id": "B0l8-wLjql5", "cdate": 1646077529133, "mdate": null, "content": {"title": "Balancing Utility and Scalability in Metric Differential Privacy", "abstract": "Metric differential privacy (mDP)  is a modification of differential privacy that is more suitable when records can be represented in a general metric space, such as text data represented as word embeddings or geographical coordinates on a map. We consider the task of releasing elements of the metric space under metric differential privacy where utility is measured as the distance of the released element to the original element. Linear programming (LP) can be used to construct a mechanism that achieves the optimal utility for a particular mDP constraint. However, these LPs suffer from a polynomial explosion of variables and constraints that render them impractical for solving real-world problems. An important question is how to design rigorous mDP mechanisms that balance the utility-scalability tradeoff.\n\nOur main contribution is a new method for reducing the LP size used to generate mDP mechanisms by constraining the search space such that certain input and output pairs have transition probabilities derived from the exponential mechanism. Our method produces mDP mechanisms whose LPs are smaller that all prior work in this area. We also provide a lower bound on the best possible mechanism utility. \nOur experiments on real-world metric spaces highlight the superior utility-scalability tradeoff of our mechanism."}}
{"id": "vT8xMfwrkXj", "cdate": 1609459200000, "mdate": 1630854074759, "content": {"title": "No-Substitution $k$-means Clustering with Low Center Complexity and Memory", "abstract": "We consider online $k$-means clustering where each new point is assigned to the nearest cluster center, after which the algorithm may update its centers. The loss incurred is the sum of squared distances from new points to their assigned cluster centers. The goal over a data stream $X$ is to achieve loss that is a constant factor of $L(X, OPT_k)$, the best possible loss using $k$ fixed points in hindsight. We propose a data parameter, $\\Lambda(X)$, such that for any algorithm maintaining $O(k\\text{poly}(\\log n))$ centers at time $n$, there exists a data stream $X$ for which a loss of $\\Omega(\\Lambda(X))$ is inevitable. We then give a randomized algorithm that achieves clustering loss $O(\\Lambda(X) + L(X, OPT_k))$. Our algorithm uses $O(k\\text{poly}(\\log n))$ memory and maintains $O(k\\text{poly}(\\log n))$ cluster centers. Our algorithm also enjoys a running time of $O(k\\text{poly}(\\log n))$ and is the first algorithm to achieve polynomial space and time complexity in this setting. It also is the first to have provable guarantees without making any assumptions on the input data."}}
{"id": "3TRupCsmhp_", "cdate": 1609459200000, "mdate": 1630854074740, "content": {"title": "Privacy Amplification Via Bernoulli Sampling", "abstract": "Balancing privacy and accuracy is a major challenge in designing differentially private machine learning algorithms. One way to improve this tradeoff for free is to leverage the noise in common data operations that already use randomness. Such operations include noisy SGD and data subsampling. The additional noise in these operations may amplify the privacy guarantee of the overall algorithm, a phenomenon known as privacy amplification. In this paper, we analyze the privacy amplification of sampling from a multidimensional Bernoulli distribution family given the parameter from a private algorithm. This setup has applications to Bayesian inference and to data compression. We provide an algorithm to compute the amplification factor, and we establish upper and lower bounds on this factor."}}
{"id": "M78oswp9b5", "cdate": 1577836800000, "mdate": 1630854074726, "content": {"title": "Locally Differentially Private Analysis of Graph Statistics", "abstract": "Differentially private analysis of graphs is widely used for releasing statistics from sensitive graphs while still preserving user privacy. Most existing algorithms however are in a centralized privacy model, where a trusted data curator holds the entire graph. As this model raises a number of privacy and security issues -- such as, the trustworthiness of the curator and the possibility of data breaches, it is desirable to consider algorithms in a more decentralized local model where no server holds the entire graph. In this work, we consider a local model, and present algorithms for counting subgraphs -- a fundamental task for analyzing the connection patterns in a graph -- with LDP (Local Differential Privacy). For triangle counts, we present algorithms that use one and two rounds of interaction, and show that an additional round can significantly improve the utility. For $k$-star counts, we present an algorithm that achieves an order optimal estimation error in the non-interactive local model. We provide new lower-bounds on the estimation error for general graph statistics including triangle counts and $k$-star counts. Finally, we perform extensive experiments on two real datasets, and show that it is indeed possible to accurately estimate subgraph counts in the local differential privacy model."}}
{"id": "SyfqPNBeIH", "cdate": 1567802466185, "mdate": null, "content": {"title": "Capacity Bounded Differential Privacy", "abstract": "Differential privacy, a notion of algorithmic stability, is a gold standard for  measuring the additional risk an algorithm's output poses to the privacy of a single record in the dataset. Differential privacy is defined as the distance between the output distribution of an algorithm on neighboring datasets that differ in one entry. In this work, we present a novel relaxation of differential privacy, capacity bounded differential privacy, where the adversary that distinguishes output distributions is assumed to be capacity-bounded -- i.e. bounded not in computational power, but in terms of the function class from which their attack algorithm is drawn. We model adversaries in terms of restricted f-divergences between probability distributions, and study properties of the definition and algorithms that satisfy them."}}
