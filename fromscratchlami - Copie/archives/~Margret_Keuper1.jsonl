{"id": "1zeYCAHHeqU", "cdate": 1698592730516, "mdate": 1698592730516, "content": {"title": "On the unreasonable vulnerability of transformers for image restoration - and an easy fix", "abstract": "Following their success in visual recognition tasks, Vision Transformers(ViTs) are being increasingly employed for image restoration. As a few recent works claim that ViTs for image classification also have better robustness properties, we investigate whether the improved adversarial robustness of ViTs extends to image restoration. We consider the recently proposed Restormer model, as well as NAFNet and the \"Baseline network\" which are both simplified versions of a Restormer. We use Projected Gradient Descent (PGD) and CosPGD for our robustness evaluation. Our experiments are performed on real-world images from the GoPro dataset for image deblurring. Our analysis indicates that contrary to as advocated by ViTs in image classification works, these models are highly susceptible to adversarial attacks. We attempt to find an easy fix and improve their robustness through adversarial training. While this yields a significant increase in robustness for Restormer, results on other networks are less promising. Interestingly, we find that the design choices in NAFNet and Baselines, which were based on i.i.d. performance, and not on robust generalization, seem to be at odds with the model robustness."}}
{"id": "LV-5kHj-uV5", "cdate": 1679417875598, "mdate": null, "content": {"title": "Differentiable Architecture Search: a One-Shot Method?", "abstract": "Differentiable architecture search (DAS) is a widely researched tool for the design of novel architectures. The main benefit of DAS is the effectiveness achieved through the weight-sharing one-shot paradigm, which allows efficient architecture search. In this work, we investigate DAS in a systematic case study of inverse problems, which allows us to analyze these potential benefits in a controlled manner. \nWe demonstrate that the success of DAS can be extended from image classification to signal reconstruction, in principle. However, our experiments also expose three fundamental difficulties in the evaluation of DAS-based methods in inverse problems: First, the results show a large variance in all test cases. Second, the final performance is strongly dependent on the hyperparameters of the optimizer. And third, the performance of the weight-sharing architecture used during training does not reflect the final performance of the found architecture well. While the results on image reconstruction confirm the potential of the DAS paradigm, they challenge the common understanding of DAS as a one-shot method."}}
{"id": "ps6fKUfn6W", "cdate": 1672531200000, "mdate": 1681545560957, "content": {"title": "Unfolding Local Growth Rate Estimates for (Almost) Perfect Adversarial Detection", "abstract": ""}}
{"id": "nyR_ULQIWT", "cdate": 1672531200000, "mdate": 1681545560956, "content": {"title": "FullFormer: Generating Shapes Inside Shapes", "abstract": ""}}
{"id": "n5M5NCxyFrC", "cdate": 1672531200000, "mdate": 1681545560956, "content": {"title": "An Extended Study of Human-like Behavior under Adversarial Training", "abstract": ""}}
{"id": "dvhPli2Y3GN", "cdate": 1672531200000, "mdate": 1681545560958, "content": {"title": "Higher-Order Multicuts for Geometric Model Fitting and Motion Segmentation", "abstract": ""}}
{"id": "_tGIE_4ZoY", "cdate": 1672531200000, "mdate": 1681545561196, "content": {"title": "CosPGD: a unified white-box adversarial attack for pixel-wise prediction tasks", "abstract": ""}}
{"id": "5YS7yrRu259", "cdate": 1672531200000, "mdate": 1681545560955, "content": {"title": "Intra-Source Style Augmentation for Improved Domain Generalization", "abstract": ""}}
{"id": "I9VZRzTSDNA", "cdate": 1668566308246, "mdate": 1668566308246, "content": {"title": "SP-ViT: Learning 2D Spatial Priors for Vision Transformers", "abstract": "Transformers have shown great potential in image classification and established state-of-the-art results on the ImageNet benchmark. In contrast to CNNs which leverage the local correlation properties of image content, the spatial arrangement of an image is dissolved in transformers at the input level. As a result, vision transformers (ViT) are initially unbiased in learning spatial relationships from data, where nearby pixels have the same chance of interacting as far away pixels and complex relationships can be learned more easily. Yet, due to their large capacity, ViTs converge more slowly and are prone to overfitting in low-data regimes. To overcome this limitation, we propose\nSpatial Prior \u2013 enhanced Self-Attention (SP-SA), a novel variant of Self-Attention (SA) tailored for ViTs. Unlike convolutional inductive biases, which focus exclusively on hard-coded local regions, the proposed Spatial Priors are learned by the model itself and take a variety of complementary spatial relations into account. Experiments show that SP-SA consistently improves the performance of ViT models. We denote the resulting models SP-ViT. Taking a recently proposed vision transformer LV-ViT as an example, when equipped with SP-SA, the largest model achieves a record-equalling 86.1% Top-1 accuracy with nearly halved parameters (150M SP-ViT-L\u2191384 vs 271M CaiT-M-36\u2191384) among all ImageNet-1K models trained on 224x224 and fine-tuned on 384x384 resolution w/o extra data."}}
{"id": "H4e48qrOtD", "cdate": 1667290350062, "mdate": 1667290350062, "content": {"title": "Uncertainty in Minimum Cost Multicuts for Image and Motion Segmentation", "abstract": "The minimum cost lifted multicut approach has proven practically good performance in a wide range of applications such as image decomposition, mesh segmentation, multiple object tracking, and motion segmentation. It addresses such problems in a graph-based model, where real-valued costs are assigned to the edges between entities such that the minimum cut decomposes the graph into an optimal number of segments. Driven by a probabilistic formulation of minimum cost multicuts, we provide a measure for the uncertainties of the decisions made during the optimization. We argue that access to such uncertainties is crucial for many practical applications and conduct an evaluation by means of sparsifications on three different, widely used datasets in the context of image decomposition (BSDS-500) and motion segmentation (DAVIS2016 and FBMS59) in terms of variation of information (VI) and Rand index (RI)."}}
