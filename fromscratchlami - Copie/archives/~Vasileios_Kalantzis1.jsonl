{"id": "w_QwPPZmqE", "cdate": 1640995200000, "mdate": 1683989777951, "content": {"title": "Towards Quantum Advantage on Noisy Quantum Computers", "abstract": "Quantum computers offer the potential of achieving significant speedup for certain computational problems. Yet, many existing quantum algorithms with notable asymptotic speedups require a degree of fault tolerance that is currently unavailable. The quantum algorithm for topological data analysis (TDA) by Lloyd et al. is believed to be one such algorithm. TDA is a powerful technique for extracting complex and valuable shape-related summaries of high-dimensional data. However, the computational demands of classical TDA algorithms are exorbitant, and become impractical for high-order characteristics. In this paper, we present NISQ-TDA, the first fully implemented end-to-end quantum machine learning algorithm needing only a short circuit-depth, that is applicable to non-handcrafted high-dimensional classical data, and with provable asymptotic speedup for certain classes of problems. The algorithm neither suffers from the data-loading problem nor does it need to store the input data on the quantum computer explicitly. Our approach includes three key innovations: an efficient realization of the full boundary operator; a quantum rejection sampling and projection approach to restrict a quantum state to the simplices of the desired order in the given complex; and a stochastic rank estimation method to estimate the topological features in the form of approximate Betti numbers. We present theoretical results that establish additive error guarantees, along with computational cost and circuit-depth complexities for normalized output estimates, up to the error tolerance. The algorithm was successfully executed on quantum computing devices, as well as on noisy quantum simulators, applied to small datasets. Preliminary empirical results suggest that the algorithm is robust to noise. Finally, we provide target depths and noise level estimates to realize near-term, non-fault-tolerant quantum advantage."}}
{"id": "reZYJezKbc", "cdate": 1640995200000, "mdate": 1647022048820, "content": {"title": "PCENet: High Dimensional Surrogate Modeling for Learning Uncertainty", "abstract": "Learning data representations under uncertainty is an important task that emerges in numerous machine learning applications. However, uncertainty quantification (UQ) techniques are computationally intensive and become prohibitively expensive for high-dimensional data. In this paper, we present a novel surrogate model for representation learning and uncertainty quantification, which aims to deal with data of moderate to high dimensions. The proposed model combines a neural network approach for dimensionality reduction of the (potentially high-dimensional) data, with a surrogate model method for learning the data distribution. We first employ a variational autoencoder (VAE) to learn a low-dimensional representation of the data distribution. We then propose to harness polynomial chaos expansion (PCE) formulation to map this distribution to the output target. The coefficients of PCE are learned from the distribution representation of the training data using a maximum mean discrepancy (MMD) approach. Our model enables us to (a) learn a representation of the data, (b) estimate uncertainty in the high-dimensional data system, and (c) match high order moments of the output distribution; without any prior statistical assumptions on the data. Numerical experimental results are presented to illustrate the performance of the proposed method."}}
{"id": "KXvx8Mk5Al", "cdate": 1640995200000, "mdate": 1672859561384, "content": {"title": "Directed Graph Auto-Encoders", "abstract": ""}}
{"id": "H_-WtyeMFb5", "cdate": 1640995200000, "mdate": 1647022048820, "content": {"title": "Directed Graph Auto-Encoders", "abstract": "We introduce a new class of auto-encoders for directed graphs, motivated by a direct extension of the Weisfeiler-Leman algorithm to pairs of node labels. The proposed model learns pairs of interpretable latent representations for the nodes of directed graphs, and uses parameterized graph convolutional network (GCN) layers for its encoder and an asymmetric inner product decoder. Parameters in the encoder control the weighting of representations exchanged between neighboring nodes. We demonstrate the ability of the proposed model to learn meaningful latent embeddings and achieve superior performance on the directed link prediction task on several popular network datasets."}}
{"id": "rW4ZKklMtb9", "cdate": 1609459200000, "mdate": 1647022048822, "content": {"title": "Solving sparse linear systems with approximate inverse preconditioners on analog devices", "abstract": "Sparse linear system solvers are computationally expensive kernels that lie at the heart of numerous applications. This paper proposes a preconditioning framework that combines approximate inverses with stationary iterations to substantially reduce the time and energy requirements of this task by utilizing a hybrid architecture that combines conventional digital microprocessors with analog crossbar array accelerators. Our analysis and experiments with a simulator for analog hardware show that an order of magnitude speedup is readily attainable despite the noise in analog computations."}}
{"id": "rL5ZY1gMtWc", "cdate": 1609459200000, "mdate": 1647022048823, "content": {"title": "Projection techniques to update the truncated SVD of evolving matrices with applications", "abstract": "This submission considers the problem of updating the rank-$k$ truncated Singular Value Decomposition (SVD) of matrices subject to the addition of new rows and/or columns over time. Such matrix pro..."}}
{"id": "S6PWYkxGtb9", "cdate": 1609459200000, "mdate": 1647022048821, "content": {"title": "Solving sparse linear systems with approximate inverse preconditioners on analog devices", "abstract": "Sparse linear system solvers are computationally expensive kernels that lie at the heart of numerous applications. This paper proposes a flexible preconditioning framework to substantially reduce the time and energy requirements of this task by utilizing a hybrid architecture that combines conventional digital microprocessors with analog crossbar array accelerators. Our analysis and experiments with a simulator for analog hardware demonstrate that an order of magnitude speedup is readily attainable without much impact on convergence, despite the noise in analog computations."}}
{"id": "rnGZFJefF-c", "cdate": 1514764800000, "mdate": 1647022048843, "content": {"title": "Do digital computers dream?", "abstract": "No abstract available."}}
{"id": "rTGWF1gGFZ5", "cdate": 1514764800000, "mdate": 1647022048843, "content": {"title": "The CS generation", "abstract": "No abstract available."}}
{"id": "HxbZFkeGFZc", "cdate": 1514764800000, "mdate": 1647022048824, "content": {"title": "Anonymity: from Plato to Tor", "abstract": "No abstract available."}}
