{"id": "Jq6SDnnPG5", "cdate": 1640995200000, "mdate": 1682370567063, "content": {"title": "Reflect, Not Reflex: Inference-Based Common Ground Improves Dialogue Response Quality", "abstract": ""}}
{"id": "CWcDW4cPRJI", "cdate": 1640995200000, "mdate": 1678111063981, "content": {"title": "Know Thy Strengths: Comprehensive Dialogue State Tracking Diagnostics", "abstract": ""}}
{"id": "3uGs-IxQu2N", "cdate": 1640995200000, "mdate": 1682370567068, "content": {"title": "Reflect, Not Reflex: Inference-Based Common Ground Improves Dialogue Response Quality", "abstract": "Human communication relies on common ground (CG), the mutual knowledge and beliefs shared by participants, to produce coherent and interesting conversations. In this paper, we demonstrate that current response generation (RG) models produce generic and dull responses in dialogues because they act reflexively, failing to explicitly model CG, both due to the lack of CG in training data and the standard RG training procedure. We introduce Reflect, a dataset that annotates dialogues with explicit CG (materialized as inferences approximating shared knowledge and beliefs) and solicits 9k diverse human-generated responses each following one common ground. Using Reflect, we showcase the limitations of current dialogue data and RG models: less than half of the responses in current data are rated as high quality (sensible, specific, and interesting) and models trained using this data have even lower quality, while most Reflect responses are judged high quality. Next, we analyze whether CG can help models produce better-quality responses by using Reflect CG to guide RG models. Surprisingly, we find that simply prompting GPT3 to \"think\" about CG generates 30% more quality responses, showing promising benefits to integrating CG into the RG process."}}
{"id": "t_lOAOt79eW", "cdate": 1609459200000, "mdate": 1682370567065, "content": {"title": "Agenda Pushing in Email to Thwart Phishing", "abstract": ""}}
{"id": "pSu_CvUnU7O", "cdate": 1609459200000, "mdate": 1682370567066, "content": {"title": "Probing Commonsense Explanation in Dialogue Response Generation", "abstract": ""}}
{"id": "41iYHIOGyF0", "cdate": 1609459200000, "mdate": 1670463497451, "content": {"title": "CheckDST: Measuring Real-World Generalization of Dialogue State Tracking Performance", "abstract": "Recent works that revealed the vulnerability of dialogue state tracking (DST) models to distributional shifts have made holistic comparisons on robustness and qualitative analyses increasingly important for understanding their relative performance. We present our findings from standardized and comprehensive DST diagnoses, which have previously been sparse and uncoordinated, using our toolkit, CheckDST, a collection of robustness tests and failure mode analytics. We discover that different classes of DST models have clear strengths and weaknesses, where generation models are more promising for handling language variety while span-based classification models are more robust to unseen entities. Prompted by this discovery, we also compare checkpoints from the same model and find that the standard practice of selecting checkpoints using validation loss/accuracy is prone to overfitting and each model class has distinct patterns of failure. Lastly, we demonstrate how our diagnoses motivate a pre-finetuning procedure with non-dialogue data that offers comprehensive improvements to generation models by alleviating the impact of distributional shifts through transfer learning."}}
{"id": "-RvGsYX3TwO", "cdate": 1609459200000, "mdate": 1682370567065, "content": {"title": "Viola: A Topic Agnostic Generate-and-Rank Dialogue System", "abstract": "We present Viola, an open-domain dialogue system for spoken conversation that uses a topic-agnostic dialogue manager based on a simple generate-and-rank approach. Leveraging recent advances of generative dialogue systems powered by large language models, Viola fetches a batch of response candidates from various neural dialogue models trained with different datasets and knowledge-grounding inputs. Additional responses originating from template-based generators are also considered, depending on the user's input and detected entities. The hand-crafted generators build on a dynamic knowledge graph injected with rich content that is crawled from the web and automatically processed on a daily basis. Viola's response ranker is a fine-tuned polyencoder that chooses the best response given the dialogue history. While dedicated annotations for the polyencoder alone can indirectly steer it away from choosing problematic responses, we add rule-based safety nets to detect neural degeneration and a dedicated classifier to filter out offensive content. We analyze conversations that Viola took part in for the Alexa Prize Socialbot Grand Challenge 4 and discuss the strengths and weaknesses of our approach. Lastly, we suggest future work with a focus on curating conversation data specifcially for socialbots that will contribute towards a more robust data-driven socialbot."}}
{"id": "uAbj7ztpgO", "cdate": 1577836800000, "mdate": 1682370567068, "content": {"title": "Grounding Conversations with Improvised Dialogues", "abstract": "Effective dialogue involves grounding, the process of establishing mutual knowledge that is essential for communication between people. Modern dialogue systems are not explicitly trained to build common ground, and therefore overlook this important aspect of communication. Improvisational theater (improv) intrinsically contains a high proportion of dialogue focused on building common ground, and makes use of the yes-and principle, a strong grounding speech act, to establish coherence and an actionable objective reality. We collect a corpus of more than 26,000 yes-and turns, transcribing them from improv dialogues and extracting them from larger, but more sparsely populated movie script dialogue corpora, via a bootstrapped classifier. We fine-tune chit-chat dialogue systems with our corpus to encourage more grounded, relevant conversation and confirm these findings with human evaluations."}}
{"id": "tBWLCRv2LE", "cdate": 1577836800000, "mdate": 1682370567065, "content": {"title": "Grounding Conversations with Improvised Dialogues", "abstract": ""}}
