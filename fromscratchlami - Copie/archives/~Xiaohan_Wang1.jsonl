{"id": "Z9FS-GRJi0", "cdate": 1577618818828, "mdate": null, "content": {"title": "[RE] Glyce: Glyph-vectors for Chinese Character Representations", "abstract": "Based on the Shannon AI team\u2019s study of Glyph-vectors for Chinese character and a series of NLP tasks, we implement 2 baselines reported in the original paper, BiLSTM-CRF and BERT and reproduce their results of Chinese NLP Tagging tasks on various datasets. We are unable to reproduce the results for BiLSTM-CRF. However, we obtain a similar result for BERT model. \nOn this basis, we undertake further experiments of hyper-parameter tuning and ablations on CRF$+$biLSTM and BERT, respectively.\nBy evaluating their performances, we compare and contrast how the components and hyper-parameters can affect the model's accuracy and robustness.\nWe discover that the implementation of BERT embedding as well as adding multiple layers or conditional random field (CRF)\ncan boost the model accuracy to a decent extent."}}
