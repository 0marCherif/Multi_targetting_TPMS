{"id": "2axZKrCSQ8HU", "cdate": 1664046171984, "mdate": null, "content": {"title": "Agent-based Graph Neural Networks", "abstract": "We present a novel graph neural network we call AgentNet, which is designed specifically for graph-level tasks. AgentNet is inspired by sublinear algorithms, featuring a computational complexity that is independent of the graph size. The architecture of AgentNet differs fundamentally from the architectures of traditional graph neural networks. In AgentNet, some trained \\textit{neural agents} intelligently walk the graph, and then collectively decide on the output. We provide an extensive theoretical analysis of AgentNet: We show that the agents can learn to systematically explore their neighborhood, and that AgentNet can distinguish some structures that are even indistinguishable by 3-WL. Moreover, AgentNet is able to separate any two graphs which are sufficiently different in terms of subgraphs. We confirm these theoretical results with synthetic experiments on hard-to-distinguish graphs and real-world graph classification tasks. In both cases, we compare favorably not only to standard GNNs but also to computationally more expensive GNN extensions."}}
{"id": "06erEMdoSml", "cdate": 1664046171322, "mdate": null, "content": {"title": "Diffusion Models for Graphs Benefit From Discrete State Spaces", "abstract": "Denoising diffusion probabilistic models and score-matching models have proven to be very powerful for generative tasks. While these approaches have also been applied to the generation of discrete graphs, they have, so far, relied on continuous Gaussian perturbations. Instead, in this work, we suggest using discrete noise for the forward Markov process. This ensures that in every intermediate step the graph remains discrete. Compared to the previous approach, our experimental results on four datasets and multiple architectures show that using a discrete noising process results in higher quality generated samples indicated with an average MMDs reduced by a factor of 1.5. Furthermore,  the number of denoising steps is reduced from 1000 to 32 steps leading to 30 times faster sampling procedure."}}
{"id": "9IlzJa5cAv", "cdate": 1663850401545, "mdate": null, "content": {"title": "DT+GNN: A Fully Explainable Graph Neural Network using Decision Trees", "abstract": "We propose a new Decision Tree Graph Neural Network (DT+GNN) architecture for Graph Neural Network (GNN) explanation. Existing post-hoc explanation methods highlight important inputs but fail to reveal how a GNN uses these inputs. In contrast DT+GNN is fully explainable: Humans can inspect and understand the decision making of DT+GNN at every step. DT+GNN internally uses a novel GNN layer that is restricted to categorical state spaces for nodes and messages. After training with gradient descent we can easily distill these layers into decision trees. These trees are further pruned using our newly proposed method to ensure they are small and easy to interpret. DT+GNN can also compute node-level importance scores like the existing explanation methods. We demonstrate on real-world GNN benchmarks that DT+GNN has competitive classification accuracy and computes competitive explanations. Furthermore, we leverage DT+GNN's full explainability to inspect the decision processes in synthetic and real-world datasets with surprising results. We make this inspection accessible through an interactive web tool."}}
{"id": "8WTAh0tj2jC", "cdate": 1663850031693, "mdate": null, "content": {"title": "Agent-based Graph Neural Networks", "abstract": "We present a novel graph neural network we call AgentNet, which is designed specifically for graph-level tasks. AgentNet is inspired by sublinear algorithms, featuring a computational complexity that is independent of the graph size. The architecture of AgentNet differs fundamentally from the architectures of traditional graph neural networks. In AgentNet, some trained \\textit{neural agents} intelligently walk the graph, and then collectively decide on the output. We provide an extensive theoretical analysis of AgentNet: We show that the agents can learn to systematically explore their neighborhood and that AgentNet can distinguish some structures that are even indistinguishable by 2-WL. Moreover, AgentNet is able to separate any two graphs which are sufficiently different in terms of subgraphs. We confirm these theoretical results with synthetic experiments on hard-to-distinguish graphs and real-world graph classification tasks. In both cases, we compare favorably not only to standard GNNs but also to computationally more expensive GNN extensions."}}
{"id": "CtsKBwhTMKg", "cdate": 1662812621950, "mdate": null, "content": {"title": "Diffusion Models for Graphs Benefit From Discrete State Spaces", "abstract": "Denoising diffusion probabilistic models and score-matching models have proven to be very powerful for generative tasks. While these approaches have also been applied to the generation of discrete graphs, they have, so far, relied on continuous Gaussian perturbations. Instead, in this work, we suggest using discrete noise for the forward Markov process. This ensures that in every intermediate step the graph remains discrete. Compared to the previous approach, our experimental results on four datasets and multiple architectures show that using a discrete noising process results in higher quality generated samples indicated with an average MMDs reduced by a factor of 1.5. Furthermore,  the number of denoising steps is reduced from 1000 to 32 steps leading to 30 times faster sampling procedure."}}
{"id": "sGTBSApDMT", "cdate": 1640995200000, "mdate": 1681649713351, "content": {"title": "Automating Rigid Origami Design", "abstract": ""}}
{"id": "_K-PB_b4gn", "cdate": 1640995200000, "mdate": 1681649713327, "content": {"title": "DT+GNN: A Fully Explainable Graph Neural Network using Decision Trees", "abstract": ""}}
{"id": "JCQw-09gHM", "cdate": 1640995200000, "mdate": 1681649713335, "content": {"title": "On Isotropy Calibration of Transformer Models", "abstract": ""}}
{"id": "CQ-yrN7pLT-", "cdate": 1640995200000, "mdate": 1681649713330, "content": {"title": "Diffusion Models for Graphs Benefit From Discrete State Spaces", "abstract": ""}}
{"id": "AVtCskM2i2b", "cdate": 1640995200000, "mdate": 1681649713490, "content": {"title": "Agent-based Graph Neural Networks", "abstract": ""}}
