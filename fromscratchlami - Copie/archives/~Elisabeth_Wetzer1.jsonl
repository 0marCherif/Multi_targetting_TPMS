{"id": "Xb5s7fkE6X", "cdate": 1672531200000, "mdate": 1681554733403, "content": {"title": "Can representation learning for multimodal image registration be improved by supervision of intermediate layers?", "abstract": ""}}
{"id": "anKFuh0Div", "cdate": 1640995200000, "mdate": 1681554733525, "content": {"title": "Cross-Modality Sub-Image Retrieval using Contrastive Multimodal Image Representations", "abstract": ""}}
{"id": "MILsihuMWzN", "cdate": 1620382533454, "mdate": null, "content": {"title": "Image Processing using Color Space Models for Forensic Fiber Detection", "abstract": "The purpose of this study is to investigate the feasibility of automating fiber analysis in forensic science applications. In order to make self-directed collection of spectral data possible the number of measuring locations needs to be restricted to fibers only. Full scans of the samples would result in very large amounts of data of which only a small part carries actual information about the objects of interest.\n\nImages obtained by optical microscopes are used for preprocessing to find suitable candidates for measuring locations that subsequently may be used to control the microscope stage for spectroscopic measurements. This paper presents a method based on a nonlinear transform known to enhance the contrast in a way that makes segmentation on grayscale images possible. It further introduces an approach using the differences between the color channels of RGB images combined with common morphological operators to segment color images. A third application is presented that enables the search for fibers matching a query object in color based attributes, for which it is necessary to consider multiple color models. This approach reduces time and efforts significantly when trying to match one specific fiber to other samples."}}
{"id": "l7aTDweQpm", "cdate": 1577836800000, "mdate": null, "content": {"title": "CoMIR: Contrastive Multimodal Image Representation for Registration", "abstract": "We propose contrastive coding to learn shared, dense image representations, referred to as CoMIRs (Contrastive Multimodal Image Representations). CoMIRs enable the registration of multimodal images where existing registration methods often fail due to a lack of sufficiently similar image structures. CoMIRs reduce the multimodal registration problem to a monomodal one, in which general intensity-based, as well as feature-based, registration algorithms can be applied. The method involves training one neural network per modality on aligned images, using a contrastive loss based on noise-contrastive estimation (InfoNCE). Unlike other contrastive coding methods, used for, e.g., classification, our approach generates image-like representations that contain the information shared between modalities. We introduce a novel, hyperparameter-free modification to InfoNCE, to enforce rotational equivariance of the learnt representations, a property essential to the registration task. We assess the extent of achieved rotational equivariance and the stability of the representations with respect to weight initialization, training set, and hyperparameter settings, on a remote sensing dataset of RGB and near-infrared images. We evaluate the learnt representations through registration of a biomedical dataset of bright-field and second-harmonic generation microscopy images; two modalities with very little apparent correlation. The proposed approach based on CoMIRs significantly outperforms registration of representations created by GAN-based image-to-image translation, as well as a state-of-the-art, application-specific method which takes additional knowledge about the data into account. Code is available at: https://github.com/MIDA-group/CoMIR."}}
{"id": "l4k8SAXFDfA", "cdate": 1577836800000, "mdate": null, "content": {"title": "When Texture Matters: Texture-Focused Cnns Outperform General Data Augmentation and Pretraining in Oral Cancer Detection", "abstract": "Early detection is essential to reduce cancer mortality. Oral cancer could be subject to screening programs (similar as for cervical cancer) by collecting Pap smear samples at any dentist visit. However, manual analysis of the resulting massive amount of data is prohibitively costly. Convolutional neural networks (CNNs) have shown promising results in discriminating between cancerous and non-cancerous cells, which enables efficient automated processing of cancer screening data. We investigate different CNN architectures which explicitly aim to utilize texture information, for cytological cancer classification, motivated by studies showing that chromatin texture is among the most important discriminative features for that purpose. Results show that CNN classifiers inspired by Local Binary Patterns (LBPs) achieve better performance than general purpose CNNs. This holds also when different levels of general data augmentation, as well as pretraining, are considered."}}
{"id": "k2HdiWxVlG1", "cdate": 1577836800000, "mdate": 1681554733402, "content": {"title": "CoMIR: Contrastive Multimodal Image Representation for Registration", "abstract": ""}}
{"id": "r1Z3KYZObr", "cdate": 1514764800000, "mdate": null, "content": {"title": "Towards Automated Multiscale Imaging and Analysis in TEM: Glomerulus Detection by Fusion of CNN and LBP Maps", "abstract": "Glomerulal structures in kidney tissue have to be analysed at a nanometer scale for several medical diagnoses. They are therefore commonly imaged using Transmission Electron Microscopy. The high resolution produces large amounts of data and requires long acquisition time, which makes automated imaging and glomerulus detection a desired option. This paper presents a deep learning approach for Glomerulus detection, using two architectures, VGG16 (with batch normalization) and ResNet50. To enhance the performance over training based only on intensity images, multiple approaches to fuse the input with texture information encoded in local binary patterns of different scales have been evaluated. The results show a consistent improvement in Glomerulus detection when fusing texture-based trained networks with intensity-based ones at a late classification stage."}}
