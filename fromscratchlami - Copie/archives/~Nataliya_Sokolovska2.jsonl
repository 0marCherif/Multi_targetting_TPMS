{"id": "rcUzWI8iqg5", "cdate": 1646077512710, "mdate": null, "content": {"title": "Learning Sparse Representations of Preferences within Choquet Expected Utility Theory", "abstract": "This paper deals with preference elicitation within Choquet Expected Utility (CEU) theory for decision making under uncertainty. We consider the Savage's framework with a finite set of states and assume that preferences of the Decision Maker over acts are observable. The CEU model involves two parameters that must be tuned to the value system of the decision maker: a set function (capacity) modeling weights attached to events, of size exponential in the number of states, and a utility function defined on the space of outcomes.  Our aim is to learn a sparse representation of the CEU model from preference data.  We propose and test a preference learning approach based on a spline representation of utilities and the sparse learning of capacities to obtain CEU models achieving a good tradeoff between the aim of sparsity and the expressivity required by preference data."}}
{"id": "siGsu1L_NG6", "cdate": 1577836800000, "mdate": null, "content": {"title": "Using Unlabeled Data to Discover Bivariate Causality with Deep Restricted Boltzmann Machines", "abstract": "An important question in microbiology is whether treatment causes changes in gut flora, and whether it also affects metabolism. The reconstruction of causal relations purely from non-temporal observational data is challenging. We address the problem of causal inference in a bivariate case, where the joint distribution of two variables is observed. We consider, in particular, data on discrete domains. The state-of-the-art causal inference methods for continuous data suffer from high computational complexity. Some modern approaches are not suitable for categorical data, and others need to estimate and fix multiple hyper-parameters. In this contribution, we introduce a novel method of causal inference which is based on the widely used assumption that if X causes Y, then P(X) and P(Y|X) are independent. We propose to explore a semi-supervised approach where P(Y|X) and P(X) are estimated from labeled and unlabeled data respectively, whereas the marginal probability is estimated potentially from much more (cheap unlabeled) data than the conditional distribution. We validate the proposed method on the standard cause-effect pairs. We illustrate by experiments on several benchmarks of biological network reconstruction that the proposed approach is very competitive in terms of computational time and accuracy compared to the state-of-the-art methods. Finally, we apply the proposed method to an original medical task where we study whether drugs confound human metagenome."}}
{"id": "YO_SmVyO_O", "cdate": 1577836800000, "mdate": null, "content": {"title": "A Principled Approach to Analyze Expressiveness and Accuracy of Graph Neural Networks", "abstract": "Graph neural networks (GNNs) have known an increasing success recently, with many GNN variants achieving state-of-the-art results on node and graph classification tasks. The proposed GNNs, however, often implement complex node and graph embedding schemes, which makes it challenging to explain their performance. In this paper, we investigate the link between a GNN\u2019s expressiveness, that is, its ability to map different graphs to different representations, and its generalization performance in a graph classification setting. In particular, we propose a principled experimental procedure where we (i) define a practical measure for expressiveness, (ii) introduce an expressiveness-based loss function that we use to train a simple yet practical GNN that is permutation-invariant, (iii) illustrate our procedure on benchmark graph classification problems and on an original real-world application. Our results reveal that expressiveness alone does not guarantee a better performance, and that a powerful GNN should be able to produce graph representations that are well separated with respect to the class of the corresponding graphs."}}
{"id": "qjIx-5GCvIr", "cdate": 1546300800000, "mdate": null, "content": {"title": "Interpretable Cascade Classifiers with Abstention", "abstract": "In many prediction tasks such as medical diagnostics, sequential decisions are crucial to provide optimal individual treatment. Budget in real-life applications is always limited, and it can represent any limited resource such as time, money, or side effects of medications. In this contribution, we develop a POMDP-based framework to learn cost-sensitive heterogeneous cascading systems. We provide both the theoretical support for the introduced approach and the intuition behind it. We evaluate our novel method on some standard benchmarks, and we discuss how the learned models can be interpreted by human experts."}}
{"id": "hOJUAdFscJ", "cdate": 1546300800000, "mdate": null, "content": {"title": "Disease Prediction Using Synthetic Image Representations of Metagenomic Data and Convolutional Neural Networks", "abstract": "Information from metagenomic data from human microbiome may improve diagnosis and prognosis for multiple human diseases. However, to achieve a prediction based on bacterial abundance information remains a challenge. Indeed, the number of features being much higher than the number of samples, we face difficulties related to high dimensional data processing, as well as overfitting. In this study, we investigate several convolutional neural network architectures for synthetic images and some experimental techniques to generate and train these synthetic images. We also explore supervised learning for visualizing high dimensional data that use data on genus, species and higher taxonomic level information. In addition, some dimensionality reduction approaches are examined on very high dimensional data such as gene families abundance. We evaluated our approach on six different metagenomic datasets including five types of diseases with more than 1000 samples. Our method displays promising results and can be used in different omics data settings, including integrative ones."}}
{"id": "OdMJ5aPTZBL", "cdate": 1546300800000, "mdate": null, "content": {"title": "Revealing causality between heterogeneous data sources with deep restricted Boltzmann machines", "abstract": "Highlights \u2022 Inferring causal relations between blocks of heterogeneous observations is challenging but possible. \u2022 A causal direction can be inferred from estimated marginal and conditional probabilities of random variables from a data set. \u2022 Conditional and marginal probability distributions can be estimated from data using deep restricted Boltzmann machines. \u2022 Distance correlation is used as the independence measure. Abstract In a number of real life applications, scientists do not have access to temporal data, since budget for data acquisition is always limited. Here we challenge the problem of causal inference between groups of heterogeneous non-temporal observations obtained from multiple sources. We consider a family of probabilistic algorithms for causal inference based on an assumption that in case where X causes Y, P ( X ) and P ( Y | X ) are statistically independent. For a number of real world applications, deep learning methods were reported to achieve the most accurate empirical performance, what motivates us to use deep Boltzmann machines to approximate the marginal and conditional probabilities of heterogeneous observations as accurate as possible. We introduce a novel algorithm to infer causal relationships between blocks of variables. The proposed method was tested on a benchmark of multivariate cause-effect pairs. We show by our experiments that our method achieves the state-of-the-art empirical accuracy, and sometimes outperforms the state-of-the-art methods. An important part of our contribution is an application of the proposed algorithm to an original medical data set, where we explore relations between alimentary patters, human gut microbiome composition, and health status. Previous article in issue Next article in issue"}}
{"id": "JKO_3oOf8Rr", "cdate": 1546300800000, "mdate": null, "content": {"title": "Robust structure measures of metabolic networks that predict prokaryotic optimal growth temperature", "abstract": "Background Metabolic networks reflect the relationships between metabolites (biomolecules) and the enzymes (proteins), and are of particular interest since they describe all chemical reactions of an organism. The metabolic networks are constructed from the genome sequence of an organism, and the graphs can be used to study fluxes through the reactions, or to relate the graph structure to environmental characteristics and phenotypes. About ten years ago, Takemoto et al. (2007) stated that the structure of prokaryotic metabolic networks represented as undirected graphs, is correlated to their living environment. Although metabolic networks are naturally directed graphs, they are still usually analysed as undirected graphs. Results We implemented a pipeline to reconstruct metabolic networks from genome data and confirmed some of the results of Takemoto et al. (2007) with today data using up-to-date databases. However, Takemoto et al. (2007) used only a fraction of all available enzymes from the genome and taking into account all the enzymes we fail to reproduce the main results. Therefore, we introduce three robust measures on directed representations of graphs, which lead to similar results regardless of the method of network reconstruction. We show that the size of the largest strongly connected component, the flow hierarchy and the Laplacian spectrum are strongly correlated to the environmental conditions. Conclusions We found a significant negative correlation between the size of the largest strongly connected component (a cycle) and the optimal growth temperature of the considered prokaryotes. This relationship holds true for the spectrum, high temperature being associated with lower eigenvalues. The hierarchy flow shows a negative correlation with optimal growth temperature. This suggests that the dynamical properties of the network are dependant on environmental factors."}}
{"id": "DzNvtGxDO6o", "cdate": 1546300800000, "mdate": null, "content": {"title": "CrystalGAN: Learning to Discover Crystallographic Structures with Generative Adversarial Networks", "abstract": ""}}
{"id": "esdryVlRMKU", "cdate": 1514764800000, "mdate": null, "content": {"title": "Disease Classification in Metagenomics with 2D Embeddings and Deep Learning", "abstract": "Deep learning (DL) techniques have shown unprecedented success when applied to images, waveforms, and text. Generally, when the sample size ($N$) is much bigger than the number of features ($d$), DL often outperforms other machine learning (ML) techniques, often through the use of Convolutional Neural Networks (CNNs). However, in many bioinformatics fields (including metagenomics), we encounter the opposite situation where $d$ is significantly greater than $N$. In these situations, applying DL techniques would lead to severe overfitting. Here we aim to improve classification of various diseases with metagenomic data through the use of CNNs. For this we proposed to represent metagenomic data as images. The proposed Met2Img approach relies on taxonomic and t-SNE embeddings to transform abundance data into \"synthetic images\". We applied our approach to twelve benchmark data sets including more than 1400 metagenomic samples. Our results show significant improvements over the state-of-the-art algorithms (Random Forest (RF), Support Vector Machine (SVM)). We observe that the integration of phylogenetic information alongside abundance data improves classification. The proposed approach is not only important in classification setting but also allows to visualize complex metagenomic data. The Met2Img is implemented in Python."}}
{"id": "aDsPTYfYvv8", "cdate": 1514764800000, "mdate": null, "content": {"title": "Risk Scores Learned by Deep Restricted Boltzmann Machines with Trained Interval Quantization", "abstract": "A compact easily applicable and highly accurate classification model is of a big interest in decision making. A simple scoring system which stratifies patients efficiently can help a clinician in diagnostics or with the choice of treatment. Deep learning methods are becoming the preferred approach for various applications in artificial intelligence and machine learning, since they usually achieve the best accuracy. However, deep learning models are complex systems with non-linear data transformation, what makes it challenging to use them as scoring systems. The state-of-the-art deep models are sparse, in particular, deep models with ternary weights are reported to be efficient in image processing. However, the ternary models seem to be not expressive enough in many tasks. In this contribution, we introduce an interval quantization method which learns both the codebook index and the codebook values, and results in a compact but powerful model. We show by experiments on several standard benchmarks that the proposed approach achieves the state-of-the-art performance in terms of generalizing accuracy, and outperforms modern approaches in terms of storage and computational efficiency. We also consider a real biomedical problem of a type 2 diabetes remission, and discuss how the trained model can be used as a predictive medical score, and be helpful for physicians."}}
