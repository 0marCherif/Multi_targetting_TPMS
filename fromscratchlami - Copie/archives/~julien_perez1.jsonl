{"id": "S1x63TEYvr", "cdate": 1569439156886, "mdate": null, "content": {"title": "Latent Question Reformulation and Information Accumulation for Multi-Hop Machine Reading", "abstract": "Multi-hop text-based question-answering is a current challenge in machine comprehension. \nThis task requires to sequentially integrate facts from multiple passages to answer complex natural language questions.\nIn this paper, we propose a novel architecture, called the Latent Question Reformulation Network (LQR-net), a multi-hop and parallel attentive network designed for question-answering tasks that require reasoning capabilities.\nLQR-net is composed of an association of \\textbf{reading modules} and \\textbf{reformulation modules}.\nThe purpose of the reading module is to produce a question-aware representation of the document.\nFrom this document representation, the reformulation module extracts essential elements to calculate an updated representation of the question.\nThis updated question is then passed to the following hop.\nWe evaluate our architecture on the \\hotpotqa question-answering dataset designed to assess multi-hop reasoning capabilities.\nOur model achieves competitive results on the public leaderboard and outperforms the best current \\textit{published} models in terms of Exact Match (EM) and $F_1$ score.\nFinally, we show that an analysis of the sequential reformulations can provide interpretable reasoning paths."}}
{"id": "B1xtFpVtvB", "cdate": 1569439105275, "mdate": null, "content": {"title": "Improving the Generalization of Visual Navigation Policies using Invariance Regularization", "abstract": "Training agents to operate in one environment often yields overfitted models that are unable to generalize to the changes in that environment. However, due to the numerous variations that can occur in the real-world, the agent is often required to be robust in order to be useful. This has not been the case for agents trained with reinforcement learning (RL) algorithms. In this paper, we investigate the overfitting of RL agents to the training environments in visual navigation tasks. Our experiments show that deep RL agents can overfit even when trained on multiple environments simultaneously. \nWe propose a regularization method which combines RL with supervised learning methods by adding a term to the RL objective that would encourage the invariance of a policy to variations in the observations that ought not to affect the action taken. The results of this method, called invariance regularization, show an improvement in the generalization of policies to environments not seen during training.\n"}}
{"id": "SJel4-c2j4", "cdate": 1557074215603, "mdate": null, "content": {"title": "Improving the Generalization of Visual Navigation Policies using Invariance Regularization", "abstract": "Training agents to operate in one environment often yields overfitted models that are unable to generalize to the changes in that environment. However, due to the numerous variations that can occur in the real-world, the agent is often required to be robust in order to be useful. This has not been the case for agents trained with reinforcement learning (RL) algorithms. In this paper, we investigate the overfitting of RL agents to the training environments in visual navigation tasks. Our experiments show that deep RL agents can overfit even when trained on multiple environments simultaneously. \nWe propose a regularization method which combines RL with supervised learning methods by adding a term to the RL objective that would encourage the invariance of a policy to variations in the observations that ought not to affect the action taken. The results of this method, called Invariance Regularization, show an improvement in the generalization of policies to environments not seen during training. The experimentation is done on the VizDoom environment which contains hundreds of textures, so allowing us to investigate generalization to changes in the visual observation."}}
{"id": "SkGH2oRcYX", "cdate": 1538087853458, "mdate": null, "content": {"title": "DEEP ADVERSARIAL FORWARD MODEL", "abstract": "Learning world dynamics has recently been investigated as a way to make reinforcement\nlearning (RL) algorithms to be more sample efficient and interpretable.\nIn this paper, we propose to capture an environment dynamics with a novel forward\nmodel that leverages recent works on adversarial learning and visual control. Such\na model estimates future observations conditioned on the current ones and other\ninput variables such as actions taken by an RL-agent. We focus on image generation\nwhich is a particularly challenging topic but our method can be adapted to\nother modalities. More precisely, our forward model is trained to produce realistic\nobservations of the future while a discriminator model is trained to distinguish\nbetween real images and the model\u2019s prediction of the future. This approach overcomes\nthe need to define an explicit loss function for the forward model which is currently\nused for solving such a class of problem. As a consequence, our learning protocol\ndoes not have to rely on an explicit distance such as Euclidean distance which\ntends to produce unsatisfactory predictions. To illustrate our method, empirical\nqualitative and quantitative results are presented on a real driving scenario, along\nwith qualitative results on Atari game Frostbite."}}
{"id": "Hy3MvSlRW", "cdate": 1518730183873, "mdate": null, "content": {"title": "Adversarial reading networks for machine comprehension", "abstract": "Machine reading has recently shown remarkable progress thanks to differentiable\nreasoning models. In this context, End-to-End trainable Memory Networks\n(MemN2N) have demonstrated promising performance on simple natural language\nbased reasoning tasks such as factual reasoning and basic deduction. However,\nthe task of machine comprehension is currently bounded to a supervised setting\nand available question answering dataset. In this paper we explore the paradigm\nof adversarial learning and self-play for the task of machine reading comprehension.\nInspired by the successful propositions in the domain of game learning, we\npresent a novel approach of training for this task that is based on the definition\nof a coupled attention-based memory model. On one hand, a reader network is\nin charge of finding answers regarding a passage of text and a question. On the\nother hand, a narrator network is in charge of obfuscating spans of text in order\nto minimize the probability of success of the reader. We experimented the model\non several question-answering corpora. The proposed learning paradigm and associated\nmodels present encouraging results."}}
{"id": "SJiHOSeR-", "cdate": 1518730183796, "mdate": null, "content": {"title": "Contextual memory bandit for pro-active dialog engagement", "abstract": "An objective of pro-activity in dialog systems is to enhance the usability of conversational\nagents by enabling them to initiate conversation on their own. While\ndialog systems have become increasingly popular during the last couple of years,\ncurrent task oriented dialog systems are still mainly reactive and users tend to\ninitiate conversations. In this paper, we propose to introduce the paradigm of contextual\nbandits as framework for pro-active dialog systems. Contextual bandits\nhave been the model of choice for the problem of reward maximization with partial\nfeedback since they fit well to the task description. As a second contribution,\nwe introduce and explore the notion of memory into this paradigm. We propose\ntwo differentiable memory models that act as parts of the parametric reward estimation\nfunction. The first one, Convolutional Selective Memory Networks, uses\na selection of past interactions as part of the decision support. The second model,\ncalled Contextual Attentive Memory Network, implements a differentiable attention\nmechanism over the past interactions of the agent. The goal is to generalize\nthe classic model of contextual bandits to settings where temporal information\nneeds to be incorporated and leveraged in a learnable manner. Finally, we illustrate\nthe usability and performance of our model for building a pro-active mobile\nassistant through an extensive set of experiments."}}
{"id": "HJZNNfzuWB", "cdate": 1420070400000, "mdate": null, "content": {"title": "Motivating Personality-aware Machine Translation", "abstract": "Language use is known to be influenced by personality traits as well as by sociodemographic characteristics such as age or mother tongue. As a result, it is possible to automatically identify these traits of the author from her texts. It has recently been shown that knowledge of such dimensions can improve performance in NLP tasks such as topic and sentiment modeling. We posit that machine translation is another application that should be personalized. In order to motivate this, we explore whether translation preserves demographic and psychometric traits. We show that, largely, both translation of the source training data into the target language, and the target test data into the source language has a detrimental effect on the accuracy of predicting author traits. We argue that this supports the need for personal and personality-aware machine translation models."}}
{"id": "HkWlLNWO-S", "cdate": 1230768000000, "mdate": null, "content": {"title": "Toward autonomic grids: analyzing the job flow with affinity streaming", "abstract": "The Affinity Propagation (AP) clustering algorithm proposed by Frey and Dueck (2007) provides an understandable, nearly optimal summary of a dataset, albeit with quadratic computational complexity. This paper, motivated by Autonomic Computing, extends AP to the data streaming framework. Firstly a hierarchical strategy is used to reduce the complexity to O(N1+\u03b5); the distortion loss incurred is analyzed in relation with the dimension of the data items. Secondly, a coupling with a change detection test is used to cope with non-stationary data distribution, and rebuild the model as needed. The presented approach StrAP is applied to the stream of jobs submitted to the EGEE Grid, providing an understandable description of the job flow and enabling the system administrator to spot online some sources of failures."}}
