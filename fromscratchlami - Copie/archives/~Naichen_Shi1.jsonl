{"id": "l5UNyaHqFdO", "cdate": 1652737636403, "mdate": null, "content": {"title": "Adam Can Converge Without Any Modification On Update Rules", "abstract": "Ever since \\citet{reddi2019convergence} pointed out the divergence issue of Adam, many new variants have been designed to obtain convergence. However, vanilla Adam remains exceptionally popular and it works well in practice. Why is there a gap between theory and practice? We point out there is a mismatch between the settings of theory and practice: \\citet{reddi2019convergence} pick the problem after picking the hyperparameters of Adam, i.e., $(\\beta_1,\\beta_2)$; while practical applications often fix the problem first and then tune $(\\beta_1,\\beta_2)$.   Due to this observation, we conjecture that the empirical convergence can be theoretically justified, only if we change the order of picking the problem and hyperparameter.  In this work, we confirm this conjecture.  We prove that, when the 2nd-order momentum parameter $\\beta_2$ is large and 1st-order momentum parameter $\\beta_1 < \\sqrt{\\beta_2}<1$, Adam converges to the neighborhood of critical points. The size of the neighborhood is propositional to the variance of stochastic gradients. Under an extra condition (strong growth condition), Adam converges to critical points. It is worth mentioning that our results cover a wide range of hyperparameters: as $\\beta_2$  increases, our convergence result can cover any $\\beta_1 \\in [0,1)$ including $\\beta_1=0.9$, which is the default setting in deep learning libraries. To our knowledge, this is the first result showing that Adam can converge {\\it without any modification} on its update rules. Further, our analysis does not require assumptions of bounded gradients or bounded 2nd-order momentum. When $\\beta_2$ is small, we further point out a large region of  $(\\beta_1,\\beta_2)$ combinations where  Adam can diverge to infinity. Our divergence result considers the same setting (fixing the optimization problem ahead) as our convergence result, indicating that there is a phase transition from divergence to convergence when increasing $\\beta_2$. These positive and negative results provide suggestions on how to tune Adam hyperparameters: for instance,  when Adam does not work well, we suggest tuning up $\\beta_2$ and trying $\\beta_1< \\sqrt{\\beta_2}$."}}
{"id": "KitjhnGfjf", "cdate": 1640995200000, "mdate": 1683641747059, "content": {"title": "Adam Can Converge Without Any Modification on Update Rules", "abstract": "Ever since Reddi et al. 2018 pointed out the divergence issue of Adam, many new variants have been designed to obtain convergence. However, vanilla Adam remains exceptionally popular and it works well in practice. Why is there a gap between theory and practice? We point out there is a mismatch between the settings of theory and practice: Reddi et al. 2018 pick the problem after picking the hyperparameters of Adam, i.e., $(\\beta_1, \\beta_2)$; while practical applications often fix the problem first and then tune $(\\beta_1, \\beta_2)$. Due to this observation, we conjecture that the empirical convergence can be theoretically justified, only if we change the order of picking the problem and hyperparameter. In this work, we confirm this conjecture. We prove that, when $\\beta_2$ is large and $\\beta_1 < \\sqrt{\\beta_2}<1$, Adam converges to the neighborhood of critical points. The size of the neighborhood is propositional to the variance of stochastic gradients. Under an extra condition (strong growth condition), Adam converges to critical points. It is worth mentioning that our results cover a wide range of hyperparameters: as $\\beta_2$ increases, our convergence result can cover any $\\beta_1 \\in [0,1)$ including $\\beta_1=0.9$, which is the default setting in deep learning libraries. To our knowledge, this is the first result showing that Adam can converge without any modification on its update rules. Further, our analysis does not require assumptions of bounded gradients or bounded 2nd-order momentum. When $\\beta_2$ is small, we further point out a large region of $(\\beta_1,\\beta_2)$ where Adam can diverge to infinity. Our divergence result considers the same setting as our convergence result, indicating a phase transition from divergence to convergence when increasing $\\beta_2$. These positive and negative results can provide suggestions on how to tune Adam hyperparameters."}}
{"id": "8kAn98Is1WG", "cdate": 1640995200000, "mdate": 1683641747139, "content": {"title": "Adam Can Converge Without Any Modification On Update Rules", "abstract": "Ever since \\citet{reddi2019convergence} pointed out the divergence issue of Adam, many new variants have been designed to obtain convergence. However, vanilla Adam remains exceptionally popular and it works well in practice. Why is there a gap between theory and practice? We point out there is a mismatch between the settings of theory and practice: \\citet{reddi2019convergence} pick the problem after picking the hyperparameters of Adam, i.e., $(\\beta_1,\\beta_2)$; while practical applications often fix the problem first and then tune $(\\beta_1,\\beta_2)$. Due to this observation, we conjecture that the empirical convergence can be theoretically justified, only if we change the order of picking the problem and hyperparameter. In this work, we confirm this conjecture. We prove that, when the 2nd-order momentum parameter $\\beta_2$ is large and 1st-order momentum parameter $\\beta_1 &lt; \\sqrt{\\beta_2}&lt;1$, Adam converges to the neighborhood of critical points. The size of the neighborhood is propositional to the variance of stochastic gradients. Under an extra condition (strong growth condition), Adam converges to critical points. It is worth mentioning that our results cover a wide range of hyperparameters: as $\\beta_2$ increases, our convergence result can cover any $\\beta_1 \\in [0,1)$ including $\\beta_1=0.9$, which is the default setting in deep learning libraries. To our knowledge, this is the first result showing that Adam can converge {\\it without any modification} on its update rules. Further, our analysis does not require assumptions of bounded gradients or bounded 2nd-order momentum. When $\\beta_2$ is small, we further point out a large region of $(\\beta_1,\\beta_2)$ combinations where Adam can diverge to infinity. Our divergence result considers the same setting (fixing the optimization problem ahead) as our convergence result, indicating that there is a phase transition from divergence to convergence when increasing $\\beta_2$. These positive and negative results provide suggestions on how to tune Adam hyperparameters: for instance, when Adam does not work well, we suggest tuning up $\\beta_2$ and trying $\\beta_1&lt; \\sqrt{\\beta_2}$."}}
{"id": "w-W8U4OJp2", "cdate": 1609459200000, "mdate": 1667382216859, "content": {"title": "Fed-ensemble: Improving Generalization through Model Ensembling in Federated Learning", "abstract": "In this paper we propose Fed-ensemble: a simple approach that bringsmodel ensembling to federated learning (FL). Instead of aggregating localmodels to update a single global model, Fed-ensemble uses random permutations to update a group of K models and then obtains predictions through model averaging. Fed-ensemble can be readily utilized within established FL methods and does not impose a computational overhead as it only requires one of the K models to be sent to a client in each communication round. Theoretically, we show that predictions on newdata from all K models belong to the same predictive posterior distribution under a neural tangent kernel regime. This result in turn sheds light onthe generalization advantages of model averaging. We also illustrate thatFed-ensemble has an elegant Bayesian interpretation. Empirical results show that our model has superior performance over several FL algorithms,on a wide range of data sets, and excels in heterogeneous settings often encountered in FL applications."}}
{"id": "bVwYF9MVQN", "cdate": 1609459200000, "mdate": 1683641747042, "content": {"title": "The Internet of Federated Things (IoFT)", "abstract": "The Internet of Things (IoT) is on the verge of a major paradigm shift. In the IoT system of the future, IoFT, the \u201ccloud\u201d will be substituted by the \u201ccrowd\u201d where model training is brought to the edge, allowing IoT devices to collaboratively extract knowledge and build smart analytics/models while keeping their personal data stored locally. This paradigm shift was set into motion by the tremendous increase in computational power on IoT devices and the recent advances in decentralized and privacy-preserving model training, coined as federated learning (FL). This article provides a vision for IoFT and a systematic overview of current efforts towards realizing this vision. Specifically, we first introduce the defining characteristics of IoFT and discuss FL data-driven approaches, opportunities, and challenges that allow decentralized inference within three dimensions: (i) a global model that maximizes utility across all IoT devices, (ii) a personalized model that borrows strengths across all devices yet retains its own model, (iii) a meta-learning model that quickly adapts to new devices or learning tasks. We end by describing the vision and challenges of IoFT in reshaping different industries through the lens of domain experts. Those industries include manufacturing, transportation, energy, healthcare, quality & reliability, business, and computing."}}
{"id": "IcLApand42", "cdate": 1609459200000, "mdate": 1683641747083, "content": {"title": "ScrofaZero: Mastering Trick-taking Poker Game Gongzhu by Deep Reinforcement Learning", "abstract": "People have made remarkable progress in game AIs, especially in domain of perfect information game. However, trick-taking poker game, as a popular form of imperfect information game, has been regarded as a challenge for a long time. Since trick-taking game requires high level of not only reasoning, but also inference to excel, it can be a new milestone for imperfect information game AI. We study Gongzhu, a trick-taking game analogous to, but slightly simpler than contract bridge. Nonetheless, the strategies of Gongzhu are complex enough for both human and computer players. We train a strong Gongzhu AI ScrofaZero from \\textit{tabula rasa} by deep reinforcement learning, while few previous efforts on solving trick-taking poker game utilize the representation power of neural networks. Also, we introduce new techniques for imperfect information game including stratified sampling, importance weighting, integral over equivalent class, Bayesian inference, etc. Our AI can achieve human expert level performance. The methodologies in building our program can be easily transferred into a wide range of trick-taking games."}}
{"id": "H9UZeB9bPg9", "cdate": 1609459200000, "mdate": 1645840952428, "content": {"title": "RMSprop converges with proper hyper-parameter", "abstract": "Despite the existence of divergence examples, RMSprop remains one of the most popular algorithms in machine learning. Towards closing the gap between theory and practice, we prove that RMSprop converges with proper choice of hyper-parameters under certain conditions. More specifically, we prove that when the hyper-parameter $\\beta_2$ is close enough to $1$, RMSprop and its random shuffling version converge to a bounded region in general, and to critical points in the interpolation regime. It is worth mentioning that our results do not depend on ``bounded gradient\" assumption, which is often the key assumption utilized by existing theoretical work for Adam-type adaptive gradient method. Removing this assumption allows us to establish a phase transition from divergence to non-divergence for RMSprop. Finally, based on our theory, we conjecture that in practice there is a critical threshold $\\sf{\\beta_2^*}$, such that RMSprop generates reasonably good results only if $1>\\beta_2\\ge \\sf{\\beta_2^*}$. We provide empirical evidence for such a phase transition in our numerical experiments."}}
{"id": "9UxiFVTK2HU", "cdate": 1609459200000, "mdate": 1683641747258, "content": {"title": "The Internet of Federated Things (IoFT): A Vision for the Future and In-depth Survey of Data-driven Approaches for Federated Learning", "abstract": "The Internet of Things (IoT) is on the verge of a major paradigm shift. In the IoT system of the future, IoFT, the cloud will be substituted by the crowd where model training is brought to the edge, allowing IoT devices to collaboratively extract knowledge and build smart analytics/models while keeping their personal data stored locally. This paradigm shift was set into motion by the tremendous increase in computational power on IoT devices and the recent advances in decentralized and privacy-preserving model training, coined as federated learning (FL). This article provides a vision for IoFT and a systematic overview of current efforts towards realizing this vision. Specifically, we first introduce the defining characteristics of IoFT and discuss FL data-driven approaches, opportunities, and challenges that allow decentralized inference within three dimensions: (i) a global model that maximizes utility across all IoT devices, (ii) a personalized model that borrows strengths across all devices yet retains its own model, (iii) a meta-learning model that quickly adapts to new devices or learning tasks. We end by describing the vision and challenges of IoFT in reshaping different industries through the lens of domain experts. Those industries include manufacturing, transportation, energy, healthcare, quality & reliability, business, and computing."}}
{"id": "3UDSdyIcBDA", "cdate": 1601308320419, "mdate": null, "content": {"title": "RMSprop converges with proper hyper-parameter", "abstract": "Despite the existence of divergence examples, RMSprop remains \none of the most popular algorithms in machine learning. Towards closing the gap between theory and practice, we prove that RMSprop converges with proper choice of hyper-parameters under certain conditions. More specifically, we prove that when the hyper-parameter $\\beta_2$ is close enough to $1$, RMSprop and its random shuffling version converge to a bounded region in general, and to critical points in the interpolation regime. It is worth mentioning that our results do not depend on  ``bounded gradient\"  assumption, which is often the key assumption utilized by existing theoretical work for Adam-type adaptive gradient method. Removing this assumption allows us to establish a phase transition from divergence to non-divergence for RMSprop. \n\nFinally, based on our theory, we conjecture that in practice there is a critical threshold $\\sf{\\beta_2^*}$, such that RMSprop generates reasonably good results only if $1>\\beta_2\\ge \\sf{\\beta_2^*}$. We provide empirical evidence for such a phase transition in our numerical experiments."}}
