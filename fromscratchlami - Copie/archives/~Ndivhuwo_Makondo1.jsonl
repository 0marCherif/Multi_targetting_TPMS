{"id": "9218OsdhFF", "cdate": 1706861547047, "mdate": 1706861547047, "content": {"title": "An Ensemble Approach for Automated Theorem Proving Based on Efficient Name Invariant Graph Neural Representations", "abstract": "Using reinforcement learning for automated theorem proving has recently received much attention. Current approaches use representations of logical statements that often rely on the names used in these statements and, as a result, the models are generally not transferable from one domain to another. The size of these representations and whether to include the whole theory or part of it are other important decisions that affect the performance of these approaches as well as their runtime efficiency. In this paper, we present NIAGRA; an ensemble Name InvAriant Graph RepresentAtion. NIAGRA addresses this problem by using 1) improved Graph Neural Networks for learning name-invariant formula representations that is tailored for their unique characteristics and 2) an efficient ensemble approach for automated theorem proving. Our experimental evaluation shows state-of-the-art performance on multiple datasets from different domains with improvements up to 10% compared to the best learning-based approaches. Furthermore, transfer learning experiments show that our approach significantly outperforms other learning-based approaches by up to 28%."}}
{"id": "-EnZkOVMPh", "cdate": 1706861472914, "mdate": 1706861472914, "content": {"title": "Self-Supervised Rule Learning to Link Text Segments to Relational Elements of Structured Knowledge", "abstract": "We present a neuro-symbolic approach to self-learn rules that serve as interpretable knowledge to perform relation linking in knowledge base question answering systems. These rules define natural language text predicates as a weighted mixture of knowledge base paths. The weights learned during training effectively serve the mapping needed to perform relation linking. We use popular masked training strategy to self-learn the rules. A key distinguishing aspect of our work is that the masked training operate over logical forms of the sentence instead of their natural language text form. This offers opportunity to extract extended context information from the structured knowledge source and use that to build robust and human readable rules. We evaluate accuracy and usefulness of such learned rules by utilizing them for prediction of missing kinship relation in CLUTRR dataset and relation linking in a KBQA system using SWQ-WD dataset. Results demonstrate the effectiveness of our approach - its generalizability, interpretability and ability to achieve an average performance gain of 17% on CLUTRR dataset."}}
{"id": "Xw3kb6UyA31", "cdate": 1633706938225, "mdate": null, "content": {"title": "Proof Extraction for Logical Neural Networks", "abstract": "Automated Theorem Provers (ATPs) are widely used for the verification of logicalstatements.  Explainability is one of the key advantages of ATPs:  providing anexpert readable proof path which shows the inference steps taken to concludecorrectness. Conversely, Neuro-Symbolic Networks (NSNs) that perform theoremproving, do not have this capability.  We propose a proof-tracing and filteringalgorithm to provide explainable reasoning in the case of Logical Neural Networks(LNNs), a special type of Neural-Theorem Prover (NTP)."}}
{"id": "HNJnbl1BlPR", "cdate": 1631185169372, "mdate": 1631185169372, "content": {"title": "Knowledge Transfer using Model-Based Deep Reinforcement Learning", "abstract": "Deep reinforcement learning has recently been adopted for robot behavior learning, where robot skills are\nacquired and adapted from data generated by the robot while interacting with its environment through a trial-and-error process. Despite this success, most model-free deep reinforcement learning algorithms learn a task-specific policy from a clean\nslate and thus suffer from high sample complexity (i.e., they require a significant amount of interaction with the environment to learn reasonable policies and even more to reach convergence). They also suffer from poor initial performance due to executing\na randomly initialized policy in the early stages of learning to obtain experience used to train a policy or value function. Modelbased deep reinforcement learning mitigates these shortcomings. However, it suffers from poor asymptotic performance in contrast\nto a model-free approach. In this work, we investigate knowledge transfer from a model-based teacher to a task-specific modelfree learner to alleviate executing a randomly initialized policy in the early stages of learning. Our experiments show that this approach results in better asymptotic performance, enhanced initial performance, improved safety, better action effectiveness, and reduced sample complexity."}}
{"id": "CTqLhjH3pZM", "cdate": 1631184881096, "mdate": 1631184881096, "content": {"title": "An Analysis of Reinforcement Learning for Malaria Control", "abstract": "Previous work on policy learning for Malaria control has often formulated the problem as an optimization problem assuming the objective function and the search space have a specific structure. The problem has been formulated as multi-armed bandits, contextual bandits and a Markov Decision Process in isolation. Furthermore, an emphasis is put on developing new algorithms specific to an instance of Malaria control, while ignoring a plethora of simpler and general algorithms in the literature. In this work, we formally study the formulation of Malaria control and present a comprehensive analysis of several formulations used in the literature. In addition, we implement and analyze several reinforcement learning algorithms in all formulations and compare them to black box optimization. In contrast to previous work, our results show that simple algorithms based on Upper Confidence Bounds are sufficient for learning good Malaria policies, and tend to outperform their more advanced counterparts on the malaria OpenAI Gym environment."}}
{"id": "QmfSzePb6mp", "cdate": 1609459200000, "mdate": 1625771381766, "content": {"title": "Learning to Guide a Saturation-Based Theorem Prover", "abstract": "Traditional automated theorem provers have relied on manually tuned heuristics to guide how they perform proof search. Recently, however, there has been a surge of interest in the design of learning mechanisms that can be integrated into theorem provers to improve their performance automatically. In this work, we introduce TRAIL, a deep learning-based approach to theorem proving that characterizes core elements of saturation-based theorem proving within a neural framework. TRAIL leverages (a) an effective graph neural network for representing logical formulas, (b) a novel neural representation of the state of a saturation-based theorem prover in terms of processed clauses and available actions, and (c) a novel representation of the inference selection process as an attention-based action policy. We show through a systematic analysis that these components allow TRAIL to significantly outperform previous reinforcement learning-based theorem provers on two standard benchmark datasets (up to 36% more theorems proved). In addition, to the best of our knowledge, TRAIL is the first reinforcement learning-based approach to exceed the performance of a state-of-the-art traditional theorem prover on a standard theorem proving benchmark (solving up to 17% more problems)."}}
{"id": "DAhG3YzTekF", "cdate": 1577836800000, "mdate": null, "content": {"title": "Question Answering over Knowledge Bases by Leveraging Semantic Parsing and Neuro-Symbolic Reasoning", "abstract": "Knowledge base question answering (KBQA)is an important task in Natural Language Processing. Existing approaches face significant challenges including complex question understanding, necessity for reasoning, and lack of large end-to-end training datasets. In this work, we propose Neuro-Symbolic Question Answering (NSQA), a modular KBQA system, that leverages (1) Abstract Meaning Representation (AMR) parses for task-independent question understanding; (2) a simple yet effective graph transformation approach to convert AMR parses into candidate logical queries that are aligned to the KB; (3) a pipeline-based approach which integrates multiple, reusable modules that are trained specifically for their individual tasks (semantic parser, entity andrelationship linkers, and neuro-symbolic reasoner) and do not require end-to-end training data. NSQA achieves state-of-the-art performance on two prominent KBQA datasets based on DBpedia (QALD-9 and LC-QuAD1.0). Furthermore, our analysis emphasizes that AMR is a powerful tool for KBQA systems."}}
{"id": "9_tgmRvMTlS", "cdate": 1577836800000, "mdate": null, "content": {"title": "Logical Neural Networks", "abstract": "We propose a novel framework seamlessly providing key properties of both neural nets (learning) and symbolic logic (knowledge and reasoning). Every neuron has a meaning as a component of a formula in a weighted real-valued logic, yielding a highly intepretable disentangled representation. Inference is omnidirectional rather than focused on predefined target variables, and corresponds to logical reasoning, including classical first-order logic theorem proving as a special case. The model is end-to-end differentiable, and learning minimizes a novel loss function capturing logical contradiction, yielding resilience to inconsistent knowledge. It also enables the open-world assumption by maintaining bounds on truth values which can have probabilistic semantics, yielding resilience to incomplete knowledge."}}
{"id": "r1gG5MWcDH", "cdate": 1569489546104, "mdate": null, "content": {"title": "Knowledge Transfer for Learning Robot Models via Local Procrustes Analysis", "abstract": "Learning of robot kinematic and dynamic models\nfrom data has attracted much interest recently as an alternative\nto manually defined models. However, the amount of data\nrequired to learn these models becomes large when the number\nof degrees of freedom increases and collecting it can be a timeintensive\nprocess. We employ transfer learning techniques in\norder to speed up learning of robot models, by using additional\ndata obtained from other robots. We propose a method for\napproximating non-linear mappings between manifolds, which\nwe call Local Procrustes Analysis (LPA), by adopting and\nextending the linear Procrustes Analysis method. Experimental\nresults indicate that the proposed method offers an accurate\ntransfer of data and significantly improves learning of the\nforward kinematics model. Furthermore, it allows learning\na global mapping between two robots that can be used to\nsuccessfully transfer trajectories."}}
{"id": "rkl6rzbqDH", "cdate": 1569489476607, "mdate": null, "content": {"title": "Accelerating model learning with inter-robot knowledge transfer", "abstract": "Online learning of a robot\u2019s inverse dynamics\nmodel for trajectory tracking necessitates an interaction between\nthe robot and its environment to collect training data.\nThis is challenging for physical robots in the real world,\nespecially for humanoids and manipulators due to their large\nand high dimensional state and action spaces, as a large amount\nof data must be collected over time. This can put the robot\nin danger when learning tabula rasa and can also be a timeintensive\nprocess especially in a multi-robot setting, where\neach robot is learning its model from scratch. We propose\naccelerating learning of the inverse dynamics model for trajectory\ntracking tasks in this multi-robot setting using knowledge\ntransfer, where robots share and re-use data collected by preexisting\nrobots, in order to speed up learning for new robots.\nWe propose a scheme for collecting a sample of correspondences\nfrom the robots for training transfer models, and demonstrate,\nin simulations, the benefit of knowledge transfer in accelerating\nonline learning of the inverse dynamics model between several\nrobots, including between a low-cost Interbotix PhantomX\nPincher arm, and a more expensive and relatively heavier Kuka\nyouBot arm. We show that knowledge transfer can save up to\n63% of training time of the youBot arm compared to learning\nfrom scratch, and about 58% for the lighter Pincher arm."}}
