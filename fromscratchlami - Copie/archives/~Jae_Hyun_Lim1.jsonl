{"id": "qj07D8bPt89", "cdate": 1622637626145, "mdate": null, "content": {"title": "A Variational Perspective on Diffusion-Based Generative Models and Score Matching", "abstract": "Discrete-time diffusion-based generative models and score matching methods have shown promising results in modeling high-dimensional image data. Recently, Song et al. (2021) show that diffusion processes can be reverted via learning the score function, i.e. the gradient of the log-density of the perturbed data. They propose to plug the learned score function into an inverse formula to define a generative diffusion process. Despite the empirical success, a theoretical underpinning of this procedure is still lacking. In this work, we approach the (continuous-time) generative diffusion directly and derive a variational framework for likelihood estimation, which includes continuous-time normalizing flows as a special case, and can be seen as an infinitely deep variational autoencoder. Under this framework, we show that minimizing the score-matching loss is equivalent to maximizing the ELBO of the plug-in reverse SDE proposed by Song et al. (2021), bridging the theoretical gap."}}
{"id": "bXehDYUjjXi", "cdate": 1621630337720, "mdate": null, "content": {"title": "A Variational Perspective on Diffusion-Based Generative Models and Score Matching", "abstract": "Discrete-time diffusion-based generative models and score matching methods have shown promising results in modeling high-dimensional image data. Recently, Song et al. (2021) show that diffusion processes that transform data into noise can be reversed via learning the score function, i.e. the gradient of the log-density of the perturbed data. They propose to plug the learned score function into an inverse formula to define a generative diffusion process. Despite the empirical success, a theoretical underpinning of this procedure is still lacking. In this work, we approach the (continuous-time) generative diffusion directly and derive a variational framework for likelihood estimation, which includes continuous-time normalizing flows as a special case, and can be seen as an infinitely deep variational autoencoder. Under this framework, we show that minimizing the score-matching loss is equivalent to maximizing a lower bound of the likelihood of the plug-in reverse SDE proposed by Song et al. (2021), bridging the theoretical gap."}}
{"id": "yALYfI1nPlA", "cdate": 1606146130575, "mdate": null, "content": {"title": "Bijective-Contrastive Estimation", "abstract": "In this work, we propose Bijective-Contrastive Estimation (BCE), a classification-based learning criterion for energy-based models. We generate a collection of contrasting distributions using bijections, and solve all the classification problems between the original data distribution and the distributions induced by the bijections using a classifier parameterized by an energy model. We show that if the classification objective is minimized, the energy function will uniquely recover the data density up to a normalizing constant. This has the benefit of not having to explicitly specify a contrasting distribution, like noise contrastive estimation. Experimentally, we demonstrate that the proposed method works well on 2D synthetic datasets. We discuss the difficulty in high dimensional cases, and propose potential directions to explore for future work."}}
{"id": "_u8m-zKQ1Ed", "cdate": 1577836800000, "mdate": null, "content": {"title": "AR-DAE: Towards Unbiased Neural Entropy Gradient Estimation", "abstract": "Entropy is ubiquitous in machine learning, but it is in general intractable to compute the entropy of the distribution of an arbitrary continuous random variable. In this paper, we propose the amortized residual denoising autoencoder (AR-DAE) to approximate the gradient of the log density function, which can be used to estimate the gradient of entropy. Amortization allows us to significantly reduce the error of the gradient approximator by approaching asymptotic optimality of a regular DAE, in which case the estimation is in theory unbiased. We conduct theoretical and experimental analyses on the approximation error of the proposed method, as well as extensive studies on heuristics to ensure its robustness. Finally, using the proposed gradient approximator to estimate the gradient of entropy, we demonstrate state-of-the-art performance on density estimation with variational autoencoders and continuous control with soft actor-critic."}}
{"id": "LEsUEUxqj3g", "cdate": 1577836800000, "mdate": null, "content": {"title": "AR-DAE: Towards Unbiased Neural Entropy Gradient Estimation", "abstract": "Entropy is ubiquitous in machine learning, but it is in general intractable to compute the entropy of the distribution of an arbitrary continuous random variable. In this paper, we propose the amor..."}}
{"id": "UNh4f0vRx2W", "cdate": 1546300800000, "mdate": null, "content": {"title": "Neural Multisensory Scene Inference", "abstract": "For embodied agents to infer representations of the underlying 3D physical world they inhabit, they should efficiently combine multisensory cues from numerous trials, e.g., by looking at and touching objects. Despite its importance, multisensory 3D scene representation learning has received less attention compared to the unimodal setting. In this paper, we propose the Generative Multisensory Network (GMN) for learning latent representations of 3D scenes which are partially observable through multiple sensory modalities. We also introduce a novel method, called the Amortized Product-of-Experts, to improve the computational efficiency and the robustness to unseen combinations of modalities at test time. Experimental results demonstrate that the proposed model can efficiently infer robust modality-invariant 3D-scene representations from arbitrary combinations of modalities and perform accurate cross-modal generation. To perform this exploration we have also developed a novel multi-sensory simulation environment for embodied agents."}}
{"id": "PJE_nIy-Cui", "cdate": 1483228800000, "mdate": null, "content": {"title": "Geometric GAN", "abstract": "Generative Adversarial Nets (GANs) represent an important milestone for effective generative models, which has inspired numerous variants seemingly different from each other. One of the main contributions of this paper is to reveal a unified geometric structure in GAN and its variants. Specifically, we show that the adversarial generative model training can be decomposed into three geometric steps: separating hyperplane search, discriminator parameter update away from the separating hyperplane, and the generator update along the normal vector direction of the separating hyperplane. This geometric intuition reveals the limitations of the existing approaches and leads us to propose a new formulation called geometric GAN using SVM separating hyperplane that maximizes the margin. Our theoretical analysis shows that the geometric GAN converges to a Nash equilibrium between the discriminator and generator. In addition, extensive numerical results show that the superior performance of geometric GAN."}}
{"id": "6lfAKXCuP96", "cdate": 1356998400000, "mdate": null, "content": {"title": "Multiple Kernel Learning with Hierarchical Feature Representations", "abstract": "In this paper, we suggest multiple kernel learning with hierarchical feature representations. Recently, deep learning represents excellent performance to extract hierarchical feature representations in unsupervised manner. However, since fine-tuning step of deep learning only considers global level of features for classification problems, it makes each layers hierarchical features intractable. Therefore, we propose a method to employ the combined multiple levels of pre-trained features via Multiple Kernel Learning (MKL). MKL is lately proposed optimization problem in classification and is applied to various machine learning problems. MKL automatically finds the best combination of kernels. By applying multiple kernel learning to hierarchical features pre-trained by deep learning, we obtain the optimal combinations of multiple levels of features for the classification task. Also, MKL is applied to analyze the contribution of each layer of features for classification by obtained weight of each kernel."}}
{"id": "GpvzfkCMIcr", "cdate": 1325376000000, "mdate": null, "content": {"title": "Reward hierarchical temporal memory", "abstract": "In humans and animals, reward prediction error encoded by dopamine systems is thought to be important in the temporal difference learning class of reinforcement learning (RL). With RL algorithms, many brain models have described the function of dopamine and related areas, including the basal ganglia and frontal cortex. In spite of this importance, how the reward prediction error itself is computed is not understood well, including the problem of how the current states are assigned to a memorized states and how the values of the states are memorized. In this paper, we describe a neocortical model for memorizing state space and computing reward prediction error, known as `reward hierarchical temporal memory' (rHTM). In this model, the temporal relationships among events are hierarchically stored. Using this memory, rHTM computes reward prediction errors by associating the memorized sequences to rewards and inhibits the predicted reward. In a simulation, our model behaved similarly to dopaminergic neurons. We suggest that our model can provide a hypothetical framework of interaction between cortex and dopamine neurons."}}
{"id": "1QJIQUtnoTo", "cdate": 1325376000000, "mdate": null, "content": {"title": "Learning spatio-temporally invariant representations from video", "abstract": "Learning invariant representations of environments through experience has been important area of research both in the field of machine learning as well as in computational neuroscience. In the present study, we propose a novel unsupervised method for the discovery of invariants from a single video input based on the learning of the spatio-temporal relationship of inputs. In an experiment, we tested the learning of spatio-temporal invariant features from a single video that involves rotational movements of faces of several subjects. From the results of this experiment, we demonstrate that the proposed system for the learning of invariants based on spatio-temporal continuity can be used as a compelling unsupervised method for learning invariants from an input that includes temporal information."}}
