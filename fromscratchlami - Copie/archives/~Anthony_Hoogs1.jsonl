{"id": "MUzkYtRZBcz", "cdate": 1672531200000, "mdate": 1682713145357, "content": {"title": "MEVID: Multi-view Extended Videos with Identities for Video Person Re-Identification", "abstract": "In this paper, we present the Multi-view Extended Videos with Identities (MEVID) dataset for large-scale, video person re-identification (ReID) in the wild. To our knowledge, MEVID represents the most-varied video person ReID dataset, spanning an extensive indoor and outdoor environment across nine unique dates in a 73-day window, various camera viewpoints, and entity clothing changes. Specifically, we label the identities of 158 unique people wearing 598 outfits taken from 8, 092 tracklets, average length of about 590 frames, seen in 33 camera views from the very-large-scale MEVA person activities dataset. While other datasets have more unique identities, MEVID emphasizes a richer set of information about each individual, such as: 4 outfits/identity vs. 2 outfits/identity in CCVID, 33 viewpoints across 17 locations vs. 6 in 5 simulated locations for MTA, and 10 million frames vs. 3 million for LS-VID. Being based on the MEVA video dataset, we also inherit data that is intentionally demographically balanced to the continental United States. To accelerate the annotation process, we developed a semi-automatic annotation framework and GUI that combines state-of-the-art real-time models for object detection, pose estimation, person ReID, and multi-object tracking. We evaluate several state-of-the-art methods on MEVID challenge problems and comprehensively quantify their robustness in terms of changes of outfit, scale, and background location. Our quantitative analysis on the realistic, unique aspects of MEVID shows that there are significant remaining challenges in video person ReID and indicates important directions for future research."}}
{"id": "An7uxf7xvVV", "cdate": 1672531200000, "mdate": 1682713145354, "content": {"title": "Reconstructing Humpty Dumpty: Multi-feature Graph Autoencoder for Open Set Action Recognition", "abstract": "Most action recognition datasets and algorithms assume a closed world, where all test samples are instances of the known classes. In open set problems, test samples may be drawn from either known or unknown classes. Existing open set action recognition methods are typically based on extending closed set methods by adding post hoc analysis of classification scores or feature distances and do not capture the relations among all the video clip elements. Our approach uses the reconstruction error to determine the novelty of the video since unknown classes are harder to put back together and thus have a higher reconstruction error than videos from known classes. We refer to our solution to the open set action recognition problem as \"Humpty Dumpty\", due to its reconstruction abilities. Humpty Dumpty is a novel graph-based autoencoder that accounts for contextual and semantic relations among the clip pieces for improved reconstruction. A larger reconstruction error leads to an increased likelihood that the action can not be reconstructed, i.e., can not put Humpty Dumpty back together again, indicating that the action has never been seen before and is novel/unknown. Extensive experiments are performed on two publicly available action recognition datasets including HMDB-51 and UCF-101, showing the state-of-the-art performance for open set action recognition."}}
{"id": "gyl1h6jPre", "cdate": 1667578140275, "mdate": 1667578140275, "content": {"title": "From Leaderboard To Operations: DIVA Transition Experiences", "abstract": "The IARPA Deep Intermodal Video Analytics (DIVA) program has sponsored the development of systems that detect and recognize activities in security video. During the period from September 2017 to March 2021, the development and evaluation of these systems was focused on optimizing accuracy, embodied in quantified metrics, against a large but relatively static corpus of video collected and annotated by the program. This focus was aided by various software engineering decisions collaboratively reached by the program performers and Test & Evaluation (T&E) team, which established a common software framework enabling ongoing quantitative evaluation via software submissions to a leaderboard. While continuing to support the leaderboard, in March 2021 the program began efforts, still in progress, to transition capabilities developed on DIVA from the research environment to operational evaluation and deployment. As an operational system is a different use case than a research environment, it is not surprising that design decisions favoring the former will not always align with the latter. This paper discusses our work to transition DIVA systems into an operational setting, particularly identifying and resolving conflicts between the evaluation framework and operational requirements. We describe transition efforts to date, propose future work, and conclude with lessons learned from the overall transition effort."}}
{"id": "l-2OMblIQXJ", "cdate": 1640995200000, "mdate": 1663255457067, "content": {"title": "Discover and Mitigate Unknown Biases with Debiasing Alternate Networks", "abstract": "Deep image classifiers have been found to learn biases from datasets. To mitigate the biases, most previous methods require labels of protected attributes (e.g., age, skin tone) as full-supervision, which has two limitations: 1) it is infeasible when the labels are unavailable; 2) they are incapable of mitigating unknown biases -- biases that humans do not preconceive. To resolve those problems, we propose Debiasing Alternate Networks (DebiAN), which comprises two networks -- a Discoverer and a Classifier. By training in an alternate manner, the discoverer tries to find multiple unknown biases of the classifier without any annotations of biases, and the classifier aims at unlearning the biases identified by the discoverer. While previous works evaluate debiasing results in terms of a single bias, we create Multi-Color MNIST dataset to better benchmark mitigation of multiple biases in a multi-bias setting, which not only reveals the problems in previous methods but also demonstrates the advantage of DebiAN in identifying and mitigating multiple biases simultaneously. We further conduct extensive experiments on real-world datasets, showing that the discoverer in DebiAN can identify unknown biases that may be hard to be found by humans. Regarding debiasing, DebiAN achieves strong bias mitigation performance."}}
{"id": "doc-DNLrVX2", "cdate": 1640995200000, "mdate": 1663255457146, "content": {"title": "1st ACM SIGKDD Workshop on Ethical Artificial Intelligence: Methods and Applications (EAI-KDD22)", "abstract": "Ethical AI has become increasingly important and it has been attracting attention from academia and industry, due to its increased popularity in real-world applications with fairness concerns. It also places fundamental importance on ethical considerations in determining legitimate and illegitimate uses of AI. Organizations that apply ethical AI have clearly stated well-defined review processes to ensure adherence to legal guidelines. Therefore, the wave of research at the intersection of ethical AI in data mining and machine learning has also influenced other fields of science, including computer vision, natural language processing, reinforcement learning, and social science. Despite these successes, ethical AI still faces many challenges. Consequently, there is an urgent need to bring experts and researchers together at prestigious venues to discuss ethical AI, which has been rarely seen in previous KDD conferences. This workshop will provide a premium platform for both research and industry from different backgrounds to exchange ideas on opportunities, challenges, and cutting-edge techniques in ethical AI."}}
{"id": "WkOdfgRRyvr", "cdate": 1640995200000, "mdate": 1663255457018, "content": {"title": "X-MIR: EXplainable Medical Image Retrieval", "abstract": "Despite significant progress in the past few years, machine learning systems are still often viewed as \"black boxes,\" which lack the ability to explain their output decisions. In high-stakes situations such as healthcare, there is a need for explainable AI (XAI) tools that can help open up this black box. In contrast to approaches which largely tackle classification problems in the medical imaging domain, we address the less-studied problem of explainable image retrieval. We test our approach on a COVID-19 chest X-ray dataset and the ISIC 2017 skin lesion dataset, showing that saliency maps help reveal the image features used by models to determine image similarity. We evaluated three different saliency algorithms, which were either occlusion-based, attention-based, or relied on a form of activation mapping. We also develop quantitative evaluation metrics that allow us to go beyond simple qualitative comparisons of the different saliency algorithms. Our results have the potential to aid clinicians when viewing medical images and addresses an urgent need for interventional tools in response to COVID-19. The source code is publicly available at: https://gitlab.kitware.com/brianhhu/x-mir."}}
{"id": "TbBlbY4OBRw", "cdate": 1640995200000, "mdate": 1663255457097, "content": {"title": "Doppelg\u00e4nger Saliency: Towards More Ethical Person Re-Identification", "abstract": "Modern surveillance systems have become increasingly dependent on artificial intelligence to provide actionable information for real-time decision making. A critical question relates to how these systems handle difficult ethical dilemmas, such as the re-identification of similar looking individuals. Potential misidentification of individuals can have severe negative consequences, as evidenced by recent headlines of individuals who were wrongly targeted for crimes they did not commit based on false matches. A computer vision-based saliency algorithm is proposed to help identify pixel-level differences in pairs of images containing visually similar individuals, which we term \"doppelg\u00e4ngers.\" The computed saliency maps can alert human users of the presence of doppelg\u00e4ngers and provide important visual evidence to reduce the potential of false matches in these high-stakes situations. We show both qualitative and quantitative saliency results on doppelg\u00e4ngers found in a video-based person re-identification dataset (MARS) using three different state-of-the-art models. Our results suggest that this novel use of visual saliency can improve overall outcomes by helping human users in the person re-identification setting, while assuring the ethical and trusted operation of surveillance systems."}}
{"id": "M-M0RazTmR", "cdate": 1640995200000, "mdate": 1663255457071, "content": {"title": "From Leaderboard To Operations: DIVA Transition Experiences", "abstract": "The IARPA Deep Intermodal Video Analytics (DIVA) program has sponsored the development of systems that detect and recognize activities in security video. During the period from September 2017 to March 2021, the development and evaluation of these systems was focused on optimizing accuracy, embodied in quantified metrics, against a large but relatively static corpus of video collected and annotated by the program. This focus was aided by various software engineering decisions collaboratively reached by the program performers and Test & Evaluation (T&E) team, which established a common software framework enabling ongoing quantitative evaluation via software submissions to a leaderboard. While continuing to support the leaderboard, in March 2021 the program began efforts, still in progress, to transition capabilities developed on DIVA from the research environment to operational evaluation and deployment. As an operational system is a different use case than a research environment, it is not surprising that design decisions favoring the former will not always align with the latter. This paper discusses our work to transition DIVA systems into an operational setting, particularly identifying and resolving conflicts between the evaluation framework and operational requirements. We describe transition efforts to date, propose future work, and conclude with lessons learned from the overall transition effort."}}
{"id": "I_uobsfXaoY", "cdate": 1640995200000, "mdate": 1668094722541, "content": {"title": "Novelty Detection in Remote Sensing Imagery", "abstract": "Object detection and classification in remote sensing imagery have been studied for decades, and has had a resurgence recently with significant improvements from deep learning. Most approaches follow the standard target recognition paradigm by assuming a fixed set of known object classes. The detector/classifier is trained on these, and attempts to disregard everything else. However, the real-world is complicated and unpredictable; often, there are new, interesting objects that are similar to known classes, but sufficiently different such that the system will (correctly) ignore them. The goal of novelty detection is to detect instances of new object types rather than misclassifying them as known types or background, while continuing to correctly classify instances of known object types. The primary challenge in novelty detection is determining how different a new image should be in order to be novel, vs. a new condition or variant of a known class. To address this, our method performs novelty detection in imagery using extreme value theory (EVT) operating in a CNN-based feature space. EVT characterizes the distribution of outliers in long-tailed distributions to identify novelties. We conducted experiments on the xView dataset for object detection and classification in satellite imagery, reducing it to a classification dataset by using its annotated bounding boxes on objects and holding out a set of 18 of its 60 classes as novelties. Our results indicate that EVT is effective at distinguishing novel from known object classes, even when novel classes are similar to known ones."}}
{"id": "Enmzm37jOB", "cdate": 1640995200000, "mdate": 1678392261129, "content": {"title": "Discover and Mitigate Unknown Biases with Debiasing Alternate Networks", "abstract": ""}}
