{"id": "KICUSNslb7Q", "cdate": 1663849955710, "mdate": null, "content": {"title": "Union Subgraph Neural Networks", "abstract": "Graph Neural Networks (GNNs) are widely used for graph representation learning in many application domains. The expressiveness of GNNs is upper-bounded by 1-dimensional Weisfeiler-Lehman (1-WL) test as they operate on rooted subtrees in message passing. In this paper, we empower GNNs by injecting neighbor-connectivity information extracted from a new type of substructures. We first investigate different kinds of connectivities existing in a local neighborhood and identify a substructure called union subgraph, which is able to capture the complete picture of the neighborhood. We then design a shortest-path-based substructure descriptor that possesses three nice properties and can effectively encode the high-order connectivities in union subgraphs. By infusing the encoded neighbor connectivities, we propose a novel model, namely Union Subgraph Neural Network (UnionSNN), which is proven to be strictly more powerful than 1-WL in distinguishing non-isomorphic graphs. Our extensive experiments on both graph-level and node-level classification tasks demonstrate that UnionSNN outperforms state-of-the-art baseline models, with competitive computational efficiency.\n"}}
{"id": "9HFobmKAmGv", "cdate": 1663849856968, "mdate": null, "content": {"title": "A Class-Aware Representation Refinement Framework for Graph Classification", "abstract": "Graph Neural Networks (GNNs) are widely used for graph representation learning. Despite its prevalence, GNN suffers from two drawbacks in the graph classification task, the neglect of graph-level relationships, and the generalization issue. Each graph is treated separately in GNN message passing/graph pooling, and existing methods to address overfitting operate on each individual graph. This makes the graph representations learnt less effective in the downstream classification. In this paper, we propose a Class-Aware Representation rEfinement (CARE) framework for the task of graph classification. CARE computes simple yet powerful class representations and injects them to steer the learning of graph representations towards better class separability. CARE is a plug-and-play framework that is highly flexible and able to incorporate arbitrary GNN backbones without significantly increasing the computational cost. We also theoretically prove that CARE has a better generalization upper bound than its GNN backbone through Vapnik-Chervonenkis (VC) dimension analysis. Our extensive experiments with 10 well-known GNN backbones on 9 benchmark datasets validate the superiority and effectiveness of CARE over its GNN counterparts."}}
{"id": "WW5TaISMRVB", "cdate": 1640995200000, "mdate": 1681697906439, "content": {"title": "A Class-Aware Representation Refinement Framework for Graph Classification", "abstract": "Graph Neural Networks (GNNs) are widely used for graph representation learning. Despite its prevalence, GNN suffers from two drawbacks in the graph classification task, the neglect of graph-level relationships, and the generalization issue. Each graph is treated separately in GNN message passing/graph pooling, and existing methods to address overfitting operate on each individual graph. This makes the graph representations learnt less effective in the downstream classification. In this paper, we propose a Class-Aware Representation rEfinement (CARE) framework for the task of graph classification. CARE computes simple yet powerful class representations and injects them to steer the learning of graph representations towards better class separability. CARE is a plug-and-play framework that is highly flexible and able to incorporate arbitrary GNN backbones without significantly increasing the computational cost. We also theoretically prove that CARE has a better generalization upper bound than its GNN backbone through Vapnik-Chervonenkis (VC) dimension analysis. Our extensive experiments with 10 well-known GNN backbones on 9 benchmark datasets validate the superiority and effectiveness of CARE over its GNN counterparts."}}
{"id": "L6uD0y18j7x", "cdate": 1640995200000, "mdate": 1681697906563, "content": {"title": "Data-Driven Network Neuroscience: On Data Collection and Benchmark", "abstract": "This paper presents a comprehensive and quality collection of functional human brain network data for potential research in the intersection of neuroscience, machine learning, and graph analytics. Anatomical and functional MRI images of the brain have been used to understand the functional connectivity of the human brain and are particularly important in identifying underlying neurodegenerative conditions such as Alzheimer's, Parkinson's, and Autism. Recently, the study of the brain in the form of brain networks using machine learning and graph analytics has become increasingly popular, especially to predict the early onset of these conditions. A brain network, represented as a graph, retains richer structural and positional information that traditional examination methods are unable to capture. However, the lack of brain network data transformed from functional MRI images prevents researchers from data-driven explorations. One of the main difficulties lies in the complicated domain-specific preprocessing steps and the exhaustive computation required to convert data from MRI images into brain networks. We bridge this gap by collecting a large amount of available MRI images from existing studies, working with domain experts to make sensible design choices, and preprocessing the MRI images to produce a collection of brain network datasets. The datasets originate from 5 different sources, cover 3 neurodegenerative conditions, and consist of a total of 2,642 subjects. We test our graph datasets on 5 machine learning models commonly used in neuroscience and on a recent graph-based analysis model to validate the data quality and to provide domain baselines. To lower the barrier to entry and promote the research in this interdisciplinary field, we release our brain network data https://doi.org/10.17608/k6.auckland.21397377 and complete preprocessing details including codes."}}
{"id": "PrqCmK6zKe0", "cdate": 1594396080449, "mdate": null, "content": {"title": "Reachability and Time-Based Path Queries in Temporal Graphs", "abstract": "A temporal graph is a graph in which vertices communicate with each other at specific time, e.g., A calls B at 11 a.m. and talks for 7 minutes, which is modeled by an edge from A to B with starting time \u201c11 a.m.\u201d and duration \u201c7 mins\u201d. Temporal graphs can be used to model many networks with time-related activities, but efficient algorithms for analyzing temporal graphs are severely inadequate. We study fundamental problems such as answering reachability and time-based path queries in a temporal graph, and propose an efficient indexing technique specifically designed for processing these queries in a temporal graph. Our results show that our method is efficient and scalable in both index construction and query processing."}}
{"id": "bT91Fl68foz", "cdate": 1577836800000, "mdate": null, "content": {"title": "Subdomain Adaptation with Manifolds Discrepancy Alignment", "abstract": "Reducing domain divergence is a key step in transfer learning problems. Existing works focus on the minimization of global domain divergence. However, two domains may consist of several shared subdomains, and differ from each other in each subdomain. In this paper, we take the local divergence of subdomains into account in transfer. Specifically, we propose to use low-dimensional manifold to represent subdomain, and align the local data distribution discrepancy in each manifold across domains. A Manifold Maximum Mean Discrepancy (M3D) is developed to measure the local distribution discrepancy in each manifold. We then propose a general framework, called Transfer with Manifolds Discrepancy Alignment (TMDA), to couple the discovery of data manifolds with the minimization of M3D. We instantiate TMDA in the subspace learning case considering both the linear and nonlinear mappings. We also instantiate TMDA in the deep learning framework. Extensive experimental studies demonstrate that TMDA is a promising method for various transfer learning tasks."}}
{"id": "UDmQMQoUrMK", "cdate": 1577836800000, "mdate": null, "content": {"title": "Tweedie-Hawkes Processes: Interpreting the Phenomena of Outbreaks", "abstract": "Self-exciting event sequences, in which the occurrence of an event increases the probability of triggering subsequent ones, are common in many disciplines. In this paper, we propose a Bayesian model called Tweedie-Hawkes Processes (THP), which is able to model the outbreaks of events and find out the dominant factors behind. THP leverages on the Tweedie distribution in capturing various excitation effects. A variational EM algorithm is developed for model inference. Some theoretical properties of THP, including the sub-criticality, convergence of the learning algorithm and kernel selection method are discussed. Applications to Epidemiology and information diffusion analysis demonstrate the versatility of our model in various disciplines. Evaluations on real-world datasets show that THP outperforms the rival state-of-the-art baselines in the task of forecasting future events."}}
{"id": "LRR3gdLwn_", "cdate": 1577836800000, "mdate": null, "content": {"title": "Adaptive Knowledge Transfer based on Transfer Neural Kernel Network", "abstract": "Transfer agents are widely used in the challenging problems where knowledge is cross-used among different tasks. One popular research approach is to design a transfer kernel that controls the strength of knowledge transfer based on the similarity of tasks. In this paper, we propose a Transfer Neural Kernel Network (TNKN), which enables flexible modeling of the task similarity. The proposed TNKN is constructed by compositions of primitive kernels and represented by a neural network. Two coupled compositional kernel structures are used to characterize data covariance, one for the intra-task data covariance and another for the inter-task one. A sufficient condition that validates the transfer agent using TNKN for any data is given. This condition also discloses the relationship of the two compositional kernel structures, and can be used as a constraint in the agent learning. Since the overall architecture of TNKN is differentiable, the learning of the transfer agent using TNKN is end-to-end trainable with gradient-based optimization. Extensive experiments on various real-world datasets demonstrate the transfer effectiveness of TNKN."}}
{"id": "ackqEpL7h8m", "cdate": 1546300800000, "mdate": null, "content": {"title": "A General Domain Specific Feature Transfer Framework for Hybrid Domain Adaptation", "abstract": "Heterogeneous domain adaptation needs supplementary information to link up different domains. However, such supplementary information may not always be available in real cases. In this paper, a new problem setting called hybrid domain adaptation is investigated. It is a special case of heterogeneous domain adaptation, in which different domains share some common features, but also have their own domain specific features. We leverage upon common features instead of supplementary information to achieve effective adaptation. We propose a general domain specific feature transfer framework, which can link up different domains using common features and simultaneously reduce domain divergences. Specifically, we learn the translations between common features and domain specific features. Then, we cross-use the learned translations to transfer the domain specific features of one domain to another domain. Finally, we compose a homogeneous space in which the domain divergences are minimized. We instantiate the general framework to a linear case and a nonlinear case. Extensive experiments verify the effectiveness of the two cases."}}
{"id": "VWflPfLnvork", "cdate": 1546300800000, "mdate": null, "content": {"title": "Knowledge Transfer based on Multiple Manifolds Assumption", "abstract": "Unsupervised domain adaptation is a popular but challenging problem setting. Existing unsupervised domain adaptation methods are based on the single manifold assumption, i.e., data are sampled from a single low-dimensional manifold, and thus may not well capture the complex characteristic of the real-world data. In this paper, we propose to transfer knowledge across domains under the multiple manifolds assumption that assumes the data are sampled from multiple low-dimensional manifolds. Specifically, we develop a multiple manifolds information transfer framework (MMIT). The proposed MMIT aims to transfer the multiple manifolds information, which is represented by the data manifold neighborhood structure, with the the best adaptation capacity. To do so, we propose to couple the multiple manifolds information transfer with the domain distribution discrepancy minimization in the adaptation procedure. Experimental studies demonstrate that MMIT achieves the promising adaptation performance on various real-world adaptation tasks."}}
