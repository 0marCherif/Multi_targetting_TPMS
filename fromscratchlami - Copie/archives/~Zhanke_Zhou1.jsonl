{"id": "MWGDhOQkr3", "cdate": 1663850317763, "mdate": null, "content": {"title": "Towards Reliable Link Prediction with Robust Graph Information Bottleneck", "abstract": "Link prediction on graphs has achieved great success with the rise of deep graph learning. However, the potential robustness under the edge noise is less investigated. We reveal that the inherent edge noise that naturally perturbs both input topology and target label leads to severe performance degradation and representation collapse. Here, we propose an information-theory guided principle, Robust Graph Information Bottleneck (RGIB), to extract reliable supervision signals and avoid representation collapse. Different from the general information bottleneck, RGIB decouples and balances the mutual dependence among graph topology, edge label, and representation, building a new learning objective for robust representation. We also provide two implementations, RGIB-SSL and RGIB-REP, that benefit from different methodologies, i.e., self-supervised learning and data reparametrization, for indirect and direct data denoising, respectively. Extensive experiments on six benchmarks with various scenarios verify the effectiveness of the proposed RGIB."}}
{"id": "wkffYI3ft50", "cdate": 1640995200000, "mdate": 1681705794140, "content": {"title": "KGTuner: Efficient Hyper-parameter Search for Knowledge Graph Learning", "abstract": "While hyper-parameters (HPs) are important for knowledge graph (KG) learning, existing methods fail to search them efficiently. To solve this problem, we first analyze the properties of different HPs and measure the transfer ability from small subgraph to the full graph. Based on the analysis, we propose an efficient two-stage search algorithm KGTuner, which efficiently explores HP configurations on small subgraph at the first stage and transfers the top-performed configurations for fine-tuning on the large full graph at the second stage. Experiments show that our method can consistently find better HPs than the baseline algorithms within the same time budget, which achieves {9.1\\%} average relative improvement for four embedding models on the large-scale KGs in open graph benchmark."}}
{"id": "7syUqTLY8Ze", "cdate": 1640995200000, "mdate": 1681705794198, "content": {"title": "Efficient Hyper-parameter Search for Knowledge Graph Embedding", "abstract": ""}}
{"id": "7Viatlxrasa", "cdate": 1640995200000, "mdate": 1681705794195, "content": {"title": "Learning Adaptive Propagation for Knowledge Graph Reasoning", "abstract": "Due to the popularity of Graph Neural Networks (GNNs), various GNN-based methods have been designed to reason on knowledge graphs (KGs). An important design component of GNN-based KG reasoning methods is called the propagation path, which contains a set of involved entities in each propagation step. Existing methods use hand-designed propagation paths, ignoring the correlation between the entities and the query relation. In addition, the number of involved entities will explosively grow at larger propagation steps. In this work, we are motivated to learn an adaptive propagation path in order to filter out irrelevant entities while preserving promising targets. First, we design an incremental sampling mechanism where the nearby targets and layer-wise connections can be preserved with linear complexity. Second, we design a learning-based sampling distribution to identify the semantically related entities. Extensive experiments show that our method is powerful, efficient, and semantic-aware. The code is available at https://github.com/LARS-research/AdaProp."}}
{"id": "ovZLdLW7I5l", "cdate": 1609459200000, "mdate": 1631163123185, "content": {"title": "AutoSF+: Towards Automatic Scoring Function Design for Knowledge Graph Embedding", "abstract": "Learning embeddings for entities and relations in knowledge graph (KG) have benefited many downstream tasks. In recent years, scoring functions, the crux of KG learning, have been human-designed to measure the plausibility of triples and capture different kinds of relations in KGs. However, as relations exhibit intricate patterns that are hard to infer before training, none of them consistently perform the best on benchmark tasks. In this paper, inspired by the recent success of automated machine learning (AutoML), we search bilinear scoring functions for different KG tasks through the AutoML techniques. However, it is non-trivial to explore domain-specific information here. We first set up a search space for AutoBLM by analyzing existing scoring functions. Then, we propose a progressive algorithm (AutoBLM) and an evolutionary algorithm (AutoBLM+), which are further accelerated by filter and predictor to deal with the domain-specific properties for KG learning. Finally, we perform extensive experiments on benchmarks in KG completion, multi-hop query, and entity classification tasks. Empirical results show that the searched scoring functions are KG dependent, new to the literature, and outperform the existing scoring functions. AutoBLM+ is better than AutoBLM as the evolutionary algorithm can flexibly explore better structures in the same budget."}}
{"id": "vrj1M3oRY1t", "cdate": 1577836800000, "mdate": 1681705794127, "content": {"title": "Enhancing WiFi Multiple Access Performance with Federated Deep Reinforcement Learning", "abstract": "Carrier sensing multiple access/collision avoidance (CSMA/CA) is the backbone MAC protocol for IEEE 802.11 networks. However, tuning the binary exponential back-off (BEB) mechanism of CSMA/CA in user-dense scenarios so as to maximize aggregate throughput still remains a practically essential and challenging problem. In this paper, we propose a new and enhanced multiple access mechanism based on the application of deep reinforcement learning (DRL) and Federated learning (FL). A new Monte Carlo (MC) reward updating method for DRL training is proposed and the access history of each station is used to derive a DRL-based MAC protocol that improves the network throughput vis-a-vis the traditional distributed coordination function (DCF). Further, federated learning (FL) is applied to achieve fairness among users. The simulation results showcase that the proposed federated reinforcement multiple access (FRMA) performs better than basic DCF by 20% and DCF with request-to-send/clear-to-send (RTS/CTS) by 5% while guaranteeing the fairness in user-dense scenarios."}}
