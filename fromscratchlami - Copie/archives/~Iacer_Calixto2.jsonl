{"id": "WMRVBlClB_C", "cdate": 1672531200000, "mdate": 1682331072452, "content": {"title": "Soft-prompt tuning to predict lung cancer using primary care free-text Dutch medical notes", "abstract": "We investigate different natural language processing (NLP) approaches based on contextualised word representations for the problem of early prediction of lung cancer using free-text patient medical notes of Dutch primary care physicians. Because lung cancer has a low prevalence in primary care, we also address the problem of classification under highly imbalanced classes. Specifically, we use large Transformer-based pretrained language models (PLMs) and investigate: 1) how \\textit{soft prompt-tuning} -- an NLP technique used to adapt PLMs using small amounts of training data -- compares to standard model fine-tuning; 2) whether simpler static word embedding models (WEMs) can be more robust compared to PLMs in highly imbalanced settings; and 3) how models fare when trained on notes from a small number of patients. We find that 1) soft-prompt tuning is an efficient alternative to standard model fine-tuning; 2) PLMs show better discrimination but worse calibration compared to simpler static word embedding models as the classification problem becomes more imbalanced; and 3) results when training models on small number of patients are mixed and show no clear differences between PLMs and WEMs. All our code is available open source in \\url{https://bitbucket.org/aumc-kik/prompt_tuning_cancer_prediction/}."}}
{"id": "icZ79HG5J0", "cdate": 1640995200000, "mdate": 1664970926707, "content": {"title": "VALSE: A Task-Independent Benchmark for Vision and Language Models Centered on Linguistic Phenomena", "abstract": "Letitia Parcalabescu, Michele Cafagna, Lilitta Muradjan, Anette Frank, Iacer Calixto, Albert Gatt. Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 2022."}}
{"id": "a0eK1WKwem", "cdate": 1640995200000, "mdate": 1676021324927, "content": {"title": "Detecting Euphemisms with Literal Descriptions and Visual Imagery", "abstract": "This paper describes our two-stage system for the Euphemism Detection shared task hosted by the 3rd Workshop on Figurative Language Processing in conjunction with EMNLP 2022. Euphemisms tone down expressions about sensitive or unpleasant issues like addiction and death. The ambiguous nature of euphemistic words or expressions makes it challenging to detect their actual meaning within a context. In the first stage, we seek to mitigate this ambiguity by incorporating literal descriptions into input text prompts to our baseline model. It turns out that this kind of direct supervision yields remarkable performance improvement. In the second stage, we integrate visual supervision into our system using visual imageries, two sets of images generated by a text-to-image model by taking terms and descriptions as input. Our experiments demonstrate that visual supervision also gives a statistically significant performance boost. Our system achieved the second place with an F1 score of 87.2%, only about 0.9% worse than the best submission."}}
{"id": "Bn-PE9ripLV", "cdate": 1640995200000, "mdate": 1676021324924, "content": {"title": "Endowing Language Models with Multimodal Knowledge Graph Representations", "abstract": "We propose a method to make natural language understanding models more parameter efficient by storing knowledge in an external knowledge graph (KG) and retrieving from this KG using a dense index. Given (possibly multilingual) downstream task data, e.g., sentences in German, we retrieve entities from the KG and use their multimodal representations to improve downstream task performance. We use the recently released VisualSem KG as our external knowledge repository, which covers a subset of Wikipedia and WordNet entities, and compare a mix of tuple-based and graph-based algorithms to learn entity and relation representations that are grounded on the KG multimodal information. We demonstrate the usefulness of the learned entity representations on two downstream tasks, and show improved performance on the multilingual named entity recognition task by $0.3\\%$--$0.7\\%$ F1, while we achieve up to $2.5\\%$ improvement in accuracy on the visual sense disambiguation task. All our code and data are available in: \\url{https://github.com/iacercalixto/visualsem-kg}."}}
{"id": "9at2xPoHmS", "cdate": 1640995200000, "mdate": 1664970926722, "content": {"title": "Neural Natural Language Generation: A Survey on Multilinguality, Multimodality, Controllability and Learning", "abstract": "Developing artificial learning systems that can understand and generate natural language has been one of the long-standing goals of artificial intelligence. Recent decades have witnessed an impressive progress on both of these problems, giving rise to a new family of approaches. Especially, the advances in deep learning over the past couple of years have led to neural approaches to natural language generation (NLG). These methods combine generative language learning techniques with neural-networks based frameworks. With a wide range of applications in natural language processing, neural NLG (NNLG) is a new and fast growing field of research. In this state-of-the-art report, we investigate the recent developments and applications of NNLG in its full extent from a multidimensional view, covering critical perspectives such as multimodality, multilinguality, controllability and learning strategies. We summarize the fundamental building blocks of NNLG approaches from these aspects and provide detailed reviews of commonly used preprocessing steps and basic neural architectures. This report also focuses on the seminal applications of these NNLG models such as machine translation, description generation, automatic speech recognition, abstractive summarization, text simplification, question answering and generation, and dialogue generation. Finally, we conclude with a thorough discussion of the described frameworks by pointing out some open research directions."}}
{"id": "-s__L9MSOE", "cdate": 1640995200000, "mdate": 1671014909746, "content": {"title": "Multi3Generation: Multitask, Multilingual, Multimodal Language Generation", "abstract": "Anabela Barreiro, Jos\u00e9 GC de Souza, Albert Gatt, Mehul Bhatt, Elena Lloret, Aykut Erdem, Dimitra Gkatzia, Helena Moniz, Irene Russo, Fabio Kepler, Iacer Calixto, Marcin Paprzycki, Fran\u00e7ois Portet, Isabelle Augenstein, Mirela Alhasani. Proceedings of the 23rd Annual Conference of the European Association for Machine Translation. 2022."}}
{"id": "fC-MP02JkuE", "cdate": 1609459200000, "mdate": 1636107773784, "content": {"title": "Wikipedia Entities as Rendezvous across Languages: Grounding Multilingual Language Models by Predicting Wikipedia Hyperlinks", "abstract": "Iacer Calixto, Alessandro Raganato, Tommaso Pasini. Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. 2021."}}
{"id": "_YVABOU2Lq8", "cdate": 1609459200000, "mdate": 1676021324922, "content": {"title": "Zero-shot hashtag segmentation for multilingual sentiment analysis", "abstract": "Hashtag segmentation, also known as hashtag decomposition, is a common step in preprocessing pipelines for social media datasets. It usually precedes tasks such as sentiment analysis and hate speech detection. For sentiment analysis in medium to low-resourced languages, previous research has demonstrated that a multilingual approach that resorts to machine translation can be competitive or superior to previous approaches to the task. We develop a zero-shot hashtag segmentation framework and demonstrate how it can be used to improve the accuracy of multilingual sentiment analysis pipelines. Our zero-shot framework establishes a new state-of-the-art for hashtag segmentation datasets, surpassing even previous approaches that relied on feature engineering and language models trained on in-domain data."}}
{"id": "aRpOEBrlwQl", "cdate": 1601051296218, "mdate": null, "content": {"title": "Latent Variable Model for Multi-modal Translation", "abstract": "In this work, we propose to model the interaction between visual and textual features\nfor multi-modal neural machine translation\n(MMT) through a latent variable model. This\nlatent variable can be seen as a multi-modal\nstochastic embedding of an image and its description in a foreign language. It is used\nin a target-language decoder and also to predict image features. Importantly, our model\nformulation utilises visual and textual inputs\nduring training but does not require that images be available at test time. We show\nthat our latent variable MMT formulation improves considerably over strong baselines, including a multi-task learning approach (Elliottand Kad\u00b4 ar\u00b4 , 2017) and a conditional variational\nauto-encoder approach (Toyama et al., 2016).\nFinally, we show improvements due to (i) predicting image features in addition to only conditioning on them, (ii) imposing a constraint\non the minimum amount of information encoded in the latent variable, and (iii) by training on additional target-language image descriptions (i.e. synthetic data)."}}
{"id": "vaq4pd-fWoJ", "cdate": 1577836800000, "mdate": null, "content": {"title": "A Study on the Autoregressive and non-Autoregressive Multi-label Learning", "abstract": "Extreme classification tasks are multi-label tasks with an extremely large number of labels (tags). These tasks are hard because the label space is usually (i) very large, e.g. thousands or millions of labels, (ii) very sparse, i.e. very few labels apply to each input document, and (iii) highly correlated, meaning that the existence of one label changes the likelihood of predicting all other labels. In this work, we propose a self-attention based variational encoder-model to extract the label-label and label-feature dependencies jointly and to predict labels for a given input. In more detail, we propose a non-autoregressive latent variable model and compare it to a strong autoregressive baseline that predicts a label based on all previously generated labels. Our model can therefore be used to predict all labels in parallel while still including both label-label and label-feature dependencies through latent variables, and compares favourably to the autoregressive baseline. We apply our models to four standard extreme classification natural language data sets, and one news videos dataset for automated label detection from a lexicon of semantic concepts. Experimental results show that although the autoregressive models, where use a given order of the labels for chain-order label prediction, work great for the small scale labels or the prediction of the highly ranked label, but our non-autoregressive model surpasses them by around 2% to 6% when we need to predict more labels, or the dataset has a larger number of the labels."}}
