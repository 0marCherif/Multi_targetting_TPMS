{"id": "wbCuZFVKdC", "cdate": 1680307200000, "mdate": 1681697803737, "content": {"title": "Discrete Search Photometric Stereo for Fast and Accurate Shape Estimation", "abstract": "We consider the problem of estimating surface normals of a scene with spatially varying, general bidirectional reflectance distribution functions (BRDFs) observed by a static camera under varying distant illuminations. Unlike previous approaches that rely on continuous optimization of surface normals, we cast the problem as a <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">discrete</i> search problem over a set of finely discretized surface normals. In this setting, we show that the expensive processes can be precomputed in a scene-independent manner, resulting in accelerated inference. We discuss two variants of our discrete search photometric stereo (DSPS), one working with continuous linear combinations of BRDF bases and the other working with discrete BRDFs sampled from a BRDF space. Experiments show that DSPS has comparable accuracy to state-of-the-art exemplar-based photometric stereo methods while achieving 10\u2013100x acceleration."}}
{"id": "FMHWZoCiCo", "cdate": 1677628800000, "mdate": 1681697804069, "content": {"title": "Shuffled Linear Regression with Outliers in Both Covariates and Responses", "abstract": "This paper studies a shuffled linear regression problem. As a variant of ordinary linear regression, it requires estimating not only the regression variable, but also permutational correspondences between the covariates and responses. While existing formulations require the underlying ground-truth correspondences to be an ideal bijection such that all pieces of data should match, such a requirement barely holds in real-world applications due to either missing data or outliers. In this work, we generalize the formulation of shuffled linear regression to a broader range of conditions where only a part of the data should correspond. To this end, the effective recovery condition and NP-hardness of the proposed formulation are also studied. Moreover, we present a simple yet effective algorithm for deriving the solution. Its global convergence property and convergence rate are also analyzed in detail. Distinct tasks validate the effectiveness of our proposed formulation and the solution method."}}
{"id": "_xCpThyIEv", "cdate": 1672531200000, "mdate": 1681697804276, "content": {"title": "Accuracy Evaluation and Prediction of Single-Image Camera Calibration", "abstract": "This paper proposes an application to statistically predict the accuracy of single-image geometric camera calibration that uses given 2D-3D correspondences. Deriving both camera intrinsics and extrinsics from correspondences between a single image and a 3D shape, is important for the scene analysis when the optical system of the camera is lost, such as in the analyses of traffic accidents. It is unclear whether the single-image calibration will be successful in practice, particularly when the number of 2D-3D correspondences is small, even if we could assign accurate correspondences by manual labor. To this end, we perform a systematic evaluation of the camera parameter accuracy using synthetic environments. Based on the statistics observed during the experiments, our application predicts the calibration accuracy from simple variables (e.g., the area that correspondences could be given). Since the prediction process does not rely on 3D shapes, it provides an estimate of the success of the calibration before time-consuming processes, i.e., 3D scanning and 2D-3D correspondence mapping."}}
{"id": "8MdpMqI54ok", "cdate": 1672531200000, "mdate": 1681697804024, "content": {"title": "Text-Guided Scene Sketch-to-Photo Synthesis", "abstract": "We propose a method for scene-level sketch-to-photo synthesis with text guidance. Although object-level sketch-to-photo synthesis has been widely studied, whole-scene synthesis is still challenging without reference photos that adequately reflect the target style. To this end, we leverage knowledge from recent large-scale pre-trained generative models, resulting in text-guided sketch-to-photo synthesis without the need for reference images. To train our model, we use self-supervised learning from a set of photographs. Specifically, we use a pre-trained edge detector that maps both color and sketch images into a standardized edge domain, which reduces the gap between photograph-based edge images (during training) and hand-drawn sketch images (during inference). We implement our method by fine-tuning a latent diffusion model (i.e., Stable Diffusion) with sketch and text conditions. Experiments show that the proposed method translates original sketch images that are not extracted from color images into photos with compelling visual quality."}}
{"id": "3CDAXiMjsiH", "cdate": 1672531200000, "mdate": 1681697804011, "content": {"title": "Multi-View Azimuth Stereo via Tangent Space Consistency", "abstract": "We present a method for 3D reconstruction only using calibrated multi-view surface azimuth maps. Our method, multi-view azimuth stereo, is effective for textureless or specular surfaces, which are difficult for conventional multi-view stereo methods. We introduce the concept of tangent space consistency: Multi-view azimuth observations of a surface point should be lifted to the same tangent space. Leveraging this consistency, we recover the shape by optimizing a neural implicit surface representation. Our method harnesses the robust azimuth estimation capabilities of photometric stereo methods or polarization imaging while bypassing potentially complex zenith angle estimation. Experiments using azimuth maps from various sources validate the accurate shape recovery with our method, even without zenith angles."}}
{"id": "uHRSz8OKVe0", "cdate": 1640995200000, "mdate": 1667547624012, "content": {"title": "Bilateral Normal Integration", "abstract": "This paper studies the discontinuity preservation problem in recovering a surface from its surface normal map. To model discontinuities, we introduce the assumption that the surface to be recovered is semi-smooth, i.e., the surface is one-sided differentiable (hence one-sided continuous) everywhere in the horizontal and vertical directions. Under the semi-smooth surface assumption, we propose a bilaterally weighted functional for discontinuity preserving normal integration. The key idea is to relatively weight the one-sided differentiability at each point\u2019s two sides based on the definition of one-sided depth discontinuity. As a result, our method effectively preserves discontinuities and alleviates the under- or over-segmentation artifacts in the recovered surfaces compared to existing methods. Further, we unify the normal integration problem in the orthographic and perspective cases in a new way and show effective discontinuity preservation results in both cases (Source code is available at https://github.com/hoshino042/bilateral_normal_integration .)."}}
{"id": "rr7Ke7Arql", "cdate": 1640995200000, "mdate": 1667547623840, "content": {"title": "Multispectral Photometric Stereo for Spatially-Varying Spectral Reflectances", "abstract": "Multispectral photometric stereo (MPS) aims at recovering the surface normal of a scene measured under multiple light sources with different wavelengths. While it opens up a capability of a single-shot measurement of surface normal, the problem has been known ill-posed. To make the problem well-posed, existing MPS methods rely on restrictive assumptions, such as shape prior, surfaces having a monochromatic with uniform albedo. This paper alleviates these restrictive assumptions in existing methods. We show that the problem becomes well-posed for surfaces with uniform chromaticity but spatially-varying albedos based on our new formulation. Specifically, if at least three (or two) scene points share the same chromaticity, the proposed method uniquely recovers their surface normals with the illumination of no less than four (or five) spectral lights in a closed-form. In addition, we show that a more general setting of spatially-varying both chromaticities and albedos can become well-posed if the light spectra and camera spectral sensitivity are calibrated. For this general setting, we derive a unique and closed-form solution for MPS using the linear bases extracted from a spectral reflectance database. Experiments on both synthetic and real captured data with spatially-varying reflectance demonstrate the effectiveness of our method and show the potential applicability for multispectral heritage preservation."}}
{"id": "e97gmNjS4P5", "cdate": 1640995200000, "mdate": 1667547624003, "content": {"title": "Shape-coded ArUco: Fiducial Marker for Bridging 2D and 3D Modalities", "abstract": "We introduce a fiducial marker for the registration of two-dimensional (2D) images and untextured three-dimensional (3D) shapes that are recorded by commodity laser scanners. Specifically, we design a 3D-version of the ArUco marker that retains exactly the same appearance as its 2D counterpart from any viewpoint above the marker but contains shape information. The shape-coded ArUco can naturally work with off-the-shelf ArUco marker detectors in the 2D image domain. For the 3D domain, we develop a method for detecting the marker in an untextured 3D point cloud. Experiments demonstrate accurate 2D-3D registration using our shape-coded ArUco markers in comparison to baseline methods."}}
{"id": "HOlX4oDv9p", "cdate": 1640995200000, "mdate": 1667547623868, "content": {"title": "Shape and Albedo Recovery by Your Phone using Stereoscopic Flash and No-Flash Photography", "abstract": "Recovering shape and albedo for the immense number of existing cultural heritage artifacts is challenging. Accurate 3D reconstruction systems are typically expensive and thus inaccessible to many and cheaper off-the-shelf 3D sensors often generate results of unsatisfactory quality. This paper presents a high-fidelity shape and albedo recovery method that only requires a stereo camera and a flashlight, a typical camera setup equipped in many off-the-shelf smartphones. The stereo camera allows us to infer rough shape from a pair of no-flash images, and a flash image is further captured for shape refinement based on our flash/no-flash image formation model. We verify the effectiveness of our method on real-world artifacts in indoor and outdoor conditions using smartphones with different camera/flashlight configurations. Comparison results demonstrate that our stereoscopic flash and no-flash photography benefits the high-fidelity shape and albedo recovery on a smartphone. Using our method, people can immediately turn their phones into high-fidelity 3D scanners, facilitating the digitization of cultural heritage artifacts."}}
{"id": "EzRukIeXqJn", "cdate": 1640995200000, "mdate": 1667547624057, "content": {"title": "Close-Contact Detection Using a Single Camera for Sports Considering Occlusion", "abstract": "The Coronavirus disease 2019 (COVID-19) is still prevalent in the world. Exercise is important to maintain our health while dealing with infectious diseases. Social distancing is more important during exercise because we may not be able to wear masks to avoid breathing problems, heatstroke, etc. To maintain social distancing during exercise, we develop a close-contact detection system using a single camera especially for sports in schools and gyms. We rely on a single camera because of the deployment cost. The system recognizes people from a video and estimates the interpersonal distance for close-contact detection. The challenge is the occlusion of people, which leads to false negatives in close-contact detection. To solve the problem, we leverage the observation that most false negatives in human detection are caused by occlusion owing to other people. This is because there are few obstacles in sports facilities. Based on the above observation, we assume that a person still exists near the last detected position even when s/he disappears in the proximity of other people. For evaluation, we recorded 834 videos that were 112 min long in total including various scenarios with 2724 close-contacts. The results show that the F1-score of close-contact detection and tracking are 83.6% and 67.3%, respectively. We also confirmed that the start and end time errors are within 1 s for more than 80% of the close-contacts."}}
