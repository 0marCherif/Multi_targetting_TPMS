{"id": "thSG2-ii1w", "cdate": 1683882619064, "mdate": 1683882619064, "content": {"title": "The epistemic virtues of harnessing rigorous machine learning systems in ethically-sensitive domains", "abstract": "Some physicians, in their care of patients at risk of misusing opioids, use machine learning (ML)-based Prediction Drug Monitoring Programmes (PDMPs) to guide their decision-making in the prescription of opioids. This can cause a conflict: a PDMP score can indicate a patient is at a high risk of opioid abuse while a patient expressly reports oppositely. The prescriber is then left to balance the credibility and trust of the patient with the PDMP score."}}
{"id": "k2fcfQL0WY", "cdate": 1683882575072, "mdate": 1683882575072, "content": {"title": "Sensing and processing whisker deflections in rodents", "abstract": "The classical view of sensory information mainly flowing into barrel cortex at layer IV, moving up for complex feature processing and lateral interactions in layers II and III, then down to layers V and VI for output and corticothalamic feedback is becoming increasingly undermined by new evidence. We review the neurophysiology of sensing and processing whisker deflections, emphasizing the general processing and organisational principles present along the entire sensory pathway\u2014from the site of physical deflection at the whiskers to the encoding of deflections in the barrel cortex. Many of these principles support the classical view. However, we also highlight the growing number of exceptions to these general principles, which complexify the system and which investigators should be mindful of when interpreting their results. We identify gaps in the literature for experimentalists and theorists to investigate, not just to better understand whisker sensation but also to better understand sensory and cortical processing."}}
{"id": "imjyNPv6w8", "cdate": 1683882530499, "mdate": 1683882530499, "content": {"title": "Classic Hebbian learning endows feed-forward networks with sufficient adaptability in challenging reinforcement learning tasks", "abstract": "A common pitfall of current reinforcement learning agents implemented in computational models is in their inadaptability postoptimization. Najarro and Risi [Najarro E, Risi S. Proc 33rd Conf Neural Inf Process Systems (NeurIPS 2020). 2020: 20719\u201320731, 2020] demonstrate how such adaptability may be salvaged in artificial feed-forward networks by optimizing coefficients of classic Hebbian rules to dynamically control the networks\u2019 weights instead of optimizing the weights directly. Although such models fail to capture many important neurophysiological details, allying the fields of neuroscience and artificial intelligence in this way bears many fruits for both fields, especially when computational models engage with topics with a rich history in neuroscience such as Hebbian plasticity."}}
{"id": "7XFNwfFenY4", "cdate": 1683882492547, "mdate": 1683882492547, "content": {"title": "Combining complexity measures of EEG data: multiplying measures reveal previously hidden information", "abstract": "Many studies have noted significant differences among human electroencephalograph (EEG) results when participants or patients are exposed to different stimuli, undertaking different tasks, or being affected by conditions such as epilepsy or Alzheimer's disease. Such studies often use only one or two measures of complexity and do not regularly justify their choice of measure beyond the fact that it has been used in previous studies. If more measures were added to such studies, however, more complete information might be found about these reported differences. Such information might be useful in confirming the existence or extent of such differences, or in understanding their physiological bases. In this study we analysed publically-available EEG data using a range of complexity measures to determine how well the measures correlated with one another. The complexity measures did not all significantly correlate, suggesting that different measures were measuring unique features of the EEG signals and thus revealing information which other measures were unable to detect. Therefore, the results from this analysis suggests that combinations of complexity measures reveal unique information which is in addition to the information captured by other measures of complexity in EEG data. For this reason, researchers using individual complexity measures for EEG data should consider using combinations of measures to more completely account for any differences they observe and to ensure the robustness of any relationships identified."}}
{"id": "tAXBpiKezRb", "cdate": 1683882434135, "mdate": 1683882434135, "content": {"title": "A Bergson-Inspired Adaptive Time Constant for the Multiple Timescales Recurrent Neural Network Model", "abstract": "We introduce an adaptive time constant for the multiple timescales recurrent neural network (MTRNN) inspired by the work of philosopher Henri Bergson (1859-1941). Observed variations in the recent activity of MTRNN neurons is used to adapt the time constant. We analyse how the time constant adapts in response to neuronal activity for a simple one-dimensional function-fitting task."}}
{"id": "Vj8moRs-S0", "cdate": 1683882332262, "mdate": 1683882332262, "content": {"title": "A mathematical approach to correlating objective spectro-temporal features of non-linguistic sounds with their subjective perceptions in humans", "abstract": "Non-linguistic sounds (NLSs) are a core feature of our everyday life and many evoke powerful cognitive and emotional outcomes. The subjective perception of NLSs by humans has occasionally been defined for single percepts, e.g., their pleasantness, whereas many NLSs evoke multiple perceptions. There has also been very limited attempt to determine if NLS perceptions are predicted from objective spectro-temporal features. We therefore examined three human perceptions well-established in previous NLS studies (\u201cComplexity,\u201d \u201cPleasantness,\u201d and \u201cFamiliarity\u201d), and the accuracy of identification, for a large NLS database and related these four measures to objective spectro-temporal NLS features, defined using rigorous mathematical descriptors including stimulus entropic and algorithmic complexity measures, peaks-related measures, fractal dimension estimates, and various spectral measures (mean spectral centroid, power in discrete frequency ranges, harmonicity, spectral flatness, and spectral structure). We mapped the perceptions to the spectro-temporal measures individually and in combinations, using complex multivariate analyses including principal component analyses and agglomerative hierarchical clustering."}}
{"id": "8gplpoXtpv", "cdate": 1683882277637, "mdate": 1683882277637, "content": {"title": "Temporal activity patterns of layer II and IV rat barrel cortex neurons in healthy and injured conditions", "abstract": "\nNeurons are known to encode information not just by how frequently they fire, but also at what times they fire. However, characterizations of temporal encoding in sensory cortices under conditions of health and injury are limited. Here we characterized and compared the stimulus-evoked activity of 1210 online-sorted units in layers II and IV of rat barrel cortex under healthy and diffuse traumatic brain injury (TBI) (caused by a weight-drop model) conditions across three timepoints post-injury: four days, two weeks, and eight weeks. Temporal activity patterns in the first 50 ms post-stimulus recording showed four categories of responses: no response or 1, 2, or 3 temporally-distinct response components, that is, periods of high unit activity separated by silence. The relative proportions of unit response categories were similar between layers II and IV in healthy conditions but not in early post-TBI conditions. For units with multiple response components, inter-component timings were reliable in healthy and late post-TBI conditions but disrupted by injury. Response component times typically shifted earlier with increasing stimulus intensity and this was more pronounced in layer IV than layer II. Surprisingly, injury caused a reversal of this trend and in the late post-TBI condition no stimulus intensity-dependence differences were observed between layers II and IV. We speculate this indicates a potential compensatory mechanism in response to injury. These results demonstrate how temporal encoding features maladapt or functionally recover differently in sensory cortex after TBI. Such maladaptation or functional recovery is layer-dependent, perhaps due to differences in thalamic input or local inhibitory neuronal makeup."}}
{"id": "U-SpMb5S9HT", "cdate": 1683882230014, "mdate": 1683882230014, "content": {"title": "Multiscale and extended retrieval of associative memory structures in a cortical model of local-global inhibition balance", "abstract": "Inhibitory neurons take on many forms and functions. How this diversity contributes to memory function is not completely known. Previous formal studies indicate inhibition differentiated by local and global connectivity in associative memory networks functions to rescale the level of retrieval of excitatory assemblies. However, such studies lack biological details such as a distinction between types of neurons (excitatory and inhibitory), unrealistic connection schemas, and nonsparse assemblies. In this study, we present a rate-based cortical model where neurons are distinguished (as excitatory, local inhibitory, or global inhibitory), connected more realistically, and where memory items correspond to sparse excitatory assemblies. We use this model to study how local-global inhibition balance can alter memory retrieval in associative memory structures, including naturalistic and artificial structures. Experimental studies have reported inhibitory neurons and their subtypes uniquely respond to specific stimuli and can form sophisticated, joint excitatory-inhibitory assemblies. Our model suggests such joint assemblies, as well as a distribution and rebalancing of overall inhibition between two inhibitory subpopulations, one connected to excitatory assemblies locally and the other connected globally, can quadruple the range of retrieval across related memories. We identify a possible functional role for local-global inhibitory balance to, in the context of choice or preference of relationships, permit and maintain a broader range of memory items when local inhibition is dominant and conversely consolidate and strengthen a smaller range of memory items when global inhibition is dominant. This model, while still theoretical, therefore highlights a potentially biologically-plausible and behaviorally-useful function of inhibitory diversity in memory."}}
{"id": "NAuVe6pQ7Jb", "cdate": 1663850523304, "mdate": null, "content": {"title": "Efficient, probabilistic analysis of combinatorial neural codes", "abstract": "Artificial and biological neural networks (ANNs and BNNs) can encode inputs in the form of combinations of individual neurons' activities. These combinatorial neural codes present a computational challenge for direct and efficient analysis due to their high dimensionality and often large volumes of data. Here we improve the computational complexity -- from factorial to quadratic time -- of direct algebraic methods previously applied to small examples and apply them to large neural codes generated by experiments. These methods provide a novel and efficient way of probing algebraic, geometric, and topological characteristics of combinatorial neural codes and provide insights into how such characteristics are related to learning and experience in neural networks. We introduce a procedure to perform hypothesis testing on the intrinsic features of neural codes using information geometry. We then apply these methods to neural activities from an ANN for image classification and a BNN for 2D navigation to, without observing any inputs or outputs, estimate the structure and dimensionality of the stimulus or task space. Additionally, we demonstrate how an ANN varies its internal representations across network depth and during learning."}}
{"id": "_QLsH8gatwx", "cdate": 1663850086452, "mdate": null, "content": {"title": "Simplicial Hopfield networks", "abstract": "Hopfield networks are artificial neural networks which store memory patterns on the states of their neurons by choosing recurrent connection weights and update rules such that the energy landscape of the network forms attractors around the memories. How many stable, sufficiently-attracting memory patterns can we store in such a network using $N$ neurons? The answer depends on the choice of weights and update rule. Inspired by setwise connectivity in biology, we extend Hopfield networks by adding setwise connections and embedding these connections in a simplicial complex. Simplicial complexes are higher dimensional analogues of graphs which naturally represent collections of pairwise and setwise relationships. We show that our simplicial Hopfield networks increase memory storage capacity. Surprisingly, even when connections are limited to a small random subset of equivalent size to an all-pairwise network, our networks still outperform their pairwise counterparts. Such scenarios include non-trivial simplicial topology. We also test analogous modern continuous Hopfield networks, offering a potentially promising avenue for improving the attention mechanism in Transformer models."}}
