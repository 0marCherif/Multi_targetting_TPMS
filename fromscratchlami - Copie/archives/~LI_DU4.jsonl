{"id": "zJ6n7Vki6L", "cdate": 1640995200000, "mdate": 1684410079950, "content": {"title": "Binary Neural Networks as a general-propose compute paradigm for on-device computer vision", "abstract": "For binary neural networks (BNNs) to become the mainstream on-device computer vision algorithm, they must achieve a superior speed-vs-accuracy tradeoff than 8-bit quantization and establish a similar degree of general applicability in vision tasks. To this end, we propose a BNN framework comprising 1) a minimalistic inference scheme for hardware-friendliness, 2) an over-parameterized training scheme for high accuracy, and 3) a simple procedure to adapt to different vision tasks. The resultant framework overtakes 8-bit quantization in the speed-vs-accuracy tradeoff for classification, detection, segmentation, super-resolution and matching: our BNNs not only retain the accuracy levels of their 8-bit baselines but also showcase 1.3-2.4$\\times$ faster FPS on mobile CPUs. Similar conclusions can be drawn for prototypical systolic-array-based AI accelerators, where our BNNs promise 2.8-7$\\times$ fewer execution cycles than 8-bit and 2.1-2.7$\\times$ fewer cycles than alternative BNN designs. These results suggest that the time for large-scale BNN adoption could be upon us."}}
{"id": "ppDinBvbeJ", "cdate": 1640995200000, "mdate": 1684410079991, "content": {"title": "A Low-Power High-Accuracy Urban Waterlogging Depth Sensor Based on Millimeter-Wave FMCW Radar", "abstract": "The method of making precise measurements of remote water depth using mmWave technology has great potential for preventing urban waterlogging. To achieve waterlogging prevention, the mmWave system needs to measure the water depth change accurately with a short acquisition time. This paper demonstrates a new accurate mmWave water depth measurement system based on Frequency Modulated Continuous Wave (FMCW) Radar with a center frequency of 77 GHz. To improve distance resolution and lower acquisition time, the Swept Frequency-Cross Correlation (SFCC) algorithm is proposed for the first time to improve the distance computation resolution by 9\u00d7 and lower time complexity from O(n\u00b7logn) to O(n) compared to traditional FFT-based FMCW radar distance computation. A prototype system equipped with a humidity sensor, a processor module and TI\u2019s FMCW radar module is designed for monitoring urban floods in cities. Using the prototype system with the proposed SFCC, the depth measurement error is reduced from 4.5 cm to less than 5 mm, compared to the default radar post-processing algorithm embedded in the radar module."}}
{"id": "mw7hQ6KXiHc", "cdate": 1640995200000, "mdate": 1684410079940, "content": {"title": "A Reconfigurable Design of Flexible-arbitrated Crossbar Interconnects in Multi-core SoC system", "abstract": "In the system of multi-core SoC, many specifications need to be considered to optimize interconnect bus architecture, such as the arbitration mechanism, latency, area and power consumption. This paper proposes a reconfigurable design of flexible-arbitrated crossbar to analyze the relevant factors and improve the performance and practicality with the reconfigurable implementation. Two priority matching algorithms are proposed in the design to meet more flexible-arbitrated choices for the application scenarios of multi-core SoC. Moreover, the static and dynamic reconfiguration proposed in the paper provides a valuable reference for the design of bus structure in SoC systems. Compared with the original design in the case analysis, the reconfigurable design achieves 23.3% smaller area, 15.7% less latency, and 23% power saving."}}
{"id": "mb8nRCBLOmRx", "cdate": 1640995200000, "mdate": 1664876338280, "content": {"title": "Prototype-Voxel Contrastive Learning for LiDAR Point Cloud Panoptic Segmentation", "abstract": "LiDAR point cloud panoptic segmentation, including both semantic and instance segmentation, plays a critical role in meticulous scene understanding for autonomous driving. Existing 3D voxelized approaches either utilize 3D sparse convolution that only focuses on local scene understanding, or add extra and time-consuming PointNet branch to capture global feature structures. To address these limitations, we propose an end-to-end Prototype-Voxel Contrastive Learning (PVCL) framework for learning stable and discriminative semantic representations, which includes voxel-level and prototype-level contrastive learning (CL). The voxel-level CL decreases intra-class distance and increases inter-class distance among sample representations, while the prototype-level CL further reduces the dependence of CL on negative sampling and avoids the influence of outliers from the same class, enabling PVCL to be more effective for outdoor point cloud panoptic segmentation. Extensive experiments are conducted on the public point cloud panoptic segmentation datasets, Semantic-KITTI and nuScenes, where evaluations and ablation studies demonstrate PVCL achieves superior performance compared with the state-of-the-art. Our approach ranks the top on the public leaderboard of Semantic-KITTI at the time of submission, and surpasses the published 2nd rank, EfficientLPS, by 1.7% in PQ."}}
{"id": "iBFYqOTzPv", "cdate": 1640995200000, "mdate": 1684410079843, "content": {"title": "Memory-Efficient CNN Accelerator Based on Interlayer Feature Map Compression", "abstract": "Existing deep convolutional neural networks (CNNs) generate massive interlayer feature data during network inference. To maintain real-time processing in embedded systems, large on-chip memory is required to buffer the interlayer feature maps. In this paper, we propose an efficient hardware accelerator with an interlayer feature compression technique to significantly reduce the required on-chip memory size and off-chip memory access bandwidth. The accelerator compresses interlayer feature maps through transforming the stored data into frequency domain using hardware-implemented <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"> <tex-math notation=\"LaTeX\">$8\\times 8$ </tex-math></inline-formula> discrete cosine transform (DCT). The high-frequency components are removed after the DCT through quantization. Sparse matrix compression is utilized to further compress the interlayer feature maps. The on-chip memory allocation scheme is designed to support dynamic configuration of the feature map buffer size and scratch pad size according to different network-layer requirements. The hardware accelerator combines compression, decompression, and CNN acceleration into one computing stream, achieving minimal compressing and processing delay. A prototype accelerator is implemented on an FPGA platform and also synthesized in TSMC 28-nm COMS technology. It achieves 403GOPS peak throughput and <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"> <tex-math notation=\"LaTeX\">$1.4\\times \\sim 3.3\\times $ </tex-math></inline-formula> interlayer feature map reduction by adding light hardware area overhead, making it a promising hardware accelerator for intelligent IoT devices."}}
{"id": "fun1ERihEFn", "cdate": 1640995200000, "mdate": 1684410079814, "content": {"title": "CSQ: Growing Mixed-Precision Quantization Scheme with Bi-level Continuous Sparsification", "abstract": "Mixed-precision quantization has been widely applied on deep neural networks (DNNs) as it leads to significantly better efficiency-accuracy tradeoffs compared to uniform quantization. Meanwhile, determining the exact precision of each layer remains challenging. Previous attempts on bit-level regularization and pruning-based dynamic precision adjustment during training suffer from noisy gradients and unstable convergence. In this work, we propose Continuous Sparsification Quantization (CSQ), a bit-level training method to search for mixed-precision quantization schemes with improved stability. CSQ stabilizes the bit-level mixed-precision training process with a bi-level gradual continuous sparsification on both the bit values of the quantized weights and the bit selection in determining the quantization precision of each layer. The continuous sparsification scheme enables fully-differentiable training without gradient approximation while achieving an exact quantized model in the end.A budget-aware regularization of total model size enables the dynamic growth and pruning of each layer's precision towards a mixed-precision quantization scheme of the desired size. Extensive experiments show CSQ achieves better efficiency-accuracy tradeoff than previous methods on multiple models and datasets."}}
{"id": "fO01_56pba", "cdate": 1640995200000, "mdate": 1684410079817, "content": {"title": "An X-band Phase Detector Based on Quadrature Modulation in 28-nm CMOS", "abstract": "A phase detector (PD) based on quadrature modulation is presented, which is used to perform a phase delay measurement due to signal path at X-band. The X-band signal phase difference is converted to the baseband signal difference through complex frequency conversion. In this paper, an improved active balun and a two-stage tunable poly-phase filter (PPF) are used to generate broadband in-phase and quadrature (I/Q) signals. L-C resonance-based double-balanced Gilbert cells are used as mixers for modulation and demodulation. The proposed X-band PD is implemented in 28-nm CMOS technology and occupies 0.33mm2. The simulated maximal phase error is less than 0.75\u00b0 over 8-12GHz. The PD consumes 3.5 mW with 0.9V power supply, achieving 0\u00b0-180\u00b0 extended linear phase detection range."}}
{"id": "V7S63Nam9v", "cdate": 1640995200000, "mdate": 1683907040527, "content": {"title": "NoisyQuant: Noisy Bias-Enhanced Post-Training Activation Quantization for Vision Transformers", "abstract": "The complicated architecture and high training cost of vision transformers urge the exploration of post-training quantization. However, the heavy-tailed distribution of vision transformer activations hinders the effectiveness of previous post-training quantization methods, even with advanced quantizer designs. Instead of tuning the quantizer to better fit the complicated activation distribution, this paper proposes NoisyQuant, a quantizer-agnostic enhancement for the post-training activation quantization performance of vision transformers. We make a surprising theoretical discovery that for a given quantizer, adding a fixed Uniform noisy bias to the values being quantized can significantly reduce the quantization error under provable conditions. Building on the theoretical insight, NoisyQuant achieves the first success on actively altering the heavy-tailed activation distribution with additive noisy bias to fit a given quantizer. Extensive experiments show NoisyQuant largely improves the post-training quantization performance of vision transformer with minimal computation overhead. For instance, on linear uniform 6-bit activation quantization, NoisyQuant improves SOTA top-1 accuracy on ImageNet by up to 1.7%, 1.1% and 0.5% for ViT, DeiT, and Swin Transformer respectively, achieving on-par or even higher performance than previous nonlinear, mixed-precision quantization."}}
{"id": "KqCQOY3HXFp", "cdate": 1640995200000, "mdate": 1684410079918, "content": {"title": "An Efficient High-Throughput Structured-Light Depth Engine", "abstract": "In this article, an efficient high-throughput depth engine is proposed to generate high-quality 3-D depth maps for speckle-pattern structured-light depth cameras. A dynamic-binarization (DB) method is introduced with a significant reduction of computational complexity in contrast to the sum-of-absolute-distance (SAD) method. The depth map evaluation shows good robustness compared with other window-based correlation methods. Parallel architecture and reuse of intermediate results are employed for efficient hardware implementation. Our design is verified on a field-programmable gate array (FPGA) and implemented in the SMIC 55-nm CMOS technology, achieving a frame rate of 1731.77 fps ( <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"> <tex-math notation=\"LaTeX\">$640\\times480$ </tex-math></inline-formula> ) with an area efficiency of 3.75 fps/KGE. The proposed engine shows a <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"> <tex-math notation=\"LaTeX\">$2.71\\times $ </tex-math></inline-formula> promotion of area efficiency in contrast to the SAD-based implementation. In addition, the subpixel estimation algorithm deployed in postprocessing is optimized for efficient hardware implementation, reducing the gate count by 69.2% without significant performance loss."}}
{"id": "GixPpn-Z3E0", "cdate": 1640995200000, "mdate": 1684410080085, "content": {"title": "Deep Neural Network Interlayer Feature Map Compression Based on Least-Squares Fitting", "abstract": "Deep convolutional neural networks (CNNs) have brought a significant amount of interlayer data during computation, resulting in a large data-exchange delay and power consumption. This paper proposes a Least-Squares Fitting Compression (LSFC) method to compress the interlayer data to resolve the above problem. In LSFC, the feature maps are firstly divided into block groups; then, two base blocks are selected for each block group. Finally, the LSFC core is applied to get the fitting parameters, and the fitting parameters are selectively stored in the on-chip memory according to the mean-squared error (MSE) results. The proposed compression method is hardware-implemented and integrated into an AI accelerator to support the on-the-fly compression process with a slight hardware overhead and latency. Experiments show that the LSFC can reduce the required on-chip storage space by 21.9% $\\sim$ 33.6% during CNN computation without loss of network prediction."}}
