{"id": "pJBCZTaEj6", "cdate": 1640995200000, "mdate": 1682325950424, "content": {"title": "Learning Natural Language Generation with Truncated Reinforcement Learning", "abstract": "Alice Martin, Guillaume Quispe, Charles Ollion, Sylvain Le Corff, Florian Strub, Olivier Pietquin. Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. 2022."}}
{"id": "XheVTx5eVaD", "cdate": 1640995200000, "mdate": 1682325950280, "content": {"title": "Diffusion bridges vector quantized variational autoencoders", "abstract": "Vector Quantized-Variational AutoEncoders (VQ-VAE) are generative models based on discrete latent representations of the data, where inputs are mapped to a finite set of learned embeddings. To gene..."}}
{"id": "52XXcK8jY0J", "cdate": 1621630228821, "mdate": null, "content": {"title": "Disentangling Identifiable Features from Noisy Data with Structured Nonlinear ICA", "abstract": "We introduce a new general identifiable framework for principled disentanglement referred to as Structured Nonlinear Independent Component Analysis (SNICA). Our contribution is to extend the identifiability theory of deep generative models for a very broad class of structured models. While previous works have shown identifiability for specific classes of time-series models, our theorems extend this to more general temporal structures as well as to models with more complex  structures such as spatial dependencies. In particular, we establish the major result that identifiability for this framework holds even in the presence of noise of unknown distribution. Finally, as an example of our framework's flexibility, we introduce the first nonlinear ICA model for time-series that combines the following very useful properties: it accounts for both nonstationarity and autocorrelation in a fully unsupervised setting;  performs dimensionality reduction;  models hidden states; and  enables principled estimation and inference by variational maximum-likelihood."}}
{"id": "PTo9C5G0qK9", "cdate": 1621629972515, "mdate": null, "content": {"title": "NEO: Non Equilibrium Sampling on the Orbits of a Deterministic Transform", "abstract": "Sampling from a complex distribution $\\pi$ and approximating its intractable normalizing constant $\\mathrm{Z}$ are challenging problems. \nIn this paper, a novel family of importance samplers (IS) and Markov chain Monte Carlo (MCMC) samplers is derived. \nGiven an invertible map $\\mathrm{T}$, these schemes combine (with weights) elements from the forward and backward Orbits   through points sampled from a proposal distribution $\\rho$. The map $\\mathrm{T}$ does not leave the target $\\pi$ invariant, hence the name NEO, standing for Non-Equilibrium Orbits. \nNEO-IS provides unbiased estimators of the normalizing constant and self-normalized IS estimators of expectations under $\\pi$ while NEO-MCMC combines multiple NEO-IS estimates of the normalizing constant and an iterated sampling-importance resampling mechanism to sample from $\\pi$. \nFor $\\mathrm{T}$ chosen as a discrete-time integrator of a conformal Hamiltonian system, NEO-IS achieves state-of-the art performance on difficult benchmarks and NEO-MCMC is able to explore highly multimodal targets. Additionally, we provide detailed theoretical results for both methods. In particular, we show that NEO-MCMC is uniformly geometrically ergodic and establish explicit mixing time estimates under mild conditions.\n"}}
{"id": "76tTYokjtG", "cdate": 1621629972515, "mdate": null, "content": {"title": "NEO: Non Equilibrium Sampling on the Orbits of a Deterministic Transform", "abstract": "Sampling from a complex distribution $\\pi$ and approximating its intractable normalizing constant $\\mathrm{Z}$ are challenging problems. \nIn this paper, a novel family of importance samplers (IS) and Markov chain Monte Carlo (MCMC) samplers is derived. \nGiven an invertible map $\\mathrm{T}$, these schemes combine (with weights) elements from the forward and backward Orbits   through points sampled from a proposal distribution $\\rho$. The map $\\mathrm{T}$ does not leave the target $\\pi$ invariant, hence the name NEO, standing for Non-Equilibrium Orbits. \nNEO-IS provides unbiased estimators of the normalizing constant and self-normalized IS estimators of expectations under $\\pi$ while NEO-MCMC combines multiple NEO-IS estimates of the normalizing constant and an iterated sampling-importance resampling mechanism to sample from $\\pi$. \nFor $\\mathrm{T}$ chosen as a discrete-time integrator of a conformal Hamiltonian system, NEO-IS achieves state-of-the art performance on difficult benchmarks and NEO-MCMC is able to explore highly multimodal targets. Additionally, we provide detailed theoretical results for both methods. In particular, we show that NEO-MCMC is uniformly geometrically ergodic and establish explicit mixing time estimates under mild conditions.\n"}}
{"id": "rxhM0LI2Ob", "cdate": 1609459200000, "mdate": 1682325950440, "content": {"title": "Disentangling Identifiable Features from Noisy Data with Structured Nonlinear ICA", "abstract": "We introduce a new general identifiable framework for principled disentanglement referred to as Structured Nonlinear Independent Component Analysis (SNICA). Our contribution is to extend the identifiability theory of deep generative models for a very broad class of structured models. While previous works have shown identifiability for specific classes of time-series models, our theorems extend this to more general temporal structures as well as to models with more complex structures such as spatial dependencies. In particular, we establish the major result that identifiability for this framework holds even in the presence of noise of unknown distribution. Finally, as an example of our framework's flexibility, we introduce the first nonlinear ICA model for time-series that combines the following very useful properties: it accounts for both nonstationarity and autocorrelation in a fully unsupervised setting; performs dimensionality reduction; models hidden states; and enables principled estimation and inference by variational maximum-likelihood."}}
{"id": "lRazhJPgFj", "cdate": 1609459200000, "mdate": 1682325950662, "content": {"title": "NEO: Non Equilibrium Sampling on the Orbits of a Deterministic Transform", "abstract": "Sampling from a complex distribution $\\pi$ and approximating its intractable normalizing constant $\\mathrm{Z}$ are challenging problems. In this paper, a novel family of importance samplers (IS) and Markov chain Monte Carlo (MCMC) samplers is derived. Given an invertible map $\\mathrm{T}$, these schemes combine (with weights) elements from the forward and backward Orbits through points sampled from a proposal distribution $\\rho$. The map $\\mathrm{T}$ does not leave the target $\\pi$ invariant, hence the name NEO, standing for Non-Equilibrium Orbits. NEO-IS provides unbiased estimators of the normalizing constant and self-normalized IS estimators of expectations under $\\pi$ while NEO-MCMC combines multiple NEO-IS estimates of the normalizing constant and an iterated sampling-importance resampling mechanism to sample from $\\pi$. For $\\mathrm{T}$ chosen as a discrete-time integrator of a conformal Hamiltonian system, NEO-IS achieves state-of-the art performance on difficult benchmarks and NEO-MCMC is able to explore highly multimodal targets. Additionally, we provide detailed theoretical results for both methods. In particular, we show that NEO-MCMC is uniformly geometrically ergodic and establish explicit mixing time estimates under mild conditions."}}
{"id": "cbVHNJVFabd", "cdate": 1609459200000, "mdate": 1682325950473, "content": {"title": "End-to-end deep meta modelling to calibrate and optimize energy consumption and comfort", "abstract": "In this paper, we propose a new end-to-end methodology to optimize the energy performance as well as comfort and air quality in large buildings without any renovation work. We introduce a metamodel based on recurrent neural networks and trained to predict the behavior of a general class of buildings using a database sampled from a simulation program. This metamodel is then deployed in different frameworks and its parameters are calibrated using the specific data of two real buildings. Parameters are estimated by comparing the predictions of the metamodel with real data obtained from sensors using the CMA-ES algorithm, a derivative free optimization procedure. Then, energy consumptions are optimized while maintaining a target thermal comfort and air quality, using the NSGA-II multi-objective optimization procedure. The numerical experiments illustrate how this metamodel ensures a significant gain in energy efficiency, up to almost 10%, while being computationally much more appealing than numerical models and flexible enough to be adapted to several types of buildings."}}
{"id": "XNj-cZgslqv", "cdate": 1609459200000, "mdate": 1682325950340, "content": {"title": "Learning Natural Language Generation from Scratch", "abstract": "This paper introduces TRUncated ReinForcement Learning for Language (TrufLL), an original ap-proach to train conditional language models from scratch by only using reinforcement learning (RL). AsRL methods unsuccessfully scale to large action spaces, we dynamically truncate the vocabulary spaceusing a generic language model. TrufLL thus enables to train a language agent by solely interacting withits environment without any task-specific prior knowledge; it is only guided with a task-agnostic languagemodel. Interestingly, this approach avoids the dependency to labelled datasets and inherently reduces pre-trained policy flaws such as language or exposure biases. We evaluate TrufLL on two visual questiongeneration tasks, for which we report positive results over performance and language metrics, which wethen corroborate with a human evaluation. To our knowledge, it is the first approach that successfullylearns a language generation policy (almost) from scratch."}}
{"id": "K7io7jsFlP", "cdate": 1609459200000, "mdate": 1682325950456, "content": {"title": "Joint self-supervised blind denoising and noise estimation", "abstract": "We propose a novel self-supervised image blind denoising approach in which two neural networks jointly predict the clean signal and infer the noise distribution. Assuming that the noisy observations are independent conditionally to the signal, the networks can be jointly trained without clean training data. Therefore, our approach is particularly relevant for biomedical image denoising where the noise is difficult to model precisely and clean training data are usually unavailable. Our method significantly outperforms current state-of-the-art self-supervised blind denoising algorithms, on six publicly available biomedical image datasets. We also show empirically with synthetic noisy data that our model captures the noise distribution efficiently. Finally, the described framework is simple, lightweight and computationally efficient, making it useful in practical cases."}}
