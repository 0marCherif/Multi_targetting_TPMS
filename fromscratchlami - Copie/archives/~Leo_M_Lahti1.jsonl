{"id": "JzV42sLEnkC", "cdate": 1546300800000, "mdate": null, "content": {"title": "Interdisciplinary Collaboration in Studying Newspaper Materiality.", "abstract": ""}}
{"id": "9mhyHi0VmrT", "cdate": 1546300800000, "mdate": null, "content": {"title": "Reconstructing Intellectual Networks: From the ESTC's bibliographic metadata to historical material.", "abstract": ""}}
{"id": "880DElP7zb", "cdate": 1546300800000, "mdate": null, "content": {"title": "Scaling Up Bibliographic Data Science.", "abstract": ""}}
{"id": "DVU4Yk-ERT9", "cdate": 1514764800000, "mdate": null, "content": {"title": "Open Data Science.", "abstract": "The increasing openness of data, methods, and collaboration networks has created new opportunities for research, citizen science, and industry. Whereas openly licensed scientific, governmental, and institutional data sets can now be accessed through programmatic interfaces, compressed archives, and downloadable spreadsheets, realizing the full potential of open data streams depends critically on the availability of targeted data analytical methods, and on user communities that can derive value from these digital resources. Interoperable software libraries have become a central element in modern statistical data analysis, bridging the gap between theory and practice, while open developer communities have emerged as a powerful driver of research software development. Drawing insights from a decade of community engagement, I propose the concept of open data science, which refers to the new forms of research enabled by open data, open methods, and open collaboration."}}
{"id": "0A4mGlBMoi", "cdate": 1514764800000, "mdate": null, "content": {"title": "A Hierarchical Ornstein-Uhlenbeck Model for Stochastic Time Series Analysis.", "abstract": "Longitudinal data is ubiquitous in research, and often complemented by broad collections of static background information. There is, however, a shortage of general-purpose statistical tools for studying the temporal dynamics of complex and stochastic dynamical systems especially when data is scarce, and the underlying mechanisms that generate the observation are poorly understood. Contemporary microbiome research provides a topical example, where vast cross-sectional and longitudinal collections of taxonomic profiling data from the human body and other environments are now being collected in various research laboratories world-wide. Many classical algorithms rely on long and densely sampled time series, whereas human microbiome studies typically have more limited sample sizes, short time spans, sparse sampling intervals, lack of replicates and high levels of unaccounted technical and biological variation. We demonstrate how non-parametric models can help to quantify key properties of a dynamical system when the actual data-generating mechanisms are largely unknown. Such properties include the locations of stable states, resilience of the system, and the levels of stochastic fluctuations. Moreover, we show how limited data availability can be compensated by pooling statistical evidence across multiple individuals or studies, and by incorporating prior information in the models. In particular, we derive and implement a hierarchical Bayesian variant of Ornstein-Uhlenbeck driven t-processes. This can be used to characterize universal dynamics in univariate, unimodal, and mean reversible systems based on multiple short time series. We validate the model with simulated data and investigate its applicability in characterizing temporal dynamics of human gut microbiome."}}
{"id": "94hk8fObRpw", "cdate": 1483228800000, "mdate": null, "content": {"title": "Retrieval and Analysis of Eurostat Open Data with the eurostat Package.", "abstract": "This article is licensed under a Creative Commons Attribution 4.0 International license . @article{RJ-2017-019, author "}}
{"id": "3iHrBqFKuXS", "cdate": 1483228800000, "mdate": null, "content": {"title": "Linking Statistical and Ecological Theory: Hubbell's Unified Neutral Theory of Biodiversity as a Hierarchical Dirichlet Process.", "abstract": "Neutral models which assume ecological equivalence between species provide null models for community assembly. In Hubbell's unified neutral theory of biodiversity (UNTB), many local communities are connected to a single metacommunity through differing immigration rates. Our ability to fit the full multisite UNTB has hitherto been limited by the lack of a computationally tractable and accurate algorithm. We show that a large class of neutral models with this mainland-island structure but differing local community dynamics converge in the large population limit to the hierarchical Dirichlet process. Using this approximation we developed an efficient Bayesian fitting strategy for the multisite UNTB. We can also use this approach to distinguish between neutral local community assembly given a nonneutral metacommunity distribution and the full UNTB where the metacommunity too assembles neutrally. We applied this fitting strategy to both tropical trees and a data set comprising 570 851 sequences from 278 human gut microbiomes. The tropical tree data set was consistent with the UNTB but for the human gut neutrality was rejected at the whole community level. However, when we applied the algorithm to gut microbial species within the same taxon at different levels of taxonomic resolution, we found that species abundances within some genera were almost consistent with local community assembly. This was not true at higher taxonomic ranks. This suggests that the gut microbiota is more strongly niche constrained than macroscopic organisms, with different groups adopting different functional roles, but within those groups diversity may at least partially be maintained by neutrality. We also observed a negative correlation between body mass index and immigration rates within the family Ruminococcaceae. This provides a novel interpretation of the impact of obesity on the human microbiome as a relative increase in the importance of local growth versus external immigration within this key group of carbohydrate degrading organisms."}}
{"id": "DdofpNIB9hV", "cdate": 1451606400000, "mdate": null, "content": {"title": "Printing in a Periphery: a Quantitative Study of Finnish Knowledge Production, 1640-1828.", "abstract": ""}}
{"id": "u0UKjgUckv", "cdate": 1420070400000, "mdate": null, "content": {"title": "Beyond open access: the changing culture of producing and disseminating scientific knowledge.", "abstract": "This is an extended abstract for the workshop \"Beyond Open Access - The Changing Culture of Producing and Disseminating Scientific Knowledge\", organized by the Open Knowledge Foundation Finland Open Science Working Group at the Academic Mindtrek Conference, 24 September 2015. The workshop organizers felt that the traditional model for disseminating scientific knowledge, through pay-walled peer-reviewed journal articles, has become both inefficient and unfair, and that the Open Access to publishing movement solves only part of the problem. The workshop took the four main functions of the academic article as a starting point for the discussion; a) dissemination of scientific knowledge, b) a forum for academic discussion, c) maintaining and monitoring the quality of research and d) determining academic merit. The aim was to reflect on alternative ways of meeting those functions, such that would support the principles of open science (transparency, accessibility, integrity). These alternatives included open research processes, altmetrics and open peer review. The effects of open practices on research integrity were also discussed. Recordings of the workshop presentations are available for viewing at bit.ly/beyond-open-access."}}
{"id": "qrvpdz8i0n", "cdate": 1356998400000, "mdate": null, "content": {"title": "Cancer gene prioritization by integrative analysis of mRNA expression and DNA copy number data: a comparative review.", "abstract": "A variety of genome-wide profiling techniques are available to investigate complementary aspects of genome structure and function. Integrative analysis of heterogeneous data sources can reveal higher level interactions that cannot be detected based on individual observations. A standard integration task in cancer studies is to identify altered genomic regions that induce changes in the expression of the associated genes based on joint analysis of genome-wide gene expression and copy number profiling measurements. In this review, we highlight common approaches to genomic data integration and provide a transparent benchmarking procedure to quantitatively compare method performances in cancer gene prioritization. Algorithms, data sets and benchmarking results are available at http://intcomp.r-forge.r-project.org."}}
