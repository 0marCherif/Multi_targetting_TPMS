{"id": "xIs9rtdnCJm", "cdate": 1640995200000, "mdate": 1667585999039, "content": {"title": "Multiagent Model-based Credit Assignment for Continuous Control", "abstract": ""}}
{"id": "fPvBWO35x08", "cdate": 1640995200000, "mdate": 1671891624692, "content": {"title": "Option Transfer and SMDP Abstraction with Successor Features", "abstract": "ion plays an important role in the generalisation of knowledge and skills and is key to sample efficient learning. In this work, we study joint temporal and state abstraction in reinforcement learning, where temporally-extended actions in the form of options induce temporal abstractions, while aggregation of similar states with respect to abstract options induces state abstractions. Many existing abstraction schemes ignore the interplay of state and temporal abstraction. Consequently, the considered option policies often cannot be directly transferred to new environments due to changes in the state space and transition dynamics. To address this issue, we propose a novel abstraction scheme building on successor features. This includes an algorithm for transferring abstract options across different environments and a state abstraction mechanism that allows us to perform efficient planning with the transferred options."}}
{"id": "vieHT2Gexd", "cdate": 1609459200000, "mdate": 1671891624699, "content": {"title": "MDP Abstraction with Successor Features", "abstract": "ion plays an important role in the generalisation of knowledge and skills and is key to sample efficient learning. In this work, we study joint temporal and state abstraction in reinforcement learning, where temporally-extended actions in the form of options induce temporal abstractions, while aggregation of similar states with respect to abstract options induces state abstractions. Many existing abstraction schemes ignore the interplay of state and temporal abstraction. Consequently, the considered option policies often cannot be directly transferred to new environments due to changes in the state space and transition dynamics. To address this issue, we propose a novel abstraction scheme building on successor features. This includes an algorithm for transferring abstract options across different environments and a state abstraction mechanism that allows us to perform efficient planning with the transferred options."}}
{"id": "g8qkC04P0RD", "cdate": 1609459200000, "mdate": 1671891624707, "content": {"title": "Behavioural strategies in weighted Boolean games", "abstract": ""}}
{"id": "Z-xJeL9Pl_3", "cdate": 1577836800000, "mdate": null, "content": {"title": "Replication-Robust Payoff-Allocation with Applications in Machine Learning Marketplaces", "abstract": "Submodular functions have been a powerful mathematical model for a wide range of real-world applications. Recently, submodular functions are becoming increasingly important in machine learning (ML) for modelling notions such as information and redundancy among entities such as data and features. Among these applications, a key question is payoff allocation, i.e., how to evaluate the importance of each entity towards the collective objective? To this end, classic solution concepts from cooperative game theory offer principled approaches to payoff allocation. However, despite the extensive body of game-theoretic literature, payoff allocation in submodular games are relatively under-researched. In particular, an important notion that arises in the emerging submodular applications is redundancy, which may occur from various sources such as abundant data or malicious manipulations where a player replicates its resource and act under multiple identities. Though many game-theoretic solution concepts can be directly used in submodular games, naively applying them for payoff allocation in these settings may incur robustness issues against replication. In this paper, we systematically study the replication manipulation in submodular games and investigate replication robustness, a metric that quantitatively measures the robustness of solution concepts against replication. Using this metric, we present conditions which theoretically characterise the robustness of semivalues, a wide family of solution concepts including the Shapley and Banzhaf value. Moreover, we empirically validate our theoretical results on an emerging submodular ML application, i.e., the ML data market."}}
{"id": "jMzp7kS5ZjZ", "cdate": 1546300800000, "mdate": 1671891624708, "content": {"title": "Multi-Agent Hierarchical Reinforcement Learning with Dynamic Termination", "abstract": "In a multi-agent system, an agent's optimal policy will typically depend on the policies of other agents. Predicting the behaviours of others, and responding promptly to changes in such behaviours, is therefore a key issue in multi-agent systems research. One obvious possibility is for each agent to broadcast their current intention, for example, the currently executed option in a hierarchical RL framework. However, this approach results in inflexible agents when options have an extended duration. While adjusting the executed option at each step improves flexibility from a single-agent perspective, frequent changes in options can induce inconsistency between an agent's actual behaviour and its broadcasted intention. In order to balance flexibility and predictability, we propose a dynamic termination Bellman equation that allows the agents to flexibly terminate their options."}}
{"id": "HN47-uHWomh", "cdate": 1546300800000, "mdate": 1671891624696, "content": {"title": "Multi-agent Hierarchical Reinforcement Learning with Dynamic Termination", "abstract": ""}}
