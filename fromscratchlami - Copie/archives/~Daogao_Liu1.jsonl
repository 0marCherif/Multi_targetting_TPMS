{"id": "nQ4DQ3_6yi0", "cdate": 1672531200000, "mdate": 1681635728365, "content": {"title": "ReSQueing Parallel and Private Stochastic Convex Optimization", "abstract": ""}}
{"id": "myJURQZ9nU", "cdate": 1672531200000, "mdate": 1682331381565, "content": {"title": "Super-resolution and Robust Sparse Continuous Fourier Transform in Any Constant Dimension: Nearly Linear Time and Sample Complexity", "abstract": "The ability to resolve detail in the object that is being imaged, named by resolution, is the core parameter of an imaging system. Super-resolution is a class of techniques that can enhance the resolution of an imaging system and even transcend the diffraction limit of systems. Despite huge success in the application, super-resolution is not well understood on the theoretical side, especially for any dimension d \u2265 2. In particular, in order to recover a k-sparse signal, all previous results suffer from either/both poly(k) samples or running time. We design robust algorithms for any (constant) dimension under a strong noise model based on developing some new techniques in Sparse Fourier transform (Sparse FT), such as inverting a robust linear system, \u201ceggshell\u201d sampling schemes, and partition and voting methods in high dimension. These algorithms are the first to achieve running time and sample complexity (nearly) linear in the number of source points and logarithmic in bandwidth for any constant dimension, and we believe the techniques developed in the work can find their further applications on the Super-resolution and Sparse FT problem. * The full version of the paper can be accessed at https://arxiv.org/abs/2005.06156"}}
{"id": "_7oMvSClaP", "cdate": 1672531200000, "mdate": 1681753835154, "content": {"title": "Private (Stochastic) Non-Convex Optimization Revisited: Second-Order Stationary Points and Excess Risks", "abstract": "We consider the problem of minimizing a non-convex objective while preserving the privacy of the examples in the training data. Building upon the previous variance-reduced algorithm SpiderBoost, we introduce a new framework that utilizes two different kinds of gradient oracles. The first kind of oracles can estimate the gradient of one point, and the second kind of oracles, less precise and more cost-effective, can estimate the gradient difference between two points. SpiderBoost uses the first kind periodically, once every few steps, while our framework proposes using the first oracle whenever the total drift has become large and relies on the second oracle otherwise. This new framework ensures the gradient estimations remain accurate all the time, resulting in improved rates for finding second-order stationary points. Moreover, we address a more challenging task of finding the global minima of a non-convex objective using the exponential mechanism. Our findings indicate that the regularized exponential mechanism can closely match previous empirical and population risk bounds, without requiring smoothness assumptions for algorithms with polynomial running time. Furthermore, by disregarding running time considerations, we show that the exponential mechanism can achieve a good population risk bound and provide a nearly matching lower bound."}}
{"id": "YwaI-KFU66U", "cdate": 1672531200000, "mdate": 1682331381626, "content": {"title": "kNN-Adapter: Efficient Domain Adaptation for Black-Box Language Models", "abstract": "Fine-tuning a language model on a new domain is standard practice for domain adaptation. However, it can be infeasible when it comes to modern large-scale language models such as GPT-3, which can only be accessed through APIs, making it difficult to access the internal parameters of the model. In this paper, we propose $k$NN-Adapter, a method to effectively adapt these black-box large language models (LLMs) to a new domain. The $k$NN-Adapter builds on top of the retrieval-augmented language model, and adaptively learns to interpolate the output of the language model with retrieval results from a datastore consisting of the target domain data. Our experiments on four different domains demonstrate that $k$NN-Adapter significantly improves perplexity, and works particularly well in settings with limited access to LLMs. Additionally, we show that $k$NN-Adapter is more effective than fine-tuning when the amount of training data is limited. We also release a dataset to encourage further study."}}
{"id": "62t6xU994fe", "cdate": 1672531200000, "mdate": 1682331381772, "content": {"title": "Algorithmic Aspects of the Log-Laplace Transform and a Non-Euclidean Proximal Sampler", "abstract": "The development of efficient sampling algorithms catering to non-Euclidean geometries has been a challenging endeavor, as discretization techniques which succeed in the Euclidean setting do not readily carry over to more general settings. We develop a non-Euclidean analog of the recent proximal sampler of [LST21], which naturally induces regularization by an object known as the log-Laplace transform (LLT) of a density. We prove new mathematical properties (with an algorithmic flavor) of the LLT, such as strong convexity-smoothness duality and an isoperimetric inequality, which are used to prove a mixing time on our proximal sampler matching [LST21] under a warm start. As our main application, we show our warm-started sampler improves the value oracle complexity of differentially private convex optimization in $\\ell_p$ and Schatten-$p$ norms for $p \\in [1, 2]$ to match the Euclidean setting [GLL22], while retaining state-of-the-art excess risk bounds [GLLST23]. We find our investigation of the LLT to be a promising proof-of-concept of its utility as a tool for designing samplers, and outline directions for future exploration."}}
{"id": "0R0maNuPds", "cdate": 1672531200000, "mdate": 1682331381565, "content": {"title": "Private Convex Optimization in General Norms", "abstract": "We propose a new framework for differentially private optimization of convex functions which are Lipschitz in an arbitrary norm ||\u00b7||x. Our algorithms are based on a regularized exponential mechanism which samples from the density \u221e exp(-k(F + \u03bcr)) where F is the empirical loss and \u03c4 is a regularizer which is strongly convex with respect to ||\u00b7||x, generalizing a recent work of [GLL22] to non-Euclidean settings. We show that this mechanism satisfies Gaussian differential privacy and solves both DP-ERM (empirical risk minimization) and DP-SCO (stochastic convex optimization), by using localization tools from convex geometry. Our framework is the first to apply to private convex optimization in general normed spaces, and directly recovers non-private SCO rates achieved by mirror descent, as the privacy parameter \u03b5 \u2192 \u221e. As applications, for Lipschitz optimization in \u2113p norms for all p \u2208 (1, 2), we obtain the first optimal privacy-utility tradeoffs; for p = 1, we improve tradeoffs obtained by the recent works [AFKT21, BGN21] by at least a logarithmic factor. Our \u2113p norm and Schatten-p norm optimization frameworks are complemented with polynomial-time samplers whose query complexity we explicitly bound."}}
{"id": "kPPVmUF6bM_", "cdate": 1663850382908, "mdate": null, "content": {"title": "Augmentation with Projection: Towards an Effective and Efficient Data Augmentation Paradigm for Distillation", "abstract": "Knowledge distillation is one of the primary methods of transferring knowledge from large to small models. However, it requires massive task-specific data, which may not be plausible in many real-world applications. Data augmentation methods such as representation interpolation, token replacement, or augmentation with models are applied to tackle this problem. However, these data augmentation methods either potentially cause shifts in decision boundaries (representation interpolation), are not expressive enough (token replacement), or introduce too much computational overhead (augmentation with models). To this end, we propose AugPro (Augmentation with Projection), an effective and efficient data augmentation method for distillation. Our method builds on top of representation interpolation augmentation methods to maintain the diversity of expressions and converts the augmented data to tokens to avoid shifting decision boundaries. It uses simple operations that come with little computational overhead. The results on multiple GLUE tasks show that our methods can improve distillation performance by a large margin at a low time cost."}}
{"id": "Jqas82UP428", "cdate": 1663850039767, "mdate": null, "content": {"title": "Lower Bounds for Differentially Private ERM: Unconstrained and Non-Euclidean", "abstract": "We consider the lower bounds of differentially private empirical risk minimization (DP-ERM) for convex functions in both constrained and unconstrained cases concerning the general $\\ell_p$ norm beyond the $\\ell_2$ norm considered by most of the previous works.\n\nWe provide a simple black-box reduction approach that can generalize lower bounds in constrained to unconstrained cases.\nMoreover, for $(\\epsilon,\\delta)$-DP, we achieve the optimal $\\Omega(\\frac{\\sqrt{d \\log(1/\\delta)}}{\\epsilon n})$ lower bounds for both constrained and unconstrained cases and any $\\ell_p$ geometry where $p\\geq 1$ by considering $\\ell_1$ loss over the $\\ell_{\\infty}$ ball."}}
{"id": "bzpCoHn1Vc_", "cdate": 1663850039533, "mdate": null, "content": {"title": "The Convergence Rate of SGD's Final Iterate: Analysis on Dimension Dependence", "abstract": "Stochastic Gradient Descent (SGD) is among the simplest and most popular optimization and machine learning methods. Running SGD with a fixed step size and outputting the final iteration is an ideal strategy one can hope for, but it is still not well-understood even though SGD has been studied extensively for over 70 years. Given the $\\Theta(\\log T)$ gap between current upper and lower bounds for running SGD for $T$ steps, it was then asked by [Koren and Segal COLT 20'] how to characterize the final-iterate convergence of SGD with a fixed step size in the constant dimension setting, i.e., $d=O(1)$. \n\nIn this paper, we consider the more general setting for any $d\\leq T$, proving $\\Omega(\\log d/\\sqrt{T})$ lower bounds for the sub-optimality of the final iterate of SGD in minimizing non-smooth Lipschitz convex functions with standard step sizes. Our results provide the first general dimension-dependent lower bound on the convergence of SGD's final iterate, partially resolving the COLT open question raised by [Koren and Segal COLT 20'].\nMoreover, we present a new method in one dimension based on martingale and Freedman\u2019s inequality, which gets the tight $O(1/\\sqrt{T})$ upper bound with mild assumptions and recovers the same bounds $O(\\log T/\\sqrt{T})$ as previous best results under the standard assumptions."}}
{"id": "FR--mkQu0dw", "cdate": 1652737822591, "mdate": null, "content": {"title": "When Does Differentially Private Learning Not Suffer in High Dimensions?", "abstract": "Large pretrained models can be fine-tuned with differential privacy to achieve performance approaching that of non-private models. A common theme in these results is the surprising observation that high-dimensional models can achieve favorable privacy-utility trade-offs. This seemingly contradicts known results on the model-size dependence of differentially private convex learning and raises the following research question: When does the performance of differentially private learning not degrade with increasing model size? We identify that the magnitudes of gradients projected onto subspaces is a key factor that determines performance. To precisely characterize this for private convex learning, we introduce a condition on the objective that we term restricted Lipschitz continuity and derive improved bounds for the excess empirical and population risks that are dimension- independent under additional conditions. We empirically show that in private fine-tuning of large language models, gradients obtained during fine-tuning are mostly controlled by a few principal components. This behavior is similar to conditions under which we obtain dimension-independent bounds in convex settings. Our theoretical and empirical results together provide a possible explanation for the recent success of large-scale private fine-tuning. Code to reproduce our results can be found at https://github.com/lxuechen/private-transformers/tree/main/examples/classification/spectral_analysis. "}}
