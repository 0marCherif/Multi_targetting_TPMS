{"id": "rXiZMBJBdB", "cdate": 1664310942103, "mdate": null, "content": {"title": "Action Matching: A Variational Method for Learning Stochastic Dynamics from Samples", "abstract": "Stochastic dynamics are ubiquitous in many fields of science, from the evolution of quantum systems in physics to diffusion-based models in machine learning. Existing methods such as score matching can be used to simulate these physical processes by assuming that the dynamics is a diffusion, which is not always the case. In this work, we propose a method called \"Action Matching\" that enables us to learn a much broader family of stochastic dynamics. Our method requires access only to samples from different time-steps, makes no explicit assumptions about the underlying dynamics, and can be applied even when samples are uncorrelated (i.e., are not part of a trajectory). Action Matching directly learns an underlying mechanism to move samples in time without modeling the distributions at each time-step. In this work, we showcase how Action Matching can be used for several computer vision tasks such as generative modeling, super-resolution, colorization, and inpainting; and further, discuss potential applications in other areas of science."}}
{"id": "T6HPzkhaKeS", "cdate": 1663850373432, "mdate": null, "content": {"title": "Action Matching: A Variational Method for Learning Stochastic Dynamics from Samples", "abstract": "Stochastic dynamics are ubiquitous in many fields of science, from the evolution of quantum systems in physics to diffusion-based models in machine learning. Existing methods such as score matching can be used to simulate these physical processes by assuming that the dynamics is a diffusion, which is not always the case. In this work, we propose a method called \"Action Matching\" that enables us to learn a much broader family of stochastic dynamics. Our method requires access only to samples from different time-steps, makes no explicit assumptions about the underlying dynamics, and can be applied even when samples are uncorrelated (i.e., are not part of a trajectory). Action Matching directly learns an underlying mechanism to move samples in time without modeling the distributions at each time-step. In this work, we showcase how Action Matching can be used for several computer vision tasks such as generative modeling, super-resolution, colorization, and inpainting; and further discuss potential applications in other areas of science."}}
{"id": "oNJ5sDeUpw", "cdate": 1640995200000, "mdate": 1683896925453, "content": {"title": "Compressing Multisets with Large Alphabets", "abstract": "Current methods which compress multisets at an optimal rate have computational complexity that scales linearly with alphabet size, making them too slow to be practical in many real-world settings. We show how to convert a compression algorithm for sequences into one for multisets, in exchange for an additional complexity term that is quasi-linear in sequence length. This allows us to compress multisets of independent and identically distributed symbols at an optimal rate, with computational complexity decoupled from the alphabet size. The key insight is to avoid encoding the multiset directly, and instead compress a proxy sequence, using a technique called \u2018bits-back coding\u2019. We demonstrate the method experimentally on two tasks which are intractible with previous optimal-rate methods: compression of multisets of images and JavaScript Object Notation (JSON) files. Code for our experiments is available at https://github.com/facebookresearch/multiset-compression."}}
{"id": "b2JT_8BE-Rp", "cdate": 1640995200000, "mdate": 1683896925419, "content": {"title": "Data-Driven Optimization for Zero-Delay Lossy Source Coding with Side Information", "abstract": "This paper proposes a data-driven architecture for zero-delay lossy source coding with side information (i.e., Wyner-Ziv coding) for sources with memory. The overall architecture involves designing suitable filters at the encoder and the decoder and performing fixed-rate scalar quantization followed by one-dimensional binning of quantization indices. Unlike previous work, which uses an exhaustive search to optimize the system parameters, this paper proposes a lower-complexity data-driven method that does not require a priori knowledge of source and side information statistics. The main ingredients of the proposed approach include modeling the quantization process by an additive quantization noise process, modeling the modulo operation by a continuous approximation, and approximating the decoding process by a softmin function, which makes the system amenable to training using stochastic gradient descent. Experimental results on Gauss-Markov sources with different memory orders demonstrate that our proposed system can match the performance of systems optimized using an exhaustive search."}}
{"id": "TVkBP0-bA0U", "cdate": 1640995200000, "mdate": 1683896925532, "content": {"title": "Action Matching: A Variational Method for Learning Stochastic Dynamics from Samples", "abstract": "Learning the continuous dynamics of a system from snapshots of its temporal marginals is a problem which appears throughout natural sciences and machine learning, including in quantum systems, single-cell biological data, and generative modeling. In these settings, we assume access to cross-sectional samples that are uncorrelated over time, rather than full trajectories of samples. In order to better understand the systems under observation, we would like to learn a model of the underlying process that allows us to propagate samples in time and thereby simulate entire individual trajectories. In this work, we propose Action Matching, a method for learning a rich family of dynamics using only independent samples from its time evolution. We derive a tractable training objective, which does not rely on explicit assumptions about the underlying dynamics and does not require back-propagation through differential equations or optimal transport solvers. Inspired by connections with optimal transport, we derive extensions of Action Matching to learn stochastic differential equations and dynamics involving creation and destruction of probability mass. Finally, we showcase applications of Action Matching by achieving competitive performance in a diverse set of experiments from biology, physics, and generative modeling."}}
{"id": "vjrsNCu8Km", "cdate": 1632765016589, "mdate": null, "content": {"title": "Your Dataset is a Multiset and You Should Compress it Like One", "abstract": "Neural Compressors (NCs) are codecs that leverage neural networks and entropy coding to achieve competitive compression performance for images, audio, and other data types. These compressors exploit parallel hardware, and are particularly well suited to compressing i.i.d. batches of data. The average number of bits needed to represent each example is at least the well-known cross-entropy. However, the cross-entropy bound assumes the order of the compressed examples in a batch is preserved, which in many applications is not necessary. The number of bits used to implicitly store the order information is the logarithm of the number of unique permutations of the dataset. In this work, we present a method that reduces the bitrate of any codec by exactly the number of bits needed to store the order, at the expense of shuffling the dataset in the process. Conceptually, our method applies bits-back coding to a latent variable model with observed symbol counts (i.e. multiset) and a latent permutation defining the ordering, and does not require retraining any models. We present experiments with both lossy off-the-shelf codecs (WebP) as well as lossless NCs. On Binarized MNIST, lossless NCs achieved savings of up to $7.6\\%$, while adding only $10\\%$ extra compute time."}}
{"id": "pZhSCfqSskE", "cdate": 1614887118389, "mdate": null, "content": {"title": "Improving Lossless Compression Rates via Monte Carlo Bits-Back Coding", "abstract": "Latent variable models have been successfully applied in lossless compression with the bits-back coding algorithm. However, bits-back suffers from an increase in the bitrate equal to the KL divergence between the approximate posterior and the true posterior. In this paper, we show how to remove this gap asymptotically by deriving bits-back schemes from tighter variational bounds. The key idea is to exploit extended space representations of Monte Carlo estimators of the marginal likelihood. Naively applied, our schemes would require more initial bits than the standard bits-back coder, but we show how to drastically reduce this additional cost with couplings in the latent space. We demonstrate improved lossless compression rates in a variety of settings."}}
{"id": "rGvEPWvjVyC", "cdate": 1609459200000, "mdate": 1651948755520, "content": {"title": "Improving Lossless Compression Rates via Monte Carlo Bits-Back Coding", "abstract": "Latent variable models have been successfully applied in lossless compression with the bits-back coding algorithm. However, bits-back suffers from an increase in the bitrate equal to the KL divergence between the approximate posterior and the true posterior. In this paper, we show how to remove this gap asymptotically by deriving bits-back coding algorithms from tighter variational bounds. The key idea is to exploit extended space representations of Monte Carlo estimators of the marginal likelihood. Naively applied, our schemes would require more initial bits than the standard bits-back coder, but we show how to drastically reduce this additional cost with couplings in the latent space. When parallel architectures can be exploited, our coders can achieve better rates than bits-back with little additional cost. We demonstrate improved lossless compression rates in a variety of settings, especially in out-of-distribution or sequential data compression."}}
{"id": "MVJwW_ogWm", "cdate": 1609459200000, "mdate": 1683896925504, "content": {"title": "Predi\u00e7\u00e3o de Incid\u00eancia de Les\u00e3o por Press\u00e3o em Pacientes de UTI usando Aprendizado de M\u00e1quina", "abstract": "Pressure ulcers have high prevalence in ICU patients but are preventable if identified in initial stages. In practice, the Braden scale is used to classify high-risk patients. This paper investigates the use of machine learning in electronic health records data for this task, by using data available in MIMIC-III v1.4. Two main contributions are made: a new approach for evaluating models that considers all predictions made during a stay, and a new training method for the machine learning models. The results show a superior performance in comparison to the state of the art; moreover, all models surpass the Braden scale in every operating point in the precision-recall curve. -- -- Les\\~oes por press\\~ao possuem alta preval\\^encia em pacientes de UTI e s\\~ao preven\\'iveis ao serem identificadas em est\\'agios iniciais. Na pr\\'atica utiliza-se a escala de Braden para classifica\\c{c}\\~ao de pacientes em risco. Este artigo investiga o uso de aprendizado de m\\'aquina em dados de registros eletr\\^onicos para este fim, a partir da base de dados MIMIC-III v1.4. S\\~ao feitas duas contribui\\c{c}\\~oes principais: uma nova abordagem para a avalia\\c{c}\\~ao dos modelos e da escala de Braden levando em conta todas as predi\\c{c}\\~oes feitas ao longo das interna\\c{c}\\~oes, e um novo m\\'etodo de treinamento para os modelos de aprendizado de m\\'aquina. Os resultados obtidos superam o estado da arte e verifica-se que os modelos superam significativamente a escala de Braden em todos os pontos de opera\\c{c}\\~ao da curva de precis\\~ao por sensibilidade."}}
{"id": "Hhz-j9z9Leq", "cdate": 1609459200000, "mdate": 1645810322521, "content": {"title": "Improving Lossless Compression Rates via Monte Carlo Bits-Back Coding", "abstract": "Latent variable models have been successfully applied in lossless compression with the bits-back coding algorithm. However, bits-back suffers from an increase in the bitrate equal to the KL diverge..."}}
