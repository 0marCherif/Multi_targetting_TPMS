{"id": "sTQi_TCSxb7", "cdate": 1652577939095, "mdate": 1652577939095, "content": {"title": "Instance-level Image Retrieval using Reranking Transformers", "abstract": "Instance-level image retrieval is the task of searching in a large database for images that match an object in a query image. To address this task, systems usually rely on a retrieval step that uses global image descriptors, and a subsequent step that performs domain-specific refinements or reranking by leveraging operations such as geometric verification based on local features. In this work, we propose Reranking Transformers (RRTs) as a general model to incorporate both local and global features to rerank the matching images in a supervised fashion and thus replace the relatively expensive process of geometric verification. RRTs are lightweight and can be easily parallelized so that reranking a set of top matching results can be performed in a single forward-pass. We perform extensive experiments on the Revisited Oxford and Paris datasets, and the Google Landmarks v2 dataset, showing that RRTs outperform previous reranking approaches while using much fewer local descriptors. Moreover, we demonstrate that, unlike existing approaches, RRTs can be optimized jointly with the feature extractor, which can lead to feature representations tailored to downstream tasks and further accuracy improvements."}}
{"id": "riggWeXXxuar", "cdate": 1546300800000, "mdate": null, "content": {"title": "Fashion-AttGAN: Attribute-Aware Fashion Editing With Multi-Objective GAN.", "abstract": "In this paper, we introduce a novel task, namely attribute-aware fashion-editing, to the fashion domain. A first dataset is constructed for this task with 14,221 images and 22 attributes, which has been made publically available. We re-define the overall objectives in AttGAN and propose the Fashion-AttGAN model to tackle this new task. Experimental results show effectiveness of our Fashion-AttGAN on fashion editing over the original AttGAN."}}
{"id": "Sy41D9WOZr", "cdate": 1325376000000, "mdate": null, "content": {"title": "Efficient Mining of Repetitions in Large-Scale TV Streams with Product Quantization Hashing", "abstract": "Duplicates or near-duplicates mining in video sequences is of broad interest to many multimedia applications. How to design an effective and scalable system, however, is still a challenge to the community. In this paper, we present a method to detect recurrent sequences in large-scale TV streams in an unsupervised manner and with little a priori knowledge on the content. The method relies on a product k-means quantizer that efficiently produces hash keys adapted to the data distribution for frame descriptors. This hashing technique combined with a temporal consistency check allows the detection of meaningful repetitions in TV streams. When considering all frames (about 47 millions) of a 22-day long TV broadcast, our system detects all repetitions in 15 minutes, excluding the computation of the frame descriptors. Experimental results show that our approach is a promising way to deal with very large video databases."}}
