{"id": "SMDSkDx_YpM", "cdate": 1695984566044, "mdate": 1695984566044, "content": {"title": "Constructing Deep Spiking Neural Networks from Artificial Neural Networks with Knowledge Distillation", "abstract": "Spiking neural networks (SNNs) are well known as the brain-inspired models with high computing efficiency, due to a key component that they utilize spikes as information units, close to the biological neural systems. Although spiking based models are energy efficient by taking advantage of discrete spike signals, their performance is limited by current network structures and their training methods. As discrete signals, typical SNNs cannot apply the gradient descent rules directly into parameters adjustment as artificial neural networks (ANNs). Aiming at this limitation, here we propose a novel method of constructing deep SNN models with knowledge distillation (KD) that uses ANN as teacher model and SNN as student model. Through ANN-SNN joint training algorithm, the student SNN model can learn rich feature information from the teacher ANN model through the KD method, yet it avoids training SNN from scratch when communicating with non-differentiable spikes. Our method can not only build a more efficient deep spiking structure feasibly and reasonably, but use few time steps to train whole model compared to direct training or ANN to SNN methods. More importantly, it has a superb ability of noise immunity for various types of artificial noises and natural signals. The proposed novel method provides efficient ways to improve the performance of SNN through constructing deeper structures in a high-throughput fashion, with potential usage for light and efficient brain-inspired computing of practical scenarios."}}
{"id": "Da0pXPFkDGk", "cdate": 1683273356501, "mdate": 1683273356501, "content": {"title": "ESL-SNNs: An Evolutionary Structure Learning Strategy For Spiking Neural Networks", "abstract": "Spiking neural networks (SNNs) have manifested remarkable advantages in power consumption and event-driven property during the inference process. To take full advantage of low power consumption and improve the efficiency of these models further, the pruning methods have been explored to find sparse SNNs without redundancy connections after training. However, parameter redundancy still hinders the efficiency of SNNs during training. In the human brain, the rewiring process of neural networks is highly dynamic, while synaptic connections maintain relatively sparse during brain development. Inspired by this, here we propose an efficient evolutionary structure learning (ESL) framework for SNNs, named ESL-SNNs, to implement the sparse SNN training from scratch. The pruning and regeneration of synaptic connections in SNNs evolve dynamically during learning, yet keep the structural sparsity at a certain level. As a result, the ESL-SNNs can search for optimal sparse connectivity by exploring all possible parameters across time. Our experiments show that the proposed ESL-SNNs framework is able to learn SNNs with sparse structures effectively while reducing the limited accuracy. The ESL-SNNs achieve merely 0.28% accuracy loss with 10% connection density on the DVS-Cifar10 dataset. Our work presents a brand-new approach for sparse training of SNNs from scratch with biologically plausible evolutionary mechanisms, closing the gap in the expressibility between sparse training and dense training. Hence, it has great potential for SNN lightweight training and inference with low power consumption and small memory usage."}}
{"id": "Zd4hTGjpMNm", "cdate": 1663850212609, "mdate": null, "content": {"title": "A computational framework to unify representation similarity and function in biological and artificial neural networks", "abstract": "Artificial neural network (ANN) is a versatile tool to study the neural representation in the ventral visual stream, and the knowledge in neuroscience in return inspires ANN models to improve performance in the task. However, it is still unclear how to merge these two directions into a unified framework. In this study, we propose an integrated framework called Deep Autoencoder with Neural Response (DAE-NR), which incorporates information from ANN and the visual cortex to achieve better image reconstruction performance and higher neural representation similarity between biological and artificial neurons. The same visual stimuli (i.e., natural images) are input to both the mice brain and DAE-NR. The encoder of DAE-NR jointly learns the dependencies from neural spike encoding and image reconstruction. For the neural spike encoding task, the features derived from a specific hidden layer of the encoder are transformed by a mapping function to predict the ground-truth neural response under the constraint of image reconstruction. Simultaneously, for the image reconstruction task, the latent representation obtained by the encoder is assigned to a decoder to restore the original image under the guidance of neural information. In DAE-NR, the learning process of encoder, mapping function and decoder are all implicitly constrained by these two tasks. Our experiments demonstrate that if and only if with the joint learning, DAE-NRs can improve the performance of visual image reconstruction and increase the representation similarity between biological neurons and artificial neurons. The DAE-NR offers a new perspective on the integration of computer vision and neuroscience."}}
{"id": "_-BHVPvT8Wm", "cdate": 1601308163896, "mdate": null, "content": {"title": "Bigeminal Priors Variational Auto-encoder", "abstract": "Variational auto-encoders (VAEs) are an influential and generally-used class of likelihood-based generative models in unsupervised learning. The likelihood-based generative models have been reported to be highly robust to the out-of-distribution (OOD) inputs and can be a detector by assuming that the model assigns higher likelihoods to the samples from the in-distribution (ID) dataset than an OOD dataset. However, recent works reported a phenomenon that VAE recognizes some OOD samples as ID by assigning a higher likelihood to the OOD inputs compared to the one from ID.  In this work, we introduce a new model, namely \\textit{Bigeminal Priors Variational auto-encoder (BPVAE)}, to address this phenomenon. The BPVAE aims to enhance the robustness of the VAEs by combing the power of VAE with the two independent priors that belong to the training dataset and simple dataset, which complexity is lower than the training dataset, respectively. BPVAE learns two datasets\u2019 features, assigning a higher likelihood for the training dataset than the simple dataset. In this way, we can use BPVAE\u2019s density estimate for detecting the OOD samples. Quantitative experimental results suggest that our model has better generalization capability and stronger robustness than the standard VAEs, proving the effectiveness of the proposed approach of hybrid learning by collaborative priors. Overall, this work paves a new avenue to potentially overcome the OOD problem via multiple latent priors modeling."}}
{"id": "ETBYiC8l6c", "cdate": 1601085166958, "mdate": null, "content": {"title": "Multiscale Spatio-Temporal Features for AER Object Recognition Using Unsupervised Spiking Neural Networks.", "abstract": "This paper proposes an unsupervised address event representation (AER) object recognition approach. The proposed approach consists of a novel multiscale spatio-temporal feature (MuST) representation of input AER events and a spiking neural network (SNN) using spike-timing-dependent plasticity (STDP) for object recognition with MuST. MuST extracts the features contained in both the spatial and temporal information of AER event \ufb02ow, and meanwhile forms an informative and compact feature spike representation. We show not only how MuST exploits spikes to convey information more effectively, but also how it bene\ufb01ts the recognition using SNN. The recognition process is performed in an unsupervised manner, which does not need to specify the desired status of every single neuron of SNN, and thus can be \ufb02exibly applied in real-world recognition tasks. The experiments are performed on \ufb01ve AER datasets including a new one named GESTURE-DVS. Extensive experimental results show the effectiveness and advantages of this proposed approach."}}
{"id": "SC4N__4NCdm", "cdate": 1601085086789, "mdate": null, "content": {"title": "SparseConnect: Regularizing CNNs on Fully-Connected Layers", "abstract": "Deep Convolutional Neural Networks (CNNs) have achieved unprecedented success in many domains. The numerous parameters allow CNNs to learn complex features, but also tend to hinder generalization by over-\ufb01tting training data. Despite many previously proposed regularization methods, over-\ufb01tting is one of many problems in training a robust CNN. Among many factors that may lead to over\ufb01tting, the numerous parameters of Fully-Connected Layers (FCLs) of a typical CNN are a contributor to the over-\ufb01tting problem. We propose SparseConnect, which alleviates over-\ufb01tting by sparsifying connections to FCLs. Experimental results on three benchmark datasets MNIST and CIFAR10 show SparseConnect outperforms several state-of-the-art regularization methods."}}
{"id": "SJ84ZNw008N", "cdate": 1601085023399, "mdate": null, "content": {"title": "Over\ufb01tting remedy by sparsifying regularization on fully-connected layers of CNNs", "abstract": "Deep learning, especially Convolutional Neural Networks (CNNs), has been widely applied in many domains. The large number of parameters in a CNN allow it to learn complex features, however, they may tend to hinder generalization by over-\ufb01tting training data. Despite many previously proposed regularization methods, over-\ufb01tting is still a problem in training a robust CNN. Among many factors that lead to over-\ufb01tting, the numerous parameters of fully-connected layers (FCLs) of a typical CNN should be taken into account. This paper proposes the SparseConnect, a simple idea which alleviates over-\ufb01tting by sparsifying connections to FCLs. Experimental results on three benchmark datasets MNIST, CIFAR10 and ImageNet show that the SparseConnect outperforms several state-of-the-art regularization methods."}}
{"id": "3pfErxyBZZU", "cdate": 1601084937672, "mdate": null, "content": {"title": "Darwin: A neuromorphic hardware co-processor based on spiking neural networks", "abstract": "Spiking Neural Network (SNN) is a type of biologically-inspired neural networks that perform information processing based on discrete-time spikes, different from traditional Arti\ufb01cial Neural Network (ANN). Hardware implementation of SNNs is necessary for achieving high-performance and low-power. We present the Darwin Neural Processing Unit (NPU), a highly-con\ufb01gurable neuromorphic hardware coprocessor based on SNN implemented with digital logic, supporting a con\ufb01gurable number of neurons, synapses and synaptic delays. The Darwin NPU was fabricated by standard 180 nm CMOS technology with area size of 5 \u00d7 5 mm 2 and 70 MHz clock frequency at the worst case. It consumes 0.84 mW/MHz with 1.8 V power supply for typical applications. Two prototype applications are used to demonstrate the performance and e\ufb03ciency of the Darwin NPU."}}
{"id": "PLA_lcIpF_M", "cdate": 1601084829656, "mdate": null, "content": {"title": "DSPD: A deep spike-to-pattern decoder for the multimodality of brain-machine interface", "abstract": "Neural coding, including encoding and decoding, is one of the key problems in the brain-machine interface (BMI) for understanding how the brain uses neural signals to relate sensory perception and motor behaviors with neural systems. Moreover, it is also the cornerstone for building a robust pattern reconstruction for controlling the physical devices interplayed with neural signals. However, most of the existed studies only aim at dealing with the analogy signal of neural systems, while lacking a unique feature of biological neurons, termed spikes, which is the fundamental information unit for neural computation as well as a building block for neuromorphic computing. Aiming at these limitations, we propose a robust pattern reconstruction model named deep spike-to-pattern decoder (DSPD) to reconstruct multi-modal stimuli from the event-driven nature of spikes. Using about 5% of information represented in terms of spikes, the proposed DSPD can not only feasibly and accurately reconstruct dynamical visual and auditory scenes, but also rebuild the stimulus patterns from fMRI brain activities. The experimental results demonstrate the DSPD can achieve state-of-the-art performance. Importantly, it has a superb ability of noise-immunity for various types of arti\ufb01cial noises and background signals. The proposed framework provides ef\ufb01cient ways to perform multimodal feature representation and reconstruction in a high-throughput fashion, with potential usage for the next generation of BMI."}}
{"id": "OjjHanEF13Z", "cdate": 1601084764839, "mdate": null, "content": {"title": "Deep CovDenseSNN:  A hierarchical event-driven dynamic framework with spiking neurons in noisy environment.", "abstract": "Neurons in the brain use an event signal, termed spike, encode temporal information for neural computation. Spiking neural networks (SNNs) take this advantage to serve as biological relevant models. However, the e\ufb00ective encoding of sensory information and also its integration with downstream neurons of SNNs are limited by the current shallow structures and learning algorithms. To tackle this limitation, this paper proposes a novel hybrid framework combining the feature learning ability of continuous-valued convolutional neural networks (CNNs) and SNNs, named deep CovDenseSNN, such that SNNs can make use of the feature extraction ability of CNNs during the encoding stage, but still process features with unsupervised learning rule of spiking neurons. We evaluate them on MNIST and its variations to show that our model can extract and transmit more important information than existing models, especially for anti-noise ability in the noisy environment. The proposed architecture provides e\ufb03cient ways to perform feature representation and recognition in a consistent temporal learning framework, which is easily adapted to neuromorphic hardware implementations and bring more biological realism into modern image classi\ufb01cation models, with the hope that the proposed framework can inform us how sensory information is transmitted and represented in the brain."}}
