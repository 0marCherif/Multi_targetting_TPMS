{"id": "AVkJEb1ahOY", "cdate": 1681833044506, "mdate": null, "content": {"title": "Neural Score Estimation: Likelihood-Free Inference with Conditional Score Based Diffusion Models", "abstract": "In recent years, score based diffusion models have achieved remarkable empirical performance across a wide range of generative modelling tasks. In this paper, we study the use of conditional score-based diffusion models for Bayesian inference in simulator-based models. \nWe consider two objectives for training these models, one of which approximates the score of the diffused likelihood, while the other directly estimates the score of the diffused posterior. \nWe validate these methods, which we term Neural Posterior Score Estimation (NPSE) and Neural Likelihood Score Estimation (NLSE), on several numerical examples, demonstrating comparable or superior performance to existing state-of-the-art methods such as Neural Posterior Estimation (NPE) and Neural Likelihood Estimation (NLE)."}}
{"id": "HVVDVaegjaW", "cdate": 1663850273839, "mdate": null, "content": {"title": "MonoFlow: A Unified Generative Modeling Framework for GAN Variants", "abstract": "Generative adversarial networks (GANs) play a minmax two-player game via adversarial training. The conventional understanding of adversarial training is that the discriminator is trained to estimate a divergence and the generator learns to minimize this divergence. We argue that despite the fact that many variants of GANs are developed following this paradigm, the existing theoretical understanding of GANs and the practical algorithms are inconsistent. In order to gain deeper theoretical insights and algorithmic inspiration for these GAN variants, we leverage Wasserstein gradient flows which characterize the evolution of particles in the sample space. Based on this, we introduce a unified generative modeling framework \u2013 MonoFlow: the particle evolution is rescaled via an arbitrary monotonically increasing mapping. Under our framework, adversarial training can be viewed as a procedure first obtaining MonoFlow's vector field via the discriminator and then the generator learns to parameterize the flow defined by the corresponding vector field. We also reveal the fundamental difference between variational divergence minimization and adversarial training. These analysis help us to identify what types of generator loss functions can lead to the successful training of GANs and suggest that GANs may have more loss designs beyond those developed in the literature, e.g., non-saturated loss, as long as they realize MonoFlow. Consistent empirical studies are also included to validate the effectiveness of our framework."}}
{"id": "q4IG88RJiMv", "cdate": 1652737716078, "mdate": null, "content": {"title": "Estimating the Arc Length of the Optimal ROC Curve and Lower Bounding the Maximal AUC", "abstract": "In this paper, we show the arc length of the optimal ROC curve is an $f$-divergence. By leveraging this result, we express the arc length using a variational objective and estimate it accurately using positive and negative samples. We show this estimator has a non-parametric convergence rate $O_p(n^{-\\beta/4})$ ($\\beta \\in (0,1]$ depends on the smoothness). Using the same technique, we show the surface area sandwiched between the optimal ROC curve and the diagonal can be expressed via a similar variational objective. These new insights lead to a novel two-step classification procedure that maximizes an approximate lower bound of the maximal AUC.  Experiments on CIFAR-10 datasets show the proposed two-step procedure achieves good AUC performance in imbalanced binary classification tasks."}}
{"id": "XwCwmIbrjgU", "cdate": 1637576010454, "mdate": null, "content": {"title": "Sliced Wasserstein Variational Inference", "abstract": "Variational Inference approximates an unnormalized distribution via the minimization of \\textit{Kullback-Leibler} (KL) divergence. Although this divergence is efficient for computation and has been widely used in applications, it suffers from some unreasonable properties. For example, it is not a proper metric, i.e., it is non-symmetric and does not preserve the triangle inequality. On the other hand, optimal transport distances recently have shown some advantages over KL divergence. To make use of these advantages, we propose a new variational inference method by minimizing sliced Wasserstein distance. This sliced Wasserstein distance can be approximated simply by running very few MCMC steps without solving any optimization problem. Our approximation also does not require a tractable density function of variational distributions so that approximating families can be amortized by generators like neural networks. Experiments on synthetic and real data are illustrated to show the performance of the proposed method."}}
{"id": "svH3klEbuXa", "cdate": 1637576009617, "mdate": null, "content": {"title": "Variational Likelihood-Free Gradient Descent", "abstract": "In many scientific applications, we do not have explicit access to the likelihood function. However simulations of the process of interest, using different parameter settings, may give us access to the likelihood function implicitly. The methodology for approximating likelihoods and posterior distributions based on simulated observations can be described as simulation-based inference. In this paper, we propose a simulation-based inference algorithm in which we iteratively update particles to more closely resemble the posterior. Our approach utilises simulations to estimate a density ratio function at each iteration and then uses it to approximate the KL divergence between the particle density and the posterior density. By alternating between gradient descent and density ratio estimation, the approximated KL divergence is minimized. We benchmark the performance of our algorithm on a Gaussian mixture model and the M/G/1 queue process model and report promising results. "}}
{"id": "C7gt7kVmMQc", "cdate": 1633790966433, "mdate": null, "content": {"title": "Continual Density Ratio Estimation", "abstract": "In online applications with streaming data, awareness of how far the empirical training or test data has shifted away from its original data distribution can be crucial to the performance of the model. However, historical samples in the data stream may not be kept either due to space requirements or for regulatory reasons. To cope with such situations, we propose Continual Density Ratio Estimation (CDRE), for estimating density ratios between the initial and latest distributions (p/q_t) of a data stream without the need of storing past samples, where q_t shifted away from p after a time period t. In particular, CDRE is more accurate than standard DRE when the two distributions are less similar, despite not requiring samples from the original distribution. CDRE can be applied in scenarios of online or continual learning, such as importance weighted covariate shift, measuring dataset changes for better decision making.  "}}
{"id": "FUKjnUHcJEP", "cdate": 1589639578947, "mdate": null, "content": {"title": "Two-sample inference for high-dimensional markov networks", "abstract": "Markov networks are frequently used in sciences to represent conditional independence relationships underlying observed variables arising from a complex system. It is often of interest to understand how an underlying network differs between two conditions. In this paper, we develop methodology for performing valid statistical inference for difference between parameters of Markov network in a high-dimensional setting where the number of observed variables is allowed to be larger than the sample size. Our proposal is based on the regularized Kullback-Leibler Importance Estimation Procedure that allows us to directly learn the parameters of the differential network, without requiring for separate or joint estimation of the individual Markov network parameters. This allows for applications in cases where individual networks are not sparse, such as networks that contain hub nodes, but the differential network is sparse. We prove that our estimator is regular and its distribution can be well approximated by a normal under wide range of data generating processes and, in particular, is not sensitive to model selection mistakes. Furthermore, we develop a new testing procedure for equality of Markov networks, which is based on a max-type statistics. A valid bootstrap procedure is developed that approximates quantiles of the test statistics. The performance of the methodology is illustrated through extensive simulations and real data examples."}}
{"id": "HJemQJBKDr", "cdate": 1569439515177, "mdate": null, "content": {"title": "Continual Density Ratio Estimation (CDRE): A new method for evaluating generative models in continual learning", "abstract": "We propose a new method Continual Density Ratio Estimation (CDRE), which can estimate density ratios between a target distribution of real samples and a distribution of samples generated by a model while the model is changing over time and the data of the target distribution is not available after a certain time point. This method perfectly fits the setting of continual learning, in which one model is supposed to learn different tasks sequentially and the most crucial restriction is that model has none or very limited access to the data of all learned tasks. Through CDRE, we can evaluate generative models in continual learning using f-divergences. To the best of our knowledge, there is no existing method that can evaluate generative models under the setting of continual learning without storing real samples from the target distribution."}}
{"id": "S1xgR4HxIS", "cdate": 1567802568143, "mdate": null, "content": {"title": "Fisher Efficient Inference of Intractable Models", "abstract": "Maximum Likelihood Estimators (MLE) has many good properties. For example, the asymptotic variance of MLE solution attains equality of the asymptotic Cram{\\'e}r-Rao lower bound (efficiency bound), which is the minimum possible variance for an unbiased estimator.  However, obtaining such MLE solution requires calculating the likelihood function which may not be tractable due to the normalization term of the density model. In this paper, we derive a Discriminative Likelihood Estimator (DLE) from the Kullback-Leibler divergence minimization criterion implemented via density ratio estimation procedure and Stein operator. We study the problem of model inference using DLE. We prove its consistency and show the asymptotic variance of its solution can also attain the equality of the efficiency bound under mild regularity conditions.  We also propose a dual formulation of DLE which can be easily optimized. Numerical studies validate our asymptotic theorems and we give an example where DLE successfully estimates an intractable model constructed using a pre-trained deep neural network. "}}
