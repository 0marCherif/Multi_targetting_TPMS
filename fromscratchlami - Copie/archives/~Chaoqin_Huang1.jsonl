{"id": "rvnNdcTsrf", "cdate": 1640995200000, "mdate": 1667362748259, "content": {"title": "Self-Supervised Masking for Unsupervised Anomaly Detection and Localization", "abstract": "Recently, anomaly detection and localization in multimedia data have received significant attention among the machine learning community. In real-world applications such as medical diagnosis and industrial defect detection, anomalies only present in a fraction of the images. To extend the reconstruction-based anomaly detection architecture to the localized anomalies, we propose a self-supervised learning approach through random masking and then restoring, named Self-Supervised Masking (SSM) for unsupervised anomaly detection and localization. SSM not only enhances the training of the inpainting network but also leads to great improvement in the efficiency of mask prediction at inference. Through random masking, each image is augmented into a diverse set of training triplets, thus enabling the autoencoder to learn to reconstruct with masks of various sizes and shapes during training. To improve the efficiency and effectiveness of anomaly detection and localization at inference, we propose a novel progressive mask refinement approach that progressively uncovers the normal regions and finally locates the anomalous regions. The proposed SSM method outperforms several state-of-the-arts for both anomaly detection and anomaly localization, achieving 98.3% AUC on Retinal-OCT and 93.9% AUC on MVTec AD, respectively."}}
{"id": "pfuCS1lPs4", "cdate": 1640995200000, "mdate": 1676467428036, "content": {"title": "Registration Based Few-Shot Anomaly Detection", "abstract": "This paper considers few-shot anomaly detection (FSAD), a practical yet under-studied setting for anomaly detection (AD), where only a limited number of normal images are provided for each category at training. So far, existing FSAD studies follow the one-model-per-category learning paradigm used for standard AD, and the inter-category commonality has not been explored. Inspired by how humans detect anomalies, i.e., comparing an image in question to normal images, we here leverage registration, an image alignment task that is inherently generalizable across categories, as the proxy task, to train a category-agnostic anomaly detection model. During testing, the anomalies are identified by comparing the registered features of the test image and its corresponding support (normal) images. As far as we know, this is the first FSAD method that trains a single generalizable model and requires no re-training or parameter fine-tuning for new categories. Experimental results have shown that the proposed method outperforms the state-of-the-art FSAD methods by 3%\u20138% in AUC on the MVTec and MPDD benchmarks. Source code is available at: https://github.com/MediaBrain-SJTU/RegAD ."}}
{"id": "fEPNq6E0pSy", "cdate": 1640995200000, "mdate": 1667362748267, "content": {"title": "Attribute Restoration Framework for Anomaly Detection", "abstract": "With the recent advances in deep neural networks, anomaly detection in multimedia has received much attention in the computer vision community. While reconstruction-based methods have recently shown great promise for anomaly detection, the information equivalence among input and supervision for reconstruction tasks can not effectively force the network to learn semantic feature embeddings. We here propose to break this equivalence by erasing selected attributes from the original data and reformulate it as a restoration task, where the normal and the anomalous data are expected to be distinguishable based on restoration errors. Through forcing the network to restore the original image, the semantic feature embeddings related to the erased attributes are learned by the network. During testing phases, because anomalous data are restored with the attribute learned from the normal data, the restoration error is expected to be large. Extensive experiments have demonstrated that the proposed method significantly outperforms several state-of-the-arts on multiple benchmark datasets, especially on ImageNet, increasing the AUROC of the top-performing baseline by 10.1%. We also evaluate our method on a real-world anomaly detection dataset MVTec AD."}}
{"id": "XeE4MiKkHkg", "cdate": 1609459200000, "mdate": 1667362748256, "content": {"title": "ESAD: End-to-end Semi-supervised Anomaly Detection", "abstract": ""}}
{"id": "4OlPIms1V5W", "cdate": 1609459200000, "mdate": 1667362748260, "content": {"title": "Deep Unsupervised Image Anomaly Detection: An Information Theoretic Framework", "abstract": "Surrogate task based methods have recently shown great promise for unsupervised image anomaly detection. However, there is no guarantee that the surrogate tasks share the consistent optimization direction with anomaly detection. In this paper, we return to a direct objective function for anomaly detection with information theory, which maximizes the distance between normal and anomalous data in terms of the joint distribution of images and their representation. To make this objective function directly optimizable under the unsupervised setting, we manage to find its lower bound which weights the trade-off between mutual information and entropy, which leads to a novel information theoretic framework for unsupervised image anomaly detection. Extensive experiments on several benchmark data sets have shown that the proposed framework significantly outperforms several state-of-the-arts."}}
{"id": "2Hk8Cmi2Ui", "cdate": 1546300800000, "mdate": 1667362748261, "content": {"title": "DrivingStereo: A Large-Scale Dataset for Stereo Matching in Autonomous Driving Scenarios", "abstract": "Great progress has been made on estimating disparity maps from stereo images. However, with the limited stereo data available in the existing datasets and unstable ranging precision of current stereo methods, industry-level stereo matching in autonomous driving remains challenging. In this paper, we construct a novel large-scale stereo dataset named DrivingStereo. It contains over 180k images covering a diverse set of driving scenarios, which is hundreds of times larger than the KITTI Stereo dataset. High-quality labels of disparity are produced by a model-guided filtering strategy from multi-frame LiDAR points. For better evaluations, we present two new metrics for stereo matching in the driving scenes, i.e. a distance-aware metric and a semantic-aware metric. Extensive experiments show that compared with the models trained on FlyingThings3D or Cityscapes, the models trained on our DrivingStereo achieve higher generalization accuracy in real-world driving scenes, while the proposed metrics better evaluate the stereo methods on all-range distances and across different classes. Our dataset and code are available at https://drivingstereo-dataset.github.io."}}
{"id": "S1VkapbOWH", "cdate": 1514764800000, "mdate": null, "content": {"title": "Recurrent Residual Module for Fast Inference in Videos", "abstract": "Deep convolutional neural networks (CNNs) have made impressive progress in many video recognition tasks such as video pose estimation and video object detection. However, running CNN inference on video requires numerous computation and is usually slow. In this work, we propose a framework called Recurrent Residual Module (RRM) to accelerate the CNN inference for video recognition tasks. This framework has a novel design of using the similarity of the intermediate feature maps of two consecutive frames to largely reduce the redundant computation. One unique property of the proposed method compared to previous work is that feature maps of each frame are precisely computed. The experiments show that, while maintaining the similar recognition performance, our RRM yields averagely 2\u00d7 acceleration on the commonly used CNNs such as AlexNet, ResNet, deep compression model (thus 8\u221212\u00d7 faster than the original dense models on the ef\ufb01cient inference engine), and impressively 9\u00d7 acceleration on some binary networks such as XNOR-Nets (thus 500\u00d7 faster than the original model). We further verify the effectiveness of the RRM on speeding CNNs for video pose estimation and video object detection."}}
