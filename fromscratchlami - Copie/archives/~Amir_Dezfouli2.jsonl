{"id": "_qd8bm6Q5ef", "cdate": 1684224226465, "mdate": 1684224226465, "content": {"title": "Optimizing Sequential Experimental Design with Deep Reinforcement Learning", "abstract": "Bayesian approaches developed to solve the optimal design of sequential experiments are mathematically elegant but computationally challenging. Recently, techniques using amortization have been proposed to make these Bayesian approaches practical, by training a parameterized policy that proposes designs efficiently at deployment time. However, these methods may not sufficiently explore the design space, require access to a differentiable probabilistic model and can only optimize over continuous design spaces. Here, we address these limitations by showing that the problem of optimizing policies can be reduced to solving a Markov decision process (MDP). We solve the equivalent MDP with modern deep reinforcement learning techniques. Our experiments show that our approach is also computationally efficient at deployment time and exhibits state-of-the-art performance on both continuous and discrete design spaces, even when the probabilistic model is a black box.\n"}}
{"id": "XtRJsuVsLU", "cdate": 1663850074631, "mdate": null, "content": {"title": "Benchmarking Approximate k-Nearest Neighbour Search for Big High Dimensional Dynamic Data", "abstract": "Approximate k-Nearest Neighbour (ANN) methods are commonly used for mining information from big high-dimensional datasets. For each application the high-level dataset properties and run-time requirements determine which method will provide the most suitable tradeoffs. However, due to a significant lack of comprehensive benchmarking, judicious method selection is not currently possible for ANN applications that involve frequent online changes to datasets. Here we address this issue by building upon existing benchmarks for static search problems to provide a new benchmarking framework for big high dimensional dynamic data. We apply our framework to dynamic scenarios modelled after common real world applications. In all cases we are able to identify a suitable recall-runtime tradeoff to improve upon a worst-case exhaustive search. Our framework provides a flexible solution to accelerate future ANN research and enable researchers in other online data-rich domains to find suitable methods for handling their ANN searches."}}
{"id": "edmYVRkYZv", "cdate": 1621629980366, "mdate": null, "content": {"title": "TacticZero: Learning to Prove Theorems from Scratch with Deep Reinforcement Learning", "abstract": "We propose a novel approach to interactive theorem-proving (ITP) using deep reinforcement learning. The proposed framework is able to learn proof search strategies as well as tactic and arguments prediction in an end-to-end manner. We formulate the process of ITP as a Markov decision process (MDP) in which each state represents a set of potential derivation paths. This structure allows us to introduce a novel backtracking mechanism which enables the agent to efficiently discard (predicted) dead-end derivations and restart the derivation from promising alternatives. We implement the framework in the HOL theorem prover. Experimental results show that the framework using learned search strategies outperforms existing automated theorem provers (i.e., hammers) available in HOL when evaluated on unseen problems. We further elaborate the role of key components of the framework using ablation studies.\n\n"}}
{"id": "HJeQ8NSx8H", "cdate": 1567802442718, "mdate": null, "content": {"title": "Disentangled behavioural representations", "abstract": "Individual characteristics in human decision-making are often   quantified by fitting a parametric cognitive model to subjects'   behavior and then studying differences between them in the associated   parameter space.  However, these models often fit behavior more poorly   than recurrent neural networks (RNNs), which are more flexible and   make fewer assumptions about the underlying decision-making processes.   Unfortunately, the parameter and latent activity spaces of RNNs are   generally high-dimensional and uninterpretable, making it hard to use   them to study individual differences.  Here, we   show how to benefit from the flexibility of RNNs while representing   individual differences in a low-dimensional and interpretable space.   To achieve this, we propose a novel end-to-end learning framework in   which an encoder is trained to map the behavior of subjects into a   low-dimensional latent space. These low-dimensional representations   are used to generate the parameters of individual RNNs corresponding   to the decision-making process of each subject.  We introduce terms   into the loss function that ensure that the latent dimensions are   informative and disentangled, i.e., encouraged to have distinct effects on behavior. This allows them to align with separate facets of   individual differences. We illustrate the performance    of our framework on synthetic data as well as a dataset including the behavior    of patients with psychiatric disorders."}}
{"id": "Sy-LFsWOWB", "cdate": 1514764800000, "mdate": null, "content": {"title": "Variational Network Inference: Strong and Stable with Concrete Support", "abstract": "Traditional methods for the discovery of latent network structures are limited in two ways: they either assume that all the signal comes from the network (i.e. there is no source of signal outside ..."}}
{"id": "Bk-BgD-d-S", "cdate": 1514764800000, "mdate": null, "content": {"title": "Integrated accounts of behavioral and neuroimaging data using flexible recurrent neural network models", "abstract": "Neuroscience studies of human decision-making abilities commonly involve subjects completing a decision-making task while BOLD signals are recorded using fMRI. Hypotheses are tested about which brain regions mediate the effect of past experience, such as rewards, on future actions. One standard approach to this is model-based fMRI data analysis, in which a model is fitted to the behavioral data, i.e., a subject's choices, and then the neural data are parsed to find brain regions whose BOLD signals are related to the model's internal signals. However, the internal mechanics of such purely behavioral models are not constrained by the neural data, and therefore might miss or mischaracterize aspects of the brain. To address this limitation, we introduce a new method using recurrent neural network models that are flexible enough to be jointly fitted to the behavioral and neural data. We trained a model so that its internal states were suitably related to neural activity during the task, while at the same time its output predicted the next action a subject would execute. We then used the fitted model to create a novel visualization of the relationship between the activity in brain regions at different times following a reward and the choices the subject subsequently made. Finally, we validated our method using a previously published dataset. We found that the model was able to recover the underlying neural substrates that were discovered by explicit model engineering in the previous work, and also derived new results regarding the temporal pattern of brain activity."}}
{"id": "s_zaCZVmUax", "cdate": 1483228800000, "mdate": null, "content": {"title": "Gray-box Inference for Structured Gaussian Process Models.", "abstract": "We develop an automated variational inference method for Bayesian structured prediction problems with Gaussian process (GP) priors and linear-chain likelihoods. Our approach does not need to know the details of the structured likelihood model and can scale up to a large number of observations. Furthermore, we show that the required expected likelihood term and its gradients in the variational objective (ELBO) can be estimated efficiently by using expectations over very low-dimensional Gaussian distributions. Optimization of the ELBO is fully parallelizable over sequences and amenable to stochastic optimization, which we use along with control variate techniques to make our framework useful in practice. Results on a set of natural language processing tasks show that our method can be as good as (and sometimes better than, in particular with respect to expected log-likelihood) hard-coded approaches including SVM-struct and CRF, and overcomes the scalability limitations of previous inference algorithms based on sampling. Overall, this is a fundamental step to developing automated inference methods for Bayesian structured prediction."}}
{"id": "iMG_hNtMBl", "cdate": 1420070400000, "mdate": null, "content": {"title": "Hierarchical models of goal-directed and automatic actions.", "abstract": "Decision-making processes behind instrumental actions can be divided into two categories: goal-directed actions, and automatic actions. The structure of automatic actions, their interaction with goal-directed actions, and their behavioral and computational properties are the topics of the current thesis. We conceptualize the structure of automatic actions as sequences of actions that form a single response unit and are integrated within goal-directed processes in a hierarchical manner. We represent this hypothesis using the computational framework of reinforcement learning and develop a new normative computational model for the acquisition of action sequences, and their hierarchical interaction with goal-directed processes. We develop a neurally plausible hypothesis for the role of neuromodulator dopamine as a teaching signal for the acquisition of action sequences. We further explore the predictions of the proposed model in a two-stage decision-making task in humans and we show that the proposed model has higher explanatory power than its alternatives. Finally, we translate the two-stage decision-making task to an experimental protocol in rats and show that, similar to humans, rats also use action sequences and engage in hierarchical decision-making. The results provide a new theoretical and experimental paradigm for conceptualizing and measuring the operation and interaction of goal-directed and automatic actions."}}
{"id": "SJWsUwWubB", "cdate": 1420070400000, "mdate": null, "content": {"title": "Scalable Inference for Gaussian Process Models with Black-Box Likelihoods", "abstract": "We propose a sparse method for scalable automated variational inference (AVI) in a large class of models with Gaussian process (GP) priors, multiple latent functions, multiple outputs and non-linear likelihoods. Our approach maintains the statistical efficiency property of the original AVI method, requiring only expectations over univariate Gaussian distributions to approximate the posterior with a mixture of Gaussians. Experiments on small datasets for various problems including regression, classification, Log Gaussian Cox processes, and warped GPs show that our method can perform as well as the full method under high levels of sparsity. On larger experiments using the MNIST and the SARCOS datasets we show that our method can provide superior performance to previously published scalable approaches that have been handcrafted to specific likelihood models."}}
{"id": "AY1vCRnvEyL", "cdate": 1356998400000, "mdate": null, "content": {"title": "Actions, Action Sequences and Habits: Evidence That Goal-Directed and Habitual Action Control Are Hierarchically Organized.", "abstract": "Author Summary In order to make choices that lead to desirable outcomes, individuals tend to deliberate over the consequences of various alternatives. This goal-directed deliberation is, however, slow and cognitively demanding. As a consequence, under appropriate conditions decision-making can become habitual and automatic. The nature of these habitual actions, how they are learned, expressed, and interact with the goal-directed process is not clearly understood. Here we report that (1) habits interact with the goal-directed process in a hierarchical manner (i.e., the goal-directed system selects a goal, and then determines which habit should be executed to reach that goal), and (2) habits are learned sequences of actions that, once triggered by the goal-directed process, can be expressed quickly and in an efficient manner. The findings provide critical new experimental and computational information on the nature of habits and how they interact with the goal-directed decision-making."}}
