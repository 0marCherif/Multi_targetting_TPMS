{"id": "YhrLM3XW_OI", "cdate": 1683216108491, "mdate": 1683216108491, "content": {"title": "PECO: Examining Single Sentence Label Leakage in Natural Language Inference Datasets through Progressive Evaluation of Cluster Outliers", "abstract": "     Building natural language inference (NLI) benchmarks that are both challenging for modern techniques, and free from shortcut biases is difficult. Chief among these biases is \"single sentence label leakage,\" where annotator-introduced spurious correlations yield datasets where the logical relation between (premise, hypothesis) pairs can be accurately predicted from only a single sentence, something that should in principle be impossible. We demonstrate that despite efforts to reduce this leakage, it persists in modern datasets that have been introduced since its 2018 discovery. To enable future amelioration efforts, introduce a novel model-driven technique, the progressive evaluation of cluster outliers (PECO) which enables both the objective measurement of leakage, and the automated detection of subpopulations in the data which maximally exhibit it. "}}
{"id": "xGNBNzb0ZfD", "cdate": 1672531200000, "mdate": 1694472486778, "content": {"title": "Causal Balancing for Domain Generalization", "abstract": ""}}
{"id": "tL_so7vNUW5", "cdate": 1672531200000, "mdate": 1694472486776, "content": {"title": "CausalDialogue: Modeling Utterance-level Causality in Conversations", "abstract": ""}}
{"id": "hGmRfz0K-U", "cdate": 1672531200000, "mdate": 1694472486851, "content": {"title": "Let's Think Frame by Frame: Evaluating Video Chain of Thought with Video Infilling and Prediction", "abstract": "Despite constituting 65% of all internet traffic in 2023, video content is underrepresented in generative AI research. Meanwhile, recent large language models (LLMs) have become increasingly integrated with capabilities in the visual modality. Integrating video with LLMs is a natural next step, so how can this gap be bridged? To advance video reasoning, we propose a new research direction of VideoCOT on video keyframes, which leverages the multimodal generative abilities of vision-language models to enhance video reasoning while reducing the computational complexity of processing hundreds or thousands of frames. We introduce VIP, an inference-time dataset that can be used to evaluate VideoCOT, containing 1) a variety of real-life videos with keyframes and corresponding unstructured and structured scene descriptions, and 2) two new video reasoning tasks: video infilling and scene prediction. We benchmark various vision-language models on VIP, demonstrating the potential to use vision-language models and LLMs to enhance video chain of thought reasoning."}}
{"id": "aKf3DO5tM9M", "cdate": 1672531200000, "mdate": 1694472486781, "content": {"title": "Visual Chain of Thought: Bridging Logical Gaps with Multimodal Infillings", "abstract": "Recent advances in large language models elicit reasoning in a chain of thought that allows models to decompose problems in a human-like fashion. Though this paradigm improves multi-step reasoning ability in language models, it is limited by being unimodal and applied mainly to question-answering tasks. We claim that incorporating visual augmentation into reasoning is essential, especially for complex, imaginative tasks. Consequently, we introduce VCoT, a novel method that leverages chain of thought prompting with vision-language grounding to recursively bridge the logical gaps within sequential data. Our method uses visual guidance to generate synthetic multimodal infillings that add consistent and novel information to reduce the logical gaps for downstream tasks that can benefit from temporal reasoning, as well as provide interpretability into models' multi-step reasoning. We apply VCoT to the Visual Storytelling and WikiHow summarization datasets and demonstrate through human evaluation that VCoT offers novel and consistent synthetic data augmentation beating chain of thought baselines, which can be used to enhance downstream performance."}}
{"id": "Wf0tcXSpGn", "cdate": 1672531200000, "mdate": 1694472486781, "content": {"title": "Disparities in Text-to-Image Model Concept Possession Across Languages", "abstract": "We propose the notion of conceptual possession in generative text-to-image (T2I) systems, wherein a model is considered to possess a concept if it can generate a distinctive, correct, and self-consistent population of images for a simple prompt containing that concept. We use this idea to develop a model benchmark of multilingual parity in conceptual possession across a set of almost 200 tangible nouns across 7 languages: English, Spanish, German, Chinese, Japanese, Hebrew, and Indonesian. This technique allows us to estimate how well-suited a model is to a target language as well as identify model-specific weaknesses, spurious correlations, and biases without a-priori assumptions. We demonstrate how it can be used to benchmark T2I models in terms of multilinguality, and that despite its simplicity our method captures the necessary conditions for the impressive \u201ccreative\u201d generative abilities users expect from T2I models. Our benchmark will guide future work in reducing disparities across languages, improving accessibility of these technologies."}}
{"id": "WOT6-iPGDMc", "cdate": 1672531200000, "mdate": 1694472486780, "content": {"title": "WikiWhy: Answering and Explaining Cause-and-Effect Questions", "abstract": ""}}
{"id": "PB7m1nlxUsU", "cdate": 1672531200000, "mdate": 1693521058705, "content": {"title": "Automatically Correcting Large Language Models: Surveying the landscape of diverse self-correction strategies", "abstract": "Large language models (LLMs) have demonstrated remarkable performance across a wide array of NLP tasks. However, their efficacy is undermined by undesired and inconsistent behaviors, including hallucination, unfaithful reasoning, and toxic content. A promising approach to rectify these flaws is self-correction, where the LLM itself is prompted or guided to fix problems in its own output. Techniques leveraging automated feedback -- either produced by the LLM itself or some external system -- are of particular interest as they are a promising way to make LLM-based solutions more practical and deployable with minimal human feedback. This paper presents a comprehensive review of this emerging class of techniques. We analyze and taxonomize a wide array of recent work utilizing these strategies, including training-time, generation-time, and post-hoc correction. We also summarize the major applications of this strategy and conclude by discussing future directions and challenges."}}
{"id": "Eecsnc7Iiw", "cdate": 1672531200000, "mdate": 1694472486782, "content": {"title": "Multilingual Conceptual Coverage in Text-to-Image Models", "abstract": "We propose \"Conceptual Coverage Across Languages\" (CoCo-CroLa), a technique for benchmarking the degree to which any generative text-to-image system provides multilingual parity to its training language in terms of tangible nouns. For each model we can assess \"conceptual coverage\" of a given target language relative to a source language by comparing the population of images generated for a series of tangible nouns in the source language to the population of images generated for each noun under translation in the target language. This technique allows us to estimate how well-suited a model is to a target language as well as identify model-specific weaknesses, spurious correlations, and biases without a-priori assumptions. We demonstrate how it can be used to benchmark T2I models in terms of multilinguality, and how despite its simplicity it is a good proxy for impressive generalization."}}
{"id": "BoqdqX0ln0", "cdate": 1672531200000, "mdate": 1694472486783, "content": {"title": "Data Augmentation for Diverse Voice Conversion in Noisy Environments", "abstract": "Voice conversion (VC) models have demonstrated impressive few-shot conversion quality on the clean, native speech populations they're trained on. However, when source or target speech accents, background noise conditions, or microphone characteristics differ from training, quality voice conversion is not guaranteed. These problems are often left unexamined in VC research, giving rise to frustration in users trying to use pretrained VC models on their own data. We are interested in accent-preserving voice conversion for name pronunciation from self-recorded examples, a domain in which all three of the aforementioned conditions are present, and posit that demonstrating higher performance in this domain correlates with creating VC models that are more usable by otherwise frustrated users. We demonstrate that existing SOTA encoder-decoder VC models can be made robust to these variations and endowed with natural denoising capabilities using more diverse data and simple data augmentation techniques in pretraining."}}
