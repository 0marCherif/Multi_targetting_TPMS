{"id": "E__Cin7C01m", "cdate": 1640995200000, "mdate": 1682905696967, "content": {"title": "Triple-Sigmoid Activation Function for Deep Open-Set Recognition", "abstract": "Traditional models for various machine learning problems such as image classification perform well only under the assumption of a closed set. This implies that inputs must belong to the classes for which the models were trained. Data collected in the real world may not belong to any finite set of classes, and training a model with an infinite number of classes would obviously be impossible. Rather than incorrectly classifying outlier inputs that belong to unknown classes as members of one of the classes on which the model was trained, learning models must recognize and reject such data samples, or request human assistance in labeling them. For example, when a self-driving vehicle detects unfamiliar scenes or objects, it must notify the driver and hand over control. Various models have been proposed to address the open-set problem. However, the existing models are generally complex or use complicated techniques such as generative adversarial networks and auto-encoders, and their efficiency is not proportional to their complexity. In this study, we propose Triple-Sigmoid as a simple activation function comprised of three Sigmoid functions. Using Triple-Sigmoid in the last activation layer of any deep neural network model enables the model to recognize outliers. Although Triple-Sigmoid can be applied to a variety of machine learning problems, including semi-supervised learning, active learning, and incremental learning, we only investigated the open-set recognition problem in this work. The results of numerous experiments are presented to validate that substituting Triple-Sigmoid for conventional activations such as Softmax and Sigmoid not only retained performance in closed-set settings, but also significantly improved performance in open-set configurations. Furthermore, these results demonstrate that Triple-Sigmoid significantly outperformed existing state-of-the-art methods. Source code for the proposed model is available at <uri xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">https://github.com/dinhtuantran/triple-sigmoid</uri> ."}}
{"id": "5hKlZMFEi-", "cdate": 1640995200000, "mdate": 1682905696967, "content": {"title": "ABLE: Aesthetic Box Lunch Editing", "abstract": "This paper proposes an exploratory research that contains a pre-trained ordering recovery model to obtain correct placement sequences from box lunch images, and a generative adversarial network to composite novel box lunch presentations from single item food and generated layouts. Furthermore, we present Bento800, the first cleanly annotated, high-quality, and standardized dataset for aesthetic box lunch presentation generation and other downstream tasks. Bento800 dataset is available at \\urlhttps://github.com/Yutong-Zhou-cv/Bento800_Dataset."}}
{"id": "r1_IAIgjUXx", "cdate": 1609459200000, "mdate": 1682905696966, "content": {"title": "Semiotically adaptive cognition: toward the realization of remotely-operated service robots for the new normal symbiotic society", "abstract": "The installation of remotely-operated service robots in the environments of our daily life (including offices, homes, and hospitals) can improve work-from-home policies and enhance the quality of t..."}}
{"id": "m6FBnQssFGR", "cdate": 1609459200000, "mdate": 1682905696971, "content": {"title": "Scene Descriptor Expressing Ambiguity in Information Recovery Based on Incomplete Partial Observation", "abstract": "In recent studies, the widespread of deep learning has made many kinds of large-scale image datasets available and it has enabled to improve the performance of image-based 3-D scene reconstruction. Several studies estimate whole 3-D scenes including occluded or unseen parts consistent with the obtained partial observations by integrating prior knowledge from training datasets with them, under no camera parameters nor image landmark correspondence are known. Although they generate \u201cdiscrete\u201d scene instances, they cannot represent and treat their \u201cambiguity\u201d at all.This paper proposes a novel deep-learning-based framework that can directly represent and treat the ambiguity of scene reconstructions. We introduce a neural network which encodes a target scene as a descriptor. The network takes partial observations as input and outputs a parametric set of the scene descriptors containing all scenes consistent with given observations. The input observations may be \u201cincomplete\u201d in the sense that they do not have enough pieces of information to uniquely determine the whole scene due to neither geometry in-formation nor landmark correspondences available (ill-defined cases). The network is trained based on the dataset of the complete 3-D scenes and possible partial observations so that it can predict the unseen parts from incomplete observations. The paper introduces the method to induce such a descriptor space into the encoder/decoder architecture by employing novel definitions of loss functions measuring \u201cvalidity\u201d, \u201cconsistency\u201d and \u201creproducibility\u201d. When the series of partial and incom-plete observations for the same 3-D scene is obtained, the reconstruction ambiguity is explicitly treated by parametrically integrating the descriptor set for each observation into one descriptor set."}}
{"id": "cvXN0aUYky_", "cdate": 1609459200000, "mdate": 1682905696969, "content": {"title": "ROS2-Based Distributed System Implementation for Logging Indoor Human Activities", "abstract": "This research implements a system that detects and records various human activities in indoor scenes. For example, it detects who brings in or takes out an object and the handled object\u2019s image with the incident timestamp. It\u2019s constructed over ROS2, a widely used distributed communication framework for robotic implementation based on micro-services architecture, so that it can separate each subprocess of detection and improve the maintainability of each module. This paper reports the constructed system with visual human and pose detection, object detection, and recognition of object handling activities. Since the system was able to separate hardware not only service process, it was able to employ computationally heavy machine learning models simultaneously on multiple PCs with GPU."}}
{"id": "XK2T6ABOgX", "cdate": 1609459200000, "mdate": 1682905696971, "content": {"title": "Non-tactile Thumb Tip Measurement System for Encouraging Rehabilitation After Surgery", "abstract": "The thumb is the only finger that has a high degree of freedom of articulation and can face the other four fingers, and functional training is significant after injury surgery. We propose a system to measure and visualize the range of motion of the thumb during rehabilitation in a non-contact manner using a depth sensor and a deep neural model."}}
{"id": "Qmv_tsRORo", "cdate": 1609459200000, "mdate": 1682905696968, "content": {"title": "Generative Adversarial Network for Text-to-Face Synthesis and Manipulation with Pretrained BERT Model", "abstract": "This work proposes a cyclic generative adversarial network with spatial-wise and channel-wise attention modules for text-to-face synthesis and manipulation. Then, we explore the pre-trained transformer-based BERT model to obtain text embedding. Furthermore, dual-layer perceptual loss and SSIM loss are introduced to reinforce the delicate features and preserve facial identity during the manipulation task. Additionally, we adopt a novel Flickr-Faces-HQ with Text descriptions (FFHQ-Text) dataset with numerous facial attribute annotations to advance the development of the text-to-face task. In particular, by introducing the StyleGAN encoder for learning latent representations to our proposed post-processing method, we demonstrate that even training on a smaller text-to-face dataset can synthesize more realistic images. Experimental results reveal the effectiveness of our approach, which generates photo-realistic facial images, edits the specific facial attribute with the correlated keywords manipulation, outperforms previous state-of-the-art methods both in quality and quantity, and suggests promising future directions."}}
{"id": "9E4acDGcw4P", "cdate": 1577836800000, "mdate": 1623580541309, "content": {"title": "Rain Streaks and Snowflakes Removal for Video Sequences via Motion Compensation and Matrix Completion", "abstract": "Image and video deraining tasks aim to reconstruct original scenes, from which human vision and computer vision systems can better identify objects and more details present in images and video sequences. This paper proposes a three-step method to detect and remove rain streaks, even snowflakes from great majority video sequences, using motion compensation and low-rank matrix completion method. Firstly, we adopt the optical flow estimation between consecutive frames to detect the motion of rain streaks. We then employ the online dictionary learning for sparse representation technique, and SVM classifier to eliminate parts that are not rain streaks. Finally, we reconstruct the video sequence by using low-rank matrix completion techniques. In particular, by introducing the image dehazing network(GCANet) to our proposed method, the heavy rain caused dense rain accumulation and blurry phenomenon can be worked out well. The experimental results demonstrate the proposed algorithm and perform qualitatively and quantitatively better in several image quality metrics, boosting the best published PSNR metric by 4.47%, 6.05% on two static video sequences and 12.13% on a more challenging dynamic video sequence. In addition, to demonstrate the generality of the proposed method, we further apply it to two challenge tasks, which also achieves state-of-the-art performance."}}
{"id": "v8veVuu0LuX", "cdate": 1546300800000, "mdate": 1623580541168, "content": {"title": "Positive and Negative Opinions About Living with Robots in Japanese University Students", "abstract": "This research used a questionnaire survey to examine the positive and negative opinions of Japanese university students about living with robots. The results show that the effect of educational background on the hope of living with a robot is statistically significant, that gender affects negative attitudes toward the social influence of robots, and that negative correlation between the hope of living with a robot and negative attitudes toward emotional interaction with robots is statistically significant. An exploratory qualitative classification reveals that most Japanese undergraduates hold the negative opinion that they have no need to live with robots because they are not alone."}}
{"id": "MvLG4zMyuqg", "cdate": 1546300800000, "mdate": 1623580541166, "content": {"title": "Using Motion Compensation and Matrix Completion Algorithm to Remove Rain Streaks and Snow for Video Sequences", "abstract": "The current outdoor surveillance equipment and cameras are vulnerable to be influenced by rain, snow, and other inclement weather, reducing the performance of the surveillance systems. In this paper, we propose a method to detect and remove rain streaks even snow artifacts from video sequences, using motion compensation and low-rank matrix completion method. First, we adopt the optical flow estimation method between consecutive frames to get a warped frame and obtain an initial binary rain map. We further use morphological component analysis method to dilate the tiny rain streaks. Then we employ the online dictionary learning for sparse representation technique and SVM classifier to refine the rain map by getting rid of parts which are not rain streaks. Finally, we reconstruct the video sequence by using low-rank matrix completion techniques. The experimental results demonstrate the proposed algorithm and perform qualitatively as well as quantitatively better in terms of PSNR/SSIM."}}
