{"id": "BZxNYSWz7CF", "cdate": 1683880688882, "mdate": 1683880688882, "content": {"title": "Towards Deep and Representation Learning for Talent Search at LinkedIn", "abstract": "Talent search and recommendation systems at LinkedIn strive to match the potential candidates to the hiring needs of a recruiter\nor a hiring manager expressed in terms of a search query or a job posting. Recent work in this domain has mainly focused on linear\nmodels, which do not take complex relationships between features into account, as well as ensemble tree models, which introduce non-linearity but are still insufficient for exploring all the potential feature interactions, and strictly separate feature generation from modeling. In this paper, we present the results of our application of deep and representation learning models on LinkedIn Recruiter. Our key contributions include: (i) Learning semantic representations of sparse entities within the talent search domain, such as recruiter ids, candidate ids, and skill entity ids, for which we utilize neural network models that take advantage of LinkedIn Economic Graph, and (ii) Deep models for learning recruiter engagement and candidate response in talent search applications. We also explore learning to rank approaches applied to deep models, and show the benefits for the talent search use case. Finally, we present offline and online evaluation results for LinkedIn talent search and recommendation systems, and discuss potential challenges along the path to a fully deep model architecture. The challenges and approaches discussed generalize to any multi-faceted search engine."}}
{"id": "Q9U0Rls3Ci", "cdate": 1652745423794, "mdate": 1652745423794, "content": {"title": "Social media data mining and analytics", "abstract": "Harness the power of social media to predict customer behavior and improve sales Social media is the biggest source of Big Data. Because of this, 90% of Fortune 500 companies are investing in Big Data initiatives that will help them predict consumer behavior to produce better sales results. Social Media Data Mining and Analytics shows analysts how to use sophisticated techniques to mine social media data, obtaining the information they need to generate amazing results for their businesses. Social Media Data Mining and Analytics isn't just another book on the business case for social media. Rather, this book provides hands-on examples for applying state-of-the-art tools and technologies to mine social media-examples include Twitter, Wikipedia, Stack Exchange, LiveJournal, movie reviews, and other rich data sources. In it, you will learn: The four key characteristics of online services-users, social networks, actions, and content The full data discovery lifecycle-data extraction, storage, analysis, and visualization How to work with code and extract data to create solutions How to use Big Data to make accurate customer predictions How to personalize the social media experience using machine learning Using the techniques the authors detail will provide organizations the competitive advantage they need to harness the rich data available from social media platforms."}}
{"id": "j0FtncEDcsQ", "cdate": 1652745383303, "mdate": 1652745383303, "content": {"title": "Deploying deep ranking models for search verticals", "abstract": "In this paper, we present an architecture executing a complex machine learning model such as a neural network capturing semantic similarity between a query and a document; and deploy to a real-world production system serving 500M+users. We present the challenges that arise in a real-world system and how we solve them. We demonstrate that our architecture provides competitive modeling capability without any significant performance impact to the system in terms of latency. Our modular solution and insights can be used by other real-world search systems to realize and productionize recent gains in neural networks."}}
{"id": "AYrO8ouMH2j", "cdate": 1652745346833, "mdate": 1652745346833, "content": {"title": "Learning to be relevant: evolution of a course recommendation system", "abstract": "We present the evolution of a large-scale content recommendation platform for LinkedIn Learning, serving 645M+ LinkedIn users across several different channels (eg, desktop, mobile). We address challenges and complexities from both algorithms and infrastructure perspectives. We describe the progression from unsupervised models that exploit member similarity with course content, to supervised learning models leveraging member interactions with courses, and finally to hyper-personalized mixed-effects models with several million coefficients. For all the experiments, we include metric lifts achieved via online A/B tests and illustrate the trade-offs between computation and storage requirements."}}
{"id": "YznNCZh04q", "cdate": 1652745310523, "mdate": 1652745310523, "content": {"title": "Stylistic analysis of paintings usingwavelets and machine learning", "abstract": "Wavelet transforms and machine learning tools can be used to assist art experts in the stylistic analysis of paintings. A dual-tree complex wavelet transform, Hidden Markov Tree modeling and Random Forest classifiers are used here for a stylistic analysis of Vincent van Gogh's paintings with results on two stylometry challenges that concern \u201cdating, resp. extracting distinguishing features\u201d."}}
{"id": "-XXr9ZTzLRj", "cdate": 1652745282909, "mdate": 1652745282909, "content": {"title": "Detection of forgery in paintings using supervised learning", "abstract": "This paper examines whether machine learning and image analysis tools can be used to assist art experts in the authentication of unknown or disputed paintings. Recent work on this topic has presented some promising initial results. Our reexamination of some of these recently successful experiments shows that variations in image clarity in the experimental datasets were correlated with authenticity, and may have acted as a confounding factor, artificially improving the results. To determine the extent of this factor's influence on previous results, we provide a new \u00bfground truth\u00bf data set in which originals and copies are known and image acquisition conditions are uniform. Multiple previously-successful methods are found ineffective on this new confounding-factor-free dataset, but we demonstrate that supervised machine learning on features derived from hidden-Markov-tree-modeling of the paintings' wavelet \u2026"}}
{"id": "OUDA4yzjoV", "cdate": 1652745195244, "mdate": 1652745195244, "content": {"title": "Towards deep and representation learning for talent search at linkedin", "abstract": "Talent search and recommendation systems at LinkedIn strive to match the potential candidates to the hiring needs of a recruiter or a hiring manager expressed in terms of a search query or a job posting. Recent work in this domain has mainly focused on linear models, which do not take complex relationships between features into account, as well as ensemble tree models, which introduce non-linearity but are still insufficient for exploring all the potential feature interactions, and strictly separate feature generation from modeling. In this paper, we present the results of our application of deep and representation learning models on LinkedIn Recruiter. Our key contributions include:(i) Learning semantic representations of sparse entities within the talent search domain, such as recruiter ids, candidate ids, and skill entity ids, for which we utilize neural network models that take advantage of LinkedIn Economic Graph \u2026"}}
{"id": "Ed2a66OSdjD", "cdate": 1652745160620, "mdate": 1652745160620, "content": {"title": "A Bayesian nonparametric approach to image super-resolution", "abstract": "Super-resolution methods form high-resolution images from low-resolution images. In this paper, we develop a new Bayesian nonparametric model for super-resolution. Our method uses a beta-Bernoulli process to learn a set of recurring visual patterns, called dictionary elements, from the data. Because it is nonparametric, the number of elements found is also determined from the data. We test the results on both benchmark and natural images, comparing with several other models from the research literature. We perform large-scale human evaluation experiments to assess the visual quality of the results. In a first implementation, we use Gibbs sampling to approximate the posterior. However, this algorithm is not feasible for large-scale data. To circumvent this, we then develop an online variational Bayes (VB) algorithm. This algorithm finds high quality dictionaries in a fraction of the time needed by the Gibbs sampler."}}
{"id": "ilfUpWCmzx4", "cdate": 1652745120763, "mdate": 1652745120763, "content": {"title": "An Attentive Survey of Attention Models", "abstract": "Attention Model has now become an important concept in neural networks that has been researched within diverse application domains. This survey provides a structured and comprehensive overview of the developments in modeling attention. In particular, we propose a taxonomy that groups existing techniques into coherent categories. We review salient neural architectures in which attention has been incorporated and discuss applications in which modeling attention has shown a significant impact. We also describe how attention has been used to improve the interpretability of neural networks. Finally, we discuss some future research directions in attention. We hope this survey will provide a succinct introduction to attention models and guide practitioners while developing approaches for their applications."}}
{"id": "lkwXlIZUqDm", "cdate": 1652745074044, "mdate": 1652745074044, "content": {"title": "Lambda Learner: Fast Incremental Learning on Data Streams", "abstract": "     One of the most well-established applications of machine learning is in deciding what content to show website visitors. When observation data comes from high-velocity, user-generated data streams, machine learning methods perform a balancing act between model complexity, training time, and computational costs. Furthermore, when model freshness is critical, the training of models becomes time-constrained. Parallelized batch offline training, although horizontally scalable, is often not time-considerate or cost-effective. In this paper, we propose Lambda Learner, a new framework for training models by incremental updates in response to mini-batches from data streams. We show that the resulting model of our framework closely estimates a periodically updated model trained on offline data and outperforms it when model updates are time-sensitive. We provide theoretical proof that the incremental learning updates improve the loss-function over a stale batch model. We present a large-scale deployment on the sponsored content platform for a large social network, serving hundreds of millions of users across different channels (e.g., desktop, mobile). We address challenges and complexities from both algorithms and infrastructure perspectives, and illustrate the system details for computation, storage, and streaming production of training data. "}}
