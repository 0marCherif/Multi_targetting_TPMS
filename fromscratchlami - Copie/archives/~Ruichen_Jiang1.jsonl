{"id": "I4Lpdm_Znex", "cdate": 1683929832600, "mdate": 1683929832600, "content": {"title": "A conditional gradient-based method for simple bilevel optimization with convex lower-level problem", "abstract": "In this paper, we study a class of bilevel optimization problems, also known as simple bilevel optimization, where we minimize a smooth objective function over the optimal solution set of another convex constrained optimization problem. Several iterative methods have been developed for tackling this class of problems. Alas, their convergence guarantees are either asymptotic for the upper-level objective, or the convergence rates are slow and sub-optimal. To address this issue,\nin this paper, we introduce a novel bilevel optimization method that locally approximates the solution set of the lower-level problem via a cutting plane and then runs a conditional gradient update to decrease the upper-level objective.  When the upper-level objective is convex, we show that our method requires ${\\mathcal{O}}(\\max\\{1/\\epsilon_f,1/\\epsilon_g\\})$ iterations to find a solution that is $\\epsilon_f$-optimal for the upper-level objective and  $\\epsilon_g$-optimal for the lower-level objective. Moreover, when the upper-level objective is non-convex, our method requires ${\\mathcal{O}}(\\max\\{1/\\epsilon_f^2,1/(\\epsilon_f\\epsilon_g)\\})$ iterations to find an $(\\epsilon_f,\\epsilon_g)$-optimal solution. We also prove stronger convergence guarantees under the H\\\"olderian error bound assumption on the lower-level problem.\nTo the best of our knowledge, our method achieves the best-known iteration complexity for the considered class of bilevel problems"}}
{"id": "RjK8VosVZyp", "cdate": 1674763059965, "mdate": 1674763059965, "content": {"title": "Generalized Optimistic Methods for Convex-Concave Saddle Point Problems", "abstract": "The optimistic gradient method has seen increasing popularity as an efficient first-order method for solving convex-concave saddle point problems. To analyze its iteration complexity, a recent work [arXiv:1901.08511] proposed an interesting perspective that interprets the optimistic gradient method as an approximation to the proximal point method. In this paper, we follow this approach and distill the underlying idea of optimism to propose a generalized optimistic method, which encompasses the optimistic gradient method as a special case. Our general framework can handle constrained saddle point problems with composite objective functions and can work with arbitrary norms with compatible Bregman distances. Moreover, we also develop an adaptive line search scheme to select the stepsizes without knowledge of the smoothness coefficients. We instantiate our method with first-order, second-order and higher-order oracles and give sharp global iteration complexity bounds. When the objective function is convex-concave, we show that the averaged iterates of our $p$-th-order method ($p\u22651$) converge at a rate of $O(1/N^{\\frac{p+1}{2}})$. When the objective function is further strongly-convex-strongly-concave, we prove a complexity bound of $O(\\frac{L_1}{\\mu} \\log \\frac{1}{\\epsilon} )$ for our first-order method and a bound of $O((\\frac{L_p D^{\\frac{p-1}{2}}}{\\mu})^{\\frac{2}{p+1}}+\\log\\log \\frac{1}{\\epsilon})$ for our $p$-th-order method ($p \\geq 2$) respectively, where $L_p$ ($p\\geq 1$) is the Lipschitz constant of the $p$-th-order derivative, $\\mu$ is the strongly-convex parameter, and $D$ is the initial Bregman distance to the saddle point. Moreover, our line search scheme provably only requires an almost constant number of calls to a subproblem solver per iteration on average, making our first-order and second-order methods particularly amenable to implementation."}}
{"id": "aryNFaFBV8", "cdate": 1672531200000, "mdate": 1681661155497, "content": {"title": "Online Learning Guided Curvature Approximation: A Quasi-Newton Method with Global Non-Asymptotic Superlinear Convergence", "abstract": "Quasi-Newton algorithms are among the most popular iterative methods for solving unconstrained minimization problems, largely due to their favorable superlinear convergence property. However, existing results for these algorithms are limited as they provide either (i) a global convergence guarantee with an asymptotic superlinear convergence rate, or (ii) a local non-asymptotic superlinear rate for the case that the initial point and the initial Hessian approximation are chosen properly. In particular, no current analysis for quasi-Newton methods guarantees global convergence with an explicit superlinear convergence rate. In this paper, we close this gap and present the first globally convergent quasi-Newton method with an explicit non-asymptotic superlinear convergence rate. Unlike classical quasi-Newton methods, we build our algorithm upon the hybrid proximal extragradient method and propose a novel online learning framework for updating the Hessian approximation matrices. Specifically, guided by the convergence analysis, we formulate the Hessian approximation update as an online convex optimization problem in the space of matrices, and we relate the bounded regret of the online problem to the superlinear convergence of our method."}}
{"id": "2lKGRn-gi5", "cdate": 1664731449231, "mdate": null, "content": {"title": "Conditional gradient-based method for bilevel optimization with convex lower-level problem", "abstract": "In this paper, we study simple bilevel optimization problems, where we minimize a smooth objective function over the optimal solution set of another convex constrained optimization problem. Several iterative methods have been developed for tackling this class of problems. Alas, their convergence guarantees are not satisfactory as they are either asymptotic for the upper-level objective, or the convergence rates  are slow and sub-optimal. To address this issue, in this paper, we introduce a conditional gradient-based (CG-based) method to solve the considered problem. The main idea is to locally approximate the solution set of the lower-level problem via a cutting plane, and then run a CG-type update to decrease the upper-level objective. When the upper-level objective is convex, we show that our method requires ${\\mathcal{O}}(\\max\\{1/\\epsilon_f,1/\\epsilon_g\\})$ iterations to find a solution that is $\\epsilon_f$-optimal for the upper-level objective and  $\\epsilon_g$-optimal for the lower-level objective. Moreover, when the upper-level objective is non-convex, our method requires ${\\mathcal{O}}(\\max\\{1/\\epsilon_f^2,1/(\\epsilon_f\\epsilon_g)\\})$ iterations to find an $(\\epsilon_f,\\epsilon_g)$-optimal solution. To the best of our knowledge, our method achieves the best-known iteration complexity for the considered bilevel problem. "}}
{"id": "H34Ah8Loqgq", "cdate": 1646077524426, "mdate": null, "content": {"title": "Future Gradient Descent for Adapting the Temporal Shifting Data Distribution in Online Recommendation System", "abstract": "One of the key challenges of learning an online recommendation model is the temporal domain shift, which causes the mismatch between the training and testing data distribution and hence domain generalization error. To overcome, we propose to learn a meta future gradient generator that forecasts the gradient information of the future data distribution for training so that the recommendation model can be trained as if we were able to look ahead at the future of its deployment. Compared with Batch Update, a widely used paradigm, our theory suggests that the proposed algorithm achieves smaller temporal domain generalization error measured by a gradient variation term in a local regret. We demonstrate the empirical advantage by comparing with various representative baselines."}}
{"id": "nT4q1OTFnG", "cdate": 1640995200000, "mdate": 1681661155491, "content": {"title": "Generalized Optimistic Methods for Convex-Concave Saddle Point Problems", "abstract": "The optimistic gradient method has seen increasing popularity as an efficient first-order method for solving convex-concave saddle point problems. To analyze its iteration complexity, a recent work [arXiv:1901.08511] proposed an interesting perspective that interprets the optimistic gradient method as an approximation to the proximal point method. In this paper, we follow this approach and distill the underlying idea of optimism to propose a generalized optimistic method, which encompasses the optimistic gradient method as a special case. Our general framework can handle constrained saddle point problems with composite objective functions and can work with arbitrary norms with compatible Bregman distances. Moreover, we also develop an adaptive line search scheme to select the stepsizes without knowledge of the smoothness coefficients. We instantiate our method with first-order, second-order and higher-order oracles and give sharp global iteration complexity bounds. When the objective function is convex-concave, we show that the averaged iterates of our $p$-th-order method ($p\\geq 1$) converge at a rate of $\\mathcal{O}(1/N^\\frac{p+1}{2})$. When the objective function is further strongly-convex-strongly-concave, we prove a complexity bound of $\\mathcal{O}(\\frac{L_1}{\\mu}\\log\\frac{1}{\\epsilon})$ for our first-order method and a bound of $\\mathcal{O}((L_p D^\\frac{p-1}{2}/\\mu)^{\\frac{2}{p+1}}+\\log\\log\\frac{1}{\\epsilon})$ for our $p$-th-order method ($p\\geq 2$) respectively, where $L_p$ ($p\\geq 1$) is the Lipschitz constant of the $p$-th-order derivative, $\\mu$ is the strongly-convex parameter, and $D$ is the initial Bregman distance to the saddle point. Moreover, our line search scheme provably only requires an almost constant number of calls to a subproblem solver per iteration on average, making our first-order and second-order methods particularly amenable to implementation."}}
{"id": "_YT01Qe0c_0", "cdate": 1640995200000, "mdate": 1681661155301, "content": {"title": "Generalized Frank-Wolfe Algorithm for Bilevel Optimization", "abstract": "In this paper, we study a class of bilevel optimization problems, also known as simple bilevel optimization, where we minimize a smooth objective function over the optimal solution set of another convex constrained optimization problem. Several iterative methods have been developed for tackling this class of problems. Alas, their convergence guarantees are either asymptotic for the upper-level objective, or the convergence rates are slow and sub-optimal. To address this issue, in this paper, we introduce a novel bilevel optimization method that locally approximates the solution set of the lower-level problem via a cutting plane, and then runs a conditional gradient update to decrease the upper-level objective. When the upper-level objective is convex, we show that our method requires ${\\mathcal{O}}(\\max\\{1/\\epsilon_f,1/\\epsilon_g\\})$ iterations to find a solution that is $\\epsilon_f$-optimal for the upper-level objective and $\\epsilon_g$-optimal for the lower-level objective. Moreover, when the upper-level objective is non-convex, our method requires ${\\mathcal{O}}(\\max\\{1/\\epsilon_f^2,1/(\\epsilon_f\\epsilon_g)\\})$ iterations to find an $(\\epsilon_f,\\epsilon_g)$-optimal solution. We also prove stronger convergence guarantees under the H\\\"olderian error bound assumption on the lower-level problem. To the best of our knowledge, our method achieves the best-known iteration complexity for the considered class of bilevel problems."}}
{"id": "DnhCT0ehC2", "cdate": 1640995200000, "mdate": 1669145109919, "content": {"title": "Future Gradient Descent for Adapting the Temporal Shifting Data Distribution in Online Recommendation Systems", "abstract": "One of the key challenges of learning an online recommendation model is the temporal domain shift, which causes the mismatch between the training and testing data distribution and hence domain generalization error. To overcome, we propose to learn a meta future gradient generator that forecasts the gradient information of the future data distribution for training so that the recommendation model can be trained as if we were able to look ahead at the future of its deployment. Compared with Batch Update, a widely used paradigm, our theory suggests that the proposed algorithm achieves smaller temporal domain generalization error measured by a gradient variation term in a local regret. We demonstrate the empirical advantage by comparing with various representative baselines."}}
{"id": "D40rqQ1N0lF", "cdate": 1640995200000, "mdate": 1669145110020, "content": {"title": "Future gradient descent for adapting the temporal shifting data distribution in online recommendation systems", "abstract": "One of the key challenges of learning an online recommendation model is the temporal domain shift, which causes the mismatch between the training and testing data distribution and hence domain gene..."}}
{"id": "mQjQPJPG1gz", "cdate": 1609459200000, "mdate": 1681661155301, "content": {"title": "Antenna Efficiency in Massive MIMO Detection", "abstract": "In this paper, we consider the multi-user detection problem in a multiple-input multiple-output (MIMO) system, where the number of receive antennas at the base station (BS) grows infinitely large. We propose a new performance metric, called antenna efficiency, to characterize how fast the vector error probability (VEP) decreases as the number of receive antennas increases in the large system limit. We analyze the optimal maximum-likelihood (ML) detector and the simple zero-forcing (ZF) detector and prove that their antenna efficiency admits a simple closed form, which quantifies the impacts of the user-to-antenna ratio, the signal-to-noise ratio (SNR), and the constellation set on the VEP. Numerical results show that our analysis can well describe the empirical detection error performance in a realistic massive MIMO system."}}
