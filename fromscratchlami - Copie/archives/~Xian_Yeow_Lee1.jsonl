{"id": "62_fMHuggF", "cdate": 1665251229389, "mdate": null, "content": {"title": "A study of natural robustness of deep reinforcement learning algorithms towards adversarial perturbations", "abstract": "Deep reinforcement learning (DRL) has been shown to have numerous potential applications in the real world. However, DRL algorithms are still extremely sensitive to noise and adversarial perturbations, hence inhibiting the deployment of RL in many real-life applications. Analyzing the robustness of DRL algorithms to adversarial attacks is an important prerequisite to enabling the widespread adoption of DRL algorithms. Common perturbations on DRL frameworks during test time include perturbations to the observation and the action channel. Compared with observation channel attacks, action channel attacks are less studied; hence, few comparisons exist that compare the effectiveness of these attacks in DRL literature. In this work, we examined the effectiveness of these two paradigms of attacks on common DRL algorithms and studied the natural robustness of DRL algorithms towards various adversarial attacks in hopes of gaining insights into the individual response of each type of algorithm under different attack conditions. "}}
{"id": "f9Lk1G9q-G-", "cdate": 1664314537199, "mdate": null, "content": {"title": "Generative Design of Material Microstructures for Organic Solar Cells using Diffusion Models", "abstract": "Score-based methods, particularly denoising diffusion probabilistic models (DDPMs), have demonstrated impressive improvements to state-of-the-art generative modeling. Due to their impressive ability to sample from complex distributions, DDPM models and related variants, all broadly categorized under diffusion models, apply to various applications. In this work, we compare the performance of a diffusion model with a Wasserstein Generative Adversarial Network in generating two-phase microstructures of photovoltaic cells. We demonstrate the diffusion model's performance improvements in generating realistic-looking microstructures and its ability to cover several modes of the target distribution."}}
{"id": "wEJCMFS7Zg", "cdate": 1640995200000, "mdate": 1668484620376, "content": {"title": "Stochastic Conservative Contextual Linear Bandits", "abstract": "Many physical systems have underlying safety considerations that require that the strategy deployed ensures the satisfaction of a set of constraints. Further, often we have only partial information on the state of the system. We study the problem of safe real-time decision making under uncertainty. In this paper, we formulate a conservative stochastic contextual bandit formulation for real-time decision making when an adversary chooses a distribution on the set of possible contexts and the learner is subject to certain safety/performance constraints. The learner observes only the context distribution and the exact context is unknown, and the goal is to develop an algorithm that selects a sequence of optimal actions to maximize the cumulative reward without violating the safety constraints at any time step. By leveraging the UCB algorithm for this setting, we propose a conservative linear UCB algorithm for stochastic bandits with context distribution. We prove an upper bound on the regret of the algorithm and show that it can be decomposed into three terms: (i) an upper bound for the regret of the standard linear UCB algorithm, (ii) a constant term (independent of time horizon) that accounts for the loss of being conservative in order to satisfy the safety constraint, and (ii) a constant term (independent of time horizon) that accounts for the loss for the contexts being unknown and only the distribution being known. To validate the performance of our approach we perform extensive simulations on synthetic data and on real-world maize data collected through the Genomes to Fields (G2F) initiative."}}
{"id": "sonJCw_Qdq", "cdate": 1640995200000, "mdate": 1668484620385, "content": {"title": "PowerGym: A Reinforcement Learning Environment for Volt-Var Control in Power Distribution Systems", "abstract": "Reinforcement learning for power distribution systems has so far been studied using customized environments due to the proprietary nature of the power industry. To encourage researchers to benchmar..."}}
{"id": "WnkKdOpFs-W", "cdate": 1640995200000, "mdate": 1668484620377, "content": {"title": "Distributed Online Non-convex Optimization with Composite Regret", "abstract": "Regret has been widely adopted as the metric of choice for evaluating the performance of online optimization algorithms for distributed, multi-agent systems. However, variations in data or model associated with each agent can significantly impact decisions, and requires consensus among agents. Moreover, most existing works have focused on developing approaches for (strongly) convex losses, and very few results have been obtained in terms of regret bounds in distributed online optimization for general non-convex losses. To address these two issues, we propose a novel composite regret with a new network-based metric to evaluate distributed online optimization algorithms. We concretely define static and dynamic forms of the composite regret. By leveraging the dynamic form of our composite regret, we develop a consensus-based online normalized gradient (CONGD) approach for pseudo-convex losses and then show a sublinear behavior for CONGD relating to a regularity term for the path variation of the optimizer. For general non-convex losses, we first explore the regrets defined based on the recent advances such that no deterministic algorithm can achieve the sublinear regret. We then develop the distributed online non-convex optimization with composite regret (DINOCO) without access to the gradients, depending on an offline optimization oracle. We show that DINOCO can achieve sublinear regret; to our knowledge, this is the first regret bound for general distributed online non-convex learning."}}
{"id": "VDCp9qclAI", "cdate": 1640995200000, "mdate": 1668484620434, "content": {"title": "Distributed Online Non-convex Optimization with Composite Regret", "abstract": "Regret has been widely adopted as the metric of choice for evaluating the performance of online optimization algorithms for distributed, multi-agent systems. However, data/model variations associated with agents can significantly impact decisions and requires consensus among agents. Moreover, most existing works have focused on developing approaches for (either strongly or non-strongly) convex losses, and very few results have been obtained regarding regret bounds in distributed online optimization for general non-convex losses. To address these two issues, we propose a novel composite regret with a new network regret-based metric to evaluate distributed online optimization algorithms. We concretely define static and dynamic forms of the composite regret. By leveraging the dynamic form of our composite regret, we develop a consensus-based online normalized gradient (CONGD) approach for pseudo-convex losses, and it provably shows a sublinear behavior relating to a regularity term for the path variation of the optimizer. For general non-convex losses, we first shed light on the regret for the setting of distributed online non-convex learning based on recent advances such that no deterministic algorithm can achieve the sublinear regret. We then develop the distributed online non-convex optimization with composite regret (DINOCO) without access to the gradients, depending on an offline optimization oracle. DINOCO is shown to achieve sublinear regret; to our knowledge, this is the first regret bound for general distributed online non-convex learning."}}
{"id": "FHDDViDL6i", "cdate": 1640995200000, "mdate": 1668484620375, "content": {"title": "MDPGT: Momentum-Based Decentralized Policy Gradient Tracking", "abstract": "We propose a novel policy gradient method for multi-agent reinforcement learning, which leverages two different variance-reduction techniques and does not require large batches over iterations. Specifically, we propose a momentum-based decentralized policy gradient tracking (MDPGT) where a new momentum-based variance reduction technique is used to approximate the local policy gradient surrogate with importance sampling, and an intermediate parameter is adopted to track two consecutive policy gradient surrogates. MDPGT provably achieves the best available sample complexity of O(N -1 e -3) for converging to an e-stationary point of the global average of N local performance functions (possibly nonconcave). This outperforms the state-of-the-art sample complexity in decentralized model-free reinforcement learning and when initialized with a single trajectory, the sample complexity matches those obtained by the existing decentralized policy gradient methods. We further validate the theoretical claim for the Gaussian policy function. When the required error tolerance e is small enough, MDPGT leads to a linear speed up, which has been previously established in decentralized stochastic optimization, but not for reinforcement learning. Lastly, we provide empirical results on a multi-agent reinforcement learning benchmark environment to support our theoretical findings."}}
{"id": "h6gatquTQ5q", "cdate": 1637382368010, "mdate": null, "content": {"title": "A Conservative Stochastic Contextual Bandit Based Framework for Farming Recommender Systems", "abstract": "The goal of this work is to develop a recommendation system for smart farming such that based on the details of the farm and the farming conditions, including information on the weather and soil properties, the system presents recommendations on the choice of the crop/seed, the type of fertilizers, and the amount of water for irrigation in order to maximize the overall net profit of the farmer. We refer to this problem as the crop-fertilizer-irrigation (CFI) recommender problem. In this paper, we propose a conservative, stochastic, contextual bandit formulation for solving the CFI problem, where the context captures the farm ID, weather indices and soil properties, the action set is the possible types of crops/seed, the types of fertilizers and irrigation, and the reward is the net profit of the farmer. Our bandit formulation is a conservative bandit setting since we incorporate constraints on the learned policy such that the learned policy need to satisfy certain performance criteria imposed by the farmer while maximizing the reward. Furthermore, our bandit formulation is also stochastic in the sense that the contexts are not ob- servable, rather a distribution of the contexts are known. The stochastic bandit setting captures the uncertainty associated with the measurements of the weather indices and the soil properties. Based on the optimism in the face of uncertainty principle, we propose an algorithm to solve the bandit formulation of the CFI problem. To validate the performance of our approach we used the maize data collected through the G2F initiative. While we present initial model fitting results, the implementation and validation of the proposed algorithm are part of our future work."}}
{"id": "r7-mkF0QOCr", "cdate": 1637361803336, "mdate": null, "content": {"title": "Fast Unsupervised Generative Design for Structural Topology Optimization", "abstract": "Exploring the intersection of generative design and structural topology optimization has been a popular research area recently. Existing structural optimization methods have been shown to generate high-performance and aesthetically pleasing structures but at a tremendous computational cost. The rapidly advancing field of deep learning, particularly generative modeling, has substantial potential to tackle the structural generative design problem. Previous works have utilized deep generative models for highly specific cases, ranging from a small set of loading conditions to heavily relying on supervised loss functions for training. We propose a new method targeted at generating near-optimal structures over a wide variety of initial conditions in a completely unsupervised manner. We accomplish this by implementing a novel Generative Adversarial Network (GAN) framework to generate densities that match our given target distribution and encode extremely efficient latent representations of the initial physical conditions of the sample. The target distribution used in this work comes from data generated via the solid isotropic material condition with penalization (SIMP) topology optimization algorithm. Our results show that the proposed framework can generate similar structures to those found using the SIMP optimization algorithm, which consequently demonstrates the potential variability in solution spaces for arbitrary problems in generative design."}}
{"id": "5ThX8_KgZwQ", "cdate": 1637338090011, "mdate": null, "content": {"title": "Inverse Design of Microstructures via Generative Networks for Organic Solar Cells", "abstract": "We consider the inverse problem of efficiently designing material microstructures that exhibit desired electrical properties in an organic solar cell design. We leverage data-driven generative models to learn the underlying data distribution and generate novel microstructures during test time. We focus on a recent framework, specifically generative invariance networks (InvNets), which simultaneously learns from a dataset of microstructures while constraining the output of the generative model to conform to constraints such as generating microstructure designs with a targeted short circuit current density, J values. While previous works in this area have focused on the model training and data efficiency aspects, the applicability and success of Generative Invariance Networks to different material systems (i.e., the donor material and the acceptor material chemistry) and device thickness remain unexplored. In this paper, we demonstrate that we can successfully adapt the same InvNet framework to different material systems and device thicknesses with minimal computational effort."}}
