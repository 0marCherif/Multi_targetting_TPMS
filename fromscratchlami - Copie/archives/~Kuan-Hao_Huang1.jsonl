{"id": "yoEreDUvi0", "cdate": 1702135504260, "mdate": 1702135504260, "content": {"title": "Contextual Label Projection for Cross-Lingual Structured Prediction", "abstract": "Translating training data into target languages has proven beneficial for cross-lingual transfer. However, for structure extraction tasks, translating data requires a label projection step, which translates input text and obtains translated labels in the translated text jointly. Previous research in label projection mostly compromises translation quality by either facilitating easy identification of translated labels from translated text or using word-level alignment between translation pairs to assemble translated phrase-level labels from the aligned words. In this paper, we introduce CLAP, which first translates text to the target language and performs contextual translation on the labels using the translated text as the context, ensuring better accuracy for the translated labels. We leverage instruction-tuned language models with multilingual capabilities as our contextual translator, imposing the constraint of the presence of translated labels in the translated text via instructions. We compare CLAP with other label projection techniques for creating pseudo-training data in target languages on event argument extraction, a representative structure extraction task. Results show that CLAP improves by 2-2.5 F1-score over other methods on the Chinese and Arabic ACE05 datasets."}}
{"id": "fuL9uY94Kl", "cdate": 1672531200000, "mdate": 1696016509627, "content": {"title": "TAGPRIME: A Unified Framework for Relational Structure Extraction", "abstract": "I-Hung Hsu, Kuan-Hao Huang, Shuning Zhang, Wenxin Cheng, Prem Natarajan, Kai-Wei Chang, Nanyun Peng. Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 2023."}}
{"id": "V1w4w2z03y", "cdate": 1672531200000, "mdate": 1696016509646, "content": {"title": "GENEVA: Benchmarking Generalizability for Event Argument Extraction with Hundreds of Event Types and Argument Roles", "abstract": ""}}
{"id": "O6JXVwrFUW", "cdate": 1672531200000, "mdate": 1696016509641, "content": {"title": "ParaAMR: A Large-Scale Syntactically Diverse Paraphrase Dataset by AMR Back-Translation", "abstract": "Kuan-Hao Huang, Varun Iyer, I-Hung Hsu, Anoop Kumar, Kai-Wei Chang, Aram Galstyan. Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 2023."}}
{"id": "JZ4lvEHPna", "cdate": 1672531200000, "mdate": 1687282391054, "content": {"title": "Understanding and Mitigating Spurious Correlations in Text Classification", "abstract": "Recent research has revealed that deep learning models have a tendency to leverage spurious correlations that exist in the training set but may not hold true in general circumstances. For instance, a sentiment classifier may erroneously learn that the token performances is commonly associated with positive movie reviews. Relying on these spurious correlations degrades the classifiers performance when it deploys on out-of-distribution data. In this paper, we examine the implications of spurious correlations through a novel perspective called neighborhood analysis. The analysis uncovers how spurious correlations lead unrelated words to erroneously cluster together in the embedding space. Driven by the analysis, we design a metric to detect spurious tokens and also propose a family of regularization methods, NFL (doN't Forget your Language) to mitigate spurious correlations in text classification. Experiments show that NFL can effectively prevent erroneous clusters and significantly improve the robustness of classifiers."}}
{"id": "9qWzEFiM0e", "cdate": 1672531200000, "mdate": 1696016509645, "content": {"title": "AMPERE: AMR-Aware Prefix for Generation-Based Event Argument Extraction Model", "abstract": ""}}
{"id": "8ynl_cbfKg", "cdate": 1672531200000, "mdate": 1696016509661, "content": {"title": "PIP: Parse-Instructed Prefix for Syntactically Controlled Paraphrase Generation", "abstract": ""}}
{"id": "7yotJ5iLj13", "cdate": 1672531200000, "mdate": 1687282391057, "content": {"title": "Learning Easily Updated General Purpose Text Representations with Adaptable Task-Specific Prefixes", "abstract": "Many real-world applications require making multiple predictions from the same text. Fine-tuning a large pre-trained language model for each downstream task causes computational burdens in the inference time due to several times of forward passes. To amortize the computational cost, freezing the language model and building lightweight models for downstream tasks based on fixed text representations are common solutions. Accordingly, how to learn fixed but general text representations that can generalize well to unseen downstream tasks becomes a challenge. Previous works have shown that the generalizability of representations can be improved by fine-tuning the pre-trained language model with some source tasks in a multi-tasking way. In this work, we propose a prefix-based method to learn the fixed text representations with source tasks. We learn a task-specific prefix for each source task independently and combine them to get the final representations. Our experimental results show that prefix-based training performs better than multi-tasking training and can update the text representations at a smaller computational cost than multi-tasking training."}}
{"id": "tlj78KCz9t", "cdate": 1640995200000, "mdate": 1663802596310, "content": {"title": "DEGREE: A Data-Efficient Generation-Based Event Extraction Model", "abstract": "I-Hung Hsu, Kuan-Hao Huang, Elizabeth Boschee, Scott Miller, Prem Natarajan, Kai-Wei Chang, Nanyun Peng. Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. 2022."}}
{"id": "hvLcelAWAe_", "cdate": 1640995200000, "mdate": 1676654160701, "content": {"title": "Unsupervised Syntactically Controlled Paraphrase Generation with Abstract Meaning Representations", "abstract": ""}}
