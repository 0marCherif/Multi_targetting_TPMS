{"id": "2H9lHYofEyG", "cdate": 1672531200000, "mdate": 1683879434262, "content": {"title": "Active Membership Inference Attack under Local Differential Privacy in Federated Learning", "abstract": "Federated learning (FL) was originally regarded as a framework for collaborative learning among clients with data privacy protection through a coordinating server. In this paper, we propose a new active membership inference (AMI) attack carried out by a dishonest server in FL. In AMI attacks, the server crafts and embeds malicious parameters into global models to effectively infer whether a target data sample is included in a client's private training data or not. By exploiting the correlation among data features through a non-linear decision boundary, AMI attacks with a certified guarantee of success can achieve severely high success rates under rigorous local differential privacy (LDP) protection; thereby exposing clients' training data to significant privacy risk. Theoretical and experimental results on several benchmark datasets show that adding sufficient privacy-preserving noise to prevent our attack would significantly damage FL's model utility."}}
{"id": "u3M99cvLWth", "cdate": 1640995200000, "mdate": 1683879434302, "content": {"title": "Heterogeneous Randomized Response for Differential Privacy in Graph Neural Networks", "abstract": "Graph neural networks (GNNs) are susceptible to privacy inference attacks (PIAS) given their ability to learn joint representation from features and edges among nodes in graph data. To prevent privacy leakages in GNNs, we propose a novel heterogeneous randomized response (HeteroRR) mechanism to protect nodes\u2019 features and edges against PIAS under differential privacy (DP) guarantees, without an undue cost of data and model utility in training GNNs. Our idea is to balance the importance and sensitivity of nodes\u2019 features and edges in redistributing the privacy budgets since some features and edges are more sensitive or important to the model utility than others. As a result, we derive significantly better randomization probabilities and tighter error bounds at both levels of nodes\u2019 features and edges departing from existing approaches, thus enabling us to maintain high data utility for training GNNs. An extensive theoretical and empirical analysis using benchmark datasets shows that HeteroRR significantly outperforms various baselines in terms of model utility under rigorous privacy protection for both nodes\u2019 features and edges. That enables us to defend PIAs in DP-preserving GNNs effectively."}}
{"id": "t9_Y9TiVUH", "cdate": 1640995200000, "mdate": 1683879434287, "content": {"title": "Heterogeneous Randomized Response for Differential Privacy in Graph Neural Networks", "abstract": "Graph neural networks (GNNs) are susceptible to privacy inference attacks (PIAs), given their ability to learn joint representation from features and edges among nodes in graph data. To prevent privacy leakages in GNNs, we propose a novel heterogeneous randomized response (HeteroRR) mechanism to protect nodes' features and edges against PIAs under differential privacy (DP) guarantees without an undue cost of data and model utility in training GNNs. Our idea is to balance the importance and sensitivity of nodes' features and edges in redistributing the privacy budgets since some features and edges are more sensitive or important to the model utility than others. As a result, we derive significantly better randomization probabilities and tighter error bounds at both levels of nodes' features and edges departing from existing approaches, thus enabling us to maintain high data utility for training GNNs. An extensive theoretical and empirical analysis using benchmark datasets shows that HeteroRR significantly outperforms various baselines in terms of model utility under rigorous privacy protection for both nodes' features and edges. That enables us to defend PIAs in DP-preserving GNNs effectively."}}
{"id": "ZUXZKjfptc9", "cdate": 1632875623496, "mdate": null, "content": {"title": "Bit-aware Randomized Response for Local Differential Privacy in Federated Learning", "abstract": "In this paper, we develop BitRand, a bit-aware randomized response algorithm, to preserve local differential privacy (LDP) in federated learning (FL). We encode embedded features extracted from clients' local data into binary encoding bits, in which different bits have different impacts on the embedded features. Based upon that, we randomize all the bits to preserve LDP with three key advantages: (1) Bit-aware: Bits with a more substantial influence on the model utility have smaller randomization probabilities, and vice-versa, under the same privacy protection; (2) Dimension-elastic: Increasing the dimensions of embedded features, gradients, model outcomes, and training rounds marginally affect the randomization probabilities of binary encoding bits under the same privacy protection; and (3) LDP protection is achieved for both embedded features and labels with tight privacy loss and expected error bounds ensuring high model utility. Extensive theoretical and experimental results show that our BitRand significantly outperforms various baseline approaches in text and image classification."}}
{"id": "fdCQvhYIy7", "cdate": 1514764800000, "mdate": 1683879434319, "content": {"title": "Towards Thermal Region of Interest for Human Emotion Estimation", "abstract": "In the recent years, researches in implementing visual-based Automatic Facial Expression Analysis (FEA) and human emotions estimation have been a great interest and had widespread applications. However, vision-based visual systems face challenges such as poor-quality images due to low light conditions, poker-faces, the contrast of expressions and emotions. Because of the advantages of thermal images - unsensitive to ambient light conditions, we focus on developing a human emotion estimating system using thermal-based cues. It overcomes the limits of visible images, however, once a change in emotion occurs, only some areas of the face is affected in terms of temperature. In addition, the loss of thermal information in the glasses areas is a matter of concern. This paper presents our proposed method, thermal region of interest, to fill the gap when using thermal images to estimate seven emotions."}}
