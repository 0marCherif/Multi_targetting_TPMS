{"id": "kFI7_An43fu", "cdate": 1682556928008, "mdate": 1682556928008, "content": {"title": "Generalization Analysis on Learning with a Concurrent Verifier", "abstract": "Machine learning technologies have been used in a wide range of practical systems.In practical situations, it is natural to expect the input-output pairs of a machine learning model to satisfy some requirements.However, it is difficult to obtain a model that satisfies requirements by just learning from examples.A simple solution is to add a module that checks whether the input-output pairs meet the requirements and then modifies the model's outputs. Such a module, which we call a {\\em concurrent verifier} (CV), can give a certification, although how the generalizability of the machine learning model changes using a CV is unclear. This paper gives a generalization analysis of learning with a CV. We analyze how the learnability of a machine learning model changes with a CV and show a condition where we can obtain a guaranteed hypothesis using a verifier only in the inference time.We also show that typical error bounds based on Rademacher complexity will be no larger than that of the original model when using a CV in multi-class classification and structured prediction settings."}}
{"id": "dFs4d0kqs2", "cdate": 1652737503897, "mdate": null, "content": {"title": "Generalization Analysis on Learning with a Concurrent Verifier", "abstract": "Machine learning technologies have been used in a wide range of practical systems.\nIn practical situations, it is natural to expect the input-output pairs of a machine learning model to satisfy some requirements.\nHowever, it is difficult to obtain a model that satisfies requirements by just learning from examples.\nA simple solution is to add a module that checks whether the input-output pairs meet the requirements and then modifies the model's outputs. Such a module, which we call a {\\em concurrent verifier} (CV), can give a certification, although how the generalizability of the machine learning model changes using a CV is unclear. This paper gives a generalization analysis of learning with a CV. We analyze how the learnability of a machine learning model changes with a CV and show a condition where we can obtain a guaranteed hypothesis using a verifier only in the inference time.\nWe also show that typical error bounds based on Rademacher complexity will be no larger than that of the original model when using a CV in multi-class classification and structured prediction settings. "}}
{"id": "ryWqU6lubr", "cdate": 1514764800000, "mdate": null, "content": {"title": "Submodular Function Maximization Over Graphs via Zero-Suppressed Binary Decision Diagrams", "abstract": "Submodular function maximization (SFM) has attracted much attention thanks to its applicability to various practical problems. Although most studies have considered SFM with size or budget constraints, more complex constraints often appear in practice. In this paper, we consider a very general class of SFM with such complex constraints (e.g., an s-t path constraint on a given graph). We propose a novel algorithm that takes advantage of zero-suppressed binary decision diagrams, which store all feasible solutions efficiently thus enabling us to circumvent the difficulty of determining feasibility. Theoretically, our algorithm is guaranteed to achieve (1-c)-approximations, where c is the curvature of a submodular function. Experiments show that our algorithm runs much faster than exact algorithms and finds better solutions than those obtained by an existing approximation algorithm in many instances. Notably, our algorithm achieves better than a 90%-approximation in all instances for which optimal values are available."}}
{"id": "HyWGZm-uWr", "cdate": 1514764800000, "mdate": null, "content": {"title": "Provable Fast Greedy Compressive Summarization with Any Monotone Submodular Function", "abstract": ""}}
{"id": "r1bglkWuWS", "cdate": 1483228800000, "mdate": null, "content": {"title": "Dancing with Decision Diagrams: A Combined Approach to Exact Cover", "abstract": "Exact cover is the problem of finding subfamilies, S* , of a family of\u00a0sets, S , over universe U , where S* forms a partition of U . \u00a0It is a popular NP-hard problem appearing in a wide range of computer\u00a0science studies. Knuth's algorithm DLX, a backtracking-based depth-first\u00a0search implemented with the data structure called dancing links, is known\u00a0as state-of-the-art for finding all exact covers. We propose a method to\u00a0accelerate DLX. Our method constructs a Zero-suppressed Binary Decision\u00a0Diagram (ZDD) that represents the set of solutions while running\u00a0depth-first search in DLX. Constructing ZDDs enables the efficient use of\u00a0memo cache to speed up the search. Moreover, our method has a virtue that\u00a0it outputs ZDDs; we can perform several useful operations with\u00a0them. Experiments confirm that the proposed method is up to several orders\u00a0of magnitude faster than DLX."}}
{"id": "r1ZN0axObS", "cdate": 1483228800000, "mdate": null, "content": {"title": "BDD-Constrained A* Search: A Fast Method for Solving Constrained DAG Shortest-Path Problems", "abstract": "This paper deals with the constrained DAG shortest path problem (CDSP), which finds the shortest path on a given directed acyclic graph (DAG) under any logical constraints posed on taken edges. There exists a previous work that uses binary decision diagrams (BDDs) to represent the logical constraints, and traverses the input DAG and the BDD simultaneously. The time complexity of this BDD-based method is derived from BDD size, and tends to be fast only when BDDs are small. However, since it does not prioritize the search order, there is considerable room for improvement, particularly for large BDDs. We combine the well-known A* search with the BDD-based method synergistically, and implement several novel heuristic functions. The key insight here is that the \u2018shortest path\u2019 in the BDD is a solution of a relaxed problem, just as the shortest path in the DAG is. Experiments, particularly practical machine learning applications, show that the proposed method deceases search time by up to 2 orders of magnitude, with the specific result that it is 2,000 times faster than a commercial solver."}}
{"id": "r1ZEkAg_br", "cdate": 1483228800000, "mdate": null, "content": {"title": "Compiling Graph Substructures into Sentential Decision Diagrams", "abstract": "The Zero-suppressed Sentential Decision Diagram (ZSDD) is a recentlydiscovered tractable representation of Boolean functions. ZSDD subsumes theZero-suppressed Binary Decision Diagram (ZDD) as a strict subset, andsimilar to ZDD, it can perform several useful operations like model countingand Apply operations. We propose a top-down compilation algorithmfor ZSDD that represents sets of specific graph substructures, e.g.,matchings and simple paths of a graph. We experimentally confirm that theproposed algorithm is faster than other construction methods includingbottom-up methods and top-down methods for ZDDs, and the resulting ZSDDsare smaller than ZDDs representing the same graph substructures. We alsoshow that the size constructed ZSDDs can be bounded by the branch-width of thegraph. This bound is tighter than that of ZDDs."}}
{"id": "HkbxTjxu-B", "cdate": 1483228800000, "mdate": null, "content": {"title": "Oracle Summaries of Compressive Summarization", "abstract": "This paper derives an Integer Linear Programming (ILP) formulation to obtain an oracle summary of the compressive summarization paradigm in terms of ROUGE. The oracle summary is essential to reveal the upper bound performance of the paradigm. Experimental results on the DUC dataset showed that ROUGE scores of compressive oracles are significantly higher than those of extractive oracles and state-of-the-art summarization systems. These results reveal that compressive summarization is a promising paradigm and encourage us to continue with the research to produce informative summaries."}}
{"id": "rJEiyx-u-r", "cdate": 1451606400000, "mdate": null, "content": {"title": "Zero-Suppressed Sentential Decision Diagrams", "abstract": "The Sentential Decision Diagram (SDD) is a prominent knowledge representation language that subsumes the Ordered Binary Decision Diagram (OBDD) as a strict subset. Like OBDDs, SDDs have canonical forms and support bottom-up operations for combining SDDs, but they are more succinct than OBDDs. In this paper we introduce an SDD variant, called the Zero-suppressed Sentential Decision Diagram (ZSDD). The key idea of ZSDD is to employ new trimming rules for obtaining a canonical form. As a result, ZSDD subsumes the Zero-suppressed Binary Decision Diagram (ZDD) as a strict subset. ZDDs are known for their effectiveness on representing sparse Boolean functions. Likewise, ZSDDs can be more succinct than SDDs when representing sparse Boolean functions. We propose several polytime bottom-up operations over ZSDDs, and a technique for reducing ZSDD size, while maintaining applicability to important queries. We also specify two distinct upper bounds on ZSDD sizes; one is derived from the treewidth of a CNF and the other from the size of a family of sets. Experiments show that ZSDDs are smaller than SDDs or ZDDs for a standard benchmark dataset."}}
{"id": "BkWMZneuWS", "cdate": 1451606400000, "mdate": null, "content": {"title": "Phrase Table Pruning via Submodular Function Maximization", "abstract": "Phrase table pruning is the act of removing phrase pairs from a phrase table to make it smaller, ideally removing the least useful phrases first. We propose a phrase table pruning method that formulates the task as a submodular function maximization problem, and solves it by using a greedy heuristic algorithm. The proposed method can scale with input size and long phrases, and experiments show that it achieves higher BLEU scores than state-of-the-art pruning methods."}}
