{"id": "yE8R8H1eqm", "cdate": 1693408256229, "mdate": 1693408256229, "content": {"title": "Tensor methods for strongly convex strongly concave saddle point problems and strongly monotone variational inequalities", "abstract": "In this paper we propose three p-th order tensor methods for \u03bc-strongly-convex-strongly-concave saddle point problems (SPP). The first method is based on the assumption of p-th order smoothness of the objective and it achieves a convergence rate of O((LpRp\u22121\u03bc)2p+1log\u03bcR2\u03b5G), where R is an estimate of the initial distance to the solution, and \u03b5G is the error in terms of duality gap. Under additional assumptions of first and second order smoothness of the objective we connect the first method with a locally superlinear converging algorithm and develop a second method with the complexity of O\u239b\u239d\u239c\u239c(LpRp\u22121\u03bc)2p+1logL2Rmax{1,L1\u03bc}\u03bc+loglogL312\u03bc2\u03b5GlogL1L2\u03bc2\u239e\u23a0\u239f\u239f. The third method is a modified version of the second method, and it solves gradient norm minimization SPP with O\u0303 ((LpRp\u03b5\u2207)2p+1) oracle calls, where \u03b5\u2207 is an error in terms of norm of the gradient of the objective. Since we treat SPP as a particular case of variational inequalities, we also propose three methods for strongly monotone variational inequalities with the same complexity as the described above."}}
{"id": "XmIO33yKUn", "cdate": 1693408097206, "mdate": 1693408097206, "content": {"title": "Near-optimal tensor methods for minimizing the gradient norm of convex functions and accelerated primal-dual tensor methods", "abstract": "Motivated, in particular, by the entropy-regularized optimal transport problem, we\nconsider convex optimization problems with linear equality constraints, where the\ndual objective has Lipschitz p-th order derivatives, and develop two approaches for\nsolving such problems. The first approach is based on the minimization of the norm of\nthe gradient in the dual problem and then the reconstruction of an approximate pri-\nmal solution. Recently, Grapiglia and Nesterov [22] showed lower complexity bounds\nfor the problem of minimizing the gradient norm of the function with Lipschitz p-th\norder derivatives. Still, the question of optimal or near-optimal methods remained\nopen as the algorithms presented in [22] achieve suboptimal bounds only. We close\nthis gap by proposing two near-optimal (up to logarithmic factors) methods with\ncomplexity bounds \u02dcO(\u03b5\u22122(p+1)/(3p+1)) and \u02dcO(\u03b5\u22122/(3p+1)) with respect to the initial\nobjective residual and the distance between the starting point and solution respec-\ntively. We then apply these results (having independent interest) to our primal-dual\nsetting. As the second approach, we propose a direct accelerated primal-dual tensor\nmethod for convex problems with linear equality constraints, where the dual objec-\ntive has Lipschitz p-th order derivatives. For this algorithm, we prove \u02dcO(\u03b5\u22121/(p+1))\ncomplexity in terms of the duality gap and the residual in the constraints. We il-\nlustrate the practical performance of the proposed algorithms in experiments on\nlogistic regression, entropy-regularized optimal transport problem, and the minimal\nmutual information problem."}}
{"id": "TOU3uLxyC1w", "cdate": 1677628800000, "mdate": 1684953373229, "content": {"title": "Generalized self-concordant analysis of Frank-Wolfe algorithms", "abstract": "Projection-free optimization via different variants of the Frank\u2013Wolfe method has become one of the cornerstones of large scale optimization for machine learning and computational statistics. Numerous applications within these fields involve the minimization of functions with self-concordance like properties. Such generalized self-concordant functions do not necessarily feature a Lipschitz continuous gradient, nor are they strongly convex, making them a challenging class of functions for first-order methods. Indeed, in a number of applications, such as inverse covariance estimation or distance-weighted discrimination problems in binary classification, the loss is given by a generalized self-concordant function having potentially unbounded curvature. For such problems projection-free minimization methods have no theoretical convergence guarantee. This paper closes this apparent gap in the literature by developing provably convergent Frank\u2013Wolfe algorithms with standard $$\\mathcal {O}(1/k)$$ O ( 1 / k ) convergence rate guarantees. Based on these new insights, we show how these sublinearly convergent methods can be accelerated to yield linearly convergent projection-free methods, by either relying on the availability of a local liner minimization oracle, or a suitable modification of the away-step Frank\u2013Wolfe method."}}
{"id": "Dj8P0duAbd7", "cdate": 1672531200000, "mdate": 1682680028373, "content": {"title": "High-Probability Bounds for Stochastic Optimization and Variational Inequalities: the Case of Unbounded Variance", "abstract": "During recent years the interest of optimization and machine learning communities in high-probability convergence of stochastic optimization methods has been growing. One of the main reasons for this is that high-probability complexity bounds are more accurate and less studied than in-expectation ones. However, SOTA high-probability non-asymptotic convergence results are derived under strong assumptions such as the boundedness of the gradient noise variance or of the objective's gradient itself. In this paper, we propose several algorithms with high-probability convergence results under less restrictive assumptions. In particular, we derive new high-probability convergence results under the assumption that the gradient/operator noise has bounded central $\\alpha$-th moment for $\\alpha \\in (1,2]$ in the following setups: (i) smooth non-convex / Polyak-Lojasiewicz / convex / strongly convex / quasi-strongly convex minimization problems, (ii) Lipschitz / star-cocoercive and monotone / quasi-strongly monotone variational inequalities. These results justify the usage of the considered methods for solving problems that do not fit standard functional classes studied in stochastic optimization."}}
{"id": "S4KGBKBhCPo", "cdate": 1652737687182, "mdate": null, "content": {"title": "Clipped Stochastic Methods for Variational Inequalities with Heavy-Tailed Noise", "abstract": "Stochastic first-order methods such as Stochastic Extragradient (SEG) or Stochastic Gradient Descent-Ascent (SGDA) for solving smooth minimax problems and, more generally, variational inequality problems (VIP) have been gaining a lot of attention in recent years due to the growing popularity of adversarial formulations in machine learning. While high-probability convergence bounds are known to more accurately reflect the actual behavior of stochastic methods, most convergence results are provided in expectation. Moreover, the only known high-probability complexity results have been derived under restrictive sub-Gaussian (light-tailed) noise and bounded domain assumptions [Juditsky et al., 2011]. In this work, we prove the first high-probability complexity results with logarithmic dependence on the confidence level for stochastic methods for solving monotone and structured non-monotone VIPs with non-sub-Gaussian (heavy-tailed) noise and unbounded domains. In the monotone case, our results match the best known ones in the light-tails case [Juditsky et al., 2011], and are novel for structured non-monotone problems such as negative comonotone, quasi-strongly monotone, and/or star-cocoercive ones. We achieve these results by studying SEG and SGDA with clipping. In addition, we numerically validate that the gradient noise of many practical GAN formulations is heavy-tailed and show that clipping improves the performance of SEG/SGDA."}}
{"id": "Y4vT7m4e3d", "cdate": 1652737337903, "mdate": null, "content": {"title": "Decentralized Local Stochastic Extra-Gradient for Variational Inequalities", "abstract": "We consider distributed stochastic variational inequalities (VIs) on unbounded domains with the problem data that is heterogeneous (non-IID) and distributed across many devices. We make a very general assumption on the computational network that, in particular, covers the settings of fully decentralized calculations with time-varying networks and centralized topologies commonly used in Federated Learning. Moreover, multiple local updates on the workers can be made for reducing the communication frequency between the workers.\nWe extend the stochastic extragradient method to this very general setting and theoretically analyze its convergence rate in the strongly-monotone, monotone, and non-monotone (when a Minty solution exists) settings. The provided rates explicitly exhibit the dependence on network characteristics (e.g., mixing time), iteration counter, data heterogeneity, variance, number of devices, and other standard parameters. As a special case, our method and analysis apply to distributed stochastic saddle-point problems (SPP), e.g., to the training of Deep Generative Adversarial Networks (GANs) for which decentralized training has been reported to be extremely challenging. In experiments for the decentralized training of GANs we demonstrate the effectiveness of our proposed approach."}}
{"id": "zFnp0fkVCP", "cdate": 1640995200000, "mdate": 1684953373372, "content": {"title": "Clipped Stochastic Methods for Variational Inequalities with Heavy-Tailed Noise", "abstract": "Stochastic first-order methods such as Stochastic Extragradient (SEG) or Stochastic Gradient Descent-Ascent (SGDA) for solving smooth minimax problems and, more generally, variational inequality problems (VIP) have been gaining a lot of attention in recent years due to the growing popularity of adversarial formulations in machine learning. While high-probability convergence bounds are known to more accurately reflect the actual behavior of stochastic methods, most convergence results are provided in expectation. Moreover, the only known high-probability complexity results have been derived under restrictive sub-Gaussian (light-tailed) noise and bounded domain assumptions [Juditsky et al., 2011]. In this work, we prove the first high-probability complexity results with logarithmic dependence on the confidence level for stochastic methods for solving monotone and structured non-monotone VIPs with non-sub-Gaussian (heavy-tailed) noise and unbounded domains. In the monotone case, our results match the best known ones in the light-tails case [Juditsky et al., 2011], and are novel for structured non-monotone problems such as negative comonotone, quasi-strongly monotone, and/or star-cocoercive ones. We achieve these results by studying SEG and SGDA with clipping. In addition, we numerically validate that the gradient noise of many practical GAN formulations is heavy-tailed and show that clipping improves the performance of SEG/SGDA."}}
{"id": "kL4UIjJHPr", "cdate": 1640995200000, "mdate": 1684063683043, "content": {"title": "Zeroth-order methods for noisy H\u00f6lder-gradient functions", "abstract": "In this paper, we prove new complexity bounds for zeroth-order methods in non-convex optimization with inexact observations of the objective function values. We use the Gaussian smoothing approach of Nesterov and Spokoiny(Found Comput Math 17(2): 527\u2013566, 2015. https://doi.org/10.1007/s10208-015-9296-2 ) and extend their results, obtained for optimization methods for smooth zeroth-order non-convex problems, to the setting of minimization of functions with H\u00f6lder-continuous gradient with noisy zeroth-order oracle, obtaining noise upper-bounds as well. We consider finite-difference gradient approximation based on normally distributed random Gaussian vectors and prove that gradient descent scheme based on this approximation converges to the stationary point of the smoothed function. We also consider convergence to the stationary point of the original (not smoothed) function and obtain bounds on the number of steps of the algorithm for making the norm of its gradient small. Additionally we provide bounds for the level of noise in the zeroth-order oracle for which it is still possible to guarantee that the above bounds hold. We also consider separately the case of $$\\nu = 1$$ \u03bd = 1 and show that in this case the dependence of the obtained bounds on the dimension can be improved."}}
{"id": "_X7qriF1vZX", "cdate": 1640995200000, "mdate": 1684953373230, "content": {"title": "Accelerated variance-reduced methods for saddle-point problems", "abstract": ""}}
{"id": "RiOpkhKXsy", "cdate": 1640995200000, "mdate": 1679921169641, "content": {"title": "The power of first-order smooth optimization for black-box non-smooth problems", "abstract": ""}}
