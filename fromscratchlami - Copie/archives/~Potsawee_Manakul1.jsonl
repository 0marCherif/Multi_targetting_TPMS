{"id": "mO8hHSJ5mrB", "cdate": 1706794509246, "mdate": 1706794509246, "content": {"title": "LLM Comparative Assessment: Zero-shot NLG Evaluation through Pairwise Comparisons using Large Language Models", "abstract": "Current developments in large language models (LLMs) have enabled impressive zero-shot capabilities across various natural language tasks. An interesting application of these systems is in the automated assessment of natural language generation (NLG), a highly challenging area with great practical benefit. In this paper, we explore two options for exploiting the emergent abilities of LLMs for zero-shot NLG assessment: absolute score prediction, and comparative assessment which uses relative comparisons between pairs of candidates. Though comparative assessment has not been extensively studied in NLG assessment, we note that humans often find it more intuitive to compare two options rather than scoring each one independently. This work examines comparative assessment from multiple perspectives: performance compared to absolute grading; positional biases in the prompt; and efficient ranking in terms of the number of comparisons. We illustrate that LLM comparative assessment is a simple, general and effective approach for NLG assessment. For moderate-sized open-source LLMs, such as FlanT5 and Llama2-chat, comparative assessment is superior to prompt scoring, and in many cases can achieve performance competitive with state-of-the-art methods. Additionally, we demonstrate that LLMs often exhibit strong positional biases when making pairwise comparisons, and we propose debiasing methods that can further improve performance."}}
{"id": "OfstH_lKcA", "cdate": 1672531200000, "mdate": 1679912421389, "content": {"title": "SelfCheckGPT: Zero-Resource Black-Box Hallucination Detection for Generative Large Language Models", "abstract": ""}}
{"id": "2GT3DX-RN1u", "cdate": 1672531200000, "mdate": 1679912421371, "content": {"title": "MQAG: Multiple-choice Question Answering and Generation for Assessing Information Consistency in Summarization", "abstract": ""}}
{"id": "93uRkRz2oG", "cdate": 1640995200000, "mdate": 1679912421382, "content": {"title": "Podcast Summary Assessment: A Resource for Evaluating Summary Assessment Methods", "abstract": ""}}
{"id": "rGESN-ygxRN", "cdate": 1609459200000, "mdate": 1679912421374, "content": {"title": "Long-Span Summarization via Local Attention and Content Selection", "abstract": ""}}
{"id": "GFRbuTEuGf", "cdate": 1609459200000, "mdate": 1660147349607, "content": {"title": "Attention Forcing for Machine Translation", "abstract": "Auto-regressive sequence-to-sequence models with attention mechanisms have achieved state-of-the-art performance in various tasks including Text-To-Speech (TTS) and Neural Machine Translation (NMT). The standard training approach, teacher forcing, guides a model with the reference output history. At inference stage, the generated output history must be used. This mismatch can impact performance. However, it is highly challenging to train the model using the generated output. Several approaches have been proposed to address this problem, normally by selectively using the generated output history. To make training stable, these approaches often require a heuristic schedule or an auxiliary classifier. This paper introduces attention forcing for NMT. This approach guides the model with the generated output history and reference attention, and can reduce the training-inference mismatch without a schedule or a classifier. Attention forcing has been successful in TTS, but its application to NMT is more challenging, due to the discrete and multi-modal nature of the output space. To tackle this problem, this paper adds a selection scheme to vanilla attention forcing, which automatically selects a suitable training approach for each pair of training data. Experiments show that attention forcing can improve the overall translation quality and the diversity of the translations."}}
{"id": "8gJm2S1Eav", "cdate": 1609459200000, "mdate": 1679912421380, "content": {"title": "Sparsity and Sentence Structure in Encoder-Decoder Attention of Summarization Systems", "abstract": ""}}
{"id": "yshdxOQlyL9", "cdate": 1577836800000, "mdate": 1679912421382, "content": {"title": "CUED_SPEECH at TREC 2020 Podcast Summarisation Track", "abstract": ""}}
{"id": "fCq04y3quA", "cdate": 1577836800000, "mdate": 1679912421383, "content": {"title": "Abstractive Spoken Document Summarization Using Hierarchical Model with Multi-Stage Attention Diversity Optimization", "abstract": ""}}
{"id": "mHtRa6XJqRC", "cdate": 1546300800000, "mdate": 1679912421431, "content": {"title": "Disfluency Detection for Spoken Learner English", "abstract": ""}}
