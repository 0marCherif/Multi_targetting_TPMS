{"id": "CBuHKq4hTv", "cdate": 1640995200000, "mdate": 1682375514663, "content": {"title": "Tabular data: Deep learning is not all you need", "abstract": ""}}
{"id": "vdgtepS1pV", "cdate": 1621522021147, "mdate": null, "content": {"title": "Tabular Data: Deep Learning is Not All You Need", "abstract": "A key element of AutoML systems is setting the types of models that will be used for each type of task. For classification and regression problems with tabular data, the use of tree ensemble models (like XGBoost) is usually recommended. However, several deep learning models for tabular data have recently been proposed, claiming to outperform XGBoost for some use-cases. In this paper, we explore whether these deep models should be a recommended option for tabular data, by rigorously comparing the new deep models to XGBoost on a variety of datasets. In addition to systematically comparing their accuracy, we consider the tuning and computation they require. Our study shows that XGBoost outperforms these deep models across the datasets, including datasets used in the papers that proposed the deep models. We also demonstrate that XGBoost requires much less tuning. On the positive side, we show that an ensemble of the deep models and XGBoost performs better on these datasets than XGBoost alone."}}
{"id": "ykaMFWS1QCJ", "cdate": 1609459200000, "mdate": 1682375514821, "content": {"title": "Automated Testing of Graphics Units by Deep-Learning Detection of Visual Anomalies", "abstract": ""}}
{"id": "eCkCYbmqku", "cdate": 1609459200000, "mdate": 1682375514676, "content": {"title": "Tabular Data: Deep Learning is Not All You Need", "abstract": "A key element in solving real-life data science problems is selecting the types of models to use. Tree ensemble models (such as XGBoost) are usually recommended for classification and regression problems with tabular data. However, several deep learning models for tabular data have recently been proposed, claiming to outperform XGBoost for some use cases. This paper explores whether these deep models should be a recommended option for tabular data by rigorously comparing the new deep models to XGBoost on various datasets. In addition to systematically comparing their performance, we consider the tuning and computation they require. Our study shows that XGBoost outperforms these deep models across the datasets, including the datasets used in the papers that proposed the deep models. We also demonstrate that XGBoost requires much less tuning. On the positive side, we show that an ensemble of deep models and XGBoost performs better on these datasets than XGBoost alone."}}
{"id": "S8HoZxdw1Y", "cdate": 1609459200000, "mdate": 1682375514678, "content": {"title": "Spatial-Temporal Convolutional Network for Spread Prediction of COVID-19", "abstract": "In this work we present a spatial-temporal convolutional neural network for predicting future COVID-19 related symptoms severity among a population, per region, given its past reported symptoms. This can help approximate the number of future Covid-19 patients in each region, thus enabling a faster response, e.g., preparing the local hospital or declaring a local lockdown where necessary. Our model is based on a national symptom survey distributed in Israel and can predict symptoms severity for different regions daily. The model includes two main parts - (1) learned region-based survey responders profiles used for aggregating questionnaires data into features (2) Spatial-Temporal 3D convolutional neural network which uses the above features to predict symptoms progression."}}
{"id": "qujgc9RZQK8", "cdate": 1546300800000, "mdate": null, "content": {"title": "A Weak Supervision Approach to Detecting Visual Anomalies for Automated Testing of Graphics Units", "abstract": "We present a deep learning system for testing graphics units by detecting novel visual corruptions in videos. Unlike previous work in which manual tagging was required to collect labeled training data, our weak supervision method is fully automatic and needs no human labelling. This is achieved by reproducing driver bugs that increase the probability of generating corruptions, and by making use of ideas and methods from the Multiple Instance Learning (MIL) setting. In our experiments, we significantly outperform unsupervised methods such as GAN-based models and discover novel corruptions undetected by baselines, while adhering to strict requirements on accuracy and efficiency of our real-time system."}}
{"id": "v4RE7qOnVAx", "cdate": 1388534400000, "mdate": null, "content": {"title": "Mobile facility location: combinatorial filtering via weighted occupancy", "abstract": "An instance of the mobile facility location problem consists of a complete directed graph $$G = (V, E)$$ , in which each arc $$(u, v) \\in E$$ is associated with a numerical attribute $$\\mathcal M (u,v)$$ , representing the cost of moving any object from $$u$$ to $$v$$ . An additional ingredient of the input is a collection of servers $$S = \\{ s_1, \\ldots , s_k \\}$$ and a set of clients $$C = \\{ c_1, \\ldots , c_\\ell \\}$$ , which are located at nodes of the underlying graph. With this setting in mind, a movement scheme is a function $$\\psi : S \\rightarrow V$$ that relocates each server $$s_i$$ to a new position, $$\\psi ( s_i )$$ . We refer to $$\\mathcal M ( s_i, \\psi ( s_i ) )$$ as the relocation cost of $$s_i$$ , and to $$\\min _{i \\in [k]} \\mathcal M (c_j, \\psi ( s_i ) )$$ , the cost of assigning client $$c_j$$ to the nearest final server location, as the service cost of $$c_j$$ . The objective is to compute a movement scheme that minimizes the sum of relocation and service costs. In this paper, we resolve an open question posed by Demaine et al. (SODA \u201907) by characterizing the approximability of mobile facility location through LP-based methods. We also develop a more efficient algorithm, which is based on a combinatorial filtering approach. The latter technique is of independent interest, as it may be applicable in other settings as well. In this context, we introduce a weighted version of the occupancy problem, for which we establish interesting tail bounds, not before demonstrating that existing bounds cannot be extended."}}
{"id": "5ubpQMjXIR", "cdate": 1325376000000, "mdate": null, "content": {"title": "Jumping into the water: using software to monitor water supply systems", "abstract": "How a Ph.D. graduate went from theoretical computer scientist to water-sensor analyzer. How a Ph.D. graduate went from theoretical computer scientist to water-sensor analyzer."}}
{"id": "4m8ke_NSNT", "cdate": 1325376000000, "mdate": 1682375514669, "content": {"title": "Jumping into the water: using software to monitor water supply systems", "abstract": ""}}
{"id": "K4eXbMyTeTz", "cdate": 1293840000000, "mdate": null, "content": {"title": "On min-max r-gatherings", "abstract": "We consider a min\u2013max version of the previously studied r-gathering problem with unit-demands. The problem we consider is a metric facility-location problem, in which each open facility must serve at least r customers, and the maximum of all the facility- and connection-costs should be minimized (rather than their sum ). This problem is motivated by scenarios in which r customers are required for a facility to be worth opening, and the costs represent the time until the facility/connection will be available ( i.e. , we want to have the complete solution ready as soon as possible). We present a 3-approximation algorithm for this problem, and prove that it cannot be approximated better (assuming P \u2260 N P ). Next we consider this problem with the additional natural requirement that each customer will be assigned to a nearest open facility, and present a 9-approximation algorithm. We further consider previously introduced special cases and variants, and obtain improved algorithmic and hardness results."}}
