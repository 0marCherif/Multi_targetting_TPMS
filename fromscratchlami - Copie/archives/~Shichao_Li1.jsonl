{"id": "OHgapBDAE2q", "cdate": 1640995200000, "mdate": 1648708203866, "content": {"title": "Stereo Neural Vernier Caliper", "abstract": "We propose a new object-centric framework for learning-based stereo 3D object detection. Previous studies build scene-centric representations that do not consider the significant variation among outdoor instances and thus lack the flexibility and functionalities that an instance-level model can offer. We build such an instance-level model by formulating and tackling a local update problem, i.e., how to predict a refined update given an initial 3D cuboid guess. We demonstrate how solving this problem can complement scene-centric approaches in (i) building a coarse-to-fine multi-resolution system, (ii) performing model-agnostic object location refinement, and (iii) conducting stereo 3D tracking-by-detection. Extensive experiments demonstrate the effectiveness of our approach, which achieves state-of-the-art performance on the KITTI benchmark. Code and pre-trained models are available at https://github.com/Nicholasli1995/SNVC."}}
{"id": "nwJAqvMGHfC", "cdate": 1609459200000, "mdate": 1629978537435, "content": {"title": "How Do Adam and Training Strategies Help BNNs Optimization", "abstract": "The best performing Binary Neural Networks (BNNs) are usually attained using Adam optimization and its multi-step training variants. However, to the best of our knowledge, few studies explore the f..."}}
{"id": "IQp_MZ4FCi", "cdate": 1609459200000, "mdate": 1648708203887, "content": {"title": "Joint stereo 3D object detection and implicit surface reconstruction", "abstract": "We present the first learning-based framework for category-level 3D object detection and implicit shape estimation based on a pair of stereo RGB images in the wild. Previous stereo 3D object detection approaches cannot describe the complete shape details of the detected objects and often fails for the small objects. In contrast, we propose a new progressive approach that can (1) perform precise localization as well as provide a complete and resolution-agnostic shape description for the detected objects and (2) produce significantly more accurate orientation predictions for the tiny instances. This approach features a new instance-level network that explicitly models the unseen surface hallucination problem using point-based representations and uses a new geometric representation for orientation refinement. Extensive experiments show that our approach achieves state-of-the-art performance using various metrics on the KITTI benchmark. Code and pre-trained models will be available at this https URL."}}
{"id": "9cySA8iySZa", "cdate": 1609459200000, "mdate": 1632288212426, "content": {"title": "Exploring intermediate representation for monocular vehicle pose estimation", "abstract": "We present a new learning-based framework to recover vehicle pose in SO(3) from a single RGB image. In contrast to previous works that map local appearance to observation angles, we explore a progressive approach by extracting meaningful Intermediate Geometrical Representations (IGRs) to estimate egocentric vehicle orientation. This approach features a deep model that transforms perceived intensities to IGRs, which are mapped to a 3D representation encoding object orientation in the camera coordinate system. Core problems are what IGRs to use and how to learn them more effectively. We answer the former question by designing IGRs based on an interpolated cuboid that derives from primitive 3D annotation readily. The latter question motivates us to incorporate geometry knowledge with a new loss function based on a projective invariant. This loss function allows unlabeled data to be used in the training stage to improve representation learning. Without additional labels, our system outperforms previous monocular RGB-based methods for joint vehicle detection and pose estimation on the KITTI benchmark, achieving performance even comparable to stereo methods. Code and pre-trained models are available at this HTTPS URL."}}
{"id": "z5Q0lxBvBE", "cdate": 1577836800000, "mdate": null, "content": {"title": "GSNet: Joint Vehicle Pose and Shape Reconstruction with Geometrical and Scene-Aware Supervision", "abstract": "We present a novel end-to-end framework named as GSNet (Geometric and Scene-aware Network), which jointly estimates 6DoF poses and reconstructs detailed 3D car shapes from single urban street view. GSNet utilizes a unique four-way feature extraction and fusion scheme and directly regresses 6DoF poses and shapes in a single forward pass. Extensive experiments show that our diverse feature extraction and fusion scheme can greatly improve model performance. Based on a divide-and-conquer 3D shape representation strategy, GSNet reconstructs 3D vehicle shape with great detail (1352 vertices and 2700 faces). This dense mesh representation further leads us to consider geometrical consistency and scene context, and inspires a new multi-objective loss function to regularize network training, which in turn improves the accuracy of 6D pose estimation and validates the merit of jointly performing both tasks. We evaluate GSNet on the largest multi-task ApolloCar3D benchmark and achieve state-of-the-art performance both quantitatively and qualitatively. Project page is available at https://lkeab.github.io/gsnet/ ."}}
{"id": "j2YO2gMPKW", "cdate": 1577836800000, "mdate": null, "content": {"title": "Cascaded Deep Monocular 3D Human Pose Estimation With Evolutionary Training Data", "abstract": "End-to-end deep representation learning has achieved remarkable accuracy for monocular 3D human pose estimation, yet these models may fail for unseen poses with limited and fixed training data. This paper proposes a novel data augmentation method that: (1) is scalable for synthesizing massive amount of training data (over 8 million valid 3D human poses with corresponding 2D projections) for training 2D-to-3D networks, (2) can effectively reduce dataset bias. Our method evolves a limited dataset to synthesize unseen 3D human skeletons based on a hierarchical human representation and heuristics inspired by prior knowledge. Extensive experiments show that our approach not only achieves state-of-the-art accuracy on the largest public benchmark, but also generalizes significantly better to unseen and rare poses. Relevant files and tools are available at the project website."}}
{"id": "Hsgl4zZXxOpS", "cdate": 1546300800000, "mdate": null, "content": {"title": "Visualizing the Decision-making Process in Deep Neural Decision Forest.", "abstract": "Deep neural decision forest (NDF) achieved remarkable performance on various vision tasks via combining decision tree and deep representation learning. In this work, we first trace the decision-making process of this model and visualize saliency maps to understand which portion of the input influence it more for both classification and regression problems. We then apply NDF on a multi-task coordinate regression problem and demonstrate the distribution of routing probabilities, which is vital for interpreting NDF yet not shown for regression problems. The pre-trained model and code for visualization will be available at https://github.com/Nicholasli1995/ VisualizingNDF"}}
