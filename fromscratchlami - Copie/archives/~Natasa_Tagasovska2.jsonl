{"id": "IOWJsPJ2xGd", "cdate": 1667393652626, "mdate": null, "content": {"title": "Learning Causal Representations of Single Cells via Sparse Mechanism Shift Modeling", "abstract": "Latent variable models such as the Variational Auto-Encoder (VAE) have become a go-to tool for analyzing biological data, especially in the field of single-cell genomics. One remaining challenge is the interpretability of latent variables as biological processes that define a cell's identity. Outside of biological applications, this problem is commonly referred to as learning disentangled representations. Although several disentanglement-promoting variants of the VAE were introduced, and applied to single-cell genomics data, this task has been shown to be infeasible from independent and identically distributed measurements, without additional structure.\nInstead, recent methods propose to leverage non-stationary data, as well as the sparse mechanism shift assumption in order to learn disentangled representations with a causal semantic. Here, we extend the application of these methodological advances to the analysis of single-cell genomics data with genetic or chemical perturbations. More precisely, we propose a deep generative model of single-cell gene expression data for which each perturbation is treated as a stochastic intervention targeting an unknown, but sparse, subset of latent variables. We benchmark these methods on simulated single-cell data to evaluate their performance at latent units recovery, causal target identification and out-of-domain generalization. Finally, we apply those approaches to two real-world large-scale gene perturbation data sets and find that models that exploit the sparse mechanism shift hypothesis surpass contemporary methods on a transfer learning task. We implement our new model and benchmarks using the scvi-tools library, and release it as open-source software at \\url{https://github.com/Genentech/sVAE}."}}
{"id": "gdTXCy7fZf7", "cdate": 1664815573178, "mdate": null, "content": {"title": "Learning Causal Representations of Single Cells via Sparse Mechanism Shift Modeling", "abstract": "Latent variable models have become a go-to tool for analyzing biological data, especially in the field of single-cell genomics. One remaining challenge is the identification of individual latent variables related to biological pathways, more generally conceptualized as disentanglement. \nAlthough versions of variational autoencoders that explicitly promote disentanglement were introduced and applied to single-cell genomics data, the theoretical feasibility of disentanglement from independent and identically distributed measurements has been challenged.\nRecent methods propose instead to leverage non-stationary data, as well as the sparse mechanism assumption in order to learn disentangled representations, with a causal semantic. Here, we explore the application of these methodological advances in the analysis of single-cell genomics data with genetic or chemical perturbations. We benchmark these methods on simulated single cell expression data to evaluate their performance regarding disentanglement, causal target identification and out-of-domain generalisation. Finally, by applying the approaches to a large-scale gene perturbation dataset, we find that the model relying on the sparse mechanism shift hypothesis surpasses contemporary methods on a transfer learning task."}}
{"id": "U2rNXaTTXPQ", "cdate": 1664248840948, "mdate": null, "content": {"title": "A Pareto-optimal compositional energy-based model for sampling and optimization of protein sequences", "abstract": "Deep generative models have emerged as a popular machine learning-based approach for inverse design problems in the life sciences. However, these problems often require sampling new designs that satisfy multiple properties of interest in addition to learning the data distribution. This multi-objective optimization becomes more challenging when properties are independent or orthogonal to each other.\nIn this work, we propose a Pareto-compositional energy-based model (pcEBM), a framework that uses multiple gradient descent for sampling new designs that adhere to various constraints in optimizing distinct properties. We demonstrate its ability to learn non-convex Pareto fronts and generate sequences that simultaneously satisfy multiple desired properties across a series of real-world antibody design tasks."}}
{"id": "XoEL9TYp5h", "cdate": 1620396286748, "mdate": null, "content": {"title": "Copulas as High-Dimensional Generative Models: Vine Copula Autoencoders", "abstract": "We introduce the vine copula autoencoder (VCAE), a flexible generative model\nfor high-dimensional distributions built in a straightforward three-step procedure.\nFirst, an autoencoder (AE) compresses the data into a lower dimensional representation. Second, the multivariate distribution of the encoded data is estimated with\nvine copulas. Third, a generative model is obtained by combining the estimated\ndistribution with the decoder part of the AE. As such, the proposed approach\ncan transform any already trained AE into a flexible generative model at a low\ncomputational cost. This is an advantage over existing generative models such as\nadversarial networks and variational AEs which can be difficult to train and can\nimpose strong assumptions on the latent space. Experiments on MNIST, Street\nView House Numbers and Large-Scale CelebFaces Attributes datasets show that\nVCAEs can achieve competitive results to standard baselines."}}
{"id": "kkfrPgc6b9t", "cdate": 1620396194672, "mdate": null, "content": {"title": "Distinguishing Cause from Effect Using Quantiles: Bivariate Quantile Causal Discovery", "abstract": "Causal inference using observational data is challenging, especially in the bivariate case. Through\nthe minimum description length principle, we link\nthe postulate of independence between the generating mechanisms of the cause and of the effect\ngiven the cause to quantile regression. Based on\nthis theory, we develop Bivariate Quantile Causal\nDiscovery (bQCD), a new method to distinguish\ncause from effect assuming no confounding, selection bias or feedback. Because it uses multiple\nquantile levels instead of the conditional mean\nonly, bQCD is adaptive not only to additive, but\nalso to multiplicative or even location-scale generating mechanisms. To illustrate the effectiveness of our approach, we perform an extensive\nempirical comparison on both synthetic and real\ndatasets. This study shows that bQCD is robust\nacross different implementations of the method\n(i.e., the quantile regression), computationally efficient, and compares favorably to state-of-the-art\nmethods"}}
{"id": "jWxcgGjhZHQ", "cdate": 1620396093185, "mdate": null, "content": {"title": "Deep Smoothing of the Implied Volatility Surface", "abstract": "We present a neural network (NN) approach to fit and predict implied volatility surfaces (IVSs). Atypically to standard NN applications, financial industry practitioners use such models equally to replicate market prices and to value other financial instruments. In other words, low training losses are as important as generalization capabilities. Importantly, IVS models need to generate realistic arbitrage-free option prices, meaning that no portfolio can lead to risk-free profits. We propose an approach guaranteeing the absence of arbitrage opportunities by penalizing the loss using soft constraints. Furthermore, our method can be combined with standard IVS models in quantitative finance, thus providing a NN-based correction when such models fail at replicating observed market prices. This lets practitioners use our approach as a plug-in on top of classical methods. Empirical results show that this approach is particularly useful when only sparse or erroneous data are available. We also quantify the uncertainty of the model predictions in regions with few or no observations. We further explore how deeper NNs improve over shallower ones, as well as other properties of the network architecture. We benchmark our method against standard IVS models. By evaluating our method on both training sets, and testing sets, namely, we highlight both their capacity to reproduce observed prices and predict new ones.\n\n"}}
{"id": "mRntX7V1iMc", "cdate": 1620395996276, "mdate": null, "content": {"title": "Single-model uncertainties for deep learning", "abstract": "We provide single-model estimates of aleatoric and epistemic uncertainty for deep neural networks. To estimate aleatoric uncertainty, we propose Simultaneous Quantile Regression (SQR), a loss function to learn all the conditional quantiles of a given target variable. These quantiles can be used to compute well-calibrated prediction intervals. To estimate epistemic uncertainty, we propose Orthonormal Certificates (OCs), a collection of diverse non-constant functions that map all training samples to zero. These certificates map out-of-distribution examples to non-zero values, signaling epistemic uncertainty. Our uncertainty estimators are computationally attractive, as they do not require ensembling or retraining deep models, and achieve competitive performance."}}
{"id": "SJlBoVrlIS", "cdate": 1567802524818, "mdate": null, "content": {"title": "Copulas as High-Dimensional Generative Models: Vine Copula Autoencoders", "abstract": "We propose a vine copula autoencoder to construct flexible generative models for high-dimensional distributions in a straightforward three-step procedure. First, an autoencoder compresses the data using a lower dimensional representation. Second, the multivariate distribution of the encoded data is estimated with vine copulas.  Third, a generative model is obtained by combining the estimated distribution with the decoder part of the autoencoder. This approach can transform any already trained autoencoder into a flexible generative model at a low computational cost. This is an advantage over existing generative models such as adversarial networks and variational autoencoders which can be difficult to train and can impose strong assumptions on the latent space. Experiments on MNIST, Street View House Numbers and Large-Scale CelebFaces Attributes datasets show that vine copulas autoencoders can achieve competitive results to standard baselines."}}
{"id": "B1xmi4BeLr", "cdate": 1567802522730, "mdate": null, "content": {"title": "Single-Model Uncertainties for Deep Learning", "abstract": "We provide single-model estimates of aleatoric and epistemic uncertainty for deep neural networks. To estimate aleatoric uncertainty, we propose Simultaneous Quantile Regression (SQR), a loss function to learn all the conditional quantiles of a given target variable. These quantiles can be used to compute well-calibrated prediction intervals. To estimate epistemic uncertainty, we propose Orthonormal Certificates (OCs), a collection of diverse non-constant functions that map all training samples to zero. These certificates map out-of-distribution examples to non-zero values, signaling epistemic uncertainty. Our uncertainty estimators are computationally attractive, as they do not require ensembling or retraining deep models, and achieve state-of-the-art performance."}}
{"id": "BJexMzRDsm", "cdate": 1539985927525, "mdate": null, "content": {"title": "Generative Models for Simulating Mobility Trajectories", "abstract": "Mobility datasets are fundamental for evaluating algorithms pertaining to geographic information systems and facilitating experimental reproducibility. But privacy implications restrict sharing such datasets, as even aggregated location-data is vulnerable to membership inference attacks. Current synthetic mobility dataset generators attempt to superficially match a priori modeled mobility characteristics which do not accurately reflect the real-world characteristics. Modeling human mobility to generate synthetic yet semantically and statistically realistic trajectories is therefore crucial for publishing trajectory datasets having satisfactory utility level while preserving user privacy. Specifically, long-range dependencies inherent to human mobility are challenging to capture with both discriminative and generative models. In this paper, we benchmark the performance of recurrent neural architectures (RNNs), generative adversarial networks (GANs) and nonparametric copulas to generate synthetic mobility traces. We evaluate the generated trajectories with respect to their geographic and semantic similarity, circadian rhythms, long-range dependencies, training and generation time. We also include two sample tests to assess statistical similarity between the observed and simulated distributions, and we analyze the privacy tradeoffs with respect to membership inference and location-sequence attacks."}}
