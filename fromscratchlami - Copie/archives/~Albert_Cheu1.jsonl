{"id": "DrZXuTGg2A-", "cdate": 1632875436682, "mdate": null, "content": {"title": "Shuffle Private Stochastic Convex Optimization", "abstract": "In shuffle privacy, each user sends a collection of randomized messages to a trusted shuffler, the shuffler randomly permutes these messages, and the resulting shuffled collection of messages must satisfy differential privacy. Prior work in this model has largely focused on protocols that use a single round of communication to compute algorithmic primitives like means, histograms, and counts. In this work, we present interactive shuffle protocols for stochastic convex optimization. Our optimization protocols rely on a new noninteractive protocol for summing vectors of bounded $\\ell_2$ norm. By combining this sum subroutine with techniques including mini-batch stochastic gradient descent, accelerated gradient descent, and Nesterov's smoothing method, we obtain loss guarantees for a variety of convex loss functions that significantly improve on those of the local model and sometimes match those of the central model."}}
{"id": "8yYzfDoSN-W", "cdate": 1609459200000, "mdate": null, "content": {"title": "Differentially Private Histograms in the Shuffle Model from Fake Users", "abstract": "There has been much recent work in the shuffle model of differential privacy, particularly for approximate $d$-bin histograms. While these protocols achieve low error, the number of messages sent by each user -- the message complexity -- has so far scaled with $d$ or the privacy parameters. The message complexity is an informative predictor of a shuffle protocol's resource consumption. We present a protocol whose message complexity is two when there are sufficiently many users. The protocol essentially pairs each row in the dataset with a fake row and performs a simple randomization on all rows. We show that the error introduced by the protocol is small, using rigorous analysis as well as experiments on real-world data. We also prove that corrupt users have a relatively low impact on our protocol's estimates."}}
{"id": "ztPoaj50mvz", "cdate": 1577836800000, "mdate": null, "content": {"title": "Private Query Release Assisted by Public Data", "abstract": "We study the problem of differentially private query release assisted by access to public data. In this problem, the goal is to answer a large class $\\mathcal{H}$ of statistical queries with error no more than $\\alpha$ using a combination of public and private samples. The algorithm is required to satisfy differential privacy only with respect to the private samples. We study the limits of this task in terms of the private and public sample complexities. First, we show that we can solve the problem for any query class $\\mathcal{H}$ of finite VC-dimension using only $d/\\alpha$ public samples and $\\sqrt{p}d^{3/2}/\\alpha^2$ private samples, where $d$ and $p$ are the VC-dimension and dual VC-dimension of $\\mathcal{H}$, respectively. In comparison, with only private samples, this problem cannot be solved even for simple query classes with VC-dimension one, and without any private samples, a larger public sample of size $d/\\alpha^2$ is needed. Next, we give sample complexity lower bounds that exhibit tight dependence on $p$ and $\\alpha$. For the class of decision stumps, we give a lower bound of $\\sqrt{p}/\\alpha$ on the private sample complexity whenever the public sample size is less than $1/\\alpha^2$. Given our upper bounds, this shows that the dependence on $\\sqrt{p}$ is necessary in the private sample complexity. We also give a lower bound of $1/\\alpha$ on the public sample complexity for a broad family of query classes, which by our upper bound, is tight in $\\alpha$."}}
{"id": "pCFR3uwhom", "cdate": 1577836800000, "mdate": null, "content": {"title": "Separating Local & Shuffled Differential Privacy via Histograms", "abstract": "Recent work in differential privacy has highlighted the shuffled model as a promising avenue to compute accurate statistics while keeping raw data in users' hands. We present a protocol in this model that estimates histograms with error independent of the domain size. This implies an arbitrarily large gap in sample complexity between the shuffled and local models. On the other hand, we show that the models are equivalent when we impose the constraints of pure differential privacy and single-message randomizers."}}
{"id": "kHl7NKtdJY0", "cdate": 1577836800000, "mdate": null, "content": {"title": "The Limits of Pan Privacy and Shuffle Privacy for Learning and Estimation", "abstract": "There has been a recent wave of interest in intermediate trust models for differential privacy that eliminate the need for a fully trusted central data collector, but overcome the limitations of local differential privacy. This interest has led to the introduction of the shuffle model (Cheu et al., EUROCRYPT 2019; Erlingsson et al., SODA 2019) and revisiting the pan-private model (Dwork et al., ITCS 2010). The message of this line of work is that, for a variety of low-dimensional problems -- such as counts, means, and histograms -- these intermediate models offer nearly as much power as central differential privacy. However, there has been considerably less success using these models for high-dimensional learning and estimation problems. In this work, we show that, for a variety of high-dimensional learning and estimation problems, both the shuffle model and the pan-private model inherently incur an exponential price in sample complexity relative to the central model. For example, we show that, private agnostic learning of parity functions over $d$ bits requires $\\Omega(2^{d/2})$ samples in these models, and privately selecting the most common attribute from a set of $d$ choices requires $\\Omega(d^{1/2})$ samples, both of which are exponential separations from the central model. Our work gives the first non-trivial lower bounds for these problems for both the pan-private model and the general multi-message shuffle model."}}
{"id": "JmGjBBG0N-t", "cdate": 1577836800000, "mdate": null, "content": {"title": "Connecting Robust Shuffle Privacy and Pan-Privacy", "abstract": "In the \\emph{shuffle model} of differential privacy, data-holding users send randomized messages to a secure shuffler, the shuffler permutes the messages, and the resulting collection of messages must be differentially private with regard to user data. In the \\emph{pan-private} model, an algorithm processes a stream of data while maintaining an internal state that is differentially private with regard to the stream data. We give evidence connecting these two apparently different models. Our results focus on \\emph{robustly} shuffle private protocols, whose privacy guarantees are not greatly affected by malicious users. First, we give robustly shuffle private protocols and upper bounds for counting distinct elements and uniformity testing. Second, we use pan-private lower bounds to prove robustly shuffle private lower bounds for both problems. Focusing on the dependence on the domain size $k$, we find that robust approximate shuffle privacy and approximate pan-privacy have additive error $\\Theta(\\sqrt{k})$ for counting distinct elements. For uniformity testing, we give a robust approximate shuffle private protocol with sample complexity $\\tilde O(k^{2/3})$ and show that an $\\Omega(k^{2/3})$ dependence is necessary for any robust pure shuffle private tester. Finally, we show that this connection is useful in both directions: we give a pan-private adaptation of recent work on shuffle private histograms and use it to recover further separations between pan-privacy and interactive local privacy."}}
{"id": "gVcHW9Etwgu", "cdate": 1546300800000, "mdate": null, "content": {"title": "Distributed Differential Privacy via Shuffling", "abstract": ""}}
{"id": "Dv_fmSaGbyk", "cdate": 1546300800000, "mdate": null, "content": {"title": "Manipulation Attacks in Local Differential Privacy", "abstract": "Local differential privacy is a widely studied restriction on distributed algorithms that collect aggregates about sensitive user data, and is now deployed in several large systems. We initiate a systematic study of a fundamental limitation of locally differentially private protocols: they are highly vulnerable to adversarial manipulation. While any algorithm can be manipulated by adversaries who lie about their inputs, we show that any non-interactive locally differentially private protocol can be manipulated to a much greater extent. Namely, when the privacy level is high or the input domain is large, an attacker who controls a small fraction of the users in the protocol can completely obscure the distribution of the users' inputs. We also show that existing protocols differ greatly in their resistance to manipulation, even when they offer the same accuracy guarantee with honest execution. Our results suggest caution when deploying local differential privacy and reinforce the importance of efficient cryptographic techniques for emulating mechanisms from central differential privacy in distributed settings."}}
{"id": "-O07XALsN32", "cdate": 1514764800000, "mdate": null, "content": {"title": "Skyline Identification in Multi-Arm Bandits", "abstract": "We introduce a variant of the classical PAC multi-armed bandit problem. There is an ordered set of n arms A[1], \u22ef, A[n], each with some stochastic reward drawn from some unknown bounded distribution. The goal is to identify the skyline of the set A, consisting of all arms A[i] such that A[i] has larger expected reward than all lower-numbered arms A[1], \u22ef, A[i-1]. We define a natural notion of an \u03b5-approximate skyline and prove matching upper and lower bounds for identifying an \u03b5-skyline. Specifically, we show that in order to identify an \u03b5 -skyline from among arms with probability 1-\u03b4, \u0398([n/(\u03b5 <sup xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">2</sup> )]\u00b7min{log([1/(\u03b5\u03b4)]), log([n/(\u03b4)])}) samples suffice and are necessary in the -worst case. When \u03b5 \u226b 1/n, our results improve over the na\u00efve algorithm, which draws enough samples to approximate the expected reward of every arm; the algorithm of (Auer et al., AISTATS'16) for Pareto-optimal arm identification is likewise superseded. Our results show that the sample complexity of the skyline problem lies strictly in between that of best arm identification (Even-Dar et al., COLT'02) and that of approximating the expected reward of every arm. [Full version available on arXiv: arxiv.org/abs/1711.04213]."}}
