{"id": "8fEsaaf4y6n", "cdate": 1677628800000, "mdate": 1683632554826, "content": {"title": "Special Issue : Multi-Agent Dynamic Decision Making and Learning", "abstract": ""}}
{"id": "F5kTuyp8z7r", "cdate": 1675209600000, "mdate": 1683632554618, "content": {"title": "Constrained regret minimization for multi-criterion multi-armed bandits", "abstract": "We consider a stochastic multi-armed bandit setting and study the problem of constrained regret minimization over a given time horizon. Each arm is associated with an unknown, possibly multi-dimensional distribution, and the merit of an arm is determined by several, possibly conflicting attributes. The aim is to optimize a \u2018primary\u2019 attribute subject to user-provided constraints on other \u2018secondary\u2019 attributes. We assume that the attributes can be estimated using samples from the arms\u2019 distributions, and that the estimators enjoy suitable concentration properties. We propose an algorithm called Con-LCB that guarantees a logarithmic regret, i.e., the average number of plays of all non-optimal arms is at most logarithmic in the horizon. The algorithm also outputs a boolean flag that correctly identifies, with high probability, whether the given instance is feasible/infeasible with respect to the constraints. We also show that Con-LCB is optimal within a universal constant, i.e., that more sophisticated algorithms cannot do much better universally. Finally, we establish a fundamental trade-off between regret minimization and feasibility identification. Our framework finds natural applications, for instance, in financial portfolio optimization, where risk constrained maximization of expected return is meaningful."}}
{"id": "0DzyZJEKRh", "cdate": 1672531200000, "mdate": 1683632554668, "content": {"title": "On the ubiquity of duopolies in constant sum congestion games", "abstract": "We analyse a coalition formation game between strategic service providers of a congestible service. The key novelty of our formulation is that it is a constant sum game, i.e., the total payoff across all service providers (or coalitions of providers) is fixed, and dictated by the size of the market. The game thus captures the tension between resource pooling (to benefit from the resulting statistical economies of scale) and competition between coalitions over market share. In a departure from the prior literature on resource pooling for congestible services, we show that the grand coalition is in general not stable, once we allow for competition over market share. In fact, under classical notions of stability (defined via blocking by any coalition), we show that no partition is stable. This motivates us to introduce more restricted (and relevant) notions of blocking; interestingly, we find that the stable configurations under these novel notions of stability are duopolies, where the dominant coalition exploits its economies of scale to corner a disproportionate market share. Furthermore, we completely characterise the stable duopolies in heavy and light traffic regimes."}}
{"id": "praHpnidpPC", "cdate": 1640995200000, "mdate": 1683632554836, "content": {"title": "Unsupervised Crowdsourcing with Accuracy and Cost Guarantees", "abstract": "We consider the problem of cost-optimal utilization of a crowdsourcing platform for binary, unsupervised classification of a collection of items, given a prescribed error threshold. Workers on the crowdsourcing platform are assumed to be divided into multiple classes, based on their skill, experience, and/or past performance. We model each worker class via an unknown confusion matrix, and a (known) price to be paid per label prediction. For this setting, we propose algorithms for acquiring label predictions from workers, and for inferring the true labels of items. We prove that if the number of (unlabeled) items available is large enough, our algorithms satisfy the prescribed error thresholds, incurring a cost that is near-optimal. Finally, we validate our algorithms, and some heuristics inspired by them, through an extensive case study."}}
{"id": "ldyccPiOmsd", "cdate": 1640995200000, "mdate": 1683632555227, "content": {"title": "Speed Scaling with Multiple Servers under a Sum-Power Constraint", "abstract": ""}}
{"id": "i54wBCaY5c", "cdate": 1640995200000, "mdate": 1683632555092, "content": {"title": "Non-asymptotic near optimal algorithms for two sided matchings", "abstract": "A two-sided matching system is considered, where servers are assumed to arrive at a fixed rate, while the arrival rate of customers is modulated via a price-control mechanism. We analyse a loss model, wherein customers who are not served immediately upon arrival get blocked, as well as a queueing model, wherein customers wait in a queue until they receive service. The objective is to maximize the platform profit generated from matching servers and customers, subject to quality of service constraints, such as the expected wait time of servers in the loss system model, and the stability of the customer queue in the queuing model. For the loss system, subject to a certain relaxation, we show that the optimal policy has a bang-bang structure. We also derive approximation guarantees for simple pricing policies. For the queueing system, we propose a simple bimodal matching strategy and show that it achieves near optimal profit."}}
{"id": "hCTkoHRYrr", "cdate": 1640995200000, "mdate": 1683632555098, "content": {"title": "Sequential community mode estimation", "abstract": "Several applications in online learning involve sequential sampling/polling of an underlying population. A classical learning task in this space is online cardinality estimation, where the goal is to estimate the size of a set by sequential sampling of elements from the set (see, for example, [2,4,7]). The key idea here is to use 'collisions,' i.e., instances where the same element is sampled more than once, to estimate the size of the set. Another recent application is community exploration, where the goal of the learning agent is to sample as many distinct elements as possible, given a family of sampling distributions/domains to poll from (see [3, 6])."}}
{"id": "cNX_nVm7MJ", "cdate": 1640995200000, "mdate": 1683632554835, "content": {"title": "Non-asymptotic near optimal algorithms for two sided matchings", "abstract": "A two-sided matching system is considered, where servers are assumed to arrive at a fixed rate, while the arrival rate of customers is modulated via a price-control mechanism. We analyse a loss model, wherein customers who are not served immediately upon arrival get blocked, as well as a queueing model, wherein customers wait in a queue until they receive service. The objective is to maximize the platform profit generated from matching servers and customers, subject to quality of service constraints, such as the expected wait time of servers in the loss system model, and the stability of the customer queue in the queuing model. For the loss system, subject to a certain relaxation, we show that the optimal policy has a bang-bang structure. We also derive approximation guarantees for simple pricing policies. For the queueing system, we propose a simple bi-modal matching strategy and show that it achieves near optimal profit."}}
{"id": "Rc0qxRlfh7r", "cdate": 1640995200000, "mdate": 1683632554833, "content": {"title": "Statistically Robust, Risk-Averse Best Arm Identification in Multi-Armed Bandits", "abstract": "Traditional multi-armed bandit (MAB) formulations usually make certain assumptions about the underlying arms\u2019 distributions, such as bounds on the support or their tail behaviour. Moreover, such parametric information is usually \u2018baked\u2019 into the algorithms. In this paper, we show that specialized algorithms that exploit such parametric information are prone to inconsistent learning performance when the parameter is misspecified. Our key contributions are twofold: (i) We establish fundamental performance limits of <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">statistically robust</i> MAB algorithms under the fixed-budget pure exploration setting, and (ii) We propose two classes of algorithms that are asymptotically near-optimal. Additionally, we consider a risk-aware criterion for best arm identification, where the objective associated with each arm is a linear combination of the mean and the conditional value at risk (CVaR). Throughout, we make a very mild \u2018bounded moment\u2019 assumption, which lets us work with both light-tailed and heavy-tailed distributions within a unified framework."}}
{"id": "Q5eSTS3ygS", "cdate": 1640995200000, "mdate": 1683632554834, "content": {"title": "Unsupervised Crowdsourcing with Accuracy and Cost Guarantees", "abstract": "We consider the problem of cost-optimal utilization of a crowdsourcing platform for binary, unsupervised classification of a collection of items, given a prescribed error threshold. Workers on the crowdsourcing platform are assumed to be divided into multiple classes, based on their skill, experience, and/or past performance. We model each worker class via an unknown confusion matrix, and a (known) price to be paid per label prediction. For this setting, we propose algorithms for acquiring label predictions from workers, and for inferring the true labels of items. We prove that (i) our algorithms satisfy the prescribed error threshold, and (ii) if the number of (unlabeled) items available is large enough, the algorithms incur a cost that is near-optimal. Finally, we validate our algorithms, and some heuristics inspired by them, through an extensive case study."}}
