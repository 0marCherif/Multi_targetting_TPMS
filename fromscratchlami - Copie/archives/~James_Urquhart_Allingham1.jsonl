{"id": "Ff1N3et1IV", "cdate": 1664194183186, "mdate": null, "content": {"title": "Learning Generative Models with Invariance to Symmetries", "abstract": "While imbuing a model with invariance under symmetry transformations can improve data efficiency and predictive performance, most methods require specialised architectures and, thus, prior knowledge of the symmetries. Unfortunately, we don\u2019t always know what symmetries are present in the data. Recent work has solved this problem by jointly learning the invariance (or the degree of invariance) with the model from the data alone. But, this work has focused on discriminative models. We describe a method for learning invariant generative models. We demonstrate that our method can learn a generative model of handwritten digits that is invariant to rotation."}}
{"id": "220Z65e1uc3", "cdate": 1663840876341, "mdate": 1663840876341, "content": {"title": "Adapting the Linearised Laplace Model Evidence for Modern Deep Learning", "abstract": "The linearised Laplace method for estimating model uncertainty has received renewed attention in the Bayesian deep learning community. The method provides reliable error bars and admits a closed form expression for the model evidence, allowing for scalable selection of model hyperparameters. In this work, we examine the assumptions behind this method, particularly in conjunction with model selection. We show that these interact poorly with some now-standard tools of deep learning\u2014stochastic approximation methods and normalisation layers\u2014and make recommendations for how to better adapt this classic method to the modern setting. We provide theoretical support for our recommendations and validate them empirically on MLPs, classic CNNs, residual networks with and without normalisation\nlayers, generative autoencoders and transformers."}}
{"id": "uUH8x-h9zdB", "cdate": 1637576010106, "mdate": null, "content": {"title": "Linearised Laplace Inference in Networks with Normalisation Layers and the Neural g-Prior", "abstract": "We show that for neural networks (NN) with normalisation layers, i.e. batch norm, layer norm, or group norm, the Laplace model evidence does not approximate the volume of a posterior mode and is thus unsuitable for model selection. We instead propose to use the Laplace evidence of the linearized network, which is robust to the presence of these layers. We also identify heterogeneity in the scale of Jacobian entries corresponding to different weights. We ameliorate this issue by extending the scale-invariant g-prior to NNs. We demonstrate these methods on toy regression, and image classification with a CNN."}}
{"id": "0Tnl8uBHfQw", "cdate": 1632875690933, "mdate": null, "content": {"title": "Deep Classifiers with Label Noise Modeling and Distance Awareness", "abstract": "Uncertainty estimation in deep learning has recently emerged as a crucial area of interest to advance reliability and robustness in safety-critical applications. While there have been many proposed methods that either focus on distance-aware model uncertainties for out-of-distribution detection or on input-dependent label uncertainties for in-distribution calibration, both of these types of uncertainty are often necessary. In this work, we propose the HetSNGP method for jointly modeling the model and data uncertainty. We show that our proposed model affords a favorable combination between these two complementary types of uncertainty and thus outperforms the baseline methods on some challenging out-of-distribution datasets, including CIFAR-100C, Imagenet-C, and Imagenet-A. Moreover, we propose HetSNGP Ensemble, an ensembled version of our method which adds an additional type of uncertainty and also outperforms other ensemble baselines."}}
{"id": "TD-5kgf13mH", "cdate": 1632875465616, "mdate": null, "content": {"title": "Sparse MoEs meet Efficient Ensembles", "abstract": "Machine learning models based on the aggregated outputs of submodels, either at the activation or prediction levels, lead to strong performance. We study the interplay of two popular classes of such models: ensembles of neural networks and sparse mixture of experts (sparse MoEs). First, we show that these two approaches have complementary features whose combination is beneficial. Then, we present partitioned batch ensembles, an efficient ensemble of sparse MoEs that takes the best of both classes of models. Extensive experiments on fine-tuned vision transformers demonstrate the accuracy, log-likelihood, few-shot learning, robustness, and uncertainty calibration improvements of our approach over several challenging baselines. Partitioned batch ensembles not only scale to models with up to 2.7B parameters, but also provide larger performance gains for larger models. "}}
{"id": "gVi-oIwRIks", "cdate": 1632328762192, "mdate": null, "content": {"title": "Addressing Bias in Active Learning with Depth Uncertainty Networks... or Not", "abstract": "Farquhar et al. [2021] show that correcting for active learning bias with underparameterised models leads to improved downstream performance. For overparameterised models such as NNs, however, correction leads either to decreased or unchanged performance. They suggest that this is due to an \u201coverfitting bias\u201d which offsets the active learning bias. We show that depth uncertainty networks operate in a low overfitting regime, much like underparameterised models. They should therefore see an increase in performance with bias correction. Surprisingly, they do not. We propose that this negative result, as well as the results Farquhar et al. [2021], can be explained via the lens of the bias-variance decomposition of generalisation error."}}
{"id": "rCl-jqkdrgq", "cdate": 1609459200000, "mdate": 1645735827427, "content": {"title": "Bayesian Deep Learning via Subnetwork Inference", "abstract": "The Bayesian paradigm has the potential to solve core issues of deep neural networks such as poor calibration and data inefficiency. Alas, scaling Bayesian inference to large weight spaces often re..."}}
{"id": "HOW-i9JdBg9", "cdate": 1609459200000, "mdate": 1645735827509, "content": {"title": "Deep Classifiers with Label Noise Modeling and Distance Awareness", "abstract": "Uncertainty estimation in deep learning has recently emerged as a crucial area of interest to advance reliability and robustness in safety-critical applications. While there have been many proposed methods that either focus on distance-aware model uncertainties for out-of-distribution detection or on input-dependent label uncertainties for in-distribution calibration, both of these types of uncertainty are often necessary. In this work, we propose the HetSNGP method for jointly modeling the model and data uncertainty. We show that our proposed model affords a favorable combination between these two types of uncertainty and thus outperforms the baseline methods on some challenging out-of-distribution datasets, including CIFAR-100C, ImageNet-C, and ImageNet-A. Moreover, we propose HetSNGP Ensemble, an ensembled version of our method which additionally models uncertainty over the network parameters and outperforms other ensemble baselines."}}
{"id": "BKb-n9yuBg9", "cdate": 1609459200000, "mdate": 1645735827527, "content": {"title": "Addressing Bias in Active Learning with Depth Uncertainty Networks... or Not", "abstract": "Farquhar et al. [2021] show that correcting for active learning bias with underparameterised models leads to improved downstream performance. For overparameterised models such as NNs, however, correction leads either to decreased or unchanged performance. They suggest that this is due to an \"overfitting bias\" which offsets the active learning bias. We show that depth uncertainty networks operate in a low overfitting regime, much like underparameterised models. They should therefore see an increase in performance with bias correction. Surprisingly, they do not. We propose that this negative result, as well as the results Farquhar et al. [2021], can be explained via the lens of the bias-variance decomposition of generalisation error."}}
{"id": "BKUW1uwIrxc", "cdate": 1609459200000, "mdate": 1645729638793, "content": {"title": "Sparse MoEs meet Efficient Ensembles", "abstract": "Machine learning models based on the aggregated outputs of submodels, either at the activation or prediction levels, lead to strong performance. We study the interplay of two popular classes of such models: ensembles of neural networks and sparse mixture of experts (sparse MoEs). First, we show that these two approaches have complementary features whose combination is beneficial. Then, we present partitioned batch ensembles, an efficient ensemble of sparse MoEs that takes the best of both classes of models. Extensive experiments on fine-tuned vision transformers demonstrate the accuracy, log-likelihood, few-shot learning, robustness, and uncertainty calibration improvements of our approach over several challenging baselines. Partitioned batch ensembles not only scale to models with up to 2.7B parameters, but also provide larger performance gains for larger models."}}
