{"id": "NoJ3WBNUyr9", "cdate": 1681318340174, "mdate": 1681318340174, "content": {"title": "Vehicle Type Specific Waypoint Generation", "abstract": "We develop a generic mechanism for generating vehicle-type specific sequences of waypoints from a probabilistic foundation model of driving behavior. Many foundation behavior models are trained on data that does not include vehicle information, which limits their utility in downstream applications such as planning. Our novel methodology conditionally specializes such a behavior predictive model to a vehicle-type by utilizing byproducts of the reinforcement learning algorithms used to produce vehicle specific controllers. We show how to compose a vehicle specific value function estimate with a generic probabilistic behavior model to generate vehicle-type specific waypoint sequences that are more likely to be physically plausible then their vehicle-agnostic counterparts."}}
{"id": "g-qWfKQlL3", "cdate": 1663850179951, "mdate": null, "content": {"title": "Conditional Permutation Invariant Flows", "abstract": "We present a novel, conditional generative probabilistic model of set-valued data with a tractable log density.  This model is a continuous normalizing flow governed by permutation equivariant dynamics. These dynamics are driven by a learnable per-set-element term and pairwise interactions, both parametrized by deep neural networks.  We illustrate the utility of this model via applications including (1) complex traffic scene generation conditioned on visually specified map information, and (2) object bounding box generation conditioned directly on images.  We train our model by maximizing the expected likelihood of labeled conditional data under our flow, with the aid of a penalty that ensures the dynamics are smooth and hence efficiently solvable. Our method significantly outperforms non-permutation invariant baselines in terms of log likelihood and domain-specific metrics (offroad, collision, and combined infractions), yielding realistic samples that are difficult to distinguish from real data."}}
{"id": "ObtGcyKmwna", "cdate": 1663849925958, "mdate": null, "content": {"title": "Critic Sequential Monte Carlo", "abstract": "We introduce CriticSMC, a new algorithm for planning as inference built from a composition of sequential Monte Carlo with learned Soft-Q function heuristic factors. These heuristic factors, obtained from parametric approximations of the marginal likelihood ahead, more effectively guide SMC towards the desired target distribution, which is particularly helpful for planning in environments with hard constraints placed sparsely in time. Compared with previous work, we modify the placement of such heuristic factors, which allows us to cheaply propose and evaluate large numbers of putative action particles, greatly increasing inference and planning efficiency. CriticSMC is compatible with informative priors, whose density function need not be known, and can be used as a model-free control algorithm. Our experiments on collision avoidance in a high-dimensional simulated driving task show that CriticSMC significantly reduces collision rates at a low computational cost while maintaining realism and diversity of driving behaviors across vehicles and environment scenarios."}}
{"id": "r2zEpHIiqxc", "cdate": 1646077509290, "mdate": null, "content": {"title": "Probabilistic Surrogate Networks for Simulators with Unbounded Randomness", "abstract": "We present a framework for automatically structuring and training fast, approximate, deep neural surrogates of stochastic simulators. Unlike traditional approaches to surrogate modeling, our surrogates retain the interpretable structure and control flow of the reference simulator. Our surrogates target stochastic simulators where the number of random variables itself can be stochastic and potentially unbounded. Our framework further enables an automatic replacement of the reference simulator with the surrogate when undertaking amortized inference. The fidelity and speed of our surrogates allow for both faster stochastic simulation and accurate and substantially faster posterior inference. Using an illustrative yet non-trivial example we show our surrogates' ability to accurately model a probabilistic program with an unbounded number of random variables. We then proceed with an example that shows our surrogates are able to accurately model a complex structure like an unbounded stack in a program synthesis example. We further demonstrate how our surrogate modeling technique makes amortized inference in complex black-box simulators an order of magnitude faster. Specifically, we do simulator-based materials quality testing, inferring safety-critical latent internal temperature profiles of composite materials undergoing curing."}}
{"id": "M5oTlSbMe0d", "cdate": 1640995200000, "mdate": 1681494432333, "content": {"title": "Amortized Rejection Sampling in Universal Probabilistic Programming", "abstract": ""}}
{"id": "Kqoxj7_1dZ", "cdate": 1640995200000, "mdate": 1681494432407, "content": {"title": "Conditional Permutation Invariant Flows", "abstract": ""}}
{"id": "Ipo66ly_M7h", "cdate": 1640995200000, "mdate": 1681494432328, "content": {"title": "Probabilistic surrogate networks for simulators with unbounded randomness", "abstract": ""}}
{"id": "2TVKeqiCBH", "cdate": 1640995200000, "mdate": 1681494432407, "content": {"title": "Critic Sequential Monte Carlo", "abstract": ""}}
{"id": "3GlFvO5KkY", "cdate": 1620639552689, "mdate": null, "content": {"title": "Planning as Inference in Epidemiological Models", "abstract": "In this work we demonstrate how existing software tools can be used to automate parts of infectious disease-control policy-making via performing inference in existing epidemiological dynamics models. The kind of inference tasks undertaken include computing, for planning purposes, the posterior distribution over putatively controllable, via direct policy-making choices, simulation model parameters that give rise to acceptable disease progression outcomes. Neither the full capabilities of such inference automation software tools nor their utility for planning is widely disseminated at the current time. Timely gains in understanding about these tools and how they can be used may lead to more fine-grained and less economically damaging policy prescriptions, particularly during the current COVID-19 pandemic."}}
{"id": "E5V98ZfaFi", "cdate": 1620639266897, "mdate": null, "content": {"title": "Robust Asymmetric Learning in POMDPs", "abstract": "Policies for partially observed Markov decision processes can be efficiently learned by imitating expert policies generated using asymmetric information. Unfortunately, existing approaches for this kind of imitation learning have a serious flaw: the expert does not know what the trainee cannot see, and as a result, may encourage actions that are suboptimal or unsafe under partial information. To address this issue, we derive an update which, when applied iteratively to an expert, maximizes the expected reward of the trainee\u2019s policy. Using this update, we construct a computationally efficient algorithm, adaptive asymmetric DAgger (A2D), that jointly trains the expert and trainee policies. We then show that A2D allows the trainee to safely imitate the modified expert, and outperforms policies learned either by imitating a fixed expert or through direct reinforcement learning."}}
