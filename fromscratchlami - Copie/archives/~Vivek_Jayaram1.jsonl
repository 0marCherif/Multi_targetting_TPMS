{"id": "X_i8USI_OeX", "cdate": 1640995200000, "mdate": 1673555405867, "content": {"title": "ClearBuds: wireless binaural earbuds for learning-based speech enhancement", "abstract": ""}}
{"id": "S1_WNgva2Qn", "cdate": 1609459200000, "mdate": 1673555405864, "content": {"title": "Parallel and Flexible Sampling from Autoregressive Models via Langevin Dynamics", "abstract": ""}}
{"id": "tIvxILb_mEL", "cdate": 1577836800000, "mdate": null, "content": {"title": "Source Separation with Deep Generative Priors", "abstract": "Despite substantial progress in signal source separation, results for richly structured data continue to contain perceptible artifacts. In contrast, recent deep generative models can produce authen..."}}
{"id": "o--gBsWs31t", "cdate": 1577836800000, "mdate": null, "content": {"title": "The Cone of Silence: Speech Separation by Localization", "abstract": "Given a multi-microphone recording of an unknown number of speakers talking concurrently, we simultaneously localize the sources and separate the individual speakers. At the core of our method is a deep network, in the waveform domain, which isolates sources within an angular region $\\theta \\pm w/2$, given an angle of interest $\\theta$ and angular window size $w$. By exponentially decreasing $w$, we can perform a binary search to localize and separate all sources in logarithmic time. Our algorithm also allows for an arbitrary number of potentially moving speakers at test time, including more speakers than seen during training. Experiments demonstrate state of the art performance for both source separation and source localization, particularly in high levels of background noise."}}
{"id": "I1LGl8HeziH", "cdate": 1577836800000, "mdate": null, "content": {"title": "Background Matting: The World Is Your Green Screen", "abstract": "We propose a method for creating a matte - the per-pixel foreground color and alpha - of a person by taking photos or videos in an everyday setting with a handheld camera. Most existing matting methods require a green screen background or a manually created trimap to produce a good matte. Automatic, trimap-free methods are appearing, but are not of comparable quality. In our trimap free approach, we ask the user to take an additional photo of the background without the subject at the time of capture. This step requires a small amount of foresight but is far less timeconsuming than creating a trimap. We train a deep network with an adversarial loss to predict the matte. We first train a matting network with a supervised loss on ground truth data with synthetic composites. To bridge the domain gap to real imagery with no labeling, we train another matting network guided by the first network and by a discriminator that judges the quality of composites. We demonstrate results on a wide variety of photos and videos and show significant improvement over the state of the art."}}
{"id": "2vUoerJQ4p2", "cdate": 1577836800000, "mdate": null, "content": {"title": "Real-time camera pose estimation for sports fields", "abstract": "Given an image sequence featuring a portion of a sports field filmed by a moving and uncalibrated camera, such as the one of the smartphones, our goal is to compute automatically in real time the focal length and extrinsic camera parameters for each image in the sequence without using a priori knowledges of the position and orientation of the camera.To this end, we propose a novel framework that combines accurate localization and robust identification of specific keypoints in the image by using a fully convolutional deep architecture.Our algorithm exploits both the field lines and the players\u2019 image locations, assuming their ground plane positions to be given, to achieve accuracy and robustness that is beyond the current state of the art.We will demonstrate its effectiveness on challenging soccer, basketball, and volleyball benchmark datasets."}}
