{"id": "5ycxwq2VFAX", "cdate": 1663850407276, "mdate": null, "content": {"title": "DECODING LAYER SALIENCY IN TRANSFORMERS", "abstract": "In this paper, we introduce a strategy for identifying textual saliency in large-scale language models applied to classification tasks.  In visual networks where saliency is more well-studied, saliency is naturally localized through the convolutional layers of the network; however, the same is not true in modern transformer-stack networks used to process natural language.  We adapt gradient-based saliency methods for these networks, propose a method for evaluating the degree of semantic coherence of each layer, and demonstrate consistent improvement over numerous other methods for textual saliency on multiple benchmark classification datasets. Our approach requires no additional training or access to labelled data, and is comparatively very computationally efficient."}}
{"id": "hEBHTejYIr9", "cdate": 1640995200000, "mdate": 1664406089444, "content": {"title": "Hierarchical Entity Alignment for Attribute-Rich Event-Driven Graphs", "abstract": "This paper addresses the problem of entity alignment in attribute-rich event-driven graphs. Unlike many other entity alignment problems, we are interested in aligning entities based on the similarity of their actions, i.e., entities that participate in similar events are more likely to be the same. We model the generative process of this problem as a Bayesian model and derive our proposed algorithm from the posterior predictive distribution. We apply our Hierarchical Entity AlignmenT (HEAT) algorithm to two datasets, one on publications and the other on financial transactions, derived from real data and provided to us by an external collaborator."}}
{"id": "Q3a0fTx8PQr", "cdate": 1546300800000, "mdate": null, "content": {"title": "Anomaly Detection in Partially Observed Traffic Networks", "abstract": "This paper addresses the problem of detecting anomalous activity in traffic networks where the network is not directly observed. Given knowledge of what the node-to-node traffic in a network should be, any activity that differs significantly from this baseline would be considered anomalous. We propose a Bayesian hierarchical model for estimating the traffic rates and detecting anomalous changes in the network. The probabilistic nature of the model allows us to perform statistical goodness-of-fit tests to detect significant deviations from a baseline network. We show that due to the more defined structure of the hierarchical Bayesian model, such tests perform well even when the empirical models estimated by the EM algorithm are misspecified. We apply our model to both simulated and real datasets to demonstrate its superior performance over existing alternatives."}}
{"id": "zpM0z_5kUjk", "cdate": 1514764800000, "mdate": null, "content": {"title": "Latent Laplacian Maximum Entropy Discrimination for Detection of High-Utility Anomalies", "abstract": "Data-driven anomaly detection methods suffer from the drawback of detecting all instances that are statistically rare, irrespective of whether the detected instances have real-world significance or not. In this paper, we are interested in the problem of specifically detecting anomalous instances that are known to have high real-world utility, while ignoring the low-utility statistically anomalous instances. To this end, we propose a novel method called Latent Laplacian Maximum Entropy Discrimination (LatLapMED) as a potential solution. This method uses the Entropy Minimization (EM) algorithm to simultaneously incorporate the Geometric EM principle for identifying statistical anomalies, and the MED principle to incorporate utility labels, in order to detect high-utility anomalies. We apply our method in both simulated and real datasets to demonstrate that it has superior performance over existing alternatives that independently pre-process with unsupervised anomaly detection algorithms before classifying."}}
{"id": "jcE1GcTgVH", "cdate": 1514764800000, "mdate": 1664406089445, "content": {"title": "Sequential Maximum Margin Classifiers for Partially Labeled Data", "abstract": "In many real-world applications, data is not collected as one batch, but sequentially over time, and often it is not possible or desirable to wait until the data is completely gathered before analyzing it. Thus, we propose a framework to sequentially update a maximum margin classifier by taking advantage of the Maximum Entropy Discrimination principle. Our maximum margin classifier allows for a kernel representation to represent large numbers of features and can also be regularized with respect to a smooth sub-manifold, allowing it to incorporate unlabeled observations. We compare the performance of our classifier to its non-sequential equivalents in both simulated and real datasets."}}
{"id": "XZNdmv9oa2l", "cdate": 1514764800000, "mdate": 1664406089444, "content": {"title": "Sequential Maximum Margin Classifiers for Partially Labeled Data", "abstract": "In many real-world applications, data is not collected as one batch, but sequentially over time, and often it is not possible or desirable to wait until the data is completely gathered before analyzing it. Thus, we propose a framework to sequentially update a maximum margin classifier by taking advantage of the Maximum Entropy Discrimination principle. Our maximum margin classifier allows for a kernel representation to represent large numbers of features and can also be regularized with respect to a smooth sub-manifold, allowing it to incorporate unlabeled observations. We compare the performance of our classifier to its non-sequential equivalents in both simulated and real datasets."}}
{"id": "La6HmJ5_ps_a", "cdate": 1514764800000, "mdate": null, "content": {"title": "Sequential Maximum Margin Classifiers for Partially Labeled Data.", "abstract": "In many real-world applications, data is not collected as one batch, but sequentially over time, and often it is not possible or desirable to wait until the data is completely gathered before analyzing it. Thus, we propose a framework to sequentially update a maximum margin classifier by taking advantage of the Maximum Entropy Discrimination principle. Our maximum margin classifier allows for a kernel representation to represent large numbers of features and can also be regularized with respect to a smooth sub-manifold, allowing it to incorporate unlabeled observations. We compare the performance of our classifier to its non-sequential equivalents in both simulated and real datasets."}}
{"id": "zmpivLn5bSo", "cdate": 1483228800000, "mdate": null, "content": {"title": "Latent Laplacian Maximum Entropy Discrimination for Detection of High-Utility Anomalies", "abstract": "Data-driven anomaly detection methods suffer from the drawback of detecting all instances that are statistically rare, irrespective of whether the detected instances have real-world significance or not. In this paper, we are interested in the problem of specifically detecting anomalous instances that are known to have high real-world utility, while ignoring the low-utility statistically anomalous instances. To this end, we propose a novel method called Latent Laplacian Maximum Entropy Discrimination (LatLapMED) as a potential solution. This method uses the EM algorithm to simultaneously incorporate the Geometric Entropy Minimization principle for identifying statistical anomalies, and the Maximum Entropy Discrimination principle to incorporate utility labels, in order to detect high-utility anomalies. We apply our method in both simulated and real datasets to demonstrate that it has superior performance over existing alternatives that independently pre-process with unsupervised anomaly detection algorithms before classifying."}}
{"id": "oMK4D_6hh49", "cdate": 1451606400000, "mdate": null, "content": {"title": "Efficient distributed estimation of inverse covariance matrices", "abstract": "In distributed systems, communication is a major concern due to issues such as its vulnerability or efficiency. In this paper, we are interested in estimating sparse inverse covariance matrices when samples are distributed into different machines. We address communication efficiency by proposing a method where, in a single round of communication, each machine transfers a small subset of the entries of the inverse covariance matrix. We show that, with this efficient distributed method, the error rates can be comparable with estimation in a non-distributed setting, and correct model selection is still possible. Practical performance is shown through simulations."}}
