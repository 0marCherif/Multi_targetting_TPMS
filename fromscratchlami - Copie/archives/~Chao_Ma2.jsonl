{"id": "-gVJ1_lD1RH", "cdate": 1664815580530, "mdate": null, "content": {"title": "A Causal AI Suite for Decision-Making", "abstract": "Critical data science and decision-making questions across a wide variety of domains are fundamentally causal questions. We present a suite of open-source causal tools and libraries that aims to simultaneously provide core causal AI functionality to practitioners and create a platform for research advances to be rapidly deployed. In this paper, we describe our contributions towards such a comprehensive causal AI suite of tools and libraries, its design, and lessons we are learning from its growing adoption. We hope that our work accelerates use-inspired basic research for improvement of causal AI."}}
{"id": "6DPVXzjnbDK", "cdate": 1664815579658, "mdate": null, "content": {"title": "Deep End-to-end Causal Inference", "abstract": "Causal inference is essential for data-driven decision making across domains such as business engagement, medical treatment and policy making.  However, research on causal discovery has evolved separately from causal inference, preventing straightforward combination of methods from both fields. In this work, we develop Deep End-to-end Causal Inference (DECI), a non-linear additive noise model with neural network functional relationships that takes in observational data and can perform both causal discovery and inference, including conditional average treatment effect (CATE) estimation. We provide a theoretical guarantee that DECI can asymptotically recover the ground truth causal graph and treatment effects when correctly specified. Our results show the competitive performance of DECI when compared to relevant baselines for both causal discovery and (C)ATE estimation in over a thousand experiments on both synthetic datasets and causal machine learning benchmarks."}}
{"id": "RQQxCLpCVr9", "cdate": 1664815573692, "mdate": null, "content": {"title": "Causal Reasoning in the Presence of Latent Confounders via Neural ADMG Learning", "abstract": "Latent confounding has been a long-standing obstacle for causal reasoning from observational data. One popular approach is to model the data using acyclic directed mixed graphs (ADMGs), which describe ancestral relations between variables using directed and bidirected edges. However, existing methods using ADMGs are based on either linear functional assumptions or a discrete search that is complicated to use and lacks computational tractability for large datasets. In this work, we further extend the existing body of work and develop a novel gradient-based approach to learning an ADMG with nonlinear functional relations from observational data. We first show that the presence of latent confounding is identifiable under the assumptions of bow-free ADMGs with nonlinear additive noise models. With this insight, we propose a novel neural causal model based on autoregressive flows. This not only enables us to model complex causal relationships behind the data, but also estimate their functional relationships (hence treatment effects) simultaneously. We further validate our approach via experiments on both synthetic and real-world datasets, and demonstrate the competitive performance against relevant baselines."}}
{"id": "dcN0CaXQhT", "cdate": 1663850397415, "mdate": null, "content": {"title": "Causal Reasoning in the Presence of Latent Confounders via Neural ADMG Learning", "abstract": "Latent confounding has been a long-standing obstacle for causal reasoning from observational data. One popular approach is to model the data using acyclic directed mixed graphs (ADMGs), which describe ancestral relations between variables using directed and bidirected edges. However, existing methods using ADMGs are based on either linear functional assumptions or a discrete search that is complicated to use and lacks computational tractability for large datasets. In this work, we further extend the existing body of work and develop a novel gradient-based approach to learning an ADMG with nonlinear functional relations from observational data. We first show that the presence of latent confounding is identifiable under the assumptions of bow-free ADMGs with nonlinear additive noise models. With this insight, we propose a novel neural causal model based on autoregressive flows. This not only enables us to model complex causal relationships behind the data, but also estimate their functional relationships (hence treatment effects) simultaneously. We further validate our approach via experiments on both synthetic and real-world datasets, and demonstrate the competitive performance against relevant baselines."}}
{"id": "xpR25Tsem9C", "cdate": 1652737731436, "mdate": null, "content": {"title": "Missing Data Imputation and Acquisition with Deep Hierarchical Models and Hamiltonian Monte Carlo", "abstract": "Variational Autoencoders (VAEs) have recently been highly successful at imputing and acquiring heterogeneous missing data. However, within this specific application domain, existing VAE methods are restricted by using only one layer of latent variables and strictly Gaussian posterior approximations. To address these limitations, we present HH-VAEM, a Hierarchical VAE model for mixed-type incomplete data that uses Hamiltonian Monte Carlo with automatic hyper-parameter tuning for improved approximate inference. Our experiments show that HH-VAEM outperforms existing baselines in the tasks of missing data imputation and supervised learning with missing features. Finally, we also present a sampling-based approach for efficiently computing the information gain when missing features are to be acquired with HH-VAEM. Our experiments show that this sampling-based approach is superior to alternatives based on Gaussian approximations."}}
{"id": "KLILoGYuOfw", "cdate": 1621630050565, "mdate": null, "content": {"title": "Functional Variational Inference based on Stochastic Process Generators", "abstract": "Bayesian inference in the space of functions has been an important topic for Bayesian modeling in the past. In this paper, we propose a new solution to this problem called Functional Variational Inference (FVI). In FVI, we minimize a divergence in function space between the variational distribution and the posterior process. This is done by using as functional variational family a new class of flexible distributions called Stochastic Process Generators (SPGs), which are cleverly designed so that the functional ELBO can be estimated efficiently using analytic solutions and mini-batch sampling. FVI can be applied to stochastic process priors when random function samples from those priors are available. Our experiments show that FVI consistently outperforms weight-space and function space VI methods on several tasks, which validates the effectiveness of our approach."}}
{"id": "bGXIX-CVzrq", "cdate": 1621629855393, "mdate": null, "content": {"title": "Identifiable Generative models for Missing Not at Random Data Imputation", "abstract": "Real-world datasets often have missing values associated with complex generative processes, where the cause of the missingness may not be fully observed. This is known as missing not at random (MNAR) data. However, many imputation methods do not take into account the missingness mechanism, resulting in biased imputation values when MNAR data is present. Although there are a few methods that have considered the MNAR scenario, their model's identifiability under MNAR is generally not guaranteed. That is, model parameters can not be uniquely determined even with infinite data samples, hence the imputation results given by such models can still be biased. This issue is especially overlooked by many modern deep generative models. In this work, we fill in this gap by systematically analyzing the identifiability of generative models under MNAR. Furthermore, we propose a practical deep generative model which can provide identifiability guarantees under mild assumptions, for a wide range of MNAR mechanisms. Our method demonstrates a clear advantage for tasks on both synthetic data and multiple real-world scenarios with MNAR data. "}}
{"id": "JZ-6j-siNBj", "cdate": 1591832461878, "mdate": null, "content": {"title": "VAEM: a Deep Generative Model for Heterogeneous Mixed Type Data", "abstract": "Missing data imputation methods based on deep generative models often perform poorly in real-world applications, due to the heterogeneity of natural data sets. Heterogeneity arises from data containing different types of features (categorical, ordinal, continuous, etc.) and  features of the same type having different marginal distributions.  We propose an extension of variational autoencoders (VAEs) called VAEM to\nhandle such heterogeneous data. We develop a corresponding efficient inference method, provide extensions, and demonstrate the performance of VAEM in missing data imputation tasks. Our results show that VAEM broadens the range of real-world applications where deep generative models can be successfully deployed. "}}
{"id": "S1eb5J2VKS", "cdate": 1571237768708, "mdate": null, "content": {"title": "HM-VAEs: a Deep Generative Model for Real-valued Data with Heterogeneous Marginals", "abstract": "In this paper, we focused on improving VAEs for real-valued data that has heterogeneous marginal distributions. We propose the heterogeneous-marginal VAE (HM-VAE), a method that explicitly decomposes intra-variable uncertainties  and inter-variable uncertainties. We experimentally observe that the HM-VAEs can generate realistic data with nearly indistinguishable marginals when compared with real data. "}}
{"id": "HJl0jiRqtX", "cdate": 1538087845581, "mdate": null, "content": {"title": "EDDI: Efficient Dynamic Discovery of High-Value Information with Partial VAE", "abstract": "Making decisions requires information relevant to the task at hand. Many real-life decision-making situations allow acquiring further relevant information at a specific cost. For example, in assessing the health status of a patient we may decide to take additional measurements such as diagnostic tests or imaging scans before making a final assessment. More information that is relevant allows for better decisions but it may be costly to acquire all of this information.  How can we trade off the desire to make good decisions with the option to acquire further information at a cost? To this end, we propose a principled framework, named EDDI (Efficient Dynamic Discovery of high-value Information), based on the theory of Bayesian experimental design. In EDDI we propose a novel partial variational autoencoder (Partial VAE), to efficiently handle missing data over varying subsets of known information. EDDI combines this Partial VAE with an acquisition function that maximizes expected information gain on a set of target variables. EDDI is efficient and demonstrates that dynamic discovery of high-value information is possible; we show cost reduction at the same decision quality and improved decision quality at the same cost in benchmarks and in two health-care applications.. We believe there is great potential for realizing these gains in real-world decision support systems."}}
