{"id": "XB18ZiMa_M", "cdate": 1672531200000, "mdate": 1682936055709, "content": {"title": "Lazy Node-Dropping Autoencoder", "abstract": "Autoencoders are widely used for dimensionality reduction nonlinearly. However, determining the number of nodes in the autoencoder embedding space is still a challenging task. The number of nodes in the bottleneck layer, which is an encoded representation, is estimated and determined by users. Therefore, to maintain embedding performance and reduce the complexity of the model, an indicator that automatically selects the number of bottleneck nodes is needed. This study proposes a method for automatically estimating the adequate number of nodes in the bottleneck layer while training the model. The basic idea of the proposed method is to eliminate lazy nodes which rarely affect the model performance based on the weight distribution of the bottleneck layer. Since the proposed method takes place in the learning process of the autoencoder, it has the advantage of accelerating the training speed. The proposed method showed better or similar performances in classification accuracy."}}
{"id": "VWzvG1_rwCB", "cdate": 1672531200000, "mdate": 1682936055688, "content": {"title": "Fast Integration for Multiple Graphs with Neumann Approximation", "abstract": "Graph-based models have gained much interest in the domain of machine learning as they offer the advantage of handling data that reside on complex structures. From various models that encounter graph-structured data, graph-based semi-supervised learning (SSL) have shown successful results in multiple applications. The key idea behind SSL is the spreading process of labels through the edges and the problem boils down to keeping the graph Laplacian intact. Meanwhile, with the rapid growth in availability of data, there exist multiple descriptions of graphs for the same set of data points. Each graph contains complementary information to one another, and it would be beneficial to integrate all the available information. In this paper, we propose an SSL-based fast graph integration method that employs approximation in the maximum likelihood estimation process of finding the combination. The proposed approximation utilizes the connection between the covariance and its Neumann series, which allows us to avoid explicit matrix inversion. Empirically, the proposed method achieved competitive performance with significant improvements in computational time when compared to other method."}}
{"id": "KLu4AqJ9t-n", "cdate": 1672531200000, "mdate": 1682936055695, "content": {"title": "Fast Prediction for Suspect Candidates from Criminal Networks", "abstract": "Machine learning approaches have been introduced to support criminal investigations in recent years. In criminal investigations, Criminal acts may be similar, and similar incidents may occur consecutively by the same offender or by the same criminal group. Among the various machine learning algorithms, network-based algorithms will be suitable to reflect such associations. In general, however, inference by network-based algorithms is slow when the size of data is large, so it is fatal in crime scenes that require urgency. And worse, the criminal network must be able to handle complex information entangled with case-to-case, person-to-person, and case-to-person connections. In this study, we propose a fast inference algorithm for a large-scale criminal network. The network we designed has a unique structure like a sandwich panel, where one side is a network of crime cases and the other side is a network of people such as victims, criminals, witnesses, etc., and the two networks are connected by relationships between the case and its corresponding people. The experimental results on benchmark data showed that the proposed algorithm has fast inference time and competitive performance compared to the existing approaches. After performance validation, the proposed method was applied to the actual crime data provided by the Korean National Police to predict the suspect candidates for several cases."}}
{"id": "pkYsQPhbFzC", "cdate": 1640995200000, "mdate": 1682935957562, "content": {"title": "Learning Neural Networks without Lazy Weights", "abstract": "Various approaches have been suggested for the regularization of neural networks, including the well-known Dropout and Dropconnect, which are simple and efficient to implement and therefore have been widely used. However, there is a risk of loss of well-trained weights when dropping nodes or weights randomly. In this paper, we propose a regularization method that preserves well-trained weights and removes poorly trained weights. This was motivated by the observation that the trained weights become further trained. We define these as eager weights whereas the opposite as lazy weights. On every weight update, the distribution of the changes in weight values is examined, and the lazy weights are removed layer-wise. The results demonstrate that the proposed method has a faster convergence rate, avoids overfitting, and outperforms competing methods on the classification of benchmark datasets."}}
{"id": "mdxJBUR9Lsh", "cdate": 1640995200000, "mdate": 1682935957610, "content": {"title": "Drug Repositioning with Disease-Drug Clusters from Word Representations", "abstract": "With the advent of easy access to a tremendous amount of text data, various studies utilizing text mining have been conducted in the biomedical field. However, most are only concerned with retrieving information solely from the perspective of either diseases or drugs. Extending from such boundary, we propose an approach of embedding disease and drugs from biomedical literature, determining direct relationships between them, and identifying possibilities of drug repositioning. To embed both disease and drugs, we utilize the word2vec algorithm and generate embedded word vectors for each disease and drug. Then hierarchical clustering with Ward's method is applied for categorization. Moreover, we suggest an evaluation measure that compares clusters from the text data with results from the molecular biology level. The proposed method was applied to 17,606,652 MEDLINE abstracts and extracted 4,163 diseases and 3,930 drugs. By examining heterogeneous clusters in which both disease and drug exist, nine candidate drugs were deduced for each disease in combination with 79 diseases and 84 drugs. The results are expected to serve as a baseline for the preliminary selection of candidate drugs for drug repositioning."}}
{"id": "g_yRYsCdse", "cdate": 1640995200000, "mdate": 1682935957556, "content": {"title": "Semi-supervised network regression with Gaussian process", "abstract": "In recent years, there has been a rapid growth in interest of using network-based machine learning. They offer the capacity to handle data that exist on irregular and complex structures with interactions between data points. In this paper, we present a semi-supervised regression model utilizing network-based Gaussian process. The proposed method constructs a Gaussian process prior using information from a given network. However, it incurs high computational costs from the required inversions to produce the predictive output and model selection. To overcome the difficulty, we further propose an approximated version that avoids matrix inversion. The proposed method was applied to several regression problems to validate the empirical performance and effectiveness in situations with limited amount of labeled data."}}
{"id": "NlGw12gQlMM", "cdate": 1640995200000, "mdate": 1682935957607, "content": {"title": "Brain Volume Prediction from SNP network with Semi-Supervised Regression", "abstract": "The gray matter volume of the brain is used as one of the important indicators to evaluate cognitive function. That is, the smaller the gray matter volume in the region of memory, the lower the cognitive function. Although there are several factors in the reduction of gray matter volume, it has been found that genetic factors also play a role through numerous recent studies. Genetic factors can involve in biological activities not only independently, but also collectively with complex interactions. In this study, we propose a method for predicting brain volume and deriving significant genetic variants from single-nucleotide polymorphisms (SNP) network that reflects the interactions between SNPs. The proposed method constructs a linear regression model to predict brain volume using refined SNP features obtained through feature propagation on the SNP network. The prediction model was applied to biobank innovations for chronic cerebrovascular disease with Alzheimer's disease study (BICWALZS) participants in Ajou University Hospital, Korea."}}
{"id": "Dgp1Ra6S8V", "cdate": 1640995200000, "mdate": 1682935957611, "content": {"title": "Latent Feature Separation and Extraction with Multiple Parallel Encoders for Convolutional Autoencoder", "abstract": "Much of the real-world image data is unlabeled or mislabeled. Therefore, even if there is no label, if similar images can be grouped together with image data itself and used the group as a label, more image data can be effectively used in various tasks. This will be especially effective when dividing images belonging to the same domain into sub-groups. Therefore, in this study, we propose an image feature extraction method to be used for image clustering. The proposed feature extraction model is the Multi-head Convolutional Autoencoder (MCAE), which is a model composed of multiple encoders in parallel based on the Convolutional Autoencoder (CAE). The proposed model showed about 14% lower test reconstruction loss compared to CAE, and the correlation coefficient between extracted features was about 56% lower. In addition, as the results of clustering based on the extracted features, MCAE-based clustering showed about 3.5 times higher silhouette score than that CAE-based clustering."}}
{"id": "HDAUePYTv2", "cdate": 1577836800000, "mdate": 1682935957583, "content": {"title": "Inference on historical factions based on multi-layered network of historical figures", "abstract": ""}}
{"id": "xAtrgjIBoFR", "cdate": 1546300800000, "mdate": 1682935957621, "content": {"title": "Semi-supervised learning for hierarchically structured networks", "abstract": ""}}
