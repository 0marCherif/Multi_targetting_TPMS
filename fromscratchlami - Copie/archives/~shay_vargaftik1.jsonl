{"id": "n12Bi-Nk7q", "cdate": 1672531200000, "mdate": 1680001494544, "content": {"title": "DoCoFL: Downlink Compression for Cross-Device Federated Learning", "abstract": ""}}
{"id": "HrlLY2qnDZ", "cdate": 1672531200000, "mdate": 1680001494541, "content": {"title": "THC: Accelerating Distributed Deep Learning Using Tensor Homomorphic Compression", "abstract": ""}}
{"id": "04OL67rm6ok", "cdate": 1663850297127, "mdate": null, "content": {"title": "QUIC-FL: : Quick Unbiased Compression for Federated Learning", "abstract": "Distributed Mean Estimation (DME) is a fundamental building block in communication efficient federated learning. In DME, clients communicate their lossily compressed gradients to the parameter server, which estimates the average and updates the model. \nState of the art DME techniques apply either unbiased quantization methods, resulting in large estimation errors, or biased quantization methods, where unbiasing the result requires that the server decodes each gradient individually, which markedly slows the aggregation time.\nIn this paper, we propose QUIC-FL, a DME algorithm that achieves the best of all worlds. QUIC-FL is unbiased, offers fast aggregation time, and is competitive with the most accurate (slow aggregation) DME techniques. To achieve this, we formalize the problem in a novel way that allows us to use standard solvers to design near-optimal unbiased quantization schemes."}}
{"id": "lmxXKjSj7T", "cdate": 1640995200000, "mdate": 1674492437042, "content": {"title": "Memento: Making Sliding Windows Efficient for Heavy Hitters", "abstract": "Cloud operators require timely identification of Heavy Hitters (HH) and Hierarchical Heavy Hitters (HHH) for applications such as load balancing, traffic engineering, and attack mitigation. However, existing techniques are slow in detecting new heavy hitters. In this paper, we present the case for identifying heavy hitters through <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">sliding windows</i> . Sliding windows are quicker and more accurate to detect new heavy hitters than current interval-based methods, but to date had no practical algorithms. Accordingly, we introduce, design, and analyze the <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">Memento</i> family of sliding window algorithms for the HH and HHH problems in the single-device and network-wide settings. We use extensive evaluations to show that our single-device solutions are orders of magnitude faster than existing sliding window techniques and comparable in speed to state-of-the-art non-windowed sampling based technique. Furthermore, we exemplify our network-wide HHH detection capabilities on a realistic testbed. To that end, we implemented Memento as an open-source extension to the popular HAProxy cloud load-balancer. In our evaluations, using an HTTP flood by 50 subnets, our network-wide approach detected the new subnets faster and reduced the number of undetected flood requests by up to <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"> <tex-math notation=\"LaTeX\">$37\\times $ </tex-math></inline-formula> compared to the alternatives."}}
{"id": "lTmJ1iAtM2i", "cdate": 1640995200000, "mdate": 1674492437056, "content": {"title": "EDEN: Communication-Efficient and Robust Distributed Mean Estimation for Federated Learning", "abstract": "Distributed Mean Estimation (DME) is a central building block in federated learning, where clients send local gradients to a parameter server for averaging and updating the model. Due to communicat..."}}
{"id": "XczwXALXob", "cdate": 1640995200000, "mdate": 1680001494539, "content": {"title": "Automating In-Network Machine Learning", "abstract": ""}}
{"id": "N_BBAxHb-Li", "cdate": 1640995200000, "mdate": 1675683647144, "content": {"title": "ScionFL: Secure Quantized Aggregation for Federated Learning", "abstract": "Secure aggregation is commonly used in federated learning (FL) to alleviate privacy concerns related to the central aggregator seeing all parameter updates in the clear. Unfortunately, most existing secure aggregation schemes ignore two critical orthogonal research directions that aim to (i) significantly reduce client-server communication and (ii) mitigate the impact of malicious clients. However, both of these additional properties are essential to facilitate cross-device FL with thousands or even millions of (mobile) participants. In this paper, we unite both research directions by introducing ScionFL, the first secure aggregation framework for FL that operates efficiently on quantized inputs and simultaneously provides robustness against malicious clients. Our framework leverages (novel) multi-party computation (MPC) techniques and supports multiple linear (1-bit) quantization schemes, including ones that utilize the randomized Hadamard transform and Kashin's representation. Our theoretical results are supported by extensive evaluations. We show that with no overhead for clients and moderate overhead on the server side compared to transferring and processing quantized updates in plaintext, we obtain comparable accuracy for standard FL benchmarks. Additionally, we demonstrate the robustness of our framework against state-of-the-art poisoning attacks."}}
{"id": "Dv3lbV4FDgu", "cdate": 1640995200000, "mdate": 1680001494485, "content": {"title": "Efficient multiclass classification with duet", "abstract": ""}}
{"id": "7SV18WTWQ9", "cdate": 1640995200000, "mdate": 1674492437045, "content": {"title": "QUIC-FL: Quick Unbiased Compression for Federated Learning", "abstract": "Distributed Mean Estimation (DME), in which $n$ clients communicate vectors to a parameter server that estimates their average, is a fundamental building block in communication-efficient federated learning. In this paper, we improve on previous DME techniques that achieve the optimal $O(1/n)$ Normalized Mean Squared Error (NMSE) guarantee by asymptotically improving the complexity for either encoding or decoding (or both). To achieve this, we formalize the problem in a novel way that allows us to use off-the-shelf mathematical solvers to design the quantization."}}
{"id": "2HD1PiBGLd", "cdate": 1640995200000, "mdate": 1680001494554, "content": {"title": "IIsy: Practical In-Network Classification", "abstract": ""}}
