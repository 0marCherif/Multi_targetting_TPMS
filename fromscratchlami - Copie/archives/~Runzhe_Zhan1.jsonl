{"id": "G03ZNYC36Dk", "cdate": 1691396562019, "mdate": 1691396562019, "content": {"title": "TransGEC: Improving Grammatical Error Correction with Translationese", "abstract": "Data augmentation is an effective way to improve model performance of grammatical error correction (GEC). This paper identifies a critical side-effect of GEC data augmentation, which is due to the style discrepancy between the data used in GEC tasks (i.e., texts produced by non-native speakers) and data augmentation (i.e., native texts). To alleviate this issue, we propose to use an alternative data source, translationese (i.e., human-translated texts), as input for GEC data augmentation, which 1) is easier to obtain and usually has better quality than non-native texts, and 2) has a more similar style to non-native texts. Experimental results on the CoNLL14 and BEA19 English, NLPCC18 Chinese, Falko-MERLIN German, and RULEC-GEC Russian GEC benchmarks show that our approach consistently improves correction accuracy over strong baselines. Further analyses reveal that our approach is helpful for overcoming mainstream correction difficulties such as the corrections of frequent words, missing words, and substitution errors. "}}
{"id": "p89lphTyrEv", "cdate": 1672531200000, "mdate": 1689377618145, "content": {"title": "Test-time Adaptation for Machine Translation Evaluation by Uncertainty Minimization", "abstract": ""}}
{"id": "hUWn0yGtuZ", "cdate": 1672531200000, "mdate": 1689377618144, "content": {"title": "Revisiting Commonsense Reasoning in Machine Translation: Training, Evaluation and Challenge", "abstract": ""}}
{"id": "_eiqtT4xXpS", "cdate": 1672531200000, "mdate": 1689377618145, "content": {"title": "Obscurity-Quantified Curriculum Learning for Machine Translation Evaluation", "abstract": "The pre-trained language model has been developed for evaluating the quality of machine translation. It achieves state-of-the-art results. However, building a model for the evaluation of machine translation still faces the following challenges: 1) large scale of the training data affects the speed of the optimization; 2) the varied quality of the training data makes the optimization process unstable. To alleviate the issues of data learning, curriculum learning is proposed to rearrange the training sequence following an \u201ceasy-to-hard\u201d process. However, the definition of difficulty can not be directly applied to the training data used in the machine translation evaluation. Hence, we propose an obscurity-quantified curriculum learning framework for this task. Specifically, the obscurity of each training example can be measured from multiple perspectives, including the <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">difficulty of ranking</i> , the <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">fuzziness of reference</i> , the <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">complexity of text</i> , and the <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">unreliability of judgement</i> . To incorporate the obscurity measurements, we also design a dynamic learning strategy to guide the training process from instances with low obscurity to those with high-obscurity. Experimental results show that our proposed methods yield remarkable improvements on the segment-level WMT2019 and WMT2020 Metrics Shared Tasks compared to other baseline methods."}}
{"id": "ZVynl8sCHh", "cdate": 1672531200000, "mdate": 1689377618144, "content": {"title": "TransGEC: Improving Grammatical Error Correction with Translationese", "abstract": ""}}
{"id": "5TpwJf1pgZ", "cdate": 1672531200000, "mdate": 1684670811598, "content": {"title": "Yu Sheng: Human-in-Loop Classical Chinese Poetry Generation System", "abstract": ""}}
{"id": "hhKA5k0oVy5", "cdate": 1623153015643, "mdate": null, "content": {"title": "Variance-Aware Machine Translation Test Sets", "abstract": "We release 70 small and discriminative test sets for machine translation (MT) evaluation called variance-aware test sets (VAT), covering 35 translation directions from WMT16 to WMT20 competitions. VAT is automatically created by a novel variance-aware filtering method that filters the indiscriminative test instances of the current MT benchmark without any human labor. Experimental results show that VAT outperforms the original WMT benchmark in terms of the correlation with human judgment across mainstream language pairs and test sets. Further analysis on the properties of VAT reveals the challenging linguistic features (e.g., translation of low-frequency words and proper nouns) for the competitive MT systems, providing guidance for constructing future MT test sets. The test sets and the code for preparing variance-aware MT test sets are freely available at https://github.com/NLP2CT/Variance-Aware-MT-Test-Sets."}}
{"id": "rBhSqWnvd_v", "cdate": 1609459200000, "mdate": 1628516413375, "content": {"title": "Difficulty-Aware Machine Translation Evaluation", "abstract": "Runzhe Zhan, Xuebo Liu, Derek F. Wong, Lidia S. Chao. Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers). 2021."}}
{"id": "ETFyyQ_IKT1", "cdate": 1609459200000, "mdate": 1681650274653, "content": {"title": "Variance-Aware Machine Translation Test Sets", "abstract": ""}}
{"id": "-oXVbIEqnC-", "cdate": 1609459200000, "mdate": 1635864317915, "content": {"title": "Meta-Curriculum Learning for Domain Adaptation in Neural Machine Translation", "abstract": "Meta-learning has been sufficiently validated to be beneficial for low-resource neural machine translation (NMT). However, we find that meta-trained NMT fails to improve the translation performance of the domain unseen at the meta-training stage. In this paper, we aim to alleviate this issue by proposing a novel meta-curriculum learning for domain adaptation in NMT. During meta-training, the NMT first learns the similar curricula from each domain to avoid falling into a bad local optimum early, and finally learns the curricula of individualities to improve the model robustness for learning domain-specific knowledge. Experimental results on 10 different low-resource domains show that meta-curriculum learning can improve the translation performance of both familiar and unfamiliar domains. All the codes and data are freely available at https://github.com/NLP2CT/Meta-Curriculum."}}
