{"id": "4UhmnBhns80", "cdate": 1677628800000, "mdate": 1683893101299, "content": {"title": "Does big data serve policy? Not without context. An experiment with in silico social science", "abstract": "The DARPA Ground Truth project sought to evaluate social science by constructing four varied simulated social worlds with hidden causality and unleashed teams of scientists to collect data, discover their causal structure, predict their future, and prescribe policies to create desired outcomes. This large-scale, long-term experiment of in silico social science, about which the ground truth of simulated worlds was known, but not by us, reveals the limits of contemporary quantitative social science methodology. First, problem solving without a shared ontology\u2014in which many world characteristics remain existentially uncertain\u2014poses strong limits to quantitative analysis even when scientists share a common task, and suggests how they could become insurmountable without it. Second, data labels biased the associations our analysts made and assumptions they employed, often away from the simulated causal processes those labels signified, suggesting limits on the degree to which analytic concepts developed in one domain may port to others. Third, the current standard for computational social science publication is a demonstration of novel causes, but this limits the relevance of models to solve problems and propose policies that benefit from the simpler and less surprising answers associated with most important causes, or the combination of all causes. Fourth, most singular quantitative methods applied on their own did not help to solve most analytical challenges, and we explored a range of established and emerging methods, including probabilistic programming, deep neural networks, systems of predictive probabilistic finite state machines, and more to achieve plausible solutions. However, despite these limitations common to the current practice of computational social science, we find on the positive side that even imperfect knowledge can be sufficient to identify robust prediction if a more pluralistic approach is applied. Applying competing approaches by distinct subteams, including at one point the vast TopCoder.com global community of problem solvers, enabled discovery of many aspects of the relevant structure underlying worlds that singular methods could not. Together, these lessons suggest how different a policy-oriented computational social science would be than the computational social science we have inherited. Computational social science that serves policy would need to endure more failure, sustain more diversity, maintain more uncertainty, and allow for more complexity than current institutions support."}}
{"id": "nYOlSqq9nv2", "cdate": 1663850158471, "mdate": null, "content": {"title": "Learning Intuitive Policies Using Action Features", "abstract": "An unaddressed challenge in multi-agent coordination is to enable AI agents to exploit the semantic relationships between the features of actions and the features of observations. Humans take advantage of these relationships in highly intuitive ways. For instance, in the absence of a shared language, we might point to the object we desire or hold up our fingers to indicate how many objects we want. To address this challenge, we investigate the effect of network architecture on the propensity of learning algorithms to exploit these semantic relationships. Across a procedurally generated coordination task, we find that attention-based architectures that jointly process a featurized representation of observations and actions have a better inductive bias for zero-shot coordination. Through fine-grained evaluation and scenario analysis, we show that the resulting policies are human-interpretable. Moreover, such agents coordinate with people without training on any human data. "}}
{"id": "y_2oNLw7iE8", "cdate": 1640995200000, "mdate": 1682348335345, "content": {"title": "When Is It Acceptable to Break the Rules? Knowledge Representation of Moral Judgement Based on Empirical Data", "abstract": "One of the most remarkable things about the human moral mind is its flexibility. We can make moral judgments about cases we have never seen before. We can decide that pre-established rules should be broken. We can invent novel rules on the fly. Capturing this flexibility is one of the central challenges in developing AI systems that can interpret and produce human-like moral judgment. This paper details the results of a study of real-world decision makers who judge whether it is acceptable to break a well-established norm: ``no cutting in line.'' We gather data on how human participants judge the acceptability of line-cutting in a range of scenarios. Then, in order to effectively embed these reasoning capabilities into a machine, we propose a method for modeling them using a preference-based structure, which captures a novel modification to standard ``dual process'' theories of moral judgment."}}
{"id": "yEYeozbsRid", "cdate": 1640995200000, "mdate": 1682348335114, "content": {"title": "Too Many cooks: Bayesian inference for coordinating Multi-agent Collaboration", "abstract": ""}}
{"id": "9Ot2QW0dNX1", "cdate": 1640995200000, "mdate": 1682083083383, "content": {"title": "Learning to Coordinate with Humans using Action Features", "abstract": "An unaddressed challenge in multi-agent coordination is to enable AI agents to exploit the semantic relationships between the features of actions and the features of observations. Humans take advantage of these relationships in highly intuitive ways. For instance, in the absence of a shared language, we might point to the object we desire or hold up our fingers to indicate how many objects we want. To address this challenge, we investigate the effect of network architecture on the propensity of learning algorithms to exploit these semantic relationships. Across a procedurally generated coordination task, we find that attention-based architectures that jointly process a featurized representation of observations and actions have a better inductive bias for learning intuitive policies. Through fine-grained evaluation and scenario analysis, we show that the resulting policies are human-interpretable. Moreover, such agents coordinate with people without training on any human data."}}
{"id": "j97zf-nLhC", "cdate": 1632875719683, "mdate": null, "content": {"title": "Zero-Shot Coordination via Semantic Relationships Between Actions and Observations", "abstract": "An unaddressed challenge in zero-shot coordination is to take advantage of the semantic relationship between the features of an action and the features of observations. Humans take advantage of these relationships in highly intuitive ways. For instance in the absence of a shared-language, we might point to the object we desire or hold up fingers to indicate how many objects we want. To address this challenge, we investigate the effect of network architecture on the propensity of learning algorithms to make use of these relationships in human-compatible ways. We find that attention-based architectures that jointly process a featurized representation of the observation and the action, have a better inductive bias for exploiting semantic relationships for zero-shot coordination. Excitingly, in a set of diagnostic tasks, these agents produce highly human-compatible policies, without requiring the symmetry relationships of the problems to be hard-coded."}}
{"id": "eREayMFQfyA", "cdate": 1624121978448, "mdate": 1624121978448, "content": {"title": "Too many cooks: Bayesian inference for coordinating multi-agent collaboration", "abstract": "Collaboration requires agents to coordinate their behavior on the fly, sometimes cooperating to solve a single task together and other times dividing it up into sub-tasks to work on in parallel. Underlying the human ability to collaborate is theory-of-mind, the ability to infer the hidden mental states that drive others to act. Here, we develop Bayesian Delegation, a decentralized multi-agent learning mechanism with these abilities. Bayesian Delegation enables agents to rapidly infer the hidden intentions of others by inverse planning. We test Bayesian Delegation in a suite of multi-agent Markov decision processes inspired by cooking problems. On these tasks, agents with Bayesian Delegation coordinate both their high-level plans (e.g. what sub-task they should work on) and their low-level actions (e.g. avoiding getting in each other's way). In a self-play evaluation, Bayesian Delegation outperforms alternative algorithms. Bayesian Delegation is also a capable ad-hoc collaborator and successfully coordinates with other agent types even in the absence of prior experience. Finally, in a behavioral experiment, we show that Bayesian Delegation makes inferences similar to human observers about the intent of others. Together, these results demonstrate the power of Bayesian Delegation for decentralized multi-agent collaboration.\n"}}
{"id": "X1f2YOCKL9V", "cdate": 1609459200000, "mdate": 1682348335631, "content": {"title": "Modeling Communication to Coordinate Perspectives in Cooperation", "abstract": "Communication is highly overloaded. Despite this, even young children are good at leveraging context to understand ambiguous signals. We propose a computational account of overloaded signaling from a shared agency perspective which we call the Imagined We for Communication. Under this framework, communication helps cooperators coordinate their perspectives, allowing them to act together to achieve shared goals. We assume agents are rational cooperators, which puts constraints on how signals can be sent and interpreted. We implement this model in a set of simulations demonstrating this model's success under increasing ambiguity as well as increasing layers of reasoning. Our model is capable of improving performance with deeper recursive reasoning; however, it outperforms comparison baselines at even the shallowest level, highlighting how shared knowledge and cooperative logic can do much of the heavy-lifting in language."}}
{"id": "P0yJwRziBzX", "cdate": 1609459200000, "mdate": 1682348335181, "content": {"title": "Too Many Cooks: Bayesian Inference for Coordinating Multi-Agent Collaboration", "abstract": "We develop Bayesian Delegation, a model of multi-agent learning that integrates Bayesian theory-of-mind, joint intentions, and the ability to divide-and-conquer. Bayesian Delegation enables ad-hoc co..."}}
{"id": "yYs_UjAmFwR", "cdate": 1577836800000, "mdate": null, "content": {"title": "Too Many Cooks: Coordinating Multi-agent Collaboration Through Inverse Planning", "abstract": "Humans collaborate in dynamic and flexible ways. Collaboration requires agents to coordinate their behavior on the fly, sometimes jointly solving a single task together and other times dividing it up into sub-tasks to work on in parallel. We develop Bayesian Delegation, a learning mechanism for decentralized multi-agent coordination that enables agents to rapidly infer the sub-tasks that other agents are working on by inverse planning. These inferences enable agents to determine, in the absence of communication, whether to plan jointly with others or work on complementary sub-tasks. We test this model in a suite of decentralized multi-agent environments inspired by cooking problems. To succeed, agents must coordinate both their high-level plans (sub-task) and their low-level actions (avoiding collisions). Including joint sub-tasks in the prior of Bayesian delegation enables agents to carry out sub-tasks that neither agent can finish independently. The full system outperforms lesioned systems that are missing one or more of these capabilities."}}
