{"id": "I7re8kimlq-", "cdate": 1640995200000, "mdate": 1668619829582, "content": {"title": "A New Fuzzy H\u221e Filter Design for Nonlinear Time-Delay Systems with Mismatched Premise Membership Functions", "abstract": "This paper is concerned with the fuzzy $H_{\\infty}$ filter design issue for nonlinear systems with time-varying delay. To overcome the shortcomings of the conventional methods with matched preconditions, the fuzzy $H_{\\infty}$ filter to be designed and the T-S fuzzy model are assumed to have different premise membership functions and number of rules, thus, greater design flexibility and robustness to uncertainty can be achieved. However, such design will also make the derived results conservative, to relax the result, a novel integral inequality which is tighter than the traditional inequalities derived from the Leibniz-Newton formula is applied, besides, a fuzzy Lypunov function and the information of the membership functions are also introduced. All the design methods are presented in LMI-based conditions. Finally, two numerical examples are given to prove the effectiveness and superiority of the proposed approach."}}
{"id": "DX9eAXSBNf", "cdate": 1640995200000, "mdate": 1668619829606, "content": {"title": "Improved Fuzzy H\u221e Filter Design Method for Nonlinear Systems with Time-Varing Delay", "abstract": "This paper investigates the fuzzy $H_{\\infty}$ filter design issue for nonlinear systems with time-varying delay. In order to obtain less conservative fuzzy $H_{\\infty}$ filter design method, a novel integral inequality is employed to replace the conventional Lebniz-Newton formula to analyze the stability conditions of the filtering error system. Besides, the information of the membership functions is introduced in the criterion to further relax the derived results. The proposed delay dependent filter design method is presented as LMI-based conditions, and corresponding definite expressions of fuzzy $H_{\\infty}$ filter are given as well. Finally, a simulation example is provided to prove the effectiveness and superiority of the designed fuzzy $H_{\\infty}$ filter."}}
{"id": "t7wCGeTgX74", "cdate": 1609459200000, "mdate": 1668619829700, "content": {"title": "Finite-Sample Analysis of Decentralized Q-Learning for Stochastic Games", "abstract": "Learning in stochastic games is arguably the most standard and fundamental setting in multi-agent reinforcement learning (MARL). In this paper, we consider decentralized MARL in stochastic games in the non-asymptotic regime. In particular, we establish the finite-sample complexity of fully decentralized Q-learning algorithms in a significant class of general-sum stochastic games (SGs) - weakly acyclic SGs, which includes the common cooperative MARL setting with an identical reward to all agents (a Markov team problem) as a special case. We focus on the practical while challenging setting of fully decentralized MARL, where neither the rewards nor the actions of other agents can be observed by each agent. In fact, each agent is completely oblivious to the presence of other decision makers. Both the tabular and the linear function approximation cases have been considered. In the tabular setting, we analyze the sample complexity for the decentralized Q-learning algorithm to converge to a Markov perfect equilibrium (Nash equilibrium). With linear function approximation, the results are for convergence to a linear approximated equilibrium - a new notion of equilibrium that we propose - which describes that each agent's policy is a best reply (to other agents) within a linear space. Numerical experiments are also provided for both settings to demonstrate the results."}}
{"id": "iUqZHS2Qg65", "cdate": 1609459200000, "mdate": 1668619829736, "content": {"title": "Semi-supervised Domain Adaptive Structure Learning", "abstract": "Semi-supervised domain adaptation (SSDA) is quite a challenging problem requiring methods to overcome both 1) overfitting towards poorly annotated data and 2) distribution shift across domains. Unfortunately, a simple combination of domain adaptation (DA) and semi-supervised learning (SSL) methods often fail to address such two objects because of training data bias towards labeled samples. In this paper, we introduce an adaptive structure learning method to regularize the cooperation of SSL and DA. Inspired by the multi-views learning, our proposed framework is composed of a shared feature encoder network and two classifier networks, trained for contradictory purposes. Among them, one of the classifiers is applied to group target features to improve intra-class density, enlarging the gap of categorical clusters for robust representation learning. Meanwhile, the other classifier, serviced as a regularizer, attempts to scatter the source features to enhance the smoothness of the decision boundary. The iterations of target clustering and source expansion make the target features being well-enclosed inside the dilated boundary of the corresponding source points. For the joint address of cross-domain features alignment and partially labeled data learning, we apply the maximum mean discrepancy (MMD) distance minimization and self-training (ST) to project the contradictory structures into a shared view to make the reliable final decision. The experimental results over the standard SSDA benchmarks, including DomainNet and Office-home, demonstrate both the accuracy and robustness of our method over the state-of-the-art approaches."}}
{"id": "REfHQdrt8C", "cdate": 1609459200000, "mdate": 1668619829745, "content": {"title": "Contradictory Structure Learning for Semi-supervised Domain Adaptation", "abstract": "Current adversarial adaptation methods attempt to align the cross-domain features, whereas two challenges remain unsolved: 1) the conditional distribution mismatch and 2) the bias of the decision boundary towards the source domain. To solve these challenges, we propose a novel framework for semi-supervised domain adaptation by unifying the learning of opposite structures (UODA). UODA consists of a generator and two classifiers (i.e., the source-scattering classifier and the target-clustering classifier), which are trained for contradictory purposes. The target-clustering classifier attempts to cluster the target features to improve intra-class density and enlarge inter-class divergence. Meanwhile, the source-scattering classifier is designed to scatter the source features to enhance the decision boundary's smoothness. Through the alternation of source-feature expansion and target-feature clustering procedures, the target features are well-enclosed within the dilated boundary of the corresponding source features. This strategy can make the cross-domain features to be precisely aligned against the source bias simultaneously. Moreover, to overcome the model collapse through training, we progressively update the measurement of feature's distance and their representation via an adversarial training paradigm. Extensive experiments on the benchmarks of DomainNet and Office-home datasets demonstrate the superiority of our approach over the state-of-the-art methods."}}
{"id": "uTfyged3vbu", "cdate": 1577836800000, "mdate": 1668619839818, "content": {"title": "Adversarial Crowdsourcing Through Robust Rank-One Matrix Completion", "abstract": "We consider the problem of reconstructing a rank-one matrix from a revealed subset of its entries when some of the revealed entries are corrupted with perturbations that are unknown and can be arbitrarily large. It is not known which revealed entries are corrupted. We propose a new algorithm combining alternating minimization with extreme-value filtering and provide sufficient and necessary conditions to recover the original rank-one matrix. In particular, we show that our proposed algorithm is optimal when the set of revealed entries is given by an Erd\\H os-R\\'enyi random graph.                     These results are then applied to the problem of classification from crowdsourced data under the assumption that while the majority of the workers are governed by the standard single-coin David-Skene model (i.e., they output the correct answer with a certain probability), some of the workers can deviate arbitrarily from this model. In particular, the ``adversarial'' workers could even make decisions designed to make the algorithm output an incorrect answer. Extensive experimental results show our algorithm for this problem, based on rank-one matrix completion with perturbations, outperforms all other state-of-the-art methods in such an adversarial scenario."}}
{"id": "fPH-_--d_lH", "cdate": 1577836800000, "mdate": 1668619829738, "content": {"title": "Adversarial Crowdsourcing Through Robust Rank-One Matrix Completion", "abstract": "We consider the problem of reconstructing a rank-one matrix from a revealed subset of its entries when some of the revealed entries are corrupted with perturbations that are unknown and can be arbitrarily large. It is not known which revealed entries are corrupted. We propose a new algorithm combining alternating minimization with extreme-value filtering and provide sufficient and necessary conditions to recover the original rank-one matrix. In particular, we show that our proposed algorithm is optimal when the set of revealed entries is given by an Erd\\H{o}s-R\\'enyi random graph. These results are then applied to the problem of classification from crowdsourced data under the assumption that while the majority of the workers are governed by the standard single-coin David-Skene model (i.e., they output the correct answer with a certain probability), some of the workers can deviate arbitrarily from this model. In particular, the \"adversarial\" workers could even make decisions designed to make the algorithm output an incorrect answer. Extensive experimental results show our algorithm for this problem, based on rank-one matrix completion with perturbations, outperforms all other state-of-the-art methods in such an adversarial scenario."}}
{"id": "CET4qXnKyYT", "cdate": 1577836800000, "mdate": 1668619829701, "content": {"title": "Inductive and Unsupervised Representation Learning on Graph Structured Objects", "abstract": "Inductive and unsupervised graph learning is a critical technique for predictive or information retrieval tasks where label information is difficult to obtain. It is also challenging to make graph learning inductive and unsupervised at the same time, as learning processes guided by reconstruction error based loss functions inevitably demand graph similarity evaluation that is usually computationally intractable. In this paper, we propose a general framework SEED (Sampling, Encoding, and Embedding Distributions) for inductive and unsupervised representation learning on graph structured objects. Instead of directly dealing with the computational challenges raised by graph similarity evaluation, given an input graph, the SEED framework samples a number of subgraphs whose reconstruction errors could be efficiently evaluated, encodes the subgraph samples into a collection of subgraph vectors, and employs the embedding of the subgraph vector distribution as the output vector representation for the input graph. By theoretical analysis, we demonstrate the close connection between SEED and graph isomorphism. Using public benchmark datasets, our empirical study suggests the proposed SEED framework is able to achieve up to 10% improvement, compared with competitive baseline methods."}}
{"id": "9NFdt4Gdlt", "cdate": 1577836800000, "mdate": 1668619829727, "content": {"title": "Opposite Structure Learning for Semi-supervised Domain Adaptation", "abstract": "Current adversarial adaptation methods attempt to align the cross-domain features, whereas two challenges remain unsolved: 1) the conditional distribution mismatch and 2) the bias of the decision boundary towards the source domain. To solve these challenges, we propose a novel framework for semi-supervised domain adaptation by unifying the learning of opposite structures (UODA). UODA consists of a generator and two classifiers (i.e., the source-scattering classifier and the target-clustering classifier), which are trained for contradictory purposes. The target-clustering classifier attempts to cluster the target features to improve intra-class density and enlarge inter-class divergence. Meanwhile, the source-scattering classifier is designed to scatter the source features to enhance the decision boundary's smoothness. Through the alternation of source-feature expansion and target-feature clustering procedures, the target features are well-enclosed within the dilated boundary of the corresponding source features. This strategy can make the cross-domain features to be precisely aligned against the source bias simultaneously. Moreover, to overcome the model collapse through training, we progressively update the measurement of feature's distance and their representation via an adversarial training paradigm. Extensive experiments on the benchmarks of DomainNet and Office-home datasets demonstrate the superiority of our approach over the state-of-the-art methods."}}
{"id": "rkem91rtDB", "cdate": 1569439626682, "mdate": null, "content": {"title": "Inductive and Unsupervised Representation Learning on Graph Structured Objects", "abstract": "Inductive and unsupervised graph learning is a critical technique for predictive or information retrieval tasks where label information is difficult to obtain. It is also challenging to make graph learning inductive and unsupervised at the same time, as learning processes guided by reconstruction error based loss functions inevitably demand graph similarity evaluation that is usually computationally intractable. In this paper, we propose a general framework SEED (Sampling, Encoding, and Embedding Distributions) for inductive and unsupervised representation learning on graph structured objects. Instead of directly dealing with the computational challenges raised by graph similarity evaluation, given an input graph, the SEED framework samples a number of subgraphs whose reconstruction errors could be efficiently evaluated, encodes the subgraph samples into a collection of subgraph vectors, and employs the embedding of the subgraph vector distribution as the output vector representation for the input graph. By theoretical analysis, we demonstrate the close connection between SEED and graph isomorphism. Using public benchmark datasets, our empirical study suggests the proposed SEED framework is able to achieve up to 10% improvement, compared with competitive baseline methods."}}
