{"id": "PLvdU0IPSq", "cdate": 1668688440781, "mdate": 1668688440781, "content": {"title": "CycleSegNet: Object Co-Segmentation with Cycle Refinement and Region Correspondence", "abstract": "Image co-segmentation is an active computer vision task which aims to segment the common objects in a set of images. Recently, researchers design various learning-based algorithms to handle the co-segmentation task. The main difficulty in this task is how to effectively transfer information between images to infer the common object regions. In this paper, we present CycleSegNet, a novel framework for the co-segmentation task. Our network design has two key components: a region correspondence module which is the basic operation for exchanging information between local image regions, and a cycle refinement module which utilizes ConvLSTMs to progressively update image embeddings and exchange information in a cycle manner. Experiment results on four popular benchmark datasets -- PASCAL VOC dataset, MSRC dataset, Internet dataset and iCoseg dataset demonstrate that our proposed method significantly outperforms the existing networks and achieves new state-of-the-art performance."}}
{"id": "rjYwEWKJS6T", "cdate": 1668688390058, "mdate": 1668688390058, "content": {"title": "Fast Manifold Ranking with Local Bipartite Graph", "abstract": "During the past decades, manifold ranking has been widely applied to content-based image retrieval and shown excellent performance. However, manifold ranking is computationally expensive in both graph construction and ranking learning. Much effort has been devoted to improve its performance by introducing approximating techniques. In this paper, we propose a fast manifold ranking method, namely Local Bipartite Manifold Ranking (LBMR). Given a set of images, we first extract multiple regions from each image to form a large image descriptor matrix, and then use the anchor-based strategy to construct a local bipartite graph in which a regional k-means (RKM) is proposed to obtain high quality anchors. We propose an iterative method to directly solve the manifold ranking problem from the local bipartite graph, which monotonically decreases the objective function value in each iteration until the algorithm converges. Experimental results on several real-world image datasets demonstrate the effectiveness and efficiency of our proposed method."}}
{"id": "aRwJrT9qY8", "cdate": 1668688291123, "mdate": 1668688291123, "content": {"title": "StackRec: Efficient Training of Very Deep Sequential Recommender Models by Iterative Stacking", "abstract": "Deep learning has brought great progress for the sequential recommendation (SR) tasks. With advanced network architectures, sequential recommender models can be stacked with many hidden layers, e.g., up to 100 layers on real-world recommendation datasets. Training such a deep network is difficult because it can be computationally very expensive and takes much longer time, especially in situations where there are tens of billions of user-item interactions. To deal with such a challenge, we present StackRec, a simple, yet very effective and efficient training framework for deep SR models by iterative layer stacking. Specifically, we first offer an important insight that hidden layers/blocks in a well-trained deep SR model have very similar distributions. Enlightened by this, we propose the stacking operation on the pre-trained layers/blocks to transfer knowledge from a shallower model to a deep model, then we perform iterative stacking so as to yield a much deeper but easier-to-train SR model. We validate the performance of StackRec by instantiating it with four state-of-the-art SR models in three practical scenarios with real-world datasets. Extensive experiments show that StackRec achieves not only comparable performance, but also substantial acceleration in training time, compared to SR models that are trained from scratch. Codes are available at https://github.com/wangjiachun0426/StackRec."}}
{"id": "ozL50AQyS7n", "cdate": 1668688230920, "mdate": 1668688230920, "content": {"title": "Structure-aware Mathematical Expression Recognition with Sequence-Level Modeling", "abstract": "Mathematical expression recognition (MER) aims to convert an image of mathematical expressions into a Latex sequence. In practice, the task of MER is challenging, since 1) the images of mathematical expressions often contain complex structure relationships, e.g., fractions, matrixes, and subscripts; 2) the generated Latex sequences can be very complex and they have to satisfy strict syntax rules. Existing methods, however, often ignore the complex dependence among image regions, resulting in poor feature representation. In addition, they may fail to capture the rigorous relations among different formula symbols as they consider MER as a common language generation task. To address these issues, we propose a Structure-Aware Sequence-Level (SASL) model for MER. First, to better represent and recognize the visual content of formula images, we propose a structure-aware module to capture the relationship among different symbols. Meanwhile, the sequence-level modeling helps the model to concentrate on the generation of entire sequences. To make the problem feasible, we cast the generation problem into a Markov decision process (MDP) and seek to learn a Latex sequence generating policy. Based on MDP, we learn SASL by maximizing the matching score of each image-sequence pair to obtain the generation policy. Extensive experiments on the IM2LATEX-100K dataset verify the effectiveness and superiority of the proposed method."}}
{"id": "yKlzRy1ktS", "cdate": 1668688172149, "mdate": 1668688172149, "content": {"title": "MV-TON: Memory-based Video Virtual Try-on network", "abstract": "With the development of Generative Adversarial Network, image-based virtual try-on methods have made great progress. However, limited work has explored the task of video-based virtual try-on while it is important in real-world applications. Most existing video-based virtual try-on methods usually require clothing templates and they can only generate blurred and low-resolution results. To address these challenges, we propose a Memory-based Video virtual Try-On Network (MV-TON), which seamlessly transfers desired clothes to a target person without using any clothing templates and generates high-resolution realistic videos. Specifically, MV-TON consists of two modules: 1) a try-on module that transfers the desired clothes from model images to frame images by pose alignment and region-wise replacing of pixels; 2) a memory refinement module that learns to embed the existing generated frames into the latent space as external memory for the following frame generation. Experimental results show the effectiveness of our method in the video virtual try-on task and its superiority over other existing methods."}}
{"id": "N5T22HYobQ6", "cdate": 1668687995156, "mdate": 1668687995156, "content": {"title": "Modeling the Uncertainty for Self-supervised 3D Skeleton Action Representation Learning", "abstract": "Self-supervised learning (SSL) has been proved very effective in learning representations from unlabeled data in language and vision domains. Yet, very few instrumental self-supervised approaches exist for 3D skeleton action understanding, and directly applying the existing SSL methods from other domains for skeleton action learning may suffer from misalignment of representations and some limitations. In this paper, we consider that a good representation learning encoder can distinguish the underlying features of different actions, which can make the similar motions closer while pushing the dissimilar motions away. There exists, however, some uncertainties in the skeleton actions due to the inherent ambiguity of 3D skeleton pose in different viewpoints or the sampling algorithm in contrastive learning, thus, it is ill-posed to differentiate the action features in the deterministic embedding space. To address these issues, we rethink the distance between action features and propose to model each action representation into the probabilistic embedding space to alleviate the uncertainties upon encountering the ambiguous 3D skeleton inputs. To validate the effectiveness of the proposed method, extensive experiments are conducted on Kinetics, NTU60, NTU120, and PKUMMD datasets with several alternative network architectures. Experimental evaluations demonstrate the superiority of our approach and through which, we can gain significant performance improvement without using extra labeled data."}}
{"id": "7qzgDB2J8IB", "cdate": 1668687935605, "mdate": 1668687935605, "content": {"title": "Context Decoupling Augmentation for Weakly Supervised Semantic Segmentation", "abstract": "Data augmentation is vital for deep learning neural networks. By providing massive training samples, it helps to improve the generalization ability of the model. Weakly supervised semantic segmentation (WSSS) is a challenging problem that has been deeply studied in recent years, conventional data augmentation approaches for WSSS usually employ geometrical transformations, random cropping and color jittering. However, merely increasing the same contextual semantic data does not bring much gain to the networks to distinguish the objects, e.g., the correct image-level classification of \"aeroplane\" may be not only due to the recognition of the object itself, but also its co-occurrence context like \"sky\", which will cause the model to focus less on the object features. To this end, we present a Context Decoupling Augmentation (CDA) method, to change the inherent context in which the objects appear and thus drive the network to remove the dependence between object instances and contextual information. To validate the effectiveness of the proposed method, extensive experiments on PASCAL VOC 2012 dataset with several alternative network architectures demonstrate that CDA can boost various popular WSSS methods to the new state-of-the-art by a large margin."}}
{"id": "K1H_HK_yNYP", "cdate": 1668687831725, "mdate": 1668687831725, "content": {"title": "Self-supervised 3D Skeleton Action Representation Learning with Motion Consistency and Continuity", "abstract": "Recently, self-supervised learning (SSL) has been proved very effective and it can help boost the performance in learning representations from unlabeled data in the image domain. Yet, very little is explored about its usefulness in 3D skeleton-based action recognition understanding. Directly applying existing SSL techniques for 3D skeleton learning, however, suffers from trivial solutions and imprecise representations. To tackle these drawbacks, we consider perceiving the consistency and continuity of motion at different playback speeds are two critical issues. To this end, we propose a novel SSL method to learn the 3D skeleton representation in an efficacious way. Specifically, by constructing a positive clip (speed-changed) and a negative clip (motion-broken) of the sampled action sequence, we encourage the positive pairs closer while pushing the negative pairs to force the network to learn the intrinsic dynamic motion consistency information. Moreover, to enhance the learning features, skeleton interpolation is further exploited to model the continuity of human skeleton data. To validate the effectiveness of the proposed method, extensive experiments are conducted on Kinetics, NTU60, NTU120, and PKUMMD datasets with several alternative network architectures. Experimental evaluations demonstrate the superiority of our approach and through which, we can gain significant performance improvement without using extra labeled data.\n"}}
{"id": "J4d_Jsd8Rv", "cdate": 1668687771101, "mdate": 1668687771101, "content": {"title": "Iterative Refinement for Multi-source Visual Domain Adaptation", "abstract": "One of the main challenges in multi-source domain adaptation is how to reduce the domain discrepancy between each source domain and a target domain, and then evaluate the domain relevance to determine how much knowledge should be transferred from different source domains to the target domain. However, most prior approaches barely consider both discrepancies and relevance among domains. In this paper, we propose an algorithm, called Iterative Refinement based on Feature Selection and the Wasserstein distance (IRFSW), to solve semi-supervised domain adaptation with multiple sources. Specifically, IRFSW aims to explore both the discrepancies and relevance among domains in an iterative learning procedure, which gradually refines the learning performance until the algorithm stops. In each iteration, for each source domain and the target domain, we develop a sparse model to select features in which the domain discrepancy and training loss are reduced simultaneously. Then a classifier is constructed with the selected features of the source and labeled target data. After that, we exploit optimal transport over the selected features to calculate the transferred weights. The weight values are taken as the ensemble weights to combine the learned classifiers to control the amount of knowledge transferred from source domains to the target domain. Experimental results validate the effectiveness of the proposed method."}}
{"id": "CqQKkxZxqy", "cdate": 1668687724756, "mdate": 1668687724756, "content": {"title": "Improving Generative Adversarial Networks with Local Coordinate Coding", "abstract": "Generative adversarial networks (GANs) have shown remarkable success in generating realistic data from some predefined prior distributions. However, such prior distributions are often independent of real data and thus may lose semantic information of data. In practice, the semantic information might be represented by some latent distribution learned from data. However, such latent distribution may incur difficulties in data sampling for GAN methods. In this paper, rather than sampling from the predefined prior distribution, we propose a local coordinate coding GAN (LCCGAN-v1) to improve the performance of GANs. First, we propose a local coordinate coding (LCC)-based sampling method to sample points from the latent manifold. With the LCC sampling method, we can exploit the local information on the latent manifold and thus produce new data with promising quality. Second, we propose an advanced LCCGAN-v2 by introducing a higher-order term in the generator approximation. This term is able to achieve better approximation and thus further improve the performance. More critically, we derive the generalization bound for both LCCGAN-v1 and LCCGAN-v2 and prove that a small-dimensional input is sufficient to achieve good generalization performance. Extensive experiments on four benchmark datasets demonstrate the superiority of the proposed method over existing GAN methods."}}
