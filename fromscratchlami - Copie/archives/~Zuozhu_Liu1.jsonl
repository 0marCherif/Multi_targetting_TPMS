{"id": "Kw5oxHrvNw", "cdate": 1702709308282, "mdate": null, "content": {"title": "Empirical Study of Zero-Shot NER with ChatGPT", "abstract": "Large language models (LLMs) exhibited powerful capability in various natural language processing tasks. This work focuses on exploring LLM performance on zero-shot information extraction, with a focus on the ChatGPT and named entity recognition (NER) task. Inspired by the remarkable reasoning capability of LLM on symbolic and arithmetic reasoning, we adapt the prevalent reasoning methods to NER and propose reasoning strategies tailored for NER. First, we explore a decomposed question-answering paradigm by breaking down the NER task into simpler subproblems by labels. Second, we propose syntactic augmentation to stimulate the model's intermediate thinking in two ways: syntactic prompting, which encourages the model to analyze the syntactic structure itself, and tool augmentation, which provides the model with the syntactic information generated by a parsing tool. Besides, we adapt self-consistency to NER by proposing a two-stage majority voting strategy, which first votes for the most consistent mentions, then the most consistent types. The proposed methods achieve remarkable improvements for zero-shot NER across seven benchmarks, including Chinese and English datasets, and on both domain-specific and general-domain scenarios. In addition, we present a comprehensive analysis of the error types with suggestions for optimization directions. We also verify the effectiveness of the proposed methods on the few-shot setting and other LLMs."}}
{"id": "7_jig8Y3pt", "cdate": 1680955134499, "mdate": null, "content": {"title": "Benchmark and Boosted Segmentation on Dental Panoramic Radiographs", "abstract": "Panoramic radiographs, also known as orthopantomograms, are commonly utilized by dentists to gain a comprehensive understanding of the patient\u2019s oral health and perform orthodontic procedures. However, due to physician burnout and time constraints, many dentists may use them hastily which could result in medical negligence. To streamline the workflow for dentists, we establish a mission to segment five oral structures on panoramic radiographs, namely Alveolarcrest, Condyle, Neuraltube, Sinusmaxillaris and Teeth. A Cascaded Multi-scale Mask2former(CMMask2former) method is proposed for this task. For small objects, we design a multi-scale masked attention specifically for the mask area. The entire structure is designed in a two-stage cascade for localization and prediction. Our results demonstrate superior predictive performance compared to other methods."}}
{"id": "FCYGwhzF7E", "cdate": 1680954983122, "mdate": null, "content": {"title": "TSNet: Integrating Dental Position Prior and Symptoms for Tooth Segmentation from CBCT Images", "abstract": "Automated dental diagnosis requires accurate segmentation of tooth from cone-beam computed tomography (CBCT) images. However, existing segmentation methods often overlook incorporating prior information and symptoms of teeth, which can cause unsatisfactory segmentation performance on teeth with symptoms. To this respect, we propose Tooth Symptom Network (TSNet), consisting of Dental Prior Guiding Data Augmentation (DPGDA) and Dental Symptom Shape Loss (DSSL), to improve segmentation performance for teeth with different clinical symptoms. Experiments show that TSNet outperforms all state-of-the-art methods across datasets with all kinds of symptoms with an average increase of 1.13\\% in Dice and 2.00\\% in IoU."}}
{"id": "O2DerS5oQ1", "cdate": 1673287846933, "mdate": null, "content": {"title": "Model Adaptive Tooth Segmentation", "abstract": "Automatic 3-dimensional tooth segmentation on intraoral scans (IOS) plays a pivotal role in computer-aided orthodontic treatments. In practice, deploying existing well-trained models to different medical centers suffers from two main problems: (1) the data distribution shifts between existing and new centers, (2) the data in the existing center is usually not allowed to share while annotating additional data in the new center is time-consuming and expensive. In this paper, we propose a Model Adaptive Tooth Segmentation (MATS) framework to alleviate these issues. Taking the trained model from a source center as input, MATS adapts it to different target centers without data transmission or additional annotations, as inspired by the source data-free domain adaptation (SFDA) paradigm. The model adaptation in MATS is realized by a tooth-level feature prototype learning module, a progressive pseudo-labeling module and a tooth-prior regularized information maximization loss. Experiments on a dataset with tooth abnormalities and a real-world cross-center dataset show that MATS can consistently surpass existing baselines. The effectiveness is further verified with extensive ablation studies and statistical analysis, demonstrating its applicability for privacy-preserving tooth segmentation in real-world digital dentistry. "}}
{"id": "v8JIQdiN9Sh", "cdate": 1663850103857, "mdate": null, "content": {"title": "On the Effectiveness of Out-of-Distribution Data in Self-Supervised Long-Tail Learning.", "abstract": "Though Self-supervised learning (SSL) has been widely studied as a promising technique for representation learning, it doesn't generalize well on long-tailed datasets due to the majority classes dominating the feature space. Recent work shows that the long-tailed learning performance could be boosted by sampling extra in-domain (ID) data for self-supervised training, however, large-scale ID data which can rebalance the minority classes are expensive to collect. In this paper, we propose an alternative but easy-to-use and effective solution, \\textbf{C}ontrastive with \\textbf{O}ut-of-distribution (OOD) data for \\textbf{L}ong-\\textbf{T}ail learning (COLT), which can effectively exploit OOD data to dynamically re-balance the feature space. We empirically identify the counter-intuitive usefulness of OOD samples in SSL long-tailed learning and principally design a novel SSL method. Concretely, we first localize the `\\emph{head}' and `\\emph{tail}' samples by assigning a tailness score to each OOD sample based on its neighborhoods in the feature space. Then, we propose an online OOD sampling strategy to dynamically re-balance the feature space. Finally, we enforce the model to be capable of distinguishing ID and OOD samples by a distribution-level supervised contrastive loss. Extensive experiments are conducted on various datasets and several state-of-the-art SSL frameworks to verify the effectiveness of the proposed method. The results show that our method significantly improves the performance of SSL on long-tailed datasets by a large margin, and even outperforms previous work which uses external ID data. Our code is available at \\url{https://github.com/JianhongBai/COLT}."}}
{"id": "5JEnrPnpbI7", "cdate": 1639045535832, "mdate": null, "content": {"title": "Unsupervised Pre-training Improves Tooth Segmentation in 3-Dimensional Intraoral Mesh Scans", "abstract": "Accurate tooth segmentation in 3-Dimensional (3D) intraoral scanned (IOS) mesh data is an essential step for many practical dental applications.  Recent research highlights the success of deep learning based methods for end-to-end 3D tooth segmentation, yet most of them are only trained or validated with a small dataset as annotating 3D IOS dental surfaces requires complex pipelines and intensive human efforts. In this paper, we propose a novel method to boost the performance of 3D tooth segmentation leveraging large-scale unlabeled IOS data. Our tooth segmentation network is first pre-trained with an unsupervised learning framework and point-wise contrastive learning loss on the large-scale unlabeled dataset and subsequently fine-tuned on a small labeled dataset. With the same amount of annotated samples, our method can achieve a mIoU of 89.38\\%, significantly outperforming the supervised counterpart. Moreover, our method can achieve better performance with only 40\\% of the annotated samples as compared to the fully supervised baselines. To the best of our knowledge, we present the first attempt of unsupervised pre-training for 3D tooth segmentation, demonstrating its strong potential in reducing human efforts for annotation and verification. "}}
{"id": "dK4Ic3gIfw", "cdate": 1638971910181, "mdate": null, "content": {"title": "Bridging the Patient Distribution Gap for Robust 3D Tooth Segmentation", "abstract": "Empowered by deep learning, 3D semantic segmentation algorithms have been applied to computer-aided dental systems in recent years. Existing models yield satisfactory performance for 3D point cloud data. However, there exists a common assumption that the data distribution of training and testing scenarios is the same, which limits the model capacity to deal with cross-domain situations. In real-world clinical scenarios, the patients for evaluation could be quite different from those for training in terms of their teeth symptoms, such as teeth defects and eruption. To deal with this problem, we borrow the idea of Domain Adaptation (DA) and propose a Domain-Invariant Tooth Segmentation (DITS) framework that bridges the clinically symptomatic domain gap. DITS leverages a dynamic graph convolutional neural network for 3D semantic segmentation backbone, while maximizing the probabilities of well-classified samples during evaluation by maximum square loss, thus adapting the 3D segmentation model to a realistic domain with different teeth symptoms. In the experiment, the real-world datasets are collected including 4272 3D IOS scans which are annotated with tooth-ID and three common tooth symptoms by experts. Extensive experiments have shown that DITS leads to a significant improvement for the large-scale cross-domain 3D tooth segmentation."}}
{"id": "S1ET7xZuWr", "cdate": 1514764800000, "mdate": null, "content": {"title": "Variational Probability Flow for Biologically Plausible Training of Deep Neural Networks", "abstract": "The quest for biologically plausible deep learning is driven, not just by the desire to explain experimentally-observed properties of biological neural networks, but also by the hope of discovering more efficient methods for training artificial networks. In this paper, we propose a new algorithm named Variational Probably Flow (VPF), an extension of minimum probability flow for training binary Deep Boltzmann Machines (DBMs). We show that weight updates in VPF are local, depending only on the states and firing rates of the adjacent neurons. Unlike contrastive divergence, there is no need for Gibbs confabulations; and unlike backpropagation, alternating feedforward and feedback phases are not required. Moreover, the learning algorithm is effective for training DBMs with intra-layer connections between the hidden nodes. Experiments with MNIST and Fashion MNIST demonstrate that VPF learns reasonable features quickly, reconstructs corrupted images more accurately, and generates samples with a high estimated log-likelihood. Lastly, we note that, interestingly, if an asymmetric version of VPF exists, the weight updates directly explain experimental results in Spike-Timing-Dependent Plasticity (STDP)."}}
