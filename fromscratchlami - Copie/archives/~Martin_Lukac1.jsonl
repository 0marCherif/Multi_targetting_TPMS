{"id": "znRRNI6Zk4K", "cdate": 1577836800000, "mdate": null, "content": {"title": "Selecting Algorithms Without Meta-features", "abstract": "The algorithm selection has been successfully used on a variety of decision problems. When the problem definition is structured and several algorithms for the same problem are available, then meta-features, that in turn permit a highly accurate algorithm selection on a case-by-case basis, can be easily and at a relatively low cost extracted. Real world problems such as computer vision could benefit from algorithm selection as well, however the input is not structured and datasets are very large both in samples size and sample numbers. Therefore, meta-features are either impossible or too costly to be extracted. Considering such limitations, in this paper we experimentally evaluate the cost and the complexity of algorithm selection on two popular computer vision datasets VOC2012 and MSCOCO and by using a variety task oriented features. We evaluate both dataset on algorithm selection accuracy over five algorithms and by using a various levels of dataset manipulation such as data augmentation, algorithm selector fine tuning and ensemble selection. We determine that the main reason for low accuracy from existing features is due to insufficient evaluation of existing algorithms. Our experiments show that even without meta features, it is thus possible to have meaningful algorithm selection accuracy, and thus obtain processing accuracy increase. The main result shows that using ensemble method, trained on MSCOCO dataset, we can successfully increase the processing result by at least 3% of processing accuracy."}}
{"id": "rMyAG8qECz9", "cdate": 1577836800000, "mdate": null, "content": {"title": "Geometric Refactoring of Quantum and Reversible Circuits: Quantum Layout", "abstract": "With the advent of gated quantum computers and regular structures of the qubit layout, methods for placement, routing, noise estimation and logic to hardware mapping become imminently required. In this paper, we propose a method for quantum circuit layout that is intended to solve such problems when mapping a quantum circuit to a quantum computer. The proposed method starts by building a Circuit Interaction Graph (CIG) that represents the ideal hardware layout minimizing the distance and path length between the individual qubits. The CIG is also used to introduce a qubit noise model. Once constructed, the CIG is iteratively reduced to a given architecture (qubit coupling model) specifying the neighborhood, qubits, priority and qubits noise. The introduced constraints allow to additionally reduce the graph according to preferred weights of desired properties. The proposed method is verified and tested on a set of standard benchmarks."}}
{"id": "8_n505GXx54", "cdate": 1577836800000, "mdate": null, "content": {"title": "Remove to Improve?", "abstract": "The workhorses of CNNs are its filters, located at different layers and tuned to different features. Their responses are combined using weights obtained via network training. Training is aimed at optimal results for the entire training data, e.g., highest average classification accuracy. In this paper, we are interested in extending the current understanding of the roles played by the filters, their mutual interactions, and their relationship to classification accuracy. This is motivated by observations that the classification accuracy for some classes increases, instead of decreasing when some filters are pruned from a CNN. We are interested in experimentally addressing the following question: Under what conditions does filter pruning increase classification accuracy? We show that improvement of classification accuracy occurs for certain classes. These classes are placed during learning into a space (spanned by filter usage) populated with semantically related neighbors. The neighborhood structure of such classes is however sparse enough so that during pruning, the resulting compression bringing all classes together brings sample data closer together and thus increases the accuracy of classification."}}
{"id": "37-Ju1E9rWi", "cdate": 1577836800000, "mdate": null, "content": {"title": "Capacity Limits of Fully Binary CNN", "abstract": "Convolutional Neural Networks (CNNs) have achieved a state-of-the-art performance on different real world information processing tasks. However, CNNs are computationally and power intensive, which makes them difficult to run on wearable and embedded systems. Using binary models instead of more complex models, was shown to significantly reduce the memory and computational resources; however, at the cost of a lower accuracy. The aim of the paper is to provide the further exploration of the binarization effect on the model capacity. We study a multiple-valued thresholding (binarization) of the input images and we combine features of several binary networks to perform a classification task. Each image is fitted to a separate binary CNN model. In this manner, we decompose the real world problem to several binary sub-problems. The separate binary models are then assembled into a final classifier and are used to predict the class label. The results show that while for MNIST the accuracy is very close to the full precision counterpart, for the more complex dataset, CIFAR-10, the binarization and the representational power of CNNs is strongly affected."}}
{"id": "rkxXNR4tvH", "cdate": 1569439274892, "mdate": null, "content": {"title": "Semantic Pruning for Single Class Interpretability", "abstract": "Convolutional Neural Networks (CNN) have achieved state-of-the-art performance in different computer vision tasks, but at a price of being computationally and power intensive. At the same time, only a few attempts were made toward a deeper understanding of CNNs. In this work, we propose to use semantic pruning technique toward not only CNN optimization but also as a way toward getting some insight information on convolutional filters correlation and interference. We start with a pre-trained network and prune it until it behaves as a single class classifier for a selected class. Unlike the more traditional approaches which apply retraining to the pruned CNN, the proposed semantic pruning  does not use retraining. Conducted experiments showed that a) for each class there is a pruning ration which allows removing filters with either an increase or no loss of classification accuracy, b) pruning can improve the interference between filters used for classification of different classes c) effect between classification accuracy and correlation between pruned filters groups specific for different classes. "}}
{"id": "7v5nKPXF4_", "cdate": 1546300800000, "mdate": null, "content": {"title": "Quantum encoded quantum evolutionary algorithm for the design of quantum circuits", "abstract": "In this paper we present Quanrum Encoded Quantum Evolutionary Algorithm (QEQEA) and compare its performance against a a classical GPU accelerated Genetic Algorithm (GPUGA). The proposed QEQEA differs from existing quantum evolutionary algorithms in several points: representation of candidates circuits is using qubits and qutrits and the proposed evolutionary operators can theoretically be implemented on quantum computer provided a classical control exists. The synthesized circuits are obtained by a set of measurements performed on the encoding units of quantum representation. Both algorithms are accelerated using (general purpose graphic processing unit) GPGPU. The main target of this paper is not to propose a completely novel quantum genetic algorithm but to rather experimentally estimate the advantages of certain components of genetic algorithm being encoded and implemented in a quantum compatible manner. The algorithms are compared and evaluated on several reversible and quantum circuits. The results demonstrate that on one hand the quantum encoding and quantum implementation compatible implementation provides certain disadvantages with respect to the classical evolutionary computation. On the other hand, encoding certain components in a quantum compatible manner could in theory allow to accelerate the search by providing small overhead when built in quantum computer. Therefore acceleration would in turn counter weight the implementation limitations."}}
{"id": "y33zctf1bDd", "cdate": 1514764800000, "mdate": null, "content": {"title": "QL-Net: Quantized-by-LookUp CNN", "abstract": "Convolutional Neural Networks (CNNs) have achieved a state-of-the-art performance in the different computer vision tasks. However, CNN algorithms are computationally and power intensive, which makes them difficult to run on wearable and embedded systems. One way to address this constraint is to reduce the number of computational operations performed. Recently, several approaches addressed the problem of the computational complexity in the CNNs. Most of these methods, however, require a dedicated hardware. We propose a new method for the computation reduction in CNNs that substitutes Multiply and Accumulate (MAC) operations with a codebook lookup and can be executed on the generic hardware. The proposed method called QL-Net combines several concepts: (i) a codebook construction, (ii) a layer-wise retraining strategy, and (iii) a substitution of the MAC operations with the lookup of the convolution responses at inference time. The proposed QL-Net achieves a 98.6% accuracy on the MNIST dataset with a 5.8x reduction in runtime, when compared to MAC-based CNN model that achieved a 99.2% accuracy."}}
{"id": "KsQjYDsiHiS", "cdate": 1514764800000, "mdate": null, "content": {"title": "CNOT-Measure Quantum Neural Networks", "abstract": "Various models of quantum neural networks exist imitating the powerful class of machine learning algorithms, widely applied and used in many of intelligent systems and applications. While comparative models of quantum neural networks exist, their computational complexity might require specific unitary transforms for simulating the activation function of the cell, simulation of continuous processes for learning or adding a large amount of ancilla qubits. In order to solve some of these problems, we present a quantum neural network model called CNOT Measured Network (CMN). The CMN uses only CNOT quantum gates and the measurement operator and as such is very simple to implement in any quantum computer technology. The CMN can by using only these two simple operators, result in a Turing universal operators AND and OR while keeping the learning speed optimized to the complex nature of the quantum network and a constant number of ancila qubits."}}
{"id": "qUL0YCLgogo", "cdate": 1483228800000, "mdate": null, "content": {"title": "Study of GPU Acceleration in Genetic Algorithms for Quantum Circuit Synthesis", "abstract": "In this work we present a comparative study of several GPU accelerated elements of a Genetic Algorithm (GA) for the synthesis of quantum circuits on the level of Electro-Magnetic (EM) pulses. The novelty in our approach is in the implementation: a) a completely GPU accelerated quantum simulator, b) GPU accelerated genetic operators and fitness evaluation and finally c) a set of GPU implemented optimizations for GPU accelerated evolutionary search optimization for the synthesis of quantum circuits. The reason for using EM pulses model for synthesis is the observation that this model requires the largest amount of elementary rotations to implement quantumlogic gates and thus provides a good measure to evaluate the efficiency of the acceleration by the GPU processor. The reason to use a GA is the advantage of pseudo evolutionary search in very large problem space such as the one defined by the Ising model where the EM realized quantum circuits are evolved. As a result of the several GPU optimizations several new circuits implementations are presented and their cost is compared to thecurrently known Ising model implementations."}}
{"id": "hrCWv_zwlgl", "cdate": 1483228800000, "mdate": null, "content": {"title": "Context Based Visual Content Verification", "abstract": "In this paper the intermediary visual content verification method based on multi-level co-occurrences is studied. The co-occurrence statistics are in general used to determine relational properties between objects based on information collected from data. As such these measures are heavily subject to relative number of occurrences and give only limited amount of accuracy when predicting objects in real world. In order to improve the accuracy of this method in the verification task, we include the context information such as location, type of environment etc. In order to train our model we provide new annotated dataset the Advanced Attribute VOC (AAVOC) that contains additional properties of the image. We show that the usage of context greatly improve the accuracy of verification with up to 16% improvement."}}
