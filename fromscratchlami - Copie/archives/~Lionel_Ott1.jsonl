{"id": "f4NP5aiVXb", "cdate": 1685577600000, "mdate": 1695973122100, "content": {"title": "Robust Sampling-Based Control of Mobile Manipulators for Interaction With Articulated Objects", "abstract": "In this article, we investigate and deploy sampling-based control techniques for the challenging task of the mobile manipulation of articulated objects. By their nature, manipulation tasks necessitate environment interactions, which require the handling of nondifferentiable switching contact dynamics. These dynamics represent a strong limitation for traditional gradient-based optimization methods, such as model-predictive control and differential dynamic programming, which often rely on heuristics for trajectory generation. <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">Sampling-based</i> techniques alleviate these constraints but do not ensure robots' stability and input/state constraints either. On the other hand, real-world applications in human environments require safety and robustness to unexpected events. For this reason, we propose a novel framework for safe robotic manipulation of movable articulated objects. The framework combines sampling-based control together with <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">control barrier functions</i> and <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">passivity theory</i> that, thanks to formal stability guarantees, enhance the safety and robustness of the method. We also provide the practical insights that enable robust deployment of stochastic control using a conventional central processing unit. We deploy the algorithm on a ten-degree-of-freedom mobile manipulator robot. Finally, we open source our generic and multithreaded implementation."}}
{"id": "aWYdvQK-fTy", "cdate": 1684224182095, "mdate": 1684224182095, "content": {"title": "Bayesian Curiosity for Efficient Exploration in Reinforcement Learning", "abstract": "Balancing exploration and exploitation is a fundamental part of reinforcement learning, yet most state-of-theart algorithms use a naive exploration protocol like \u000f-greedy.\nThis contributes to the problem of high sample complexity, as\nthe algorithm wastes effort by repeatedly visiting parts of the\nstate space that have already been explored. We introduce a\nnovel method based on Bayesian linear regression and latent\nspace embedding to generate an intrinsic reward signal that\nencourages the learning agent to seek out unexplored parts of\nthe state space. This method is computationally efficient, simple\nto implement, and can extend any state-of-the-art reinforcement\nlearning algorithm. We evaluate the method on a range of\nalgorithms and challenging control tasks, on both simulated\nand physical robots, demonstrating how the proposed method\ncan significantly improve sample complexity."}}
{"id": "yrr7xZcQvd", "cdate": 1684224137758, "mdate": 1684224137758, "content": {"title": "Improving reinforcement learning pre-training with variational dropout", "abstract": "Improving reinforcement learning pre-training with variational dropout"}}
{"id": "Lx7trKCpn6a", "cdate": 1681487669145, "mdate": null, "content": {"title": "Grounding Pretrained Features in 3D Representations", "abstract": "Pretraining deep neural networks has become very popular and has led to the recent trend of foundation models. For perception, pretraining has mostly been constrained to 2D feature learning. 3D representation learning has yet to have its breakthrough moment. Data is more heterogeneous and harder to come by. 3D learning algorithms are still behind their 2D counterparts and the right 3D self-supervised learning objectives are yet to be discovered. \n\nIn this paper, we take a look at a recent trend in 3D representation learning where features extracted from 2D images are grounded into a 3D representation through a 3D feature field. We discuss recent results, highlight some open problems in the field and suggest some potential avenues to solve these problems."}}
{"id": "ejXlkKZfQV", "cdate": 1681299606888, "mdate": 1681299606888, "content": {"title": "Neural Implicit Vision-Language Feature Fields", "abstract": "Recently, groundbreaking results have been presented on open-vocabulary semantic image segmentation. Such methods segment each pixel in an image into arbitrary categories provided at run-time in the form of text prompts, as opposed to a fixed set of classes defined at training time. In this work, we present a zero-shot volumetric open-vocabulary semantic scene segmentation method. Our method builds on the insight that we can fuse image features from a vision-language model into a neural implicit representation. We show that the resulting feature field can be segmented into different classes by assigning points to natural language text prompts. The implicit volumetric representation enables us to segment the scene both in 3D and 2D by rendering feature maps from any given viewpoint of the scene. We show that our method works on noisy real-world data and can run in real-time on live sensor data dynamically adjusting to text prompts. We also present quantitative comparisons on the ScanNet dataset."}}
{"id": "rWzXuwV5A8", "cdate": 1672531200000, "mdate": 1695973122096, "content": {"title": "Self-Supervised Learning for Interactive Perception of Surgical Thread for Autonomous Suture Tail-Shortening", "abstract": "Accurate 3D sensing of suturing thread is a challenging problem in automated surgical suturing because of the high state-space complexity, thinness and deformability of the thread, and possibility of occlusion by the grippers and tissue. In this work we present a method for tracking surgical thread in 3D which is robust to occlusions and complex thread configurations, and apply it to autonomously perform the surgical suture \"tail-shortening\" task: pulling thread through tissue until a desired \"tail\" length remains exposed. The method utilizes a learned 2D surgical thread detection network to segment suturing thread in RGB images. It then identifies the thread path in 2D and reconstructs the thread in 3D as a NURBS spline by triangulating the detections from two stereo cameras. Once a 3D thread model is initialized, the method tracks the thread across subsequent frames. Experiments suggest the method achieves a 1.33 pixel average reprojection error on challenging single-frame 3D thread reconstructions, and an 0.84 pixel average reprojection error on two tracking sequences. On the tail-shortening task, it accomplishes a 90% success rate across 20 trials. Supplemental materials are available at https://sites.google.com/berkeley.edu/autolab-surgical-thread/ ."}}
{"id": "pHALSh6fQ8", "cdate": 1672531200000, "mdate": 1681661366029, "content": {"title": "Material-agnostic Shaping of Granular Materials with Optimal Transport", "abstract": "From construction materials, such as sand or asphalt, to kitchen ingredients, like rice, sugar, or salt; the world is full of granular materials. Despite impressive progress in robotic manipulation, manipulating and interacting with granular material remains a challenge due to difficulties in perceiving, representing, modelling, and planning for these variable materials that have complex internal dynamics. While some prior work has looked into estimating or learning accurate dynamics models for granular materials, the literature is still missing a more abstract planning method that can be used for planning manipulation actions for granular materials with unknown material properties. In this work, we leverage tools from optimal transport and connect them to robot motion planning. We propose a heuristics-based sweep planner that does not require knowledge of the material's properties and directly uses a height map representation to generate promising sweeps. These sweeps transform granular material from arbitrary start shapes into arbitrary target shapes. We apply the sweep planner in a fast and reactive feedback loop and avoid the need for model-based planning over multiple time steps. We validate our approach with a large set of simulation and hardware experiments where we show that our method is capable of efficiently solving several complex tasks, including gathering, separating, and shaping of several types of granular materials into different target shapes."}}
{"id": "p0HaXkIHEOd", "cdate": 1672531200000, "mdate": 1682080110891, "content": {"title": "Chasing Millimeters: Design, Navigation and State Estimation for Precise In-flight Marking on Ceilings", "abstract": "Precise markings for drilling and assembly are crucial, laborious construction tasks. Aerial robots with suitable end-effectors are capable of markings at the millimeter scale. However, so far, they have only been demonstrated under laboratory conditions where rigid state estimation and navigation assumptions do not impede robustness and accuracy. This paper presents a complete aerial layouting system capable of precise markings on-site under realistic conditions. We use a compliant actuated end-effector on an omnidirectional flying base. Combining a two-stage factor-graph state estimator with a Riemannian Motion Policy-based navigation stack, we avoid the need for a globally consistent estimate and increase robustness. The policy-based navigation is structured into individual behaviors in different state spaces. Through a comprehensive study, we show that the system creates highly precise markings at a relative precision of 1.5 mm and a global accuracy of 5-6 mm and discuss the results in the context of future construction robotics."}}
{"id": "jaXsx8iy4N", "cdate": 1672531200000, "mdate": 1695973122107, "content": {"title": "Efficient volumetric mapping of multi-scale environments using wavelet-based compression", "abstract": "Volumetric maps are widely used in robotics due to their desirable properties in applications such as path planning, exploration, and manipulation. Constant advances in mapping technologies are needed to keep up with the improvements in sensor technology, generating increasingly vast amounts of precise measurements. Handling this data in a computationally and memory-efficient manner is paramount to representing the environment at the desired scales and resolutions. In this work, we express the desirable properties of a volumetric mapping framework through the lens of multi-resolution analysis. This shows that wavelets are a natural foundation for hierarchical and multi-resolution volumetric mapping. Based on this insight we design an efficient mapping system that uses wavelet decomposition. The efficiency of the system enables the use of uncertainty-aware sensor models, improving the quality of the maps. Experiments on both synthetic and real-world data provide mapping accuracy and runtime performance comparisons with state-of-the-art methods on both RGB-D and 3D LiDAR data. The framework is open-sourced to allow the robotics community at large to explore this approach."}}
{"id": "c_thjJiNXH", "cdate": 1672531200000, "mdate": 1695973122130, "content": {"title": "Efficient volumetric mapping of multi-scale environments using wavelet-based compression", "abstract": ""}}
