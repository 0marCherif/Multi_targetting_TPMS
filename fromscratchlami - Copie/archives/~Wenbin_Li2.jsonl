{"id": "JhfO82oInKf", "cdate": 1668763347030, "mdate": 1668763347030, "content": {"title": "MID-Fusion: Octree-based Object-Level Multi-Instance Dynamic SLAM", "abstract": "We propose a new multi-instance dynamic RGB-\nD SLAM system using an object-level octree-based volumet-\nric representation. It can provide robust camera tracking in\ndynamic environments and at the same time, continuously\nestimate geometric, semantic, and motion properties for ar-\nbitrary objects in the scene. For each incoming frame, we\nperform instance segmentation to detect objects and refine\nmask boundaries using geometric and motion information.\nMeanwhile, we estimate the pose of each existing moving object\nusing an object-oriented tracking method and robustly track\nthe camera pose against the static scene. Based on the estimated\ncamera pose and object poses, we associate segmented masks\nwith existing models and incrementally fuse corresponding\ncolour, depth, semantic, and foreground object probabilities\ninto each object model. In contrast to existing approaches, our\nsystem is the first system to generate an object-level dynamic\nvolumetric map from a single RGB-D camera, which can be\nused directly for robotic tasks. Our method can run at 2-3\nHz on a CPU, excluding the instance segmentation part. We\ndemonstrate its effectiveness by quantitatively and qualitatively\ntesting it on both synthetic and real-world sequences."}}
{"id": "Xj3T7Odiin", "cdate": 1580421886193, "mdate": null, "content": {"title": "Multi-view Reconstruction of Highly Specular Surfaces in Uncontrolled Environments", "abstract": "Reconstructing the surface of highly specular objects is a challenging task. The shapes of diffuse and rough specular objects can be captured in an uncontrolled setting using consumer equipment. In contrast, highly specular objects have previously deterred capture in uncontrolled environments and have only been reconstructed using tailor-made hardware. We propose a method to reconstruct such objects in uncontrolled environments using only commodity hardware. As input, our method expects multi-view photographs of the specular object, its silhouettes and an environment map of its surroundings.\n\nWe compare the reflected colors in the photographs with the ones in the environment to form probability distributions over the surface normals. As the effect of inter-reflections cannot be ignored for highly specular objects, we explicitly model them when forming the probability distributions. We recover the shape of the object in an iterative process where we alternate between estimating normals and updating the shape of the object to better explain these normals.\n\nWe run experiments on both synthetic and real-world data, that show our method is robust and produces accurate reconstructions with as few as 25 input photographs."}}
