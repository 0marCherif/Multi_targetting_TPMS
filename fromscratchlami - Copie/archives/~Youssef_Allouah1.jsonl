{"id": "dp4KYDulQg_", "cdate": 1672531200000, "mdate": 1695983479641, "content": {"title": "On the Privacy-Robustness-Utility Trilemma in Distributed Learning", "abstract": "The ubiquity of distributed machine learning (ML) in sensitive public domain applications calls for algorithms that protect data privacy, while being robust to faults and adversarial behaviors. Alt..."}}
{"id": "ZpN6VKD63EL", "cdate": 1672531200000, "mdate": 1695983479642, "content": {"title": "Robust Distributed Learning: Tight Error Bounds and Breakdown Point under Data Heterogeneity", "abstract": "The theory underlying robust distributed learning algorithms, designed to resist adversarial machines, matches empirical observations when data is homogeneous. Under data heterogeneity however, which is the norm in practical scenarios, established lower bounds on the learning error are essentially vacuous and greatly mismatch empirical observations. This is because the heterogeneity model considered is too restrictive and does not cover basic learning tasks such as least-squares regression. We consider in this paper a more realistic heterogeneity model, namely (G,B)-gradient dissimilarity, and show that it covers a larger class of learning problems than existing theory. Notably, we show that the breakdown point under heterogeneity is lower than the classical fraction 1/2. We also prove a new lower bound on the learning error of any distributed learning algorithm. We derive a matching upper bound for a robust variant of distributed gradient descent, and empirically show that our analysis reduces the gap between theory and practice."}}
{"id": "KKfhszEi7T", "cdate": 1672531200000, "mdate": 1690897805418, "content": {"title": "Fixing by Mixing: A Recipe for Optimal Byzantine ML under Heterogeneity", "abstract": "Byzantine machine learning (ML) aims to ensure the resilience of distributed learning algorithms to misbehaving (or Byzantine) machines. Although this problem received significant attention, prior ..."}}
{"id": "D7jReRHUez", "cdate": 1672531200000, "mdate": 1679948936203, "content": {"title": "Distributed Learning with Curious and Adversarial Machines", "abstract": ""}}
{"id": "7OLSwgBV4Iy", "cdate": 1672531200000, "mdate": 1679948936199, "content": {"title": "Fixing by Mixing: A Recipe for Optimal Byzantine ML under Heterogeneity", "abstract": ""}}
{"id": "3wCi7cz0yep", "cdate": 1640995200000, "mdate": 1649236903222, "content": {"title": "Robust Sparse Voting", "abstract": "Many modern Internet applications, like content moderation and recommendation on social media, require reviewing and score a large number of alternatives. In such a context, the voting can only be sparse, as the number of alternatives is too large for any individual to review a significant fraction of all of them. Moreover, in critical applications, malicious players might seek to hack the voting process by entering dishonest reviews or creating fake accounts. Classical voting methods are unfit for this task, as they usually (a) require each reviewer to assess all available alternatives and (b) can be easily manipulated by malicious players. This paper defines precisely the problem of robust sparse voting, highlights its underlying technical challenges, and presents Mehestan, a novel voting mechanism that solves the problem. Namely, we prove that by using Mehestan, no (malicious) voter can have more than a small parametrizable effect on each alternative's score, and we identify conditions of voters comparability under which any unanimous preferences can be recovered, even when these preferences are expressed by voters on very different scales."}}
{"id": "6LdVhb4M9FO", "cdate": 1609459200000, "mdate": 1649236903237, "content": {"title": "Further results on latent discourse models and word embeddings", "abstract": "We discuss some properties of generative models for word embeddings. Namely, (Arora & Al., 2016) proposed a latent discourse model implying the concentration of the partition function of the word vectors. This concentration phenomenon led to an asymptotic linear relation between the pointwise mutual information (PMI) of pairs of words and the scalar product of their vectors. Here, we first revisit this concentration phenomenon and prove it under slightly weaker assumptions, for a set of random vectors symmetrically distributed around the origin. Second, we empirically evaluate the relation between PMI and scalar products of word vectors satisfying the concentration property. Our empirical results indicate that, in practice, this relation does not hold with arbitrarily small error. This observation is further supported by two theoretical results: (i) the error cannot be exactly zero because the corresponding shifted PMI matrix cannot be positive semidefinite; (ii) under mild assumptions, there exist pairs of words for which the error cannot be close to zero. We deduce that either natural language does not follow the assumptions of the considered generative model, or the current word vector generation methods do not allow the construction of the hypothesized word embeddings."}}
