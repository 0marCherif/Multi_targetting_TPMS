{"id": "wa42N8siZ7G", "cdate": 1667401235795, "mdate": 1667401235795, "content": {"title": "DLME: Deep Local-flatness Manifold Embedding", "abstract": "Manifold learning (ML) aims to seek low-dimensional embedding from high-dimensional data. The problem is challenging on real-world datasets, especially with under-sampling data, and we find that previous methods perform poorly in this case. Generally, ML methods first transform input data into a low-dimensional embedding space to maintain the data's geometric structure and subsequently perform downstream tasks therein. The poor local connectivity of under-sampling data in the former step and inappropriate optimization objectives in the latter step leads to two problems: structural distortion and underconstrained embedding. This paper proposes a novel ML framework named Deep Local-flatness Manifold Embedding (DLME) to solve these problems. The proposed DLME constructs semantic manifolds by data augmentation and overcomes the structural distortion problem using a smoothness constrained based on a local flatness assumption about the manifold. To overcome the underconstrained embedding problem, we design a loss and theoretically demonstrate that it leads to a more suitable embedding based on the local flatness. Experiments on three types of datasets (toy, biological, and image) for various downstream tasks (classification, clustering, and visualization) show that our proposed DLME outperforms state-of-the-art ML and contrastive learning methods."}}
{"id": "LOTGOB5_Xh2", "cdate": 1663850093951, "mdate": null, "content": {"title": "Architecture-Agnostic Masked Image Modeling -- From ViT back to CNN", "abstract": "Masked image modeling (MIM), an emerging self-supervised pre-training method, has shown impressive success across numerous downstream vision tasks with Vision transformers (ViTs). Its underlying idea is simple: a portion of the input image is randomly masked out and then reconstructed via the pre-text task. However, the working principle behind MIM is not well explained, and previous studies insist that MIM primarily works for the Transformer family but is incompatible with CNNs. In this paper, we first study interactions among patches to understand what knowledge is learned and how it is acquired via the MIM task. We observe that MIM essentially teaches the model to learn better middle-order interactions among patches and extract more generalized features. Based on this fact, we propose an Architecture-Agnostic Masked Image Modeling framework (A$^2$MIM), which is compatible with both Transformers and CNNs in a unified way. Extensive experiments on popular benchmarks show that our A$^2$MIM learns better representations without explicit design and endows the backbone model with the stronger capability to transfer to various downstream tasks for both Transformers and CNNs."}}
{"id": "vny63BYDCS", "cdate": 1663850078189, "mdate": null, "content": {"title": "NSCL: Noise-Resistant Soft Contrastive Learning for Universal Domain Adaptation", "abstract": "Domain adaptation (DA) transfers knowledge from label-rich domains to new domains where labels are scarce to address the problem of generalization of deep neural networks in new domains. Universal domain adaptation (UNDA) assumes the label distributions of labeled and unlabeled data are different and unknowable. In this paper, we concentrate on solving the noise problem on the UNDA problem based on contrastive learning (CL), which includes view noise in data augmentation and label noise in the classifier training. The domain differences in UNDA amplify the noise in the view of data augmentation, resulting in data augmentation schemes that apply to all domains being challenging to find. In addition, the mainstream UNDA classifiers combine closed-set classifiers with open-set classifiers; insufficient competition among open-set classifiers leads to overconfidence, which results in incredible sensitivity to noise in labeled data. Therefore, we propose Noise-Resistant Soft Contrastive Learning (NSCL) addresses the above issues. Firstly, we propose a soft contrast learning loss to avoid the over-response of typical CL loss to noisy samples, thus enabling data augmentation to improve the performance of UNDA further. Secondly, we design an all-in-one (AIO) classifier to improve the robustness of noisy labels while introducing multi-category unknown class competition. Extensive experimental results on UNDA and open\u0002set DA demonstrate the advantages of NSCL over existing methods, especially in downstream tasks such as classification and visualization."}}
{"id": "km2lP70ds-0", "cdate": 1663849982881, "mdate": null, "content": {"title": "Boosting Discriminative Visual Representation Learning with Scenario-Agnostic Mixup", "abstract": "Mixup is a popular data-dependent augmentation technique for deep neural networks, which contains two sub-tasks, mixup generation, and classification. The community typically confines mixup to supervised learning (SL) and the objective of the generation sub-task is fixed to selected sample pair instead of considering the whole data manifold. To overcome such limitations, we systematically study the mixup generation objective and propose Scenario-Agnostic Mixup for both SL and Self-supervised Learning (SSL) scenarios, named SAMix. Specifically, we hypothesize and verify the objective function of mixup generation as optimizing local smoothness between two mixed classes subject to global discrimination from other classes. Therefore, we propose \u03b7-balanced mixup loss for complementary learning of the two sub-objectives. Meanwhile, we parameterize the generation sub-task as a learnable sub-network, Mixer, with mixing attention which avoids trivial solutions and improves transferable abilities. To eliminate the computational cost of online training, we introduce a pre-trained version, SAMixP , that achieves efficient performance in various tasks. Extensive experiments on SL and SSL benchmarks demonstrate that SAMix consistently outperforms leading methods."}}
{"id": "GOEpRos3w0L", "cdate": 1663849866023, "mdate": null, "content": {"title": "TopoZero: Digging into  Topology Alignment on Zero-Shot Learning", "abstract": "Common space learning, associating semantic and visual domains in a common\nlatent space, is essential to transfer knowledge from seen classes to unseen ones\non Zero-Shot Learning (ZSL) realm. Existing methods for common space learning\nrely heavily on structure alignment due to the heterogeneous nature between\nsemantic and visual domains, but the existing design is sub-optimal. In this paper,\nwe utilize persistent homology to investigate geometry structure alignment,\nand observe two following issues: (i) The sampled mini-batch data points present\na distinct structure gap compared to global data points, thus the learned structure\nalignment space inevitably neglects abundant and accurate global structure\ninformation. (ii) The latent visual and semantic space fail to preserve multiple\ndimensional geometry structure, especially high dimensional structure information.\nTo address the first issue, we propose a Topology-guided Sampling Strategy\n(TGSS) to mitigate the gap between sampled and global data points. Both theoretical\nanalyses and empirical results guarantee the effectiveness of the TGSS.\nTo solve the second issue, we introduce a Topology Alignment Module (TAM)\nto preserve multi-dimensional geometry structure in latent visual and semantic\nspace, respectively. The proposed method is dubbed TopoZero. Empirically, our\nTopoZero achieves superior performance on three authoritative ZSL benchmark\ndatasets."}}
{"id": "NkJOhtNKX91", "cdate": 1663849865908, "mdate": null, "content": {"title": "DamoFD: Digging into Backbone Design on Face Detection", "abstract": "Face detection (FD) has achieved remarkable success over the past few years, yet,\nthese leaps often arrive when consuming enormous computation costs. Moreover,\nwhen considering a realistic situation, i.e., building a lightweight face detector\nunder a computation-scarce scenario, such heavy computation cost limits the application\nof the face detector. To remedy this, several pioneering works design\ntiny face detectors through off-the-shelf neural architecture search (NAS) technologies,\nwhich are usually applied to the classification task. Thus, the searched\narchitectures are sub-optimal for the face detection task since some design criteria\nbetween detection and classification task are different. As a representative, the\nface detection backbone design needs to guarantee the stage-level detection ability\nwhile it is not required for the classification backbone. Furthermore, the detection\nbackbone consumes a vast body of inference budgets in the whole detection framework.\nConsidering the intrinsic design requirement and the virtual importance role\nof the face detection backbone, we thus ask a critical question: How to employ\nNAS to search FD-friendly backbone architecture? To cope with this question,\nwe propose a distribution-dependent stage-aware ranking score (DDSAR-Score)\nto explicitly characterize the stage-level expressivity and identify the individual\nimportance of each stage, thus satisfying the aforementioned design criterion of\nthe FD backbone. Based on our proposed DDSAR-Score, we conduct comprehensive\nexperiments on the challenging Wider Face benchmark dataset and achieve\ndominant performance across a wide range of compute regimes. In particular,\ncompared to the tiniest face detector SCRFD-0.5GF, our method is +2.5 % better\nin Average Precision (AP) score when using the same amount of FLOPs. The\ncode is avaliable at https://github.com/ly19965/FaceMaas/tree/master/face_project/face_detection/DamoFD."}}
{"id": "q5ru7alcpfM", "cdate": 1632875502023, "mdate": null, "content": {"title": "Unsupervised Domain Adaptation  By Optimal Transportation  Of Clusters Between Domains", "abstract": "Unsupervised domain adaptation (UDA) aims to transfer the knowledge from a labeled source domain to an unlabeled target domain. Typically, to guarantee desirable knowledge transfer, aligning the distribution  between source and target domain from a global perspective is widely adopted in UDA. Recent researchers further point out the importance of local-level alignment and borrow the experience from Optimal Transport (OT) theory to construct instance-pair alignment.\n However, existing OT-based algorithms are limited to resolve class imbalance challenge and require a huge computation cost when considering a  large-scale training situation. \nIn this paper, we address these two issues by proposing a Clustering-based Optimal Transport (COT) algorithm, which formulates the alignment procedure as an Optimal Transport problem by capturing the fine-grained attribute alignment. Concretely, COT innovatively designs the loss derived from discrete Kantorovich dual form to construct a mapping between clustering centers in source and target domain, which simultaneously eliminates the negative effect brought by class imbalance and reduces the computation cost on the basis of theoretical analysis. Finally, our COT together with some previous UDA methods achieve superior performance on several benchmarks. "}}
{"id": "NTObQ5Lz66U", "cdate": 1609459200000, "mdate": 1668074753048, "content": {"title": "Dash: Semi-Supervised Learning with Dynamic Thresholding", "abstract": "While semi-supervised learning (SSL) has received tremendous attentions in many machine learning tasks due to its successful use of unlabeled data, existing SSL algorithms use either all unlabeled ..."}}
{"id": "pWFndUPJiG", "cdate": 1546300800000, "mdate": 1668074753058, "content": {"title": "SoftTriple Loss: Deep Metric Learning Without Triplet Sampling", "abstract": "Distance metric learning (DML) is to learn the embeddings where examples from the same class are closer than examples from different classes. It can be cast as an optimization problem with triplet constraints. Due to the vast number of triplet constraints, a sampling strategy is essential for DML. With the tremendous success of deep learning in classifications, it has been applied for DML. When learning embeddings with deep neural networks (DNNs), only a mini-batch of data is available at each iteration. The set of triplet constraints has to be sampled within the mini-batch. Since a mini-batch cannot capture the neighbors in the original set well, it makes the learned embeddings sub-optimal. On the contrary, optimizing SoftMax loss, which is a classification loss, with DNN shows a superior performance in certain DML tasks. It inspires us to investigate the formulation of SoftMax. Our analysis shows that SoftMax loss is equivalent to a smoothed triplet loss where each class has a single center. In real-world data, one class can contain several local clusters rather than a single one, e.g., birds of different poses. Therefore, we propose the SoftTriple loss to extend the SoftMax loss with multiple centers for each class. Compared with conventional deep metric learning algorithms, optimizing SoftTriple loss can learn the embeddings without the sampling phase by mildly increasing the size of the last fully connected layer. Experiments on the benchmark fine-grained data sets demonstrate the effectiveness of the proposed loss function."}}
