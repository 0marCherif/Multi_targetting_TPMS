{"id": "tJBYkwVDv5", "cdate": 1652737763432, "mdate": null, "content": {"title": "Finite Sample Analysis Of Dynamic Regression Parameter Learning", "abstract": "We consider the dynamic linear regression problem, where the predictor vector may vary with time. This problem can be modeled as a linear dynamical system, with non-constant observation operator, where the parameters that need to be learned are the variance of both the process noise and the observation noise. While variance estimation for dynamic regression is a natural problem, with a variety of applications, existing approaches to this problem either lack guarantees altogether, or only have asymptotic guarantees without explicit rates. In particular, existing literature does not provide any clues to the following  fundamental question: In terms of data characteristics, what does the convergence rate depend on?  In this paper we study the global system operator -- the operator that maps the  noise vectors to the output. We obtain estimates on its spectrum, and as a result derive the first known variance estimators with finite sample complexity guarantees. The proposed bounds depend on the shape of a certain spectrum related to the system operator, and thus provide the first known explicit geometric parameter of the data that can be used to bound estimation errors. In addition, the results hold for arbitrary sub Gaussian distributions of noise terms.  We evaluate the approach on synthetic and real-world benchmarks."}}
{"id": "D1l9g3fRqc5", "cdate": 1609459200000, "mdate": null, "content": {"title": "On the Implicit Bias of Initialization Shape: Beyond Infinitesimal Mirror Descent", "abstract": "Recent work has highlighted the role of initialization scale in determining the structure of the solutions that gradient methods converge to. In particular, it was shown that large initialization leads to the neural tangent kernel regime solution, whereas small initialization leads to so called \"rich regimes\". However, the initialization structure is richer than the overall scale alone and involves relative magnitudes of different weights and layers in the network. Here we show that these relative scales, which we refer to as initialization shape, play an important role in determining the learned model. We develop a novel technique for deriving the inductive bias of gradient-flow and use it to obtain closed-form implicit regularizers for multiple cases of interest."}}
{"id": "cYkydk0GnwQ", "cdate": 1577836800000, "mdate": null, "content": {"title": "Implicit Bias in Deep Linear Classification: Initialization Scale vs Training Accuracy", "abstract": "We provide a detailed asymptotic study of gradient flow trajectories and their implicit optimization bias when minimizing the exponential loss over \"diagonal linear networks\". This is the simplest model displaying a transition between \"kernel\" and non-kernel (\"rich\" or \"active\") regimes. We show how the transition is controlled by the relationship between the initialization scale and how accurately we minimize the training loss. Our results indicate that some limit behaviors of gradient descent only kick in at ridiculous training accuracies (well beyond $10^{-100}$). Moreover, the implicit bias at reasonable initialization scales and training accuracies is more complex and not captured by these limits."}}
{"id": "2ZvkzJRp0EC", "cdate": 1577836800000, "mdate": null, "content": {"title": "Implicit Bias in Deep Linear Classification: Initialization Scale vs Training Accuracy", "abstract": "We provide a detailed asymptotic study of gradient flow trajectories and their implicit optimization bias when minimizing the exponential loss over \"diagonal linear networks\". This is the simplest model displaying a transition between \"kernel\" and non-kernel (\"rich\" or \"active\") regimes. We show how the transition is controlled by the relationship between the initialization scale and how accurately we minimize the training loss. Our results indicate that some limit behavior of gradient descent only kick in at ridiculous training accuracies (well beyond 10^-100). Moreover, the implicit bias at reasonable initialization scales and training accuracies is more complex and not captured by these limits."}}
{"id": "Byg9bxrtwS", "cdate": 1569439745966, "mdate": null, "content": {"title": "Kernel and Rich Regimes in Overparametrized Models", "abstract": "A recent line of work studies overparametrized neural networks in the \"kernel regime,\" i.e. when the network behaves during training as a kernelized linear predictor, and thus training with gradient descent has the effect of finding the minimum RKHS norm solution.  This stands in contrast to other studies which demonstrate how gradient descent on overparametrized multilayer networks can induce rich implicit biases that are not RKHS norms.  Building on an observation by Chizat and Bach, we show how the scale of the initialization controls the transition between the \"kernel\" (aka lazy) and \"rich\" (aka active) regimes and affects generalization properties in multilayer homogeneous models.  We provide a complete and detailed analysis for a simple two-layer model that already exhibits an interesting and meaningful transition between the kernel and rich regimes, and we demonstrate the transition for more complex matrix factorization models and multilayer non-linear networks. "}}
