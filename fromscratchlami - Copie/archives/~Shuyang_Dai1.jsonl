{"id": "rkNvbsWObB", "cdate": 1546300800000, "mdate": null, "content": {"title": "Variational Annealing of GANs: A Langevin Perspective", "abstract": "The generative adversarial network (GAN) has received considerable attention recently as a model for data synthesis, without an explicit specification of a likelihood function. There has been comme..."}}
{"id": "r1Wi_3W_-H", "cdate": 1514764800000, "mdate": null, "content": {"title": "JointGAN: Multi-Domain Joint Distribution Learning with Generative Adversarial Nets", "abstract": "A new generative adversarial network is developed for joint distribution matching.Distinct from most existing approaches, that only learn conditional distributions, the proposed model aims to learn..."}}
{"id": "S1bYKUbObr", "cdate": 1514764800000, "mdate": null, "content": {"title": "Adversarial Text Generation via Feature-Mover's Distance", "abstract": "Generative adversarial networks (GANs) have achieved significant success in generating real-valued data. However, the discrete nature of text hinders the application of GAN to text-generation tasks. Instead of using the standard GAN objective, we propose to improve text-generation GAN via a novel approach inspired by optimal transport. Specifically, we consider matching the latent feature distributions of real and synthetic sentences using a novel metric, termed the feature-mover's distance (FMD). This formulation leads to a highly discriminative critic and easy-to-optimize objective, overcoming the mode-collapsing and brittle-training problems in existing methods. Extensive experiments are conducted on a variety of tasks to evaluate the proposed model empirically, including unconditional text generation, style transfer from non-parallel text, and unsupervised cipher cracking. The proposed model yields superior performance, demonstrating wide applicability and effectiveness."}}
