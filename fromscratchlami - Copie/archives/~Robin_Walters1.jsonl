{"id": "RaNAaxZfKi8", "cdate": 1686324872456, "mdate": null, "content": {"title": "One-shot Imitation Learning via Interaction Warping", "abstract": "Learning robot policies from few demonstrations is crucial in open-ended applications. We propose a new method, Interaction Warping, for one-shot learning SE(3) robotic manipulation policies. We infer the 3D mesh of each object in the environment using shape warping, a technique for aligning point clouds across object instances. Then, we represent manipulation actions as keypoints on objects, which can be warped with the shape of the object. We show successful one-shot imitation learning on three simulated and real-world object re-arrangement tasks. We also demonstrate the ability of our method to predict object meshes and robot grasps in the wild. Webpage: https://shapewarping.github.io."}}
{"id": "OFoo4631KAo", "cdate": 1685111486635, "mdate": null, "content": {"title": "Edge Grasp Network: A Graph-Based SE(3)-invariant Approach to Grasp Detection", "abstract": "Given point cloud input, the problem of 6-DoF grasp pose detection is to identify a set of hand poses in $\\SE(3)$ from which an object can be successfully grasped. This important problem has many practical applications. Here we propose a novel method and neural network model that enables better grasp success rates relative to what is available in the literature. The method takes standard point cloud data as input and works well with single-view point clouds observed from arbitrary viewing directions. Videos and code are available at \\url{https://haojhuang.github.io/edge_grasp_page/}."}}
{"id": "xewFUerf7l", "cdate": 1684115654053, "mdate": 1684115654053, "content": {"title": "Improving the generalizability of protein-ligand binding predictions with AI-Bind", "abstract": "Identifying novel drug-target interactions is a critical and rate-limiting step in drug discovery. While deep learning models have been proposed to accelerate the identification process, here we show that state-of-the-art models fail to generalize to novel (i.e., never-before-seen) structures. We unveil the mechanisms responsible for this shortcoming, demonstrating how models rely on shortcuts that leverage the topology of the protein-ligand bipartite network, rather than learning the node features. Here we introduce AI-Bind, a pipeline that combines network-based sampling strategies with unsupervised pre-training to improve binding predictions for novel proteins and ligands. We validate AI-Bind predictions via docking simulations and comparison with recent experimental evidence, and step up the process of interpreting machine learning prediction of protein-ligand binding by identifying potential active binding sites on the amino acid sequence. AI-Bind is a high-throughput approach to identify drug-target combinations with the potential of becoming a powerful tool in drug discovery."}}
{"id": "pKrOHg9PXtc", "cdate": 1676170032115, "mdate": null, "content": {"title": "Controlling Dynamic Spatial Light Modulators using Equivariant Neural Networks", "abstract": "Spatial Light Modulators (SLMs) are devices that can modulate the amplitude or the phase of a beam of light. These devices are used in applications such as beam front aberration and microscopic manipulation with optical tweezers. Here, we study the problem of learning to modulate light in a new type of temperature-controlled SLM. These SLMs are panels that use a thin viscous film in which shallow wave patterns can be induced by varying the temperature of the panel. This method can be used for modulating light such as high-power lasers. The problem here is to learn which input temperature signal is necessary in order to induce a given pattern in the reflected light. We propose a deep equivariant model to learn this relationship. We generate a synthetic dataset consisting of temperature signals and corresponding light patterns by simulating the thin film lubrication equation that governs the phenomenon of thermocapillary dewetting. We use this dataset to train our networks. We demonstrate the advantage of using equivariant neural networks over convolutional neural networks in order to learn the mapping. "}}
{"id": "UsYrDvLeJ0", "cdate": 1675970199456, "mdate": null, "content": {"title": "$\\mathrm{SE}(3)$ Frame Equivariance in Dynamics Modeling and Reinforcement Learning", "abstract": "In this paper, we aim to explore the potential of symmetries in improving the understanding of continuous control tasks in the 3D environment, such as locomotion. \nThe existing work in reinforcement learning on symmetry focuses on pixel-level symmetries in 2D environments or is limited to value-based planning. \nInstead, we considers continuous state and action spaces and continuous symmetry groups, focusing on translational and rotational symmetries.\nWe propose a pipeline to use these symmetries in learning dynamics and control, with the goal of exploiting the underlying symmetry structure to improve dynamics modeling and model-based planning."}}
{"id": "p4BnuQ7PNT", "cdate": 1672531200000, "mdate": 1683657059118, "content": {"title": "A General Theory of Correct, Incorrect, and Extrinsic Equivariance", "abstract": "Although equivariant machine learning has proven effective at many tasks, success depends heavily on the assumption that the ground truth function is symmetric over the entire domain matching the symmetry in an equivariant neural network. A missing piece in the equivariant learning literature is the analysis of equivariant networks when symmetry exists only partially in the domain. In this work, we present a general theory for such a situation. We propose pointwise definitions of correct, incorrect, and extrinsic equivariance, which allow us to quantify continuously the degree of each type of equivariance a function displays. We then study the impact of various degrees of incorrect or extrinsic symmetry on model error. We prove error lower bounds for invariant or equivariant networks in classification or regression settings with partially incorrect symmetry. We also analyze the potentially harmful effects of extrinsic equivariance. Experiments validate these results in three different environments."}}
{"id": "R02OKZmSeS", "cdate": 1672531200000, "mdate": 1681682205065, "content": {"title": "Generative Adversarial Symmetry Discovery", "abstract": "Despite the success of equivariant neural networks in scientific applications, they require knowing the symmetry group a priori. However, it may be difficult to know which symmetry to use as an inductive bias in practice. Enforcing the wrong symmetry could even hurt the performance. In this paper, we propose a framework, LieGAN, to automatically discover equivariances from a dataset using a paradigm akin to generative adversarial training. Specifically, a generator learns a group of transformations applied to the data, which preserve the original distribution and fool the discriminator. LieGAN represents symmetry as interpretable Lie algebra basis and can discover various symmetries such as the rotation group $\\mathrm{SO}(n)$, restricted Lorentz group $\\mathrm{SO}(1,3)^+$ in trajectory prediction and top-quark tagging tasks. The learned symmetry can also be readily used in several existing equivariant neural networks to improve accuracy and generalization in prediction."}}
{"id": "DeNbkUib9I", "cdate": 1672531200000, "mdate": 1681842533528, "content": {"title": "Image to Sphere: Learning Equivariant Features for Efficient Pose Prediction", "abstract": "Predicting the pose of objects from a single image is an important but difficult computer vision problem. Methods that predict a single point estimate do not predict the pose of objects with symmetries well and cannot represent uncertainty. Alternatively, some works predict a distribution over orientations in $\\mathrm{SO}(3)$. However, training such models can be computation- and sample-inefficient. Instead, we propose a novel mapping of features from the image domain to the 3D rotation manifold. Our method then leverages $\\mathrm{SO}(3)$ equivariant layers, which are more sample efficient, and outputs a distribution over rotations that can be sampled at arbitrary resolution. We demonstrate the effectiveness of our method at object orientation prediction, and achieve state-of-the-art performance on the popular PASCAL3D+ dataset. Moreover, we show that our method can model complex object symmetries, without any modifications to the parameters or loss function. Code is available at https://dmklee.github.io/image2sphere."}}
{"id": "JvcLG3eek70", "cdate": 1664194183532, "mdate": null, "content": {"title": "Charting Flat Minima Using the Conserved Quantities of Gradient Flow", "abstract": "Empirical studies have revealed that many minima in the loss landscape of deep learning are connected and reside on a low-loss valley. We present a general framework for finding continuous symmetries in the parameter space, which give rise to the low-loss valleys. We introduce a novel set of nonlinear, data-dependent symmetries for neural networks. We then show that conserved quantities associated with linear symmetries can be used to define coordinates along the minima. The distribution of conserved quantities reveals that using common initialization methods, gradient flow only explores a small part of the global minimum. By relating conserved quantities to convergence rate and sharpness of the minimum, we provide insights on how initialization impacts convergence and generalizability. We also find the nonlinear action to be viable for ensemble building to improve robustness under certain adversarial attacks."}}
{"id": "s3vd1i471Rc", "cdate": 1664194170749, "mdate": null, "content": {"title": "Understanding Optimization Challenges when Encoding to Geometric Structures", "abstract": "Geometric inductive biases such as spatial curvature, factorizability, or equivariance have been shown to enable learning of latent spaces which better reflect the structure of data and perform better on downstream tasks. Training such models, however, can be a challenging task due to the topological constraints imposed by encoding to such structures. In this paper, we theoretically and empirically characterize obstructions to training autoencoders with geometric latent spaces. These include issues such as singularity (e.g. self-intersection), incorrect degree or winding number, and non-isometric homeomorphic embedding. We propose a method, isometric autoencoder, to improve the stability of training and convergence to an isometric mapping in geometric latent spaces. We perform an empirical evaluation of this method over 2 domains, which demonstrates that our approach can better circumvent the identified optimization problems."}}
