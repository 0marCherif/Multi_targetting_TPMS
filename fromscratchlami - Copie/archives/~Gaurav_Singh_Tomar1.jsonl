{"id": "EKwH-BMlkzq", "cdate": 1654191669286, "mdate": null, "content": {"title": "Dungeons and Dragons as a Dialogue Challenge for Artificial Intelligence", "abstract": "AI researchers have posited Dungeons and Dragons (D\\&D) as a challenge problem to test systems on various language-related capabilities. In this paper, we frame D\\&D specifically as a dialogue system challenge, where the tasks are to both generate the next conversational turn in the game and predict the state of the game given the dialogue history.  We create a gameplay dataset consisting of nearly 900 games, with a total of 7,000 players, 800,000 dialogue turns, 500,000 dice rolls, and 58 million words.  We automatically annotate the data with partial state information about the game play.  We train a large language model to generate the next game turn, conditioning it on different information.  The LM can respond as a particular character or as the player who runs the game\u2014i.e., the Dungeon Master (DM). It is trained to produce dialogue that is either in-character (roleplaying in the fictional world) or out-of-character (discussing rules or strategy).  We perform a human evaluation to determine what factors make the generated output plausible and interesting.  We further perform an automatic evaluation to determine how well the model can predict the game state given the history and examine how well tracking the game state improves its ability to produce plausible conversational output.  "}}
{"id": "BJe-_CNKPH", "cdate": 1569439337172, "mdate": null, "content": {"title": "Attention Interpretability Across NLP Tasks", "abstract": "The attention layer in a neural network model provides insights into the model\u2019s reasoning behind its prediction, which are usually criticized for being opaque. Recently, seemingly contradictory viewpoints have emerged about the interpretability of attention weights (Jain & Wallace, 2019; Vig & Belinkov, 2019). Amid such confusion arises the need to understand attention mechanism more systematically. In this work, we attempt to fill this gap by giving a comprehensive explanation which justifies both kinds of observations (i.e., when is attention interpretable and when it is not). Through a series of experiments on diverse NLP tasks, we validate our observations and reinforce our claim of interpretability of attention through manual evaluation."}}
{"id": "Byl5NREFDr", "cdate": 1569439281560, "mdate": null, "content": {"title": "Thieves on Sesame Street! Model Extraction of BERT-based APIs", "abstract": "We study the problem of model extraction in natural language processing, in which an adversary with only query access to a victim model attempts to reconstruct a local copy of that model. Assuming that both the adversary and victim model fine-tune a large pretrained language model such as BERT (Devlin et al., 2019), we show that the adversary does not need any real training data to successfully mount the attack. In fact, the attacker need not even use grammatical or semantically meaningful queries: we show that random sequences of words coupled with task-specific heuristics form effective queries for model extraction on a diverse set of NLP tasks, including natural language inference and question answering. Our work thus highlights an exploit only made feasible by the shift towards transfer learning methods within the NLP community: for a query budget of a few hundred dollars, an attacker can extract a model that performs only slightly worse than the victim model. Finally, we study two defense strategies against model extraction\u2014membership classification and API watermarking\u2014which while successful against some adversaries can also be circumvented by more clever ones."}}
{"id": "rkgc06VtwH", "cdate": 1569439186459, "mdate": null, "content": {"title": "Improving Semantic Parsing with Neural Generator-Reranker Architecture", "abstract": "Semantic parsing is the problem of deriving machine interpretable meaning representations from natural language utterances. Neural models with encoder-decoder architectures have recently achieved substantial improvements over traditional methods. Although neural semantic parsers appear to have relatively high recall using large beam sizes, there is room for improvement with respect to one-best precision. In this work, we propose a generator-reranker architecture for semantic parsing. The generator produces a list of potential candidates and the reranker, which consists of a pre-processing step for the candidates followed by a novel critic network, reranks these candidates based on the similarity between each candidate and the input sentence. We show the advantages of this approach along with how it improves the parsing performance through extensive analysis. We experiment our model on three semantic parsing datasets (GEO, ATIS, and OVERNIGHT). The overall architecture achieves the state-of-the-art results in all three datasets. "}}
{"id": "By-F0ZMubB", "cdate": 1483228800000, "mdate": null, "content": {"title": "Neural Paraphrase Identification of Questions with Noisy Pretraining", "abstract": "We present a solution to the problem of paraphrase identification of questions. We focus on a recent dataset of question pairs annotated with binary paraphrase labels and show that a variant of the decomposable attention model (Parikh et al., 2016) results in accurate performance on this task, while being far simpler than many competing neural architectures. Furthermore, when the model is pretrained on a noisy dataset of automatically collected question paraphrases, it obtains the best reported performance on the dataset."}}
