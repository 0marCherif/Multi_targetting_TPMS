{"id": "sRJUiGwuNP", "cdate": 1672531200000, "mdate": 1682324493609, "content": {"title": "Learning Latent Structural Relations with Message Passing Prior", "abstract": "Learning disentangled representations is an important topic in machine learning with a wide range of applications. Disentangled latent variables represent interpretable semantic information and reflect separate factors of variation in data. Although generative models can learn latent representations as well, most existing models ignore the structural information among latent variables. In this paper, we propose a novel approach to learn the disentangled latent structural representations from data using decomposable variational auto-encoders. We design a novel message passing prior for the latent representations to capture the interactions among different data components. Different from many previous methods that ignore data component or object interaction, our approach simultaneously learns component representation and encodes component relationships. We have applied our model to tasks of data segmentation and latent representation learning among different data components. Experiments on several benchmarks demonstrate the utility of the proposed method."}}
{"id": "qhO6xjQuE5", "cdate": 1640995200000, "mdate": 1682324493790, "content": {"title": "Causal Effect Prediction with Flow-based Inference", "abstract": "Causal effect inference has many applications in data analysis and predictions, e.g., user behavior modeling, medical treatment effect prediction, etc. We introduce a new method to perform causal effect inference using flow-based latent-variable models. Our method leverages the expressive power of flow-based models and tries to recover the complex relationship between observations and unobserved confounders. A methodology has been developed to perform causal effect inference along with theoretical analysis. Experimental studies are presented to verify the proposed approach. Empirical results show that the proposed method outperforms baselines on different datasets."}}
{"id": "ejIUaeHkw_", "cdate": 1640995200000, "mdate": 1682324493414, "content": {"title": "Variational Flow Graphical Model", "abstract": "This paper introduces a novel approach to embed flow-based models with hierarchical structures. The proposed framework is named Variational Flow Graphical (VFG) Model. VFGs learn the representation of high dimensional data via a message-passing scheme by integrating flow-based functions through variational inference. By leveraging the expressive power of neural networks, VFGs produce a representation of the data using a lower dimension, thus overcoming the drawbacks of many flow-based models, usually requiring a high dimensional latent space involving many trivial variables. Aggregation nodes are introduced in the VFG models to integrate forward-backward hierarchical information via a message passing scheme. Maximizing the evidence lower bound (ELBO) of data likelihood aligns the forward and backward messages in each aggregation node achieving a consistency node state. Algorithms have been developed to learn model parameters through gradient updating regarding the ELBO objective. The consistency of aggregation nodes enable VFGs to be applicable in tractable inference on graphical structures. Besides representation learning and numerical inference, VFGs provide a new approach for distribution modeling on datasets with graphical latent structures. Additionally, theoretical study shows that VFGs are universal approximators by leveraging the implicitly invertible flow-based structures. With flexible graphical structures and superior excessive power, VFGs could potentially be used to improve probabilistic inference. In the experiments, VFGs achieves improved evidence lower bound (ELBO) and likelihood values on multiple datasets."}}
{"id": "8Xf8Uh832n", "cdate": 1640995200000, "mdate": 1682324493394, "content": {"title": "Calibrating CNNs for Few-Shot Meta Learning", "abstract": "Although few-shot meta learning has been extensively studied in machine learning community, the fast adaptation towards new tasks remains a challenge in the few-shot learning scenario. The neuroscience research reveals that the capability of evolving neural network formulation is essential for task adaptation, which has been broadly studied in recent meta-learning researches. In this paper, we present a novel forward-backward meta-learning framework (FBM) to facilitate the model generalization in few-shot learning from a new perspective, i.e., neuron calibration. In particular, FBM models the neurons in deep neural network-based model as calibrated units under a general formulation, where neuron calibration could empower fast adaptation capability to the neural network-based models through influencing both their forward inference path and backward propagation path. The proposed calibration scheme is lightweight and applicable to various feed-forward neural network architectures. Extensive empirical experiments on the challenging few-shot learning benchmarks validate that our approach training with neuron calibration achieves a promising performance, which demonstrates that neuron calibration plays a vital role in improving the few-shot learning performance."}}
{"id": "751dN4w_Zrl", "cdate": 1640995200000, "mdate": 1682324493428, "content": {"title": "Variational Flow Graphical Model", "abstract": "This paper introduces a novel approach embedding flow-based models in hierarchical structures. The proposed model learns the representation of high-dimensional data via a message-passing scheme by integrating flow-based functions through variational inference. Meanwhile, our model produces a representation of the data using a lower dimension, thus overcoming the drawbacks of many flow-based models, usually requiring a high dimensional latent space involving many trivial variables. With the proposed aggregation nodes, our model provides a new approach for distribution modeling and numerical inference on datasets. Multiple experiments on synthetic and real-world datasets show the benefits of our~proposed~method and potentially broad applications."}}
{"id": "28r132Mehkm", "cdate": 1640995200000, "mdate": 1682324493364, "content": {"title": "Flow-based Perturbation for Cause-effect Inference", "abstract": "A new causal discovery method is introduced to solve the bivariate causal discovery problem. The proposed algorithm leverages the expressive power of flow-based models and tries to learn the complex relationship between two variables. Algorithms have been developed to infer the causal direction according to empirical perturbation errors obtained from an invertible flow-based function. Theoretical results as well as experimental studies are presented to verify the proposed approach. Empirical evaluations demonstrate that our proposed method could outperform baseline methods on both synthetic and real-world datasets."}}
{"id": "fZdSigpgPy", "cdate": 1609459200000, "mdate": 1682324493351, "content": {"title": "A Deep Decomposable Model for Disentangling Syntax and Semantics in Sentence Representation", "abstract": ""}}
{"id": "3vDimF-MZO", "cdate": 1609459200000, "mdate": 1682324493553, "content": {"title": "Causal Discovery with Flow-based Conditional Density Estimation", "abstract": "Causal-effect discovery plays an essential role in many disciplines of science and real-world applications. In this paper, we introduce a new causal discovery method to solve the classic problem of inferring the causal direction under a bivariate setting. In particular, our proposed method first leverages a flow model to estimate the joint probability density of the variables. Then we formulate a novel evaluation metric to infer the scores for each potential causal direction based on the variance of the conditional density estimation. By leveraging the flow-based conditional density estimation metric, our causal discovery approach alleviates the restrictive assumptions made by the conventional methods, such as assuming the linearity relationship between the two variables. Therefore, it could potentially be able to better capture the complex causal relationship among data in various problem domains that comes in arbitrary forms. We conduct extensive evaluations to compare our method with decent causal discovery approaches. Empirical results show that our method could promisingly outperform the baseline methods with noticeable margins on both synthetic and real-world datasets."}}
{"id": "JgFJwhxnw6", "cdate": 1577836800000, "mdate": 1682324493548, "content": {"title": "Thunder: a Fast Coordinate Selection Solver for Sparse Learning", "abstract": "L1 regularization has been broadly employed to pursue model sparsity. Despite the non-smoothness, people have developed efficient algorithms by leveraging the sparsity and convexity of the problems. In this paper, we propose a novel active incremental approach to further improve the efficiency of the solvers. We show that our method performs well even when the existing methods fail due to the low sparseness or high solution accuracy request. Theoretical analysis and experimental results on synthetic and real-world data sets validate the advantages of the method."}}
{"id": "GRWy_zF9iIC", "cdate": 1577836800000, "mdate": null, "content": {"title": "Estimate the Implicit Likelihoods of GANs with Application to Anomaly Detection", "abstract": "The thriving of deep models and generative models provides approaches to model high dimensional distributions. Generative adversarial networks\u00a0(GANs) can approximate data distributions and generate data samples from the learned data manifolds as well. In this paper, we propose an approach to estimate the implicit likelihoods of GAN models. A stable inverse function of the generator can be learned with the help of a variance network of the generator. The local variance of the sample distribution can be approximated by the normalized distance in the latent space. Simulation studies and likelihood testing on real-world data sets validate the proposed algorithm, which outperforms several baseline methods in these tasks. The proposed method has been further applied to anomaly detection. Experiments show that the method can achieve state-of-the-art anomaly detection performance on real-world data sets."}}
