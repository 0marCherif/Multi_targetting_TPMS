{"id": "AGsHRGRfGE3", "cdate": 1651150740508, "mdate": 1651150740508, "content": {"title": "Class Incremental Online Streaming Learning", "abstract": "A wide variety of methods have been developed to enable lifelong learning in conventional deep neural networks. However, to succeed, these methods require a \u2018batch\u2019 of samples to be available and visited multiple times during training. While this works well in a static setting, these methods continue to suffer in a more realistic situation where data arrives in online streaming manner. We empirically\ndemonstrate that the performance of current approaches degrades if the input is obtained as a stream of data with the following restrictions: (i) each instance comes one at a time and can be seen only once, and (ii) the input data violates the i.i.d assumption, i.e., there can be a class-based correlation. We propose a novel approach (CIOSL) for the class-incremental learning in an online streaming setting to address these challenges. The proposed approach leverages implicit and explicit dual weight regularization and experience replay. The implicit regularization is leveraged via the knowledge distillation, while the explicit regularization incorporates a novel approach for parameter regularization by learning the joint distribution of the buffer replay and the current sample. Also, we propose an efficient online memory replay and replacement buffer strategy that significantly boosts the model\u2019s performance. Extensive experiments and ablation on challenging datasets show the efficacy of the proposed method"}}
{"id": "9rcN5Bpld-l", "cdate": 1651150572173, "mdate": 1651150572173, "content": {"title": "SISL:Self-Supervised Image Signature Learning for Splicing Detection & Localization", "abstract": "Recent algorithms for image manipulation detection almost exclusively use deep network models. These approaches require either dense pixelwise groundtruth masks, camera ids, or image metadata to train the networks. On one hand, constructing a training set to represent the countless tampering possibilities is impractical. On the other hand, social media platforms or commercial applications are often constrained to remove camera ids as well as metadata from images. A self-supervised algorithm for training manipulation detection models without dense groundtruth or camera/image metadata would be extremely useful for many forensics applications. In this paper, we\npropose self-supervised approach for training splicing detection/localization models from frequency transforms of images. To identify the spliced regions, our deep network learns a representation to capture an image specific signature by enforcing (image) self consistency . We experimentally demonstrate that our proposed model can yield similar or better performances of multiple existing methods on\nstandard datasets without relying on labels or metadata"}}
{"id": "C0sRxNIjtqk", "cdate": 1651150379140, "mdate": 1651150379140, "content": {"title": "Multilayer Dense Connections for Hierarchical Concept Prediction", "abstract": "Multinomial logistic regression with a single final layer of dense connections has become the ubiquitous technique for CNN-based classification. While these classifiers project a mapping between the input and a set of output category classes, they do not typically yield a comprehensive description of the category. In particular, when a CNN based image classifier correctly identifies the image of a\nChimpanzee, its output does not clarify that Chimpanzee is a member of Primate, Mammal, Chordate families and a living thing. We propose a multilayer dense connectivity for concurrent prediction of category and its conceptual superclasses in hierarchical order by the same CNN. We experimentally demonstrate that our proposed network can simultaneously predict both the coarse superclasses and finer\ncategories better than several existing algorithms in multiple datasets."}}
{"id": "O9p9hKTaOl", "cdate": 1651150179976, "mdate": 1651150179976, "content": {"title": "Two Stream Active Query Suggestion for Active Learning in Connectomics", "abstract": "For large-scale vision tasks in biomedical images, the labeled data is often limited to train effective deep models. Active learning is a\ncommon solution, where a query suggestion method selects representative unlabeled samples for annotation, and the new labels are used to improve the base model. However, most query suggestion models optimize their learnable parameters only on the limited labeled data and consequently become less effective for the more challenging unlabeled data. To tackle this, we propose a two-stream active query suggestion approach. In addition to the supervised feature extractor, we introduce an unsupervised one optimized on all raw images to capture diverse image features, which can later be improved by fine-tuning on new labels. As a use case, we build an end-to-end active learning framework with our query suggestion method for 3D synapse detection and mitochondria segmentation in connectomics. With the framework, we curate, to our best knowledge, the largest connectomics dataset with dense synapses and mitochondria annotation. On this new dataset, our method outperforms previous stateof-the-art methods by 3.1% for synapse and 3.8% for mitochondria in terms of region-of-interest proposal accuracy. We also apply our method to image classification, where it outperforms previous approaches on\nCIFAR-10 under the same limited annotation budget. "}}
{"id": "NpkKIQAYNqv", "cdate": 1651149481249, "mdate": 1651149481249, "content": {"title": "VideoSSL: Semi-Supervised Learning for Video Classification", "abstract": "We propose a semi-supervised learning approach for video classification, VideoSSL, using convolutional neural networks (CNN). Like other computer vision tasks, existing supervised video classification methods demand a large amount of labeled data to attain good performance. However, annotation of a large dataset is expensive and time consuming. To minimize the dependence on a large anno-\ntated dataset, our proposed semi-supervised method trains from a small number of labeled examples and exploits two regulatory signals from unlabeled data. The first signal is the pseudo-labels of unlabeled examples computed from the confidences of the CNN being trained. The other is the normalized probabilities, as predicted by an image classifier CNN, that captures the information about appearances of\nthe interesting objects in the video. We show that, under the supervision of these guiding signals from unlabeled examples, a video classification CNN can achieve impressive performances utilizing a small fraction of annotated examples on three publicly available datasets: UCF101, HMDB51, and Kinetics."}}
{"id": "97m3gQZXp7i", "cdate": 1621278617429, "mdate": null, "content": {"title": "Efficient Correction for EM Connectomics with Skeletal Representation", "abstract": "Machine vision techniques for automatic neuron reconstruction from electron microscopy (EM) volumes have made tremendous advances in recent years. Nonetheless, large-scale reconstruction from teravoxels of EM volumes retains both under- and \noversegmentation errors. In this paper, we present an efficient correction algorithm for EM neuron reconstruction. Each region in a 3D segmentation is represented by its skeleton. We employ deep convolutional networks to detect and correct false merge and split errors at the joints and endpoints of the skeletal representation. Our algorithm can achieve the same or close accuracy of the state-of-the-art error correction algorithm by querying only at a tiny fraction of the volume. A reduction of the search space by several orders of magnitude enables our approach to be scalable for terabyte or petabyte scale neuron reconstruction."}}
{"id": "bBCd1_COA1p", "cdate": 1621278407620, "mdate": null, "content": {"title": "Parallel Separable 3D Convolution for Video and Volumetric Data Understanding", "abstract": "For video and volumetric data understanding, 3D convolution layers are widely used in deep learning, however, at the cost of increasing computation and training time. Recent works seek to replace the 3D convolution layer with convolution blocks, e.g. structured combinations of 2D and 1D convolution layers. In this paper, we propose a novel convolution block, Parallel Separable 3D Convolution (PmSCn), which applies m parallel streams of n 2D and one 1D convolution layers along different dimensions. We first mathematically justify the need of parallel streams (Pm) to replace a single 3D convolution layer through tensor decomposition. Then we jointly replace consecutive 3D convolution layers, common in modern network architectures, with the multiple 2D convolution layers (Cn). Lastly, we empirically show that PmSCn is applicable to different backbone architectures, such as ResNet, DenseNet, and UNet, for different applications, such as video action recognition, MRI brain segmentation, and electron microscopy segmentation. In all three applications, we replace the 3D convolution layers in state-of-theart models with PmSCn and achieve around 14% improvement in test performance and 40% reduction in model size and on average"}}
{"id": "otuxSY_QDZ9", "cdate": 1601308011743, "mdate": null, "content": {"title": "Multilayer Dense Connections for Hierarchical Concept Classification", "abstract": "Classification is a pivotal function for many computer vision tasks such as image recognition, object  detection, scene segmentation. Multinomial logistic regression with a single final layer of dense connections has become the ubiquitous technique for CNN-based classification. While these classifiers project a mapping between the input and a set of output category classes, they do not typically yield  a comprehensive description of the category. In particular, when a CNN based image classifier correctly identifies the image of a Chimpanzee, its output does not clarify that Chimpanzee is a member of Primate, Mammal, Chordate families and a living thing. We propose a multilayer dense connectivity for a CNN to simultaneously predict the category \\emph{and} its conceptual superclasses in hierarchical order. We experimentally demonstrate that our proposed dense connections, in conjunction with popular convolutional feature layers,  can learn to predict the  conceptual classes with minimal increase in network size while maintaining the categorical classification accuracy."}}
{"id": "HmNV32MedpB", "cdate": 1546300800000, "mdate": null, "content": {"title": "Biologically-Constrained Graphs for Global Connectomics Reconstruction.", "abstract": "Most current state-of-the-art connectome reconstruction pipelines have two major steps: initial pixel-based segmentation with affinity prediction and watershed transform, and refined segmentation by merging over-segmented regions. These methods rely only on local context and are typically agnostic to the underlying biology. Since a few merge errors can lead to several incorrectly merged neuronal processes, these algorithms are currently tuned towards over-segmentation producing an overburden of costly proofreading. We propose a third step for connectomics reconstruction pipelines to refine an over-segmentation using both local and global context with an emphasis on adhering to the underlying biology. We first extract a graph from an input segmentation where nodes correspond to segment labels and edges indicate potential split errors in the over-segmentation. In order to increase throughput and allow for large-scale reconstruction, we employ biologically inspired geometric constraints based on neuron morphology to reduce the number of nodes and edges. Next, two neural networks learn these neuronal shapes to further aid the graph construction process. Lastly, we reformulate the region merging problem as a graph partitioning one to leverage global context. We demonstrate the performance of our approach on four real-world connectomics datasets with an average variation of information improvement of 21.3%."}}
{"id": "S1NpdYbOZH", "cdate": 1514764800000, "mdate": null, "content": {"title": "Detecting Synapse Location and Connectivity by Signed Proximity Estimation and Pruning with Deep Nets", "abstract": "Synaptic connectivity detection is a critical task for neural reconstruction from Electron Microscopy (EM) data. Most of the existing algorithms for synapse detection do not identify the cleft location and direction of connectivity simultaneously. The few methods that computes direction along with contact location have only been demonstrated to work on either dyadic (most common in vertebrate brain) or polyadic (found in fruit fly brain) synapses, but not on both types. In this paper, we present an algorithm to automatically predict the location as well as the direction of both dyadic and polyadic synapses. The proposed algorithm first generates candidate synaptic connections from voxelwise predictions of signed proximity generated by a 3D U-net. A second 3D CNN then prunes the set of candidates to produce the final detection of cleft and connectivity orientation. Experimental results demonstrate that the proposed method outperforms the existing methods for determining synapses in both rodent and fruit fly brain. (Code at: https://github.com/paragt/EMSynConn )."}}
