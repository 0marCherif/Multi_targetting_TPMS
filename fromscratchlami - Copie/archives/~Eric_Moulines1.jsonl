{"id": "Ks8J_O5kT8m", "cdate": 1695981496156, "mdate": 1695981496156, "content": {"title": "Main effects and interactions in mixed and incomplete data frames", "abstract": "A mixed data frame (MDF) is a table collecting categorical, numerical, and count observations. The use of MDF is widespread in statistics and the applications are numerous from abundance data in ecology to recommender systems. In many cases, an MDF exhibits simultaneously main effects, such as row, column, or group effects and interactions, for which a low-rank model has often been suggested. Although the literature on low-rank approximations is very substantial, with few exceptions, existing methods do not allow to incorporate main effects and interactions while providing statistical guarantees. The present work fills this gap. We propose an estimation method which allows to recover simultaneously the main effects and the interactions. We show that our method is near optimal under conditions which are met in our targeted applications. We also propose an optimization algorithm which provably converges to an optimal solution. Numerical experiments reveal that our method, mimi, performs well when the main effects are sparse and the interaction matrix has low-rank. We also show that mimi compares favorably to existing methods, in particular when the main effects are significantly large compared to the interactions, and when the proportion of missing entries is large. The method is available as an R package on the Comprehensive R Archive Network. Supplementary materials for this article are available online."}}
{"id": "LAJV04icH0q", "cdate": 1695981424384, "mdate": 1695981424384, "content": {"title": "Low-rank model with covariates for count data with missing values", "abstract": "A complete methodology called LORI (Low-Rank Interaction), including a Poisson model, an algorithm, and an automatic selection of the regularization parameter, is proposed for the analysis of frequency tables with covariates, including an upper bound on the estimation error. A simulation study with synthetic data suggests that LORI improves empirically on state-of-the-art methods in terms of estimation and imputation. Illustrations show how the method can be interpreted through visual displays with the analysis of a well-known plant abundance data set, and the LORI outputs are seen to be consistent with known results. The relevance of the methodology is also demonstrated through the analysis of a waterbirds abundance contingency table from the French national agency for wildlife and hunting management. The method is available in the R package lori on the Comprehensive Archive Network (CRAN)."}}
{"id": "vi7-o8rLJV", "cdate": 1695981281218, "mdate": 1695981281218, "content": {"title": "A Patient-Specific Single Equivalent Dipole Model", "abstract": "Sophisticated models for the electrocardiographic inverse problem are available, but their reliance on imaging data and large numbers of electrodes limit their use.\nSimple models such as the single equivalent dipole model\n(SEDM) therefore remain relevant. We developed a probabilistic approach to the equivalent unbounded uniform\nsingle dipole problem and developed a natural extension\nto the bounded nonuniform case that relies on a patientspecific statistical inference of the propagation mechanism\nbetween the location of the dipole and the electrode locations. The two models were tested on data simulated with\na detailed heart-torso model with four different activation\nsequences and three different sets of tissue characteristics.\nWe observed a throughout enhancement of the ability to reconstruct the ECG of the patient-specific model when compared to the uniform unbounded dipole model."}}
{"id": "UqiiZ9Xdlrw", "cdate": 1665251223265, "mdate": null, "content": {"title": "Distributional deep Q-learning with CVaR regression", "abstract": "Reinforcement learning (RL) allows an agent interacting sequentially with an environment to maximize its long-term return, in expectation. In distributional RL (DRL), the agent is also interested in the probability distribution of the return, not just its expected value. This so-called distributional perspective of RL has led to new algorithms with improved empirical performance. In this paper, we recall the atomic DRL (ADRL) framework based on atomic distributions projected via the Wasserstein-2 metric. Then, we derive two new deep ADRL algorithms, namely SAD-Q-learning and MAD-Q-learning (both for the control task). Numerical experiments on various environments compare our approach against existing deep (distributional) RL methods."}}
{"id": "Yllpv4DrLcc", "cdate": 1652971137510, "mdate": 1652971137510, "content": {"title": "QLSD: Quantised Langevin Stochastic Dynamics for Bayesian Federated Learning", "abstract": "The objective of Federated Learning (FL) is to perform statistical inference for data which are decentralised and stored locally on networked clients. FL raises many constraints which include privacy and data ownership, communication overhead, statistical heterogeneity, and partial client participation. In this paper, we address these problems in the framework of the Bayesian paradigm. To this end, we propose a novel federated Markov Chain Monte Carlo algorithm, referred to as Quantised Langevin Stochastic Dynamics which may be seen as an extension to the FL setting of Stochastic Gradient Langevin Dynamics, which handles the communication bottleneck using gradient compression. To improve performance, we then introduce variance reduction techniques, which lead to two improved versions coined QLSD\u22c6 and QLSD++. We give both non-asymptotic and asymptotic convergence guarantees for the proposed algorithms. We illustrate their performances using various Bayesian Federated Learning benchmarks."}}
{"id": "v-RLAseRyz", "cdate": 1652971056312, "mdate": 1652971056312, "content": {"title": "DG-LMC: A Turn-key and Scalable Synchronous Distributed MCMC Algorithm via Langevin Monte Carlo within Gibbs", "abstract": "Performing reliable Bayesian inference on a big data scale is becoming a keystone in the modern era of machine learning. A workhorse class of methods to achieve this task are Markov chain Monte Carlo (MCMC) algorithms and their design to handle distributed datasets has been the subject of many works. However, existing methods are not completely either reliable or computationally efficient. In this paper, we propose to fill this gap in the case where the dataset is partitioned and stored on computing nodes within a cluster under a master/slaves architecture. We derive a user-friendly centralised distributed MCMC algorithm with provable scaling in high-dimensional settings. We illustrate the relevance of the proposed methodology on both synthetic and real data experiments."}}
{"id": "gvwDosudtyA", "cdate": 1652737692707, "mdate": null, "content": {"title": "Optimistic Posterior Sampling for Reinforcement Learning with Few Samples and Tight Guarantees", "abstract": "We consider reinforcement learning in an environment modeled by an episodic, tabular, step-dependent Markov decision process of horizon $H$ with $S$ states, and $A$ actions.  The performance of an agent is measured by the regret after interacting with the environment for $T$ episodes. We propose an optimistic posterior sampling algorithm for reinforcement learning (OPSRL), a simple variant of posterior sampling that only needs a number of posterior samples logarithmic in $H$, $S$, $A$, and $T$ per state-action pair. For OPSRL we guarantee a high-probability regret bound of order at most $O(\\sqrt{H^3SAT})$ ignoring $\\text{poly}\\log(HSAT)$ terms. The key novel technical ingredient is a new sharp anti-concentration inequality for linear forms of a Dirichlet random vector which may be of independent interest. Specifically, we extend the normal approximation-based lower bound for Beta distributions by Alfers and Dinges (1984) to Dirichlet distributions. Our bound matches the lower bound of order $\\Omega(\\sqrt{H^3SAT})$, thereby answering the open problems raised by Agrawal and Jia (2017) for the episodic setting. "}}
{"id": "KETwimTQexH", "cdate": 1652737510056, "mdate": null, "content": {"title": "FedPop: A Bayesian Approach for Personalised Federated Learning", "abstract": "Personalised federated learning (FL) aims at collaboratively learning a machine learning model tailored for each client. Albeit promising advances have been made in this direction, most of the existing approaches do not allow for uncertainty quantification which is crucial in many applications. In addition, personalisation in the cross-silo and cross-device setting still involves important issues, especially for new clients or those having a small number of observations. This paper aims at filling these gaps. To this end, we propose a novel methodology coined FedPop by recasting personalised FL into the population modeling paradigm where clients\u2019 models involve fixed common population parameters and random effects, aiming at explaining data heterogeneity. To derive convergence guarantees for our scheme, we introduce a new class of federated stochastic optimisation algorithms that relies on Markov chain Monte Carlo methods. Compared to existing personalised FL methods, the proposed methodology has important benefits: it is robust to client drift, practical for inference on new clients, and above all, enables uncertainty quantification under mild computational and memory overheads. We provide nonasymptotic convergence guarantees for the proposed algorithms and illustrate their performances on various personalised federated learning tasks."}}
{"id": "zb-xfApk4ZK", "cdate": 1652737460756, "mdate": null, "content": {"title": "Local-Global MCMC kernels: the best of both worlds", "abstract": "Recent works leveraging learning to enhance sampling have shown promising results, in particular by designing effective non-local moves and global proposals. However, learning accuracy is inevitably limited in regions where little data is available such as in the tails of distributions as well as in high-dimensional problems. In the present paper we study an Explore-Exploit Markov chain Monte Carlo strategy ($\\operatorname{Ex^2MCMC}$) that combines local and global samplers showing that it enjoys the advantages of both approaches. We prove $V$-uniform geometric ergodicity of $\\operatorname{Ex^2MCMC}$ without requiring a uniform adaptation of the global sampler to the target distribution. We also compute explicit bounds on the mixing rate of the Explore-Exploit strategy under realistic conditions. Moreover, we propose an adaptive version of the strategy ($\\operatorname{FlEx^2MCMC}$) where a normalizing flow is trained while sampling to serve as a proposal for global moves. We illustrate the efficiency of $\\operatorname{Ex^2MCMC}$ and its adaptive version on classical sampling benchmarks as well as in sampling high-dimensional distributions defined by Generative Adversarial Networks seen as Energy Based Models."}}
{"id": "HH_jBD2ObPq", "cdate": 1652737446106, "mdate": null, "content": {"title": "BR-SNIS: Bias Reduced Self-Normalized Importance Sampling", "abstract": "Importance Sampling (IS) is a method for approximating expectations with respect to a target distribution using independent samples from a proposal distribution and the associated to importance weights. In many cases, the target distribution is known up to a normalization constant and self-normalized IS (SNIS) is then used. While the use of self-normalization can have a positive effect on the dispersion of the estimator, it introduces bias. In this work, we propose a new method BR-SNIS whose complexity is essentially the same as SNIS and which significantly reduces bias. This method is a wrapper, in the sense that it uses the same proposal samples and importance weights but makes a clever use of iterated sampling-importance-resampling (i-SIR) to form a bias-reduced version of the estimator. We derive the proposed algorithm with rigorous theoretical results, including novel bias, variance, and high-probability bounds. We illustrate our findings with numerical examples."}}
