{"id": "UmUOWFmQ51", "cdate": 1672531200000, "mdate": 1708604368909, "content": {"title": "SEE-OoD: Supervised Exploration For Enhanced Out-of-Distribution Detection", "abstract": "Current techniques for Out-of-Distribution (OoD) detection predominantly rely on quantifying predictive uncertainty and incorporating model regularization during the training phase, using either real or synthetic OoD samples. However, methods that utilize real OoD samples lack exploration and are prone to overfit the OoD samples at hand. Whereas synthetic samples are often generated based on features extracted from training data, rendering them less effective when the training and OoD data are highly overlapped in the feature space. In this work, we propose a Wasserstein-score-based generative adversarial training scheme to enhance OoD detection accuracy, which, for the first time, performs data augmentation and exploration simultaneously under the supervision of limited OoD samples. Specifically, the generator explores OoD spaces and generates synthetic OoD samples using feedback from the discriminator, while the discriminator exploits both the observed and synthesized samples for OoD detection using a predefined Wasserstein score. We provide theoretical guarantees that the optimal solutions of our generative scheme are statistically achievable through adversarial training in empirical settings. We then demonstrate that the proposed method outperforms state-of-the-art techniques on various computer vision datasets and exhibits superior generalizability to unseen OoD data."}}
{"id": "XjALdTdqPi", "cdate": 1640995200000, "mdate": 1683882083359, "content": {"title": "Rethinking Cost-sensitive Classification in Deep Learning via Adversarial Data Augmentation", "abstract": "Cost-sensitive classification is critical in applications where misclassification errors widely vary in cost. However, over-parameterization poses fundamental challenges to the cost-sensitive modeling of deep neural networks (DNNs). The ability of a DNN to fully interpolate a training dataset can render a DNN, evaluated purely on the training set, ineffective in distinguishing a cost-sensitive solution from its overall accuracy maximization counterpart. This necessitates rethinking cost-sensitive classification in DNNs. To address this challenge, this paper proposes a cost-sensitive adversarial data augmentation (CSADA) framework to make over-parameterized models cost-sensitive. The overarching idea is to generate targeted adversarial examples that push the decision boundary in cost-aware directions. These targeted adversarial samples are generated by maximizing the probability of critical misclassifications and used to train a model with more conservative decisions on costly pairs. Experiments on well-known datasets and a pharmacy medication image (PMI) dataset made publicly available show that our method can effectively minimize the overall cost and reduce critical errors, while achieving comparable performance in terms of overall accuracy."}}
{"id": "bVwYF9MVQN", "cdate": 1609459200000, "mdate": 1683641747042, "content": {"title": "The Internet of Federated Things (IoFT)", "abstract": "The Internet of Things (IoT) is on the verge of a major paradigm shift. In the IoT system of the future, IoFT, the \u201ccloud\u201d will be substituted by the \u201ccrowd\u201d where model training is brought to the edge, allowing IoT devices to collaboratively extract knowledge and build smart analytics/models while keeping their personal data stored locally. This paradigm shift was set into motion by the tremendous increase in computational power on IoT devices and the recent advances in decentralized and privacy-preserving model training, coined as federated learning (FL). This article provides a vision for IoFT and a systematic overview of current efforts towards realizing this vision. Specifically, we first introduce the defining characteristics of IoFT and discuss FL data-driven approaches, opportunities, and challenges that allow decentralized inference within three dimensions: (i) a global model that maximizes utility across all IoT devices, (ii) a personalized model that borrows strengths across all devices yet retains its own model, (iii) a meta-learning model that quickly adapts to new devices or learning tasks. We end by describing the vision and challenges of IoFT in reshaping different industries through the lens of domain experts. Those industries include manufacturing, transportation, energy, healthcare, quality & reliability, business, and computing."}}
{"id": "9UxiFVTK2HU", "cdate": 1609459200000, "mdate": 1683641747258, "content": {"title": "The Internet of Federated Things (IoFT): A Vision for the Future and In-depth Survey of Data-driven Approaches for Federated Learning", "abstract": "The Internet of Things (IoT) is on the verge of a major paradigm shift. In the IoT system of the future, IoFT, the cloud will be substituted by the crowd where model training is brought to the edge, allowing IoT devices to collaboratively extract knowledge and build smart analytics/models while keeping their personal data stored locally. This paradigm shift was set into motion by the tremendous increase in computational power on IoT devices and the recent advances in decentralized and privacy-preserving model training, coined as federated learning (FL). This article provides a vision for IoFT and a systematic overview of current efforts towards realizing this vision. Specifically, we first introduce the defining characteristics of IoFT and discuss FL data-driven approaches, opportunities, and challenges that allow decentralized inference within three dimensions: (i) a global model that maximizes utility across all IoT devices, (ii) a personalized model that borrows strengths across all devices yet retains its own model, (iii) a meta-learning model that quickly adapts to new devices or learning tasks. We end by describing the vision and challenges of IoFT in reshaping different industries through the lens of domain experts. Those industries include manufacturing, transportation, energy, healthcare, quality & reliability, business, and computing."}}
{"id": "4x9Z0BKPzbX", "cdate": 1609459200000, "mdate": 1708604368950, "content": {"title": "GIFAIR-FL: An Approach for Group and Individual Fairness in Federated Learning", "abstract": "In this paper we propose \\texttt{GIFAIR-FL}: a framework that imposes \\textbf{G}roup and \\textbf{I}ndividual \\textbf{FAIR}ness to \\textbf{F}ederated \\textbf{L}earning settings. By adding a regularization term, our algorithm penalizes the spread in the loss of client groups to drive the optimizer to fair solutions. Our framework \\texttt{GIFAIR-FL} can accommodate both global and personalized settings. Theoretically, we show convergence in non-convex and strongly convex settings. Our convergence guarantees hold for both $i.i.d.$ and non-$i.i.d.$ data. To demonstrate the empirical performance of our algorithm, we apply our method to image classification and text prediction tasks. Compared to existing algorithms, our method shows improved fairness results while retaining superior or similar prediction accuracy."}}
{"id": "3eNrIs9I78x", "cdate": 1601308139284, "mdate": null, "content": {"title": "SALR: Sharpness-aware Learning Rates for Improved Generalization", "abstract": "In an effort to improve generalization in deep learning, we propose SALR: a sharpness-aware learning rate update technique designed to recover flat minimizers. Our method dynamically updates the learning rate of gradient-based optimizers based on the local sharpness of the loss function. This allows optimizers to automatically increase learning rates at sharp valleys to increase the chance of escaping them. We demonstrate the effectiveness of SALR when adopted by various algorithms over a broad range of networks. Our experiments indicate that SALR improves generalization, converges faster, and drives solutions to significantly flatter regions. "}}
{"id": "ppd5sJ6-ClH", "cdate": 1596130306219, "mdate": null, "content": {"title": "CONVERGENCE TO SECOND-ORDER STATIONARITY FOR CONSTRAINED NON-CONVEX OPTIMIZATION", "abstract": "We consider the problem of finding an approximate second-order stationary point of a\nconstrained non-convex optimization problem. We first show that, unlike the gradient descent method\nfor unconstrained optimization, the vanilla projected gradient descent algorithm may converge to a\nstrict saddle point even when there is only a single linear constraint. We then provide a hardness\nresult by showing that checking (\u03b5g,\u03b5H)-second order stationarity is NP-hard even in the presence\nof linear constraints. Despite our hardness result, we identify instances of the problem for which\nchecking second order stationarity can be done efficiently. For such instances, we propose a dynamic\nsecond order Frank\u2013Wolfe algorithm which converges to (\u03b5g,\u03b5H)-second order stationary points in\nO(max{\u03b5\u22122, \u03b5\u22123}) iterations. The proposed algorithm can be used in general constrained non-convex gH\noptimization as long as the constrained quadratic sub-problem can be solved efficiently."}}
{"id": "l213uyc7ZrW", "cdate": 1596130066888, "mdate": null, "content": {"title": "Solving a class of non-convex min-max games using iterative first order methods", "abstract": "Recent applications that arise in machine learning have surged significant interest in solving min-max saddle point games. This problem has been extensively studied in the convex-concave regime for which a global equilibrium solution can be computed efficiently. In this paper, we study the problem in the non-convex regime and show that an \u03b5\u2013first order stationary point of the game can be computed when one of the player\u2019s objective can be optimized to global optimality efficiently. In particular, we first consider the case where the objective of one of the players satisfies the Polyak-\u0141ojasiewicz (PL) condition. For such a game, we show that a simple multi-step gradient descent-ascent algorithm finds an \u03b5\u2013first order stationary\n\udbff\udc0b \u22122\npoint of the problem in O(\u03b5 ) iterations. Then we show that our framework can\nalso be applied to the case where the objective of the \u201cmax-player\" is concave. In this case, we propose a multi-step gradient descent-ascent algorithm that finds\n\udbff\udc0b \u22123.5\nan \u03b5\u2013first order stationary point of the game in O(\u03b5 ) iterations, which is the\nbest known rate in the literature. We applied our algorithm to a fair classification problem of Fashion-MNIST dataset and observed that the proposed algorithm results in smoother training and better generalization."}}
{"id": "vSrDjnDKGIc", "cdate": 1577836800000, "mdate": 1708533663247, "content": {"title": "A Trust Region Method for Finding Second-Order Stationarity in Linearly Constrained Nonconvex Optimization", "abstract": ""}}
{"id": "mI7xRQvU3j", "cdate": 1577836800000, "mdate": 1708533663205, "content": {"title": "Non-convex Min-Max Optimization: Applications, Challenges, and Recent Theoretical Advances", "abstract": "The min-max optimization problem, also known as the saddle point problem, is a classical optimization problem which is also studied in the context of zero-sum games. Given a class of objective functions, the goal is to find a value for the argument which leads to a small objective value even for the worst case function in the given class. Min-max optimization problems have recently become very popular in a wide range of signal and data processing applications such as fair beamforming, training generative adversarial networks (GANs), and robust machine learning, to just name a few. The overarching goal of this article is to provide a survey of recent advances for an important subclass of min-max problem, where the minimization and maximization problems can be non-convex and/or non-concave. In particular, we will first present a number of applications to showcase the importance of such min-max problems; then we discuss key theoretical challenges, and provide a selective review of some exciting recent theoretical and algorithmic advances in tackling non-convex min-max problems. Finally, we will point out open questions and future research directions."}}
