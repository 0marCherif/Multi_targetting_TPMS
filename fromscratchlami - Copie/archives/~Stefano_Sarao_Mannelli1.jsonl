{"id": "-a6TrnaPsJU", "cdate": 1675970196898, "mdate": null, "content": {"title": "THE RL PERCEPTRON: DYNAMICS OF POLICY LEARNING IN HIGH DIMENSIONS", "abstract": "Reinforcement learning (RL) algorithms have proven transformative in a range of\ndomains. To tackle real-world domains, these systems often use neural networks\nto learn policies directly from pixels or other high-dimensional sensory input. By\ncontrast, much theory of RL has focused on discrete state spaces or worst case\nanalyses, and fundamental questions remain about the dynamics of policy learning\nin high dimensional settings. Here we propose a simple high-dimensional model\nof RL and derive its typical dynamics as a set of closed-form ODEs. We show that\nthe model exhibits rich behavior including delayed learning under sparse rewards;\na speed-accuracy trade-off depending on reward stringency; and a dependence\nof learning regime on reward baselines. These results offer a first step toward\nunderstanding policy gradient methods in high dimensional settings.\n"}}
{"id": "6f47WT-HtuH", "cdate": 1663850093137, "mdate": null, "content": {"title": "Unfair geometries: exactly solvable data model with fairness implications", "abstract": "Machine learning (ML) may be oblivious to human bias but it is not immune to its perpetuation. Marginalisation and iniquitous group representation are often traceable in the very data used for training, and may be reflected or even enhanced by the learning models.\nIn the present work, we aim at clarifying the role played by data geometry in the emergence of ML bias. We introduce an exactly solvable high-dimensional model of data imbalance, where parametric control over the many bias-inducing factors allows for an extensive exploration of the bias inheritance mechanism.Through the tools of statistical physics, we analytically characterise the typical properties of learning models trained in this synthetic framework and obtain exact predictions for the observables that are commonly employed for fairness assessment.\nDespite the simplicity of the data model, we retrace and unpack typical unfairness behaviour observed on real-world datasets. \nWe also obtain a detailed analytical characterisation of a class of bias mitigation strategies. We first consider a basic loss-reweighing scheme, which allows for an implicit minimisation of different unfairness metrics, and quantify the incompatibilities between some existing fairness criteria. Then, we consider a novel mitigation strategy based on a matched inference approach, consisting in the introduction of coupled learning models. Our theoretical analysis of this approach shows that the coupled strategy can strike superior fairness-accuracy trade-offs."}}
{"id": "4d_tnQ_agHI", "cdate": 1652737696843, "mdate": null, "content": {"title": "An Analytical Theory of Curriculum Learning in Teacher-Student Networks", "abstract": "    In animals and humans, curriculum learning---presenting data in a curated order---is critical to rapid learning and effective pedagogy. \n    A long history of experiments has demonstrated the impact of curricula in a variety of animals but, despite its ubiquitous presence, a theoretical understanding of the phenomenon is still lacking. \n    Surprisingly, in contrast to animal learning, curricula strategies are not widely used in machine learning and recent simulation studies reach the conclusion that curricula are moderately effective or ineffective in most cases. \n    This stark difference in the importance of curriculum raises a fundamental theoretical question: when and why does curriculum learning help? \n    In this work, we analyse a prototypical neural network model of curriculum learning in the high-dimensional limit, employing statistical physics methods. \n    We study a task in which a sparse set of informative features are embedded amidst a large set of noisy features. We analytically derive average learning trajectories for simple neural networks on this task, which establish a clear speed benefit for curriculum learning in the online setting. However, when training experiences can be stored and replayed (for instance, during sleep), the advantage of curriculum in standard neural networks disappears, in line with observations from the deep learning literature. \n    Inspired by synaptic consolidation techniques developed to combat catastrophic forgetting, we investigate whether consolidating synapses at curriculum change points can boost the benefits of curricula. We derive generalisation performance as a function of consolidation strength (implemented as a Gaussian prior connecting learning phases), and show that this consolidation mechanism can yield a large improvement in test performance.\n    Our reduced analytical descriptions help reconcile apparently conflicting empirical results, trace regimes where curriculum learning yields the largest gains, and provide experimentally-accessible predictions for the impact of task parameters on curriculum benefits. More broadly, our results suggest that fully exploiting a curriculum may require explicit consolidation at curriculum boundaries."}}
{"id": "KnAMQ3nH8Pq", "cdate": 1621629839594, "mdate": null, "content": {"title": "Analytical Study of Momentum-Based Acceleration Methods in Paradigmatic High-Dimensional Non-Convex Problems", "abstract": "The optimization step in many machine learning problems rarely relies on vanilla gradient descent but it is common practice to use momentum-based accelerated methods. Despite these algorithms being widely applied to arbitrary loss functions, their behaviour in generically non-convex, high dimensional landscapes is poorly understood.\nIn this work, we use dynamical mean field theory techniques to describe analytically the average dynamics of these methods in a prototypical non-convex model: the (spiked) matrix-tensor model. We derive a closed set of equations that describe the behaviour of heavy-ball momentum and Nesterov acceleration in the infinite dimensional limit. By numerical integration of these equations, we observe that these methods speed up the dynamics but do not improve the algorithmic threshold with respect to gradient descent in the spiked model."}}
{"id": "HJeATNHxLS", "cdate": 1567802566061, "mdate": null, "content": {"title": "Who is Afraid of Big Bad Minima? Analysis of gradient-flow in spiked matrix-tensor models", "abstract": "Gradient-based algorithms are effective for many machine learning tasks, but despite ample recent effort and some progress, it often remains unclear why they work in practice in optimising high-dimensional non-convex functions and why they find good minima instead of being trapped in spurious ones.Here we present a quantitative theory explaining this behaviour in a spiked matrix-tensor model.Our framework is based on the Kac-Rice analysis of stationary points and a closed-form analysis of  gradient-flow originating from statistical physics. We show that there is a well defined region of parameters where the gradient-flow algorithm finds a good global minimum despite the presence of exponentially many spurious local minima. We show that this is achieved by surfing on saddles that have strong negative direction towards the global minima, a phenomenon that is connected to a BBP-type threshold in the Hessian describing the critical points of the landscapes."}}
{"id": "SyWZU2-uZB", "cdate": 1546300800000, "mdate": null, "content": {"title": "Passed & Spurious: Descent Algorithms and Local Minima in Spiked Matrix-Tensor Models", "abstract": "In this work we analyse quantitatively the interplay between the loss landscape and performance of descent algorithms in a prototypical inference problem, the spiked matrix-tensor model. We study a..."}}
