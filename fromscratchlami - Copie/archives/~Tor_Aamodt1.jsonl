{"id": "mwLlFEvLyX", "cdate": 1672531200000, "mdate": 1695949213131, "content": {"title": "Energy-Efficient Realtime Motion Planning", "abstract": "Motion planning is a fundamental problem in autonomous robotics with real-time and low-energy requirements for safe navigation through a dynamic environment. More than 90% of computation time in motion planning is spent on collision detection between the robot and the environment. Several motion planning approaches, such as deep learning-based motion planning, have shown significant improvements in motion planning quality and runtime with ample parallelism available in collision detection. However, naive parallelization of collision detection queries significantly increases computation compared to sequential execution. In this work, we investigate the sources of redundant computations in coarsegrained (inter-collision detection) and fine-grained (intracollision detection) parallelism. We find that the physical spatial locality of obstacles results in redundant computation in coarse-grained parallelism. We further show that the primary sources of redundant computation in fine-grained parallelism are easy cases where objects are far apart or significantly overlapping. Based on these insights, we propose MPAccel to improve the energy efficiency of parallelization in motion planning. MPAccel consists of SAS, a Spatially Aware Scheduler for coarse-grained parallelism, and CECDUs, Cascaded Early-exit Collision Detection Units for fine-grained parallelism. SAS results in 7\u00d7 speedup using 8\u00d7 parallelization with 6% increase in the computation compared to 3.7\u00d7 speedup with 83% increase in computation for naive parallelization. CECDU can perform collision detection in 46 -- 154 cycles for a robot with 6 degrees of freedom. We evaluate MPAccel to execute a state-of-the-art learning-based motion planning algorithm. Our simulations suggest MPAccel can achieve real-time motion planning for a robot with 7 degrees of freedom in 0.014ms-0.49ms with an average latency of 0.099ms compared to 1.42ms on a CPU-GPU system."}}
{"id": "jpP3ZgEZdsx", "cdate": 1672531200000, "mdate": 1695949213224, "content": {"title": "Learning Label Encodings for Deep Regression", "abstract": ""}}
{"id": "-utHUpDAhzY", "cdate": 1672531200000, "mdate": 1681650913148, "content": {"title": "Learning Label Encodings for Deep Regression", "abstract": ""}}
{"id": "k60XE_b0Ix6", "cdate": 1663849904831, "mdate": null, "content": {"title": "Learning Label Encodings for Deep Regression", "abstract": "Deep regression networks are widely used to tackle the problem of predicting a continuous value for a given input. Task-specialized approaches for training regression networks have shown significant improvement over generic approaches, such as direct regression. More recently, a generic approach based on regression by binary classification using binary-encoded labels has shown significant improvement over direct regression. The space of label encodings for regression is large. Lacking heretofore have been automated approaches to find a good label encoding for a given application. This paper introduces Regularized Label Encoding Learning (RLEL) for end-to-end training of an entire network and its label encoding. RLEL provides a generic approach for tackling regression. Underlying RLEL is our observation that the search space of label encodings can be constrained and efficiently explored by using a continuous search space of real-valued label encodings combined with a regularization function designed to encourage encodings with certain properties. These properties balance the probability of classification error in individual bits against error correction capability. Label encodings found by RLEL result in lower or comparable errors to manually designed label encodings. Applying RLEL results in $10.9\\%$ and $12.4\\%$ improvement in Mean Absolute Error (MAE) over direct regression and multiclass classification, respectively. Our evaluation demonstrates that RLEL can be combined with off-the-shelf feature extractors and is suitable across different architectures, datasets, and tasks. Code is available at \\url{https://github.com/ubc-aamodt-group/RLEL_regression}. "}}
{"id": "tFVmUJfyruO", "cdate": 1640995200000, "mdate": 1681650913088, "content": {"title": "Label Encoding for Regression Networks", "abstract": ""}}
{"id": "pC76aw1wTzi", "cdate": 1640995200000, "mdate": 1681650913173, "content": {"title": "Label Encoding for Regression Networks", "abstract": ""}}
{"id": "maavqIT6GM", "cdate": 1640995200000, "mdate": 1681650913143, "content": {"title": "Anticipating and eliminating redundant computations in accelerated sparse training", "abstract": ""}}
{"id": "k8x6Y49Hez", "cdate": 1640995200000, "mdate": 1681650913142, "content": {"title": "Vulkan-Sim: A GPU Architecture Simulator for Ray Tracing", "abstract": ""}}
{"id": "8WawVDdKqlL", "cdate": 1632875437132, "mdate": null, "content": {"title": "Label Encoding for Regression Networks", "abstract": "Deep neural networks are used for a wide range of regression problems. However, there exists a significant gap in accuracy between specialized approaches and generic direct regression in which a network is trained by minimizing the squared or absolute error of output labels. Prior work has shown that solving a regression problem with a set of binary classifiers can improve accuracy by utilizing well-studied binary classification algorithms. We introduce binary-encoded labels (BEL), which generalizes the application of binary classification to regression by providing a framework for considering arbitrary multi-bit values when encoding target values. We identify desirable properties of suitable encoding and decoding functions used for the conversion between real-valued and binary-encoded labels based on theoretical and empirical study. These properties highlight a tradeoff between classification error probability and error-correction capabilities of label encodings. BEL can be combined with off-the-shelf task-specific feature extractors and trained end-to-end. We propose a series of sample encoding, decoding, and training loss functions for BEL and demonstrate they result in lower error than direct regression and specialized approaches while being suitable for a diverse set of regression problems, network architectures, and evaluation metrics. BEL achieves state-of-the-art accuracies for several regression benchmarks. Code is available at https://github.com/ubc-aamodt-group/BEL_regression.\n"}}
{"id": "MwFdqFRxIF0", "cdate": 1621629747532, "mdate": null, "content": {"title": "AC-GC: Lossy Activation Compression with Guaranteed Convergence", "abstract": "Parallel hardware devices (e.g., graphics processor units) have limited high-bandwidth memory capacity.\nThis negatively impacts the training of deep neural networks (DNNs) by increasing runtime and/or decreasing accuracy when reducing model and/or batch size to fit this capacity. Lossy compression is a promising approach to tackling memory capacity constraints, but prior approaches rely on hyperparameter search to achieve a suitable trade-off between convergence and compression, negating runtime benefits. In this paper we build upon recent developments on Stochastic Gradient Descent convergence to prove an upper bound on the expected loss increase when training with compressed activation storage. We then express activation compression error in terms of this bound, allowing the compression rate to adapt to training conditions automatically. The advantage of our approach, called AC-GC, over existing lossy compression frameworks is that, given a preset allowable increase in loss, significant compression without significant increase in error can be achieved with a single training run. When combined with error-bounded methods, AC-GC achieves 15.1x compression with an average accuracy change of 0.1% on text and image datasets. AC-GC functions on any model composed of the layers analyzed and, by avoiding compression rate search, reduces overall training time by 4.6x over SuccessiveHalving. "}}
