{"id": "P8jSkONJ2v", "cdate": 1675299935069, "mdate": 1675299935069, "content": {"title": "Enveloped sinusoid parseval frames", "abstract": "This paper presents a method of constructing Parseval frames from any collection of complex envelopes. The resulting Enveloped Sinusoid Parseval (ESP) frames can represent a wide variety of signal types as specified by their physical morphology. Since the ESP frame retains its Parseval property even when generated from a variety of envelopes, it is compatible with large scale and iterative optimization algorithms. ESP frames are constructed by applying time-shifted enveloping functions to the discrete Fourier Transform basis, and in this way are similar to the short-time Fourier Transform. This work provides examples of ESP frame generation for both synthetic and experimentally measured signals. Furthermore, the frame\u2019s compatibility with distributed sparse optimization frameworks is demonstrated, and efficient implementation details are provided. Numerical experiments on acoustics data reveal that the flexibility of this method allows it to be simultaneously competitive with the STFT in time-frequency processing and also with Prony\u2019s Method for time-constant parameter estimation, surpassing the shortcomings of each individual technique."}}
{"id": "RyhWO5pzRX", "cdate": 1675299871967, "mdate": 1675299871967, "content": {"title": "Approximate extraction of late-time returns via morphological component analysis", "abstract": "A fundamental challenge in acoustic data processing is to separate a measured time series into relevant phenomenological components. A given measurement is typically assumed to be an additive mixture of myriad signals plus noise whose separation forms an ill-posed inverse problem. In the setting of sensing elastic objects using active sonar, we wish to separate the early-time returns (e.g., returns from the object's exterior geometry) from late-time returns caused by elastic or compressional wave coupling. Under the framework of Morphological Component Analysis (MCA), we compare two separation models using the short-duration and long-duration responses as a proxy for early-time and late-time returns. Results are computed for Stanton's elastic cylinder model as well as on experimental data taken from an in-Air circular Synthetic Aperture Sonar (AirSAS) system, whose separated time series are formed into imagery. We find that MCA can be used to separate early and late-time responses in both cases without the use of time-gating. The separation process is demonstrated to be robust to noise and compatible with AirSAS image reconstruction. The best separation results are obtained with a flexible, but computationally intensive, frame based signal model, while a faster Fourier Transform based method is shown to have competitive performance."}}
{"id": "uwGFMc25Fqm", "cdate": 1675299769580, "mdate": 1675299769580, "content": {"title": "AirSAS: Controlled Dataset Generation for Physics-Informed Machine Learning", "abstract": "Synthetic aperture sonar (SAS) is an underwater remote sensing technique for applications such as seafloor characterization and object detection. However, underwater SAS datasets are both extremely expensive to collect and difficult to control and repeat. We propose an in-air SAS measurement apparatus (AirSAS) made from commercial off-the-shelf laboratory equipment to generate controlled, repeatable datasets. AirSAS is both flexible and sufficiently delicate to capture the complex acoustic phenomena inherent in SAS measurements. The system allows us to physically control the differences between classes of interest, and observe acoustic phenomenology that is rare or expensive to collect underwater. Accordingly, we can measure and tune which acoustic phenomena deep learning models are sensitive to. AirSAS can generate both circular and linear track collections. The first iteration of the AirSAS dataset is currently under curation."}}
{"id": "r1WgknZ_ZH", "cdate": 1546300800000, "mdate": null, "content": {"title": "Beyond Backprop: Online Alternating Minimization with Auxiliary Variables", "abstract": "Despite significant recent advances in deep neural networks, training them remains a challenge due to the highly non-convex nature of the objective function. State-of-the-art methods rely on error ..."}}
{"id": "PesG6E52XVM", "cdate": 1546300800000, "mdate": null, "content": {"title": "LSALSA: accelerated source separation via learned sparse coding.", "abstract": "We propose an efficient algorithm for the generalized sparse coding (SC) inference problem. The proposed framework applies to both the single dictionary setting, where each data point is represented as a sparse combination of the columns of one dictionary matrix, as well as the multiple dictionary setting as given in morphological component analysis (MCA), where the goal is to separate a signal into additive parts such that each part has distinct sparse representation within an appropriately chosen corresponding dictionary. Both the SC task and its generalization via MCA have been cast as $$\\ell _1$$ \u2113 1 -regularized optimization problems of minimizing quadratic reconstruction error. In an effort to accelerate traditional acquisition of sparse codes, we propose a deep learning architecture that constitutes a trainable time-unfolded version of the split augmented lagrangian shrinkage algorithm (SALSA), a special case of the alternating direction method of multipliers (ADMM). We empirically validate both variants of the algorithm, that we refer to as learned-SALSA (LSALSA), on image vision tasks and demonstrate that at inference our networks achieve vast improvements in terms of the running time and the quality of estimated sparse codes on both classic SC and MCA problems over more common baselines. We also demonstrate the visual advantage of our technique on the task of source separation. Finally, we present a theoretical framework for analyzing LSALSA network: we show that the proposed approach exactly implements a truncated ADMM applied to a new, learned cost function with curvature modified by one of the learned parameterized matrices. We extend a very recent stochastic alternating optimization analysis framework to show that a gradient descent step along this learned loss landscape is equivalent to a modified gradient descent step along the original loss landscape. In this framework, the acceleration achieved by LSALSA could potentially be explained by the network\u2019s ability to learn a correction to the gradient direction of steeper descent."}}
{"id": "RjJMXT5CRzv", "cdate": 1514764800000, "mdate": null, "content": {"title": "Vector minimax concave penalty for sparse representation.", "abstract": "This paper proposes vector minimax concave (VMC) penalty for sparse representation using tools of Moreau envelope. The VMC penalty is a weighted MC function; by fine tuning the weight of the VMC penalty with given strategy, the VMC regularized least squares problem shares the same global minimizers with the L 0 regularization problem but has fewer local minima. Facilitated by the alternating direction method of multipliers (ADMM), the VMC regularization problem can be tackled as a sequence of convex sub-problems, each of which can be solved fast. Theoretical analysis of ADMM shows that the convergence of solving the VMC regularization problem is guaranteed. We present a series of numerical experiments demonstrating the superior performance of the VMC penalty and the ADMM algorithm in broad applications for sparse representation, including sparse denoising, sparse deconvolution, and missing data estimation. Previous article in issue Next article in issue"}}
