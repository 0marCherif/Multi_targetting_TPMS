{"id": "pVD1k8ge25a", "cdate": 1664194183875, "mdate": null, "content": {"title": "Equivariance With Learned Canonicalization Functions", "abstract": "Symmetry-based neural networks often constrain the architecture in order to achieve invariance or equivariance to a group of transformations. In this paper, we propose an alternative that avoids this architectural constraint by learning to produce a canonical representation of the data. These canonicalization functions can readily be plugged into non-equivariant backbone architectures. We offer explicit ways to implement them for many groups of interest. We show that this approach enjoys universality while providing interpretable insights. Our main hypothesis is that learning a neural network to perform canonicalization is better than doing it using predefined heuristics. Our results show that learning the canonicalization function indeed leads to better results and that the approach achieves great performance in practice."}}
{"id": "0Dh8dz4snu", "cdate": 1652737874468, "mdate": null, "content": {"title": "Equivariant Networks for Crystal Structures", "abstract": "Supervised learning with deep models has tremendous potential for applications in materials science. Recently, graph neural networks have been used in this context, drawing direct inspiration from models for molecules. However, materials are typically much more structured than molecules, which is a feature that these models do not leverage. In this work, we introduce a class of models that are equivariant with respect to crystalline symmetry groups. We do this by defining a generalization of the message passing operations that can be used with more general permutation groups, or that can alternatively be seen as defining an expressive convolution operation on the crystal graph. Empirically, these models achieve competitive results with state-of-the-art on the Materials Project dataset."}}
{"id": "swMiLVAEz0", "cdate": 1640995200000, "mdate": 1681485972603, "content": {"title": "Equivariant Networks for Crystal Structures", "abstract": ""}}
{"id": "WZjT5pK6VLR", "cdate": 1640995200000, "mdate": 1681485972422, "content": {"title": "Equivariance with Learned Canonicalization Functions", "abstract": ""}}
{"id": "h8flNv9x8v-", "cdate": 1621630250477, "mdate": null, "content": {"title": "Gradient Starvation: A Learning Proclivity in Neural Networks", "abstract": "We identify and formalize a fundamental gradient descent phenomenon resulting in a learning proclivity in over-parameterized neural networks. Gradient Starvation arises when cross-entropy loss is minimized by capturing only a subset of features relevant for the task, despite the presence of other predictive features that fail to be discovered. This work provides a theoretical explanation for the emergence of such feature imbalance in neural networks. Using tools from Dynamical Systems theory, we identify simple properties of learning dynamics during gradient descent that lead to this imbalance, and prove that such a situation can be expected given certain statistical structure in training data. Based on our proposed formalism, we develop guarantees for a novel regularization method aimed at decoupling feature learning dynamics, improving accuracy and robustness in cases hindered by gradient starvation. We illustrate our findings with simple and real-world out-of-distribution (OOD) generalization experiments."}}
{"id": "aExAsh1UHZo", "cdate": 1621630250477, "mdate": null, "content": {"title": "Gradient Starvation: A Learning Proclivity in Neural Networks", "abstract": "We identify and formalize a fundamental gradient descent phenomenon resulting in a learning proclivity in over-parameterized neural networks. Gradient Starvation arises when cross-entropy loss is minimized by capturing only a subset of features relevant for the task, despite the presence of other predictive features that fail to be discovered. This work provides a theoretical explanation for the emergence of such feature imbalance in neural networks. Using tools from Dynamical Systems theory, we identify simple properties of learning dynamics during gradient descent that lead to this imbalance, and prove that such a situation can be expected given certain statistical structure in training data. Based on our proposed formalism, we develop guarantees for a novel regularization method aimed at decoupling feature learning dynamics, improving accuracy and robustness in cases hindered by gradient starvation. We illustrate our findings with simple and real-world out-of-distribution (OOD) generalization experiments."}}
{"id": "tYDkqm4OoY", "cdate": 1609459200000, "mdate": 1681485972604, "content": {"title": "Prediction of Large Magnetic Moment Materials With Graph Neural Networks and Random Forests", "abstract": ""}}
{"id": "iVd6PBTrgA", "cdate": 1609459200000, "mdate": 1681485972546, "content": {"title": "Gradient Starvation: A Learning Proclivity in Neural Networks", "abstract": ""}}
{"id": "Rpe4HTOtpEu", "cdate": 1577836800000, "mdate": null, "content": {"title": "Gradient Starvation: A Learning Proclivity in Neural Networks", "abstract": "We identify and formalize a fundamental gradient descent phenomenon resulting in a learning proclivity in over-parameterized neural networks. Gradient Starvation arises when cross-entropy loss is minimized by capturing only a subset of features relevant for the task, despite the presence of other predictive features that fail to be discovered. This work provides a theoretical explanation for the emergence of such feature imbalance in neural networks. Using tools from Dynamical Systems theory, we identify simple properties of learning dynamics during gradient descent that lead to this imbalance, and prove that such a situation can be expected given certain statistical structure in training data. Based on our proposed formalism, we develop guarantees for a novel regularization method aimed at decoupling feature learning dynamics, improving accuracy and robustness in cases hindered by gradient starvation. We illustrate our findings with simple and real-world out-of-distribution (OOD) generalization experiments."}}
