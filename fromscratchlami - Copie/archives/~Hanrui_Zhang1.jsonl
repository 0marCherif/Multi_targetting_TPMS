{"id": "69pG3hlkKb", "cdate": 1672531200000, "mdate": 1681657294547, "content": {"title": "Autobidding Auctions in the Presence of User Costs", "abstract": "We study autobidding ad auctions with user costs, where each bidder is value-maximizing subject to a return-over-investment (ROI) constraint, and the seller aims to maximize the social welfare taking into consideration the user's cost of viewing an ad. We show that in the worst case, the approximation ratio of social welfare by running the vanilla VCG auctions with user costs could as bad as 0. To improve the performance of VCG, We propose a new variant of VCG based on properly chosen cost multipliers, and prove that there exist auction-dependent and bidder-dependent cost multipliers that guarantee approximation ratios of 1/2 and 1/4 respectively in terms of the social welfare."}}
{"id": "UqA1mcOxiq", "cdate": 1652737425606, "mdate": null, "content": {"title": "Posted Pricing and Dynamic Prior-independent Mechanisms with Value Maximizers", "abstract": "We study posted price auctions and dynamic prior-independent mechanisms for (ROI-constrained) value maximizers. In contrast to classic (quasi-linear) utility maximizers, these agents aim to maximize their total value subject to a minimum ratio of value per unit of payment made. When personalized posted prices are allowed, posted price auctions for value maximizers can be reduced to posted price auctions for utility maximizers. However, for anonymous posted prices, the well-known $\\frac 1 2$ approximation for utility maximizers is impossible for value maximizers and we provide a posted price mechanism with $\\frac12(1 - 1/e)$ approximation. Moreover, we demonstrate how to apply our results to design prior-independent mechanisms in a dynamic environment; and to the best of our knowledge, this gives the first constant revenue approximation with multiple value maximizers. Finally, we provide an extension to combinatorial auctions with submodular / XOS agents."}}
{"id": "ydaXw0DTW76", "cdate": 1640995200000, "mdate": 1681657294278, "content": {"title": "Efficient Algorithms for Planning with Participation Constraints", "abstract": "We consider the problem of planning with participation constraints introduced in[24]. In this problem, a principal chooses actions in a Markov decision process, resulting in separate utilities for the principal and the agent. However, the agent can and will choose to end the process whenever his expected onward utility becomes negative. The principal seeks to compute and commit to a policy that maximizes her expected utility, under the constraint that the agent should always want to continue participating. We provide the first polynomial-time exact algorithm for this problem for finite-horizon settings, where previously only an additive \u03b5-approximation algorithm was known. Our approach can also be extended to the (discounted) infinite-horizon case, for which we give an algorithm that runs in time polynomial in the size of the input and log(1/\u03b5), and returns a policy that is optimal up to an additive error of \u03b5."}}
{"id": "gV458--eM3", "cdate": 1640995200000, "mdate": 1675626279182, "content": {"title": "Near-Optimal Reviewer Splitting in Two-Phase Paper Reviewing and Conference Experiment Design", "abstract": "Many scientific conferences employ a two-phase paper review process, where some papers are assigned additional reviewers after the initial reviews are submitted. Many conferences also design and run experiments on their paper review process, where some papers are assigned reviewers who provide reviews under an experimental condition. In this paper, we consider the question: how should reviewers be divided between phases or conditions in order to maximize total assignment similarity? We make several contributions towards answering this question. First, we prove that when the set of papers requiring additional review is unknown, a simplified variant of this problem is NP-hard. Second, we empirically show that across several datasets pertaining to real conference data, dividing reviewers between phases/conditions uniformly at random allows an assignment that is nearly as good as the oracle optimal assignment. This uniformly random choice is practical for both the two-phase and conference experiment design settings. Third, we provide explanations of this phenomenon by providing theoretical bounds on the suboptimality of this random strategy under certain natural conditions. From these easily-interpretable conditions, we provide actionable insights to conference program chairs about whether a random reviewer split is suitable for their conference."}}
{"id": "amlsZgSji8M", "cdate": 1640995200000, "mdate": 1675109210992, "content": {"title": "Efficiency of the First-Price Auction in the Autobidding World", "abstract": "We study the price of anarchy of the first-price auction in the autobidding world, where bidders can be either utility maximizers (i.e., traditional bidders) or value maximizers (i.e., autobidders). We show that with autobidders only, the price of anarchy of the first-price auction is $1/2$, and with both kinds of bidders, the price of anarchy degrades to about $0.457$ (the precise number is given by an optimization). These results complement the recent result by Jin and Lu [2022] showing that the price of anarchy of the first-price auction with traditional bidders only is $1 - 1/e^2$. We further investigate a setting where the seller can utilize machine-learned advice to improve the efficiency of the auctions. There, we show that as the accuracy of the advice increases, the price of anarchy improves smoothly from about $0.457$ to $1$."}}
{"id": "agOJ-YzeeM", "cdate": 1640995200000, "mdate": 1654881191219, "content": {"title": "Near-Optimal Reviewer Splitting in Two-Phase Paper Reviewing and Conference Experiment Design", "abstract": ""}}
{"id": "VDmlmk-l2f", "cdate": 1640995200000, "mdate": 1681657294129, "content": {"title": "Efficient Algorithms for Planning with Participation Constraints", "abstract": "We consider the problem of planning with participation constraints introduced in [Zhang et al., 2022]. In this problem, a principal chooses actions in a Markov decision process, resulting in separate utilities for the principal and the agent. However, the agent can and will choose to end the process whenever his expected onward utility becomes negative. The principal seeks to compute and commit to a policy that maximizes her expected utility, under the constraint that the agent should always want to continue participating. We provide the first polynomial-time exact algorithm for this problem for finite-horizon settings, where previously only an additive $\\varepsilon$-approximation algorithm was known. Our approach can also be extended to the (discounted) infinite-horizon case, for which we give an algorithm that runs in time polynomial in the size of the input and $\\log(1/\\varepsilon)$, and returns a policy that is optimal up to an additive error of $\\varepsilon$."}}
{"id": "Etm6YdWafc", "cdate": 1640995200000, "mdate": 1681657294246, "content": {"title": "Learning Influence Adoption in Heterogeneous Networks", "abstract": "We study the problem of learning influence adoption in networks. In this problem, a communicable entity (such as an infectious disease, a computer virus, or a social media meme) propagates through a network, and the goal is to learn the state of each individual node by sampling only a small number of nodes and observing/testing their states. We study this problem in heterogeneous networks, in which each individual node has a set of distinct features that determine how it is affected by the propagating entity. We give an efficient algorithm with nearly optimal sample complexity for two variants of this learning problem, corresponding to symptomatic and asymptomatic spread. In each case, the optimal sample complexity naturally generalizes the complexity of learning how nodes are affected in isolation, and the complexity of learning influence adoption in a homogeneous network."}}
{"id": "9mh6T2mEOq", "cdate": 1640995200000, "mdate": 1681657294427, "content": {"title": "Improved prophet inequalities for combinatorial welfare maximization with (approximately) subadditive agents", "abstract": ""}}
{"id": "4XOFGFBEpkk", "cdate": 1640995200000, "mdate": 1681657294309, "content": {"title": "Planning with Participation Constraints", "abstract": "We pose and study the problem of planning in Markov decision processes (MDPs), subject to participation constraints as studied in mechanism design. In this problem, a planner must work with a self-interested agent on a given MDP. Each action in the MDP provides an immediate reward to the planner and a (possibly different) reward to the agent. The agent has no control in choosing the actions, but has the option to end the entire process at any time. The goal of the planner is to find a policy that maximizes her cumulative reward, taking into consideration the agent's ability to terminate. We give a fully polynomial-time approximation scheme for this problem. En route, we present polynomial-time algorithms for computing (exact) optimal policies for important special cases of this problem, including when the time horizon is constant, or when the MDP exhibits a \"definitive decisions\" property. We illustrate our algorithms with two different game-theoretic applications: the problem of assigning rides in ride-sharing and the problem of designing screening policies. Our results imply efficient algorithms for computing (approximately) optimal policies in both applications."}}
