{"id": "f8Bo8blLlk", "cdate": 1680307200000, "mdate": 1682946095356, "content": {"title": "Walk for Learning: A Random Walk Approach for Federated Learning From Heterogeneous Data", "abstract": "We consider the problem of a Parameter Server (PS) that wishes to learn a model that fits data distributed on the nodes of a graph. We focus on Federated Learning (FL) as a canonical application. One of the main challenges of FL is the communication bottleneck between the nodes and the parameter server. A popular solution in the literature is to allow each node to do several local updates on the model in each iteration before sending it back to the PS. While this mitigates the communication bottleneck, the statistical heterogeneity of the data owned by the different nodes has proven to delay convergence and bias the model. In this work, we study random walk (RW) learning algorithms for tackling the communication and data heterogeneity problems. The main idea is to leverage available direct connections among the nodes themselves, which are typically \u201ccheaper\u201d than the communication to the PS. In a random walk, the model is thought of as a \u201cbaton\u201d that is passed from a node to one of its neighbors after being updated in each iteration. The challenge in designing the RW is the data hetErogeneity and the uncertainty about the data distributions. Ideally, we would want to visit more often nodes that hold more informative data. We cast this problem as a sleeping multi-armed bandit (MAB) to design near-optimal node sampling strategy that achieves a variance reduced gradient estimates and approaches sub-linearly the optimal sampling strategy. Based on this framework, we present an adaptive random walk learning algorithm. We provide theoretical guarantees on its convergence. Our numerical results validate our theoretical findings and show that our algorithm outperforms existing random walk algorithms."}}
{"id": "th3eLAxNhd3", "cdate": 1640995200000, "mdate": 1682946095353, "content": {"title": "Adaptive Bandit Cluster Selection for Graph Neural Networks", "abstract": "Graph neural networks (GNNs) have shown successful performance in graph-based applications; however, training large-scale GNNs remains challenging. Current SGD-based algorithms suffer from a high computational cost that exponentially grows with the number of GNN layers. Moreover, they require a large memory to store both the entire graph and the embedding of each node. In this work, we propose a novel, bandit-based graph sampling scheme that improves GNN training efficiency, which results in faster training times and improved accuracy. Our sampling strategy consists of partitioning the graph into densely connected clusters and prioritizing more informative clusters with respect to the learning objective. The cluster selection is carried by a bandit-based graph sampling algorithm that defines the reward based on the robustness of the induced stochastic gradient. Our goal is to select more often the clusters that guide our optimization objective towards the optimal solution more quickly by processing snapshots of the graph while maintaining a theoretical guarantee of approaching optimal learning performance. We employ our algorithm on a recommendation module at the e-commerce platform Etsy and on the public benchmark Yoochoose dataset, where we show an improvement in the rate of convergence and the recommendation accuracy over graph sampling baselines."}}
{"id": "LfPVKHmQD4X", "cdate": 1640995200000, "mdate": 1682946095362, "content": {"title": "Walk for Learning: A Random Walk Approach for Federated Learning from Heterogeneous Data", "abstract": "We consider the problem of a Parameter Server (PS) that wishes to learn a model that fits data distributed on the nodes of a graph. We focus on Federated Learning (FL) as a canonical application. One of the main challenges of FL is the communication bottleneck between the nodes and the parameter server. A popular solution in the literature is to allow each node to do several local updates on the model in each iteration before sending it back to the PS. While this mitigates the communication bottleneck, the statistical heterogeneity of the data owned by the different nodes has proven to delay convergence and bias the model. In this work, we study random walk (RW) learning algorithms for tackling the communication and data heterogeneity problems. The main idea is to leverage available direct connections among the nodes themselves, which are typically \"cheaper\" than the communication to the PS. In a random walk, the model is thought of as a \"baton\" that is passed from a node to one of its neighbors after being updated in each iteration. The challenge in designing the RW is the data heterogeneity and the uncertainty about the data distributions. Ideally, we would want to visit more often nodes that hold more informative data. We cast this problem as a sleeping multi-armed bandit (MAB) to design a near-optimal node sampling strategy that achieves variance-reduced gradient estimates and approaches sub-linearly the optimal sampling strategy. Based on this framework, we present an adaptive random walk learning algorithm. We provide theoretical guarantees on its convergence. Our numerical results validate our theoretical findings and show that our algorithm outperforms existing random walk algorithms."}}
{"id": "GvN9ThK1Prj", "cdate": 1609459200000, "mdate": 1682946095355, "content": {"title": "Private Weighted Random Walk Stochastic Gradient Descent", "abstract": "We consider a decentralized learning setting in which data is distributed over nodes in a graph. The goal is to learn a global model on the distributed data without involving any central entity that needs to be trusted. While gossip-based stochastic gradient descent (SGD) can be used to achieve this learning objective, it incurs high communication and computation costs. To speed up the convergence, we propose instead to study random walk based SGD in which a global model is updated based on a random walk on the graph. We propose two algorithms based on two types of random walks that achieve, in a decentralized way, uniform sampling and importance sampling of the data. We provide a non-asymptotic analysis on the rate of convergence, taking into account the constants related to the data and the graph. Our numerical results show that the weighted random walk based algorithm has a better performance for high-variance data. Moreover, we propose a privacy-preserving random walk algorithm that achieves local differential privacy based on a Gamma noise mechanism that we propose. We also give numerical results on the convergence of this algorithm and show that it outperforms additive Laplace-based privacy mechanisms."}}
{"id": "nC69_pWlOT4", "cdate": 1577836800000, "mdate": 1682946095371, "content": {"title": "Private Weighted Random Walk Stochastic Gradient Descent", "abstract": "We consider a decentralized learning setting in which data is distributed over nodes in a graph. The goal is to learn a global model on the distributed data without involving any central entity that needs to be trusted. While gossip-based stochastic gradient descent (SGD) can be used to achieve this learning objective, it incurs high communication and computation costs, since it has to wait for all the local models at all the nodes to converge. To speed up the convergence, we propose instead to study random walk based SGD in which a global model is updated based on a random walk on the graph. We propose two algorithms based on two types of random walks that achieve, in a decentralized way, uniform sampling and importance sampling of the data. We provide a non-asymptotic analysis on the rate of convergence, taking into account the constants related to the data and the graph. Our numerical results show that the weighted random walk based algorithm has a better performance for high-variance data. Moreover, we propose a privacy-preserving random walk algorithm that achieves local differential privacy based on a Gamma noise mechanism that we propose. We also give numerical results on the convergence of this algorithm and show that it outperforms additive Laplace-based privacy mechanisms."}}
{"id": "ok47P3-2oeb", "cdate": 1546300800000, "mdate": 1682946095362, "content": {"title": "Random Walk Gradient Descent for Decentralized Learning on Graphs", "abstract": "We design a new variant of the stochastic gradient descent algorithm applied for learning a global model based on the data distributed over the nodes of a network. Motivated by settings such as in decentralized learning, we suppose that one special node in the network, which we call node 1, is interested in learning the global model. We seek a decentralized and distributed algorithm for many reasons including privacy and fault-tolerance. A natural candidate here is Gossip-style SGD. However, it suffers from slow convergence and high communication cost mainly because at the end all nodes, and not only the special node, will learn the model. We propose a distributed SGD algorithm using a weighted random walk to sample the nodes. The Markov chain is designed to have stationary probability distribution that is proportional to the smoothness bound L <sub xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">i</sub> of the local loss function at node i. We study the convergence rate of this algorithm and prove that it depends on the smoothness average L. This outperforms the case of uniform sampling algorithm obtained by a Metropolis-Hasting random walk (MHRW) which depends on the supremum of all L <sub xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">i</sub> s noted L. We present numerical simulations that substantiate our theoretical findings and show that our algorithm outperforms random walk and gossip-style algorithms."}}
{"id": "vjaQdgzS2gw", "cdate": 1514764800000, "mdate": 1682946095362, "content": {"title": "Matrix Exponential Learning for Resource Allocation with Low Informational Exchange", "abstract": "We consider a distributed resource allocation problem in networks where each transmitter-receiver pair aims at maximizing its local utility function by adjusting its action matrix, which belongs to a given feasible set. This problem has been addressed recently by applying a matrix exponential learning (MXL) algorithm which has a very appealing convergence rate. In this learning algorithm, however, each transmitter must know an estimate of the gradient matrix of the local utility. The knowledge of the gradient matrix at the transmitters incurs a high signaling overhead especially that the matrix size increases with the dimension of the action matrix. In this paper, we therefore investigate two strategies in order to decrease the informational exchange per iteration of the algorithm. In the first strategy, each receiver sends at each iteration part of the elements of the gradient matrix with respect to a certain probability. In the second strategy, each receiver feeds back sporadically the whole gradient matrix. We focus on the analysis of the convergence of the MXL algorithm to optimum under these two strategies. We prove that the algorithm can still converge to optimum almost surely. Upper bounds of the average convergence rate are also derived in both situations with general step-size setting, from which we can clearly see the impact of the incompleteness of the feedback information. The proposed algorithms are applied to solve the energy efficiency maximization problem in a multicarrier multi-user MIMO network. Simulation results further corroborate our claim."}}
{"id": "J4TNv3qz1x", "cdate": 1514764800000, "mdate": 1682946095364, "content": {"title": "Matrix Exponential Learning for Resource Allocation with Low Informational Exchange", "abstract": "We consider a distributed resource allocation problem in a multicarrier multi-user MIMO network where multiple transmitter-receiver links interfere among each other. Each user aims to maximize its own energy efficiency by adjusting its signal covariance matrix under a predefined power constraint. This problem has been addressed recently by applying a matrix exponential learning (MXL) algorithm which has a very appealing convergence rate. In this learning algorithm, however, each transmitter must know an estimate of the gradient matrix of the user utility. The knowledge of the gradient matrix at the transmitters incurs a high signaling overhead especially that this matrix size increases with the number of antennas and subcarriers. In this paper, we therefore investigate two strategies in order to decrease the informational exchange per iteration of the algorithm. In the first strategy, each user sends at each iteration part of the elements of the gradient matrix with respect to a certain probability. In the second strategy, each user feeds back \u201csporadically\u201d the whole gradient matrix. We focus on the analysis of the convergence of the MXL algorithm to Nash Equilibrium (NE) under these two strategies. Upper bounds of the average convergence rate are obtained in both situations with general step-size setting, from which we can clearly see the impact of the incompleteness of the feedback information. We prove that the algorithm can still converge to NE and the convergence rate are not seriously affected. Simulation results further corroborate our claim and show that, in terms of convergence rate, MXL performs better under the second proposed strategy."}}
