{"id": "VNC4fqZpPB0", "cdate": 1693526400000, "mdate": 1693871131318, "content": {"title": "Regret Bounds for Log-Loss via Bayesian Algorithms", "abstract": "We study sequential probability assignment in the context of online learning under logarithmic loss and obtain tight lower and upper bounds for sequential minimax regret. Sequential minimax regret is defined as the minimum excess loss over data horizon <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"> <tex-math notation=\"LaTeX\">$T$ </tex-math></inline-formula> that a predictor incurs over the best expert in a class, when the samples are presented sequentially and adversarially. Our upper bounds are established by applying Bayesian averaging over a novel \u201csmooth truncated covering\u201d of the expert class. This allows us to obtain tight (minimax) upper bounds that subsume the best known non-constructive bounds in an algorithmic fashion. For lower bounds, we reduce the problem to analyzing the fixed design regret via a novel application of Shtarkov sum adapted to online learning. We demonstrate the effectiveness of our approach by establishing tight regret bounds for a wide range of expert classes. In particular, we fully characterize the regret of generalized linear function with worst Lipschitz transform functions when the parameters are restricted to a unit norm <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"> <tex-math notation=\"LaTeX\">$\\ell _{s}$ </tex-math></inline-formula> ( <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"> <tex-math notation=\"LaTeX\">$s\\ge 2$ </tex-math></inline-formula> ) ball of dimension <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"> <tex-math notation=\"LaTeX\">$d$ </tex-math></inline-formula> . We show that the regret grows as <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"> <tex-math notation=\"LaTeX\">$\\Theta (d\\log T)$ </tex-math></inline-formula> when <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"> <tex-math notation=\"LaTeX\">$d\\le O(T^{s/(s+1)-\\epsilon })$ </tex-math></inline-formula> for all <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"> <tex-math notation=\"LaTeX\">$\\epsilon &gt;0$ </tex-math></inline-formula> (with precise constant 1 when <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"> <tex-math notation=\"LaTeX\">$d\\le e^{o(\\log T)}$ </tex-math></inline-formula> ) and <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"> <tex-math notation=\"LaTeX\">$\\tilde {O}(T^{s/(s+1)})$ </tex-math></inline-formula> when <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"> <tex-math notation=\"LaTeX\">$d\\ge \\Omega (T^{s/(s+1)})$ </tex-math></inline-formula> . Finally, we show that the Bayesian approach may not always be optimal if the support of the prior is included in the reference class itself."}}
{"id": "m5eCbqUa6Iy", "cdate": 1672531200000, "mdate": 1692543855326, "content": {"title": "Online Learning in Dynamically Changing Environments", "abstract": "We study the problem of online learning and online regret minimization when samples are drawn from a general unknown \\emph{non-stationary} process. We introduce the concept of a \\emph{dynamic chang..."}}
{"id": "8yJF7y9G6o", "cdate": 1672531200000, "mdate": 1695957201052, "content": {"title": "Robust Online Classification: From Estimation to Denoising", "abstract": "We study online classification in the presence of noisy labels. The noise mechanism is modeled by a general kernel that specifies, for any feature-label pair, a (known) set of distributions over noisy labels. At each time step, an adversary selects an unknown distribution from the distribution set specified by the kernel based on the actual feature-label pair, and generates the noisy label from the selected distribution. The learner then makes a prediction based on the actual features and noisy labels observed thus far, and incurs loss $1$ if the prediction differs from the underlying truth (and $0$ otherwise). The prediction quality is quantified through minimax risk, which computes the cumulative loss over a finite horizon $T$. We show that for a wide range of natural noise kernels, adversarially selected features, and finite class of labeling functions, minimax risk can be upper bounded independent of the time horizon and logarithmic in the size of labeling function class. We then extend these results to inifinite classes and stochastically generated features via the concept of stochastic sequential covering. Our results extend and encompass findings of Ben-David et al. (2009) through substantial generality, and provide intuitive understanding through a novel reduction to online conditional distribution estimation."}}
{"id": "9s3CbJh4vRP", "cdate": 1652737325372, "mdate": null, "content": {"title": "Precise Regret Bounds for Log-loss via a Truncated Bayesian Algorithm", "abstract": "We study sequential general online regression, known also as sequential probability assignments, under logarithmic loss when compared against a broad class of experts. We obtain tight, often matching, lower and upper bounds for sequential minimax regret, which is defined as the excess loss incurred by the predictor over the best expert in the class. After proving a general upper bound we consider some specific classes of experts from Lipschitz class to bounded Hessian class and derive matching lower and upper bounds with provably optimal constants. Our bounds work for a wide range of values of the data dimension and the number of rounds. To derive lower bounds, we use tools from information theory (e.g., Shtarkov sum) and for upper bounds, we resort to new \"smooth truncated covering\" of the class of experts. This allows us to find constructive proofs by applying a simple and novel truncated Bayesian algorithm. Our proofs are substantially simpler than the existing ones and yet provide tighter (and often optimal) bounds."}}
{"id": "0Cn8n0N5aQI", "cdate": 1640995200000, "mdate": 1663384070511, "content": {"title": "Sequential vs. Fixed Design Regrets in Online Learning", "abstract": "In source coding since Davisson\u2019s seminal paper [1] various redundancy and regrets were thoroughly analyzed, from pointwise redundancy, to average and maximal minimax and maxmin regrets. Similarly, in online learning, there are various formulations of regrets that are grouped into fixed-design (when data is known in advance) and sequential. This position paper gives a brief overview of current formulations of regrets, and provides a thorough comparison of the sequential and fixed design formulations. Moreover, inspired by the source coding literature, new classes of regrets, from average to worst case minimax, are introduced. In particular, it is shown that the fixed design and sequential regrets are equal in the worst case and average sense when data is known in advance; but, in maximal sense (when maximizing over data), the former can be significantly smaller than the latter. Specifically, this paper proves that under logarithmic loss (i) for linear predictors the two maximal formulations are of the same order; and (ii) for linear threshold predictors, fixed design maximal regret is logarithmically smaller than the sequential one."}}
{"id": "ZCgOylhnxE0", "cdate": 1609459200000, "mdate": 1652034941846, "content": {"title": "Non-uniform Consistency of Online Learning with Random Sampling", "abstract": "We study the problem of online learning a hypothesis class and a given binary 0-1 loss function, using instances generated $i.i.d.$ by a given distribution. The goal of the online learner is to make only finitely many errors (loss 1) with probability $1$ in the infinite horizon. In the binary label case, we show that hypothesis classes are online learnable in the above sense if and only if the class is effectively countable. We extend the results to hypothesis classes where labels can be non-binary. Characterization of non-binary online learnable classes is more involved for general loss functions and is not captured fully by the countability condition even for the ternary label case. In the computational bounded setup, we compare our results with well known results in recursive function learning, showing that the class of all total computable functions is indeed learnable with computable online learners and randomized sampling. Finally, we also show that the finite error guarantee will not be affected even when independent noise is added to the label."}}
{"id": "OdmtcMEM1UY", "cdate": 1609459200000, "mdate": 1652034941844, "content": {"title": "Prediction with Finitely many Errors Almost Surely", "abstract": "Using only samples from a probabilistic model, we predict properties of the model and of future observations. The prediction game continues in an online fashion as the sample size grows with new observations. After each prediction, the predictor incurs a binary (0-1) loss. The probability model underlying a sample is otherwise unknown except that it belongs to a known class of models. The goal is to make finitely many errors (i.e. loss of 1) with probability 1 under the generating model, no matter what it may be in the known model class. Model classes admitting predictors that make only finitely many errors are eventually almost surely (eas) predictable. When the losses incurred are observable (the supervised case), we completely characterize eas predictable classes. We provide analogous results in the unsupervised case. Our results have a natural interpretation in terms of regularization. In eas-predictable classes, we study if it is possible to have a universal stopping rule that identifies (to any given confidence) when no more errors will be made. Classes admitting such a stopping rule are eas learnable. When samples are generated iid, we provide a complete characterization of eas learnability. We also study cases when samples are not generated iid, but a full characterization remains open at this point."}}
{"id": "My1E8H-8kDa", "cdate": 1609459200000, "mdate": 1652034941844, "content": {"title": "Estimating Properties of Dynamic Graphical Models", "abstract": "We study the problem of estimating properties of dynamic graphical models in the non-asymptotic regime. Instead of characterizing the behavior of estimation rules with asymptotic consistency, we study sharp bounds on the sample size required to estimate the properties. We show that for certain spatio-temporal Markov random fields governed by an underlying graph, one can estimate certain natural properties with logarithmic (w.r.t. the size of the underlying graph) sample complexity. Matching lower bounds are also established for such estimation problems. We highlight our results with a \u201cbit river\u201d abstraction, where a Bernoulli source at one node flows along the edges of an underlying graph, and the task is to obtain the flow trajectory. If we do not have any restriction on the model class under consideration, we also show that an exponential sample size is required for even very simple properties."}}
{"id": "nPNFDbe806", "cdate": 1577836800000, "mdate": 1652126395705, "content": {"title": "Entropy property testing with finitely many errors", "abstract": "Let P be a class of distributions over natural numbers, and A be a subset of \u211d <sup xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">+</sup> . We study the problem of deciding, using i.i.d. samples X <sub xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">1</sub> ,X <sub xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">2</sub> ,... from an unknown p \u2208 P, whether the entropy H(p) is in A or not. The decision is updated based on every new observation X <sub xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">n</sub> -we are interested in decision rules that make only finitely many errors no matter what the underlying source is. We give necessary and sufficient conditions on the class P and A that can be decided with only finitely many errors. We show for example that such rules exist for testing the rationality of entropy within a given interval, for testing if the entropy falls in an interval of form (a,b], but no such decision rule exists to determine if the entropy is finite or if the entropy falls in an interval of form [a,b]. In the process, we also highlight the conceptual foundation this framework shares with regularization."}}
{"id": "EJSl66H1M5y", "cdate": 1546300800000, "mdate": 1652034941835, "content": {"title": "Being correct eventually almost surely", "abstract": "We study the problem of predicting upper bounds on the next draw of an unknown probability distribution after observing a sample generated by it. The unknown distribution is modeled as belonging to a class P of distributions over natural numbers. The goal is to err only finitely many times even though the game proceeds over an infinite horizon, and though there is no upper bound on what the next sample can be. If a universal prediction scheme exists that makes only finitely many errors regardless of what model in P generated the data, we say P is eventually almost surely (e.a.s.) predictable. In this paper, we fully characterize when P can be e.a.s.-predictable."}}
