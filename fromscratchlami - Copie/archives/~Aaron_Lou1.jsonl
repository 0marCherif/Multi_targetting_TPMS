{"id": "tNhxxrYTTOp", "cdate": 1684690349080, "mdate": 1684690349080, "content": {"title": "Reflected Diffusion Models", "abstract": "Score-based diffusion models learn to reverse a stochastic differential equation that maps data to noise. However, they can generate values that violate natural boundary constraints, such as images that lie outside of pixel space or categorical probabilities with negative values. Since naive recovery techniques produce unnatural samples, previous methods resort to projecting to the feasible set after each diffusion step, leading to a mismatch between the training and generation processes. To address the boundary problem in a principled manner, we present Reflected Diffusion Models, which learn to reverse a reflected stochastic differential equation that perturbs data on a prescribed domain. Our method learns the score functions of the perturbed densities with a new score matching loss for bounded domains and parameterizes a reverse reflected stochastic differential equation with these scores. Additionally, to train with and evaluate likelihoods, we extend Girsanov's theorem to derive an equivalence between the new score matching loss and the ELBO of the diffusion model. We also bridge the theoretical gap with the aforementioned \"projection after each step\" trick; the method is precisely a sampling method for reflected stochastic differential equations and can be improved with our proposed score matching objective. Finally, on standard image generation benchmarks our method remains competitive with or surpasses the state of the art without any architectural changes."}}
{"id": "25HMCfbzOC", "cdate": 1632875421810, "mdate": null, "content": {"title": "Learning Complex Geometric Structures from Data with Deep Riemannian Manifolds", "abstract": "We present Deep Riemannian Manifolds, a new class of neural network parameterized Riemannian manifolds that can represent and learn complex geometric structures. To do this, we first construct a neural network which outputs symmetric positive definite matrices and show that the induced metric can universally approximate all geometries. We then develop differentiable solvers for core manifold operations like the Riemannian exponential and logarithmic map, allowing us to train the manifold parameters in an end-to-end machine learning system. We apply our method to learn 1) low-distortion manifold graph embeddings and 2) the underlying manifold of geodesic data. In addition to improving upon the baselines, our ability to directly optimize the Riemannian manifold brings to light new perspectives with which to view these tasks."}}
{"id": "gGJRwZmCFm4", "cdate": 1622637629498, "mdate": null, "content": {"title": "Equivariant Manifold Flows", "abstract": "Tractably modelling distributions over manifolds has long been an important goal in the natural sciences. Recent work has focused on developing general machine learning models to learn such distributions. However, for many applications these distributions must respect manifold symmetries---a trait which most previous models disregard. In this paper, we lay the theoretical foundations for learning symmetry-invariant distributions on arbitrary manifolds via equivariant manifold flows. We demonstrate the utility of our approach by using it to learn gauge invariant densities over SU(n) in the context of quantum field theory."}}
{"id": "lzZX7E713nJ", "cdate": 1621630084183, "mdate": null, "content": {"title": "Equivariant Manifold Flows", "abstract": "Tractably modelling distributions over manifolds has long been an important goal in the natural sciences. Recent work has focused on developing general machine learning models to learn such distributions. However, for many applications these distributions must respect manifold symmetries\u2014a trait which most previous models disregard. In this paper, we lay the theoretical foundations for learning symmetry-invariant distributions on arbitrary manifolds via equivariant manifold flows. We demonstrate the utility of our approach by learning quantum field theory-motivated invariant SU(n) densities and by correcting meteor impact dataset bias."}}
{"id": "099uYP0EKsJ", "cdate": 1621630077570, "mdate": null, "content": {"title": "Intrinsic Dimension, Persistent Homology and Generalization in Neural Networks", "abstract": "Disobeying the classical wisdom of statistical learning theory, modern deep neural networks generalize well even though they typically contain millions of parameters. Recently, it has been shown that the trajectories of iterative optimization algorithms can possess \\emph{fractal structures}, and their generalization error can be formally linked to the complexity of such fractals. This complexity is measured by the fractal's \\emph{intrinsic dimension}, a quantity usually much smaller than the number of parameters in the network. Even though this perspective provides an explanation for why overparametrized networks would not overfit, computing the intrinsic dimension (\\eg, for monitoring generalization during training) is a notoriously difficult task,  where existing methods typically fail even in moderate ambient dimensions. In this study, we consider this problem from the lens of topological data analysis (TDA) and develop a generic computational tool that is built on rigorous mathematical foundations. By making a novel connection between learning theory and TDA, we first illustrate that the generalization error can be equivalently bounded in terms of a notion called the 'persistent homology dimension' (PHD), where, compared with prior work, our approach does not require any additional geometrical or statistical assumptions on the training dynamics. Then, by utilizing recently established theoretical results and TDA tools, we develop an efficient algorithm to estimate PHD in the scale of modern deep neural networks and further provide visualization tools to help understand generalization in deep learning. Our experiments show that the proposed approach can efficiently compute a network's intrinsic dimension in a variety of settings, which is predictive of the generalization error. "}}
{"id": "zxX2JzVIe9i", "cdate": 1577836800000, "mdate": null, "content": {"title": "Differentiating through the Fr\u00e9chet Mean", "abstract": "Recent advances in deep representation learning on Riemannian manifolds extend classical deep learning operations to better capture the geometry of the manifold. One possible extension is the Fr\\'echet mean, the generalization of the Euclidean mean; however, it has been difficult to apply because it lacks a closed form with an easily computable derivative. In this paper, we show how to differentiate through the Fr\\'echet mean for arbitrary Riemannian manifolds. Then, focusing on hyperbolic space, we derive explicit gradient expressions and a fast, accurate, and hyperparameter-free Fr\\'echet mean solver. This fully integrates the Fr\\'echet mean into the hyperbolic neural network pipeline. To demonstrate this integration, we present two case studies. First, we apply our Fr\\'echet mean to the existing Hyperbolic Graph Convolutional Network, replacing its projected aggregation to obtain state-of-the-art results on datasets with high hyperbolicity. Second, to demonstrate the Fr\\'echet mean's capacity to generalize Euclidean neural network operations, we develop a hyperbolic batch normalization method that gives an improvement parallel to the one observed in the Euclidean setting."}}
{"id": "fH5pjh4JmHz", "cdate": 1577836800000, "mdate": null, "content": {"title": "Neural Manifold Ordinary Differential Equations", "abstract": "To better conform to data geometry, recent deep generative modelling techniques adapt Euclidean constructions to non-Euclidean spaces. In this paper, we study normalizing flows on manifolds. Previous work has developed flow models for specific cases; however, these advancements hand craft layers on a manifold-by-manifold basis, restricting generality and inducing cumbersome design constraints. We overcome these issues by introducing Neural Manifold Ordinary Differential Equations, a manifold generalization of Neural ODEs, which enables the construction of Manifold Continuous Normalizing Flows (MCNFs). MCNFs require only local geometry (therefore generalizing to arbitrary manifolds) and compute probabilities with continuous change of variables (allowing for a simple and expressive flow construction). We find that leveraging continuous manifold dynamics produces a marked improvement for both density estimation and downstream tasks."}}
{"id": "VBEtRuaZdiQ", "cdate": 1577836800000, "mdate": null, "content": {"title": "Differentiating through the Fr\u00e9chet Mean", "abstract": "Recent advances in deep representation learning on Riemannian manifolds extend classical deep learning operations to better capture the geometry of the manifold. One possible extension is the Fr{\u00e9}..."}}
{"id": "EdHZXXyId9J", "cdate": 1577836800000, "mdate": null, "content": {"title": "Neural Manifold Ordinary Differential Equations", "abstract": "To better conform to data geometry, recent deep generative modelling techniques adapt Euclidean constructions to non-Euclidean spaces. In this paper, we study normalizing flows on manifolds. Previous work has developed flow models for specific cases; however, these advancements hand craft layers on a manifold-by-manifold basis, restricting generality and inducing cumbersome design constraints. We overcome these issues by introducing Neural Manifold Ordinary Differential Equations, a manifold generalization of Neural ODEs, which enables the construction of Manifold Continuous Normalizing Flows (MCNFs). MCNFs require only local geometry (therefore generalizing to arbitrary manifolds) and compute probabilities with continuous change of variables (allowing for a simple and expressive flow construction). We find that leveraging continuous manifold dynamics produces a marked improvement for both density estimation and downstream tasks."}}
{"id": "AQkJcFn5SyT", "cdate": 1514764800000, "mdate": null, "content": {"title": "Adversarial Example Decomposition", "abstract": "Research has shown that widely used deep neural networks are vulnerable to carefully crafted adversarial perturbations. Moreover, these adversarial perturbations often transfer across models. We hypothesize that adversarial weakness is composed of three sources of bias: architecture, dataset, and random initialization. We show that one can decompose adversarial examples into an architecture-dependent component, data-dependent component, and noise-dependent component and that these components behave intuitively. For example, noise-dependent components transfer poorly to all other models, while architecture-dependent components transfer better to retrained models with the same architecture. In addition, we demonstrate that these components can be recombined to improve transferability without sacrificing efficacy on the original model."}}
