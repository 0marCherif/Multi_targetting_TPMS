{"id": "p4fjAmGyZM", "cdate": 1696356559665, "mdate": 1696356559665, "content": {"title": "Mitigating Source Bias for Fairer Weak Supervision", "abstract": "Weak supervision enables efficient development of training sets by reducing the need for ground truth labels. However, the techniques that make weak supervision attractive---such as integrating any source of signal to estimate unknown labels---also entail the danger that the produced pseudolabels are highly biased. Surprisingly, given everyday use and the potential for increased bias, weak supervision has not been studied from the point of view of fairness. We begin such a study, starting with the observation that even when a fair model can be built from a dataset with access to ground-truth labels, the corresponding dataset labeled via weak supervision can be arbitrarily unfair. To address this, we propose and empirically validate a model for source unfairness in weak supervision, then introduce a simple counterfactual fairness-based technique that can mitigate these biases. Theoretically, we show that it is possible for our approach to simultaneously improve both accuracy and fairness---in contrast to standard fairness approaches that suffer from tradeoffs. Empirically, we show that our technique improves accuracy on weak supervision baselines by as much as 32% while reducing demographic parity gap by 82.5%. A simple extension of our method aimed at maximizing performance produces state-of-the-art performance in five out of ten datasets in the WRENCH benchmark."}}
{"id": "rVTCh-6Vc9", "cdate": 1683911606003, "mdate": 1683911606003, "content": {"title": "Escaping Label Subspaces via Label Geometry", "abstract": "We propose a simple approach for learning in label spaces of extremely high cardinality. In this setting, only a subset of the labels are observed at training time, but we have access to metric information that relates the labels---a common scenario in zero-shot learning, hierarchical classification, and structured prediction. Our technique adapts trained models to produce predictions of unobserved classes. We provide three theoretical insights. First, we give a characterization of the scenarios in which it is possible to predict any unobserved class. Next, we introduce an optimal active learning-like next class selection procedure for when it is not possible to do so. Lastly, we study learning-theoretic tradeoffs between label space richness, sample complexity, and model dimension. Empirical results show that it is possible to use our approach to gain up to 19.5% improvement on pre-trained zero-shot models like CLIP."}}
{"id": "gvoiTO6G_sS", "cdate": 1653750179628, "mdate": null, "content": {"title": "Causal Omnivore: Fusing Noisy Estimates of Spurious Correlations", "abstract": "Spurious correlations are one of the biggest pain points for users of modern machine learning. To handle this issue, many approaches attempt to learn features that are causally linked to the prediction variable. Such techniques, however, suffer from various flaws---they are often prohibitively complex or based on heuristics and strong assumptions that may fail in practice. There is no one-size-fits-all causal feature identification approach. To address this challenge, we propose a simple way to fuse multiple noisy estimates of causal features. Our approach treats the underlying causal structure as a latent variable and exploits recent developments in estimating latent structures without any access to ground truth. We propose new sources, including an automated way to extract causal insights from existing ontologies or foundation models. On multiple benchmark environmental shift datasets, our discovered features can train a model via vanilla empirical risk minimization that outperforms multiple baselines, including automated causal feature discovery techniques such as invariant risk minimization on three benchmark datasets."}}
