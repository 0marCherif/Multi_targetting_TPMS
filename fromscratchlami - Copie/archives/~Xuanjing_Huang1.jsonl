{"id": "GPbiCYiDVqr", "cdate": 1696601445626, "mdate": 1696601445626, "content": {"title": "DiffusionBERT: Improving Generative Masked Language Models with Diffusion Models", "abstract": "We present DiffusionBERT, a new generative masked language model based on discrete dif- fusion models. Diffusion models and many pre- trained language models have a shared training objective, i.e., denoising, making it possible to combine the two powerful models and enjoy the best of both worlds. On the one hand, dif- fusion models offer a promising training strat- egy that helps improve the generation quality. On the other hand, pre-trained denoising lan- guage models (e.g., BERT) can be used as a good initialization that accelerates convergence. We explore training BERT to learn the reverse process of a discrete diffusion process with an absorbing state and elucidate several designs to improve it. First, we propose a new noise schedule for the forward diffusion process that controls the degree of noise added at each step based on the information of each token. Sec- ond, we investigate several designs of incorpo- rating the time step into BERT. Experiments on unconditional text generation demonstrate that DiffusionBERT achieves significant improve- ment over existing diffusion models for text (e.g., D3PM and Diffusion-LM) and previous generative masked language models in terms of perplexity and BLEU score. Promising results in conditional generation tasks show that DiffusionBERT can generate texts of compa- rable quality and more diverse than a series of established baselines."}}
{"id": "htxI8XOqdr", "cdate": 1696601378138, "mdate": 1696601378138, "content": {"title": "Multitask Pre-training of Modular Prompt for Chinese Few-Shot Learning", "abstract": "Prompt tuning is a parameter-efficient approach to adapting pre-trained language models to downstream tasks. Although prompt tuning has been shown to match the performance of full model tuning when training data is sufficient, it tends to struggle in few-shot learning settings. In this paper, we present Multi-task Pre-trained Modular Prompt (MP2) to boost prompt tun- ing for few-shot learning. MP2 is a set of combinable prompts pre-trained on 38 Chinese tasks. On downstream tasks, the pre-trained prompts are selectively activated and combined, leading to strong compositional generalization to unseen tasks. To bridge the gap between pre-training and fine-tuning, we formulate up- stream and downstream tasks into a unified ma- chine reading comprehension task. Extensive experiments under two learning paradigms, i.e., gradient descent and black-box tuning, show that MP2 significantly outperforms prompt tun- ing, full model tuning, and prior prompt pre- training methods in few-shot settings. In ad- dition, we demonstrate that MP2 can achieve surprisingly fast and strong adaptation to down- stream tasks by merely learning 8 parameters to combine the pre-trained modular prompts"}}
{"id": "UYigvpNBAI", "cdate": 1686228424447, "mdate": null, "content": {"title": "TextFusion: Privacy-Preserving Pre-trained Model Inference via Token Fusion", "abstract": "Recently, more and more pre-trained language models are released as a cloud service. It allows users who lack computing resources to perform inference with a powerful model by uploading data to the cloud. The plain text may contain private information, as the result, users prefer to do partial computations locally and upload intermediate representations to the cloud for subsequent inference. However, recent studies have shown that intermediate representations can also be recovered to plain text with reasonable accuracy, thus the risk of privacy leakage still exists. To address this issue, we propose TextFusion, a novel method for preserving inference privacy. Specifically, we train a Fusion Predictor to dynamically fuse token representations, which hides multiple private token representations behind an unrecognizable one. Furthermore, an adversarial training regime is employed to privatize these representations. In this way, the cloud only receives incomplete and perturbed representations, making it difficult to accurately recover the complete plain text. The experimental results on diverse classification tasks show that our approach can effectively preserve inference privacy without significantly sacrificing performance in different scenarios."}}
{"id": "cRQwl-59CU8", "cdate": 1663850246622, "mdate": null, "content": {"title": "UTC-IE: A Unified Token-pair Classification Architecture for Information Extraction", "abstract": "Information Extraction (IE) spans several tasks with different output structures, such as named entity recognition, relation extraction and event extraction. Previously, those tasks were solved with different models because of diverse task output structures. Through re-examining IE tasks, we find that all of them can be interpreted as extracting spans and span relations. We propose using the start and end token of a span to pinpoint the span in texts, and using the start-to-start and end-to-end token pairs of two spans to determine the relation. Hence, we can unify all IE tasks under the same token-pair classification formulation. Based on the reformulation, we propose a \\textbf{U}nified \\textbf{T}oken-pair \\textbf{C}lassification architecture for \\textbf{I}nformation \\textbf{E}xtraction (\\textbf{UTC-IE}), where we introduce Plusformer on top of the token-pair feature matrix. Specifically, it models axis-aware interaction with plus-shaped self-attention and local interaction with Convolutional Neural Network over token pairs. Experiments show that our approach outperforms task-specific and unified models on all tasks in 10 datasets, and achieves better or comparable results on 2 joint IE datasets. Moreover, UTC-IE speeds up over state-of-the-art models on IE tasks significantly in most datasets, which verifies the effectiveness of our architecture."}}
{"id": "7XCFxnG8nGS", "cdate": 1652737742255, "mdate": null, "content": {"title": "Regularized Molecular Conformation Fields", "abstract": "Predicting energetically favorable 3-dimensional conformations of organic molecules from\nmolecular graph plays a fundamental role in computer-aided drug discovery research.\nHowever, effectively exploring the high-dimensional conformation space to identify (meta) stable conformers is anything but trivial.\nIn this work, we introduce RMCF, a novel framework to \ngenerate a diverse set of low-energy molecular conformations through sampling\nfrom a regularized molecular conformation field.\nWe develop a data-driven molecular segmentation algorithm to automatically partition each molecule into several structural building blocks to reduce the modeling degrees of freedom.\nThen, we employ a Markov Random Field to learn the joint probability distribution of fragment configurations and inter-fragment dihedral angles, \nwhich enables us to sample from different low-energy regions of a conformation space.\nOur model constantly outperforms state-of-the-art models for the conformation generation task on the GEOM-Drugs dataset.\nWe attribute the success of RMCF to modeling in a regularized feature space and learning a global fragment configuration distribution for effective sampling.\nThe proposed method could be generalized to deal with larger biomolecular systems."}}
{"id": "mjVZw5ADSbX", "cdate": 1652737528946, "mdate": null, "content": {"title": "CoNT: Contrastive Neural Text Generation", "abstract": "Recently, contrastive learning attracts increasing interests in neural text generation as a new solution to alleviate the exposure bias problem.  It introduces a sequence-level training signal which is crucial to generation tasks that always rely on auto-regressive decoding. However, previous methods using contrastive learning in neural text generation usually lead to inferior performance. In this paper, we analyse the underlying reasons and propose a new Contrastive Neural Text generation framework, CoNT.  CoNT addresses bottlenecks that prevent contrastive learning from being widely adopted in generation tasks from three aspects -- the construction of contrastive examples, the choice of the contrastive loss, and the strategy in decoding. We validate CoNT on five generation tasks with ten benchmarks, including machine translation, summarization, code comment generation, data-to-text generation and commonsense generation.  Experimental results show that CoNT clearly outperforms its baseline on all the ten benchmarks with a convincing margin.  Especially, CoNT surpasses previous the most competitive contrastive learning method for text generation, by 1.50 BLEU on machine translation and 1.77 ROUGE-1 on summarization, respectively. It achieves new state-of-the-art on summarization, code comment generation (without external data) and data-to-text generation."}}
{"id": "8kVP8m93VqN", "cdate": 1632875674034, "mdate": null, "content": {"title": "Task-oriented Dialogue System for Automatic Disease Diagnosis via Hierarchical Reinforcement Learning", "abstract": "In this paper, we focus on automatic disease diagnosis with reinforcement learning (RL) methods in task-oriented dialogues setting. Different from conventional RL tasks, the action space for disease diagnosis (i.e., symptoms) is inevitably large, especially when the number of diseases increases. However, existing approaches to this problem typically works well in simple tasks but has significant challenges in complex scenarios. Inspired by the offline consultation process, we propose to integrate a hierarchical policy of two levels into the dialogue policy learning. The high level policy consists of a master model that is responsible for triggering a low level model, the low level policy consists of several symptom checkers and a disease classifier. Experimental results on both self-constructed real-world and synthetic datasets demonstrate that our hierarchical framework achieves higher accuracy and symptom recall in disease diagnosis compared with existing systems.\n"}}
{"id": "CLnj31GZ4cI", "cdate": 1601308170259, "mdate": null, "content": {"title": "K-Adapter: Infusing Knowledge into Pre-Trained Models with Adapters", "abstract": "We study the problem of injecting knowledge into large pre-trained models like BERT and RoBERTa. Existing methods typically update the original parameters of pre-trained models when injecting knowledge. However, when multiple kinds of knowledge are injected, they may suffer from catastrophic forgetting.  To address this, we propose K-Adapter, which remains the original parameters of the pre-trained model fixed and supports continual knowledge infusion. Taking RoBERTa as the pre-trained model, K-Adapter has a neural adapter for each kind of infused knowledge, like a plug-in connected to RoBERTa. There is no information flow between different adapters, thus different adapters are efficiently trained in a distributed way. We inject two kinds of knowledge, including factual knowledge obtained from automatically aligned text-triplets on Wikipedia and Wikidata, and linguistic knowledge obtained from dependency parsing. Results on three knowledge-driven tasks (total six datasets) including relation classification, entity typing and question answering demonstrate that each adapter improves the performance, and the combination of both adapters brings further improvements. Probing experiments further indicate that K-Adapter captures richer factual and commonsense knowledge than RoBERTa."}}
{"id": "_QQ_v_w_uNV", "cdate": 1601308053716, "mdate": null, "content": {"title": "Generating universal language adversarial examples by understanding and enhancing the transferability across neural models", "abstract": "Deep neural network models are vulnerable to adversarial attacks. In many cases, malicious inputs intentionally crafted for one model can fool another model in the black-box attack setting. However, there is a lack of systematic studies on the transferability of adversarial examples and how to generate universal adversarial examples. In this paper, we systematically study the transferability of adversarial attacks for text classification models. In particular, we conduct extensive experiments to investigate how various factors, such as network architecture, input format, word embedding, and model capacity, affect the transferability of adversarial attacks. Based on these studies, we then propose universal black-box attack algorithms that can induce adversarial examples to attack almost all existing models. These universal adversarial examples reflect the defects of the learning process and the bias in the training dataset. Finally, we generalize these adversarial examples into universal word replacement rules that can be used for model diagnostics. "}}
{"id": "HJxTgeBtDr", "cdate": 1569439733134, "mdate": null, "content": {"title": "Towards Interpretable Evaluations: A Case Study of Named Entity Recognition", "abstract": "    With the proliferation of models for natural language processing (NLP) tasks, it is even harder to understand the differences between models and their relative merits. Simply looking at differences between holistic metrics such as accuracy, BLEU, or F1 do not tell us \\emph{why} or \\emph{how} a particular method is better and how dataset biases influence the choices of model design.\n    In this paper, we present a general methodology for {\\emph{interpretable}} evaluation of NLP systems and choose the task of named entity recognition (NER) as a case study, which is a core task of identifying people, places, or organizations in text. The proposed evaluation method enables us to interpret the \\textit{model biases}, \\textit{dataset biases}, and how the \\emph{differences in the datasets} affect the design of the models, identifying the strengths and weaknesses of current approaches. By making our {analysis} tool available, we make it easy for future researchers to run similar analyses and drive the progress in this area."}}
