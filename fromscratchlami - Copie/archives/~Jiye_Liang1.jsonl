{"id": "kZ2O8o0k1uY", "cdate": 1688169600000, "mdate": 1682409034527, "content": {"title": "A bi-level metric learning framework via self-paced learning weighting", "abstract": ""}}
{"id": "V8GQWbh0F8", "cdate": 1685577600000, "mdate": 1682409034514, "content": {"title": "High-order graph attention network", "abstract": ""}}
{"id": "LzYKvG7Us8", "cdate": 1683879343292, "mdate": 1683879343292, "content": {"title": "Spectral Clustering with Robust Self-learning Constraints", "abstract": "Spectral clustering is a leading unsupervised classification algorithm widely used to capture complex clusters in unlabeled data. Additional prior information can further enhance the quality of spectral clustering results to satisfy users' expectations. However, it is challenging for users to find the prior information under unsupervised scenes. To get rid of the deficiency, we propose a spectral clustering model with robust self-learning constraints. In this model, we first extend the optimization problem of spectral clustering by seeing label constraints as variables to learn the constraints and the clustering result simultaneously. Furthermore, we add a robust term to the proposed model so that we can learn multiple groups of label constraints to guide the clustering process and find a robust self-constrained spectral clustering result. The robust term can reduce the impact of uncertainty in the quality of a single set of label constraints on the performance of the proposed model. An iterative strategy with update formulas for variables is proposed to solve the self-constrained spectral clustering problem. We provide the theoretical analysis to explain the importance of the learned constraints in spectral clustering. Furthermore, we analyze the convergence of our optimization scheme. Finally, we have done many experiments on benchmark data sets to illustrate the effectiveness of the proposed algorithm."}}
{"id": "H-zD6JJdH4F", "cdate": 1680307200000, "mdate": 1682409034474, "content": {"title": "Self-Constrained Spectral Clustering", "abstract": "As a leading graph clustering technique, spectral clustering is one of the most widely used clustering methods to capture complex clusters in data. Some additional prior information can help it to further reduce the difference between its clustering results and users\u2019 expectations. However, it is hard to get the prior information under unsupervised scene to guide the clustering process. To solve this problem, we propose a self-constrained spectral clustering algorithm. In this algorithm, we extend the objective function of spectral clustering by adding pairwise and label self-constrained terms to it. We provide the theoretical analysis to show the roles of the self-constrained terms and the extensibility of the proposed algorithm. Based on the new objective function, we build an optimization model for self-constrained spectral clustering so that we can simultaneously learn the clustering results and constraints. Furthermore, we propose an iterative method to solve the new optimization problem. Compared to other existing versions of spectral clustering algorithms, the new algorithm can discover a high-quality cluster structure of a data set without prior information. Extensive experiments on benchmark data sets illustrate the effectiveness of the proposed algorithm."}}
{"id": "-tiqMFLxS96", "cdate": 1680307200000, "mdate": 1682409034436, "content": {"title": "Multiple metric learning via local metric fusion", "abstract": ""}}
{"id": "quxI4NZ8LL", "cdate": 1677628800000, "mdate": 1682409034502, "content": {"title": "Unsupervised Dimensionality Reduction Based on Fusing Multiple Clustering Results", "abstract": "The majority of the classical dimensionality reduction methods can be unified into a graph-embedding-based framework. A fixed graph constructed in a high-dimensional space has been extensively employed in the graph-embedding-based dimensionality reduction methods. However, a fixed graph often cannot characterize the structure of high-dimensional data owing to the curse of dimensionality. To solve this problem, we combine graph construction and dimensionality reduction into a coherent framework. Thus, the constructed graph can be updated dynamically in dimensionality reduction. In the existing methods based on the coherent framework, graphs are usually constructed by a type of neighborhood relationship and single clustering result. This study proposes an unsupervised dimensionality reduction method guided by fusing multiple clustering results. In the proposed method, multiple clustering results are first obtained by the k-means algorithm, and then a graph is constructed using a weighted co-association matrix of fusing the clustering results to capture data distribution information. Based on the graph, we present an objective function of combining graph construction and dimensionality reduction to implement mutual guidance between them. Numerical experiments on real data sets illustrate that the proposed method achieves significant improvement over some representative and state-of-the-art unsupervised dimensionality reduction methods."}}
{"id": "6x-b4MGWWP", "cdate": 1677628800000, "mdate": 1682409034488, "content": {"title": "Hybrid sampling-based contrastive learning for imbalanced node classification", "abstract": "Imbalanced node classification is a vital task because it widely exists in many real-world applications, such as financial fraud detection, anti-money laundering, drug reaction prediction and so on. However, many recent methods are for balanced graph-structured datasets, and do not perform well on imbalanced data. Therefore, we propose a hybrid sampling-based contrastive learning method (HSCL) for imbalanced node classification to alleviate this problem. The core of our method is to adopt the hybrid sampling method in contrastive learning, that is, undersampling majority classes and oversampling minority classes, to achieve a balance of samples from different classes in contrastive learning and thus obtain a discriminative representation. HSCL has been evaluated extensively on five real-world data sets. Experimental results show that the proposed method obtains better performance than other state-of-the-art methods."}}
{"id": "gDSnLjL4J1R", "cdate": 1672531200000, "mdate": 1682409034361, "content": {"title": "A trilevel analysis of uncertainty measuresin partition-based granular computing", "abstract": "Uncertainty measure is one of the most significant concepts and fundamental issues in granular computing. Nowadays, there have been extensive studies on various uncertainty measures for quantifying diverse properties and associations of granules and granular structures. However, there is a lack of a systematic study for uncertain measures. Based on a trilevel thinking framework, this paper presents a systematic review and analysis of uncertainty measures used in partition-based models of granular computing. At an object level, a granule level and a granular structure level, we categorize uncertainty measures for describing the properties and the associations of objects, granules, and partitions respectively. Moreover, we illustrate how to construct an uncertainty measure at a higher level from a lower level. At last, we discuss several potential directions to design other new uncertainty measures for partition-based granular computing."}}
{"id": "ff3zEyIuV1", "cdate": 1672531200000, "mdate": 1681652129562, "content": {"title": "Graph Neural Networks with Interlayer Feature Representation for Image Super-Resolution", "abstract": ""}}
{"id": "fMtcFeHswFq", "cdate": 1672531200000, "mdate": 1682409034344, "content": {"title": "A new contrastive learning framework for reducing the effect of hard negatives", "abstract": ""}}
