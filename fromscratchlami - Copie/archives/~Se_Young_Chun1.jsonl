{"id": "bvJOFDMRab", "cdate": 1668515806292, "mdate": 1668515806292, "content": {"title": "Multi-Temporal Recurrent Neural Networks For Progressive Non-Uniform Single Image Deblurring With Incremental Temporal Training", "abstract": "Blind non-uniform image deblurring for severe blurs induced by large motions is still challenging. Multi-scale (MS) approach has been widely used for deblurring that sequentially recovers the downsampled original image in low spatial scale first and then further restores in high spatial scale using the result(s) from lower spatial scale(s). Here, we investigate a novel alternative approach to MS, called multi-temporal (MT), for non-uniform single image deblurring by exploiting time-resolved deblurring dataset from high-speed cameras. MT approach models severe blurs as a series of small blurs so that it deblurs small amount of blurs in the original spatial scale progressively instead of restoring the images in different spatial scales. To realize MT approach, we propose progressive deblurring over iterations and incremental temporal training with temporally augmented training data. Our MT approach, that can be seen as a form of curriculum learning in a wide sense, allows a number of stateof-the-art MS based deblurring methods to yield improved performances without using MS approach. We also proposed a MT recurrent neural network with recurrent feature maps that outperformed state-of-the-art deblurring methods with the smallest number of parameters."}}
{"id": "d8LId6Brc4W", "cdate": 1648698639970, "mdate": 1648698639970, "content": {"title": "Rethinking Deep Image Prior for Denoising", "abstract": "Deep image prior (DIP) serves as a good inductive bias for diverse inverse problems. Among them, denoising is known to be particularly challenging for the DIP due to noise fitting with the requirement of an early stopping. To address the issue, we first analyze the DIP by the notion of effective degrees of freedom (DF) to monitor the optimization progress and propose a principled stopping criterion before fitting to noise without access of a paired ground truth image for Gaussian noise. We also propose the 'stochastic temporal ensemble (STE)' method for incorporating techniques to further improve DIP's performance for denoising. We additionally extend our method to Poisson noise. Our empirical validations show that given a single noisy image, our method denoises the image while pre- serving rich textual details. Further, our approach outperforms prior arts in LPIPS by large margins with comparable PSNR and SSIM on seven different datasets."}}
{"id": "eviyNGp46P", "cdate": 1640995200000, "mdate": 1681693017731, "content": {"title": "Purecomb: Poisson Unbiased Risk Estimator Based Ensemble of Self-Supervised Deep Denoisers For Clinical Bone Scan Image", "abstract": "Bone scan is a clinical practice which is performed in nuclear medicine to evaluate skeletal lesions or bone metastases. Reducing scan time is desirable due to faster throughput of gamma camera and reducing potential patient movement, but leads to increased noise. Some of the recent self-supervised deep denoisers such as Noise2Noise (N2N) and Poisson unbiased risk estimator (PURE) can be good candidates for reducing Poisson noise in nuclear medicine planar images. Here we investigate self-supervised deep denoisers for Poisson noise to boost the performance of denoising. Firstly, we propose to extend PURE to accommodate two correlated noisy images (ePURE) to self-supervisedly train a deep denoiser. Then, we propose PUREmap that measures the uncertainty of incoming noisy input image to ensemble the outputs of deep denoisers trained with N2N and our ePURE. Our proposed method was evaluated with whole body planar bone scans of 326 patients (200 for training and 126 for testing) with and without lesions, yielding comparable denoising performance only with 20% of full count to the deep denoiser that was supervisedly trained with full count images (N2F) while showing lower uncertainty on various count level (5% ~ 30%) compared to N2F."}}
{"id": "Ygtm47gGvOL", "cdate": 1640995200000, "mdate": 1681693017797, "content": {"title": "Physiology-based augmented deep neural network frameworks for ECG biometrics with short ECG pulses considering varying heart rates", "abstract": ""}}
{"id": "Qjeulu7mTA", "cdate": 1640995200000, "mdate": 1668680921490, "content": {"title": "Image Restoration by Deep Projected GSURE", "abstract": "Ill-posed inverse problems appear in many image processing applications, such as deblurring and super-resolution. In recent years, solutions that are based on deep Convolutional Neural Networks (CNNs) have shown great promise. Yet, most of these techniques, which train CNNs using external data, are restricted to the observation models that have been used in the training phase. A recent alternative that does not have this drawback relies on learning the target image using internal learning. One such prominent example is the Deep Image Prior (DIP) technique that trains a network directly on the input image with the least-squares loss. In this paper, we propose a new image restoration framework that is based on minimizing a loss function that includes a \"projected-version\" of the Generalized Stein Unbiased Risk Estimator (GSURE) and parameterization of the latent image by a CNN. We propose two ways to use our framework. In the first one, where no explicit prior is used, we show that the proposed approach outperforms other internal learning methods, such as DIP. In the second one, we show that our GSURE-based loss leads to improved performance when used within a plug-and-play priors scheme."}}
{"id": "M2sNIiCC6C", "cdate": 1632875615924, "mdate": null, "content": {"title": "Self-supervised regression learning using domain knowledge: Applications to improving self-supervised image denoising", "abstract": "Regression that predicts continuous quantity is a central part of applications using computational imaging and computer vision technologies. Yet, studying and understanding self-supervised learning for regression tasks -- except for a particular regression task, image denoising -- have lagged behind. This paper proposes a general self-supervised regression learning (SSRL) framework that enables learning regression neural networks with only input data (but without ground-truth target data), by using a designable operator that encapsulates domain knowledge of a specific application. The paper underlines the importance of domain knowledge by showing that under some mild conditions, the better designable operator is used, the proposed SSRL loss becomes closer to ordinary supervised learning loss. Numerical experiments for natural image denoising and low-dose computational tomography denoising demonstrate that proposed SSRL significantly improves the denoising quality over several existing self-supervised denoising methods."}}
{"id": "kCKxNLt43Rk", "cdate": 1609459200000, "mdate": null, "content": {"title": "Image Restoration by Deep Projected GSURE", "abstract": "Ill-posed inverse problems appear in many image processing applications, such as deblurring and super-resolution. In recent years, solutions that are based on deep Convolutional Neural Networks (CNNs) have shown great promise. Yet, most of these techniques, which train CNNs using external data, are restricted to the observation models that have been used in the training phase. A recent alternative that does not have this drawback relies on learning the target image using internal learning. One such prominent example is the Deep Image Prior (DIP) technique that trains a network directly on the input image with a least-squares loss. In this paper, we propose a new image restoration framework that is based on minimizing a loss function that includes a \"projected-version\" of the Generalized SteinUnbiased Risk Estimator (GSURE) and parameterization of the latent image by a CNN. We demonstrate two ways to use our framework. In the first one, where no explicit prior is used, we show that the proposed approach outperforms other internal learning methods, such as DIP. In the second one, we show that our GSURE-based loss leads to improved performance when used within a plug-and-play priors scheme."}}
{"id": "EyrnqriPvC", "cdate": 1609459200000, "mdate": 1681693017870, "content": {"title": "Rethinking Deep Image Prior for Denoising", "abstract": "Deep image prior (DIP) serves as a good inductive bias for diverse inverse problems. Among them, denoising is known to be particularly challenging for the DIP due to noise fitting with the requirement of an early stopping. To address the issue, we first analyze the DIP by the notion of effective degrees of freedom (DF) to monitor the optimization progress and propose a principled stopping criterion before fitting to noise without access of a paired ground truth image for Gaussian noise. We also propose the \u2018stochastic temporal ensemble (STE)\u2019 method for incorporating techniques to further improve DIP\u2019s performance for denoising. We additionally extend our method to Poisson noise. Our empirical validations show that given a single noisy image, our method denoises the image while preserving rich textual details. Further, our approach outperforms prior arts in LPIPS by large margins with comparable PSNR and SSIM on seven different datasets."}}
{"id": "9YxJivrkAnl", "cdate": 1609459200000, "mdate": null, "content": {"title": "Development and operation of a digital platform for sharing pathology image data", "abstract": "Background Artificial intelligence (AI) research is highly dependent on the nature of the data available. With the steady increase of AI applications in the medical field, the demand for quality medical data is increasing significantly. We here describe the development of a platform for providing and sharing digital pathology data to AI researchers, and highlight challenges to overcome in operating a sustainable platform in conjunction with pathologists. Methods Over 3000 pathological slides from five organs (liver, colon, prostate, pancreas and biliary tract, and kidney) in histologically confirmed tumor cases by pathology departments at three hospitals were selected for the dataset. After digitalizing the slides, tumor areas were annotated and overlaid onto the images by pathologists as the ground truth for AI training. To reduce the pathologists\u2019 workload, AI-assisted annotation was established in collaboration with university AI teams. Results A web-based data sharing platform was developed to share massive pathological image data in 2019. This platform includes 3100 images, and 5 pre-processing algorithms for AI researchers to easily load images into their learning models. Discussion Due to different regulations among countries for privacy protection, when releasing internationally shared learning platforms, it is considered to be most prudent to obtain consent from patients during data acquisition. Conclusions Despite limitations encountered during platform development and model training, the present medical image sharing platform can steadily fulfill the high demand of AI developers for quality data. This study is expected to help other researchers intending to generate similar platforms that are more effective and accessible in the future."}}
{"id": "0xlYdWc0td", "cdate": 1609459200000, "mdate": 1681693017837, "content": {"title": "Task-Aware Variational Adversarial Active Learning", "abstract": "Often, labeling large amount of data is challenging due to high labeling cost limiting the application domain of deep learning techniques. Active learning (AL) tackles this by querying the most informative samples to be annotated among unlabeled pool. Two promising directions for AL that have been recently explored are task-agnostic approach to select data points that are far from the current labeled pool and task-aware approach that relies on the perspective of task model. Unfortunately, the former does not exploit structures from tasks and the latter does not seem to well-utilize overall data distribution. Here, we propose task-aware variational adversarial AL (TA-VAAL) that modifies task-agnostic VAAL, that considered data distribution of both label and unlabeled pools, by relaxing task learning loss prediction to ranking loss prediction and by using ranking conditional generative adversarial network to embed normalized ranking loss information on VAAL. Our proposed TA-VAAL outperforms state-of-the-arts on various benchmark datasets for classifications with balanced / imbalanced labels as well as semantic segmentation and its task-aware and task-agnostic AL properties were confirmed with our in-depth analyses."}}
