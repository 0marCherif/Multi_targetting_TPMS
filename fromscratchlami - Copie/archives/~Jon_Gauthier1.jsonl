{"id": "jwYXpJpVM0", "cdate": 1708278137869, "mdate": 1708278137869, "content": {"title": "Language model acceptability judgements are not always robust to context", "abstract": "Targeted syntactic evaluations of language models ask whether models show stable preferences for syntactically acceptable content over minimal-pair unacceptable inputs. Our best syntactic evaluation datasets, however, provide substantially less linguistic context than models receive during pretraining. This mismatch raises an important question: how robust are models\u2019 syntactic judgements across different contexts? In this paper, we vary the input contexts based on: length, the types of syntactic phenomena it contains, and whether or not there are grammatical violations. We find that model judgements are generally robust when placed in randomly sampled linguistic contexts, but are unstable when contexts match the test stimuli in syntactic structure. Among all tested models (GPT-2 and five variants of OPT), we find that model performance is affected when we provided contexts with matching syntactic structure: performance significantly improves when contexts are acceptable, and it significantly declines when they are unacceptable. This effect is amplified by the length of the context, except for unrelated inputs. We show that these changes in model performance are not explainable by acceptability-preserving syntactic perturbations. This sensitivity to highly specific syntactic features of the context can only be explained by the models\u2019 implicit in-context learning abilities."}}
{"id": "ubcD9dlz2sm", "cdate": 1577836800000, "mdate": null, "content": {"title": "SyntaxGym: An Online Platform for Targeted Evaluation of Language Models", "abstract": "Targeted syntactic evaluations have yielded insights into the generalizations learned by neural network language models. However, this line of research requires an uncommon confluence of skills: both the theoretical knowledge needed to design controlled psycholinguistic experiments, and the technical proficiency needed to train and deploy large-scale language models. We present SyntaxGym, an online platform designed to make targeted evaluations accessible to both experts in NLP and linguistics, reproducible across computing environments, and standardized following the norms of psycholinguistic experimental design. This paper releases two tools of independent value for the computational linguistics community: 1. A website, syntaxgym.org, which centralizes the process of targeted syntactic evaluation and provides easy tools for analysis and visualization; 2. Two command-line tools, \u2018syntaxgym\u2018 and \u2018lm-zoo\u2018, which allow any user to reproduce targeted syntactic evaluations and general language model inference on their own machine."}}
{"id": "piobWZl7VvZ", "cdate": 1577836800000, "mdate": null, "content": {"title": "A Systematic Assessment of Syntactic Generalization in Neural Language Models", "abstract": "While state-of-the-art neural network models continue to achieve lower perplexity scores on language modeling benchmarks, it remains unknown whether optimizing for broad-coverage predictive performance leads to human-like syntactic knowledge. Furthermore, existing work has not provided a clear picture about the model properties required to produce proper syntactic generalizations. We present a systematic evaluation of the syntactic knowledge of neural language models, testing 20 combinations of model types and data sizes on a set of 34 English-language syntactic test suites. We find substantial differences in syntactic generalization performance by model architecture, with sequential models underperforming other architectures. Factorially manipulating model architecture and training dataset size (1M-40M words), we find that variability in syntactic generalization performance is substantially greater by architecture than by dataset size for the corpora tested in our experiments. Our results also reveal a dissociation between perplexity and syntactic generalization performance."}}
{"id": "ZKvDPCsSxd", "cdate": 1577836800000, "mdate": null, "content": {"title": "On the Predictive Power of Neural Language Models for Human Real-Time Comprehension Behavior", "abstract": "Human reading behavior is tuned to the statistics of natural language: the time it takes human subjects to read a word can be predicted from estimates of the word's probability in context. However, it remains an open question what computational architecture best characterizes the expectations deployed in real time by humans that determine the behavioral signatures of reading. Here we test over two dozen models, independently manipulating computational architecture and training dataset size, on how well their next-word expectations predict human reading time behavior on naturalistic text corpora. We find that across model architectures and training dataset sizes the relationship between word log-probability and reading time is (near-)linear. We next evaluate how features of these models determine their psychometric predictive power, or ability to predict human reading behavior. In general, the better a model's next-word expectations, the better its psychometric predictive power. However, we find nontrivial differences across model architectures. For any given perplexity, deep Transformer models and n-gram models generally show superior psychometric predictive power over LSTM or structurally supervised neural models, especially for eye movement data. Finally, we compare models' psychometric predictive power to the depth of their syntactic knowledge, as measured by a battery of syntactic generalization tests developed using methods from controlled psycholinguistic experiments. Once perplexity is controlled for, we find no significant relationship between syntactic knowledge and predictive power. These results suggest that different approaches may be required to best model human real-time language comprehension behavior in naturalistic reading versus behavior for controlled linguistic materials designed for targeted probing of syntactic knowledge."}}
{"id": "zGYCeHYPus", "cdate": 1546300800000, "mdate": null, "content": {"title": "Query-guided visual search", "abstract": "How do we seek information from our environment to find solutions to the questions facing us? We pose an open-ended visual search problem to adult participants, asking them to identify targets of questions in scenes guided by only an incomplete question prefix (e.g. \u201dWhy is...\u201d, \u201cWhere will...\u201d). Participants converged on visual targets and question completions given just these function words, but the preferred targets and completions for a given scene varied dramatically depending on the query. We account for this systematic query-guided behavior with a model linking conventions of linguistic reference to abstract representations of scene events. The ability to predict and find probable targets of incomplete queries may be just one example of a more general ability to pay attention to what problems require of their solutions, and to use those requirements as a helpful guide in searching for solutions."}}
{"id": "d7dq4J1rr49", "cdate": 1546300800000, "mdate": null, "content": {"title": "A rational model of syntactic bootstrapping", "abstract": "Children exploit regular links between the meanings of words and the syntactic structures in which they appear to learn about novel words. This phenomenon, known as syntactic bootstrapping, is thought to play a critical role in word learning, especially for words with more opaque meanings such as verbs. We present a computational word learning model which reproduces such syntactic bootstrapping phenomena after exposure to a naturalistic word learning dataset, even when under substantial memory constraints. The model demonstrates how experimental syntactic bootstrapping effects constitute rational behavior given the nature of natural language input. The model unifies computational accounts of word learning and syntactic bootstrapping effects observed in the laboratory, and offers a path forward for demonstrating the broad power of the syntax\u2013semantics link in language acquisition."}}
{"id": "Ub8TkYgsliE", "cdate": 1546300800000, "mdate": null, "content": {"title": "Linking artificial and human neural representations of language", "abstract": "Jon Gauthier, Roger Levy. Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP). 2019."}}
{"id": "B1NG9jxubr", "cdate": 1483228800000, "mdate": null, "content": {"title": "Are Distributional Representations Ready for the Real World? Evaluating Word Vectors for Grounded Perceptual Meaning", "abstract": "Distributional word representation methods exploit word co-occurrences to build compact vector encodings of words. While these representations enjoy widespread use in modern natural language processing, it is unclear whether they accurately encode all necessary facets of conceptual meaning. In this paper, we evaluate how well these representations can predict perceptual and conceptual features of concrete concepts, drawing on two semantic norm datasets sourced from human participants. We find that several standard word representations fail to encode many salient perceptual features of concepts, and show that these deficits correlate with word-word similarity prediction errors. Our analyses provide motivation for grounded and embodied language learning approaches, which may help to remedy these deficits."}}
{"id": "rJ-y-neOZS", "cdate": 1451606400000, "mdate": null, "content": {"title": "A Fast Unified Model for Parsing and Sentence Understanding", "abstract": "Tree-structured neural networks exploit valuable syntactic parse information as they interpret the meanings of sentences. However, they suer from two key technical problems that make them slow and unwieldyforlarge-scaleNLPtasks: theyusually operate on parsed sentences and they do not directly support batched computation. We address these issues by introducingtheStack-augmentedParser-Interpreter NeuralNetwork(SPINN),whichcombines parsing and interpretation within a single tree-sequence hybrid model by integrating tree-structured sentence interpretation into the linear sequential structure of a shiftreduceparser. Ourmodelsupportsbatched computation for a speedup of up to 25\u25ca over other tree-structured models, and its integrated parser can operate on unparsed data with little loss in accuracy. We evaluate it on the Stanford NLI entailment task and show that it significantly outperforms other sentence-encoding models."}}
