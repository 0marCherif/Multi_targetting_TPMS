{"id": "MDNgY76UJXR", "cdate": 1640995200000, "mdate": 1681802409191, "content": {"title": "Amortized Causal Discovery: Learning to Infer Causal Graphs from Time-Series Data", "abstract": "On time-series data, most causal discovery methods fit a new model whenever they encounter samples from a new underlying causal graph. However, these samples often share relevant information which ..."}}
{"id": "xtYuTyZY1FJ", "cdate": 1635261613782, "mdate": null, "content": {"title": "Amortized Causal Discovery: Learning to Infer Causal Graphs from Time-Series Data", "abstract": "On time-series data, most causal discovery methods fit a new model whenever they encounter samples from a new underlying causal graph. However, these samples often share relevant information which is lost when following this approach. Specifically, different samples may share the dynamics which describe the effects of their causal relations. We propose Amortized Causal Discovery, a novel framework that leverages such shared dynamics to learn to infer causal relations from time-series data. This enables us to train a single, amortized model that infers causal relations across samples with different underlying causal graphs, and thus leverages the shared dynamics information. We demonstrate experimentally that this approach, implemented as a variational model, leads to significant improvements in causal discovery performance, and show how it can be extended to perform well under added noise and hidden confounding."}}
{"id": "UmMqvN9Aid-", "cdate": 1633790965601, "mdate": null, "content": {"title": "Understanding Post-hoc Adaptation for Improving Subgroup Robustness", "abstract": "A number of deep learning approaches have recently been proposed to improve model performance on subgroups under-represented in the training set. However, Menon et al. recently showed that models with poor subgroup performance can still learn representations which contain useful information about these subgroups. In this work, we explore the representations learned by various approaches to robust learning, finding that different approaches learn practically identical representations. We probe a range of post-hoc procedures for making predictions from learned representations, showing that the distribution of the post-hoc validation set is paramount, and that clustering-based methods may be a promising approach."}}
{"id": "ByPR_hOE_EY", "cdate": 1621629815683, "mdate": null, "content": {"title": "Identifying and Benchmarking Natural Out-of-Context Prediction Problems", "abstract": "Deep learning systems frequently fail at out-of-context (OOC) prediction, the problem of making reliable predictions on uncommon or unusual inputs or subgroups of the training distribution. To this end, a number of benchmarks for measuring OOC performance have been recently introduced.  In this work, we introduce a framework unifying the literature on OOC performance measurement, and demonstrate how rich auxiliary information can be leveraged to identify candidate sets of OOC examples in existing datasets.  We present NOOCh: a suite of naturally-occurring \"challenge sets\", and show how varying notions of context can be used to probe specific OOC failure modes. Experimentally, we explore the tradeoffs between various learning approaches on these challenge sets and demonstrate how the choices made in designing OOC benchmarks can yield varying conclusions."}}
{"id": "mob0Qd-GiVh", "cdate": 1609459200000, "mdate": 1682347574600, "content": {"title": "Identifying and Benchmarking Natural Out-of-Context Prediction Problems", "abstract": "Deep learning systems frequently fail at out-of-context (OOC) prediction, the problem of making reliable predictions on uncommon or unusual inputs or subgroups of the training distribution. To this end, a number of benchmarks for measuring OOC performance have recently been introduced. In this work, we introduce a framework unifying the literature on OOC performance measurement, and demonstrate how rich auxiliary information can be leveraged to identify candidate sets of OOC examples in existing datasets. We present NOOCh: a suite of naturally-occurring \"challenge sets\", and show how varying notions of context can be used to probe specific OOC failure modes. Experimentally, we explore the tradeoffs between various learning approaches on these challenge sets and demonstrate how the choices made in designing OOC benchmarks can yield varying conclusions."}}
{"id": "1jYkPwMyYY", "cdate": 1609459200000, "mdate": 1682347574486, "content": {"title": "Identifying and Benchmarking Natural Out-of-Context Prediction Problems", "abstract": "Deep learning systems frequently fail at out-of-context (OOC) prediction, the problem of making reliable predictions on uncommon or unusual inputs or subgroups of the training distribution. To this end, a number of benchmarks for measuring OOC performance have been recently introduced. In this work, we introduce a framework unifying the literature on OOC performance measurement, and demonstrate how rich auxiliary information can be leveraged to identify candidate sets of OOC examples in existing datasets. We present NOOCh: a suite of naturally-occurring \"challenge sets\", and show how varying notions of context can be used to probe specific OOC failure modes. Experimentally, we explore the tradeoffs between various learning approaches on these challenge sets and demonstrate how the choices made in designing OOC benchmarks can yield varying conclusions."}}
{"id": "gW8n0uD6rl", "cdate": 1601308098011, "mdate": null, "content": {"title": "Amortized Causal Discovery: Learning to Infer Causal Graphs from Time-Series Data", "abstract": "Standard causal discovery methods must fit a new model whenever they encounter samples from a new underlying causal graph. However, these samples often share relevant information - for instance, the dynamics describing the effects of causal relations - which is lost when following this approach. We propose Amortized Causal Discovery, a novel framework that leverages such shared dynamics to learn to infer causal relations from time-series data. This enables us to train a single, amortized model that infers causal relations across samples with different underlying causal graphs, and thus makes use of the information that is shared. We demonstrate experimentally that this approach, implemented as a variational model, leads to significant improvements in causal discovery performance, and show how it can be extended to perform well under hidden confounding.\n"}}
{"id": "aJZx2Gr3pH9", "cdate": 1598891242499, "mdate": null, "content": {"title": "Amortized Causal Discovery: Learning to Infer Causal Graphs from Time-Series Data", "abstract": "Standard causal discovery methods must fit a new model whenever they encounter samples from a new underlying causal graph. However, these samples often share relevant information - for instance, the dynamics describing the effects of causal relations - which is lost when following this approach. We propose Amortized Causal Discovery, a novel framework that leverages such shared dynamics to learn to infer causal relations from time-series data. This enables us to train a single, amortized model that infers causal relations across samples with different underlying causal graphs, and thus makes use of the information that is shared. We demonstrate experimentally that this approach, implemented as a variational model, leads to significant improvements in causal discovery performance, and show how it can be extended to perform well under hidden confounding."}}
{"id": "uCjl0xl3AzA", "cdate": 1577836800000, "mdate": 1681679819815, "content": {"title": "Causal Modeling for Fairness In Dynamical Systems", "abstract": "In many applications areas\u2014lending, education, and online recommenders, for example\u2014fairness and equity concerns emerge when a machine learning system interacts with a dynamically changing environm..."}}
{"id": "oT55TmIEmVQ", "cdate": 1577836800000, "mdate": 1682347574914, "content": {"title": "Detecting Extrapolation with Local Ensembles", "abstract": "We present local ensembles, a method for detecting extrapolation at test time in a pre-trained model. We focus on underdetermination as a key component of extrapolation: we aim to detect when many possible predictions are consistent with the training data and model class. Our method uses local second-order information to approximate the variance of predictions across an ensemble of models from the same class. We compute this approximation by estimating the norm of the component of a test point's gradient that aligns with the low-curvature directions of the Hessian, and provide a tractable method for estimating this quantity. Experimentally, we show that our method is capable of detecting when a pre-trained model is extrapolating on test data, with applications to out-of-distribution detection, detecting spurious correlates, and active learning."}}
