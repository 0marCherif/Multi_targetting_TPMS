{"id": "osPsQZiB9Iq", "cdate": 1609459200000, "mdate": null, "content": {"title": "HMC, an Algorithms in Data Mining, the Functional Analysis approach", "abstract": "The main purpose of this paper is to facilitate the communication between the Analytic, Probabilistic and Algorithmic communities. We present a proof of convergence of the Hamiltonian (Hybrid) Monte Carlo algorithm from the point of view of the Dynamical Systems, where the evolving objects are densities of probability distributions and the tool are derived from the Functional Analysis."}}
{"id": "m4WFCL7oxsc", "cdate": 1609459200000, "mdate": null, "content": {"title": "HMC, an example of Functional Analysis applied to Algorithms in Data Mining. The convergence in Lp", "abstract": "We establish $L_q$ convergence for Hamiltonian Monte Carlo algorithms. More specifically, under mild conditions for the associated Hamiltonian motion, we show that the outputs of the algorithms converge (strongly for $2\\le q<\\infty$ and weakly for $1<q<2$) to the desired target distribution."}}
{"id": "mqVGHqBz7sg", "cdate": 1577836800000, "mdate": null, "content": {"title": "Optimal Control in Fluid Models of nxn Input-Queued Switches under Linear Fluid-Flow Costs", "abstract": "We consider a fluid model of n x n input-queued switches with associated fluid-flow costs and derive an optimal scheduling control policy to an infinite horizon discounted control problem with a general linear objective function of fluid cost. Our optimal policy coincides with the c\u03bc-rule in certain parameter domains, but more generally, takes the form of the solution to a flow maximization problem. Computational experiments demonstrate the benefits of our optimal scheduling policy over variants of max-weight scheduling and the c\u03bc-rule."}}
{"id": "aGjMot0illM", "cdate": 1577836800000, "mdate": null, "content": {"title": "Optimal Delay-Cost Scheduling Control in Fluid Models of General nxn Input-Queued Switches", "abstract": "Input-queued switch (IQS) architectures are widely used in modern computer/communication networks. The optimal scheduling control of these high-speed, low-latency networks is critical for our understanding of fundamental design and performance issues related to internet routers, cloud computing data centers, and high-performance computing. A large and rich literature exists around optimal scheduling in these systems. This includes the extensive study of IQSs as an important mathematical model for a general class of optimal scheduling control problems of broad interest."}}
{"id": "BJg2waqGar", "cdate": 1575296355631, "mdate": null, "content": {"title": "A Family of Robust Stochastic Operators for Reinforcement Learning", "abstract": "We consider a new family of stochastic operators for reinforcement learning with the goal of alleviating negative effects and becoming more robust to approximation or estimation errors. Various theoretical results are established, which include showing that our family of operators preserve optimality and increase the action gap in a stochastic sense. Our empirical results illustrate the strong benefits of our robust stochastic operators, significantly outperforming the classical Bellman operator and recently proposed operators."}}
{"id": "ud2wYh-u_hV", "cdate": 1546300800000, "mdate": null, "content": {"title": "A Stochastic Knapsack Game: Revenue Management in Competitions", "abstract": "We study a mathematical model for revenue management under competition with multiple sellers. The model combines the stochastic knapsack problem, a classic revenue management model, with a non coorperative game model that characterizes the sellers' rational behavior. We are able to establish a dynamic recursive procedure that incorporate the value function with the utility function of the games. The formalization of the dynamic recursion allows us to establish some fundamental structural properties."}}
{"id": "PlMSoL8xfG4", "cdate": 1546300800000, "mdate": null, "content": {"title": "A Control-Model-Based Approach for Reinforcement Learning", "abstract": "We consider a new form of reinforcement learning (RL) that is based on opportunities to directly learn the optimal control policy and a general Markov decision process (MDP) framework devised to support these opportunities. Derivations of general classes of our control-based RL methods are presented, together with forms of exploration and exploitation in learning and applying the optimal control policy over time. Our general MDP framework extends the classical Bellman operator and optimality criteria by generalizing the definition and scope of a policy for any given state. We establish the convergence and optimality-both in general and within various control paradigms (e.g., piecewise linear control policies)-of our control-based methods through this general MDP framework, including convergence of $Q$-learning within the context of our MDP framework. Our empirical results demonstrate and quantify the significant benefits of our approach."}}
{"id": "Dm7bBmwzqj0", "cdate": 1546300800000, "mdate": null, "content": {"title": "Revisiting Stochastic Loss Networks: Structures and Approximations", "abstract": "We consider fundamental properties of stochastic loss networks, seeking to improve on the so-called Erlang fixed-point approximation. We propose a family of mathematical approximations for estimati..."}}
{"id": "xXgomgzPeNb", "cdate": 1514764800000, "mdate": null, "content": {"title": "A General Family of Robust Stochastic Operators for Reinforcement Learning", "abstract": "We consider a new family of operators for reinforcement learning with the goal of alleviating the negative effects and becoming more robust to approximation or estimation errors. Various theoretical results are established, which include showing on a sample path basis that our family of operators preserve optimality and increase the action gap. Our empirical results illustrate the strong benefits of our family of operators, significantly outperforming the classical Bellman operator and recently proposed operators."}}
{"id": "kC5NUVdmHiS", "cdate": 1514764800000, "mdate": null, "content": {"title": "Control of Time-Varying Epidemic-Like Stochastic Processes and Their Mean-Field Limits", "abstract": "The optimal control of epidemic-like stochastic processes is important both historically and for emerging applications today, where it can be especially critical to include time-varying parameters that impact viral epidemic-like propagation. We connect the control of such stochastic processes with time-varying behavior to the stochastic shortest path problem and obtain solutions for various cost functions. Then, under a mean-field scaling, this general class of stochastic processes is shown to converge to a corresponding dynamical system. We further establish that the optimal control of this class of processes converges to the optimal control of the limiting dynamical system. Our comparative study of the optimal control of both systems renders various important mathematical properties of interest."}}
