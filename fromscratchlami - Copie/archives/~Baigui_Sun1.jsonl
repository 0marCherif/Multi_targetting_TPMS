{"id": "WGE3WPLFfH", "cdate": 1668749189011, "mdate": 1668749189011, "content": {"title": "An efficient training approach for very large scale face recognition", "abstract": "Face recognition has achieved significant progress in deep learning era due to the ultra-large-scale and welllabeled datasets. However, training on the outsize datasets is time-consuming and takes up a lot of hardware resource. Therefore, designing an efficient training approach is indispensable. The heavy computational and memory costs mainly result from the million-level dimensionality of the fully connected (FC) layer. To this end, we propose a novel training approach, termed Faster Face Classification (F2C), to alleviate time and cost without sacrificing the performance. This method adopts Dynamic Class Pool (DCP) for storing and updating the identities\u2019 features dynamically, which could be regarded as a substitute for the FC layer. DCP is efficiently time-saving and cost-saving, as its smaller size with the independence from the whole face identities together. We further validate the proposed F2C method across several face benchmarks and private datasets, and display comparable results, meanwhile the speed is faster than state-of-the-art FC-based methods in terms of recognition accuracy and hardware costs. Moreover, our method is further improved by a well-designed dual data loader including indentity-based and instancebased loaders, which makes it more efficient for updating DCPparameter"}}
{"id": "VBZic0FGCd", "cdate": 1667401918656, "mdate": 1667401918656, "content": {"title": "Architecture-Agnostic Masked Image Modeling -- From ViT back to CNN", "abstract": "Masked image modeling (MIM), an emerging self-supervised pre-training method, has shown impressive success across numerous downstream vision tasks with Vision transformers (ViTs). Its underlying idea is simple: a portion of the input image is randomly masked out and then reconstructed via the pre-text task. However, the working principle behind MIM is not well explained, and previous studies insist that MIM primarily works for the Transformer family but is incompatible with CNNs. In this paper, we first study interactions among patches to understand what knowledge is learned and how it is acquired via the MIM task. We observe that MIM essentially teaches the model to learn better middle-order interactions among patches and extract more generalized features. Based on this fact, we propose an Architecture-Agnostic Masked Image Modeling framework (A$^2$MIM), which is compatible with both Transformers and CNNs in a unified way. Extensive experiments on popular benchmarks show that our A$^2$MIM learns better representations without explicit design and endows the backbone model with the stronger capability to transfer to various downstream tasks for both Transformers and CNNs."}}
{"id": "wa42N8siZ7G", "cdate": 1667401235795, "mdate": 1667401235795, "content": {"title": "DLME: Deep Local-flatness Manifold Embedding", "abstract": "Manifold learning (ML) aims to seek low-dimensional embedding from high-dimensional data. The problem is challenging on real-world datasets, especially with under-sampling data, and we find that previous methods perform poorly in this case. Generally, ML methods first transform input data into a low-dimensional embedding space to maintain the data's geometric structure and subsequently perform downstream tasks therein. The poor local connectivity of under-sampling data in the former step and inappropriate optimization objectives in the latter step leads to two problems: structural distortion and underconstrained embedding. This paper proposes a novel ML framework named Deep Local-flatness Manifold Embedding (DLME) to solve these problems. The proposed DLME constructs semantic manifolds by data augmentation and overcomes the structural distortion problem using a smoothness constrained based on a local flatness assumption about the manifold. To overcome the underconstrained embedding problem, we design a loss and theoretically demonstrate that it leads to a more suitable embedding based on the local flatness. Experiments on three types of datasets (toy, biological, and image) for various downstream tasks (classification, clustering, and visualization) show that our proposed DLME outperforms state-of-the-art ML and contrastive learning methods."}}
{"id": "LOTGOB5_Xh2", "cdate": 1663850093951, "mdate": null, "content": {"title": "Architecture-Agnostic Masked Image Modeling -- From ViT back to CNN", "abstract": "Masked image modeling (MIM), an emerging self-supervised pre-training method, has shown impressive success across numerous downstream vision tasks with Vision transformers (ViTs). Its underlying idea is simple: a portion of the input image is randomly masked out and then reconstructed via the pre-text task. However, the working principle behind MIM is not well explained, and previous studies insist that MIM primarily works for the Transformer family but is incompatible with CNNs. In this paper, we first study interactions among patches to understand what knowledge is learned and how it is acquired via the MIM task. We observe that MIM essentially teaches the model to learn better middle-order interactions among patches and extract more generalized features. Based on this fact, we propose an Architecture-Agnostic Masked Image Modeling framework (A$^2$MIM), which is compatible with both Transformers and CNNs in a unified way. Extensive experiments on popular benchmarks show that our A$^2$MIM learns better representations without explicit design and endows the backbone model with the stronger capability to transfer to various downstream tasks for both Transformers and CNNs."}}
{"id": "vny63BYDCS", "cdate": 1663850078189, "mdate": null, "content": {"title": "NSCL: Noise-Resistant Soft Contrastive Learning for Universal Domain Adaptation", "abstract": "Domain adaptation (DA) transfers knowledge from label-rich domains to new domains where labels are scarce to address the problem of generalization of deep neural networks in new domains. Universal domain adaptation (UNDA) assumes the label distributions of labeled and unlabeled data are different and unknowable. In this paper, we concentrate on solving the noise problem on the UNDA problem based on contrastive learning (CL), which includes view noise in data augmentation and label noise in the classifier training. The domain differences in UNDA amplify the noise in the view of data augmentation, resulting in data augmentation schemes that apply to all domains being challenging to find. In addition, the mainstream UNDA classifiers combine closed-set classifiers with open-set classifiers; insufficient competition among open-set classifiers leads to overconfidence, which results in incredible sensitivity to noise in labeled data. Therefore, we propose Noise-Resistant Soft Contrastive Learning (NSCL) addresses the above issues. Firstly, we propose a soft contrast learning loss to avoid the over-response of typical CL loss to noisy samples, thus enabling data augmentation to improve the performance of UNDA further. Secondly, we design an all-in-one (AIO) classifier to improve the robustness of noisy labels while introducing multi-category unknown class competition. Extensive experimental results on UNDA and open\u0002set DA demonstrate the advantages of NSCL over existing methods, especially in downstream tasks such as classification and visualization."}}
{"id": "km2lP70ds-0", "cdate": 1663849982881, "mdate": null, "content": {"title": "Boosting Discriminative Visual Representation Learning with Scenario-Agnostic Mixup", "abstract": "Mixup is a popular data-dependent augmentation technique for deep neural networks, which contains two sub-tasks, mixup generation, and classification. The community typically confines mixup to supervised learning (SL) and the objective of the generation sub-task is fixed to selected sample pair instead of considering the whole data manifold. To overcome such limitations, we systematically study the mixup generation objective and propose Scenario-Agnostic Mixup for both SL and Self-supervised Learning (SSL) scenarios, named SAMix. Specifically, we hypothesize and verify the objective function of mixup generation as optimizing local smoothness between two mixed classes subject to global discrimination from other classes. Therefore, we propose \u03b7-balanced mixup loss for complementary learning of the two sub-objectives. Meanwhile, we parameterize the generation sub-task as a learnable sub-network, Mixer, with mixing attention which avoids trivial solutions and improves transferable abilities. To eliminate the computational cost of online training, we introduce a pre-trained version, SAMixP , that achieves efficient performance in various tasks. Extensive experiments on SL and SSL benchmarks demonstrate that SAMix consistently outperforms leading methods."}}
{"id": "GOEpRos3w0L", "cdate": 1663849866023, "mdate": null, "content": {"title": "TopoZero: Digging into  Topology Alignment on Zero-Shot Learning", "abstract": "Common space learning, associating semantic and visual domains in a common\nlatent space, is essential to transfer knowledge from seen classes to unseen ones\non Zero-Shot Learning (ZSL) realm. Existing methods for common space learning\nrely heavily on structure alignment due to the heterogeneous nature between\nsemantic and visual domains, but the existing design is sub-optimal. In this paper,\nwe utilize persistent homology to investigate geometry structure alignment,\nand observe two following issues: (i) The sampled mini-batch data points present\na distinct structure gap compared to global data points, thus the learned structure\nalignment space inevitably neglects abundant and accurate global structure\ninformation. (ii) The latent visual and semantic space fail to preserve multiple\ndimensional geometry structure, especially high dimensional structure information.\nTo address the first issue, we propose a Topology-guided Sampling Strategy\n(TGSS) to mitigate the gap between sampled and global data points. Both theoretical\nanalyses and empirical results guarantee the effectiveness of the TGSS.\nTo solve the second issue, we introduce a Topology Alignment Module (TAM)\nto preserve multi-dimensional geometry structure in latent visual and semantic\nspace, respectively. The proposed method is dubbed TopoZero. Empirically, our\nTopoZero achieves superior performance on three authoritative ZSL benchmark\ndatasets."}}
{"id": "NkJOhtNKX91", "cdate": 1663849865908, "mdate": null, "content": {"title": "DamoFD: Digging into Backbone Design on Face Detection", "abstract": "Face detection (FD) has achieved remarkable success over the past few years, yet,\nthese leaps often arrive when consuming enormous computation costs. Moreover,\nwhen considering a realistic situation, i.e., building a lightweight face detector\nunder a computation-scarce scenario, such heavy computation cost limits the application\nof the face detector. To remedy this, several pioneering works design\ntiny face detectors through off-the-shelf neural architecture search (NAS) technologies,\nwhich are usually applied to the classification task. Thus, the searched\narchitectures are sub-optimal for the face detection task since some design criteria\nbetween detection and classification task are different. As a representative, the\nface detection backbone design needs to guarantee the stage-level detection ability\nwhile it is not required for the classification backbone. Furthermore, the detection\nbackbone consumes a vast body of inference budgets in the whole detection framework.\nConsidering the intrinsic design requirement and the virtual importance role\nof the face detection backbone, we thus ask a critical question: How to employ\nNAS to search FD-friendly backbone architecture? To cope with this question,\nwe propose a distribution-dependent stage-aware ranking score (DDSAR-Score)\nto explicitly characterize the stage-level expressivity and identify the individual\nimportance of each stage, thus satisfying the aforementioned design criterion of\nthe FD backbone. Based on our proposed DDSAR-Score, we conduct comprehensive\nexperiments on the challenging Wider Face benchmark dataset and achieve\ndominant performance across a wide range of compute regimes. In particular,\ncompared to the tiniest face detector SCRFD-0.5GF, our method is +2.5 % better\nin Average Precision (AP) score when using the same amount of FLOPs. The\ncode is avaliable at https://github.com/ly19965/FaceMaas/tree/master/face_project/face_detection/DamoFD."}}
{"id": "j6ItDQuvHV", "cdate": 1640995200000, "mdate": 1668593647124, "content": {"title": "An Efficient Training Approach for Very Large Scale Face Recognition", "abstract": "Face recognition has achieved significant progress in deep learning era due to the ultra-large-scale and well- labeled datasets. However, training on the outsize datasets is time-consuming and takes up a lot of hardware resource. Therefore, designing an efficient training approach is in- dispensable. The heavy computational and memory costs mainly result from the million-level dimensionality of the fully connected (FC) layer. To this end, we propose a novel training approach, termed Faster Face Classification (F <inf xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">2</inf> C), to alleviate time and cost without sacrificing the performance. This method adopts Dynamic Class Pool (DCP) for storing and updating the identities' features dy-namically, which could be regarded as a substitute for the FC layer. DCP is efficiently time-saving and cost-saving, as its smaller size with the independence from the whole face identities together. We further validate the proposed F <sup xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">2</sup> C method across several face benchmarks and private datasets, and display comparable results, meanwhile the speed is faster than state-of-the-art FC-based methods in terms of recognition accuracy and hardware costs. More-over, our method is further improved by a well-designed dual data loader including indentity-based and instance- based loaders, which makes it more efficient for updating DCP parameters."}}
{"id": "LaXl8PFS57p", "cdate": 1640995200000, "mdate": 1668593647349, "content": {"title": "DLME: Deep Local-Flatness Manifold Embedding", "abstract": "Manifold learning\u00a0(ML) aims to seek low-dimensional embedding from high-dimensional data. The problem is challenging on real-world datasets, especially with under-sampling data, and we find that previous methods perform poorly in this case. Generally, ML methods first transform input data into a low-dimensional embedding space to maintain the data\u2019s geometric structure and subsequently perform downstream tasks therein. The poor local connectivity of under-sampling data in the former step and inappropriate optimization objectives in the latter step leads to two problems: structural distortion and underconstrained embedding. This paper proposes a novel ML framework named Deep Local-flatness Manifold Embedding (DLME) to solve these problems. The proposed DLME constructs semantic manifolds by data augmentation and overcomes the structural distortion problem using a smoothness constrained based on a local flatness assumption about the manifold. To overcome the underconstrained embedding problem, we design a loss and theoretically demonstrate that it leads to a more suitable embedding based on the local flatness. Experiments on three types of datasets (toy, biological, and image) for various downstream tasks (classification, clustering, and visualization) show that our proposed DLME outperforms state-of-the-art ML and contrastive learning methods."}}
