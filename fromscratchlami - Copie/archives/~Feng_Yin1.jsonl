{"id": "pBReuw1MXp", "cdate": 1672531200000, "mdate": 1684077746101, "content": {"title": "Towards Flexibility and Interpretability of Gaussian Process State-Space Model", "abstract": "The Gaussian process state-space model (GPSSM) has garnered considerable attention over the past decade. However, the standard GP with a preliminary kernel, such as the squared exponential kernel or Mat\\'{e}rn kernel, that is commonly used in GPSSM studies, limits the model's representation power and substantially restricts its applicability to complex scenarios. To address this issue, we propose a new class of probabilistic state-space models called TGPSSMs, which leverage a parametric normalizing flow to enrich the GP priors in the standard GPSSM, enabling greater flexibility and expressivity. Additionally, we present a scalable variational inference algorithm that offers a flexible and optimal structure for the variational distribution of latent states. The proposed algorithm is interpretable and computationally efficient due to the sparse GP representation and the bijective nature of normalizing flow. Moreover, we incorporate a constrained optimization framework into the algorithm to enhance the state-space representation capabilities and optimize the hyperparameters, leading to superior learning and inference performance. Experimental results on synthetic and real datasets corroborate that the proposed TGPSSM outperforms several state-of-the-art methods. The accompanying source code is available at \\url{https://github.com/zhidilin/TGPSSM}."}}
{"id": "X8HLDNVqs", "cdate": 1672531200000, "mdate": 1682608306044, "content": {"title": "Automatic Vickers Hardness Measurement With Neural Network Segmentation", "abstract": "The Vickers hardness test is widely used for metal materials. The hardness given by the test is inversely proportional to the ratio of the test force to the indentation area. Since it is inconvenient to measure the area of the indentation manually, it is usually approximated by measuring its diagonal length. On this basis, we propose a new indentation segmentation network based on existing work. Taking advantage of its high segmentation accuracy, we use the indentation area to calculate the Vickers hardness directly, rather than relying on the measurement of the diagonal length. Experimental results show that the indentation areas obtained by this method are well below the International Standardization Organization (ISO) standard and very close to those from manual measurements. In some cases, this method can be a good alternative to manual measurements."}}
{"id": "01F_NCvCQU", "cdate": 1672531200000, "mdate": 1682608306047, "content": {"title": "Towards Flexibility and Interpretability of Gaussian Process State-Space Model", "abstract": "The Gaussian process state-space model (GPSSM) has garnered considerable attention over the past decade. However, the standard GP with a preliminary kernel, such as the squared exponential kernel or Mat\\'{e}rn kernel, that is commonly used in GPSSM studies, limits the model's representation power and substantially restricts its applicability to complex scenarios. To address this issue, we propose a new class of probabilistic state-space models called TGPSSMs, which leverage a parametric normalizing flow to enrich the GP priors in the standard GPSSM, enabling greater flexibility and expressivity. Additionally, we present a scalable variational inference algorithm that offers a flexible and optimal structure for the variational distribution of latent states. The proposed algorithm is interpretable and computationally efficient due to the sparse GP representation and the bijective nature of normalizing flow. Moreover, we incorporate a constrained optimization framework into the algorithm to enhance the state-space representation capabilities and optimize the hyperparameters, leading to superior learning and inference performance. Experimental results on synthetic and real datasets corroborate that the proposed TGPSSM outperforms several state-of-the-art methods. The accompanying source code is available at \\url{https://github.com/zhidilin/TGPSSM}."}}
{"id": "Or8rcTLo7U", "cdate": 1663850316131, "mdate": null, "content": {"title": "Maximal Correlation-Based Post-Nonlinear Learning for Bivariate Causal Discovery", "abstract": "Bivariate causal discovery aims to determine the causal relationship between two random variables from passive observational data (as intervention is not affordable in many scientific fields), which is considered fundamental and challenging. Designing algorithms based on the post-nonlinear (PNL) model has aroused much attention for its generality. However, the state-of-the-art (SOTA) PNL-based algorithms involve highly non-convex objectives for neural network training, which are time-consuming and unable to produce meaningful solutions with finite samples. In this paper, we propose a novel method that incorporates maximal correlation into the PNL model learning (short as MC-PNL) such that the underlying nonlinearities can be accurately recovered. Owing to the benign structure of our objective function when modeling the nonlinearities with linear combinations of random Fourier features, the target optimization problem can be solved rather efficiently and rapidly via the block coordinate descent. We also compare the MC-PNL with SOTA methods on the downstream synthetic and real causal discovery tasks to show its superiority in time and accuracy. Our code is available at https://anonymous.4open.science/r/MC-PNL-E446/."}}
{"id": "yTYwaab8xp", "cdate": 1640995200000, "mdate": 1684077746510, "content": {"title": "Multitask Gaussian Process With Hierarchical Latent Interactions", "abstract": "Multitask Gaussian process (MTGP) is powerful for joint learning of multiple tasks with complicated correlation patterns. However, due to the assembling of additive independent latent functions (LFs), all current MTGPs including the salient linear model of coregionalization (LMC) and convolution frameworks cannot effectively represent and learn the hierarchical latent interactions between its LFs. In this paper, we further investigate the interactions in LMC of MTGP and then propose a novel kernel representation of the hierarchical interactions, which ameliorates both the expressiveness and the interpretability of MTGP. Specifically, we express the interaction as a product of function interaction (FI) and coefficient interaction. The FI is modeled by using cross convolution of LFs. The coefficient interaction between the LMCs is described as a free-form coupling coregionalization term. We validate that considering the interactions can promote knowledge transferring in MTGP and compare our approach with some state-of-the-art MTGPs on both synthetic-and real-world datasets."}}
{"id": "tDU80VyvDSs", "cdate": 1640995200000, "mdate": 1668159001015, "content": {"title": "MetaLoc: Learning to Learn Wireless Localization", "abstract": ""}}
{"id": "tCIPLik5mY9", "cdate": 1640995200000, "mdate": 1684077746512, "content": {"title": "Rethinking Bayesian Learning for Data Analysis: The art of prior and inference in sparsity-aware modeling", "abstract": "Sparse modeling for signal processing and machine learning, in general, has been at the focus of scientific research for over two decades. Among others, supervised sparsity-aware learning (SAL) consists of two major paths paved by 1) discriminative methods that establish direct input\u2013output mapping based on a regularized cost function optimization and 2) generative methods that learn the underlying distributions. The latter, more widely known as <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">Bayesian methods</i> , enable uncertainty evaluation with respect to the performed predictions. Furthermore, they can better exploit related prior information and also, in principle, can naturally introduce robustness into the model, due to their unique capacity to marginalize out uncertainties related to the parameter estimates. Moreover, hyperparameters (tuning parameters) associated with the adopted priors, which correspond to cost function regularizers, can be learned via the training data and not via costly cross-validation techniques, which is, in general, the case with the discriminative methods."}}
{"id": "t7cYssdjRS", "cdate": 1640995200000, "mdate": 1684077746768, "content": {"title": "MetaLoc: Learning to Learn Wireless Localization", "abstract": "Existing localization methods that intensively leverage the environment-specific received signal strength (RSS) or channel state information (CSI) of wireless signals are rather accurate in certain environments. However, these methods, whether based on pure statistical signal processing or data-driven approaches, often struggle to generalize to changing environments, which result in significant knowledge and effort losses. To address this challenge, we propose MetaLoc, a fingerprinting-based localization framework that leverages model-agnostic meta-learning (MAML) to achieve fast adaptation to new environments with minimal human intervention. Implemented using a deep neural network with strong representation capabilities, MetaLoc is trained on historical data collected from well-calibrated environments to optimize meta-parameters for fast adaptation. The framework includes two paradigms for obtaining meta-parameters: the centralized paradigm, which optimizes meta-parameters by sharing data from all historical environments with simplicity, and the distributed paradigm, which preserves data privacy by training environment-specific meta-parameters independently. Furthermore, the advanced distributed paradigm modifies the vanilla MAML loss function to ensure that the reduction of loss occurs in a consistent direction across various training domains, thus facilitating faster convergence during training. Our experiments on both synthetic and real datasets demonstrate that MetaLoc outperforms baseline methods in terms of localization accuracy, robustness, and cost-effectiveness. The code and datasets used in this study are publicly available."}}
{"id": "sZM22mgG76", "cdate": 1640995200000, "mdate": 1684077746769, "content": {"title": "Output-Dependent Gaussian Process State-Space Model", "abstract": "Gaussian process state-space model (GPSSM) is a fully probabilistic state-space model that has attracted much attention over the past decade. However, the outputs of the transition function in the existing GPSSMs are assumed to be independent, meaning that the GPSSMs cannot exploit the inductive biases between different outputs and lose certain model capacities. To address this issue, this paper proposes an output-dependent and more realistic GPSSM by utilizing the well-known, simple yet practical linear model of coregionalization (LMC) framework to represent the output dependency. To jointly learn the output-dependent GPSSM and infer the latent states, we propose a variational sparse GP-based learning method that only gently increases the computational complexity. Experiments on both synthetic and real datasets demonstrate the superiority of the output-dependent GPSSM in terms of learning and inference performance."}}
{"id": "p9-xEOmUNE", "cdate": 1640995200000, "mdate": 1684077746514, "content": {"title": "Salient object detection based on global to local visual search guidance", "abstract": ""}}
