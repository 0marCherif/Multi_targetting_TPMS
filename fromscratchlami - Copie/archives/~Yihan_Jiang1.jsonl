{"id": "PKrdrZpYPA0", "cdate": 1672531200000, "mdate": 1682923271920, "content": {"title": "Compressed Error HARQ: Feedback Communication on Noise-Asymmetric Channels", "abstract": "In modern communication systems with feedback, there are increasingly more scenarios where the transmitter has much less power than the receiver (e.g., medical implant devices), which we refer to as noise-asymmetric channels. For such channels, the feedback link is of higher quality than the forward link. However, feedback schemes for cellular communications, such as hybrid ARQ, do not fully utilize the high-quality feedback link. To this end, we introduce Compressed Error Hybrid ARQ, a generalization of hybrid ARQ tailored for noise-asymmetric channels; the receiver sends its estimated message to the transmitter, and the transmitter harmoniously switches between hybrid ARQ and compressed error retransmission. We show that our proposed method significantly improves reliability, latency, and spectral efficiency compared to the conventional hybrid ARQ in various practical scenarios where the transmitter is resource-constrained."}}
{"id": "laC8nKyMAF2", "cdate": 1640995200000, "mdate": 1669129259238, "content": {"title": "Bottleneck Analysis of Dynamic Graph Neural Network Inference on CPU and GPU", "abstract": "Dynamic graph neural network (DGNN) is becoming increasingly popular because of its widespread use in capturing dynamic features in the real world. A variety of dynamic graph neural networks designed from algorithmic perspectives have succeeded in incorporating temporal information into graph processing. Despite the promising algorithmic performance, deploying DGNNs on hardware presents additional challenges due to the model complexity, diversity, and the nature of the time dependency. Meanwhile, the differences between DGNNs and static graph neural networks make hardware-related optimizations for static graph neural networks unsuitable for DGNNs. In this paper, we select eight prevailing DGNNs with different characteristics and profile them on both CPU and GPU. The profiling results are summarized and analyzed, providing in-depth insights into the bottlenecks of DGNNs on hardware and identifying potential optimization opportunities for future DGNN acceleration. Followed by a comprehensive survey, we provide a detailed analysis of DGNN performance bottlenecks on hardware, including temporal data dependency, workload imbalance, data movement, and GPU warm-up. We suggest several optimizations from both software and hardware perspectives. This paper is the first to provide an in-depth analysis of the hardware performance of DGNN Code is available at https://github.com/sharc-lab/DGNN_analysis."}}
{"id": "TuiNOWQzVXL", "cdate": 1640995200000, "mdate": 1682923271921, "content": {"title": "Bottleneck Analysis of Dynamic Graph Neural Network Inference on CPU and GPU", "abstract": "Dynamic graph neural network (DGNN) is becoming increasingly popular because of its widespread use in capturing the dynamic features in the real world. A variety of dynamic graph neural networks designed from algorithmic perspectives have succeeded in incorporating temporal information into graph processing. Despite the promising algorithmic performance, deploying DGNNs on hardware presents additional challenges due to the model complexity, diversity, and the nature of the time-dependency. Meanwhile, the differences between DGNNs and static graph neural networks make hardware-related optimizations for static graph neural networks unsuitable for DGNNs. In this paper, We select eight prevailing DGNNs with different characteristics and profile them on both CPU and GPU. The profiling results are summarized and analyzed, providing in-depth insights into the bottlenecks of DGNNs on hardware and identifying potential optimization opportunities for future DGNN acceleration. Followed by a comprehensive survey, we provide a detailed analysis of DGNN performance bottlenecks on hardware, including temporal data dependency, workload imbalance, data movement, and GPU warm-up. We suggest several optimizations from both software and hardware perspectives. This paper is the first to provide an in-depth analysis of the hardware performance of DGNN* Code is available at https://github.com/sharc-lab/DGNN_analysis."}}
{"id": "-mJgljoj0g", "cdate": 1640995200000, "mdate": 1682923271922, "content": {"title": "Turbo Autoencoder with a Trainable Interleaver", "abstract": "A critical aspect of reliable communication involves the design of codes that allow transmissions to be robustly and computationally efficiently decoded under noisy conditions. Advances in the design of reliable codes have been driven by coding theory and have been sporadic. Recently, it is shown that channel codes that are comparable to modern codes can be learned solely via deep learning. In particular, Turbo Autoencoder (TurboAE), introduced by Jiang et al., is shown to achieve the reliability of Turbo codes for Additive White Gaussian Noise channels.In this paper, we focus on applying the idea of TurboAE to various practical channels, such as fading channels and chirp noise channels. We introduce TurboAE-TI, a novel neural architecture that combines TurboAE with a trainable interleaver design. We develop a carefully-designed training procedure and a novel interleaver penalty function that are crucial in learning the interleaver and TurboAE jointly. We demonstrate that TurboAE-TI outperforms TurboAE and LTE Turbo codes for several channels of interest. We also provide interpretation analysis to better understand TurboAE-TI."}}
{"id": "GqKzAg5d-r", "cdate": 1609459200000, "mdate": 1682923271923, "content": {"title": "Turbo Autoencoder with a Trainable Interleaver", "abstract": "A critical aspect of reliable communication involves the design of codes that allow transmissions to be robustly and computationally efficiently decoded under noisy conditions. Advances in the design of reliable codes have been driven by coding theory and have been sporadic. Recently, it is shown that channel codes that are comparable to modern codes can be learned solely via deep learning. In particular, Turbo Autoencoder (TURBOAE), introduced by Jiang et al., is shown to achieve the reliability of Turbo codes for Additive White Gaussian Noise channels. In this paper, we focus on applying the idea of TURBOAE to various practical channels, such as fading channels and chirp noise channels. We introduce TURBOAE-TI, a novel neural architecture that combines TURBOAE with a trainable interleaver design. We develop a carefully-designed training procedure and a novel interleaver penalty function that are crucial in learning the interleaver and TURBOAE jointly. We demonstrate that TURBOAE-TI outperforms TURBOAE and LTE Turbo codes for several channels of interest. We also provide interpretation analysis to better understand TURBOAE-TI."}}
{"id": "fzpitSFHMc3", "cdate": 1577836800000, "mdate": 1682923271968, "content": {"title": "Targeting brain functions from the scalp: Transcranial brain atlas based on large-scale fMRI data synthesis", "abstract": ""}}
{"id": "c5-9itCSfLP", "cdate": 1577836800000, "mdate": 1682923271964, "content": {"title": "Deepcode and Modulo-SK are Designed for Different Settings", "abstract": "We respond to [1] which claimed that \"Modulo-SK scheme outperforms Deepcode [2]\". We demonstrate that this statement is not true: the two schemes are designed and evaluated for entirely different settings. DeepCode is designed and evaluated for the AWGN channel with (potentially delayed) uncoded output feedback. Modulo-SK is evaluated on the AWGN channel with coded feedback and unit delay. [1] also claimed an implementation of Schalkwijk and Kailath (SK) [3] which was numerically stable for any number of information bits and iterations. However, we observe that while their implementation does marginally improve over ours, it also suffers from a fundamental issue with precision. Finally, we show that Deepcode dominates the optimized performance of SK, over a natural choice of parameterizations when the feedback is noisy."}}
{"id": "WcQlvhfFmA-", "cdate": 1577836800000, "mdate": 1682923271964, "content": {"title": "Joint Channel Coding and Modulation via Deep Learning", "abstract": "Channel coding and modulation are two fundamental building blocks of physical layer wireless communications. We propose a neural network based end-to-end communication system, where both the channel coding and the modulation blocks are modeled as neural networks. Our proposed architecture combines Turbo Autoencoder together with feed-forward neural networks for modulation, and hence called TurboAE-MOD. Turbo Autoencoder was introduced in [1] and consists of a neural network based channel encoder (convolutional neural networks with an interleaver) and a neural network based decoder (iterations of convolutional neural networks with interleavers and de-interleavers in between). By allowing joint training of the channel coding and modulation in an end-to-end manner, we demonstrate that TurboAE-MOD performs comparable to modern codes stacked with canonical modulations for moderate block lengths. We also demonstrate that TurboAE-MOD learns interesting modulation patterns that are amenable to meaningful interpretations."}}
{"id": "Vhg2qzlD5t", "cdate": 1577836800000, "mdate": 1682923271969, "content": {"title": "Feedback Turbo Autoencoder", "abstract": "Designing channel codes is one of the core research areas for modern communication systems. Canonical channel codes asymptotically achieve near-capacity performance under large block length regime for additive white gaussian noise channels. However, this achieved success does not generalize to many channels. Channels with output feedback, proposed by Shannon, is one of such channels where practical codes have been unknown for several decades.Recently it has been demonstrated that deep learning based code outperforms the state-of-the-art codes for channels with output feedback. While the success is promising and inspiring, there are a few major challenges that need to be addressed. Firstly, the channel assumes a feedback with a unit step delay, which is not very practical. Second is the lack of generalization to larger block lengths. In this work, we propose Feedback Auto Turbo Encoder (FTAE) which harmoniously combines interleaver and iterative decoding with CNN architectures and demonstrate the blocklength gain and improved performance in the block feedback setting."}}
{"id": "KC740_qDElN", "cdate": 1577836800000, "mdate": 1682923272090, "content": {"title": "LEARN Codes: Inventing Low-Latency Codes via Recurrent Neural Networks", "abstract": "Designing channel codes under low-latency constraints is one of the most demanding requirements in 5G standards. However, a sharp characterization of the performance of traditional codes is available only in the large block-length limit. Guided by such asymptotic analysis, code designs require large block lengths as well as latency to achieve the desired error rate. Tail-biting convolutional codes and other recent state-of-the-art short block codes, while promising reduced latency, are neither robust to channel-mismatch nor adaptive to varying channel conditions. When the codes designed for one channel (e.g., Additive White Gaussian Noise (AWGN) channel) are used for another (e.g., non-AWGN channels), heuristics are necessary to achieve non-trivial performance. In this paper, we first propose an end-to-end learned neural code, obtained by jointly designing a Recurrent Neural Network (RNN) based encoder and decoder. This code outperforms canonical convolutional code under block settings. We then leverage this experience to propose a new class of codes under low-latency constraints, which we call Low-latency Efficient Adaptive Robust Neural (LEARN) codes. These codes outperform state-of-the-art low-latency codes and exhibit robustness and adaptivity properties. LEARN codes show the potential to design new versatile and universal codes for future communications via tools of modern deep learning coupled with communication engineering insights."}}
