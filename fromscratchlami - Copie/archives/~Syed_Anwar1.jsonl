{"id": "tez3MFMqyYp", "cdate": 1672531200000, "mdate": 1692983594410, "content": {"title": "SelfFed: Self-supervised Federated Learning for Data Heterogeneity and Label Scarcity in IoMT", "abstract": "Self-supervised learning in federated learning paradigm has been gaining a lot of interest both in industry and research due to the collaborative learning capability on unlabeled yet isolated data. However, self-supervised based federated learning strategies suffer from performance degradation due to label scarcity and diverse data distributions, i.e., data heterogeneity. In this paper, we propose the SelfFed framework for Internet of Medical Things (IoMT). Our proposed SelfFed framework works in two phases. The first phase is the pre-training paradigm that performs augmentive modeling using Swin Transformer based encoder in a decentralized manner. The first phase of SelfFed framework helps to overcome the data heterogeneity issue. The second phase is the fine-tuning paradigm that introduces contrastive network and a novel aggregation strategy that is trained on limited labeled data for a target task in a decentralized manner. This fine-tuning stage overcomes the label scarcity problem. We perform our experimental analysis on publicly available medical imaging datasets and show that our proposed SelfFed framework performs better when compared to existing baselines concerning non-independent and identically distributed (IID) data and label scarcity. Our method achieves a maximum improvement of 8.8% and 4.1% on Retina and COVID-FL datasets on non-IID dataset. Further, our proposed method outperforms existing baselines even when trained on a few (10%) labeled instances."}}
{"id": "pkZ1j4cGRc", "cdate": 1672531200000, "mdate": 1692983594411, "content": {"title": "The Brain Tumor Segmentation (BraTS) Challenge 2023: Focus on Pediatrics (CBTN-CONNECT-DIPGR-ASNR-MICCAI BraTS-PEDs)", "abstract": "Pediatric tumors of the central nervous system are the most common cause of cancer-related death in children. The five-year survival rate for high-grade gliomas in children is less than 20\\%. Due to their rarity, the diagnosis of these entities is often delayed, their treatment is mainly based on historic treatment concepts, and clinical trials require multi-institutional collaborations. The MICCAI Brain Tumor Segmentation (BraTS) Challenge is a landmark community benchmark event with a successful history of 12 years of resource creation for the segmentation and analysis of adult glioma. Here we present the CBTN-CONNECT-DIPGR-ASNR-MICCAI BraTS-PEDs 2023 challenge, which represents the first BraTS challenge focused on pediatric brain tumors with data acquired across multiple international consortia dedicated to pediatric neuro-oncology and clinical trials. The BraTS-PEDs 2023 challenge focuses on benchmarking the development of volumentric segmentation algorithms for pediatric brain glioma through standardized quantitative performance evaluation metrics utilized across the BraTS 2023 cluster of challenges. Models gaining knowledge from the BraTS-PEDs multi-parametric structural MRI (mpMRI) training data will be evaluated on separate validation and unseen test mpMRI dataof high-grade pediatric glioma. The CBTN-CONNECT-DIPGR-ASNR-MICCAI BraTS-PEDs 2023 challenge brings together clinicians and AI/imaging scientists to lead to faster development of automated segmentation techniques that could benefit clinical trials, and ultimately the care of children with brain tumors."}}
{"id": "kgfa3FqE2M", "cdate": 1672531200000, "mdate": 1692983594408, "content": {"title": "The Brain Tumor Segmentation (BraTS) Challenge 2023: Brain MR Image Synthesis for Tumor Segmentation (BraSyn)", "abstract": "Automated brain tumor segmentation methods have become well-established and reached performance levels offering clear clinical utility. These methods typically rely on four input magnetic resonance imaging (MRI) modalities: T1-weighted images with and without contrast enhancement, T2-weighted images, and FLAIR images. However, some sequences are often missing in clinical practice due to time constraints or image artifacts, such as patient motion. Consequently, the ability to substitute missing modalities and gain segmentation performance is highly desirable and necessary for the broader adoption of these algorithms in the clinical routine. In this work, we present the establishment of the Brain MR Image Synthesis Benchmark (BraSyn) in conjunction with the Medical Image Computing and Computer-Assisted Intervention (MICCAI) 2023. The primary objective of this challenge is to evaluate image synthesis methods that can realistically generate missing MRI modalities when multiple available images are provided. The ultimate aim is to facilitate automated brain tumor segmentation pipelines. The image dataset used in the benchmark is diverse and multi-modal, created through collaboration with various hospitals and research institutions."}}
{"id": "_wlmUkN1Exu", "cdate": 1672531200000, "mdate": 1692983594408, "content": {"title": "The ASNR-MICCAI Brain Tumor Segmentation (BraTS) Challenge 2023: Intracranial Meningioma", "abstract": "Meningiomas are the most common primary intracranial tumor in adults and can be associated with significant morbidity and mortality. Radiologists, neurosurgeons, neuro-oncologists, and radiation oncologists rely on multiparametric MRI (mpMRI) for diagnosis, treatment planning, and longitudinal treatment monitoring; yet automated, objective, and quantitative tools for non-invasive assessment of meningiomas on mpMRI are lacking. The BraTS meningioma 2023 challenge will provide a community standard and benchmark for state-of-the-art automated intracranial meningioma segmentation models based on the largest expert annotated multilabel meningioma mpMRI dataset to date. Challenge competitors will develop automated segmentation models to predict three distinct meningioma sub-regions on MRI including enhancing tumor, non-enhancing tumor core, and surrounding nonenhancing T2/FLAIR hyperintensity. Models will be evaluated on separate validation and held-out test datasets using standardized metrics utilized across the BraTS 2023 series of challenges including the Dice similarity coefficient and Hausdorff distance. The models developed during the course of this challenge will aid in incorporation of automated meningioma MRI segmentation into clinical practice, which will ultimately improve care of patients with meningioma."}}
{"id": "ZvtP0vTmQdJ", "cdate": 1672531200000, "mdate": 1692983594409, "content": {"title": "The Brain Tumor Segmentation (BraTS) Challenge 2023: Local Synthesis of Healthy Brain Tissue via Inpainting", "abstract": "A myriad of algorithms for the automatic analysis of brain MR images is available to support clinicians in their decision-making. For brain tumor patients, the image acquisition time series typically starts with a scan that is already pathological. This poses problems, as many algorithms are designed to analyze healthy brains and provide no guarantees for images featuring lesions. Examples include but are not limited to algorithms for brain anatomy parcellation, tissue segmentation, and brain extraction. To solve this dilemma, we introduce the BraTS 2023 inpainting challenge. Here, the participants' task is to explore inpainting techniques to synthesize healthy brain scans from lesioned ones. The following manuscript contains the task formulation, dataset, and submission procedure. Later it will be updated to summarize the findings of the challenge. The challenge is organized as part of the BraTS 2023 challenge hosted at the MICCAI 2023 conference in Vancouver, Canada."}}
{"id": "AjbRn3R7Er", "cdate": 1672531200000, "mdate": 1692983594413, "content": {"title": "Harmonization Across Imaging Locations(HAIL): One-Shot Learning for Brain MRI", "abstract": "For machine learning-based prognosis and diagnosis of rare diseases, such as pediatric brain tumors, it is necessary to gather medical imaging data from multiple clinical sites that may use different devices and protocols. Deep learning-driven harmonization of radiologic images relies on generative adversarial networks (GANs). However, GANs notoriously generate pseudo structures that do not exist in the original training data, a phenomenon known as \"hallucination\". To prevent hallucination in medical imaging, such as magnetic resonance images (MRI) of the brain, we propose a one-shot learning method where we utilize neural style transfer for harmonization. At test time, the method uses one image from a clinical site to generate an image that matches the intensity scale of the collaborating sites. Our approach combines learning a feature extractor, neural style transfer, and adaptive instance normalization. We further propose a novel strategy to evaluate the effectiveness of image harmonization approaches with evaluation metrics that both measure image style harmonization and assess the preservation of anatomical structures. Experimental results demonstrate the effectiveness of our method in preserving patient anatomy while adjusting the image intensities to a new clinical site. Our general harmonization model can be used on unseen data from new sites, making it a valuable tool for real-world medical applications and clinical trials."}}
{"id": "4A8yCEnoai", "cdate": 1672531200000, "mdate": 1692983594412, "content": {"title": "Upper Limb Movement Execution Classification using Electroencephalography for Brain Computer Interface", "abstract": "An accurate classification of upper limb movements using electroencephalography (EEG) signals is gaining significant importance in recent years due to the prevalence of brain-computer interfaces. The upper limbs in the human body are crucial since different skeletal segments combine to make a range of motion that helps us in our trivial daily tasks. Decoding EEG-based upper limb movements can be of great help to people with spinal cord injury (SCI) or other neuro-muscular diseases such as amyotrophic lateral sclerosis (ALS), primary lateral sclerosis, and periodic paralysis. This can manifest in a loss of sensory and motor function, which could make a person reliant on others to provide care in day-to-day activities. We can detect and classify upper limb movement activities, whether they be executed or imagined using an EEG-based brain-computer interface (BCI). Toward this goal, we focus our attention on decoding movement execution (ME) of the upper limb in this study. For this purpose, we utilize a publicly available EEG dataset that contains EEG signal recordings from fifteen subjects acquired using a 61-channel EEG device. We propose a method to classify four ME classes for different subjects using spectrograms of the EEG data through pre-trained deep learning (DL) models. Our proposed method of using EEG spectrograms for the classification of ME has shown significant results, where the highest average classification accuracy (for four ME classes) obtained is 87.36%, with one subject achieving the best classification accuracy of 97.03%."}}
{"id": "wfVV6I-XC5", "cdate": 1640995200000, "mdate": 1692983594448, "content": {"title": "SB-SSL: Slice-Based Self-Supervised Transformers for Knee Abnormality Classification from MRI", "abstract": "The availability of large scale data with high quality ground truth labels is a challenge when developing supervised machine learning solutions for healthcare domain. Although, the amount of digital data in clinical workflows is increasing, most of this data is distributed on clinical sites and protected to ensure patient privacy. Radiological readings and dealing with large-scale clinical data puts a significant burden on the available resources, and this is where machine learning and artificial intelligence play a pivotal role. Magnetic Resonance Imaging (MRI) for musculoskeletal (MSK) diagnosis is one example where the scans have a wealth of information, but require a significant amount of time for reading and labeling. Self-supervised learning (SSL) can be a solution for handling the lack of availability of ground truth labels, but generally requires a large amount of training data during the pretraining stage. Herein, we propose a slice-based self-supervised deep learning framework (SB-SSL), a novel slice-based paradigm for classifying abnormality using knee MRI scans. We show that for a limited number of cases (<1000), our proposed framework is capable to identify anterior cruciate ligament tear with an accuracy of 89.17% and an AUC of 0.954, outperforming state-of-the-art without usage of external data during pretraining. This demonstrates that our proposed framework is suited for SSL in the limited data regime."}}
{"id": "gRYwx90KlLE", "cdate": 1640995200000, "mdate": 1692983594427, "content": {"title": "Automatic melanoma detection and segmentation in dermoscopy images using deep RetinaNet and conditional random fields", "abstract": "Melanoma is one of the major causes of death around the world and is also known as malignant skin cancer. Melanoma detection is possible at an early stage by visual inspection of the infected lesions. There are a limited number of expert dermatologists available, moreover visual inspection also has limited accuracy. Hence, diagnosis and clinical decision making can be complicated for melanoma detection. Towards this, we propose a deep learning method for automatic detection and segmentation of melanoma regions within the dermoscopic images for precise melanoma segmentation. Our method generates bounding boxes around multiple regions to precisely detect the affected regions using RetinaNet. Further, conditional random field (CRF) is applied to the detected regions for segmentation of the melanoma lesion. In particular, we perform three steps: image pre-processing, melanoma localization, and melanoma segmentation. We evaluate our proposed method on Pedro Hispano (PH)2, International Skin Imaging Collaboration (ISIC) 2017, and ISIC 2018 benchmark datasets. Our experimental findings reveal the performance supremacy of our proposed method. For instance, pixel-level sensitivity is 0.932, pixel-level specificity is 0.977, pixel-level accuracy is 0.942, dice coefficient is 0.931, and Jaccard index is 0.9187 for ISIC 2018 challenge data. Our proposed method has shown good performance against other state-of-the-art methods evaluated on the ISIC 2018 challenge dataset. We attribute this performance to deep features computation using RetinaNet for detecting melanoma region and CRF for precise segmentation of the melanoma lesion."}}
{"id": "XBvB3Ha2Le", "cdate": 1640995200000, "mdate": 1692983594439, "content": {"title": "An Indoor Air Temperature Prediction Framework for Model Predictive Control in HVAC Systems", "abstract": "An accurate prediction of indoor air temperature (IAT) for heating, ventilation, and air conditioning (HVAC) systems in smart buildings is a challenging task, especially for a large future prediction horizon. In particular, the dependency of IAT modelling on various complex factors including outdoor ambient conditions, a large set of HVAC system parameters, and the nonlinearity which exists in building\u2019s thermodynamics make an accurate prediction of IAT difficult. Herein, we present a black-box model based IAT prediction algorithm which is used for an accurate IAT prediction using an artificial intelligence and a data-driven approach. Towards this, a Bi-LSTM (Long-short term memory) based model is proposed which is also compared with a standard LSTM based model. Our experimental results showed an improvement in IAT prediction of up to 10% using our proposed model when compared with a standard LSTM model for IAT prediction. These results are significant for applications where accurate IAT predictions can be used for a more robust energy consumption modelling and optimization in large scale buildings."}}
