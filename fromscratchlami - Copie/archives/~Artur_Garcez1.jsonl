{"id": "AJzrFyqP0ci", "cdate": 1652737819204, "mdate": null, "content": {"title": "Formalizing Consistency and Coherence of Representation Learning", "abstract": "In the study of reasoning in neural networks, recent efforts have sought to improve consistency and coherence of sequence models, leading to important developments in the area of neuro-symbolic AI. In symbolic AI, the concepts of consistency and coherence can be defined and verified formally, but for neural networks these definitions are lacking. The provision of such formal definitions is crucial to offer a common basis for the quantitative evaluation and systematic comparison of connectionist, neuro-symbolic and transfer learning approaches. In this paper, we introduce formal definitions of consistency and coherence for neural systems. To illustrate the usefulness of our definitions, we propose a new dynamic relation-decoder model built around the principles of consistency and coherence. We compare our results with several existing relation-decoders using a partial transfer learning task based on a novel data set introduced in this paper. Our experiments show that relation-decoders that maintain consistency over unobserved regions of representation space retain\ncoherence across domains, whilst achieving better transfer learning performance."}}
{"id": "Rx_nbGdtRQD", "cdate": 1632875630953, "mdate": null, "content": {"title": "Coherent and Consistent Relational Transfer Learning with Autoencoders", "abstract": "Human defined concepts are inherently transferable, but it is not clear under what conditions they can be modelled effectively by non-symbolic artificial learners.\nThis paper argues that for a transferable concept to be learned, the system of relations that define it must be coherent across domains.\nThis is to say that the learned concept-specific relations ought to be consistent with respect to a theory that constrains their semantics and that such consistency must extend beyond the representations encountered in the source domain.\nTo demonstrate this, we first present formal definitions for consistency and coherence, and a proposed Dynamic Comparator relation-decoder model designed around these principles. \nWe then perform a proposed Partial Relation Transfer learning task on a novel data set, using a neural-symbolic autoencoder architecture that combines sub-symbolic representations with modular relation-decoders.\nBy comparing against several existing relation-decoder models, our experiments show that relation-decoders which maintain consistency over unobserved regions of representational space retain coherence across domains, whilst achieving better transfer learning performance."}}
{"id": "rkgNJCVKPS", "cdate": 1569439195844, "mdate": null, "content": {"title": "Making DenseNet Interpretable: A Case Study in Clinical Radiology", "abstract": "The monotonous routine of medical image analysis under tight time constraints has always led to work fatigue for many medical practitioners.  Medical image interpretation can be error-prone and this can increase the risk of an incorrect procedure being recommended.  While the advancement of complex deep learning models has achieved performance beyond human capability in some computer vision tasks, widespread adoption in the medical field has been held back, among other factors, by poor model interpretability and a lack of high-quality labelled data.  This paper introduces a model interpretation and visualisation framework for the analysis of the feature extraction process in a deep convolutional neural network and applies it to abnormality detection using the musculoskeletal radio-graph dataset (MURA, Stanford). The proposed framework provides a mechanism for interpreting DenseNet deep learning architectures. It aims to provide a deeper insight about the paths of feature generation and reasoning within a DenseNet architecture.  When evaluated on MURA at abnormality detection tasks, the model interpretation framework has been shown capable of identifying limitations from the reasoning of a DenseNet architecture applied to radiography, which can in turn be ameliorated through model interpretation and visualization."}}
{"id": "ByEtPiAcY7", "cdate": 1538087777392, "mdate": null, "content": {"title": "Characterizing the Accuracy/Complexity Landscape of Explanations of Deep Networks through Knowledge Extraction", "abstract": "Knowledge extraction techniques are used to convert neural networks into symbolic descriptions with the objective of producing more comprehensible learning models. The central challenge is to find an explanation which is more comprehensible than the original model while still representing that model faithfully. The distributed nature of deep networks has led many to believe that the hidden features of a neural network cannot be explained by logical descriptions simple enough to be understood by humans, and that decompositional knowledge extraction should be abandoned in favour of other methods. In this paper we examine this question systematically by proposing a knowledge extraction method using \\textit{M-of-N} rules which allows us to map the complexity/accuracy landscape of rules describing hidden features in a Convolutional Neural Network (CNN). Experiments reported in this paper show that the shape of this landscape reveals an optimal trade off between comprehensibility and accuracy, showing that each latent variable has an optimal \\textit{M-of-N} rule to describe its behaviour. We find that the rules with optimal tradeoff in the first and final layer have a high degree of explainability whereas the rules with the optimal tradeoff in the second and third layer are less explainable. The results shed light on the feasibility of rule extraction from deep networks, and point to the value of decompositional knowledge extraction as a method of explainability."}}
{"id": "00Rp6XTNJq0GY", "cdate": null, "mdate": null, "content": {"title": "Adaptive Feature Ranking for Unsupervised Transfer Learning", "abstract": "Transfer Learning is concerned with the application of knowledge gained from solving a problem to a different but related problem domain. In this paper, we propose a method and efficient algorithm for ranking and selecting representations from a Restricted Boltzmann Machine trained on a source domain to be transferred onto a target domain. Experiments carried out using the MNIST, ICDAR and TiCC image datasets show that the proposed adaptive feature ranking and transfer learning method offers statistically significant improvements on the training of RBMs. Our method is general in that the knowledge chosen by the ranking function does not depend on its relation to any specific target domain, and it works with unsupervised learning and knowledge-based transfer."}}
