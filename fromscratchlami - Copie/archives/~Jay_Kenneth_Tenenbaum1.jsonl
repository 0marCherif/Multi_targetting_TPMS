{"id": "_CDixzkzeyb", "cdate": 1663850087423, "mdate": null, "content": {"title": "Prompt-to-Prompt Image Editing with Cross-Attention Control", "abstract": "Recent large-scale text-driven synthesis diffusion models have attracted much attention thanks to their remarkable capabilities of generating highly diverse images that follow given text prompts. Therefore, it is only natural to build upon these synthesis models to provide text-driven image editing capabilities. However, Editing is challenging for these generative models, since an innate property of an editing technique is to preserve some content from the original image, while in the text-based models, even a small modification of the text prompt often leads to a completely different outcome. State-of-the-art methods mitigate this by requiring the users to provide a spatial mask to localize the edit, hence, ignoring the original structure and content within the masked region. In this paper, we pursue an intuitive prompt-to-prompt editing framework, where the edits are controlled by text only. We analyze a text-conditioned model in depth and observe that the cross-attention layers are the key to controlling the relation between the spatial layout of the image to each word in the prompt. With this observation, we propose to control the attention maps along the diffusion process. Our approach enables us to monitor the synthesis process by editing the textual prompt only, paving the way to a myriad of caption-based editing applications such as localized editing by replacing a word, global editing by adding a specification, and even controlling the extent to which a word is reflected in the image. We present our results over diverse images and prompts with different text-to-image models, demonstrating high-quality synthesis and fidelity to the edited prompts."}}
{"id": "WEwtAYNWyHh", "cdate": 1621629926075, "mdate": null, "content": {"title": "Differentially Private Multi-Armed Bandits in the Shuffle Model", "abstract": "We give an $(\\varepsilon,\\delta)$-differentially private algorithm for the Multi-Armed Bandit (MAB) problem in the shuffle model with a distribution-dependent regret of $O\\left(\\left(\\sum_{a:\\Delta_a>0}\\frac{\\log T}{\\Delta_a}\\right)+\\frac{k\\sqrt{\\log\\frac{1}{\\delta}}\\log T}{\\varepsilon}\\right)$, and a distribution-independent regret of $O\\left(\\sqrt{kT\\log T}+\\frac{k\\sqrt{\\log\\frac{1}{\\delta}}\\log T}{\\varepsilon}\\right)$, where $T$ is the number of rounds, $\\Delta_a$ is the suboptimality gap of the action $a$, and $k$ is the total number of actions. Our upper bound almost matches the regret of the best known algorithms for the centralized model, and significantly outperforms the best known algorithm in the local model."}}
{"id": "P0AeY-efPEx", "cdate": 1621629926075, "mdate": null, "content": {"title": "Differentially Private Multi-Armed Bandits in the Shuffle Model", "abstract": "We give an $(\\varepsilon,\\delta)$-differentially private algorithm for the Multi-Armed Bandit (MAB) problem in the shuffle model with a distribution-dependent regret of $O\\left(\\left(\\sum_{a:\\Delta_a>0}\\frac{\\log T}{\\Delta_a}\\right)+\\frac{k\\sqrt{\\log\\frac{1}{\\delta}}\\log T}{\\varepsilon}\\right)$, and a distribution-independent regret of $O\\left(\\sqrt{kT\\log T}+\\frac{k\\sqrt{\\log\\frac{1}{\\delta}}\\log T}{\\varepsilon}\\right)$, where $T$ is the number of rounds, $\\Delta_a$ is the suboptimality gap of the action $a$, and $k$ is the total number of actions. Our upper bound almost matches the regret of the best known algorithms for the centralized model, and significantly outperforms the best known algorithm in the local model."}}
