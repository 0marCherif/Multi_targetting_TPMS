{"id": "RUgAmrtCI6", "cdate": 1694984190387, "mdate": 1694984190387, "content": {"title": "MipConfigBench: A dataset for learning in the space of Mixed-Integer Programming algorithms", "abstract": "Algorithm configuration (AC), algorithm selection (AS), and parallel algorithm portfolio (AP) are techniques for systematically choosing algorithm parameters to improve performance. Respectively, AC finds a single configuration with good performance over a family of instances, AS predicts good configurations on a per-instance basis by observing instance features, and parallel AP identifies combinations of multiple parameter settings that achieve better performance than any individual parameter setting. See [8] for a recent survey of these general techniques. In the context of mixed-integer programming (MIP), commercial solver developers have very recently begun to recognize and exploit the promise of choosing algorithm parameters based on instance features [1, 2]"}}
{"id": "HPPdai5utfy", "cdate": 1594384471956, "mdate": null, "content": {"title": "Zero-Shot Learning for Fast Optimization of Computation Graphs", "abstract": "We present a deep reinforcement learning approach to minimizing the execution cost of neural network computation graphs in an optimizing compiler. Unlike earlier learning-based works that require expensive online training steps, we propose a \u201czero-shot learning\u201d approach that trains an optimizer offline that successfully generalizes to previously unseen graphs. This allows our approach to produce high-quality execution decisions on real-world TensorFlow graphs in seconds instead of hours. We consider two optimization tasks for computation graphs: minimizing running time and peak memory usage. In comparison to an extensive set of baselines, our approach achieves significant improvements over classical and other learning-based methods on these two tasks."}}
{"id": "iUGUc3HJ_3f", "cdate": 1594384353412, "mdate": null, "content": {"title": "Graph Representations for Higher-Order Logic and Theorem Proving", "abstract": "This paper presents the first use of graph neural networks (GNNs) for higher-order proof search and demonstrates that GNNs can improve upon state-of-the-art results in this domain. Interactive, higher-order theorem provers allow for the formalization of most mathematical theories and have been shown to pose a significant challenge for deep learning. Higher-order logic is highly expressive and, even though it is well-structured with a clearly defined grammar and semantics, there still remains no well-established method to convert formulas into graph based representations. In this paper, we consider several graphical representations of higher-order logic and evaluate them against the HOList benchmark for higher-order theorem proving."}}
{"id": "rkxDoJBYPB", "cdate": 1569439647025, "mdate": null, "content": {"title": "Reinforced Genetic Algorithm Learning for Optimizing Computation Graphs", "abstract": "We present a deep reinforcement learning approach to minimizing the execution cost of neural network computation graphs in an optimizing compiler. Unlike earlier learning-based works that require training the optimizer on the same graph to be optimized, we propose a learning approach that trains an optimizer offline and then generalizes to previously unseen graphs without further training. This allows our approach to produce high-quality execution decisions on real-world TensorFlow graphs in seconds instead of hours. We consider two optimization tasks for computation graphs: minimizing running time and peak memory usage. In comparison to an extensive set of baselines, our approach achieves significant improvements over classical and other learning-based methods on these two tasks. "}}
{"id": "iqfZerNLbd9", "cdate": 1546300800000, "mdate": null, "content": {"title": "REGAL: Transfer Learning For Fast Optimization of Computation Graphs", "abstract": "We present a deep reinforcement learning approach to minimizing the execution cost of neural network computation graphs in an optimizing compiler. Unlike earlier learning-based works that require training the optimizer on the same graph to be optimized, we propose a learning approach that trains an optimizer offline and then generalizes to previously unseen graphs without further training. This allows our approach to produce high-quality execution decisions on real-world TensorFlow graphs in seconds instead of hours. We consider two optimization tasks for computation graphs: minimizing running time and peak memory usage. In comparison to an extensive set of baselines, our approach achieves significant improvements over classical and other learning-based methods on these two tasks."}}
