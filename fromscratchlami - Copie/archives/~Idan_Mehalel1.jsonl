{"id": "4kjq_Pp97v", "cdate": 1672531200000, "mdate": 1681593528907, "content": {"title": "Optimal Prediction Using Expert Advice and Randomized Littlestone Dimension", "abstract": ""}}
{"id": "6PpLxPPTPd", "cdate": 1652737711338, "mdate": null, "content": {"title": "On Optimal Learning Under Targeted Data Poisoning", "abstract": "Consider the task of learning a hypothesis class $\\mathcal{H}$ in the presence of an adversary that can replace up to an $\\eta$ fraction of the examples in the training set with arbitrary adversarial examples. The adversary aims to fail the learner on a particular target test point $x$ which is \\emph{known} to the adversary but not to the learner. In this work we aim to characterize the smallest achievable error $\\epsilon=\\epsilon(\\eta)$ by the learner in the presence of such an adversary in both realizable and agnostic settings. We fully achieve this in the realizable setting, proving that $\\epsilon=\\Theta(\\mathtt{VC}(\\mathcal{H})\\cdot \\eta)$, where $\\mathtt{VC}(\\mathcal{H})$ is the VC dimension of $\\mathcal{H}$. Remarkably, we show that the upper bound can be attained by a deterministic learner. In the agnostic setting we reveal a more elaborate landscape: we devise a deterministic learner with a multiplicative regret guarantee of $\\epsilon \\leq  C\\cdot\\mathtt{OPT} + O(\\mathtt{VC}(\\mathcal{H})\\cdot \\eta)$, where $C > 1$ is a universal numerical constant. We complement this by showing that for any deterministic learner there is an attack which worsens its error to at least $2\\cdot \\mathtt{OPT}$. This implies that a multiplicative deterioration in the regret is unavoidable in this case. Finally, the algorithms we develop for achieving the optimal rates are inherently improper. Nevertheless, we show that for a variety of natural concept classes, such as linear classifiers, it is possible to retain the dependence $\\epsilon=\\Theta_{\\mathcal{H}}(\\eta)$ by a proper algorithm in the realizable setting. Here $\\Theta_{\\mathcal{H}}$ conceals a polynomial dependence on $\\mathtt{VC}(\\mathcal{H})$."}}
{"id": "qEv4woBi34", "cdate": 1640995200000, "mdate": 1681593528882, "content": {"title": "A Resilient Distributed Boosting Algorithm", "abstract": ""}}
{"id": "bg3QdtoSDS", "cdate": 1640995200000, "mdate": 1681593528947, "content": {"title": "A Resilient Distributed Boosting Algorithm", "abstract": ""}}
{"id": "ZK5g_aJ5sa0", "cdate": 1640995200000, "mdate": 1681593528888, "content": {"title": "On Optimal Learning Under Targeted Data Poisoning", "abstract": ""}}
{"id": "2jsH7-QNzqu", "cdate": 1640995200000, "mdate": 1684043842615, "content": {"title": "On Optimal Learning Under Targeted Data Poisoning", "abstract": "Consider the task of learning a hypothesis class $\\mathcal{H}$ in the presence of an adversary that can replace up to an $\\eta$ fraction of the examples in the training set with arbitrary adversarial examples. The adversary aims to fail the learner on a particular target test point $x$ which is \\emph{known} to the adversary but not to the learner. In this work we aim to characterize the smallest achievable error $\\epsilon=\\epsilon(\\eta)$ by the learner in the presence of such an adversary in both realizable and agnostic settings. We fully achieve this in the realizable setting, proving that $\\epsilon=\\Theta(\\mathtt{VC}(\\mathcal{H})\\cdot \\eta)$, where $\\mathtt{VC}(\\mathcal{H})$ is the VC dimension of $\\mathcal{H}$. Remarkably, we show that the upper bound can be attained by a deterministic learner. In the agnostic setting we reveal a more elaborate landscape: we devise a deterministic learner with a multiplicative regret guarantee of $\\epsilon \\leq C\\cdot\\mathtt{OPT} + O(\\mathtt{VC}(\\mathcal{H})\\cdot \\eta)$, where $C &gt; 1$ is a universal numerical constant. We complement this by showing that for any deterministic learner there is an attack which worsens its error to at least $2\\cdot \\mathtt{OPT}$. This implies that a multiplicative deterioration in the regret is unavoidable in this case. Finally, the algorithms we develop for achieving the optimal rates are inherently improper. Nevertheless, we show that for a variety of natural concept classes, such as linear classifiers, it is possible to retain the dependence $\\epsilon=\\Theta_{\\mathcal{H}}(\\eta)$ by a proper algorithm in the realizable setting. Here $\\Theta_{\\mathcal{H}}$ conceals a polynomial dependence on $\\mathtt{VC}(\\mathcal{H})$."}}
{"id": "ZTt8CtGBL0", "cdate": 1609459200000, "mdate": 1684043842583, "content": {"title": "Optimal sets of questions for Twenty Questions", "abstract": "In the distributional Twenty Questions game, Bob chooses a number $x$ from $1$ to $n$ according to a distribution $\\mu$, and Alice (who knows $\\mu$) attempts to identify $x$ using Yes/No questions, which Bob answers truthfully. Her goal is to minimize the expected number of questions. The optimal strategy for the Twenty Questions game corresponds to a Huffman code for $\\mu$, yet this strategy could potentially uses all $2^n$ possible questions. Dagan et al. constructed a set of $1.25^{n+o(n)}$ questions which suffice to construct an optimal strategy for all $\\mu$, and showed that this number is optimal (up to sub-exponential factors) for infinitely many $n$. We determine the optimal size of such a set of questions for all $n$ (up to sub-exponential factors), answering an open question of Dagan et al. In addition, we generalize the results of Dagan et al. to the $d$-ary setting, obtaining similar results with $1.25$ replaced by $1 + (d-1)/d^{d/(d-1)}$."}}
