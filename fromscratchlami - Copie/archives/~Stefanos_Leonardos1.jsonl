{"id": "MNGYhZgov0K", "cdate": 1695952210856, "mdate": 1695952210856, "content": {"title": "Addressing Out-Of-Distribution Joint Actions in Offline Multi-Agent RL via Alternating Stationary Distribution Correction Estimation", "abstract": "One of the main challenges in offline Reinforcement Learning (RL) is the distribution shift that arises from the learned policy deviating from the data collection policy. This is often addressed by avoiding out-of-distribution (OOD) actions during policy improvement as their presence can lead to substantial performance degradation. This challenge is amplified in the offline Multi-Agent RL (MARL) setting since the joint action space grows exponentially with the number of agents. To remedy the exponential complexity, existing MARL methods adopt either value decomposition methods or fully decentralized training of individual agents. However, we observe that these methods, even combined with the conservatism principles used in offline RL, can result in the selection of OOD joint actions in offline MARL. To this end, we introduce AlberDICE, an offline MARL algorithm that alternatively performs centralized training of individual agents based on stationary distribution optimization. AlberDICE circumvents the exponential complexity of MARL by computing the best response of one agent at a time while effectively avoiding OOD joint action selection. Theoretically, we show that the alternating optimization procedure converges to Nash policies. In the experiments, we demonstrate that AlberDICE significantly outperforms baseline algorithms on a standard suite of MARL benchmarks."}}
{"id": "nksj3YvdEvD", "cdate": 1672531200000, "mdate": 1693322224820, "content": {"title": "Catastrophe by Design in Population Games: A Mechanism to Destabilize Inefficient Locked-in Technologies", "abstract": "In multi-agent environments in which coordination is desirable, the history of play often causes lock-in at sub-optimal outcomes. Notoriously, technologies with significant environmental footprint or high social cost persist despite the successful development of more environmentally friendly and/or socially efficient alternatives. The displacement of the status quo is hindered by entrenched economic interests and network effects. To exacerbate matters, the standard mechanism design approaches based on centralized authorities with the capacity to use preferential subsidies to effectively dictate system outcomes are not always applicable to modern decentralized economies. What other types of mechanisms are feasible? In this article, we develop and analyze a mechanism that induces transitions from inefficient lock-ins to superior alternatives. This mechanism does not exogenously favor one option over another; instead, the phase transition emerges endogenously via a standard evolutionary learning model, Q-learning, where agents trade off exploration and exploitation. Exerting the same transient influence to both the efficient and inefficient technologies encourages exploration and results in irreversible phase transitions and permanent stabilization of the efficient one. On a technical level, our work is based on bifurcation and catastrophe theory, a branch of mathematics that deals with changes in the number and stability properties of equilibria. Critically, our analysis is shown to be structurally robust to significant and even adversarially chosen perturbations to the parameters of both our game and our behavioral model."}}
{"id": "Jdj0fZhswJC", "cdate": 1663850581453, "mdate": null, "content": {"title": "Convergence is Not Enough: Average-Case Performance of No-Regret Learning Dynamics", "abstract": "Learning in games involves two main challenges, even in settings in which agents seek to coordinate: convergence to equilibria and selection of good equilibria. Unfortunately, solving the issue of convergence, which is the focus of state-of-the-art models, conveys little information about the quality of the equilibria that are eventually reached, often none at all. In this paper, we study a class of games in which q-replicator (QRD), a widely-studied class of no-regret learning dynamics that include gradient descent, \u201cstandard\u201d replicator, and log-barrier dynamics as special cases, can be shown to converge pointwise to Nash equilibria. This is the starting point for our main task, which is the mathematically challenging problem of performance. In our main contribution, we quantify both conceptually and experimentally the outcome of optimal learning dynamics via average performance metrics, i.e., metrics that couple the regions of attraction with the quality of each attracting point. We provide an exhaustive comparison between gradient descent and \u201cstandard\u201d replicator in a class of games with severe equilibrium selection problems and empirically extend our results to all dynamics in the QRD class. Our results combine tools from machine learning, game theory, and dynamical systems and provide a framework to initiate the systematic comparison of different optimal learning dynamics in arbitrary games."}}
{"id": "BWbUocJ6xq", "cdate": 1646226078146, "mdate": null, "content": {"title": "Global Convergence of Multi-Agent Policy Gradient in Markov Potential Games", "abstract": "Potential games are one of the most important and widely studied classes of normal-form games. They define the archetypal setting of multi-agent coordination in which all agents utilities are perfectly aligned via a common potential function. Can we embed this intuitive framework in the setting of Markov games? What are the similarities and differences between multi-agent coordination with and without state dependence? To answer these questions, we study a natural class of Markov Potential Games (MPGs) that generalizes prior attempts to capture complex stateful multi-agent coordination. Counter-intuitively, insights from normal-form potential games do not carry over since MPGs involve Markov games with zero-sum state-games, but Markov games in which all state-games are potential games are not necessarily MPGs. Nevertheless, MPGs showcase standard desirable properties such as the existence of deterministic Nash policies. In our main result, we prove convergence of independent policy gradient and its stochastic counterpart to Nash policies at a rate that is polynomial in the approximation error by adapting single-agent gradient domination properties to multi-agent settings. This answers questions on the convergence of finite-sample, independent policy gradient methods beyond settings of pure conflicting or pure common interests.\n"}}
{"id": "rTy6hGh5Fb7", "cdate": 1640995200000, "mdate": 1682324352179, "content": {"title": "Monopoly pricing in vertical markets with demand uncertainty", "abstract": "Pricing decisions are often made when market information is still poor. While modern pricing analytics aid firms to infer the distribution of the stochastic demand that they are facing, data-driven price optimization methods are often impractical or incomplete if not coupled with testable theoretical predictions. In turn, existing theoretical models often reason about the response of optimal prices to changing market characteristics without exploiting all available information about the demand distribution. Academic/practical relevance Our aim is to develop a theory for the optimization and systematic comparison of prices between different instances of the same market under various forms of knowledge about the corresponding demand distributions. Methodology We revisit the classic problem of monopoly pricing under demand uncertainty in a vertical market with an upstream supplier and multiple forms of downstream competition between arbitrary symmetric retailers. In all cases, demand uncertainty falls to the supplier who acts first and sets a uniform price before the retailers observe the realized demand and place their orders. Results Our main methodological contribution is that we express the price elasticity of expected demand in terms of the mean residual demand (MRD) function of the demand distribution. This leads to a closed form characterization of the points of unitary elasticity that maximize the supplier\u2019s profits and the derivation of a mild unimodality condition for the supplier\u2019s objective function that generalizes the widely used increasing generalized failure rate (IGFR) condition. A direct implication is that optimal prices between different markets can be ordered if the markets can be stochastically ordered according to their MRD functions or equivalently, their elasticities. Using the above, we develop a systematic framework to compare optimal prices between different market instances via the rich theory of stochastic orders. This leads to comparative statics that challenge previously established economic insights about the effects of market size, demand transformations and demand variability on monopolistic prices. Managerial implications Our findings complement data-driven decisions regarding price optimization and provide a systematic framework useful for making theoretical predictions in advance of market movements."}}
{"id": "lziz-vYEPC2", "cdate": 1640995200000, "mdate": 1693322224822, "content": {"title": "Market Equilibria and Risk Diversification in Blockchain Mining Economies", "abstract": "The success of blockchain-based applications, most notably cryptocurrencies, has brought the allocation of mining resources at the epicenter of academic and entrepreneurial attention. Critical for the stability of these markets is the question of how miners should adjust their allocations over time in response to changes in their environment and in other miners\u2019 strategies. In this paper, we present a proportional response (PR) protocol that makes these adjustments for any risk profile of a miner. The protocol has low informational requirements and is particularly suitable for such distributed settings. When the environment is static, we formally show that the PR protocol attains stability by converging to the market equilibrium. For dynamic environments, we carry out an empirical study with actual data from four popular cryptocurrencies. We find that running the PR protocol with higher risk diversification is beneficial both to the market by curbing volatile re-allocations (and, thus, increasing market stability), and to individual miners by improving their profits after accounting for factor mobility (switching) costs."}}
{"id": "jappZIjxaJC", "cdate": 1640995200000, "mdate": 1659119792018, "content": {"title": "Exploration-exploitation in multi-agent learning: Catastrophe theory meets game theory", "abstract": ""}}
{"id": "foWfk9hDet", "cdate": 1640995200000, "mdate": 1682324352125, "content": {"title": "Global Convergence of Multi-Agent Policy Gradient in Markov Potential Games", "abstract": "Potential games are arguably one of the most important and widely studied classes of normal form games. They define the archetypal setting of multi-agent coordination in which all agents utilities are perfectly aligned via a common potential function. Can this intuitive framework be transplanted in the setting of Markov games? What are the similarities and differences between multi-agent coordination with and without state dependence? To answer these questions, we study a natural class of Markov Potential Games (MPGs) that generalize prior attempts at capturing complex stateful multi-agent coordination. Counter-intuitively, insights from normal-form potential games do not carry over as MPGs involve settings where state-games can be zero-sum games. In the opposite direction, Markov games where every state-game is a potential game are not necessarily MPGs. Nevertheless, MPGs showcase standard desirable properties such as the existence of deterministic Nash policies. In our main technical result, we prove convergence of independent policy gradient and its stochastic counterpart to Nash policies (polynomially fast in the approximation error) by adapting recent gradient dominance property arguments developed for single-agent Markov decision processes to multi-agent learning settings."}}
{"id": "Q6e5cf4heb", "cdate": 1640995200000, "mdate": 1693322224821, "content": {"title": "Griefing Factors and Evolutionary In-Stabilities in Blockchain Mining Games", "abstract": "We revisit the standard game-theoretic model of blockchain mining and identify two sources of instabilities for its unique Nash equilibrium. In our first result, we show that griefing, a practice according to which participants of peer-to-peer networks harm other participants at some lesser cost to themselves, is a plausible threat that may lead cost-efficient miners to allocate more resources than predicted. The proof relies on the evaluation of griefing factors, ratios that measure network losses relative to an attacker\u2019s own losses and leads to a generalization of the notion of evolutionary stability to non-homogeneous populations which may be of independent game-theoretic interest. From a practical perspective, this finding provides explains the over-dissipation of mining resources, consolidation of power and high entry barriers that are currently observed in many mining networks. We, then, turn to the natural question of whether dynamic adjustments of mining allocations may, in fact, lead to the Nash equilibrium prediction. By studying two common learning rules, gradient ascent and best response dynamics, we provide evidence for the contrary. Thus, along with earlier results regarding in-protocol attacks, these findings paint a more complete picture about the various inherent instabilities of permissionless mining networks."}}
{"id": "1zNd7Z-yQA", "cdate": 1640995200000, "mdate": 1682324352124, "content": {"title": "Optimality Despite Chaos in Fee Markets", "abstract": "Transaction fee markets are essential components of blockchain economies, as they resolve the inherent scarcity in the number of transactions that can be added to each block. In early blockchain protocols, this scarcity was resolved through a first-price auction in which users were forced to guess appropriate bids from recent blockchain data. Ethereum's EIP-1559 fee market reform streamlines this process through the use of a base fee that is increased (or decreased) whenever a block exceeds (or fails to meet) a specified target block size. Previous work has found that the EIP-1559 mechanism may lead to a base fee process that is inherently chaotic, in which case the base fee does not converge to a fixed point even under ideal conditions. However, the impact of this chaotic behavior on the fee market's main design goal -- blocks whose long-term average size equals the target -- has not previously been explored. As our main contribution, we derive near-optimal upper and lower bounds for the time-average block size in the EIP-1559 mechanism despite its possibly chaotic evolution. Our lower bound is equal to the target utilization level whereas our upper bound is approximately 6% higher than optimal. Empirical evidence is shown in great agreement with these theoretical predictions. Specifically, the historical average was approximately 2.9% larger than the target rage under Proof-of-Work and decreased to approximately 2.0% after Ethereum's transition to Proof-of-Stake. We also find that an approximate version of EIP-1559 achieves optimality even in the absence of convergence."}}
