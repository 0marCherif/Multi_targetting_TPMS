{"id": "MpXaR2Amflv", "cdate": 1641506816194, "mdate": 1641506816194, "content": {"title": "Language Models Are An Effective Representation Learning Technique For Electronic Health Record Data", "abstract": "Widespread adoption of electronic health records (EHRs) has fueled the development of using machine learning to build prediction models for various clinical outcomes. This process is often constrained by having a relatively small number of patient records for training the model. We demonstrate that using patient representation schemes inspired from techniques in natural language processing can increase\nthe accuracy of clinical prediction models by transferring information learned from the entire patient population to the task of training a specific model, where only a subset of the population is relevant. Such patient representation schemes enable a 3.5% mean improvement in AUROC on five prediction tasks compared to standard baselines, with the average improvement rising to 19% when only a small\nnumber of patient records are available for training the clinical prediction model."}}
{"id": "lQ6ci-NxLD0", "cdate": 1640995200000, "mdate": 1657129222231, "content": {"title": "Net benefit, calibration, threshold selection, and training objectives for algorithmic fairness in healthcare", "abstract": "A growing body of work uses the paradigm of algorithmic fairness to frame the development of techniques to anticipate and proactively mitigate the introduction or exacerbation of health inequities that may follow from the use of model-guided decision-making. We evaluate the interplay between measures of model performance, fairness, and the expected utility of decision-making to offer practical recommendations for the operationalization of algorithmic fairness principles for the development and evaluation of predictive models in healthcare. We conduct an empirical case-study via development of models to estimate the ten-year risk of atherosclerotic cardiovascular disease to inform statin initiation in accordance with clinical practice guidelines. We demonstrate that approaches that incorporate fairness considerations into the model training objective typically do not improve model performance or confer greater net benefit for any of the studied patient populations compared to the use of standard learning paradigms followed by threshold selection concordant with patient preferences, evidence of intervention effectiveness, and model calibration. These results hold when the measured outcomes are not subject to differential measurement error across patient populations and threshold selection is unconstrained, regardless of whether differences in model performance metrics, such as in true and false positive error rates, are present. In closing, we argue for focusing model development efforts on developing calibrated models that predict outcomes well for all patient populations while emphasizing that such efforts are complementary to transparent reporting, participatory design, and reasoning about the impact of model-informed interventions in context."}}
{"id": "KoUyxUj85Ny", "cdate": 1640995200000, "mdate": 1657129222230, "content": {"title": "Improving the Fairness of Chest X-ray Classifiers", "abstract": "Deep learning models have reached or surpassed human-level performance in the field of medical imaging, especially in disease diagnosis using chest x-rays. However, prior work has found that such c..."}}
{"id": "sUuKEdOZOb", "cdate": 1609459200000, "mdate": 1657129222230, "content": {"title": "Systematic Review of Approaches to Preserve Machine Learning Performance in the Presence of Temporal Dataset Shift in Clinical Medicine", "abstract": "p> <b>Objective</b>\u2003The change in performance of machine learning models over time as a result of temporal dataset shift is a barrier to machine learning-derived models facilitating decision-making in clinical practice. Our aim was to describe technical procedures used to preserve the performance of machine learning models in the presence of temporal dataset shifts.</p> <p> <b>Methods</b>\u2003Studies were included if they were fully published articles that used machine learning and implemented a procedure to mitigate the effects of temporal dataset shift in a clinical setting. We described how dataset shift was measured, the procedures used to preserve model performance, and their effects.</p> <p> <b>Results</b>\u2003Of 4,457 potentially relevant publications identified, 15 were included. The impact of temporal dataset shift was primarily quantified using changes, usually deterioration, in calibration or discrimination. Calibration deterioration was more common (<i>n</i>\u2009=\u200911) than discrimination deterioration (<i>n</i>\u2009=\u20093). Mitigation strategies were categorized as model level or feature level. Model-level approaches (<i>n</i>\u2009=\u200915) were more common than feature-level approaches (<i>n</i>\u2009=\u20092), with the most common approaches being model refitting (<i>n</i>\u2009=\u200912), probability calibration (<i>n</i>\u2009=\u20097), model updating (<i>n</i>\u2009=\u20096), and model selection (<i>n</i>\u2009=\u20096). In general, all mitigation strategies were successful at preserving calibration but not uniformly successful in preserving discrimination.</p> <p> <b>Conclusion</b>\u2003There was limited research in preserving the performance of machine learning models in the presence of temporal dataset shift in clinical medicine. Future research could focus on the impact of dataset shift on clinical decision making, benchmark the mitigation strategies on a wider range of datasets and tasks, and identify optimal strategies for specific settings.</p>"}}
{"id": "hX9-r4YH70R", "cdate": 1609459200000, "mdate": 1641394779001, "content": {"title": "An empirical characterization of fair machine learning for clinical risk prediction", "abstract": "Highlights \u2022 We study the effect of algorithmic fairness constraints on clinical risk prediction. \u2022 We study fairness defined as conditional prediction parity, calibration, and ranking. \u2022 There is heterogeneity in trade-offs among measures of performance and fairness. \u2022 Researchers should engage with the broader context surrounding ML use in healthcare. Abstract The use of machine learning to guide clinical decision making has the potential to worsen existing health disparities. Several recent works frame the problem as that of algorithmic fairness, a framework that has attracted considerable attention and criticism. However, the appropriateness of this framework is unclear due to both ethical as well as technical considerations, the latter of which include trade-offs between measures of fairness and model performance that are not well-understood for predictive models of clinical outcomes. To inform the ongoing debate, we conduct an empirical study to characterize the impact of penalizing group fairness violations on an array of measures of model performance and group fairness. We repeat the analysis across multiple observational healthcare databases, clinical outcomes, and sensitive attributes. We find that procedures that penalize differences between the distributions of predictions across groups induce nearly-universal degradation of multiple performance metrics within groups. On examining the secondary impact of these procedures, we observe heterogeneity of the effect of these procedures on measures of fairness in calibration and ranking across experimental conditions. Beyond the reported trade-offs, we emphasize that analyses of algorithmic fairness in healthcare lack the contextual grounding and causal awareness necessary to reason about the mechanisms that lead to health disparities, as well as about the potential of algorithmic fairness methods to counteract those mechanisms. In light of these limitations, we encourage researchers building predictive models for clinical use to step outside the algorithmic fairness frame and engage critically with the broader sociotechnical context surrounding the use of machine learning in healthcare."}}
{"id": "S1DS7MUVP8O", "cdate": 1609459200000, "mdate": 1641394779028, "content": {"title": "A comparison of approaches to improve worst-case predictive model performance over patient subpopulations", "abstract": "Predictive models for clinical outcomes that are accurate on average in a patient population may underperform drastically for some subpopulations, potentially introducing or reinforcing inequities in care access and quality. Model training approaches that aim to maximize worst-case model performance across subpopulations, such as distributionally robust optimization (DRO), attempt to address this problem without introducing additional harms. We conduct a large-scale empirical study of DRO and several variations of standard learning procedures to identify approaches for model development and selection that consistently improve disaggregated and worst-case performance over subpopulations compared to standard approaches for learning predictive models from electronic health records data. In the course of our evaluation, we introduce an extension to DRO approaches that allows for specification of the metric used to assess worst-case performance. We conduct the analysis for models that predict in-hospital mortality, prolonged length of stay, and 30-day readmission for inpatient admissions, and predict in-hospital mortality using intensive care data. We find that, with relatively few exceptions, no approach performs better, for each patient subpopulation examined, than standard learning procedures using the entire training dataset. These results imply that when it is of interest to improve model performance for patient subpopulations beyond what can be achieved with standard practices, it may be necessary to do so via data collection techniques that increase the effective sample size or reduce the level of noise in the prediction problem."}}
{"id": "2TmaMPzNZ_8", "cdate": 1609459200000, "mdate": 1641394779022, "content": {"title": "Language models are an effective representation learning technique for electronic health record data", "abstract": "Highlights \u2022 Electronic health records are often used to predict clinical outcomes. \u2022 One primary limiting factor for obtaining high quality predictions is limited data. \u2022 We demonstrate a representation learning technique that works around this limitation. \u2022 Models trained on these representations offer superior performance in many settings. Abstract Widespread adoption of electronic health records (EHRs) has fueled the development of using machine learning to build prediction models for various clinical outcomes. However, this process is often constrained by having a relatively small number of patient records for training the model. We demonstrate that using patient representation schemes inspired from techniques in natural language processing can increase the accuracy of clinical prediction models by transferring information learned from the entire patient population to the task of training a specific model, where only a subset of the population is relevant. Such patient representation schemes enable a 3.5% mean improvement in AUROC on five prediction tasks compared to standard baselines, with the average improvement rising to 19% when only a small number of patient records are available for training the clinical prediction model."}}
{"id": "FYkcVjyPe4", "cdate": 1577836800000, "mdate": null, "content": {"title": "Language Models Are An Effective Patient Representation Learning Technique For Electronic Health Record Data", "abstract": "Widespread adoption of electronic health records (EHRs) has fueled the development of using machine learning to build prediction models for various clinical outcomes. This process is often constrained by having a relatively small number of patient records for training the model. We demonstrate that using patient representation schemes inspired from techniques in natural language processing can increase the accuracy of clinical prediction models by transferring information learned from the entire patient population to the task of training a specific model, where only a subset of the population is relevant. Such patient representation schemes enable a 3.5% mean improvement in AUROC on five prediction tasks compared to standard baselines, with the average improvement rising to 19% when only a small number of patient records are available for training the clinical prediction model."}}
{"id": "qmgO_hYNLuF", "cdate": 1546300800000, "mdate": null, "content": {"title": "Counterfactual Reasoning for Fair Clinical Risk Prediction", "abstract": "The use of machine learning systems to support decision making in healthcare raises questions as to what extent these systems may introduce or exacerbate disparities in care for historically underr..."}}
{"id": "YmDv2HoztG", "cdate": 1546300800000, "mdate": null, "content": {"title": "Creating Fair Models of Atherosclerotic Cardiovascular Disease Risk", "abstract": "Guidelines for the management of atherosclerotic cardiovascular disease (ASCVD) recommend the use of risk stratification models to identify patients most likely to benefit from cholesterol-lowering and other therapies. These models have differential performance across race and gender groups with inconsistent behavior across studies, potentially resulting in an inequitable distribution of beneficial therapy. In this work, we leverage adversarial learning and a large observational cohort extracted from electronic health records (EHRs) to develop a \"fair\" ASCVD risk prediction model with reduced variability in error rates across groups. We empirically demonstrate that our approach is capable of aligning the distribution of risk predictions conditioned on the outcome across several groups simultaneously for models built from high-dimensional EHR data. We also discuss the relevance of these results in the context of the empirical trade-off between fairness and model performance."}}
