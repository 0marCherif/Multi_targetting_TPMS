{"id": "sCXbQK5z9r0", "cdate": 1648704602487, "mdate": 1648704602487, "content": {"title": "Object-Guided Day-Night Visual Localization in Urban Scenes", "abstract": "We introduce Object-Guided Localization (OGuL) based on a novel method of local-feature matching. Direct matching of local features is sensitive to significant changes in illumination. In contrast, object detection often survives severe changes in lighting conditions. The proposed method first detects semantic objects and establishes correspondences of those objects between images. Object correspondences provide local coarse alignment of the images in the form of a planar homography. These homographies are consequently used to guide the matching of local features. Experiments on standard urban localization datasets (Aachen, Extended-CMU-Season, RobotCar-Season) show that OGuL significantly improves localization results with as simple local features as SIFT, and its performance competes with the state-of-the-art CNN-based methods trained for day-to-night localization."}}
{"id": "4899tbiuUl0", "cdate": 1640995200000, "mdate": 1682319033550, "content": {"title": "Object-Guided Day-Night Visual localization in Urban Scenes", "abstract": "We introduce Object-Guided localization (OGuL) based on a novel method of local-feature matching. Direct matching of local features is sensitive to significant changes in illumination. In contrast, object detection often survives severe changes in lighting conditions. The proposed method first detects semantic objects and establishes correspondences of those objects between images. Object correspondences provide local coarse alignment of the images in the form of a planar homography. These homographies are consequently used to guide the matching of local features. Experiments on standard urban localization datasets (Aachen, RobotCar-Season) show that OGuL significantly improves localization results with as simple local features as SIFT, and its performance competes with the state-of-the-art CNN-based methods trained for day-to-night localization."}}
{"id": "0MGVopatnt", "cdate": 1577836800000, "mdate": 1631877937641, "content": {"title": "Image-Based Place Recognition on Bucolic Environment Across Seasons From Semantic Edge Description", "abstract": "Most of the research effort on image-based place recognition is designed for urban environments. In bucolic environments such as natural scenes with low texture and little semantic content, the main challenge is to handle the variations in visual appearance across time such as illumination, weather, vegetation state or viewpoints. The nature of the variations is different and this leads to a different approach to describing a bucolic scene. We introduce a global image description computed from its semantic and topological information. It is built from the wavelet transforms of the image's semantic edges. Matching two images is then equivalent to matching their semantic edge transforms. This method reaches state-of-the-art image retrieval performance on two multi-season environment-monitoring datasets: the CMU-Seasons and the Symphony Lake dataset. It also generalizes to urban scenes on which it is on par with the current baselines NetVLAD and DELF."}}
{"id": "xtJ6TSWoVm", "cdate": 1546300800000, "mdate": null, "content": {"title": "Semi-supervised Domain Adaptation with Representation Learning for Semantic Segmentation Across Time", "abstract": "Deep learning generates state-of-the-art semantic segmentation provided that a large number of images together with pixel-wise annotations are available. To alleviate the expensive data collection process, we propose a semi-supervised domain adaptation method for the specific case of images with similar semantic content but different pixel distributions. A network trained with supervision on a past dataset is finetuned on the new dataset to conserve its features maps. The domain adaptation becomes a simple regression between feature maps and does not require annotations on the new dataset. This method reaches performances similar to classic transfer learning on the PASCAL VOC dataset with synthetic transformations."}}
{"id": "lhCelvdF82M", "cdate": 1546300800000, "mdate": 1631877883485, "content": {"title": "Semantic Nearest Neighbor Fields Monocular Edge Visual-Odometry", "abstract": "Recent advances in deep learning for edge detection and segmentation opens up a new path for semantic-edge-based ego-motion estimation. In this work, we propose a robust monocular visual odometry (VO) framework using category-aware semantic edges. It can reconstruct large-scale semantic maps in challenging outdoor environments. The core of our approach is a semantic nearest neighbor field that facilitates a robust data association of edges across frames using semantics. This significantly enlarges the convergence radius during tracking phases. The proposed edge registration method can be easily integrated into direct VO frameworks to estimate photometrically, geometrically, and semantically consistent camera motions. Different types of edges are evaluated and extensive experiments demonstrate that our proposed system outperforms state-of-art indirect, direct, and semantic monocular VO systems."}}
{"id": "lOLTkvs6XCg", "cdate": 1546300800000, "mdate": 1668153496888, "content": {"title": "ELF: Embedded Localisation of Features in Pre-Trained CNN", "abstract": ""}}
{"id": "RYS3B0MFcNs", "cdate": 1546300800000, "mdate": null, "content": {"title": "Learning Sensor Placement from Demonstration for UAV networks", "abstract": "This work demonstrates how to leverage previous network expert demonstrations of UAV deployment to automate the drones placement in civil applications. Optimal UAV placement is an NP-complete problem: it requires a closed-form utility function that defines the environment and the UAV constraints, it is not unique and must be defined for each new UAV mission. This complex and time-consuming process hinders the development of UAV-networks in civil applications. We propose a method that leverages previous network expert solutions of UAV-network deployment to learn the expert's untold utility function form demonstrations only. This is especially interesting as it may be difficult for the inspection expert to explicit his expertise into such a function as it is too complex. Once learned, our model generates a utility function which maxima match expert UAV locations. We test this method on a Wi-Fi UAV network application inside a crowd simulator and reach similar quality-of-service as the expert. We show that our method is not limited to this UAV application and can be extended to other missions such as building monitoring."}}
