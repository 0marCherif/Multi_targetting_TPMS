{"id": "mC-95pi7agE", "cdate": 1577836800000, "mdate": null, "content": {"title": "Seq2seq Fingerprint with Byte-Pair Encoding for Predicting Changes in Protein Stability upon Single Point Mutation", "abstract": "The engineering of stable proteins is crucial for various industrial purposes. Several machine learning methods have been developed to predict changes in the stability of proteins corresponding to single point mutations. To improve the prediction accuracy, we propose a new unsupervised descriptor for protein sequences, which is based on a sequence-to-sequence (seq2seq) neural network model combined with a sequence-compression method called byte-pair encoding (BPE). Our results demonstrate that BPE can encode a protein sequence into a sequence of shorter length, thereby enabling efficient training of the seq2seq model. Furthermore, we implement a basic predictor using the proposed descriptor, and our experimental results demonstrate that the predictor achieves state-of-the-art accuracy in tests for proteins that are not included in the training data."}}
{"id": "emEqa0MAxW9", "cdate": 1577836800000, "mdate": null, "content": {"title": "Variational Monocular Depth Estimation for Reliability Prediction", "abstract": "Self-supervised learning for monocular depth estimation is widely investigated as an alternative to supervised learning approach, that requires a lot of ground truths. Previous works have successfully improved the accuracy of depth estimation by modifying the model structure, adding objectives, and masking dynamic objects and occluded area. However, when using such estimated depth image in applications, such as autonomous vehicles, and robots, we have to uniformly believe the estimated depth at each pixel position. This could lead to fatal errors in performing the tasks, because estimated depth at some pixels may make a bigger mistake. In this paper, we theoretically formulate a variational model for the monocular depth estimation to predict the reliability of the estimated depth image. Based on the results, we can exclude the estimated depths with low reliability or refine them for actual use. The effectiveness of the proposed method is quantitatively and qualitatively demonstrated using the KITTI benchmark and Make3D dataset."}}
{"id": "eZl3GtzgJI", "cdate": 1577836800000, "mdate": null, "content": {"title": "Neural Time Warping For Multiple Sequence Alignment", "abstract": "Multiple sequences alignment (MSA) is a traditional and challenging task for time-series analyses. The MSA problem is formulated as a discrete optimization problem and is typically solved by dynamic programming. However, the computational complexity increases exponentially with respect to the number of input sequences. In this paper, we propose neural time warping (NTW) that relaxes the original MSA to a continuous optimization and obtains the alignments using a neural network. The solution obtained by NTW is guaranteed to be a feasible solution for the original discrete optimization problem under mild conditions. Our experimental results show that NTW successfully aligns a hundred time-series and significantly outperforms existing methods for solving the MSA problem. In addition, we show a method for obtaining average time-series data as one of applications of NTW. Compared to the existing barycenters, the mean time series data retains the features of the input time-series data."}}
{"id": "UXPobQFXvO-", "cdate": 1577836800000, "mdate": null, "content": {"title": "PLG-IN: Pluggable Geometric Consistency Loss with Wasserstein Distance in Monocular Depth Estimation", "abstract": "We propose a novel objective for penalizing geometric inconsistencies to improve the depth and pose estimation performance of monocular camera images. Our objective is designed using the Wasserstein distance between two point clouds, estimated from images with different camera poses. The Wasserstein distance can impose a soft and symmetric coupling between two point clouds, which suitably maintains geometric constraints and results in a differentiable objective. By adding our objective to the those of other state-of-the-art methods, we can effectively penalize geometric inconsistencies and obtain highly accurate depth and pose estimations. Our proposed method is evaluated using the KITTI dataset."}}
{"id": "S2NjkoVqMCw", "cdate": 1577836800000, "mdate": null, "content": {"title": "Learning Wasserstein Isometric Embedding for Point Clouds", "abstract": "The Wasserstein distance has been employed for determining the distance between point clouds, which have variable numbers of points and invariance of point order. However, the high computational cost associated with the Wasserstein distance hinders its practical applications for large-scale datasets. We propose a new embedding method for point clouds, which aims to embed point clouds into a Euclidean space, isometric to the Wasserstein space defined on the point clouds. In numerical experiments, we demonstrate that the point clouds decoded from the Euclidean averages and the interpolations in the embedding space accurately mimic the Wasserstein barycenters and interpolations of the point clouds. Furthermore, we show that the embedding vectors can be utilized as inputs for machine learning models (e.g., principal component analysis and neural networks)."}}
{"id": "wz2Ad7e-JO8", "cdate": 1546300800000, "mdate": null, "content": {"title": "Canonical Soft Time Warping", "abstract": "Alignment of two given sequences (i.e., computing correspondence between frames considering local time shifting) is a fundamental operation for various applications such as computer vision and bioi..."}}
{"id": "J4ljDOhBB-", "cdate": 1546300800000, "mdate": null, "content": {"title": "Flow-based Image-to-Image Translation with Feature Disentanglement", "abstract": "Learning non-deterministic dynamics and intrinsic factors from images obtained through physical experiments is at the intersection of machine learning and material science. Disentangling the origins of uncertainties involved in microstructure growth, for example, is of great interest because future states vary due to thermal fluctuation and other environmental factors. To this end we propose a flow-based image-to-image model, called Flow U-Net with Squeeze modules (FUNS), that allows us to disentangle the features while retaining the ability to generate highquality diverse images from condition images. Our model successfully captures probabilistic phenomena by incorporating a U-Net-like architecture into the flowbased model. In addition, our model automatically separates the diversity of target images into condition-dependent/independent parts. We demonstrate that the quality and diversity of the images generated for microstructure growth and CelebA datasets outperform existing variational generative models."}}
{"id": "HJVB7uZObB", "cdate": 1514764800000, "mdate": null, "content": {"title": "Neural Edit Operations for Biological Sequences", "abstract": "The evolution of biological sequences, such as proteins or DNAs, is driven by the three basic edit operations: substitution, insertion, and deletion. Motivated by the recent progress of neural network models for biological tasks, we implement two neural network architectures that can treat such edit operations. The first proposal is the edit invariant neural networks, based on differentiable Needleman-Wunsch algorithms. The second is the use of deep CNNs with concatenations. Our analysis shows that CNNs can recognize star-free regular expressions, and that deeper CNNs can recognize more complex regular expressions including the insertion/deletion of characters. The experimental results for the protein secondary structure prediction task suggest the importance of insertion/deletion. The test accuracy on the widely-used CB513 dataset is 71.5%, which is 1.2-points better than the current best result on non-ensemble models."}}
{"id": "aS4EajMIJx", "cdate": 1483228800000, "mdate": null, "content": {"title": "Causal Patterns: Extraction of Multiple Causal Relationships by Mixture of Probabilistic Partial Canonical Correlation Analysis", "abstract": "In this paper, we propose a mixture of probabilistic partial canonical correlation analysis (MPPCCA) that extracts the Causal Patterns from two multivariate time series. Causal patterns refer to the signal patterns within interactions of two elements having multiple types of mutually causal relationships, rather than a mixture of simultaneous correlations or the absence of presence of a causal relationship between the elements. In multivariate statistics, partial canonical correlation analysis (PCCA) evaluates the correlation between two multivariates after subtracting the effect of the third multivariate. PCCA can calculate the Granger Causality Index (which tests whether a time-series can be predicted from another time-series), but is not applicable to data containing multiple partial canonical correlations. After introducing the MPPCCA, we propose an expectation-maxmization (EM) algorithm that estimates the parameters and latent variables of the MPPCCA. The MPPCCA is expected to extract multiple partial canonical correlations from data series without any supervised signals to split the data as clusters. The method was then evaluated in synthetic data experiments. In the synthetic dataset, our method estimated the multiple partial canonical correlations more accurately than the existing method. To determine the types of patterns detectable by the method, experiments were also conducted on real datasets. The method estimated the communication patterns In motion-capture data. The MPPCCA is applicable to various type of signals such as brain signals, human communication and nonlinear complex multibody systems."}}
{"id": "eO084YblRqo", "cdate": 1356998400000, "mdate": null, "content": {"title": "RoboCup 2013: Best Humanoid Award Winner JoiTech", "abstract": "This article presents the technical strategy employed by JoiTech in the RoboCup 2013 humanoid league adult size championship. Two features focused on by the team were the design of a versatile robot simulator and smart strategies for the robot player JoiTech Messi. The input for the versatile robot simulator in our system was data from the robot\u2019s camera and the output was a motor command given to the robot. Our system used real video data and a robot, as well as virtual data and video data recorded from the real robot\u2019s camera. Thus, we could select one of three inputs, i.e., real, virtual, and recorded, and one of two outputs, i.e., real and virtual. This combination of data allowed us to debug the codes used by Messi in an efficient manner. This reduced the number of real robot tests, which minimized damage to the robot. In the design of the smart strategies for the robot player JoiTech Messi, we developed a system that recognized opponent robots using background subtraction, which improved the accuracy of the striker and the goalkeeper. The detection of an opponent player was useful for finding the space to shoot and to block the goal when an opponent player attempted to score. These two features worked effectively during the competitions and our JoiTech team won the championship, as well as the best humanoid award (\u201dLouis Vuitton Cup\u201d), which demonstrated the success of our system."}}
