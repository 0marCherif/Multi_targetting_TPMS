{"id": "yKl4KclLwjB", "cdate": 1672531200000, "mdate": 1703529898633, "content": {"title": "Smooth Lower Bounds for Differentially Private Algorithms via Padding-and-Permuting Fingerprinting Codes", "abstract": "Fingerprinting arguments, first introduced by Bun, Ullman, and Vadhan (STOC 2014), are the most widely used method for establishing lower bounds on the sample complexity or error of approximately differentially private (DP) algorithms. Still, there are many problems in differential privacy for which we don't know suitable lower bounds, and even for problems that we do, the lower bounds are not smooth, and usually become vacuous when the error is larger than some threshold. In this work, we present a simple method to generate hard instances by applying a padding-and-permuting transformation to a fingerprinting code. We illustrate the applicability of this method by providing new lower bounds in various settings: 1. A tight lower bound for DP averaging in the low-accuracy regime, which in particular implies a new lower bound for the private 1-cluster problem introduced by Nissim, Stemmer, and Vadhan (PODS 2016). 2. A lower bound on the additive error of DP algorithms for approximate k-means clustering, as a function of the multiplicative error, which is tight for a constant multiplication error. 3. A lower bound for estimating the top singular vector of a matrix under DP in low-accuracy regimes, which is a special case of DP subspace estimation studied by Singhal and Steinke (NeurIPS 2021). Our main technique is to apply a padding-and-permuting transformation to a fingerprinting code. However, rather than proving our results using a black-box access to an existing fingerprinting code (e.g., Tardos' code), we develop a new fingerprinting lemma that is stronger than those of Dwork et al. (FOCS 2015) and Bun et al. (SODA 2017), and prove our lower bounds directly from the lemma. Our lemma, in particular, gives a simpler fingerprinting code construction with optimal rate (up to polylogarithmic factors) that is of independent interest."}}
{"id": "3FdMh6PZy8A", "cdate": 1672531200000, "mdate": 1690316152038, "content": {"title": "Adaptive Data Analysis in a Balanced Adversarial Model", "abstract": "In adaptive data analysis, a mechanism gets $n$ i.i.d. samples from an unknown distribution $D$, and is required to provide accurate estimations to a sequence of adaptively chosen statistical queries with respect to $D$. Hardt and Ullman (FOCS 2014) and Steinke and Ullman (COLT 2015) showed that in general, it is computationally hard to answer more than $\\Theta(n^2)$ adaptive queries, assuming the existence of one-way functions. However, these negative results strongly rely on an adversarial model that significantly advantages the adversarial analyst over the mechanism, as the analyst, who chooses the adaptive queries, also chooses the underlying distribution $D$. This imbalance raises questions with respect to the applicability of the obtained hardness results -- an analyst who has complete knowledge of the underlying distribution $D$ would have little need, if at all, to issue statistical queries to a mechanism which only holds a finite number of samples from $D$. We consider more restricted adversaries, called \\emph{balanced}, where each such adversary consists of two separated algorithms: The \\emph{sampler} who is the entity that chooses the distribution and provides the samples to the mechanism, and the \\emph{analyst} who chooses the adaptive queries, but does not have a prior knowledge of the underlying distribution. We improve the quality of previous lower bounds by revisiting them using an efficient \\emph{balanced} adversary, under standard public-key cryptography assumptions. We show that these stronger hardness assumptions are unavoidable in the sense that any computationally bounded \\emph{balanced} adversary that has the structure of all known attacks, implies the existence of public-key cryptography."}}
{"id": "Wib8eLRF77", "cdate": 1640995200000, "mdate": 1681235577889, "content": {"title": "On the complexity of two-party differential privacy", "abstract": ""}}
{"id": "Qvckv4JOeB", "cdate": 1640995200000, "mdate": 1681235577890, "content": {"title": "FriendlyCore: Practical Differentially Private Aggregation", "abstract": ""}}
{"id": "7Z4xZobnci", "cdate": 1640995200000, "mdate": 1681235577891, "content": {"title": "Highly Efficient OT-Based Multiplication Protocols", "abstract": ""}}
{"id": "0xtLE_i0eGr", "cdate": 1609459200000, "mdate": 1681235577888, "content": {"title": "Differentially-Private Clustering of Easy Instances", "abstract": ""}}
{"id": "AXV16trZH6E", "cdate": 1577836800000, "mdate": null, "content": {"title": "Private Learning of Halfspaces: Simplifying the Construction and Reducing the Sample Complexity", "abstract": "We present a differentially private learner for halfspaces over a finite grid $G$ in $\\R^d$ with sample complexity $\\approx d^{2.5}\\cdot 2^{\\log^*|G|}$, which improves the state-of-the-art result of [Beimel et al., COLT 2019] by a $d^2$ factor. The building block for our learner is a new differentially private algorithm for approximately solving the linear feasibility problem: Given a feasible collection of $m$ linear constraints of the form $Ax\\geq b$, the task is to {\\em privately} identify a solution $x$ that satisfies {\\em most} of the constraints. Our algorithm is iterative, where each iteration determines the next coordinate of the constructed solution $x$."}}
{"id": "3a54itlzIN", "cdate": 1577836800000, "mdate": 1681235577889, "content": {"title": "A Tight Parallel Repetition Theorem for Partially Simulatable Interactive Arguments via Smooth KL-Divergence", "abstract": ""}}
{"id": "qIbxyUH3C3", "cdate": 1514764800000, "mdate": 1681235870366, "content": {"title": "It Takes Two to #MeToo - Using Enclaves to Build Autonomous Trusted Systems", "abstract": ""}}
{"id": "ATtd5ZPuDTI", "cdate": 1514764800000, "mdate": 1681235870367, "content": {"title": "Securing the Storage Data Path with SGX Enclaves", "abstract": ""}}
