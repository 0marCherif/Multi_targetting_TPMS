{"id": "-rN5dfR5aa", "cdate": 1672531200000, "mdate": 1699646899900, "content": {"title": "Real-time Concealed Weapon Detection on 3D Radar Images for Walk-through Screening System", "abstract": "This paper presents a framework for real-time concealed weapon detection (CWD) on 3D radar images for walk-through screening systems. The walk-through screening system aims to ensure security in crowded areas by performing CWD on walking persons, hence it requires an accurate and real-time detection approach. To ensure accuracy, a weapon needs to be detected irrespective of its 3D orientation, thus we use the 3D radar images as detection input. For achieving real-time, we reformulate classic U-Net based segmentation networks to perform 3D detection tasks. Our 3D segmentation network predicts peak-shaped probability map, instead of voxel-wise masks, to enable position inference by elementary peak detection operation on the predicted map. In the peak-shaped probability map, the peak marks the weapon\u2019s position. So, weapon detection task translates to peak detection on the probability map. A Gaussian function is used to model weapons in the probability map. We experimentally validate our approach on realistic 3D radar images obtained from a walk-through weapon screening system prototype. Extensive ablation studies verify the effectiveness of our proposed approach over existing conventional approaches. The experimental results demonstrate that our proposed approach can perform accurate and real-time CWD, thus making it suitable for practical applications of walk-through screening."}}
{"id": "sN_ZXcC7SM4", "cdate": 1609459200000, "mdate": null, "content": {"title": "A Multi-Scale Conditional Deep Model for Tumor Cell Ratio Counting", "abstract": "We propose a method to accurately obtain the ratio of tumor cells over an entire histological slide. We use deep fully convolutional neural network models trained to detect and classify cells on images of H&E-stained tissue sections. Pathologists' labels consisting of exhaustive nuclei locations and tumor regions were used to trained the model in a supervised fashion. We show that combining two models, each working at a different magnification allows the system to capture both cell-level details and surrounding context to enable successful detection and classification of cells as either tumor-cell or normal-cell. Indeed, by conditioning the classification of a single cell on a multi-scale context information, our models mimic the process used by pathologists who assess cell neoplasticity and tumor extent at different microscope magnifications. The ratio of tumor cells can then be readily obtained by counting the number of cells in each class. To analyze an entire slide, we split it into multiple tiles that can be processed in parallel. The overall tumor cell ratio can then be aggregated. We perform experiments on a dataset of 100 slides with lung tumor specimens from both resection and tissue micro-array (TMA). We train fully-convolutional models using heavy data augmentation and batch normalization. On an unseen test set, we obtain an average mean absolute error on predicting the tumor cell ratio of less than 6%, which is significantly better than the human average of 20% and is key in properly selecting tissue samples for recent genetic panel tests geared at prescribing targeted cancer drugs. We perform ablation studies to show the importance of training two models at different magnifications and to justify the choice of some parameters, such as the size of the receptive field."}}
{"id": "VXOdEVSYIr", "cdate": 1609459200000, "mdate": 1699646899774, "content": {"title": "Automatic Fine-Grained Localization of Utility Pole Landmarks on Distributed Acoustic Sensing Traces Based on Bilinear Resnets", "abstract": "In distributed acoustic sensing (DAS) on aerial fiber-optic cables, utility pole localization is a prerequisite for any subsequent event detection. Currently, localizing the utility poles on DAS traces relies on human experts who manually label the poles\u2019 locations by examining DAS signal patterns generated in response to hammer knocks on the poles. This process is inefficient, error-prone and expensive, thus impractical and non-scalable for industrial applications. In this paper, we propose two machine learning approaches to automate this procedure for large-scale implementation. In particular, we investigate both unsupervised and supervised methods for fine-grained pole localization. Our methods are tested on two real-world datasets from field trials, and demonstrate successful estimation of pole locations at the same level of accuracy as human experts and strong robustness to label noises."}}
{"id": "vqDSqa8Vnv", "cdate": 1598972777975, "mdate": null, "content": {"title": "Automated gastric cancer diagnosis on H&E-stained sections; training a classifier on a large scale with multiple instance machine learning", "abstract": "We present a system that detects cancer on slides of gastric tissue sections stained with hematoxylin and eosin (H&E). At its heart is a classifier trained using the semi-supervised multi-instance learning framework (MIL) where each tissue is represented by a set of regions-of-interest (ROI) and a single label. Such labels are readily obtained because pathologists diagnose each tissue independently as part of the normal clinical workflow. From a large dataset of over 26K gastric tissue sections from over 12K patients obtained from a clinical load spanning several months, we train a MIL classifier on a patient-level partition of the dataset (2/3 of the patients) and obtain a very high performance of 96% (AUC), tested on the remaining 1/3 never-seen before patients (over 8K tissues). We show this level of performance to match the more costly supervised approach where individual ROIs need to be labeled manually. The large amount of data used to train this system gives us confidence in its robustness and that it can be safely used in a clinical setting. We demonstrate how it can improve the clinical workflow when used for pre-screening or quality control. For pre-screening, the system can diagnose 47% of the tissues with a very low likelihood (< 1%) of missing cancers, thus halving the clinicians' caseload. For quality control, compared to random rechecking of 33% of the cases, the system achieves a three-fold increase in the likelihood of catching cancers missed by pathologists. The system is currently in regular use at independent pathology labs in Japan where it is used to double-check clinician's diagnoses. At the end of 2012 it will have analyzed over 80,000 slides of gastric and colorectal samples (200,000 tissues)."}}
{"id": "GVxPJplFo_", "cdate": 1598972547938, "mdate": null, "content": {"title": "Grading nuclear pleomorphism on histological micrographs", "abstract": "A mainstay in cancer diagnostics is the classification or grading of cell nuclei based on their appearance. While the analysis of cytological samples has been automated successfully for a long time, the complexity of histological tissue samples has prevented a reliable classification with machine vision techniques. We approach this complex problem in multiple stages, analyzing first image quality, staining quality, and tissue appearance, before segmenting nuclei and finally classifying or grading areas of tissue. The key step is the training of a classifier to judge the nuclei segmentation quality. Using active learning techniques, we train this classifier to identify problems in the image as well as weaknesses of the image analysis tools. This way we obtain robust nuclear segmentation allowing precise measurements of features that can be used safely for classification. We validate our findings on several hundred cases of breast cancer, demonstrating that automatic pleomorphism grading is possible with high accuracy. This technique can provide a stable and objective basis for what has been a subjective process that suffers from low reproducibility."}}
{"id": "nJQcBiUGmjL", "cdate": 1598972397979, "mdate": null, "content": {"title": "Classification of mitotic figures with convolutional neural networks and seeded blob features", "abstract": "Background:\nThe mitotic figure recognition contest at the 2012 International Conference on Pattern Recognition (ICPR) challenges a system to identify all mitotic figures in a region of interest of hematoxylin and eosin stained tissue, using each of three scanners (Aperio, Hamamatsu, and multispectral).\n\nMethods:\nOur approach combines manually designed nuclear features with the learned features extracted by convolutional neural networks (CNN). The nuclear features capture color, texture, and shape information of segmented regions around a nucleus. The use of a CNN handles the variety of appearances of mitotic figures and decreases sensitivity to the manually crafted features and thresholds.\n\nResults:\nOn the test set provided by the contest, the trained system achieves F1 scores up to 0.659 on color scanners and 0.589 on multispectral scanner."}}
{"id": "r99pgby6rYC", "cdate": 1356998400000, "mdate": null, "content": {"title": "Automatic classification of hepatocellular carcinoma images based on nuclear and structural features", "abstract": "Diagnosis of hepatocellular carcinoma (HCC) on the basis of digital images is a challenging problem because, unlike gastrointestinal carcinoma, strong structural and morphological features are limited and sometimes absent from HCC images. In this study, we describe the classification of HCC images using statistical distributions of features obtained from image analysis of cell nuclei and hepatic trabeculae. Images of 130 hematoxylin-eosin (HE) stained histologic slides were captured at 20X by a slide scanner (Nanozoomer, Hamamatsu Photonics, Japan) and 1112 regions of interest (ROI) images were extracted for classification (551 negatives and 561 positives, including 113 well-differentiated positives). For a single nucleus, the following features were computed: area, perimeter, circularity, ellipticity, long and short axes of elliptic fit, contour complexity and gray level cooccurrence matrix (GLCM) texture features (angular second moment, contrast, homogeneity and entropy). In addition, distributions of nuclear density and hepatic trabecula thickness within an ROI were also extracted. To represent an ROI, statistical distributions (mean, standard deviation and percentiles) of these features were used. In total, 78 features were extracted for each ROI and a support vector machine (SVM) was trained to classify negative and positive ROIs. Experimental results using 5-fold cross validation show 90% sensitivity for an 87.8% specificity. The use of statistical distributions over a relatively large area makes the HCC classifier robust to occasional failures in the extraction of nuclear or hepatic trabecula features, thus providing stability to the system."}}
{"id": "Tc0iiF5vnPC", "cdate": 1356998400000, "mdate": null, "content": {"title": "Dawn of the digital diagnosis assisting system, can it open a new age for pathology?", "abstract": "Digital pathology is developing based on the improvement and popularization of WSI (whole slide imaging) scanners. WSI scanners are widely expected to be used as the next generation microscope for diagnosis; however, their usage is currently mostly limited to education and archiving. Indeed, there are still many hindrances in using WSI scanners for diagnosis (not research purpose), two of the main reasons being the perceived high cost and small gain in productivity obtained by switching from the microscope to a WSI system and the lack of WSI standardization. We believe that a key factor for advancing digital pathology is the creation of computer assisted diagnosis systems (CAD). Such systems require high-resolution digitization of slides and provide a clear added value to the often costly conversion to WSI. We (NEC Corporation) are creating a CAD system, named e-<i>Pathologist</i> &#174;. This system is currently used at independent pathology labs for quality control (QC/QA), double-checking pathologists diagnosis and preventing missed cancers. At the end of 2012, about 80,000 slides, 200,000 tissues of gastric and colorectal samples will have been analyzed by e-<i>Pathologist</i> &#174;. Through the development of e-<i>Pathologist</i> &#174;, it has become clear that a computer program should be inspired by the pathologist diagnosis process, yet it should not be a mere copy or simulation of it. Indeed pathologists often approach the diagnosis of slides in a \"holistic\" manner, examining them at various magnifications, panning and zooming in a seemingly haphazard way that they often have a hard time to precisely describe. Hence there has been no clear recipe emerging from numerous interviews with pathologists on how to exactly computer code a diagnosis expert system. Instead, we focused on extracting a small set of histopathological features that were consistently indicated as important by the pathologists and then let the computer figure out how to interpret in a quantitative way the presence or absence of these features over the entire slide. Using the overall pathologists diagnosis (into a class of disease), we train the computer system using advanced machine learning techniques to predict the disease based on the extracted features. By considering the diagnosis of several expert pathologists during the training phase, we insure that the machine is learning a \"gold standard\" that will be applied consistently and objectively for all subsequent diagnosis, making them more predictable and reliable. Considering the future of digital pathology, it is essential for a CAD system to produce effective and accurate clinical data. To this effect, there remain many hurdles, including standardization as well as more research into seeking clinical evidences from \"computer-friendly\" objective measurements of histological images. Currently the most commonly used staining method is H&#38;E (Hematoxylin and Eosin), but it is extremely difficult to standardize the H&#38;E staining process. Current pathology criteria, category, definitions, and thresholds are all on based pathologists subjective observations. Digital pathology is an emerging field and researchers should bear responsibility not only for developing new algorithms, but also for understanding the meaning of measured quantitative data."}}
{"id": "-7L2CNJjoRb", "cdate": 1356998400000, "mdate": null, "content": {"title": "Automated gastric cancer diagnosis on H&E-stained sections; ltraining a classifier on a large scale with multiple instance machine learning", "abstract": "We present a system that detects cancer on slides of gastric tissue sections stained with hematoxylin and eosin (H&amp;E). At its heart is a classifier trained using the semi-supervised multi-instance learning framework (MIL) where each tissue is represented by a set of regions-of-interest (ROI) and a single label. Such labels are readily obtained because pathologists diagnose each tissue independently as part of the normal clinical workflow. From a large dataset of over 26K gastric tissue sections from over 12K patients obtained from a clinical load spanning several months, we train a MIL classifier on a patient-level partition of the dataset (2/3 of the patients) and obtain a very high performance of 96% (AUC), tested on the remaining 1/3 never-seen before patients (over 8K tissues). We show this level of performance to match the more costly supervised approach where individual ROIs need to be labeled manually. The large amount of data used to train this system gives us confidence in its robustness and that it can be safely used in a clinical setting. We demonstrate how it can improve the clinical workflow when used for pre-screening or quality control. For pre-screening, the system can diagnose 47% of the tissues with a very low likelihood (&lt; 1%) of missing cancers, thus halving the clinicians' caseload. For quality control, compared to random rechecking of 33% of the cases, the system achieves a three-fold increase in the likelihood of catching cancers missed by pathologists. The system is currently in regular use at independent pathology labs in Japan where it is used to double-check clinician's diagnoses. At the end of 2012 it will have analyzed over 80,000 slides of gastric and colorectal samples (200,000 tissues)."}}
{"id": "b-c8juSclx", "cdate": 1293840000000, "mdate": null, "content": {"title": "Dynamic Radial Contour Extraction by Splitting Homogeneous Areas", "abstract": "We introduce a dynamic programming based algorithm to extract a radial contour around an input point. Unlike many approaches, it encloses a region using feature homogeneity, without relying on edge maps. The algorithm operates in linear time in the number of pixels to be analyzed. Multiple initializations are unnecessary, and no fixed smoothness/local\u2013optimality tradeoff needs to be tuned. We show that this method is beneficial in extracting nuclei from color micrographs of hematoxylin and eosin stained biopsy slides."}}
