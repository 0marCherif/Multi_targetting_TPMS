{"id": "kQtxXZsFtr", "cdate": 1680191544289, "mdate": null, "content": {"title": "Robust, Accurate Stochastic Optimization for Variational Inference", "abstract": "We consider the problem of fitting variational posterior approximations using\nstochastic optimization methods. The performance of these approximations de-\npends on (1) how well the variational family matches the true posterior distribution,\n(2) the choice of divergence, and (3) the optimization of the variational objective.\nWe show that even in the best-case scenario when the exact posterior belongs to\nthe assumed variational family, common stochastic optimization methods lead to\npoor variational approximations if the problem dimension is moderately large. We\nalso demonstrate that these methods are not robust across diverse model types.\nMotivated by these findings, we develop a more robust and accurate stochastic\noptimization framework by viewing the underlying optimization algorithm as pro-\nducing a Markov chain. Our approach is theoretically motivated and includes a\ndiagnostic for convergence and a novel stopping rule, both of which are robust to\nnoisy evaluations of the objective function. We show empirically that the proposed\nframework works well on a diverse set of models: it can automatically detect\nstochastic optimization failure or inaccurate variational approximation."}}
{"id": "kuFGLDlyIb", "cdate": 1676827087123, "mdate": null, "content": {"title": "On the Role of Model Uncertainties in Bayesian Optimisation", "abstract": "Bayesian Optimization (BO) is a popular method for black-box optimization, which relies on uncertainty as part of its decision-making process when deciding which experiment to perform next. However, not much work has addressed the effect of uncertainty on the performance of the BO algorithm and to what extent calibrated uncertainties improve the ability to find the global optimum. In this work, we provide an extensive study of the relationship between the BO performance (regret) and uncertainty calibration for popular surrogate models and acquisition functions, and compare them across both synthetic and real-world experiments. Our results show that Gaussian Processes, and more surprisingly, Deep Ensembles are strong surrogate models. Our results further show a positive association between calibration error and regret, but interestingly, this association disappears  when we control for the type of surrogate model in the analysis. We also study the effect of recalibration and demonstrate that it generally does not lead to improved regret. Finally, we provide theoretical justification for why uncertainty calibration might be difficult to combine with BO due to the small sample sizes commonly used."}}
{"id": "23WtTkwyzLJ", "cdate": 1622637630599, "mdate": null, "content": {"title": "Challenges for BBVI with Normalizing Flows", "abstract": "Current black-box variational inference (BBVI) methods require the user to make numerous design choices---such as the selection of variational objective and approximating family---yet there is little principled guidance on how to do so. We develop a conceptual framework and set of experimental tools to understand the effects of these choices, which we leverage to propose best practices for maximizing posterior approximation accuracy. Our approach is based on studying the pre-asymptotic tail behavior of the density ratios between the joint distribution and the variational approximation, then exploiting insights and tools from the importance sampling literature. We focus on normalizing flow models and give recommendations on how to be used(and diagnostics) in BBVI, though we are not limited to them."}}
{"id": "_A4-JP8d_f", "cdate": 1621629760547, "mdate": null, "content": {"title": "Challenges and Opportunities in High Dimensional Variational Inference", "abstract": "Current black-box variational inference (BBVI) methods require the user to make numerous design choices \u2013 such as the selection of variational objective and approximating family \u2013 yet there is little principled guidance on how to do so. We develop a conceptual framework and set of experimental tools to understand the effects of these choices, which we leverage to propose best practices for maximizing posterior approximation accuracy. Our approach is based on studying the pre-asymptotic tail behavior of the density ratios between the joint distribution and the variational approximation, then exploiting insights and tools from the importance sampling literature. Our framework and supporting experiments help to distinguish between the behavior of BBVI methods for approximating low-dimensional versus moderate-to-high-dimensional posteriors. In the latter case, we show that mass-covering variational objectives are difficult to optimize and do not improve accuracy, but flexible variational families can improve accuracy and the effectiveness of importance sampling \u2013 at the cost of additional optimization challenges. Therefore, for moderate-to-high-dimensional posteriors we recommend using the (mode-seeking) exclusive KL divergence since it is the easiest to optimize, and improving the variational family or using model parameter transformations to make the posterior and optimal variational approximation more similar. On the other hand, in low-dimensional settings, we show that heavy-tailed variational families and mass-covering divergences are effective and can increase the chances that the approximation can be improved by importance sampling. "}}
{"id": "5Tyfu8S1Kc1", "cdate": 1609459200000, "mdate": null, "content": {"title": "Challenges and Opportunities in High-dimensional Variational Inference", "abstract": "Current black-box variational inference (BBVI) methods require the user to make numerous design choices -- such as the selection of variational objective and approximating family -- yet there is little principled guidance on how to do so. We develop a conceptual framework and set of experimental tools to understand the effects of these choices, which we leverage to propose best practices for maximizing posterior approximation accuracy. Our approach is based on studying the pre-asymptotic tail behavior of the density ratios between the joint distribution and the variational approximation, then exploiting insights and tools from the importance sampling literature. Our framework and supporting experiments help to distinguish between the behavior of BBVI methods for approximating low-dimensional versus moderate-to-high-dimensional posteriors. In the latter case, we show that mass-covering variational objectives are difficult to optimize and do not improve accuracy, but flexible variational families can improve accuracy and the effectiveness of importance sampling -- at the cost of additional optimization challenges. Therefore, for moderate-to-high-dimensional posteriors we recommend using the (mode-seeking) exclusive KL divergence since it is the easiest to optimize, and improving the variational family or using model parameter transformations to make the posterior and optimal variational approximation more similar. On the other hand, in low-dimensional settings, we show that heavy-tailed variational families and mass-covering divergences are effective and can increase the chances that the approximation can be improved by importance sampling."}}
{"id": "h6v7H2vPLr-", "cdate": 1577836800000, "mdate": null, "content": {"title": "Robust, Accurate Stochastic Optimization for Variational Inference", "abstract": "We consider the problem of fitting variational posterior approximations using stochastic optimization methods. The performance of these approximations depends on (1) how well the variational family matches the true posterior distribution,(2) the choice of divergence, and (3) the optimization of the variational objective. We show that even in the best-case scenario when the exact posterior belongs to the assumed variational family, common stochastic optimization methods lead to poor variational approximations if the problem dimension is moderately large. We also demonstrate that these methods are not robust across diverse model types. Motivated by these findings, we develop a more robust and accurate stochastic optimization framework by viewing the underlying optimization algorithm as producing a Markov chain. Our approach is theoretically motivated and includes a diagnostic for convergence and a novel stopping rule, both of which are robust to noisy evaluations of the objective function. We show empirically that the proposed framework works well on a diverse set of models: it can automatically detect stochastic optimization failure or inaccurate variational approximation"}}
{"id": "aLoMQ6obgY", "cdate": 1577836800000, "mdate": null, "content": {"title": "Scalable Gaussian Process for Extreme Classification", "abstract": "We address the limitations of Gaussian processes for multiclass classification in the setting where both the number of classes and the number of observations is very large. We propose a scalable approximate inference framework by combining the inducing points method with variational approximations of the likelihood that have been recently proposed in the literature. This leads to a tractable lower bound on the marginal likelihood that decomposes into a sum over both data points and class labels, and hence, is amenable to doubly stochastic optimization. To overcome memory issues when dealing with large datasets, we resort to amortized inference, which coupled with subsampling over classes reduces the computational and the memory footprint without a significant loss in performance. We demonstrate empirically that the proposed algorithm leads to superior performance in terms of test accuracy, and improved detection of tail labels."}}
{"id": "JGxwbsgT93", "cdate": 1577836800000, "mdate": null, "content": {"title": "Preferential Batch Bayesian Optimization", "abstract": "Most research in Bayesian optimization (BO) has focused on \\emph{direct feedback} scenarios, where one has access to exact values of some expensive-to-evaluate objective. This direction has been mainly driven by the use of BO in machine learning hyper-parameter configuration problems. However, in domains such as modelling human preferences, A/B tests, or recommender systems, there is a need for methods that can replace direct feedback with \\emph{preferential feedback}, obtained via rankings or pairwise comparisons. In this work, we present preferential batch Bayesian optimization (PBBO), a new framework that allows finding the optimum of a latent function of interest, given any type of parallel preferential feedback for a group of two or more points. We do so by using a Gaussian process model with a likelihood specially designed to enable parallel and efficient data collection mechanisms, which are key in modern machine learning. We show how the acquisitions developed under this framework generalize and augment previous approaches in Bayesian optimization, expanding the use of these techniques to a wider range of domains. An extensive simulation study shows the benefits of this approach, both with simulated functions and four real data sets."}}
{"id": "FwnisRnw4Wr", "cdate": 1577836800000, "mdate": null, "content": {"title": "Leave-One-Out Cross-Validation for Bayesian Model Comparison in Large Data", "abstract": "Recently, new methods for model assessment, based on subsampling and posterior approximations, have been proposed for scaling leave-one-out cross-validation (LOO-CV) to large datasets. Although the..."}}
{"id": "6ZXf5nKd5oi", "cdate": 1577836800000, "mdate": null, "content": {"title": "State Space Expectation Propagation: Efficient Inference Schemes for Temporal Gaussian Processes", "abstract": "We formulate approximate Bayesian inference in non-conjugate temporal and spatio-temporal Gaussian process models as a simple parameter update rule applied during Kalman smoothing. This viewpoint e..."}}
