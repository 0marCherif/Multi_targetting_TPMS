{"id": "mZvDZPaKR_d", "cdate": 1668990733902, "mdate": 1668990733902, "content": {"title": "Semantic Scene Completion via Integrating Instances and Scene In-the-Loop", "abstract": "Semantic Scene Completion aims at reconstructing a\ncomplete 3D scene with precise voxel-wise semantics from a\nsingle-view depth or RGBD image. It is a crucial but challenging\nproblem for indoor scene understanding. In this\nwork, we present a novel framework named Scene-Instance-\nScene Network (SISNet), which takes advantages of both instance\nand scene level semantic information. Our method\nis capable of inferring fine-grained shape details as well as\nnearby objects whose semantic categories are easily mixedup.\nThe key insight is that we decouple the instances from\na coarsely completed semantic scene instead of a raw input\nimage to guide the reconstruction of instances and the overall\nscene. SISNet conducts iterative scene-to-instance (SI)\nand instance-to-scene (IS) semantic completion. Specifically,\nthe SI is able to encode objects\u2019 surrounding context\nfor effectively decoupling instances from the scene and each\ninstance could be voxelized into higher resolution to capture\nfiner details. With IS, fine-grained instance information\ncan be integrated back into the 3D scene and thus leads to\nmore accurate semantic scene completion. Utilizing such\nan iterative mechanism, the scene and instance completion\nbenefits each other to achieve higher completion accuracy\nExtensively experiments show that our proposed method\nconsistently outperforms state-of-the-art methods on both\nreal NYU, NYUCAD and synthetic SUNCG-RGBD datasets."}}
{"id": "wdi8e_aa3pV", "cdate": 1668682206351, "mdate": null, "content": {"title": "learning a structured latent space for unsupervised point cloud completion", "abstract": "Unsupervised point cloud completion aims at estimating\nthe corresponding complete point cloud of a partial point\ncloud in an unpaired manner. It is a crucial but challenging\nproblem since there is no paired partial-complete supervision that can be exploited directly. In this work, we propose a novel framework, which learns a unified and structured latent space that encoding both partial and complete\npoint clouds. Specifically, we map a series of related partial point clouds into multiple complete shape and occlusion code pairs and fuse the codes to obtain their representations in the unified latent space. To enforce the learning of such a structured latent space, the proposed method\nadopts a series of constraints including structured ranking\nregularization, latent code swapping constraint, and distribution supervision on the related partial point clouds.\nBy establishing such a unified and structured latent space,\nbetter partial-complete geometry consistency and shape\ncompletion accuracy can be achieved. Extensive experiments show that our proposed method consistently outperforms state-of-the-art unsupervised methods on both synthetic ShapeNet and real-world KITTI, ScanNet, and Matterport3D datasets."}}
{"id": "fv2Bzpsa3Ub", "cdate": 1640995200000, "mdate": 1648981400261, "content": {"title": "Potential escalator-related injury identification and prevention based on multi-module integrated system for public health", "abstract": "Escalator-related injuries threaten public health with the widespread use of escalators. The existing studies tend to focus on after-the-fact statistics, reflecting on the original design and use of defects to reduce the impact of escalator-related injuries, but few attention has been paid to ongoing and impending injuries. In this study, a multi-module escalator safety monitoring system based on computer vision is designed and proposed to simultaneously monitor and deal with three major injury triggers, including losing balance, not holding on to handrails and carrying large items. The escalator identification module is utilized to determine the escalator region, namely the region of interest. The passenger monitoring module is leveraged to estimate the passengers\u2019 pose to recognize unsafe behaviors on the escalator. The dangerous object detection module detects large items that may enter the escalator and raises alarms. The processing results of the above three modules are summarized in the safety assessment module as the basis for the intelligent decision of the system. The experimental results demonstrate that the proposed system has good performance and great application potential."}}
{"id": "r8Ag_R49Wj-", "cdate": 1609459200000, "mdate": 1648981400267, "content": {"title": "Semantic Scene Completion via Integrating Instances and Scene In-the-Loop", "abstract": "Semantic Scene Completion aims at reconstructing a complete 3D scene with precise voxel-wise semantics from a single-view depth or RGBD image. It is a crucial but challenging problem for indoor scene understanding. In this work, we present a novel framework named Scene-Instance-Scene Network (SISNet), which takes advantages of both instance and scene level semantic information. Our method is capable of inferring fine-grained shape details as well as nearby objects whose semantic categories are easily mixedup. The key insight is that we decouple the instances from a coarsely completed semantic scene instead of a raw input image to guide the reconstruction of instances and the overall scene. SISNet conducts iterative scene-to-instance (SI) and instance-to-scene (IS) semantic completion. Specifically, the SI is able to encode objects' surrounding context for effectively decoupling instances from the scene and each instance could be voxelized into higher resolution to capture finer details. With IS, fine-grained instance information can be integrated back into the 3D scene and thus leads to more accurate semantic scene completion. Utilizing such an iterative mechanism, the scene and instance completion benefits each other to achieve higher completion accuracy. Extensively experiments show that our proposed method consistently outperforms state-of-the-art methods on both real NYU, NYUCAD and synthetic SUNCG-RGBD datasets. The code and the supplementary material will be available at https://github.com/yjcaimeow/SISNet."}}
{"id": "QAMjwGiU9pk", "cdate": 1607954946229, "mdate": null, "content": {"title": "Using Enhanced Gaussian Cross-Entropy in Imitation Learning to Digging the First Diamond in Minecraft", "abstract": "Although state-ofthe-art reinforcement learning (RL) systems has led to breakthroughs in many difficult tasks, the sample inefficiency of standard reinforcement learning methods still precludes their application to more extremely complex tasks. Such limitation will make many reinforcement learning systems cannot be applied to real-world problem, in which environment samples are expensive. To solve this problem, MineRL (13) provide an ideal develop environment to facilitate the research that leveraging fewer human demonstrations with more efficient reinforcement learning systems. Based on the MineRL environmnet, we proposed an enhanced Gaussian cross entropy (EGCE) loss for imitation learnning problems to achieve ideal performance. In the ObtainDiamond task, our EGCE achieves about 7.7% improvement than a strong baseline imitation learning pipeline. The demo video is available at here."}}
{"id": "6i9GpTeyec", "cdate": 1577836800000, "mdate": 1648981400271, "content": {"title": "Monocular 3D Object Detection with Decoupled Structured Polygon Estimation and Height-Guided Depth Estimation", "abstract": "Monocular 3D object detection task aims to predict the 3D bounding boxes of objects based on monocular RGB images. Since the location recovery in 3D space is quite difficult on account of absence of depth information, this paper proposes a novel unified framework which decomposes the detection problem into a structured polygon prediction task and a depth recovery task. Different from the widely studied 2D bounding boxes, the proposed novel structured polygon in the 2D image consists of several projected surfaces of the target object. Compared to the widely-used 3D bounding box proposals, it is shown to be a better representation for 3D detection. In order to inversely project the predicted 2D structured polygon to a cuboid in the 3D physical world, the following depth recovery task uses the object height prior to complete the inverse projection transformation with the given camera projection matrix. Moreover, a fine-grained 3D box refinement scheme is proposed to further rectify the 3D detection results. Experiments are conducted on the challenging KITTI benchmark, in which our method achieves state-of-the-art detection accuracy."}}
{"id": "sDGKDjHcQJy", "cdate": 1546300800000, "mdate": 1648981400471, "content": {"title": "A new approach to oil spill detection that combines deep learning with unmanned aerial vehicles", "abstract": "Highlights \u2022 A new approach, combining computer vision with UAV, is proposed to detect oil spills. \u2022 This approach is pioneering, and the results are state-of-the art in practice. \u2022 The integration of deep learning and traditional algorithms including Otsu & MSER. \u2022 The location and severity of oil spills can be reported at the same time. \u2022 The factors that influence the performance of our method are analyzed numerically. Abstract This study presents a novel approach to automatic oil spill detection, using unmanned aerial vehicle (UAV) images to realize intelligent control in oil production. Despite considerable effort, oil spills still cannot be detected automatically and effectively due to the complexity of the real production environment, which forces oil enterprises to manually inspect facilities and detect oil spills. To solve the problem, we propose an approach consisting of UAVs, deep learning and traditional algorithms\u2014an approach which divides the oil spill detection task into three independent sub-tasks. First, we constructed a model based on the deep convolutional neural network, which can quickly detect the suspected oil spill area in images to ensure there are no omissions. Second, to remove other obstacles in the images, we adjusted the Otsu algorithm to filter the detection results, which improves precision while not affecting the recall rate. Third, the Maximally Stable Extremal Regions algorithm was used to obtain the detail polygon region from the detection box, thus automatically evaluating the severity of the oil spill. Experiments showed that our method could solve problems effectively, reducing the cost of oil spill detection by 57.2% when compared with the traditional manual inspection process."}}
