{"id": "zJ-c9RbKULz", "cdate": 1618513296754, "mdate": null, "content": {"title": "Learning Overcomplete, Low Coherence Dictionaries withLinear Inference", "abstract": "Finding overcomplete latent representations of data has applications in data analysis, signal processing, machine learning, theoretical neuroscience and many other fields.  In an over-complete  representation,  the  number  of  latent  features  exceeds  the  data  dimensionality, which is useful when the data is undersampled by the measurements (compressed sensing or information bottlenecks in neural systems) or composed from multiple complete sets of linear features,  each spanning the data space.  Independent Components Analysis (ICA)is a linear technique for learning sparse latent representations, which typically has a lower computational cost than sparse coding, a linear generative model which requires an itera-tive, nonlinear inference step.  While well suited for finding complete representations, we show that overcompleteness poses a challenge to existing ICA algorithms.  Specifically, the coherence control used in existing ICA and other dictionary learning algorithms, necessary to prevent the formation of duplicate dictionary features, is ill-suited in the overcomplete case.  We show that in the overcomplete case, several existing ICA algorithms have undesirable global minima that maximize coherence.  We provide a theoretical explanation of these failures and, based on the theory, propose improved coherence control costs for over-complete ICA algorithms.  Further, by comparing ICA algorithms to the computationally more expensive sparse coding on synthetic data, we show that the limited applicability of overcomplete, linear inference can be extended with the proposed cost functions.  Finally,when trained on natural images, we show that the coherence control biases the explorationof  the  data  manifold,  sometimes  yielding  suboptimal,  coherent  solutions.   All  told,  thisstudy contributes new insights into and methods for coherence control for linear ICA, someof which are applicable to many other nonlinear models."}}
{"id": "u6fswXo9zc", "cdate": 1483228800000, "mdate": null, "content": {"title": "Sparse coding of ECoG signals identifies interpretable components for speech control in human sensorimotor cortex", "abstract": "The concept of sparsity has proven useful to understanding elementary neural computations in sensory systems. However, the role of sparsity in motor regions is poorly understood. Here, we investigated the functional properties of sparse structure in neural activity collected with high-density electrocorticography (ECoG) from speech sensorimotor cortex (vSMC) in neurosurgical patients. Using independent components analysis (ICA), we found individual components corresponding to individual major oral articulators (i.e., Coronal Tongue, Dorsal Tongue, Lips), which were selectively activated during utterances that engaged that articulator on single trials. Some of the components corresponded to spatially sparse activations. Components with similar properties were also extracted using convolutional sparse coding (CSC), and required less data pre-processing. Finally, individual utterances could be accurately decoded from vSMC ECoG recordings using linear classifiers trained on the high-dimensional sparse codes generated by CSC. Together, these results suggest that sparse coding may be an important framework and tool for understanding sensory-motor activity generating complex behaviors, and may be useful for brain-machine interfaces."}}
{"id": "jitGXB7lgdr", "cdate": 1483228800000, "mdate": null, "content": {"title": "Union of Intersections (UoI) for Interpretable Data Driven Discovery and Prediction", "abstract": "The increasing size and complexity of scientific data could dramatically enhance discovery and prediction for basic scientific applications, e.g., neuroscience, genetics, systems biology, etc. Realizing this potential, however, requires novel statistical analysis methods that are both interpretable and predictive. We introduce the Union of Intersections (UoI) method, a flexible, modular, and scalable framework for enhanced model selection and estimation. The method performs model selection and model estimation through intersection and union operations, respectively. We show that UoI can satisfy the bi-criteria of low-variance and nearly unbiased estimation of a small number of interpretable features, while maintaining high-quality prediction accuracy. We perform extensive numerical investigation to evaluate a UoI algorithm ($UoI_{Lasso}$) on synthetic and real data. In doing so, we demonstrate the extraction of interpretable functional networks from human electrophysiology recordings as well as the accurate prediction of phenotypes from genotype-phenotype data with reduced features. We also show (with the $UoI_{L1Logistic}$ and $UoI_{CUR}$ variants of the basic framework) improved prediction parsimony for classification and matrix factorization on several benchmark biomedical data sets. These results suggest that methods based on UoI framework could improve interpretation and prediction in data-driven discovery across scientific fields."}}
{"id": "kDJwXimg7N0", "cdate": 1451606400000, "mdate": null, "content": {"title": "On degeneracy control in overcomplete ICA", "abstract": "Finding overcomplete latent representations of data has applications in data analysis, signal processing, machine learning, theoretical neuroscience and many other fields. In an overcomplete representation, the number of latent features exceeds the data dimensionality, which is useful when the data is undersampled by the measurements (compressed sensing, information bottlenecks in neural systems) or composed from multiple complete sets of linear features, each spanning the data space. Independent Components Analysis (ICA) is a linear technique for learning sparse latent representations, which typically has a lower computational cost than sparse coding, its nonlinear, recurrent counterpart. While well suited for finding complete representations, we show that overcompleteness poses a challenge to existing ICA algorithms. Specifically, the coherence control in existing ICA algorithms, necessary to prevent the formation of duplicate dictionary features, is ill-suited in the overcomplete case. We show that in this case several existing ICA algorithms have undesirable global minima that maximize coherence. Further, by comparing ICA algorithms on synthetic data and natural images to the computationally more expensive sparse coding solution, we show that the coherence control biases the exploration of the data manifold, sometimes yielding suboptimal solutions. We provide a theoretical explanation of these failures and, based on the theory, propose improved overcomplete ICA algorithms. All told, this study contributes new insights into and methods for coherence control for linear ICA, some of which are applicable to many other, potentially nonlinear, unsupervised learning methods."}}
{"id": "Lw9l3tLkek", "cdate": 1388534400000, "mdate": null, "content": {"title": "Communication through Resonance in Spiking Neuronal Networks", "abstract": "Author Summary The cortex is a highly modular structure with a large number of functionally specialized areas that communicate with each other through long-range cortical connections. It is has been suggested that communication between spiking neuronal networks (SNNs) requires synchronization of spiking activity which is either provided by the flow of neuronal activity across divergent/convergent connections, as suggested by computational models of SNNs, or by local oscillations in the gamma frequency band (30\u2013100 Hz). However, such communication requires unphysiologically dense/strong connectivity, and the mechanisms required to synchronize separated local oscillators remain poorly understood. Here, we present a novel mechanism that alleviates these shortcomings and enables the propagation synchrony across weakly connected SNNs by locally amplifying feeble synchronization through resonance that naturally occurs in oscillating networks of excitatory and inhibitory neurons. We show that oscillatory stimuli at the network resonance frequencies generate a slowly propagating oscillation that is synchronized across the distributed networks. Moreover, communication with such oscillations depends on the dynamical state of the background activity in the SNN. Our results suggest that the emergence of synchronized oscillations can be viewed as a consequence of spiking activity propagation in weakly connected networks that is supported by resonance and modulated by the dynamics of the ongoing activity."}}
