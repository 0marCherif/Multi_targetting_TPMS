{"id": "hKrHbEnZNku", "cdate": 1674970482865, "mdate": 1674970482865, "content": {"title": "Curriculum Reinforcement Learning for Cohesive Team in Mobile Ad Hoc Networks", "abstract": "In emergency scenarios, such as disaster or military situations, ad hoc networks should be deployed as no central coordination is available. In this letter, we propose a distributed solution for building mobile ad hoc networks, where the mobile nodes determine their positions as a team autonomously based on reinforcement learning. We propose a special design of a decentralized partially observable Markov decision process to build a cohesive team of mobile nodes in a distributed manner. Each mobile node in the team learns an individual policy that determines movement under partial observation, with the common goal of maximizing network throughput. In the learning process, each node indirectly negotiates the role in the team while explicitly considering the locations of other neighboring nodes and network throughput. To improve learning efficiency, we design a curriculum that encourages nodes to disperse initially but reside in specific regions eventually. Such a curriculum enables each node to be placed in its best location, thereby expediting the collective convergence of all nodes as a cohesive team. Simulation results confirm that the proposed solution can successfully build a cohesive team that maintains high network throughput with low power consumption."}}
{"id": "-lSdsfb1AZ2", "cdate": 1674970445462, "mdate": 1674970445462, "content": {"title": "ADAS-RL: Safety Learning Approach for Stable Autonomous Driving", "abstract": "Stability is the most significant component of an autonomous driving system, affecting both the lives of drivers and pedestrians and traffic flow. Reinforcement learning (RL) is a representative technology used in autonomous driving, but it has challenges because it is based on trial and error. In this letter, we propose an efficient learning approach for stable autonomous driving. The proposed deep reinforcement learning based approach can address the partially observable scenario in mixed traffic which includes both autonomous vehicles and human-driven vehicles. Simulation results show that the proposed model outperforms the control-theoretic and vanilla RL approaches. Furthermore, we confirm the effect of the sync-penalty, which teaches the agent about unsafe decisions without experiencing the accidents.\n\n"}}
{"id": "m0XmD60xJmk", "cdate": 1674970394713, "mdate": 1674970394713, "content": {"title": "Hierarchical Detection of Network Anomalies: A Self-supervised Learning Approach", "abstract": "With the increasing amount of Internet traffic, a significant number of network intrusion events have recently been reported. In this letter, we propose a network intrusion detection system that enables hierarchical detection based on self-supervised learning. The proposed solution consists of multiple stages of detection, including the early detection of extreme outliers, which may cause severe damage to the system. Furthermore, it performs thorough reexaminations using the hidden spaces with specialized anomaly scores, which leads to high detection accuracy. Extensive simulation results confirm that the proposed solution can preemptively detect 20% of abnormal data, thereby enabling a proactive response, and can detect 99% of abnormal data at the final stage."}}
{"id": "KLS6yWEL5f0", "cdate": 1674970299523, "mdate": 1674970299523, "content": {"title": "Reproduction Factor Based Latent Epidemic Model Inference: A Data-driven Approach Using COVID-19 Datasets", "abstract": "The mathematical modeling of infectious diseases aims to evaluate the transmissibility of the on-going spread of disease and guide the government's control strategies and interventions. In this paper, we propose a novel transmissibility indicator, reproduction factor , which evaluates the number of secondary infections from a single nonisolated infectious individual. In contrast to classic reproduction numbers, the reproduction factor explicitly considers the fraction of susceptible individuals (who are not immune to disease naturally or through vaccination) and the nonisolated population to evaluate near real-time transmissibility. Thus, it can be an effective indicator when the spread of disease has progressed and control strategies have been implemented. Other merits of the proposed reproduction factor include data-driven inference based on a Markov chain, which enables the inference of latent information, such as the number of nondetected infectious individuals and the number of daily new infections. We performed an extensive simulation using the COVID-19 datasets of Germany, Italy, South Korea, and California (the U.S.) to verify our model. We further compared the results with other transmissibility measures, including reproduction numbers, and the results of state-of-the-art epidemic models. Through the results, we confirmed that the proposed reproduction factor and corresponding inference model explained the COVID-19 datasets."}}
{"id": "HW5_bIq8BG", "cdate": 1674970215747, "mdate": 1674970215747, "content": {"title": "Stability Analysis in Mixed-autonomous Traffic with Deep Reinforcement Learning", "abstract": "The emergence of autonomous driving vehicles on roads has increased the importance of research on autonomous driving in mixed-autonomous traffic. In mixed-autonomous traffic scenarios, it is necessary to comprehend the instability of autonomous vehicles and traffic flow corresponding to the uncertainty level in human-driven behaviors. However, studies of stability analysis in deep reinforcement learning are limited. This study focuses on the impact of deep reinforcement learning based autonomous vehicles in mixed-autonomous traffic from the stability perspective. We define the policy instability and traffic flow instabilities using the entropy of the velocity distributions to quantitatively measure the instability of an autonomous vehicle. Subsequently, we provide mathematical analyses to explain logarithmic growth patterns of instability. Moreover, we propose a novel deep reinforcement learning approach that jointly determines discrete and continuous actions under partial observation. To verify the proposed solution, we perform extensive simulations of various traffic scenarios (e.g., increasing traffic volumes, increasing the number of autonomous vehicles on the road, and setting the multiple uncertainty levels for human-driven behaviors) with ablation studies on reward function. Moreover, we analyze instabilities when human-driven vehicles are modeled using the human-like noisy controller and a policy that imitates actual human-driving data based on imitation learning. The simulation results support the theoretical analysis and confirm that the proposed method is stabler compared to a conventional control-theoretic approach."}}
{"id": "MvgDwhdbxIT", "cdate": 1622459420018, "mdate": null, "content": {"title": "Rational thoughts in neural codes", "abstract": "Complex behaviors are often driven by an internal model, which integrates sensory information over time and facilitates long-term planning to reach subjective goals. A fundamental challenge in neuroscience is, How can we use behavior and neural activity to understand this internal model and its dynamic latent variables? Here we interpret behavioral data by assuming an agent behaves rationally\u2014that is, it takes actions that optimize its subjective reward according to its understanding of the task and its relevant causal variables. We apply a method, inverse rational control (IRC), to learn an agent\u2019s internal model and reward function by maximizing the likelihood of its measured sensory observations and actions. This thereby extracts rational and interpretable thoughts of the agent from its behavior. We also provide a framework for interpreting encoding, recoding, and decoding of neural data in light of this rational model for behavior. When applied to behavioral and neural data from simulated agents performing suboptimally on a naturalistic foraging task, this method successfully recovers their internal model and reward function, as well as the Markovian computational dynamics within the neural manifold that represent the task. This work lays a foundation for discovering how the brain represents and computes with dynamic latent variables."}}
{"id": "qtBY8AJHBuf", "cdate": 1622459363358, "mdate": null, "content": {"title": "Inverse Rational Control with Partially Observable Continuous Nonlinear Dynamics", "abstract": "A fundamental question in neuroscience is how the brain creates an internal model of the world to guide actions using sequences of ambiguous sensory information. This is naturally formulated as a reinforcement learning problem under partial observations, where an agent must estimate relevant latent variables in the world from its evidence, anticipate possible future states, and choose actions that optimize total expected reward. This problem can be solved by control theory, which allows us to find the optimal actions for a given system dynamics and objective function. However, animals often appear to behave suboptimally. Why? We hypothesize that animals have their own flawed internal model of the world, and choose actions with the highest expected subjective reward according to that flawed model. We describe this behavior as {\\it rational} but not optimal. The problem of Inverse Rational Control (IRC) aims to identify which internal model would best explain an agent's actions. Our contribution here generalizes past work on Inverse Rational Control which solved this problem for discrete control in partially observable Markov decision processes. Here we accommodate continuous nonlinear dynamics and continuous actions, and impute sensory observations corrupted by unknown noise that is private to the animal. We first build an optimal Bayesian agent that learns an optimal policy generalized over the entire model space of dynamics and subjective rewards using deep reinforcement learning. Crucially, this allows us to compute a likelihood over models for experimentally observable action trajectories acquired from a suboptimal agent. We then find the model parameters that maximize the likelihood using gradient ascent. Our method successfully recovers the true model of rational agents. This approach provides a foundation for interpreting the behavioral and neural dynamics of animal brains during complex tasks."}}
{"id": "n883zRWpWd0", "cdate": 1546300800000, "mdate": null, "content": {"title": "Network Coding Based Evolutionary Network Formation for Dynamic Wireless Networks", "abstract": "In this paper, we aim to find a robust network formation strategy that can adaptively evolve the network topology against network dynamics in a distributed manner. We consider a network coding deployed wireless ad hoc network where source nodes are connected to terminal nodes with the help of intermediate nodes. We show that mixing operations in network coding can induce packet anonymity that allows the inter-connections in a network to be decoupled. This enables each intermediate node to consider complex network inter-connections as a node-environment interaction such that the Markov decision process (MDP) can be employed at each intermediate node. The optimal policy that can be obtained by solving the MDP provides each node with the optimal amount of changes in transmission range given network dynamics (e.g., the number of nodes in the range and channel condition). Hence, the network can be adaptively and optimally evolved by responding to the network dynamics. The proposed strategy is used to maximize long-term utility, which is achieved by considering both current network conditions and future network dynamics. We define the utility of an action to include network throughput gain and the cost of transmission power. We show that the resulting network of the proposed strategy eventually converges to stationary networks, which maintain the states of the nodes. Moreover, we propose to determine initial transmission ranges and initial network topology that can expedite the convergence of the proposed algorithm. Our simulation results confirm that the proposed strategy builds a network which adaptively changes its topology in the presence of network dynamics. Moreover, the proposed strategy outperforms existing strategies in terms of system goodput and successful connectivity ratio."}}
{"id": "fX-WVSYzVUT", "cdate": 1546300800000, "mdate": null, "content": {"title": "Distributed topology design for network coding deployed networks", "abstract": "Highlights \u2022 We formulate the problem of network topology design as a network formation game, which leads to a distributed strategy for topology formation. \u2022 We analytically show that network coding decomposes the network formation game into link formation games, leading to an algorithm with significantly low complexity. \u2022 We design a utility function for the network formation game such that nodes can explicitly consider the tradeoff between the distance reduction and the cost associated with making links. \u2022 We quantitatively evaluate the proposed solution and show that the proposed solution eventually leads to increased network throughput and a reduced number of unnecessary redundant links between nodes. Abstract In this paper, we propose a solution to the distributed topology formation problem for large-scale sensor networks with multi-source multicast flows. The proposed solution is based on game-theoretic approaches in conjunction with network coding. The proposed algorithm requires significantly low computational complexity, while it is known as NP-hard to find an optimal topology for network coding deployed multi-source multicast flows. In particular, we formulate the problem of distributed network topology formation as a network formation game by considering the nodes in the network as players that can take actions for making outgoing links. The proposed solution decomposes the original game that consists of multiple players and multicast flows into independent link formation games played by only two players with a unicast flow. We also show that the proposed algorithm is guaranteed to determine at least one stable topology. Our simulation results confirm that the computational complexity of the proposed solution is low enough for practical deployment in large-scale networks."}}
{"id": "VfwqnBSR3h0", "cdate": 1514764800000, "mdate": null, "content": {"title": "Systematic network coding based reliable real-time multimedia streaming system", "abstract": "In this paper, we propose an implementation of a real-time multimedia streaming system that can simultaneously support a large number of clients. The proposed solution is based on systematic network coding that does not require feedback channels for acknowledgment or retransmission while it is resilient to packet erasures. Our experiment includes simultaneous full HD video transmission to 20 clients with 4 different types of mobile devices. The measured results confirm that the proposed system is the most robust against the packet losses compared to two conventional real-time streaming solutions."}}
