{"id": "mOPoAoJuLQu", "cdate": 1672531200000, "mdate": 1696422810532, "content": {"title": "Enhancing CLIP with CLIP: Exploring Pseudolabeling for Limited-Label Prompt Tuning", "abstract": "Fine-tuning vision-language models (VLMs) like CLIP to downstream tasks is often necessary to optimize their performance. However, a major obstacle is the limited availability of labeled data. We study the use of pseudolabels, i.e., heuristic labels for unlabeled data, to enhance CLIP via prompt tuning. Conventional pseudolabeling trains a model on labeled data and then generates labels for unlabeled data. VLMs' zero-shot capabilities enable a ``second generation'' of pseudolabeling approaches that do not require task-specific training on labeled data. By using zero-shot pseudolabels as a source of supervision, we observe that learning paradigms such as semi-supervised, transductive zero-shot, and unsupervised learning can all be seen as optimizing the same loss function. This unified view enables the development of versatile training strategies that are applicable across learning paradigms. We investigate them on image classification tasks where CLIP exhibits limitations, by varying prompt modalities, e.g., textual or visual prompts, and learning paradigms. We find that (1) unexplored prompt tuning strategies that iteratively refine pseudolabels consistently improve CLIP accuracy, by 19.5 points in semi-supervised learning, by 28.4 points in transductive zero-shot learning, and by 15.2 points in unsupervised learning, and (2) unlike conventional semi-supervised pseudolabeling, which exacerbates model biases toward classes with higher-quality pseudolabels, prompt tuning leads to a more equitable distribution of per-class accuracy. The code to reproduce the experiments is at github.com/BatsResearch/menghini-enhanceCLIPwithCLIP-code."}}
{"id": "tzNWhvOomsK", "cdate": 1652737585201, "mdate": null, "content": {"title": "Tight Lower Bounds on Worst-Case Guarantees for Zero-Shot Learning with Attributes", "abstract": "We develop a rigorous mathematical analysis of zero-shot learning with attributes. In this setting, the goal is to label novel classes with no training data, only detectors for attributes and a description of how those attributes are correlated with the target classes, called the class-attribute matrix. We develop the first non-trivial lower bound on the worst-case error of the best map from attributes to classes for this setting, even with perfect attribute detectors. The lower bound characterizes the theoretical intrinsic difficulty of the zero-shot problem based on the available information---the class-attribute matrix---and the bound is practically computable from it. Our lower bound is tight, as we show that we can always find a randomized map from attributes to classes whose expected error is upper bounded by the value of the lower bound. We show that our analysis can be predictive of how standard zero-shot methods behave in practice, including which classes will likely be confused with others."}}
{"id": "sNFhchgSO6", "cdate": 1640995200000, "mdate": 1680534277921, "content": {"title": "TAGLETS: A System for Automatic Semi-Supervised Learning with Auxiliary Data", "abstract": ""}}
{"id": "bbKsxpa7-kk", "cdate": 1640995200000, "mdate": 1680534277880, "content": {"title": "The Drift of #MyBodyMyChoice Discourse on Twitter", "abstract": ""}}
{"id": "CNqCIWVdKws", "cdate": 1640995200000, "mdate": 1670799253555, "content": {"title": "Reducing polarization and increasing diverse navigability in graphs by inserting edges and swapping edge weights", "abstract": "The sets of hyperlinks in web pages, relationship ties in social networks, or sets of recommendations in recommender systems, have a major impact on the diversity of content accessed by the user in a browsing session. Bias induced by the graph structure may trap a reader in a polarized bubble with no access to other opinions. It is widely accepted that exposure to diverse opinions creates more informed citizens and consumers. We introduce the concept of the polarized bubble radius of a node, as the expected length of a random walk from it to a node of different opinion. Using the bubble radius, we define the measures of structural bias and diverse navigability to quantify the effect of links and recommendations on the diversity of content visited in a browsing session. We then propose algorithmic techniques to reduce the structural bias of the graph or improve the diverse navigability of the system through minimal modifications, such as edge insertions or flipping the order of existing links or recommendations, corresponding to switching the edge traversal probabilities. Under mild conditions, our techniques obtain a constant factor-approximation of their respective tasks. In our extensive experimental evaluation, we show that our algorithms reduce the structural bias or improve the diverse navigability faster than appropriate baselines, including some designed with the goal of reducing the polarization of a graph."}}
{"id": "vPUIARV2Jf", "cdate": 1609459200000, "mdate": 1680534277964, "content": {"title": "How Inclusive Are Wikipedia's Hyperlinks in Articles Covering Polarizing Topics?", "abstract": ""}}
{"id": "IUYg5VKnSg", "cdate": 1609459200000, "mdate": 1648749156849, "content": {"title": "RePBubLik: Reducing Polarized Bubble Radius with Link Insertions", "abstract": "The topology of the hyperlink graph among pages expressing different opinions may influence the exposure of readers to diverse content. Structural bias may trap a reader in a 'polarized' bubble with no access to other opinions. We model readers' behavior as random walks. A node is in a 'polarized' bubble if the expected length of a random walk from it to a page of different opinion is large. The structural bias of a graph is the sum of the radii of highly-polarized bubbles. We study the problem of decreasing the structural bias through edge insertions. 'Healing' all nodes with high polarized bubble radius is hard to approximate within a logarithmic factor, so we focus on finding the best k edges to insert to maximally reduce the structural bias. We present RePBubLik, an algorithm that leverages a variant of the random walk closeness centrality to select the edges to insert. RePBubLik obtains, under mild conditions, a constant-factor approximation. It reduces the structural bias faster than existing edge-recommendation methods, including some designed to reduce the polarization of a graph."}}
{"id": "e8YwrIhIKQ", "cdate": 1546300800000, "mdate": 1680534277866, "content": {"title": "Wikipedia Polarization and Its Effects on Navigation Paths", "abstract": ""}}
{"id": "ozm3ORLk-vH", "cdate": 1514764800000, "mdate": 1680534277878, "content": {"title": "Compiling Questions into Balanced Quizzes about Documents", "abstract": ""}}
