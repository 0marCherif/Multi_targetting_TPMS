{"id": "4XMAzZasId", "cdate": 1663849802382, "mdate": null, "content": {"title": "Model-agnostic Measure of Generalization Difficulty", "abstract": "The measure of a machine learning algorithm is the difficulty of the tasks it can perform, and sufficiently difficult tasks are critical drivers of strong machine learning models. However, quantifying the generalization difficulty of machine learning benchmarks has remained challenging. We propose what is to our knowledge the first model-agnostic measure of the inherent generalization difficulty of tasks. Our inductive bias complexity measure quantifies the total information required to generalize well on a task minus the information provided by the data. It does so by measuring the fractional volume occupied by hypotheses that generalize on a task given that they fit the training data. It scales exponentially with the intrinsic dimensionality of the space over which the model must generalize but only polynomially in resolution per dimension, showing that tasks which require generalizing over many dimensions are drastically more difficult than tasks involving more detail in fewer dimensions. Our measure can be applied to compute and compare supervised learning, reinforcement learning and meta-learning task difficulties against each other. We show that applied empirically, it formally quantifies intuitively expected trends, e.g. that in terms of required inductive bias, MNIST $<$ CIFAR10 $<$ Imagenet and fully observable Markov decision processes (MDPs) $<$ partially observable MDPs. Further, we show that classification of complex images $<$ few-shot meta-learning with simple images. Our measure provides a quantitative metric to guide the construction of more complex tasks requiring greater inductive bias, and thereby encourages the development of more sophisticated architectures and learning algorithms with more powerful generalization capabilities."}}
{"id": "ED2Jjms9A4H", "cdate": 1663849801938, "mdate": null, "content": {"title": "Efficient Exploration via Fragmentation and Recall", "abstract": "Efficient exploration and model-building are critical for learning in large state- spaces. However, agents typically face problems like getting stuck locally during exploration and catastrophic forgetting in their construction of models when the environments are heterogeneous. Here, we propose and apply the concept of Fragmentation-and-Recall to solve spatial (FarMap) and reinforcement learning problems (FarCuriosity). Agents construct local maps or local models, respectively, which are used to predict the current observation. High surprisal points lead to a fragmentation event. At fracture points, we store the current map or model fragment in a long-term memory (LTM) and initialize a new fragment. On the other hand, Fragments are recalled (and thus reused) from LTM if the observations of their fracture points match the agent\u2019s current observation during exploration. The set of fracture points defines a set of intrinsic potential subgoals. Agents choose their next subgoal from the set of near and far potential subgoals in the current fragment or LTM, respectively. Thus, local maps and model fragments guide exploration locally and avoid catastrophic forgetting in learning heterogeneous environments, while LTM promotes exploration more globally. We evaluate FarMap and FarCuriosity on complex procedurally-generated spatial environments and on reinforcement learning benchmarks and demonstrate that the proposed methods are more efficient at exploration and memory use, and in harvesting extrinsic rewards, respectively."}}
{"id": "sKjBkoqVBh", "cdate": 1624353775834, "mdate": null, "content": {"title": "Exemplar-Based Open-Set Panoptic Segmentation Network", "abstract": "We extend panoptic segmentation to the open-world and introduce an open-set panoptic segmentation (OPS) task. This task requires performing panoptic segmentation for not only known classes but also unknown ones that have not been acknowledged during training. We investigate the practical challenges of the task and construct a benchmark on top of an existing dataset, COCO. In addition, we propose a novel exemplar-based open-set panoptic segmentation network (EOPSN) inspired by exemplar theory. Our approach identifies a new class based on exemplars, which are identified by clustering and employed as pseudo-ground-truths. The size of each class increases by mining new exemplars based on the similarities to the existing ones associated with the class. We evaluate EOPSN on the proposed benchmark and demonstrate the effectiveness of our proposals. The primary goal of our work is to draw the attention of the community to the recognition in the open-world scenarios. The implementation of our algorithm is available on the project webpage."}}
{"id": "1MGJMNwtfb8", "cdate": 1623571860892, "mdate": null, "content": {"title": "Weakly Supervised Instance Segmentation by Deep Community Learning", "abstract": "We present a weakly supervised instance segmentation algorithm based on deep community learning with multiple tasks. This task is formulated as a combination of weakly supervised object detection and semantic segmentation, where individual objects of the same class are identified and segmented separately. We address this problem by designing a unified deep neural network architecture, which has a positive feedback loop of object detection with bounding box regression, instance mask generation, instance segmentation, and feature extraction. Each component of the network makes active interactions with others to improve accuracy, and the end-to-end trainability of our model makes our results more robust and reproducible. The proposed algorithm achieves state-of-the-art performance in the weakly supervised setting without any additional training such as Fast R-CNN and Mask R\u0002CNN on the standard benchmark dataset. The implementation of our algorithm is available on the project webpage: https://cv.snu.ac.kr/research/WSIS_CL.\n"}}
{"id": "QjAUV13Jjm9", "cdate": 1546300800000, "mdate": 1652035629351, "content": {"title": "Robust harmonic field based tooth segmentation in real-life noisy scanned mesh", "abstract": "Dental segmentation plays an important role in prosthetic dentistry such as crowns, implants and even orthodontics. Since people have different dental structures, it is hard to make a general dental segmentation model. Recently, there are only a few studies which try to tackle this problem. In this paper, we propose simple and intuitive algorithms for harmonic field based dental segmentation method to provide robustness for clinical dental mesh data. Our model includes additional grounds to gum, a pair of different Dirichlet boundary conditions, and convex segmentation for post-processing. Our data is generated for clinical usage and therefore has many noise, holes, and crowns. Moreover, some meshes have abraded teeth which deter the performance of harmonic field due to its dramatic gradient change. To the best of our knowledge, the proposed method and experiments are the first that deals with real clinical data containing noise and fragmented areas. We evaluate the results qualitatively and quantitatively to demonstrate the performance of the model. The model separates teeth from gum and other teeth very accurately. We use intersection over union (IoU) to calculate the overlap ratio between tooth. Moreover, human evaluation is used for measuring and comparing the performance of our segmentation model to other models. We compare the segmentation results of a baseline model and our model. Ablation study shows that our model improves the segmentation performance. Our model outperforms the baseline model at the expanse of some overlap which can be ignored."}}
{"id": "rkxkHnA5tX", "cdate": 1538087991361, "mdate": null, "content": {"title": "Learning from Noisy Demonstration Sets via Meta-Learned Suitability Assessor", "abstract": "A noisy and diverse demonstration set may hinder the performances of an agent aiming to acquire certain skills via imitation learning. However, state-of-the-art imitation learning algorithms often assume the optimality of the given demonstration set.\nIn this paper, we address such optimal assumption by learning only from the most suitable demonstrations in a given set. Suitability of a demonstration is estimated by whether imitating it produce desirable outcomes for achieving the goals of the tasks. For more efficient demonstration suitability assessments, the learning agent should be capable of imitating a demonstration as quick as possible, which shares similar spirit with fast adaptation in the meta-learning regime. Our framework, thus built on top of Model-Agnostic Meta-Learning, evaluates how desirable the imitated outcomes are, after adaptation to each demonstration in the set. The resulting assessments hence enable us to select suitable demonstration subsets for acquiring better imitated skills. The videos related to our experiments are available at: https://sites.google.com/view/deepdj"}}
