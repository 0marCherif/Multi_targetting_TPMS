{"id": "pdl3R_7vTPW", "cdate": 1640995200000, "mdate": 1684002618105, "content": {"title": "Higher-Order Generalization Bounds: Learning Deep Probabilistic Programs via PAC-Bayes Objectives", "abstract": "Deep Probabilistic Programming (DPP) allows powerful models based on recursive computation to be learned using efficient deep-learning optimization techniques. Additionally, DPP offers a unified perspective, where inference and learning algorithms are treated on a par with models as stochastic programs. Here, we offer a framework for representing and learning flexible PAC-Bayes bounds as stochastic programs using DPP-based methods. In particular, we show that DPP techniques may be leveraged to derive generalization bounds that draw on the compositionality of DPP representations. In turn, the bounds we introduce offer principled training objectives for higher-order probabilistic programs. We offer a definition of a higher-order generalization bound, which naturally encompasses single- and multi-task generalization perspectives (including transfer- and meta-learning) and a novel class of bound based on a learned measure of model complexity. Further, we show how modified forms of all higher-order bounds can be efficiently optimized as objectives for DPP training, using variational techniques. We test our framework using single- and multi-task generalization settings on synthetic and biological data, showing improved performance and generalization prediction using flexible DPP model representations and learned complexity measures."}}
{"id": "WineRUBm8F", "cdate": 1640995200000, "mdate": 1684002618104, "content": {"title": "A Meta-Probabilistic-Programming Language for Bisimulation of Probabilistic and Non-Well-Founded Type Systems", "abstract": "We introduce a formal meta-language for probabilistic programming, capable of expressing both programs and the type systems in which they are embedded. We are motivated here by the desire to allow an AGI to learn not only relevant knowledge (programs/proofs), but also appropriate ways of reasoning (logics/type systems). We draw on the frameworks of cubical type theory and dependent typed metagraphs to formalize our approach. In doing so, we show that specific constructions within the meta-language can be related via bisimulation (implying path equivalence) to the type systems they correspond. This allows our approach to provide a convenient means of deriving synthetic denotational semantics for various type systems. Particularly, we derive bisimulations for pure type systems (PTS), and probabilistic dependent type systems (PDTS). We discuss further the relationship of PTS to non-well-founded set theory, and demonstrate the feasibility of our approach with an implementation of a bisimulation proof in a Guarded Cubical Type Theory type checker."}}
{"id": "9Tk6_1UY0p5", "cdate": 1640995200000, "mdate": 1684002618106, "content": {"title": "A meta-probabilistic-programming language for bisimulation of probabilistic and non-well-founded type systems", "abstract": "We introduce a formal meta-language for probabilistic programming, capable of expressing both programs and the type systems in which they are embedded. We are motivated here by the desire to allow an AGI to learn not only relevant knowledge (programs/proofs), but also appropriate ways of reasoning (logics/type systems). We draw on the frameworks of cubical type theory and dependent typed metagraphs to formalize our approach. In doing so, we show that specific constructions within the meta-language can be related via bisimulation (implying path equivalence) to the type systems they correspond. This allows our approach to provide a convenient means of deriving synthetic denotational semantics for various type systems. Particularly, we derive bisimulations for pure type systems (PTS), and probabilistic dependent type systems (PDTS). We discuss further the relationship of PTS to non-well-founded set theory, and demonstrate the feasibility of our approach with an implementation of a bisimulation proof in a Guarded Cubical Type Theory type checker."}}
{"id": "q4HuPoEQK_o", "cdate": 1601308392947, "mdate": null, "content": {"title": "Hybrid Quantum-Classical Stochastic Networks with Boltzmann Layers", "abstract": "Quantum Machine Learning (QML) has the potential to significantly advance the state-of-the-art in artificial intelligence, due to recent developments in quantum computing hardware and algorithm design.  Particularly, an avenue opened up by these advances is the possibility of enhancing classical models through developing quantum analogues, which have greater representational power at no extra cost in terms of training and inference.  Here, we investigate analogues of classical networks with stochastic layers, by introducing a class of hybrid stochastic networks that combine layers of several types, including stochastic quantum and classical layers and deterministic classical layers. Further, we introduce Quantum-Annealing (QA)-based sampling techniques that allow such models to be efficiently learned on current QA architectures, using variational and importance-sampling based approaches. Our framework provides benefits in training existing models, including Quantum Boltzmann Machines (QBMs) and Quantum Variational Autoencoders, by allowing local transverse field weights to be optimized jointly with other model parameters, and allows novel hierarchical hybrid models to be learned efficiently. We use classical simulations on synthetic and genomics data to test the impact of including quantum mechanical transverse field terms in such models relative to their classical counterparts. We show that hybrid models are able to achieve better predictive accuracy compared to classical models of matching architecture in these settings, and provide evidence that the local transverse terms can be interpreted as introducing tunable higher-order interactions by connecting genes belonging to common biological pathways."}}
{"id": "8kE_ofSBPI8", "cdate": 1577836800000, "mdate": 1667494632819, "content": {"title": "Analyses of non-coding somatic drivers in 2,658 cancer whole genomes", "abstract": "The discovery of drivers of cancer has traditionally focused on protein-coding genes1\u20134. Here we present analyses of driver point mutations and structural variants in non-coding regions across 2,658&nbsp;genomes from the Pan-Cancer Analysis of Whole Genomes (PCAWG) Consortium5 of the International Cancer Genome Consortium (ICGC) and The Cancer Genome Atlas (TCGA). For point mutations, we developed a statistically rigorous strategy for combining significance levels from multiple methods of driver discovery that overcomes the limitations of individual methods. For structural variants, we present two methods of driver discovery, and identify regions that are significantly affected by recurrent breakpoints and recurrent somatic juxtapositions. Our analyses confirm previously reported drivers6,7, raise doubts about others and identify novel candidates, including point mutations in the 5\u2032 region of TP53, in the 3\u2032 untranslated regions of NFKBIZ and TOB1, focal deletions in BRD4 and rearrangements in the loci of AKR1C genes. We show that although&nbsp;point mutations and structural variants that drive cancer are less frequent in non-coding genes and regulatory sequences than in protein-coding genes, additional examples of these drivers will be found as more cancer genomes become available. Analyses of 2,658 whole genomes across 38 types of cancer identify the contribution of non-coding point mutations and structural variants to driving cancer."}}
{"id": "yiLS6lRx7pP", "cdate": 1514764800000, "mdate": 1684002618106, "content": {"title": "Rank Projection Trees for Multilevel Neural Network Interpretation", "abstract": "A variety of methods have been proposed for interpreting nodes in deep neural networks, which typically involve scoring nodes at lower layers with respect to their effects on the output of higher-layer nodes (where lower and higher layers are closer to the input and output layers, respectively). However, we may be interested in picking out a prioritized collection of subsets of the inputs across a range of scales according to their importance for an output node, and not simply a prioritized ranking across the inputs as singletons. Such a situation may arise in biological applications, for instance, where we are interested in epistatic effects between groups of genes in determining a trait of interest. Here, we outline a flexible framework which may be used to generate multiscale network interpretations, using any previously defined scoring function. We demonstrate the ability of our method to pick out biologically important genes and gene sets in the domains of cancer and psychiatric genomics."}}
{"id": "spOI0MEgYO", "cdate": 1388534400000, "mdate": 1684002618154, "content": {"title": "Filter-Based Mean-Field Inference for Random Fields with Higher-Order Terms and Product Label-Spaces", "abstract": "Recently, a number of cross bilateral filtering methods have been proposed for solving multi-label problems in computer vision, such as stereo, optical flow and object class segmentation that show an order of magnitude improvement in speed over previous methods. These methods have achieved good results despite using models with only unary and/or pairwise terms. However, previous work has shown the value of using models with higher-order terms e.g. to represent label consistency over large regions, or global co-occurrence relations. We show how these higher-order terms can be formulated such that filter-based inference remains possible. We demonstrate our techniques on joint stereo and object labelling problems, as well as object class segmentation, showing in addition for joint object-stereo labelling how our method provides an efficient approach to inference in product label-spaces. We show that we are able to speed up inference in these models around 10\u201330 times with respect to competing graph-cut/move-making methods, as well as maintaining or improving accuracy in all cases. We show results on PascalVOC-10 for object class segmentation, and Leuven for joint object-stereo labelling."}}
{"id": "fLbkPVTU136", "cdate": 1388534400000, "mdate": 1684002618112, "content": {"title": "A Tiered Move-making Algorithm for General Non-submodular Pairwise Energies", "abstract": "A large number of problems in computer vision can be modelled as energy minimization problems in a Markov Random Field (MRF) or Conditional Random Field (CRF) framework. Graph-cuts based $\\alpha$-expansion is a standard move-making method to minimize the energy functions with sub-modular pairwise terms. However, certain problems require more complex pairwise terms where the $\\alpha$-expansion method is generally not applicable. In this paper, we propose an iterative {\\em tiered move making algorithm} which is able to handle general pairwise terms. Each move to the next configuration is based on the current labeling and an optimal tiered move, where each tiered move requires one application of the dynamic programming based tiered labeling method introduced in Felzenszwalb et. al. \\cite{tiered_cvpr_felzenszwalbV10}. The algorithm converges to a local minimum for any general pairwise potential, and we give a theoretical analysis of the properties of the algorithm, characterizing the situations in which we can expect good performance. We first evaluate our method on an object-class segmentation problem using the Pascal VOC-11 segmentation dataset where we learn general pairwise terms. Further we evaluate the algorithm on many other benchmark labeling problems such as stereo, image segmentation, image stitching and image denoising. Our method consistently gets better accuracy and energy values than alpha-expansion, loopy belief propagation (LBP), quadratic pseudo-boolean optimization (QPBO), and is competitive with TRWS."}}
{"id": "Hybi0kz_bS", "cdate": 1388534400000, "mdate": null, "content": {"title": "Dense Semantic Image Segmentation with Objects and Attributes", "abstract": "The concepts of objects and attributes are both important for describing images precisely, since verbal descriptions often contain both adjectives and nouns (e.g. 'I see a shiny red chair'). In this paper, we formulate the problem of joint visual attribute and object class image segmentation as a dense multi-labelling problem, where each pixel in an image can be associated with both an object-class and a set of visual attributes labels. In order to learn the label correlations, we adopt a boosting-based piecewise training approach with respect to the visual appearance and co-occurrence cues. We use a filtering-based mean-field approximation approach for efficient joint inference. Further, we develop a hierarchical model to incorporate region-level object and attribute information. Experiments on the aPASCAL, CORE and attribute augmented NYU indoor scenes datasets show that the proposed approach is able to achieve state-of-the-art results."}}
{"id": "ymBm5K_dK2o", "cdate": 1356998400000, "mdate": 1684002618116, "content": {"title": "Comparison of active SIFT-based 3D object recognition algorithms", "abstract": "Active object recognition aims to manipulate the sensor and its parameters, and interact with the environment and/or the object of interest in order to gather more information to complete the 3D object recognition task as quickly and accurately as possible. It can leverage the mobility of robotic platforms to capture additional viewpoints about an object as single images are not always sufficient especially if objects appear in cluttered human environments. Active vision algorithms should reduce the number of viewpoints required to recognise an object and hence reduce the computational time as well. This paper compares two active object recognition systems. Both systems use SIFT features for object recognition, but use contrasting models, update and viewpoint selection strategies. The methods for integrating information across views used by the two systems are investigated. This is essential as this module is used to select the next best viewpoint. The number of viewpoints and the time taken to recognise objects are used to compare the performance of these two methods."}}
