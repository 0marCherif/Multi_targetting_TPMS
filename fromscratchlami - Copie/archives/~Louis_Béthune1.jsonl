{"id": "HnetdtNFNk", "cdate": 1672531200000, "mdate": 1681654272002, "content": {"title": "Robust One-Class Classification with Signed Distance Function using 1-Lipschitz Neural Networks", "abstract": ""}}
{"id": "Fl5fjmIIe7O", "cdate": 1672531200000, "mdate": 1693330454405, "content": {"title": "Robust One-Class Classification with Signed Distance Function using 1-Lipschitz Neural Networks", "abstract": "We propose a new method, dubbed One Class Signed Distance Function (OCSDF), to perform One Class Classification (OCC) by provably learning the Signed Distance Function (SDF) to the boundary of the ..."}}
{"id": "Ev7eJOvVSYM", "cdate": 1672531200000, "mdate": 1693330454404, "content": {"title": "DP-SGD Without Clipping: The Lipschitz Neural Network Way", "abstract": "State-of-the-art approaches for training Differentially Private (DP) Deep Neural Networks (DNN) faces difficulties to estimate tight bounds on the sensitivity of the network's layers, and instead rely on a process of per-sample gradient clipping. This clipping process not only biases the direction of gradients but also proves costly both in memory consumption and in computation. To provide sensitivity bounds and bypass the drawbacks of the clipping process, our theoretical analysis of Lipschitz constrained networks reveals an unexplored link between the Lipschitz constant with respect to their input and the one with respect to their parameters. By bounding the Lipschitz constant of each layer with respect to its parameters we guarantee DP training of these networks. This analysis not only allows the computation of the aforementioned sensitivities at scale but also provides leads on to how maximize the gradient-to-noise ratio for fixed privacy guarantees. To facilitate the application of Lipschitz networks and foster robust and certifiable learning under privacy guarantees, we provide a Python package that implements building blocks allowing the construction and private training of such networks."}}
{"id": "796Sz-4BNHM", "cdate": 1672531200000, "mdate": 1693330454384, "content": {"title": "A Holistic Approach to Unifying Automatic Concept Extraction and Concept Importance Estimation", "abstract": "In recent years, concept-based approaches have emerged as some of the most promising explainability methods to help us interpret the decisions of Artificial Neural Networks (ANNs). These methods seek to discover intelligible visual 'concepts' buried within the complex patterns of ANN activations in two key steps: (1) concept extraction followed by (2) importance estimation. While these two steps are shared across methods, they all differ in their specific implementations. Here, we introduce a unifying theoretical framework that comprehensively defines and clarifies these two steps. This framework offers several advantages as it allows us: (i) to propose new evaluation metrics for comparing different concept extraction approaches; (ii) to leverage modern attribution methods and evaluation metrics to extend and systematically evaluate state-of-the-art concept-based approaches and importance estimation techniques; (iii) to derive theoretical guarantees regarding the optimality of such methods. We further leverage our framework to try to tackle a crucial question in explainability: how to efficiently identify clusters of data points that are classified based on a similar shared strategy. To illustrate these findings and to highlight the main strategies of a model, we introduce a visual representation called the strategic cluster graph. Finally, we present https://serre-lab.github.io/Lens, a dedicated website that offers a complete compilation of these visualizations for all classes of the ImageNet dataset."}}
{"id": "2Xy6E2MNsyb", "cdate": 1672531200000, "mdate": 1693330454165, "content": {"title": "Gaussian Processes on Distributions based on Regularized Optimal Transport", "abstract": "We present a novel kernel over the space of probability measures based on the dual formulation of optimal regularized transport. We propose an Hilbertian embedding of the space of probabilities usi..."}}
{"id": "GMB-UN9F04U", "cdate": 1668734786594, "mdate": null, "content": {"title": "Certifiable Metric One Class Learning with adversarially trained Lipschitz Classifier", "abstract": "We propose a new Novelty Detection and One Class classifier, based on the smoothness properties of orthogonal neural network, and on the properties of Hinge Kantorovich Rubinstein (HKR) function. The classifier benefits from robustness certificates against $l2$-attacks thanks to the Lipschitz constraint, whilst the HKR loss allows to provably approximate the signed distance function to the boundary of the distribution: the normality score induces by the classifier has a meaningful interpretation in term of distance to the support. Finally, gradient steps in the input space allows free generation of samples from the one class in a fashion that reminds GAN or VAE."}}
{"id": "8FuITQn6rG3", "cdate": 1652737319269, "mdate": null, "content": {"title": "CRAFT: explaining using Concepts from Recursive Activation FacTorization", "abstract": "Despite their considerable potential, concept-based explainability methods have received relatively little attention, and explaining what\u2019s driving models\u2019 decisions and where it\u2019s located in the input is still an open problem. To tackle this, we revisit unsupervised concept extraction techniques for explaining the decisions of deep neural networks and present CRAFT \u2013 a framework to generate concept-based explanations for understanding individual predictions and the model\u2019s high-level logic for whole classes. CRAFT takes advantage of a novel method for recursively decomposing higher-level concepts into more elementary ones, combined with a novel approach for better estimating the importance of identified concepts with Sobol indices. Furthermore, we show how implicit differentiation can be used to generate concept-wise attribution explanations for individual images. We further demonstrate through fidelity metrics that our proposed concept importance estimation technique is more faithful to the model than previous methods, and, through human psychophysic experiments, we confirm that our recursive decomposition can generate meaningful and accurate concepts. Finally, we illustrate CRAFT\u2019s potential to enable the understanding of predictions of trained models on multiple use-cases by producing meaningful concept-based explanations."}}
{"id": "BRIL0EFvTgc", "cdate": 1652737302951, "mdate": null, "content": {"title": "Pay attention to your loss : understanding misconceptions about Lipschitz neural networks", "abstract": "Lipschitz constrained networks have gathered considerable attention in the deep learning community, with usages ranging from Wasserstein distance estimation to the training of certifiably robust classifiers. However they remain commonly considered as less accurate, and their properties in learning are still not fully understood. In this paper we clarify the matter: when it comes to classification 1-Lipschitz neural networks enjoy several advantages over their unconstrained counterpart. First, we show that these networks are as accurate as classical ones, and can fit arbitrarily difficult boundaries. Then, relying on a robustness metric that reflects operational needs we characterize the most robust classifier: the WGAN discriminator. Next, we show that 1-Lipschitz neural networks generalize well under milder assumptions. Finally, we show that hyper-parameters of the loss are crucial for controlling the accuracy-robustness trade-off. We conclude that they exhibit appealing properties to pave the way toward provably accurate, and provably robust neural networks.    "}}
{"id": "yKSk96q-K95", "cdate": 1640995200000, "mdate": 1681654272114, "content": {"title": "Efficient circuit implementation for coined quantum walks on binary trees and application to reinforcement learning", "abstract": ""}}
{"id": "hvbOqVNY8Z", "cdate": 1640995200000, "mdate": 1681654272028, "content": {"title": "CRAFT: Concept Recursive Activation FacTorization for Explainability", "abstract": ""}}
