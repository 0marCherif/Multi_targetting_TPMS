{"id": "myoo3uBVIb", "cdate": 1699262612834, "mdate": 1699262612834, "content": {"title": "Semantic Motif Segmentation of Archaeological Fresco Fragments", "abstract": "Archaeological fragment processing is crucial to support the analysis of pictorial contents of broken artifacts. In this paper, we focus on the unexplored task of semantic segmentation of fresco fragments. This task enables the extraction of semantic information from a fragment, facilitating subsequent tasks like fragment classification or reassembly. We introduce a semantic segmentation dataset of fresco fragments acquired at the Pompeii Archeological Site, accompanied by baseline models. Additionally, we introduce a supplementary task of fragment cleaning, providing a dataset with the detection of manual annotations of archaeological marks that require restoration before further analysis. Our experiments, using standard metrics and state-of-the-art baselines, demonstrate that semantic segmentation of fresco fragments is feasible, paving the way toward more complex activities that require a semantic understanding of fragmented artifacts. Dataset with annotations, and code will be released at https://repairproject.github.io/fragment-restoration/"}}
{"id": "9Jxc2Xasdso", "cdate": 1669123692841, "mdate": 1669123692841, "content": {"title": "Two sides of the same coin: Improved ancient coin classification using Graph Transduction Games", "abstract": "In this work we tackle the problem of automatic recognition of ancient coin types using a semisupervised learning method, namely Graph Transduction Games. Such problem is complex, mainly due to the low inter-class and large intra-class variations and the task becomes even more complex due to lack of labeled large datasets from certain ancient ages. In this paper we propose a new dataset which is chiefly the extension of a previous one both in terms of quantity and diversity. Moreover, we propose a game-theoretic model that exploits both sides of a coin to achieve higher classification accuracy. We experimentally demonstrate that proposed approach brings performance improvement in this complex task even when few number of labelled images are available."}}
{"id": "8i2M8zAQ-L", "cdate": 1668991522954, "mdate": 1668991522954, "content": {"title": "The Group Loss for Deep Metric Learning", "abstract": "Deep metric learning has yielded impressive results in tasks such as clustering and image retrieval by leveraging neural networks to obtain highly discriminative feature embeddings, which can be used to group samples into different classes. Much research has been devoted to the design of smart loss functions or data mining strategies for training such networks. Most methods consider only pairs or triplets of samples within a mini-batch to compute the loss function, which is commonly based on the distance between embeddings. We propose Group Loss, a loss function based on a differentiable label-propagation method that enforces embedding similarity across all samples of a group while promoting, at the same time, low-density regions amongst data points belonging to different groups. Guided by the smoothness assumption that \"similar objects should belong to the same group\", the proposed loss trains the neural network for a classification task, enforcing a consistent labelling amongst samples within a class. We show state-of-the-art results on clustering and image retrieval on several datasets, and show the potential of our method when combined with other techniques such as ensembles"}}
{"id": "us2kWUQu_2", "cdate": 1640995200000, "mdate": 1668991637525, "content": {"title": "The Group Loss++: A deeper look into group loss for deep metric learning", "abstract": "Deep metric learning has yielded impressive results in tasks such as clustering and image retrieval by leveraging neural networks to obtain highly discriminative feature embeddings, which can be used to group samples into different classes. Much research has been devoted to the design of smart loss functions or data mining strategies for training such networks. Most methods consider only pairs or triplets of samples within a mini-batch to compute the loss function, which is commonly based on the distance between embeddings. We propose Group Loss, a loss function based on a differentiable label-propagation method that enforces embedding similarity across all samples of a group while promoting, at the same time, low-density regions amongst data points belonging to different groups. Guided by the smoothness assumption that \"similar objects should belong to the same group\", the proposed loss trains the neural network for a classification task, enforcing a consistent labelling amongst samples within a class. We design a set of inference strategies tailored towards our algorithm, named Group Loss++ that further improve the results of our model. We show state-of-the-art results on clustering and image retrieval on four retrieval datasets, and present competitive results on two person re-identification datasets, providing a unified framework for retrieval and re-identification."}}
{"id": "rGR_5yxDkw", "cdate": 1640995200000, "mdate": 1668991637533, "content": {"title": "Relaxation Labeling Meets GANs: Solving Jigsaw Puzzles with Missing Borders", "abstract": "This paper proposes JiGAN, a GAN-based method for solving Jigsaw puzzles with eroded or missing borders. Missing borders is a common real-world situation, for example, when dealing with the reconstruction of broken artifacts or ruined frescoes. In this particular condition, the puzzle\u2019s pieces do not align perfectly due to the borders\u2019 gaps; in this situation, the patches\u2019 direct match is unfeasible due to the lack of color and line continuations. JiGAN, is a two-steps procedure that tackles this issue: first, we repair the eroded borders with a GAN-based image extension model and measure the alignment affinity between pieces; then, we solve the puzzle with the relaxation labeling algorithm to enforce consistency in pieces positioning, hence, reconstructing the puzzle. We test the method on a large dataset of small puzzles and on three commonly used benchmark datasets to demonstrate the feasibility of the proposed approach."}}
{"id": "koP7jm_Pij", "cdate": 1640995200000, "mdate": 1668991637545, "content": {"title": "Wild Patterns Reloaded: A Survey of Machine Learning Security against Training Data Poisoning", "abstract": "The success of machine learning is fueled by the increasing availability of computing power and large training datasets. The training data is used to learn new models or update existing ones, assuming that it is sufficiently representative of the data that will be encountered at test time. This assumption is challenged by the threat of poisoning, an attack that manipulates the training data to compromise the model's performance at test time. Although poisoning has been acknowledged as a relevant threat in industry applications, and a variety of different attacks and defenses have been proposed so far, a complete systematization and critical review of the field is still missing. In this survey, we provide a comprehensive systematization of poisoning attacks and defenses in machine learning, reviewing more than 100 papers published in the field in the last 15 years. We start by categorizing the current threat models and attacks, and then organize existing defenses accordingly. While we focus mostly on computer-vision applications, we argue that our systematization also encompasses state-of-the-art attacks and defenses for other data modalities. Finally, we discuss existing resources for research in poisoning, and shed light on the current limitations and open research questions in this research field."}}
{"id": "MSaSEj3FD_", "cdate": 1640995200000, "mdate": 1668991637547, "content": {"title": "Geolocation of Cultural Heritage using Multi-View Knowledge Graph Embedding", "abstract": "Knowledge Graphs (KGs) have proven to be a reliable way of structuring data. They can provide a rich source of contextual information about cultural heritage collections. However, cultural heritage KGs are far from being complete. They are often missing important attributes such as geographical location, especially for sculptures and mobile or indoor entities such as paintings. In this paper, we first present a framework for ingesting knowledge about tangible cultural heritage entities from various data sources and their connected multi-hop knowledge into a geolocalized KG. Secondly, we propose a multi-view learning model for estimating the relative distance between a given pair of cultural heritage entities, based on the geographical as well as the knowledge connections of the entities."}}
{"id": "Hvh9KJ8LBhP", "cdate": 1640995200000, "mdate": 1668991637523, "content": {"title": "Relaxation Labeling Meets GANs: Solving Jigsaw Puzzles with Missing Borders", "abstract": "This paper proposes JiGAN, a GAN-based method for solving Jigsaw puzzles with eroded or missing borders. Missing borders is a common real-world situation, for example, when dealing with the reconstruction of broken artifacts or ruined frescoes. In this particular condition, the puzzle's pieces do not align perfectly due to the borders' gaps; in this situation, the patches' direct match is unfeasible due to the lack of color and line continuations. JiGAN, is a two-steps procedure that tackles this issue: first, we repair the eroded borders with a GAN-based image extension model and measure the alignment affinity between pieces; then, we solve the puzzle with the relaxation labeling algorithm to enforce consistency in pieces positioning, hence, reconstructing the puzzle. We test the method on a large dataset of small puzzles and on three commonly used benchmark datasets to demonstrate the feasibility of the proposed approach."}}
{"id": "gYAGNlDfe0", "cdate": 1609459200000, "mdate": 1668991637979, "content": {"title": "Ice Core Science Meets Computer Vision: Challenges and Perspectives", "abstract": "Polar ice cores play a central role in studies of the earth\u2019s climate system through natural archives. A pressing issue is the analysis of the oldest, highly thinned ice core sections, where the identification of paleoclimate signals is particularly challenging. For this, state-of-the-art imaging by laser-ablation inductively-coupled plasma mass spectrometry (LA-ICP-MS) has the potential to be revolutionary due to its combination of micron-scale 2D chemical information with visual features. However, the quantitative study of record preservation in chemical images raises new questions that call for the expertise of the computer vision community. To illustrate this new inter-disciplinary frontier, we describe a selected set of key questions. One critical task is to assess the paleoclimate significance of single line profiles along the main core axis, which we show is a scale-dependent problem for which advanced image analysis methods are critical. Another important issue is the evaluation of post-depositional layer changes, for which the chemical images provide rich information. Accordingly, the time is ripe to begin an intensified exchange between the two scientific communities of computer vision and ice core science. The collaborative building of a new framework for investigating high-resolution chemical images with automated image analysis techniques will also benefit the already wide-spread application of laser-ablation inductively-coupled plasma mass spectrometry chemic..."}}
{"id": "UCNwBG_G9h", "cdate": 1609459200000, "mdate": 1668991637965, "content": {"title": "The Hammer and the Nut: Is Bilevel Optimization Really Needed to Poison Linear Classifiers?", "abstract": "One of the most concerning threats for modern AI systems is data poisoning, where the attacker injects maliciously crafted training data to corrupt the system's behavior at test time. Availability poisoning is a particularly worrisome subset of poisoning attacks where the attacker aims to cause a Denial-of-Service (DoS) attack. However, the state-of-the-art algorithms are computationally expensive because they try to solve a complex bi-level optimization problem (the \u201chammer\u201d). We observed that in particular conditions, namely, where the target model is linear (the \u201cnut\u201d), the usage of computationally costly procedures can be avoided. We propose a counter-intuitive but efficient heuristic that allows contaminating the training set such that the target system's performance is highly compromised. We further suggest a re-parameterization trick to decrease the number of variables to be optimized. Finally, we demonstrate that, under the considered settings, our framework achieves comparable, or even better, performances in terms of the attacker's objective while being significantly more computationally efficient."}}
