{"id": "RV9yuISJKi", "cdate": 1667335545611, "mdate": 1667335545611, "content": {"title": "Learning Energy-Based Models With Adversarial Training", "abstract": "We study a new approach to learning energy-based models (EBMs) based on adversarial training (AT). We show that (binary) AT learns a special kind of energy function that models the support of the data distribution, and the learning process is closely related to MCMC-based maximum likelihood learning of EBMs. We further propose improved techniques for generative modeling with AT, and demonstrate that this new approach is capable of generating diverse and realistic images. Aside from having competitive image generation performance to explicit EBMs, the studied approach is stable to train, is well-suited for image translation tasks, and exhibits strong out-of-distribution adversarial robustness. Our results demonstrate the viability of the AT approach to generative modeling, suggesting that AT is a competitive alternative approach to learning EBMs."}}
{"id": "52ZYBpgwh_u", "cdate": 1609459200000, "mdate": 1667335190656, "content": {"title": "A Pilot Study on Video-based Eye Movement Assessment of the NeuroEye Examination", "abstract": "The ability to perform automated neurological assessment could enhance diagnosis and treatment in the pre-hospital setting such as during telemedicine or emergency medical services (EMS) encounters. In this pilot study we present the preliminary analysis of a video-based eye movement assessment workflow (NeuroGaze) for neurological eye examinations. Our workflow uses a pupil detector to detect the center of the pupil for both eyes for a given video and determine the conjugacy of eye movement. The study evaluated the proposed workflow on 18 healthy volunteers while performing a digitally adapted neurological eye examination (NeuroEye) to assess conjugacy of gaze in all cardinal positions. The NeuroGaze performance was compared to the COTS eye tracker. The video-based eye movement assessment workflow reported an average Pearson correlation coefficient of 0.84, compared to the COTS eye tracker with an average of 0.95. The preliminary analysis indicates that NeuroGaze can be used to determine the individuals ability to perform conjugate eye movements. Future study will assess the performance of NeuroGaze in patients with pathological eye movements."}}
{"id": "PsdsEbzxZWr", "cdate": 1601308105496, "mdate": null, "content": {"title": "Analyzing and Improving Generative Adversarial Training for Generative Modeling and Out-of-Distribution Detection", "abstract": "Generative adversarial training (GAT) is a recently introduced adversarial defense method. Previous works have focused on empirical evaluations of its application to training robust predictive models. In this paper we focus on theoretical understanding of the GAT method and extending its application to generative modeling and out-of-distribution detection. We analyze the optimal solutions of the maximin formulation employed by the GAT objective, and make a comparative analysis of the minimax formulation employed by GANs. We use theoretical analysis and 2D simulations to understand the convergence property of the training algorithm. Based on these results, we develop an unconstrained GAT algorithm, and conduct comprehensive evaluations of the algorithm's application to image generation and adversarial out-of-distribution detection. Our results suggest that generative adversarial training is a promising new direction for the above applications."}}
{"id": "VYb_wiIixYF", "cdate": 1577836800000, "mdate": 1667335190684, "content": {"title": "Radon cumulative distribution transform subspace modeling for image classification", "abstract": "We present a new supervised image classification method applicable to a broad class of image deformation models. The method makes use of the previously described Radon Cumulative Distribution Transform (R-CDT) for image data, whose mathematical properties are exploited to express the image data in a form that is more suitable for machine learning. While certain operations such as translation, scaling, and higher-order transformations are challenging to model in native image space, we show the R-CDT can capture some of these variations and thus render the associated image classification problems easier to solve. The method -- utilizing a nearest-subspace algorithm in R-CDT space -- is simple to implement, non-iterative, has no hyper-parameters to tune, is computationally efficient, label efficient, and provides competitive accuracies to state-of-the-art neural networks for many types of classification problems. In addition to the test accuracy performances, we show improvements (with respect to neural network-based methods) in terms of computational efficiency (it can be implemented without the use of GPUs), number of training samples needed for training, as well as out-of-distribution generalization. The Python code for reproducing our results is available at https://github.com/rohdelab/rcdt_ns_classifier."}}
{"id": "LZE-tZGQCZ", "cdate": 1577836800000, "mdate": 1667335190645, "content": {"title": "Neural Networks, Hypersurfaces, and the Generalized Radon Transform [Lecture Notes]", "abstract": "Artificial neural networks (ANNs) have long been used as a mathematical modeling method and have recently found numerous applications in science and technology, including computer vision, signal processing, and machine learning [1], to name a few. Although notable function approximation results exist [2], theoretical explanations have yet to catch up with newer developments, particularly with regard to (deep) hierarchical learning. As a consequence, numerous doubts often accompany NN practitioners, such as How many layers should one use? What is the effect of different activation functions? What are the effects of pooling? and many others."}}
{"id": "SJeQEp4YDH", "cdate": 1569439019038, "mdate": null, "content": {"title": "GAT: Generative Adversarial Training for Adversarial Example Detection and Robust Classification", "abstract": "The vulnerabilities of deep neural networks against adversarial examples have become a significant concern for deploying these models in sensitive domains. Devising a definitive defense against such attacks is proven to be challenging, and the methods relying on detecting adversarial samples are only valid when the attacker is oblivious to the detection mechanism. In this paper we propose a principled adversarial example detection method that can withstand norm-constrained white-box attacks. Inspired by one-versus-the-rest classification, in a K class classification problem, we train K binary classifiers where the i-th binary classifier is used to distinguish between clean data of class i and adversarially perturbed samples of other classes. At test time, we first use a trained classifier to get the predicted label (say k) of the input, and then use the k-th binary classifier to determine whether the input is a clean sample (of class k) or an adversarially perturbed example (of other classes). We further devise a generative approach to detecting/classifying adversarial examples by interpreting each binary classifier as an unnormalized density model of the class-conditional data. We provide comprehensive evaluation of the above adversarial example detection/classification methods, and demonstrate their competitive performances and compelling properties. Code is available at https://github.com/xuwangyin/GAT-Generative-Adversarial-Training"}}
{"id": "SkWoaQbuZr", "cdate": 1546300800000, "mdate": null, "content": {"title": "Chat-crowd: A Dialog-based Platform for Visual Layout Composition", "abstract": "Paola Cascante-Bonilla, Xuwang Yin, Vicente Ordonez, Song Feng. Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics (Demonstrations). 2019."}}
{"id": "-2OXwVSwdzo", "cdate": 1546300800000, "mdate": 1667335190684, "content": {"title": "Neural Networks, Hypersurfaces, and Radon Transforms", "abstract": "Connections between integration along hypersufaces, Radon transforms, and neural networks are exploited to highlight an integral geometric mathematical interpretation of neural networks. By analyzing the properties of neural networks as operators on probability distributions for observed data, we show that the distribution of outputs for any node in a neural network can be interpreted as a nonlinear projection along hypersurfaces defined by level surfaces over the input data space. We utilize these descriptions to provide new interpretation for phenomena such as nonlinearity, pooling, activation functions, and adversarial examples in neural network-based learning problems."}}
{"id": "SkNH0WG_br", "cdate": 1483228800000, "mdate": null, "content": {"title": "Obj2Text: Generating Visually Descriptive Language from Object Layouts", "abstract": "Generating captions for images is a task that has recently received considerable attention. In this work we focus on caption generation for abstract scenes, or object layouts where the only information provided is a set of objects and their locations. We propose OBJ2TEXT, a sequence-to-sequence model that encodes a set of objects and their locations as an input sequence using an LSTM network, and decodes this representation using an LSTM language model. We show that our model, despite encoding object layouts as a sequence, can represent spatial relationships between objects, and generate descriptions that are globally coherent and semantically relevant. We test our approach in a task of object-layout captioning by using only object annotations as inputs. We additionally show that our model, combined with a state-of-the-art object detector, improves an image captioning model from 0.863 to 0.950 (CIDEr score) in the test benchmark of the standard MS-COCO Captioning task."}}
{"id": "BQCPWuElOTB", "cdate": 1388534400000, "mdate": null, "content": {"title": "Robust Text Detection in Natural Scene Images.", "abstract": "Text detection in natural scene images is an important prerequisite for many content-based image analysis tasks. In this paper, we propose an accurate and robust method for detecting texts in natural scene images. A fast and effective pruning algorithm is designed to extract Maximally Stable Extremal Regions (MSERs) as character candidates using the strategy of minimizing regularized variations. Character candidates are grouped into text candidates by the single-link clustering algorithm, where distance weights and clustering threshold are learned automatically by a novel self-training distance metric learning algorithm. The posterior probabilities of text candidates corresponding to non-text are estimated with a character classifier; text candidates with high non-text probabilities are eliminated and texts are identified with a text classifier. The proposed system is evaluated on the ICDAR 2011 Robust Reading Competition database; the f-measure is over 76%, much better than the state-of-the-art performance of 71%. Experiments on multilingual, street view, multi-orientation and even born-digital databases also demonstrate the effectiveness of the proposed method."}}
