{"id": "fG-S2MhhteI", "cdate": 1672531200000, "mdate": 1682760951204, "content": {"title": "Hierarchical Explanations for Video Action Recognition", "abstract": "To interpret deep neural networks, one main approach is to dissect the visual input and find the prototypical parts responsible for the classification. However, existing methods often ignore the hierarchical relationship between these prototypes, and thus can not explain semantic concepts at both higher level (e.g., water sports) and lower level (e.g., swimming). In this paper inspired by human cognition system, we leverage hierarchal information to deal with uncertainty: When we observe water and human activity, but no definitive action it can be recognized as the water sports parent class. Only after observing a person swimming can we definitively refine it to the swimming action. To this end, we propose HIerarchical Prototype Explainer (HIPE) to build hierarchical relations between prototypes and classes. HIPE enables a reasoning process for video action classification by dissecting the input video frames on multiple levels of the class hierarchy, our method is also applicable to other video tasks. The faithfulness of our method is verified by reducing accuracy-explainability trade off on ActivityNet and UCF-101 while providing multi-level explanations."}}
{"id": "cK9V8mBhWas", "cdate": 1672531200000, "mdate": 1707065823586, "content": {"title": "Cross-modal Scalable Hyperbolic Hierarchical Clustering", "abstract": "Hierarchical clustering is a natural approach to discover ontologies from data. Yet, existing approaches are hampered by their inability to scale to large datasets and the discrete encoding of the hierarchy. We introduce scalable Hyperbolic Hierarchical Clustering (sHHC) which overcomes these limitations by learning continuous hierarchies in hyperbolic space. Our hierarchical clustering is of high quality and can be obtained in a fraction of the runtime.Additionally, we demonstrate the strength of sHHC on a downstream cross-modal self-supervision task. By using the discovered hierarchies from sound and vision to construct continuous hierarchical pseudo-labels we can efficiently optimize a network for activity recognition and obtain competitive performance compared to recent self-supervised learning models. Our findings demonstrate the strength of Hyperbolic Hierarchical Clustering and its potential for Self-Supervised Learning."}}
{"id": "BoCh7ffis08", "cdate": 1672531200000, "mdate": 1699283614945, "content": {"title": "Hierarchical Explanations for Video Action Recognition", "abstract": "To interpret deep neural networks, one main approach is to dissect the visual input and find the prototypical parts responsible for the classification. However, existing methods often ignore the hierarchical relationship between these prototypes, and thus can not explain semantic concepts at both higher level (e.g., water sports) and lower level (e.g., swimming). In this paper inspired by human cognition system, we leverage hierarchal information to deal with uncertainty. To this end, we propose HIerarchical Prototype Explainer (HIPE) to build hierarchical relations between prototypes and classes. The faithfulness of our method is verified by reducing accuracy-explainability trade-off on UCF-101 while providing multi-level explanations."}}
{"id": "NnPFjavcRXt", "cdate": 1609459200000, "mdate": 1682760951186, "content": {"title": "Point-Based Weakly Supervised Learning for Object Detection in High Spatial Resolution Remote Sensing Images", "abstract": "Object detection is challenging in high spatial resolution (HSR) remote sensing images that have a complex background and irregular object locations. To minimize manual annotation cost in supervised learning methods and achieve advanced detection performance, we proposed a point-based weakly supervised learning method to address the object detection challenge in HSR remote sensing images. In the study, point labels are introduced to guide candidate bounding box mining and generate pseudobounding boxes for objects. Then, pseudobounding boxes are applied to train the detection model. A progressive candidate bounding box mining strategy is proposed to refine object detection. Experiments are conducted on a comprehensive HSR dataset which contains four categories. Results indicate the proposed method achieves competitive performance compared to YOLOv5 which is trained on manual bounding box annotations. In comparison to the state-of-the-art weakly supervised learning method, our method outperforms WSDDN method with 0.62 mean average precision score."}}
{"id": "4Qxcz9DFnf-", "cdate": 1577836800000, "mdate": null, "content": {"title": "Searching for Actions on the Hyperbole", "abstract": "In this paper, we introduce hierarchical action search. Starting from the observation that hierarchies are mostly ignored in the action literature, we retrieve not only individual actions but also relevant and related actions, given an action name or video example as input. We propose a hyperbolic action network, which is centered around a hyperbolic space shared by action hierarchies and videos. Our discriminative hyperbolic embedding projects actions on the shared space while jointly optimizing hypernym-hyponym relations between action pairs and a large margin separation between all actions. The projected actions serve as hyperbolic prototypes that we match with projected video representations. The result is a learned space where videos are positioned in entailment cones formed by different subtrees. To perform search in this space, we start from a query and increasingly enlarge its entailment cone to retrieve hierarchically relevant action videos. Experiments on three action datasets with new hierarchy annotations show the effectiveness of our approach for hierarchical action search by name and by video example, regardless of whether queried actions have been seen or not during training. Our implementation is available at https://github.com/Tenglon/hyperbolic_action."}}
{"id": "pdTruMDr9A", "cdate": 1514764800000, "mdate": 1668013963223, "content": {"title": "Zero-shot learning via discriminative representation extraction", "abstract": ""}}
{"id": "hETjduPJuHd", "cdate": 1514764800000, "mdate": 1682760951174, "content": {"title": "Semi-Supervised Remote Sensing Classification Via Associative Transfer", "abstract": "Images classification is an essential field in remote sensing community. However, a variety of target shapes, as well as changing conditions during multiple time periods and different areas usually result in shifts in classification. This problem can affect classification results seriously. Although the affection is significant in remote sensing classification, very few people have considered this issue, and have solved it. In this paper, we introduce the associative domain adaptation (ADA) method to address this challenge. We apply this algorithm to two public remote sensing datasets. One is famous UC Merced dataset; another is NWPU-RESISC45 dataset which has a much more variance within the class. We then build a classification model by using UC Merced training images and labels as well as using training images from NWPU-RESISC45. This semi-supervised classification performance achieves an impressive test accuracy on the NWPU-RESISC45 test dataset."}}
{"id": "KrekKEnLn_c", "cdate": 1514764800000, "mdate": 1682760951194, "content": {"title": "Pseudo Transfer with Marginalized Corrupted Attribute for Zero-shot Learning", "abstract": "Zero-shot learning (ZSL) aims to recognize unseen classes that are excluded from training classes. ZSL suffers from 1) Zero-shot bias (Z-Bias) --- model is biased towards seen classes because unseen data is inaccessible for training; 2) Zero-shot variance (Z-Variance) --- associating different images to same semantic embedding yields large associating error. To reduce Z-Bias, we propose a pseudo transfer mechanism, where we first synthesize the distribution of unseen data using semantic embeddings, then we minimize the mismatch between the seen distribution and the synthesized unseen distribution. To reduce Z-Variance, we implicitly corrupted one semantic embedding multiple times to generate image-wise semantic vectors, with which our model learn robust classifiers. Lastly, we integrate our Z-Bias and Z-variance reduction techniques with a linear ZSL model to show its usefulness. Our proposed model successfully overcomes the Z-bias and Z-variance problems. Extensive experiments on five benchmark datasets including ImageNet-1K demonstrate that our model outperforms the state-of-the-art methods with fast training."}}
{"id": "u_XunCDKCy", "cdate": 1483228800000, "mdate": 1682760951189, "content": {"title": "Evaluation the performance of fully convolutional networks for building extraction compared with shallow models", "abstract": "With the development of machine learning, many researchers have used machine learning models for building extraction in high resolution remote sensing images. Especially for the recently proposed deep learning models, it has been widely used for building detection in the urban monitoring. In this study, the performances of images segmentation for building extraction based on Fully Convolutional Networks (FCN) model and shallow models are qualitatively and quantitatively compared. Firstly, the public aerial dataset of Massachusetts building dataset[1] are preprocessed to extract features. Then, we trained shallow models and deep model on Massachusetts building dataset. Moreover, the trained FCN model and shallow models are used to extract the building on the same image. Finally, we compared performances between shallow models and deep model. It is found that FCN gives the highest recall 0.63, precision 0.62, and F-measure rate 0.63. The qualitative and quantitative analysis of the building extraction results fully demonstrates that FCN gives the best performance compared with traditional shallow models."}}
