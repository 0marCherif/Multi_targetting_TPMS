{"id": "Sh97TNO5YY_", "cdate": 1663850136905, "mdate": null, "content": {"title": "Biases in Evaluation of Molecular Optimization Methods and Bias Reduction Strategies", "abstract": "We are interested in in silico evaluation methodology for molecular optimization methods. Given a sample of molecules and their properties of our interest, we wish not only to train a generator of molecules that can find those optimized with respect to a target property but also to evaluate its performance accurately. A common practice is to train a predictor of the target property on the sample and use it for both training and evaluating the generator. We theoretically investigate this evaluation methodology and show that it potentially suffers from two biases; one is due to misspecification of the predictor and the other to reusing the same sample for training and evaluation. We discuss bias reduction methods for each of the biases, and empirically investigate their effectiveness.\n"}}
{"id": "cwf7nnoK5o", "cdate": 1663850083456, "mdate": null, "content": {"title": "Interval-based Offline Policy Evaluation without Sufficient Exploration or Realizability", "abstract": "We study the problem of offline policy evaluation (OPE),\nwhere the goal is to estimate the value of given decision-making policy without interacting with the actual environment.\nIn particular, we consider the interval-based OPE, where the output is an interval rather than a point, indicating the uncertainty of the evaluation.\nThe interval-based estimation is especially important in OPE since, \nwhen the data coverage is insufficient relative to the complexity of the environmental model,\nany OPE method can be biased even with infinite sample size.\nIn this paper, we characterize the worst case of such irreducible bias, called the *minimax bias*, in terms of the discrepancy between the target policy and the data-sampling distribution,\nand show that the marginal-importance-sampling (MIS) estimator achieves the minimax bias with an appropriate importance-weight function.\nMotivated with this result, we then propose a new interval-based MIS estimator that asymptotically achieves the minimax bias."}}
{"id": "jbYn_X-Jj9f", "cdate": 1609459200000, "mdate": 1623583917422, "content": {"title": "A Differentiable Point Process with Its Application to Spiking Neural Networks", "abstract": "This paper is concerned about a learning algorithm for a probabilistic model of spiking neural networks (SNNs). Jimenez Rezende & Gerstner (2014) proposed a stochastic variational inference algorithm to train SNNs with hidden neurons. The algorithm updates the variational distribution using the score function gradient estimator, whose high variance often impedes the whole learning algorithm. This paper presents an alternative gradient estimator for SNNs based on the path-wise gradient estimator. The main technical difficulty is a lack of a general method to differentiate a realization of an arbitrary point process, which is necessary to derive the path-wise gradient estimator. We develop a differentiable point process, which is the technical highlight of this paper, and apply it to derive the path-wise gradient estimator for SNNs. We investigate the effectiveness of our gradient estimator through numerical simulation."}}
{"id": "kAZrdOk4tWO", "cdate": 1546300800000, "mdate": 1623583945066, "content": {"title": "Towards Stable Symbol Grounding with Zero-Suppressed State AutoEncoder", "abstract": "While classical planning has been an active branch of AI, its applicability is limited to the tasks precisely modeled by humans. Fully automated high-level agents should be instead able to find a symbolic representation of an unknown environment without supervision, otherwise it exhibits the knowledge acquisition bottleneck. Meanwhile, Latplan (Asai and Fukunaga 2018) partially resolves the bottleneck with a neural network called State AutoEncoder (SAE). SAE obtains the propositional representation of the image-based puzzle domains with unsupervised learning, generates a state space and performs classical planning. In this paper, we identify the problematic, stochastic behavior of the SAE-produced propositions as a new sub-problem of symbol grounding problem, the symbol stability problem. Informally, symbols are stable when their referents (e.g. propositional values) do not change against small perturbation of the observation, and unstable symbols are harmful for symbolic reasoning. We analyze the problem in Latplan both formally and empirically, and propose \u201cZero-Suppressed SAE\u201d, an enhancement that stabilizes the propositions using the idea of closed-world assumption as a prior for NN optimization. We show that it finds the more stable propositions and the more compact representations, resulting in an improved success rate of Latplan. It is robust against various hyperparameters and eases the tuning effort, and also provides a weight pruning capability as a side effect."}}
{"id": "SXVqIT-lOTr", "cdate": 1546300800000, "mdate": null, "content": {"title": "Cogra: Concept-Drift-Aware Stochastic Gradient Descent for Time-Series Forecasting.", "abstract": "We approach the time-series forecasting problem in the presence of concept drift by automatic learning rate tuning of stochastic gradient descent (SGD). The SGD-based approach is preferable to other concept drift algorithms in that it can be applied to any model and it can keep learning efficiently whilst predicting online. Among a number of SGD algorithms, the variance-based SGD (vSGD) can successfully handle concept drift by automatic learning rate tuning, which is reduced to an adaptive mean estimation problem. However, its performance is still limited because of its heuristic mean estimator. In this paper, we present a concept-drift-aware stochastic gradient descent (Cogra), equipped with more theoretically-sound mean estimator called sequential mean tracker (SMT). Our key contribution is that we define a goodness criterion for the mean estimators; SMT is designed to be optimal according to this criterion. As a result of comprehensive experiments, we find that (i) our SMT can estimate the mean better than vSGD\u2019s estimator in the presence of concept drift, and (ii) in terms of predictive performance, Cogra reduces the predictive loss by 16\u201367% for real-world datasets, indicating that SMT improves the prediction accuracy significantly."}}
{"id": "L5IQlN_QPUX", "cdate": 1546300800000, "mdate": 1623583945080, "content": {"title": "Towards Stable Symbol Grounding with Zero-Suppressed State AutoEncoder", "abstract": "While classical planning has been an active branch of AI, its applicability is limited to the tasks precisely modeled by humans. Fully automated high-level agents should be instead able to find a symbolic representation of an unknown environment without supervision, otherwise it exhibits the knowledge acquisition bottleneck. Meanwhile, Latplan (Asai and Fukunaga 2018) partially resolves the bottleneck with a neural network called State AutoEncoder (SAE). SAE obtains the propositional representation of the image-based puzzle domains with unsupervised learning, generates a state space and performs classical planning. In this paper, we identify the problematic, stochastic behavior of the SAE-produced propositions as a new sub-problem of symbol grounding problem, the symbol stability problem. Informally, symbols are stable when their referents (e.g. propositional values) do not change against small perturbation of the observation, and unstable symbols are harmful for symbolic reasoning. We analyze the problem in Latplan both formally and empirically, and propose \"Zero-Suppressed SAE\", an enhancement that stabilizes the propositions using the idea of closed-world assumption as a prior for NN optimization. We show that it finds the more stable propositions and the more compact representations, resulting in an improved success rate of Latplan. It is robust against various hyperparameters and eases the tuning effort, and also provides a weight pruning capability as a side effect."}}
{"id": "HkbcxhZdbB", "cdate": 1546300800000, "mdate": null, "content": {"title": "Molecular Hypergraph Grammar with Its Application to Molecular Optimization", "abstract": "Molecular optimization aims to discover novel molecules with desirable properties, and its two fundamental challenges are: (i) it is not trivial to generate valid molecules in a controllable way du..."}}
{"id": "SkcLNJJwf", "cdate": 1518429266416, "mdate": null, "content": {"title": "Neuron as an Agent", "abstract": "Existing multi-agent reinforcement learning (MARL) communication methods have relied on a trusted third party (TTP) to distribute reward to agents, leaving them inapplicable in peer-to-peer environments. This paper proposes reward distribution using {\\em Neuron as an Agent} (NaaA) in MARL without a TTP with two key ideas: (i) inter-agent reward distribution and (ii) auction theory. Auction theory is introduced because inter-agent reward distribution is insufficient for optimization. Agents in NaaA maximize their profits (the difference between reward and cost) and, as a theoretical result, the auction mechanism is shown to have agents autonomously evaluate counterfactual returns as the values of other agents. NaaA enables representation trades in peer-to-peer environments, ultimately regarding unit in neural networks as agents. Finally, numerical experiments (a single-agent environment from OpenAI Gym and a multi-agent environment from ViZDoom) confirm that NaaA framework optimization leads to better performance in reinforcement learning."}}
{"id": "a-tTTczfZeK", "cdate": 1514764800000, "mdate": 1623583945036, "content": {"title": "Safe Exploration in Markov Decision Processes with Time-Variant Safety using Spatio-Temporal Gaussian Process", "abstract": "In many real-world applications (e.g., planetary exploration, robot navigation), an autonomous agent must be able to explore a space with guaranteed safety. Most safe exploration algorithms in the field of reinforcement learning and robotics have been based on the assumption that the safety features are a priori known and time-invariant. This paper presents a learning algorithm called ST-SafeMDP for exploring Markov decision processes (MDPs) that is based on the assumption that the safety features are a priori unknown and time-variant. In this setting, the agent explores MDPs while constraining the probability of entering unsafe states defined by a safety function being below a threshold. The unknown and time-variant safety values are modeled using a spatio-temporal Gaussian process. However, there remains an issue that an agent may have no viable action in a shrinking true safe space. To address this issue, we formulate a problem maximizing the cumulative number of safe states in the worst case scenario with respect to future observations. The effectiveness of this approach was demonstrated in two simulation settings, including one using real lunar terrain data."}}
{"id": "x7oJZ81i-2N", "cdate": 1483228800000, "mdate": 1623583945099, "content": {"title": "Link Prediction in Sparse Networks by Incidence Matrix Factorization", "abstract": "Link prediction plays an important role in multiple areas of artificial intelligence, including social network analysis and bioinformatics; however, i \u2026"}}
