{"id": "9y_Gzg-0tQ", "cdate": 1672531200000, "mdate": 1682320333700, "content": {"title": "Harmonizing Base and Novel Classes: A Class-Contrastive Approach for Generalized Few-Shot Segmentation", "abstract": "Current methods for few-shot segmentation (FSSeg) have mainly focused on improving the performance of novel classes while neglecting the performance of base classes. To overcome this limitation, the task of generalized few-shot semantic segmentation (GFSSeg) has been introduced, aiming to predict segmentation masks for both base and novel classes. However, the current prototype-based methods do not explicitly consider the relationship between base and novel classes when updating prototypes, leading to a limited performance in identifying true categories. To address this challenge, we propose a class contrastive loss and a class relationship loss to regulate prototype updates and encourage a large distance between prototypes from different classes, thus distinguishing the classes from each other while maintaining the performance of the base classes. Our proposed approach achieves new state-of-the-art performance for the generalized few-shot segmentation task on PASCAL VOC and MS COCO datasets."}}
{"id": "ueSz5PRoPA-", "cdate": 1663849912228, "mdate": null, "content": {"title": "Physics-Regularized Stereo Matching for Depth Estimation", "abstract": "Depth estimation from stereo or multi-view images is an essential technology for a wide range of vision and robotics applications. In recent years, many deep learning based methods have been proposed for this purpose. However, training the stereo matching network is challenging and requires a large amount of data, especially for the 3D convolution networks. Existing stereo matching approaches are mostly data-driven, which often converge to a local minimum biased to the training data. In this paper, we propose a novel self-supervised physics regularization framework to improve the training of the networks using physical knowledge or constraints. More specifically, we explore the use of low-level structures as physical constraints for the regularization of the stereo-matching network via multi-task learning. Moreover, a disparity aggregation module is proposed to aggregate the disparity output with image features to consider the association in between. We also find that the canny edge can be used as a pseudo ground truth to train the network with performance comparable to the ideal ground truth edge in the Scene Flow dataset. We combine the proposed physics regularization with four existing stereo matching algorithms. The experimental results in three public datasets, including Scene Flow, KITTI 2012, and KITTI 2015, show the effectiveness and generality of the proposed framework. "}}
{"id": "d31RKRpVf4O", "cdate": 1640995200000, "mdate": 1667464126008, "content": {"title": "Long-tailed Recognition by Learning from Latent Categories", "abstract": "In this work, we address the challenging task of long-tailed image recognition. Previous long-tailed recognition methods commonly focus on the data augmentation or re-balancing strategy of the tail classes to give more attention to tail classes during the model training. However, due to the limited training images for tail classes, the diversity of tail class images is still restricted, which results in poor feature representations. In this work, we hypothesize that common latent features among the head and tail classes can be used to give better feature representation. Motivated by this, we introduce a Latent Categories based long-tail Recognition (LCReg) method. Specifically, we propose to learn a set of class-agnostic latent features shared among the head and tail classes. Then, we implicitly enrich the training sample diversity via applying semantic data augmentation to the latent features. Extensive experiments on five long-tailed image recognition datasets demonstrate that our proposed LCReg is able to significantly outperform previous methods and achieve state-of-the-art results."}}
{"id": "PMMqLRcsul", "cdate": 1640995200000, "mdate": 1682320333686, "content": {"title": "CRCNet: Few-shot Segmentation with Cross-Reference and Region-Global Conditional Networks", "abstract": "Few-shot segmentation aims to learn a segmentation model that can be generalized to novel classes with only a few training images. In this paper, we propose a Cross-Reference and Local-Global Conditional Networks (CRCNet) for few-shot segmentation. Unlike previous works that only predict the query image's mask, our proposed model concurrently makes predictions for both the support image and the query image. Our network can better find the co-occurrent objects in the two images with a cross-reference mechanism, thus helping the few-shot segmentation task. To further improve feature comparison, we develop a local-global conditional module to capture both global and local relations. We also develop a mask refinement module to refine the prediction of the foreground regions recurrently. Experiments on the PASCAL VOC 2012, MS COCO, and FSS-1000 datasets show that our network achieves new state-of-the-art performance."}}
{"id": "NTlojuA1Ud", "cdate": 1640995200000, "mdate": 1667464126010, "content": {"title": "Distilling Knowledge from Object Classification to Aesthetics Assessment", "abstract": "In this work, we point out that the major dilemma of image aesthetics assessment (IAA) comes from the abstract nature of aesthetic labels. That is, a vast variety of distinct contents can correspond to the same aesthetic label. On the one hand, during inference, the IAA model is required to relate various distinct contents to the same aesthetic label. On the other hand, when training, it would be hard for the IAA model to learn to distinguish different contents merely with the supervision from aesthetic labels, since aesthetic labels are not directly related to any specific content. To deal with this dilemma, we propose to distill knowledge on semantic patterns for a vast variety of image contents from multiple pre-trained object classification (POC) models to an IAA model. Expecting the combination of multiple POC models can provide sufficient knowledge on various image contents, the IAA model can easier learn to relate various distinct contents to a limited number of aesthetic labels. By supervising an end-to-end single-backbone IAA model with the distilled knowledge, the performance of the IAA model is significantly improved by 4.8% in SRCC compared to the version trained only with ground-truth aesthetic labels. On specific categories of images, the SRCC improvement brought by the proposed method can achieve up to 7.2%. Peer comparison also shows that our method outperforms 10 previous IAA methods."}}
{"id": "A2SwthA_tg", "cdate": 1640995200000, "mdate": 1682320333750, "content": {"title": "Distilling Knowledge From Object Classification to Aesthetics Assessment", "abstract": "In this work, we point out that the major dilemma of image aesthetics assessment (IAA) comes from the abstract nature of aesthetic labels. That is, a vast variety of distinct contents can correspond to the same aesthetic label. On the one hand, during inference, the IAA model is required to relate various distinct contents to the same aesthetic label. On the other hand, when training, it would be hard for the IAA model to learn to distinguish different contents merely with the supervision from aesthetic labels, since aesthetic labels are not directly related to any specific content. To deal with this dilemma, we propose to distill knowledge on semantic patterns for a vast variety of image contents from multiple pre-trained object classification (POC) models to an IAA model. Expecting the combination of multiple POC models can provide sufficient knowledge on various image contents, the IAA model can easier learn to relate various distinct contents to a limited number of aesthetic labels. By supervising an end-to-end single-backbone IAA model with the distilled knowledge, the performance of the IAA model is significantly improved by 4.8% in SRCC compared to the version trained only with ground-truth aesthetic labels. On specific categories of images, the SRCC improvement brought by the proposed method can achieve up to 7.2%. Peer comparison also shows that our method outperforms 10 previous IAA methods."}}
{"id": "1DLl_cJ2Gv", "cdate": 1640995200000, "mdate": 1682320333779, "content": {"title": "CRCNet: Few-Shot Segmentation with Cross-Reference and Region-Global Conditional Networks", "abstract": "Few-shot segmentation aims to learn a segmentation model that can be generalized to novel classes with only a few training images. In this paper, we propose a Cross-Reference and Local\u2013Global Conditional Networks (CRCNet) for few-shot segmentation. Unlike previous works that only predict the query image\u2019s mask, our proposed model concurrently makes predictions for both the support image and the query image. Our network can better find the co-occurrent objects in the two images with a cross-reference mechanism, thus helping the few-shot segmentation task. To further improve feature comparison, we develop a local-global conditional module to capture both global and local relations. We also develop a mask refinement module to refine the prediction of the foreground regions recurrently. Experiments on the PASCAL VOC 2012, MS COCO, and FSS-1000 datasets show that our network achieves new state-of-the-art performance."}}
{"id": "g9B7h9gycMg", "cdate": 1632875421494, "mdate": null, "content": {"title": "LONG-TAILED RECOGNITION BY LEARNING FROM LATENT CATEGORIES", "abstract": "In this work, we address the challenging task of long-tailed recognition. Previous long-tailed recognition methods commonly focus on data augmentation of tailed classes or re-balancing strategy to give more attention to tailed classes during training. However, due to the limited training images for tailed classes, the diversity of augmented images are still restricted, which results in poor feature representations.  In this work, we argue that there are common latent features between the head and tailed classes that can be used to give better feature representation. We propose to learn a set of semantic and class-agnostic latent features shared by the head and tailed classes. Then, we implicitly enrich the training sample diversity via leveraging semantic data augmentation for the commonality features. We evaluate our methods on several popular long-tailed datasets and achieve new state-of-the-art performance consistently."}}
{"id": "zlDA1Ruj5xn", "cdate": 1609459200000, "mdate": 1668673904159, "content": {"title": "Cross-Image Region Mining with Region Prototypical Network for Weakly Supervised Segmentation", "abstract": "Weakly supervised image segmentation trained with image-level labels usually suffers from inaccurate coverage of object areas during the generation of the pseudo groundtruth. This is because the object activation maps are trained with the classification objective and lack the ability to generalize. To improve the generality of the objective activation maps, we propose a region prototypical network RPNet to explore the cross-image object diversity of the training set. Similar object parts across images are identified via region feature comparison. Object confidence is propagated between regions to discover new object areas while background regions are suppressed. Experiments show that the proposed method generates more complete and accurate pseudo object masks, while achieving state-of-the-art performance on PASCAL VOC 2012 and MS COCO. In addition, we investigate the robustness of the proposed method on reduced training sets."}}
{"id": "sbyYChAVlp", "cdate": 1609459200000, "mdate": 1667464126277, "content": {"title": "Few-Shot Segmentation with Global and Local Contrastive Learning", "abstract": "In this work, we address the challenging task of few-shot segmentation. Previous few-shot segmentation methods mainly employ the information of support images as guidance for query image segmentation. Although some works propose to build cross-reference between support and query images, their extraction of query information still depends on the support images. We here propose to extract the information from the query itself independently to benefit the few-shot segmentation task. To this end, we first propose a prior extractor to learn the query information from the unlabeled images with our proposed global-local contrastive learning. Then, we extract a set of predetermined priors via this prior extractor. With the obtained priors, we generate the prior region maps for query images, which locate the objects, as guidance to perform cross interaction with support features. In such a way, the extraction of query information is detached from the support branch, overcoming the limitation by support, and could obtain more informative query clues to achieve better interaction. Without bells and whistles, the proposed approach achieves new state-of-the-art performance for the few-shot segmentation task on PASCAL-5$^{i}$ and COCO datasets."}}
