{"id": "ltyCx9gEUL", "cdate": 1672531200000, "mdate": 1695949059863, "content": {"title": "Making individually fair predictions with causal pathways", "abstract": "Machine learning is being increasingly used to make algorithmic decisions that have strong societal impact on people\u2019s lives. Due to their huge societal impact, such algorithmic decisions need to be accurate and fair with respect to sensitive features, including race, gender, religion, and sexual orientation. To achieve a good balance between prediction accuracy and fairness, causality-based methods have been proposed, which utilize a causal graph with unfair pathways. However, none of these methods can ensure fairness for each individual without making restrictive functional assumptions about the data generating processes, which are not satisfied in many cases. In this paper, we propose a far more practical causality-based framework for learning an individually fair classifier. To avoid impractical functional assumptions, we introduce a new criterion, the probability of individual unfairness, and derive its upper bound that can be estimated from data. We then train a classifier by solving an optimization problem where the upper bound value is forced to be close to zero. We elucidate why solving such an optimization problem can guarantee fairness for each individual. Moreover, we provide two extensions for dealing with challenging real-world scenarios where there are unobserved variables called latent confounders, and the true causal graph is uncertain. Experimental results show that our method can learn an individually fair classifier at a slight cost of prediction accuracy."}}
{"id": "fzB_S75duF3", "cdate": 1672531200000, "mdate": 1704982687937, "content": {"title": "Uncertainty Quantification in Heterogeneous Treatment Effect Estimation with Gaussian-Process-Based Partially Linear Model", "abstract": "Estimating heterogeneous treatment effects across individuals has attracted growing attention as a statistical tool for performing critical decision-making. We propose a Bayesian inference framework that quantifies the uncertainty in treatment effect estimation to support decision-making in a relatively small sample size setting. Our proposed model places Gaussian process priors on the nonparametric components of a semiparametric model called a partially linear model. This model formulation has three advantages. First, we can analytically compute the posterior distribution of a treatment effect without relying on the computationally demanding posterior approximation. Second, we can guarantee that the posterior distribution concentrates around the true one as the sample size goes to infinity. Third, we can incorporate prior knowledge about a treatment effect into the prior distribution, improving the estimation efficiency. Our experimental results show that even in the small sample size setting, our method can accurately estimate the heterogeneous treatment effects and effectively quantify its estimation uncertainty."}}
{"id": "02U3YYGjCM4", "cdate": 1672531200000, "mdate": 1695949059860, "content": {"title": "Meta-learning for heterogeneous treatment effect estimation with closed-form solvers", "abstract": "This article proposes a meta-learning method for estimating the conditional average treatment effect (CATE) from a few observational data. The proposed method learns how to estimate CATEs from multiple tasks and uses the knowledge for unseen tasks. In the proposed method, based on the meta-learner framework, we decompose the CATE estimation problem into sub-problems. For each sub-problem, we formulate our estimation models using neural networks with task-shared and task-specific parameters. With our formulation, we can obtain optimal task-specific parameters in a closed form that are differentiable with respect to task-shared parameters, making it possible to perform effective meta-learning. The task-shared parameters are trained such that the expected CATE estimation performance in few-shot settings is improved by minimizing the difference between a CATE estimated with a large amount of data and one estimated with just a few data. Our experimental results demonstrate that our method outperforms the existing meta-learning approaches and CATE estimation methods."}}
{"id": "HhGMxUUo5lc", "cdate": 1646077511716, "mdate": null, "content": {"title": "Feature Selection for Discovering Distributional Treatment Effect Modifiers", "abstract": "Finding the features relevant to the difference in treatment effects is essential to unveil underlying causal mechanisms. Existing methods seek such features by measuring how greatly the feature attributes affect the degree of the {\\it conditional average treatment effect} (CATE). However, these methods may overlook important features because CATE, a measure of an average treatment effect, cannot detect the difference of other distribution parameters than the mean (e.g., variance). In this paper, we propose a feature selection framework for discovering {\\it distributional treatment effect modifiers}. To resolve the weakness of the existing methods, we formulate a feature importance measure that quantifies how strongly the feature attributes influence the discrepancy between potential outcome distributions. We derive its computationally efficient estimator and develop a feature selection algorithm that can control the type I error rate at some desired level. Experimental results show that our framework successfully discovers important features and outperforms the existing mean-based method."}}
{"id": "b1UzdmyTni9", "cdate": 1640995200000, "mdate": 1681714410351, "content": {"title": "Feature selection for discovering distributional treatment effect modifiers", "abstract": "Finding the features relevant to the difference in treatment effects is essential to unveil the underlying causal mechanisms. Existing methods seek such features by measuring how greatly the feature attributes affect the degree of the {\\it conditional average treatment effect} (CATE). However, these methods may overlook important features because CATE, a measure of the average treatment effect, cannot detect differences in distribution parameters other than the mean (e.g., variance). To resolve this weakness of existing methods, we propose a feature selection framework for discovering {\\it distributional treatment effect modifiers}. We first formulate a feature importance measure that quantifies how strongly the feature attributes influence the discrepancy between potential outcome distributions. Then we derive its computationally efficient estimator and develop a feature selection algorithm that can control the type I error rate to the desired level. Experimental results show that our framework successfully discovers important features and outperforms the existing mean-based method."}}
{"id": "HHl-Tl_xLe5", "cdate": 1609459200000, "mdate": 1645770741275, "content": {"title": "Learning Individually Fair Classifier with Path-Specific Causal-Effect Constraint", "abstract": "Machine learning is used to make decisions for individuals in various fields, which require us to achieve good prediction accuracy while ensuring fairness with respect to sensitive features (e.g., race and gender). This problem, however, remains difficult in complex real-world scenarios. To quantify unfairness under such situations, existing methods utilize path-specific causal effects. However, none of them can ensure fairness for each individual without making impractical functional assumptions about the data. In this paper, we propose a far more practical framework for learning an individually fair classifier. To avoid restrictive functional assumptions, we define the probability of individual unfairness (PIU) and solve an optimization problem where PIU\u2019s upper bound, which can be estimated from data, is controlled to be close to zero. We elucidate why our method can guarantee fairness for each individual. Experimental results show that our method can learn an individually fair classifier at a slight cost of accuracy."}}
{"id": "rJZUyNGuWB", "cdate": 1514764800000, "mdate": null, "content": {"title": "Causal Inference in Time Series via Supervised Learning", "abstract": "Causal inference in time series is an important problem in many fields. Traditional methods use regression models for this problem. The inference accuracies of these methods depend greatly on whether or not the model can be well fitted to the data, and therefore we are required to select an appropriate regression model, which is difficult in practice. This paper proposes a supervised learning framework that utilizes a classifier instead of regression models. We present a feature representation that employs the distance between the conditional distributions given past variable values and show experimentally that the feature representation provides sufficiently different feature vectors for time series with different causal relationships. Furthermore, we extend our framework to multivariate time series and present experimental results where our method outperformed the model-based methods and the supervised learning method for i.i.d. data."}}
{"id": "SNxbpgOlUlq", "cdate": 1356998400000, "mdate": 1645770741265, "content": {"title": "LibSBMLSim: a reference implementation of fully functional SBML simulator", "abstract": "The Systems Biology Markup Language (SBML) is currently supported by >230 software tools, among which 160 support numerical integration of ordinary differential equation (ODE) models. Although SBML is a widely accepted standard within this field, there is still no language-neutral library that supports all features of SBML for simulating ODE models. Therefore, a demand exists for a simple portable implementation of a numerical integrator that supports SBML to enhance the development of a computational platform for systems biology."}}
