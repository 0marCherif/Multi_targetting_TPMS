{"id": "ZYvzqFmTJS", "cdate": 1668637204075, "mdate": 1668637204075, "content": {"title": "Online Adaptation for Implicit Object Tracking and Shape Reconstruction in the Wild", "abstract": "Tracking and reconstructing 3D objects from cluttered scenes are the key components for computer vision, robotics and autonomous driving systems. While recent progress in implicit function has shown encouraging results on high-quality 3D shape reconstruction, it is still very challenging to generalize to cluttered and partially observable LiDAR data. In this paper, we propose to leverage the continuity in video data. We introduce a novel and unified framework which utilizes a neural implicit function to simultaneously track and reconstruct 3D objects in the wild. Our approach adapts the DeepSDF model (i.e., an instantiation of the implicit function) in the video online, iteratively improving the shape reconstruction while in return improving the tracking, and vice versa. We experiment with both Waymo and KITTI datasets and show significant improvements over state-of-the-art methods for both tracking and shape reconstruction tasks. Our project page is at https://jianglongye.com/implicit-tracking ."}}
{"id": "G7_LoXdE2Oe", "cdate": 1663849891473, "mdate": null, "content": {"title": "Video-based 3D Object Detection with Learnable Object-Centric Global Optimization", "abstract": "We study utilizing long-term temporal visual correspondence-based optimization for video-based 3D object detection in this work. Visual correspondence refers to one-to-one mappings for pixels across multiple images. Correspondence-based optimization is the cornerstone for 3D scene reconstruction but is less studied in 3D object detection, for that moving objects violate multi-view geometry constraints and are treated as outliers during scene reconstruction. We resolve this issue by treating objects as first-class citizens during correspondence-based optimization. In this work, we propose BA-Det, an end-to-end optimizable object detector with object-centric temporal correspondence learning and object-centric featuremetric bundle adjustment. Empirically, we verify the effectiveness and efficiency of BA-Det for multiple baseline 3D detectors under various setups. Our BA-Det achieves SOTA performance on the large-scale Waymo Open Dataset (WOD) with only marginal computation cost.  Codes will be released soon."}}
{"id": "eQfuHqEsUj", "cdate": 1652737286736, "mdate": null, "content": {"title": "4D Unsupervised Object Discovery", "abstract": "Object discovery is a core task in computer vision. While fast progresses have been made in supervised object detection, its unsupervised counterpart remains largely unexplored. With the growth of data volume, the expensive cost of annotations is the major limitation hindering further study.  Therefore, discovering objects without annotations has great significance. However, this task seems impractical on still-image or point cloud alone due to the lack of discriminative information. Previous studies underlook the crucial temporal information and constraints naturally behind multi-modal inputs. In this paper, we propose 4D unsupervised object discovery, jointly discovering objects from 4D data -- 3D point clouds and 2D RGB images with temporal information. We present the first practical approach for this task by proposing a ClusterNet on 3D point clouds, which is jointly iteratively optimized with a 2D localization network. Extensive experiments on the large-scale Waymo Open Dataset suggest that the localization network and ClusterNet achieve competitive performance on both class-agnostic 2D object detection and 3D instance segmentation, bridging the gap between unsupervised methods and full supervised ones. Codes and models will be made available at https://github.com/Robertwyq/LSMOL."}}
{"id": "s6sRwFUf7X", "cdate": 1640995200000, "mdate": 1668039213504, "content": {"title": "Densely Constrained Depth Estimator for Monocular 3D Object Detection", "abstract": "Estimating accurate 3D locations of objects from monocular images is a challenging problem because of lacking depth. Previous work shows that utilizing the object's keypoint projection constraints to estimate multiple depth candidates boosts the detection performance. However, the existing methods can only utilize vertical edges as projection constraints for depth estimation. So these methods only use a small number of projection constraints and produce insufficient depth candidates, leading to inaccurate depth estimation. In this paper, we propose a method that utilizes dense projection constraints from edges of any direction. In this way, we employ much more projection constraints and produce considerable depth candidates. Besides, we present a graph matching weighting module to merge the depth candidates. The proposed method DCD (Densely Constrained Detector) achieves state-of-the-art performance on the KITTI and WOD benchmarks. Code is released at https://github.com/BraveGroup/DCD."}}
{"id": "qscJURTRsg", "cdate": 1640995200000, "mdate": 1668039213658, "content": {"title": "From Individual to Whole: Reducing Intra-class Variance by Feature Aggregation", "abstract": "The recording process of observation is influenced by multiple factors, such as viewpoint, illumination, and state of the object-of-interest etc.Thus, the image observation of the same object may vary a lot under different conditions. This leads to severe intra-class variance which greatly challenges the discrimination ability of the vision model. However, the current prevailing softmax loss for visual recognition only pursues perfect inter-class separation in the feature space. Without considering the intra-class compactness, the learned model easily collapses when it encounters the instances that deviate a lot from their class centroid. To resist the intra-class variance, we start by organizing the input instances as a graph. From this viewpoint, we find that the normalized cut on the graph is a favorable surrogate metric of the intra-class variance within the training batch. Inspired by the equivalence between the normalized cut and random walk, we propose a feature aggregation scheme using transition probabilities as guidance. By imposing supervision on the aggregated features, we can constrain the transition probabilities to form a graph partition consistent with the given labels. Thus, the normalized cut as well as intra-class variance can be well suppressed. To validate the effectiveness of this idea, we instantiate it in spatial, temporal, and spatial-temporal scenarios. Experimental results on corresponding benchmarks demonstrate that the proposed feature aggregation leads to significant improvement in performance. Our method is on par with, or even better than current state-of-the-arts in both tasks."}}
{"id": "f1RA3z-MTE", "cdate": 1640995200000, "mdate": 1668039213470, "content": {"title": "GIFS: Neural Implicit Function for General Shape Representation", "abstract": ""}}
{"id": "x_pvLAfEVeq", "cdate": 1609459200000, "mdate": 1668039213523, "content": {"title": "Immortal Tracker: Tracklet Never Dies", "abstract": "Previous online 3D Multi-Object Tracking(3DMOT) methods terminate a tracklet when it is not associated with new detections for a few frames. But if an object just goes dark, like being temporarily occluded by other objects or simply getting out of FOV, terminating a tracklet prematurely will result in an identity switch. We reveal that premature tracklet termination is the main cause of identity switches in modern 3DMOT systems. To address this, we propose Immortal Tracker, a simple tracking system that utilizes trajectory prediction to maintain tracklets for objects gone dark. We employ a simple Kalman filter for trajectory prediction and preserve the tracklet by prediction when the target is not visible. With this method, we can avoid 96% vehicle identity switches resulting from premature tracklet termination. Without any learned parameters, our method achieves a mismatch ratio at the 0.0001 level and competitive MOTA for the vehicle class on the Waymo Open Dataset test set. Our mismatch ratio is tens of times lower than any previously published method. Similar results are reported on nuScenes. We believe the proposed Immortal Tracker can offer a simple yet powerful solution for pushing the limit of 3DMOT. Our code is available at https://github.com/ImmortalTracker/ImmortalTracker."}}
{"id": "cyS0b2NRNNd", "cdate": 1609459200000, "mdate": 1668039213507, "content": {"title": "Online Adaptation for Implicit Object Tracking and Shape Reconstruction in the Wild", "abstract": "Tracking and reconstructing 3D objects from cluttered scenes are the key components for computer vision, robotics and autonomous driving systems. While recent progress in implicit function has shown encouraging results on high-quality 3D shape reconstruction, it is still very challenging to generalize to cluttered and partially observable LiDAR data. In this paper, we propose to leverage the continuity in video data. We introduce a novel and unified framework which utilizes a neural implicit function to simultaneously track and reconstruct 3D objects in the wild. Our approach adapts the DeepSDF model (i.e., an instantiation of the implicit function) in the video online, iteratively improving the shape reconstruction while in return improving the tracking, and vice versa. We experiment with both Waymo and KITTI datasets and show significant improvements over state-of-the-art methods for both tracking and shape reconstruction tasks. Our project page is at https://jianglongye.com/implicit-tracking ."}}
{"id": "2LNdD6SbYdk", "cdate": 1609459200000, "mdate": 1668039213531, "content": {"title": "Unsupervised Object Detection With LIDAR Clues", "abstract": "Despite the importance of unsupervised object detection, to the best of our knowledge, there is no previous work addressing this problem. One main issue, widely known to the community, is that object boundaries derived only from 2D image appearance are ambiguous and unreliable. To address this, we exploit LiDAR clues to aid unsupervised object detection. By exploiting the 3D scene structure, the issue of localization can be considerably mitigated. We further identify another major issue, seldom noticed by the community, that the long-tailed and open-ended (sub-)category distribution should be accommodated. In this paper, we present the first practical method for unsupervised object detection with the aid of LiDAR clues. In our approach, candidate object segments based on 3D point clouds are firstly generated. Then, an iterative segment labeling process is conducted to assign segment labels and to train a segment labeling network, which is based on features from both 2D images and 3D point clouds. The labeling process is carefully designed so as to mitigate the issue of long-tailed and open-ended distribution. The final segment labels are set as pseudo annotations for object detection network training. Extensive experiments on the large-scale Waymo Open dataset suggest that the derived unsupervised object detection method achieves reasonable accuracy compared with that of strong supervision within the LiDAR visible range."}}
{"id": "iAdtvgv2WP", "cdate": 1582424824019, "mdate": null, "content": {"title": "SimpleDet: A Simple and Versatile Distributed Framework for Object Detection and Instance Recognition", "abstract": "Object detection and instance recognition play a central role in many AI applications like\nautonomous driving, video surveillance and medical image analysis. However, training object detection models on large scale datasets remains computationally expensive and time\nconsuming. This paper presents an efficient and open source object detection framework\ncalled SimpleDet which enables the training of state-of-the-art detection models on consumer grade hardware at large scale. SimpleDet covers a wide range of models including\nboth high-performance and high-speed ones. SimpleDet is well-optimized for both low precision training and distributed training and achieves 70% higher throughput for the Mask\nR-CNN detector compared with existing frameworks. Codes, examples and documents of\nSimpleDet can be found at https://github.com/tusimple/simpledet."}}
