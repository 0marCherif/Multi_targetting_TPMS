{"id": "ZidnM8gc-K", "cdate": 1672531200000, "mdate": 1682349158224, "content": {"title": "Can We Find Nash Equilibria at a Linear Rate in Markov Games?", "abstract": "We study decentralized learning in two-player zero-sum discounted Markov games where the goal is to design a policy optimization algorithm for either agent satisfying two properties. First, the player does not need to know the policy of the opponent to update its policy. Second, when both players adopt the algorithm, their joint policy converges to a Nash equilibrium of the game. To this end, we construct a meta algorithm, dubbed as $\\texttt{Homotopy-PO}$, which provably finds a Nash equilibrium at a global linear rate. In particular, $\\texttt{Homotopy-PO}$ interweaves two base algorithms $\\texttt{Local-Fast}$ and $\\texttt{Global-Slow}$ via homotopy continuation. $\\texttt{Local-Fast}$ is an algorithm that enjoys local linear convergence while $\\texttt{Global-Slow}$ is an algorithm that converges globally but at a slower sublinear rate. By switching between these two base algorithms, $\\texttt{Global-Slow}$ essentially serves as a ``guide'' which identifies a benign neighborhood where $\\texttt{Local-Fast}$ enjoys fast convergence. However, since the exact size of such a neighborhood is unknown, we apply a doubling trick to switch between these two base algorithms. The switching scheme is delicately designed so that the aggregated performance of the algorithm is driven by $\\texttt{Local-Fast}$. Furthermore, we prove that $\\texttt{Local-Fast}$ and $\\texttt{Global-Slow}$ can both be instantiated by variants of optimistic gradient descent/ascent (OGDA) method, which is of independent interest."}}
{"id": "eQzLwwGyQrb", "cdate": 1663850372149, "mdate": null, "content": {"title": "Can We Find Nash Equilibria at a Linear Rate in Markov Games?", "abstract": "We study decentralized learning in two-player zero-sum discounted Markov games where the goal is to design a policy optimization algorithm for either agent satisfying two properties. First, the player does not need to know the policy of the opponent to update its policy. Second, when both players adopt the algorithm, their joint policy converges to a Nash equilibrium of the game. To this end, we construct a meta-algorithm, dubbed as $\\texttt{Homotopy-PO}$, which provably finds a Nash equilibrium at a global linear rate. In particular, $\\texttt{Homotopy-PO}$ interweaves two base algorithms $\\texttt{Local-Fast}$ and $\\texttt{Global-Slow}$ via homotopy continuation. $\\texttt{Local-Fast}$ is an algorithm that enjoys local linear convergence while $\\texttt{Global-Slow}$ is an algorithm that converges globally but at a slower sublinear rate. By switching between these two base algorithms, $\\texttt{Global-Slow}$ essentially serves as a ``guide'' which identifies a benign neighborhood where $\\texttt{Local-Fast}$ enjoys fast convergence. However, since the exact size of such a neighborhood is unknown, we apply a doubling trick to switch between these two base algorithms. The switching scheme is delicately designed so that the aggregated performance of the algorithm is driven by $\\texttt{Local-Fast}$. Furthermore, we prove that $\\texttt{Local-Fast}$ and $\\texttt{Global-Slow}$ can both be instantiated by variants of optimistic gradient descent/ascent (OGDA) method, which is of independent interest."}}
{"id": "AyiiHcRzTd", "cdate": 1652737619493, "mdate": null, "content": {"title": "Communication-Efficient Topologies for Decentralized Learning with $O(1)$ Consensus Rate", "abstract": "Decentralized optimization is an emerging paradigm in distributed learning in which agents achieve network-wide solutions by  peer-to-peer communication without the central server. Since communication tends to be slower than computation, when each agent communicates with only a few neighboring agents per iteration, they can complete iterations faster than with more agents or a central server. However, the total number of iterations to reach a network-wide solution is affected by the speed at which the information of the agents is ``mixed'' by communication. We found that popular communication topologies either have large degrees (such as stars and complete graphs) or are ineffective at mixing information (such as rings and grids). To address this problem, we propose a new family of topologies, EquiTopo, which has an (almost) constant degree and network-size-independent consensus rate which is used to measure the mixing efficiency.\n\nIn the proposed family, EquiStatic has a degree of $\\Theta(\\ln(n))$, where $n$ is the network size, and a series of time-varying one-peer topologies, EquiDyn, has a constant degree of 1. We generate EquiDyn through a certain random sampling procedure. Both of them achieve $n$-independent consensus rate. We apply them to decentralized SGD and decentralized gradient tracking and obtain faster communication and better convergence, both theoretically and empirically. Our code is implemented through BlueFog and available at https://github.com/kexinjinnn/EquiTopo."}}
{"id": "D4PrGF1yEk", "cdate": 1640995200000, "mdate": 1682349158236, "content": {"title": "Sparsified block elimination for directed laplacians", "abstract": ""}}
{"id": "B8_Jz9pdmZ5", "cdate": 1640995200000, "mdate": 1652660258763, "content": {"title": "Compressed Gradient Tracking for Decentralized Optimization Over General Directed Networks", "abstract": "In this paper, we propose two communication-efficient decentralized optimization algorithms over a general directed multi-agent network. The first algorithm, termed Compressed Push-Pull (CPP), combines the gradient tracking Push-Pull method with communication compression. We show that CPP is applicable to a general class of unbiased compression operators and achieves linear convergence rate for strongly convex and smooth objective functions. The second algorithm is a broadcast-like version of CPP (B-CPP), and it also achieves linear convergence rate under the same conditions on the objective functions. B-CPP can be applied in an asynchronous broadcast setting and further reduce communication costs compared to CPP. Numerical experiments complement the theoretical analysis and confirm the effectiveness of the proposed methods."}}
{"id": "7PSEJO97mc", "cdate": 1640995200000, "mdate": 1682320769767, "content": {"title": "Communication-Efficient Topologies for Decentralized Learning with O(1) Consensus Rate", "abstract": "Decentralized optimization is an emerging paradigm in distributed learning in which agents achieve network-wide solutions by peer-to-peer communication without the central server. Since communication tends to be slower than computation, when each agent communicates with only a few neighboring agents per iteration, they can complete iterations faster than with more agents or a central server. However, the total number of iterations to reach a network-wide solution is affected by the speed at which the agents' information is ``mixed'' by communication. We found that popular communication topologies either have large maximum degrees (such as stars and complete graphs) or are ineffective at mixing information (such as rings and grids). To address this problem, we propose a new family of topologies, EquiTopo, which has an (almost) constant degree and a network-size-independent consensus rate that is used to measure the mixing efficiency. In the proposed family, EquiStatic has a degree of $\\Theta(\\ln(n))$, where $n$ is the network size, and a series of time-dependent one-peer topologies, EquiDyn, has a constant degree of 1. We generate EquiDyn through a certain random sampling procedure. Both of them achieve an $n$-independent consensus rate. We apply them to decentralized SGD and decentralized gradient tracking and obtain faster communication and better convergence, theoretically and empirically. Our code is implemented through BlueFog and available at \\url{https://github.com/kexinjinnn/EquiTopo}"}}
{"id": "xN_ZEozmYQE", "cdate": 1609459200000, "mdate": 1652660258844, "content": {"title": "Provably Accelerated Decentralized Gradient Method Over Unbalanced Directed Graphs", "abstract": "In this work, we consider the decentralized optimization problem in which a network of $n$ agents, each possessing a smooth and convex objective function, wish to collaboratively minimize the average of all the objective functions through peer-to-peer communication in a directed graph. To solve the problem, we propose two accelerated Push-DIGing methods termed APD and APD-SC for minimizing non-strongly convex objective functions and strongly convex ones, respectively. We show that APD and APD-SC respectively converge at the rates $O\\left(\\frac{1}{k^2}\\right)$ and $O\\left(\\left(1 - C\\sqrt{\\frac{\\mu}{L}}\\right)^k\\right)$ up to constant factors depending only on the mixing matrix. To the best of our knowledge, APD and APD-SC are the first decentralized methods to achieve provable acceleration over unbalanced directed graphs. Numerical experiments demonstrate the effectiveness of both methods."}}
{"id": "e7FvETlojqA", "cdate": 1609459200000, "mdate": 1682349158259, "content": {"title": "Sparsified Block Elimination for Directed Laplacians", "abstract": "We show that the sparsified block elimination algorithm for solving undirected Laplacian linear systems from [Kyng-Lee-Peng-Sachdeva-Spielman STOC'16] directly works for directed Laplacians. Given access to a sparsification algorithm that, on graphs with $n$ vertices and $m$ edges, takes time $\\mathcal{T}_{\\rm S}(m)$ to output a sparsifier with $\\mathcal{N}_{\\rm S}(n)$ edges, our algorithm solves a directed Eulerian system on $n$ vertices and $m$ edges to $\\epsilon$ relative accuracy in time $$ O(\\mathcal{T}_{\\rm S}(m) + {\\mathcal{N}_{\\rm S}(n)\\log {n}\\log(n/\\epsilon)}) + \\tilde{O}(\\mathcal{T}_{\\rm S}(\\mathcal{N}_{\\rm S}(n)) \\log n), $$ where the $\\tilde{O}(\\cdot)$ notation hides $\\log\\log(n)$ factors. By previous results, this implies improved runtimes for linear systems in strongly connected directed graphs, PageRank matrices, and asymmetric M-matrices. When combined with slower constructions of smaller Eulerian sparsifiers based on short cycle decompositions, it also gives a solver that runs in $O(n \\log^{5}n \\log(n / \\epsilon))$ time after $O(n^2 \\log^{O(1)} n)$ pre-processing. At the core of our analyses are constructions of augmented matrices whose Schur complements encode error matrices."}}
{"id": "1iASgpvvGnP", "cdate": 1609459200000, "mdate": 1652660258942, "content": {"title": "Compressed Gradient Tracking for Decentralized Optimization Over General Directed Networks", "abstract": "In this paper, we propose two communication efficient decentralized optimization algorithms over a general directed multi-agent network. The first algorithm, termed Compressed Push-Pull (CPP), combines the gradient tracking Push-Pull method with communication compression. We show that CPP is applicable to a general class of unbiased compression operators and achieves linear convergence rate for strongly convex and smooth objective functions. The second algorithm is a broadcast-like version of CPP (B-CPP), and it also achieves linear convergence rate under the same conditions on the objective functions. B-CPP can be applied in an asynchronous broadcast setting and further reduce communication costs compared to CPP. Numerical experiments complement the theoretical analysis and confirm the effectiveness of the proposed methods."}}
