{"id": "xzU2TEWhwm", "cdate": 1640995200000, "mdate": 1682362804753, "content": {"title": "SAGE: Saliency-Guided Mixup with Optimal Rearrangements", "abstract": ""}}
{"id": "E4UITtU9hf", "cdate": 1640995200000, "mdate": 1682362804908, "content": {"title": "SAGE: Saliency-Guided Mixup with Optimal Rearrangements", "abstract": "Data augmentation is a key element for training accurate models by reducing overfitting and improving generalization. For image classification, the most popular data augmentation techniques range from simple photometric and geometrical transformations, to more complex methods that use visual saliency to craft new training examples. As augmentation methods get more complex, their ability to increase the test accuracy improves, yet, such methods become cumbersome, inefficient and lead to poor out-of-domain generalization, as we show in this paper. This motivates a new augmentation technique that allows for high accuracy gains while being simple, efficient (i.e., minimal computation overhead) and generalizable. To this end, we introduce Saliency-Guided Mixup with Optimal Rearrangements (SAGE), which creates new training examples by rearranging and mixing image pairs using visual saliency as guidance. By explicitly leveraging saliency, SAGE promotes discriminative foreground objects and produces informative new images useful for training. We demonstrate on CIFAR-10 and CIFAR-100 that SAGE achieves better or comparable performance to the state of the art while being more efficient. Additionally, evaluations in the out-of-distribution setting, and few-shot learning on mini-ImageNet, show that SAGE achieves improved generalization performance without trading off robustness."}}
{"id": "A6OFpo91rl", "cdate": 1609459200000, "mdate": 1682362804910, "content": {"title": "Improving Hierarchical Adversarial Robustness of Deep Neural Networks", "abstract": "Do all adversarial examples have the same consequences? An autonomous driving system misclassifying a pedestrian as a car may induce a far more dangerous -- and even potentially lethal -- behavior than, for instance, a car as a bus. In order to better tackle this important problematic, we introduce the concept of hierarchical adversarial robustness. Given a dataset whose classes can be grouped into coarse-level labels, we define hierarchical adversarial examples as the ones leading to a misclassification at the coarse level. To improve the resistance of neural networks to hierarchical attacks, we introduce a hierarchical adversarially robust (HAR) network design that decomposes a single classification task into one coarse and multiple fine classification tasks, before being specifically trained by adversarial defense techniques. As an alternative to an end-to-end learning approach, we show that HAR significantly improves the robustness of the network against $\\ell_2$ and $\\ell_{\\infty}$ bounded hierarchical attacks on the CIFAR-10 and CIFAR-100 dataset."}}
{"id": "sojnduJtbfQ", "cdate": 1601308315803, "mdate": null, "content": {"title": "Improving Hierarchical Adversarial Robustness of Deep Neural Networks", "abstract": "Do all adversarial examples have the same consequences? An autonomous driving system misclassifying a pedestrian as a car may induce a far more dangerous --and even potentially lethal-- behavior than, for instance, a car as a bus. In order to better tackle this important problematic, we introduce the concept of hierarchical adversarial robustness. Given a dataset whose classes can be grouped into coarse-level labels, we define hierarchical adversarial examples as the ones leading to a misclassification at the coarse level. To improve the resistance of neural networks to hierarchical attacks, we introduce a hierarchical adversarially robust (HAR) network design that decomposes a single classification task into one coarse and multiple fine classification tasks, before being specifically trained by adversarial defense techniques. As an alternative to an end-to-end learning approach, we show that HAR significantly improves the robustness of the network against $\\ell_{\\infty}$  and $\\ell_{2}$bounded hierarchical attacks on CIFAR-100."}}
{"id": "Ms9zjhVB5R", "cdate": 1601308313882, "mdate": null, "content": {"title": "SOAR: Second-Order Adversarial Regularization", "abstract": "Adversarial training is a common approach to improving the robustness of deep neural networks against adversarial examples. In this work, we propose a novel regularization approach as an alternative. To derive the regularizer, we formulate the adversarial robustness problem under the robust optimization framework and approximate the loss function using a second-order Taylor series expansion. Our proposed second-order adversarial regularizer (SOAR) is an upper bound based on the Taylor approximation of the inner-max in the robust optimization objective. We empirically show that the proposed method improves the robustness of networks against the $\\ell_\\infty$ and $\\ell_2$ bounded perturbations on CIFAR-10 and SVHN."}}
{"id": "8oXHG0w_m4D", "cdate": 1577836800000, "mdate": null, "content": {"title": "Adversarial Robustness through Regularization: A Second-Order Approach", "abstract": "Adversarial training is a common approach to improving the robustness of deep neural networks against adversarial examples. In this work, we propose a novel regularization approach as an alternative. To derive the regularizer, we formulate the adversarial robustness problem under the robust optimization framework and approximate the loss function using a second-order Taylor series expansion. Our proposed second-order adversarial regularizer (SOAR) is an upper bound based on the Taylor approximation of the inner-max in the robust optimization objective. We empirically show that the proposed method significantly improves the robustness of networks against the $\\ell_\\infty$ and $\\ell_2$ bounded perturbations generated using cross-entropy-based PGD on CIFAR-10 and SVHN."}}
{"id": "6yD1rZEtp-", "cdate": 1514764800000, "mdate": 1682362804769, "content": {"title": "Deep Learning-Driven Depth from Defocus via Active Multispectral Quasi-Random Projections with Complex Subpatterns", "abstract": "A promising approach to depth from defocus (DfD) involves actively projecting a quasi-random point pattern onto an object and assessing the blurriness of the point projection as captured by a camera to recover the depth of the scene. Recently, it was found that the depth inference can be made not only faster but also more accurate by leveraging deep learning approaches to computationally model and predict depth based on the quasi-random point projections as captured by a camera. Motivated by the fact that deep learning techniques can automatically learn useful features from the captured image of the projection, in this paper we present an extension of this quasi-random projection approach to DfD by introducing the use of a new quasi-random projection pattern consisting of complex subpatterns instead of points. The design and choice of the subpattern used in the quasi-random projection is a key factor in the ability to achieve improved depth recovery with high fidelity. Experimental results using quasi-random projection patterns composed of a variety of non-conventional subpattern designs on complex surfaces showed that the use of complex subpatterns in the quasi-random projection pattern can significantly improve depth reconstruction quality compared to a point pattern."}}
{"id": "zCUCVPr1MD", "cdate": 1483228800000, "mdate": 1682362804773, "content": {"title": "Depth from Defocus via Active Quasi-random Point Projections: A Deep Learning Approach", "abstract": "Depth estimation plays an important role in many computer vision and computer graphics applications. Existing depth measurement techniques are still complex and restrictive. In this paper, we present a novel technique for inferring depth measurements via depth from defocus using active quasi-random point projection patterns. A quasi-random point projection pattern is projected onto the scene of interest, and each projection point in the image captured by a cellphone camera is analyzed using a deep learning model to estimate the depth at that point. The proposed method has a relatively simple setup, consisting of a camera and a projector, and enables depth inference from a single capture. We evaluate the proposed method both quantitatively and qualitatively and demonstrate strong potential for simple and efficient depth sensing."}}
