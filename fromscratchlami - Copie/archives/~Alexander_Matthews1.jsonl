{"id": "9cU2iW3bz0", "cdate": 1652737417620, "mdate": null, "content": {"title": "Score-Based Diffusion meets Annealed Importance Sampling", "abstract": "More than twenty years after its introduction, Annealed Importance Sampling (AIS) remains one of the most effective methods for marginal likelihood estimation. It relies on a sequence of distributions interpolating between a tractable initial distribution and the target distribution of interest which we simulate from approximately using a non-homogeneous Markov chain. To obtain an importance sampling estimate of the marginal likelihood, AIS introduces an extended target distribution to reweight the Markov chain proposal. While much effort has been devoted to improving the proposal distribution used by AIS, by changing the intermediate distributions and corresponding Markov kernels, an underappreciated issue is that AIS uses a convenient but suboptimal extended target distribution. This can hinder its performance. We here leverage recent progress in score-based generative modeling (SGM) to approximate the optimal extended target distribution for AIS proposals corresponding to the discretization of Langevin and Hamiltonian dynamics. We demonstrate these novel, differentiable, AIS procedures on a number of synthetic benchmark distributions and variational auto-encoders."}}
{"id": "H43MpnN_vZ9", "cdate": 1646916788962, "mdate": null, "content": {"title": "Annealed Importance Sampling meets Score Matching", "abstract": "Annealed Importance Sampling (AIS) is one of the most effective methods for marginal likelihood estimation. It relies on a sequence of distributions interpolating between a tractable initial distribution and the posterior of interest which we simulate from approximately using a non-homogeneous Markov chain. To obtain an importance sampling (IS) estimate of the marginal likelihood, AIS introduces an extended target distribution to reweight the Markov chain proposal. While much effort has been devoted to improving the proposal distribution used by AIS by changing the intermediate distributions and corresponding Markov kernels, an underappreciated issue is that AIS uses an convenient but suboptimal extended target distribution which can hinder its performance. We leverage here recent progress in score-based generative modeling to learn the optimal extended target distribution for a given AIS proposal using score matching ideas. We demonstrate this novel differentiable AIS procedure on a number of synthetic benchmark distributions and a normalizing flow target."}}
{"id": "RFKWKWzx2ic", "cdate": 1640995200000, "mdate": 1682322430594, "content": {"title": "Continual Repeated Annealed Flow Transport Monte Carlo", "abstract": "We propose Continual Repeated Annealed Flow Transport Monte Carlo (CRAFT), a method that combines a sequential Monte Carlo (SMC) sampler (itself a generalization of Annealed Importance Sampling) wi..."}}
{"id": "PsEgBzxJXV", "cdate": 1640995200000, "mdate": 1682322430795, "content": {"title": "Score-Based Diffusion meets Annealed Importance Sampling", "abstract": "More than twenty years after its introduction, Annealed Importance Sampling (AIS) remains one of the most effective methods for marginal likelihood estimation. It relies on a sequence of distributions interpolating between a tractable initial distribution and the target distribution of interest which we simulate from approximately using a non-homogeneous Markov chain. To obtain an importance sampling estimate of the marginal likelihood, AIS introduces an extended target distribution to reweight the Markov chain proposal. While much effort has been devoted to improving the proposal distribution used by AIS, an underappreciated issue is that AIS uses a convenient but suboptimal extended target distribution. We here leverage recent progress in score-based generative modeling (SGM) to approximate the optimal extended target distribution minimizing the variance of the marginal likelihood estimate for AIS proposals corresponding to the discretization of Langevin and Hamiltonian dynamics. We demonstrate these novel, differentiable, AIS procedures on a number of synthetic benchmark distributions and variational auto-encoders."}}
{"id": "3FZBjkECKr", "cdate": 1640995200000, "mdate": 1682322430794, "content": {"title": "Aspects of scaling and scalability for flow-based sampling of lattice QCD", "abstract": "Recent applications of machine-learned normalizing flows to sampling in lattice field theory suggest that such methods may be able to mitigate critical slowing down and topological freezing. However, these demonstrations have been at the scale of toy models, and it remains to be determined whether they can be applied to state-of-the-art lattice quantum chromodynamics calculations. Assessing the viability of sampling algorithms for lattice field theory at scale has traditionally been accomplished using simple cost scaling laws, but as we discuss in this work, their utility is limited for flow-based approaches. We conclude that flow-based approaches to sampling are better thought of as a broad family of algorithms with different scaling properties, and that scalability must be assessed experimentally."}}
{"id": "KrshkToZBG", "cdate": 1609459200000, "mdate": 1682322430838, "content": {"title": "Annealed Flow Transport Monte Carlo", "abstract": "Annealed Importance Sampling (AIS) and its Sequential Monte Carlo (SMC) extensions are state-of-the-art methods for estimating normalizing constants of probability distributions. We propose here a ..."}}
{"id": "NG05QYRfK1J", "cdate": 1600168108021, "mdate": null, "content": {"title": "Ab-Initio Solution of the Many-Electron Schr\u00f6dinger Equation with Deep Neural Networks", "abstract": "Given access to accurate solutions of the many-electron Schr\u00a8odinger equation, nearly all chemistry could be derived from first principles. Exact wavefunctions of interesting chemical systems are\nout of reach because they are NP-hard to compute in general,1 but approximations can be found\nusing polynomially-scaling algorithms. The key challenge for many of these algorithms is the choice\nof wavefunction approximation, or Ansatz, which must trade off between efficiency and accuracy.\nNeural networks have shown impressive power as accurate practical function approximators2,3 and\npromise as a compact wavefunction Ansatz for spin systems,4 but problems in electronic structure\nrequire wavefunctions that obey Fermi-Dirac statistics. Here we introduce a novel deep learning\narchitecture, the Fermionic Neural Network, as a powerful wavefunction Ansatz for many-electron\nsystems. The Fermionic Neural Network is able to achieve accuracy beyond other variational quantum Monte Carlo Ans\u00a8atze on a variety of atoms and small molecules. Using no data other than\natomic positions and charges, we predict the dissociation curves of the nitrogen molecule and hydrogen chain, two challenging strongly-correlated systems, to significantly higher accuracy than\nthe coupled cluster method,5 widely considered the most accurate scalable method for quantum\nchemistry at equilibrium geometry. This demonstrates that deep neural networks can improve the\naccuracy of variational quantum Monte Carlo to the point where it outperforms other ab-initio quantum chemistry methods, opening the possibility of accurate direct optimisation of wavefunctions for\npreviously intractable molecules and solids."}}
{"id": "C4-wtaQUYbk", "cdate": 1599591175616, "mdate": null, "content": {"title": "Sample-then-optimize posterior sampling for Bayesian linear models", "abstract": "In modern machine learning it is common to train models which have an extremely high intrinsic capacity. The results obtained are often initialization dependent, are different for disparate optimizers and in some cases have no explicit regularization. This raises difficult questions about generalization [1]. A natural approach to questions of generalization is a Bayesian one. There is therefore a growing literature attempting to understand how Bayesian posterior inference could emerge from the complexity of modern practice [2, 3], even without having such a procedure as the stated goal.\nIn this work we consider a simple special case where exact Bayesian posterior sampling emerges from sampling (cf initialization) and then gradient descent. Specifically, for a Bayesian linear model, if we parameterize it in terms of a deterministic function of an isotropic normal prior, then the action of sampling from the prior followed by first order optimization of the squared loss will give a posterior sample. Although the assumptions are stronger than many real problems, it still exhibits the challenging properties of redundant model capacity and a lack of explicit regularizers, along with initialization and optimizer dependence. It is therefore an interesting controlled test case. Given its simplicity, the method itself may turn out to be of independent interest from our original goal. Whilst the material of Section 2 is classical [4], the material in Section 3 is, as far as we are aware, novel."}}
{"id": "D0ZeVou-ZHh", "cdate": 1577836800000, "mdate": null, "content": {"title": "Functional Regularisation for Continual Learning with Gaussian Processes", "abstract": "We introduce a framework for Continual Learning (CL) based on Bayesian inference over the function space rather than the parameters of a deep neural network. This method, referred to as functional regularisation for Continual Learning, avoids forgetting a previous task by constructing and memorising an approximate posterior belief over the underlying task-specific function. To achieve this we rely on a Gaussian process obtained by treating the weights of the last layer of a neural network as random and Gaussian distributed. Then, the training algorithm sequentially encounters tasks and constructs posterior beliefs over the task-specific functions by using inducing point sparse Gaussian process methods. At each step a new task is first learnt and then a summary is constructed consisting of (i) inducing inputs \u2013 a fixed-size subset of the task inputs selected such that it optimally represents the task \u2013 and (ii) a posterior distribution over the function values at these inputs. This summary then regularises learning of future tasks, through Kullback-Leibler regularisation terms. Our method thus unites approaches focused on (pseudo-)rehearsal with those derived from a sequential Bayesian inference perspective in a principled way, leading to strong results on accepted benchmarks."}}
{"id": "HkxCzeHFDB", "cdate": 1569439766152, "mdate": null, "content": {"title": "Functional Regularisation for  Continual Learning with Gaussian Processes", "abstract": "We introduce a framework for Continual Learning (CL) based on Bayesian inference over the function space rather than the parameters of a deep neural network. This method, referred to as functional regularisation for Continual Learning, avoids forgetting a previous task by constructing and memorising an approximate posterior belief over the underlying task-specific function. To achieve this we rely on a Gaussian process obtained by treating the weights of the last layer of a neural network as random and Gaussian distributed. Then, the training algorithm sequentially encounters tasks and constructs posterior beliefs over the task-specific functions by using inducing point sparse Gaussian process methods. At each step a new task is first learnt and then a summary is constructed consisting of (i) inducing inputs \u2013 a fixed-size subset of the task inputs selected such that it optimally represents the task \u2013 and (ii) a posterior distribution over the function values at these inputs. This summary then regularises learning of future tasks, through Kullback-Leibler regularisation terms. Our method thus unites approaches focused on (pseudo-)rehearsal with those derived from a sequential Bayesian inference perspective in a principled way, leading to strong results on accepted benchmarks."}}
