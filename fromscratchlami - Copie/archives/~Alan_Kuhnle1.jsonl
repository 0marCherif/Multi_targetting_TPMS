{"id": "Ri2G086_3v", "cdate": 1621629749912, "mdate": null, "content": {"title": "Best of Both Worlds: Practical and Theoretically Optimal Submodular Maximization in Parallel", "abstract": "For the problem of maximizing a monotone, submodular function with respect to a cardinality constraint $k$ on a ground set of size $n$, we provide an algorithm that achieves the state-of-the-art in both its empirical performance and its theoretical properties, in terms of adaptive complexity, query complexity, and approximation ratio; that is, it obtains, with high probability, query complexity of $O(n)$ in expectation, adaptivity of $O(\\log(n))$, and approximation ratio of nearly $1-1/e$. The main algorithm is assembled from two components which may be of independent interest. The first component of our algorithm, LINEARSEQ, is useful as a preprocessing algorithm to improve the query complexity of many algorithms. Moreover, a variant of LINEARSEQ is shown to have adaptive complexity of $O( \\log (n / k) )$ which is smaller than that of any previous algorithm in the literature. The second component is a parallelizable thresholding procedure THRESHOLDSEQ for adding elements with gain above a constant threshold. Finally, we demonstrate that our main algorithm empirically outperforms, in terms of runtime, adaptive rounds, total queries, and objective values, the previous state-of-the-art algorithm FAST in a comprehensive evaluation with six submodular objective functions."}}
{"id": "L8OP7UwSWn6", "cdate": 1577836800000, "mdate": null, "content": {"title": "Simultaenous Sieves: A Deterministic Streaming Algorithm for Non-Monotone Submodular Maximization", "abstract": "In this work, we present a combinatorial, deterministic single-pass streaming algorithm for the problem of maximizing a submodular function, not necessarily monotone, with respect to a cardinality constraint (SMCC). In the case the function is monotone, our algorithm reduces to the optimal streaming algorithm of Badanidiyuru et al. (2014). In general, our algorithm achieves ratio $\\alpha / (1 + \\alpha) - \\varepsilon$, for any $\\varepsilon > 0$, where $\\alpha$ is the ratio of an offline (deterministic) algorithm for SMCC used for post-processing. Thus, if exponential computation time is allowed, our algorithm deterministically achieves nearly the optimal $1/2$ ratio. These results nearly match those of a recently proposed, randomized streaming algorithm that achieves the same ratios in expectation. For a deterministic, single-pass streaming algorithm, our algorithm achieves in polynomial time an improvement of the best approximation factor from $1/9$ of previous literature to $\\approx 0.2689$."}}
{"id": "JDv8yVApx3_", "cdate": 1577836800000, "mdate": null, "content": {"title": "Quick Streaming Algorithms for Maximization of Monotone Submodular Functions in Linear Time", "abstract": "We consider the problem of monotone, submodular maximization over a ground set of size $n$ subject to cardinality constraint $k$. For this problem, we introduce the first deterministic algorithms with linear time complexity; these algorithms are streaming algorithms. Our single-pass algorithm obtains a constant ratio in $\\lceil n / c \\rceil + c$ oracle queries, for any $c \\ge 1$. In addition, we propose a deterministic, multi-pass streaming algorithm with a constant number of passes that achieves nearly the optimal ratio with linear query and time complexities. We prove a lower bound that implies no constant-factor approximation exists using $o(n)$ queries, even if queries to infeasible sets are allowed. An empirical analysis demonstrates that our algorithms require fewer queries (often substantially less than $n$) yet still achieve better objective value than the current state-of-the-art algorithms, including single-pass, multi-pass, and non-streaming algorithms."}}
{"id": "3hNd-uxpxeI", "cdate": 1577836800000, "mdate": null, "content": {"title": "Nearly Linear-Time, Parallelizable Algorithms for Non-Monotone Submodular Maximization", "abstract": "We present combinatorial and parallelizable algorithms for maximization of a submodular function, not necessarily monotone, with respect to a size constraint. We improve the best approximation factor achieved by an algorithm that has optimal adaptivity and nearly optimal query complexity to $0.193 - \\varepsilon$. The conference version of this work mistakenly employed a subroutine that does not work for non-monotone, submodular functions. In this version, we propose a fixed and improved subroutine to add a set with high average marginal gain, \\threseq, which returns a solution in $O( \\log(n) )$ adaptive rounds with high probability. Moreover, we provide two approximation algorithms. The first has approximation ratio $1/6 - \\varepsilon$, adaptivity $O( \\log (n) )$, and query complexity $O( n \\log (k) )$, while the second has approximation ratio $0.193 - \\varepsilon$, adaptivity $O( \\log^2 (n) )$, and query complexity $O(n \\log (k))$. Our algorithms are empirically validated to use a low number of adaptive rounds and total queries while obtaining solutions with high objective value in comparison with state-of-the-art approximation algorithms, including continuous algorithms that use the multilinear extension."}}
{"id": "rjQ9eTrah_", "cdate": 1546300800000, "mdate": null, "content": {"title": "Interlaced Greedy Algorithm for Maximization of Submodular Functions in Nearly Linear Time", "abstract": "A deterministic approximation algorithm is presented for the maximization of non-monotone submodular functions over a ground set of size $n$ subject to cardinality constraint $k$; the algorithm is based upon the idea of interlacing two greedy procedures. The algorithm uses interlaced, thresholded greedy procedures to obtain tight ratio $1/4 - \\epsilon$ in $O \\left( \\frac{n}{\\epsilon} \\log \\left( \\frac{k}{\\epsilon} \\right) \\right)$ queries of the objective function, which improves upon both the ratio and the quadratic time complexity of the previously fastest deterministic algorithm for this problem. The algorithm is validated in the context of two applications of non-monotone submodular maximization, on which it outperforms the fastest deterministic and randomized algorithms in prior literature."}}
{"id": "r1E1PiZOZr", "cdate": 1546300800000, "mdate": null, "content": {"title": "Submodular Cost Submodular Cover with an Approximate Oracle", "abstract": "In this work, we study the Submodular Cost Submodular Cover problem, which is to minimize the submodular cost required to ensure that the submodular benefit function exceeds a given threshold. Exis..."}}
{"id": "ndZEH6hiJrC", "cdate": 1546300800000, "mdate": null, "content": {"title": "Matching reads to many genomes with the r-index", "abstract": "The $r$-index is a tool for compressed indexing of genomic databases for exact pattern matching, which can be used to completely align reads that perfectly match some part of a genome in the database or to find seeds for reads that do not. This paper shows how to download and install the programs ri-buildfasta and ri-align; how to call ri-buildfasta on a FASTA file to build an $r$-index for that file; and how to query that index with ri-align. Availability: The source code for these programs is released under GPLv3 and available at https://github.com/alshai/r-index ."}}
{"id": "hqyvsJzvE8D", "cdate": 1546300800000, "mdate": null, "content": {"title": "Nearly Linear-Time, Deterministic Algorithm for Maximizing (Non-Monotone) Submodular Functions Under Cardinality Constraint", "abstract": "A deterministic approximation algorithm is presented for the maximization of non-monotone submodular functions over a ground set of size $n$ subject to cardinality constraint $k$; the algorithm is based upon the idea of interlacing two greedy procedures. The algorithm uses interlaced, thresholded greedy procedures to obtain tight ratio $1/4 - \\epsilon$ in $O \\left( \\frac{n}{\\epsilon} \\log \\left( \\frac{k}{\\epsilon} \\right) \\right)$ queries of the objective function, which improves upon both the ratio and the quadratic time complexity of the previously fastest deterministic algorithm for this problem. The algorithm is validated in the context of two applications of non-monotone submodular maximization, on which it outperforms the fastest deterministic and randomized algorithms in prior literature."}}
{"id": "gyCtY3BsGAB", "cdate": 1546300800000, "mdate": null, "content": {"title": "Scalable approximations to k-cycle transversal problems on dynamic networks", "abstract": "We study scalable approximation algorithms for the k-cycle transversal problem, which is to find a minimum-size set of edges that intersects all simple cycles of length k in a network. This problem is relevant to network reliability through the important metric of network clustering coefficient of order k. We formulate two algorithms to be both scalable and have good solution quality in practice: CARL and DARC. DARC is able to efficiently update its solution under dynamic node and edge insertion and removal to the network. In our experimental evaluation, we demonstrate that DARC is able to run on networks with billions of 3-cycles within 2 h and is able to dynamically update its solution in microseconds."}}
{"id": "VwwTfckm85h", "cdate": 1546300800000, "mdate": null, "content": {"title": "Efficient Construction of a Complete Index for Pan-Genomics Read Alignment", "abstract": "While short read aligners, which predominantly use the FM-index, are able to easily index one or a few human genomes, they do not scale well to indexing databases containing thousands of genomes. To understand why, it helps to examine the main components of the FM-index in more detail, which is a rank data structure over the Burrows-Wheeler Transform ( $${\\mathsf{BWT}}$$ ) of the string that will allow us to find the interval in the string\u2019s suffix array ( $${\\mathsf{SA}}$$ ) containing pointers to starting positions of occurrences of a given pattern; second, a sample of the $${\\mathsf{SA}}$$ that\u2014when used with the rank data structure\u2014allows us access to the $${\\mathsf{SA}}$$ . The rank data structure can be kept small even for large genomic databases, by run-length compressing the $${\\mathsf{BWT}}$$ , but until recently there was no means known to keep the $${\\mathsf{SA}}$$ sample small without greatly slowing down access to the $${\\mathsf{SA}}$$ . Now that Gagie et al. (SODA 2018) have defined an $${\\mathsf{SA}}$$ sample that takes about the same space as the run-length compressed $${\\mathsf{BWT}}$$ \u2014we have the design for efficient FM-indexes of genomic databases but are faced with the problem of building them. In 2018 we showed how to build the $${\\mathsf{BWT}}$$ of large genomic databases efficiently (WABI 2018) but the problem of building Gagie et al.\u2019s $${\\mathsf{SA}}$$ sample efficiently was left open. We compare our approach to state-of-the-art methods for constructing the $${\\mathsf{SA}}$$ sample, and demonstrate that it is the fastest and most space-efficient method on highly repetitive genomic databases. Lastly, we apply our method for indexing partial and whole human genomes and show that it improves over Bowtie with respect to both memory and time. Availability: The implementations of our methods can be found at https://gitlab.com/manzai/Big-BWT (BWT and SA sample construction) and at https://github.com/alshai/r-index (indexing)."}}
