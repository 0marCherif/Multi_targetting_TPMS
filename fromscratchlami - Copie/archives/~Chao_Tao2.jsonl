{"id": "tSYfwCAh9_k", "cdate": 1609459200000, "mdate": 1655015343606, "content": {"title": "Near-Optimal MNL Bandits Under Risk Criteria", "abstract": "We study MNL bandits, which is a variant of the traditional multi-armed bandit problem, under risk criteria. Unlike the ordinary expected revenue, risk criteria are more general goals widely used in industries and business. We design algorithms for a broad class of risk criteria, including but not limited to the well-known conditional value-at-risk, Sharpe ratio, and entropy risk, and prove that they suffer a near-optimal regret. As a complement, we also conduct experiments with both synthetic and real data to show the empirical performance of our proposed algorithms."}}
{"id": "huU_WWQw-dZ", "cdate": 1546300800000, "mdate": 1655015343606, "content": {"title": "Collaborative Learning with Limited Interaction: Tight Bounds for Distributed Exploration in Multi-armed Bandits", "abstract": "Best arm identification (or, pure exploration) in multi-armed bandits is a fundamental problem in machine learning. In this paper we study the distributed version of this problem where we have multiple agents, and they want to learn the best arm collaboratively. We want to quantify the power of collaboration under limited interaction (or, communication steps), as interaction is expensive in many settings. We measure the running time of a distributed algorithm as the speedup over the best centralized algorithm where there is only one agent. We give almost tight round-speedup tradeoffs for this problem, along which we develop several new techniques for proving lower bounds on the number of communication steps under time or confidence constraints."}}
{"id": "VRU_nMSQE9I", "cdate": 1546300800000, "mdate": 1655015343592, "content": {"title": "Thresholding Bandit with Optimal Aggregate Regret", "abstract": "We consider the thresholding bandit problem, whose goal is to find arms of mean rewards above a given threshold $\\theta$, with a fixed budget of $T$ trials. We introduce LSA, a new, simple and anytime algorithm that aims to minimize the aggregate regret (or the expected number of mis-classified arms). We prove that our algorithm is instance-wise asymptotically optimal. We also provide comprehensive empirical results to demonstrate the algorithm's superior performance over existing algorithms under a variety of different scenarios."}}
{"id": "SJEtdiWdZB", "cdate": 1514764800000, "mdate": null, "content": {"title": "Best Arm Identification in Linear Bandits with Linear Dimension Dependency", "abstract": "We study the best arm identification problem in linear bandits, where the mean reward of each arm depends linearly on an unknown $d$-dimensional parameter vector $\\theta$, and the goal is to identi..."}}
