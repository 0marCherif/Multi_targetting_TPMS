{"id": "6f47WT-HtuH", "cdate": 1663850093137, "mdate": null, "content": {"title": "Unfair geometries: exactly solvable data model with fairness implications", "abstract": "Machine learning (ML) may be oblivious to human bias but it is not immune to its perpetuation. Marginalisation and iniquitous group representation are often traceable in the very data used for training, and may be reflected or even enhanced by the learning models.\nIn the present work, we aim at clarifying the role played by data geometry in the emergence of ML bias. We introduce an exactly solvable high-dimensional model of data imbalance, where parametric control over the many bias-inducing factors allows for an extensive exploration of the bias inheritance mechanism.Through the tools of statistical physics, we analytically characterise the typical properties of learning models trained in this synthetic framework and obtain exact predictions for the observables that are commonly employed for fairness assessment.\nDespite the simplicity of the data model, we retrace and unpack typical unfairness behaviour observed on real-world datasets. \nWe also obtain a detailed analytical characterisation of a class of bias mitigation strategies. We first consider a basic loss-reweighing scheme, which allows for an implicit minimisation of different unfairness metrics, and quantify the incompatibilities between some existing fairness criteria. Then, we consider a novel mitigation strategy based on a matched inference approach, consisting in the introduction of coupled learning models. Our theoretical analysis of this approach shows that the coupled strategy can strike superior fairness-accuracy trade-offs."}}
{"id": "4d_tnQ_agHI", "cdate": 1652737696843, "mdate": null, "content": {"title": "An Analytical Theory of Curriculum Learning in Teacher-Student Networks", "abstract": "    In animals and humans, curriculum learning---presenting data in a curated order---is critical to rapid learning and effective pedagogy. \n    A long history of experiments has demonstrated the impact of curricula in a variety of animals but, despite its ubiquitous presence, a theoretical understanding of the phenomenon is still lacking. \n    Surprisingly, in contrast to animal learning, curricula strategies are not widely used in machine learning and recent simulation studies reach the conclusion that curricula are moderately effective or ineffective in most cases. \n    This stark difference in the importance of curriculum raises a fundamental theoretical question: when and why does curriculum learning help? \n    In this work, we analyse a prototypical neural network model of curriculum learning in the high-dimensional limit, employing statistical physics methods. \n    We study a task in which a sparse set of informative features are embedded amidst a large set of noisy features. We analytically derive average learning trajectories for simple neural networks on this task, which establish a clear speed benefit for curriculum learning in the online setting. However, when training experiences can be stored and replayed (for instance, during sleep), the advantage of curriculum in standard neural networks disappears, in line with observations from the deep learning literature. \n    Inspired by synaptic consolidation techniques developed to combat catastrophic forgetting, we investigate whether consolidating synapses at curriculum change points can boost the benefits of curricula. We derive generalisation performance as a function of consolidation strength (implemented as a Gaussian prior connecting learning phases), and show that this consolidation mechanism can yield a large improvement in test performance.\n    Our reduced analytical descriptions help reconcile apparently conflicting empirical results, trace regimes where curriculum learning yields the largest gains, and provide experimentally-accessible predictions for the impact of task parameters on curriculum benefits. More broadly, our results suggest that fully exploiting a curriculum may require explicit consolidation at curriculum boundaries."}}
{"id": "11rXr_KSl4M", "cdate": 1597054389818, "mdate": null, "content": {"title": "Role of synaptic stochasticity in training low-precision neural networks", "abstract": "Stochasticity and limited precision of synaptic weights in neural network models are key aspects of both biological and hardware modeling of learning processes. Here we show that a neural network model with stochastic binary weights naturally gives prominence to exponentially rare dense regions of solutions with a number of desirable properties such as robustness and good generalization performance, while typical solutions are isolated and hard to find. Binary solutions of the standard perceptron problem are obtained from a simple gradient descent procedure on a set of real values parametrizing a probability distribution over the binary synapses. Both analytical and numerical results are presented. An algorithmic extension that allows to train discrete deep neural networks is also investigated."}}
{"id": "pzcEDrINylg", "cdate": 1597054172713, "mdate": null, "content": {"title": "Large deviations for the perceptron model and consequences for active learning", "abstract": "Active learning is a branch of machine learning that deals with problems where unlabeled data is abundant yet obtaining labels is expensive. The learning algorithm has the possibility of querying a limited number of samples to obtain the corresponding labels, subsequently used for supervised learning. In this work, we consider the task of choosing the subset of samples to be labeled from a fixed finite pool of samples. We assume the pool of samples to be a random matrix and the ground truth labels to be generated by a single-layer teacher random neural network. We employ replica methods to analyze the large deviations for the accuracy achieved after supervised learning on a subset of the original pool. These large deviations then provide optimal achievable performance boundaries for any active learning algorithm. We show that the optimal learning performance can be efficiently approached by simple message-passing active learning algorithms. We also provide a comparison with the performance of some other popular active learning strategies."}}
{"id": "SrzvN7INv32", "cdate": 1597053976750, "mdate": null, "content": {"title": "Unreasonable effectiveness of learning neural networks: From accessible states and robust ensembles to basic algorithmic schemes", "abstract": "In artificial neural networks, learning from data is a computationally demanding task in which a large number of connection\nweights are iteratively tuned through stochastic-gradient-based\nheuristic processes over a cost function. It is not well understood how learning occurs in these systems, in particular how\nthey avoid getting trapped in configurations with poor computational performance. Here, we study the difficult case of networks with discrete weights, where the optimization landscape is\nvery rough even for simple architectures, and provide theoretical\nand numerical evidence of the existence of rare\u2014but extremely\ndense and accessible\u2014regions of configurations in the network\nweight space. We define a measure, the robust ensemble (RE),\nwhich suppresses trapping by isolated configurations and amplifies the role of these dense regions. We analytically compute the\nRE in some exactly solvable models and also provide a general\nalgorithmic scheme that is straightforward to implement: define\na cost function given by a sum of a finite number of replicas of\nthe original cost function, with a constraint centering the replicas\naround a driving assignment. To illustrate this, we derive several\npowerful algorithms, ranging from Markov Chains to message\npassing to gradient descent processes, where the algorithms target the robust dense states, resulting in substantial improvements in performance. The weak dependence on the number of\nprecision bits of the weights leads us to conjecture that very\nsimilar reasoning applies to more conventional neural networks.\nAnalogous algorithmic schemes can also be applied to other\noptimization problems."}}
{"id": "rkbjxi-u-H", "cdate": 1546300800000, "mdate": null, "content": {"title": "Generalized Approximate Survey Propagation for High-Dimensional Estimation", "abstract": "In Generalized Linear Estimation (GLE) problems, we seek to estimate a signal that is observed through a linear transform followed by a component-wise, possibly nonlinear and noisy, channel. In the..."}}
{"id": "SyVUd_WOWH", "cdate": 1514764800000, "mdate": null, "content": {"title": "Gaussian Process Prior Variational Autoencoders", "abstract": "Variational autoencoders (VAE) are a powerful and widely-used class of models to learn complex data distributions in an unsupervised fashion. One important limitation of VAEs is the prior assumption that latent sample representations are independent and identically distributed. However, for many important datasets, such as time-series of images, this assumption is too strong: accounting for covariances between samples, such as those in time, can yield to a more appropriate model specification and improve performance in downstream tasks. In this work, we introduce a new model, the Gaussian Process (GP) Prior Variational Autoencoder (GPPVAE), to specifically address this issue. The GPPVAE aims to combine the power of VAEs with the ability to model correlations afforded by GP priors. To achieve efficient inference in this new class of models, we leverage structure in the covariance matrix, and introduce a new stochastic backpropagation strategy that allows for computing stochastic gradients in a distributed and low-memory fashion. We show that our method outperforms conditional VAEs (CVAEs) and an adaptation of standard VAEs in two image data applications."}}
