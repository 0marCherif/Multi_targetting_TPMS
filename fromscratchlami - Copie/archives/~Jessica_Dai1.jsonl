{"id": "Khj3IpED5iZ", "cdate": 1640995200000, "mdate": 1683948920250, "content": {"title": "Fairness via Explanation Quality: Evaluating Disparities in the Quality of Post hoc Explanations", "abstract": ""}}
{"id": "ur-zkHwBbd5", "cdate": 1609459200000, "mdate": 1683948920266, "content": {"title": "Fair Machine Learning Under Partial Compliance", "abstract": ""}}
{"id": "uMkpYybUeY", "cdate": 1609459200000, "mdate": 1683948920238, "content": {"title": "What will it take to generate fairness-preserving explanations?", "abstract": "In situations where explanations of black-box models may be useful, the fairness of the black-box is also often a relevant concern. However, the link between the fairness of the black-box model and the behavior of explanations for the black-box is unclear. We focus on explanations applied to tabular datasets, suggesting that explanations do not necessarily preserve the fairness properties of the black-box algorithm. In other words, explanation algorithms can ignore or obscure critical relevant properties, creating incorrect or misleading explanations. More broadly, we propose future research directions for evaluating and generating explanations such that they are informative and relevant from a fairness perspective."}}
