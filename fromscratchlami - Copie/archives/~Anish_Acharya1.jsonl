{"id": "wSJsR5uqxp", "cdate": 1675118359893, "mdate": 1675118359893, "content": {"title": "Positive Unlabeled Contrastive Learning", "abstract": "Self-supervised pretraining on unlabeled data followed by supervised finetuning\non labeled data is a popular paradigm for learning from limited labeled examples.\nIn this paper, we investigate and extend this paradigm to the classical positive unlabeled (PU) setting - the weakly supervised task of learning a binary classifier only\nusing a few labeled positive examples and a set of unlabeled samples. We propose\na novel PU learning objective positive unlabeled Noise Contrastive Estimation\n(puNCE) that leverages the available explicit (from labeled samples) and implicit\n(from unlabeled samples) supervision to learn useful representations from positive\nunlabeled input data. The underlying idea is to assign each training sample an\nindividual weight; labeled positives are given unit weight; unlabeled samples are\nduplicated, one copy is labeled positive and the other as negative with weights \u03c0\nand (1 \u2212 \u03c0) where \u03c0 denotes the class prior. Extensive experiments across vision\nand natural language tasks reveal that puNCE consistently improves over existing\nunsupervised and supervised contrastive baselines under limited supervision."}}
{"id": "I7-KGoBeRMk", "cdate": 1664567041977, "mdate": 1664567041977, "content": {"title": "On the Benefits of Multiple Gossip Steps in Communication-Constrained Decentralized Federated Learning", "abstract": "Federated learning (FL) is an emerging collaborative machine learning (ML) framework that enables training of predictive models in a distributed fashion where the communication among the participating nodes are facilitated by a central server. To deal with the communication bottleneck at the server, decentralized FL (DFL) methods advocate rely on local communication of nodes with their neighbors according to a specific communication network. In DFL, it is common algorithmic practice to have nodes interleave (local) gradient descent iterations with gossip (i.e. averaging over the network) steps. As the size of the ML models grows, the limited communication bandwidth among the nodes does not permit communication of full-precision messages; hence, it is becoming increasingly common to require that messages be {\\em lossy, compressed} versions of the local parameters. The requirement of communicating compressed messages gives rise to the important question: {\\em given a fixed communication budget, what should be our communication strategy to minimize the (training) loss as much as possible?} In this paper, we explore this direction, and show that in such compressed DFL settings, there are benefits to having {\\em multiple} gossip steps between subsequent gradient iterations, even when the cost of doing so is appropriately accounted for, e.g. by means of reducing the precision of compressed information. In particular, we show that having $\\O(\\log\\frac{1}{\\epsilon})$ gradient iterations {with constant step size} - and $\\O(\\log\\frac{1}{\\epsilon})$ gossip steps between every pair of these iterations - enables convergence to within $\\epsilon$ of the optimal value for a class of non-convex problems that arise in the training of deep learning models, namely, smooth non-convex objectives satisfying Polyak-\\L{}ojasiewicz condition. Empirically, we show that our proposed scheme bridges the gap between centralized gradient descent and DFL on various machine learning tasks across different network topologies and compression operators."}}
{"id": "SSlLRUIs9e9", "cdate": 1646077526332, "mdate": null, "content": {"title": "Faster Non-Convex Federated Learning via Global and Local Momentum", "abstract": "We propose \\texttt{FedGLOMO}, a novel federated learning (FL) algorithm with an iteration complexity of $\\mathcal{O}(\\epsilon^{-1.5})$ to converge to an $\\epsilon$-stationary point (i.e., $\\mathbb{E}[\\|\\nabla f(x)\\|^2] \\leq \\epsilon$) for smooth non-convex functions -- under arbitrary client heterogeneity and compressed communication -- compared to the $\\mathcal{O}(\\epsilon^{-2})$ complexity of most prior works. Our key algorithmic idea that enables achieving this improved complexity is based on the observation that the convergence in FL is hampered by two sources of high variance: (i) the global server aggregation step with multiple local updates, exacerbated by client heterogeneity, and (ii) the noise of the local client-level stochastic gradients. The first issue is particularly detrimental to FL algorithms that perform plain averaging at the server. By modeling the server aggregation step as a generalized gradient-type update, we propose a variance-reducing momentum-based global update at the server, which when applied in conjunction with variance-reduced local updates at the clients, enables \\texttt{FedGLOMO} to enjoy an improved convergence rate. Our experiments illustrate the intrinsic variance reduction effect of \\texttt{FedGLOMO}, which implicitly suppresses client-drift in heterogeneous data distribution settings and promotes communication efficiency."}}
{"id": "pTJKCACq6tM", "cdate": 1632875455419, "mdate": null, "content": {"title": "Robust Training in High Dimensions via Block Coordinate Geometric Median Descent", "abstract": "Geometric median (GM) is a classical method in statistics for achieving a robust estimation of the  uncorrupted data; under gross corruption, it achieves the optimal breakdown point of 0.5. However, its computational complexity makes it infeasible for robustifying stochastic gradient descent (SGD) for high-dimensional optimization problems. In this paper, we show that by applying GM to only a judiciously chosen block of coordinates at a time and using a memory mechanism, one can retain the breakdown point of 0.5 for smooth non-convex problems, with non-asymptotic convergence rates comparable to the SGD with GM.\n\nWe validate both the runtime and the robustness of our approach empirically on three neural network settings including ResNet-18 on CIFAR-10 and MLP / LeNet on Fashion-MNIST."}}
{"id": "shzNQDcu9iV", "cdate": 1620330185692, "mdate": null, "content": {"title": "Alexa Conversations: An Extensible Data-driven Approach for Building Task-oriented Dialogue Systems", "abstract": "Traditional goal-oriented dialogue systems rely on various components such as natural language understanding, dialogue state tracking, policy learning and response generation. Training each component requires annotations which are hard to obtain for every new domain, limiting scalability of such systems. Similarly, rule-based dialogue systems require extensive writing and maintenance of rules and do not scale either. End-to-End dialogue systems, on the other hand, do not require module-specific annotations but need a large amount of data for training. To overcome these problems, in this demo, we present Alexa Conversations, a new approach for building goal-oriented dialogue systems that is scalable, extensible as well as data efficient. The components of this system are trained in a data-driven manner, but instead of collecting annotated conversations for training, we generate them using a novel dialogue simulator based on a few seed dialogues and specifications of APIs and entities provided by the developer. Our approach provides out-of-the-box support for natural conversational phenomena like entity sharing across turns or users changing their mind during conversation without requiring developers to provide any such dialogue flows. We exemplify our approach using a simple pizza ordering task and showcase its value in reducing the developer burden for creating a robust experience. Finally, we evaluate our system using a typical movie ticket booking task and show that the dialogue simulator is an essential component of the system that leads to over 50% improvement in turn-level action signature prediction accuracy. "}}
{"id": "BibZ0yGeuar", "cdate": 1546300800000, "mdate": null, "content": {"title": "Online Embedding Compression for Text Classification Using Low Rank Matrix Factorization.", "abstract": "Deep learning models have become state of the art for natural language processing (NLP) tasks, however deploying these models in production system poses significant memory constraints. Existing compression methods are either lossy or introduce significant latency. We propose a compression method that leverages low rank matrix factorization during training, to compress the word embedding layer which represents the size bottleneck for most NLP models. Our models are trained, compressed and then further re-trained on the downstream task to recover accuracy while maintaining the reduced size. Empirically, we show that the proposed method can achieve 90% compression with minimal impact in accuracy for sentence classification tasks, and outperforms alternative methods like fixed-point quantization or offline word embedding compression. We also analyze the inference time and storage space for our method through FLOP calculations, showing that we can compress DNN models by a configurable ratio and regain accuracy loss without introducing additional latency compared to fixed point quantization. Finally, we introduce a novel learning rate schedule, the Cyclically Annealed Learning Rate (CALR), which we empirically demonstrate to outperform other popular adaptive learning rate algorithms on a sentence classification benchmark."}}
