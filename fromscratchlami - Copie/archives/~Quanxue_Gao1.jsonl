{"id": "gm77A5cyq6", "cdate": 1680307200000, "mdate": 1684211885404, "content": {"title": "Tensorized Bipartite Graph Learning for Multi-View Clustering", "abstract": "Despite the impressive clustering performance and efficiency in characterizing both the relationship between the data and cluster structure, most existing graph-based multi-view clustering methods still have the following drawbacks. They suffer from the expensive time burden due to both the construction of graphs and eigen-decomposition of Laplacian matrix. Moreover, none of them simultaneously considers the similarity of inter-view and similarity of intra-view. In this article, we propose a variance-based de-correlation anchor selection strategy for bipartite construction. The selected anchors not only cover the whole classes but also characterize the intrinsic structure of data. Following that, we present a <i>tensorized bipartite graph learning for multi-view clustering</i> (TBGL). Specifically, TBGL exploits the similarity of inter-view by minimizing the tensor Schatten <i>p</i> -norm, which well exploits both the spatial structure and complementary information embedded in the bipartite graphs of views. We exploit the similarity of intra-view by using the <inline-formula><tex-math notation=\"LaTeX\">$\\ell _{\\text {1,2}}$</tex-math></inline-formula> -norm minimization regularization and connectivity constraint on each bipartite graph. So the learned graph not only well encodes discriminative information but also has the exact connected components which directly indicates the clusters of data. Moreover, we solve TBGL by an efficient algorithm which is time-economical and has good convergence. Extensive experimental results demonstrate that TBGL is superior to the state-of-the-art methods. Codes and datasets are available: <uri>https://github.com/xdweixia/TBGL-MVC</uri> ."}}
{"id": "KteiMKs_ia", "cdate": 1680307200000, "mdate": 1684211885058, "content": {"title": "Enhanced tensor low-rank representation learning for multi-view clustering", "abstract": ""}}
{"id": "xyS1Kn75XT", "cdate": 1672531200000, "mdate": 1684211885350, "content": {"title": "Multi-View Clustering via Semi-non-negative Tensor Factorization", "abstract": "Multi-view clustering (MVC) based on non-negative matrix factorization (NMF) and its variants have received a huge amount of attention in recent years due to their advantages in clustering interpretability. However, existing NMF-based multi-view clustering methods perform NMF on each view data respectively and ignore the impact of between-view. Thus, they can't well exploit the within-view spatial structure and between-view complementary information. To resolve this issue, we present semi-non-negative tensor factorization (Semi-NTF) and develop a novel multi-view clustering based on Semi-NTF with one-side orthogonal constraint. Our model directly performs Semi-NTF on the 3rd-order tensor which is composed of anchor graphs of views. Thus, our model directly considers the between-view relationship. Moreover, we use the tensor Schatten p-norm regularization as a rank approximation of the 3rd-order tensor which characterizes the cluster structure of multi-view data and exploits the between-view complementary information. In addition, we provide an optimization algorithm for the proposed method and prove mathematically that the algorithm always converges to the stationary KKT point. Extensive experiments on various benchmark datasets indicate that our proposed method is able to achieve satisfactory clustering performance."}}
{"id": "lvL0GmMVsy", "cdate": 1672531200000, "mdate": 1684479741075, "content": {"title": "Rethinking k-means from manifold learning perspective", "abstract": "Although numerous clustering algorithms have been developed, many existing methods still leverage k-means technique to detect clusters of data points. However, the performance of k-means heavily depends on the estimation of centers of clusters, which is very difficult to achieve an optimal solution. Another major drawback is that it is sensitive to noise and outlier data. In this paper, from manifold learning perspective, we rethink k-means and present a new clustering algorithm which directly detects clusters of data without mean estimation. Specifically, we construct distance matrix between data points by Butterworth filter such that distance between any two data points in the same clusters equals to a small constant, while increasing the distance between other data pairs from different clusters. To well exploit the complementary information embedded in different views, we leverage the tensor Schatten p-norm regularization on the 3rd-order tensor which consists of indicator matrices of different views. Finally, an efficient alternating algorithm is derived to optimize our model. The constructed sequence was proved to converge to the stationary KKT point. Extensive experimental results indicate the superiority of our proposed method."}}
{"id": "HHH83XEMSwX", "cdate": 1672531200000, "mdate": 1684211885433, "content": {"title": "Graph Embedding Contrastive Multi-Modal Representation Learning for Clustering", "abstract": "Multi-modal clustering (MMC) aims to explore complementary information from diverse modalities for clustering performance facilitating. This article studies challenging problems in MMC methods based on deep neural networks. On one hand, most existing methods lack a unified objective to simultaneously learn the inter- and intra-modality consistency, resulting in a limited representation learning capacity. On the other hand, most existing processes are modeled for a finite sample set and cannot handle out-of-sample data. To handle the above two challenges, we propose a novel Graph Embedding Contrastive Multi-modal Clustering network (GECMC), which treats the representation learning and multi-modal clustering as two sides of one coin rather than two separate problems. In brief, we specifically design a contrastive loss by benefiting from pseudo-labels to explore consistency across modalities. Thus, GECMC shows an effective way to maximize the similarities of intra-cluster representations while minimizing the similarities of inter-cluster representations at both inter- and intra-modality levels. So, the clustering and representation learning interact and jointly evolve in a co-training framework. After that, we build a clustering layer parameterized with cluster centroids, showing that GECMC can learn the clustering labels with given samples and handle out-of-sample data. GECMC yields superior results than 14 competitive methods on four challenging datasets. Codes and datasets are available: <uri xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">https://github.com/xdweixia/GECMC</uri> ."}}
{"id": "xK0X7hzoSTw", "cdate": 1640995200000, "mdate": 1684211885301, "content": {"title": "Multiview Spectral Clustering With Bipartite Graph", "abstract": "Multi-view spectral clustering has become appealing due to its good performance in capturing the correlations among all views. However, on one hand, many existing methods usually require a quadratic or cubic complexity for graph construction or eigenvalue decomposition of Laplacian matrix; on the other hand, they are inefficient and unbearable burden to be applied to large scale data sets, which can be easily obtained in the era of big data. Moreover, the existing methods cannot encode the complementary information between adjacency matrices, <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">i.e.</i> , similarity graphs of views and the low-rank spatial structure of adjacency matrix of each view. To address these limitations, we develop a novel multi-view spectral clustering model. Our model well encodes the complementary information by Schatten <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"> <tex-math notation=\"LaTeX\">$p$ </tex-math></inline-formula> -norm regularization on the third tensor whose lateral slices are composed of the adjacency matrices of the corresponding views. To further improve the computational efficiency, we leverage anchor graphs of views instead of full adjacency matrices of the corresponding views, and then present a fast model that encodes the complementary information embedded in anchor graphs of views by Schatten <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"> <tex-math notation=\"LaTeX\">$p$ </tex-math></inline-formula> -norm regularization on the tensor bipartite graph. Finally, an efficient alternating algorithm is derived to optimize our model. The constructed sequence was proved to converge to the stationary KKT point. Extensive experimental results indicate that our method has good performance."}}
{"id": "w8JbnQC0xV", "cdate": 1640995200000, "mdate": 1684211885356, "content": {"title": "Contrastive deep embedded clustering", "abstract": ""}}
{"id": "nvQirTqUYB8", "cdate": 1640995200000, "mdate": 1684211885310, "content": {"title": "Self-Supervised Graph Convolutional Network for Multi-View Clustering", "abstract": "Despite the promising preliminary results, existing graph convolutional network (GCN) based multi-view learning methods directly use the graph structure as view descriptor, which may inhibit the ability of multi-view learning for multimedia data. The major reason is that, in real multimedia applications, the graph structure may contain outliers. Moreover, they fail to take advantage of the information embedded in the inaccurate clustering labels obtained from their proposed methods, resulting in inferior clustering results. These observations motivate us to study whether there is a better alternative GCN based framework for multi-view clustering. To this end, in this paper, we propose an end-to-end self-supervised graph convolutional network for multi-view clustering (SGCMC). Specifically, SGCMC constructs a new view descriptor for graph-structured data by mapping the raw node content into the complex space via Euler transformation, which not only suppresses outliers but also reveals non-linear patterns embedded in data. Meanwhile, the proposed SGCMC uses the clustering labels to guide the learning of the latent representation and coefficient matrix, and the latter in turn is used to conduct the subsequent node clustering. By this way, clustering and representation learning are seamlessly connected, with the aim to achieve better clustering results. Extensive experimental results indicate that the proposed SGCMC outperforms the state-of-the-art methods."}}
{"id": "nAv2NcZEFuX", "cdate": 1640995200000, "mdate": 1683894774867, "content": {"title": "A multi-view clustering framework via integrating K-means and graph-cut", "abstract": ""}}
{"id": "muuzL9O9D6t", "cdate": 1640995200000, "mdate": 1684211885443, "content": {"title": "View-Consistency Learning for Incomplete Multiview Clustering", "abstract": "In this article, we present a novel general framework for incomplete multi-view clustering by integrating graph learning and spectral clustering. In our model, a tensor low-rank constraint are introduced to learn a stable low-dimensional representation, which encodes the complementary information and takes into account the cluster structure between different views. A corresponding algorithm associated with augmented Lagrangian multipliers is established. In particular, tensor Schatten  <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"> <tex-math notation=\"LaTeX\">$p$ </tex-math></inline-formula> -norm is used as a tighter approximation to the tensor rank function. Besides, both consistency and specificity are jointly exploited for subspace representation learning. Extensive experiments on benchmark datasets demonstrate that our model outperforms several baseline methods in incomplete multi-view clustering."}}
