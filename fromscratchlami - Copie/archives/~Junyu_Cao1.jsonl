{"id": "2ezIHvA06VK", "cdate": 1684220745392, "mdate": 1684220745392, "content": {"title": "Stall Economy: The Value of Mobility in Retail on Wheels", "abstract": "Urban open space emerges as a new territory to embrace retail innovations. Selling products in public spaces with wheeled stalls can potentially become ubiquitous in our future cities. Transition into such a \u201cstall economy\u201d paradigm is being spurred by the rapidly advancing self-driving technologies. Motivated by this transformation, this paper provides models, theory, and insights of spatial queueing systems, in which one server moves around to meet mobile customers/machines and in which the \u201clast 100 meters\u201d are expensive. Specifically, we study two service modes: (i) on-demand, first come, first served and (ii) spatially and temporally pooling customer demands. In each mode, we derive the dependence of customer waiting and stall repositioning on two key decisions: the service zone size and the walking distance imposed on customers to meet a stall. In particular, for the on-demand mode, we propose and solve a \u201crendezvous problem\u201d to analytically characterize the spatial distribution of the stall-customer meeting locations. We also propose a stylized joint truck-stall routing model to capture the inventory replenishment operations. Our main finding is that the stall economy potentially profits more than stationary retail, not only because of the mobility of stalls for providing proximity to customers, but also because of its operational flexibilities that allow for avoiding the \u201clast 100 meters\u201d and pooling demands. In a broader sense, this work looks toward an expanded scope of future retail empowered by self-driving technologies."}}
{"id": "xEAI4RctuWg", "cdate": 1577836800000, "mdate": null, "content": {"title": "Fatigue-Aware Bandits for Dependent Click Models", "abstract": "As recommender systems send a massive amount of content to keep users engaged, users may experience fatigue which is contributed by 1) an overexposure to irrelevant content, 2) boredom from seeing too many similar recommendations. To address this problem, we consider an online learning setting where a platform learns a policy to recommend content that takes user fatigue into account. We propose an extension of the Dependent Click Model (DCM) to describe users' behavior. We stipulate that for each piece of content, its attractiveness to a user depends on its intrinsic relevance and a discount factor which measures how many similar contents have been shown. Users view the recommended content sequentially and click on the ones that they find attractive. Users may leave the platform at any time, and the probability of exiting is higher when they do not like the content. Based on user's feedback, the platform learns the relevance of the underlying content as well as the discounting effect due to content fatigue. We refer to this learning task as \u201cfatigue-aware DCM Bandit\u201d problem. We consider two learning scenarios depending on whether the discounting effect is known. For each scenario, we propose a learning algorithm which simultaneously explores and exploits, and characterize its regret bound."}}
{"id": "BXW9lGxOpH", "cdate": 1546300800000, "mdate": null, "content": {"title": "Dynamic Learning of Sequential Choice Bandit Problem under Marketing Fatigue.", "abstract": "Motivated by the observation that overexposure to unwanted marketing activities leads to customer dissatisfaction, we consider a setting where a platform offers a sequence of messages to its users and is penalized when users abandon the platform due to marketing fatigue. We propose a novel sequential choice model to capture multiple interactions taking place between the platform and its user: Upon receiving a message, a user decides on one of the three actions: accept the message, skip and receive the next message, or abandon the platform. Based on user feedback, the platform dynamically learns users\u2019 abandonment distribution and their valuations of messages to determine the length of the sequence and the order of the messages, while maximizing the cumulative payoff over a horizon of length T. We refer to this online learning task as the sequential choice bandit problem. For the offline combinatorial optimization problem, we show a polynomialtime algorithm. For the online problem, we propose an algorithm that balances exploration and exploitation, and characterize its regret bound. Lastly, we demonstrate how to extend the model with user contexts to incorporate personalization."}}
{"id": "B1b2ZhWOZS", "cdate": 1546300800000, "mdate": null, "content": {"title": "Dynamic Learning with Frequent New Product Launches: A Sequential Multinomial Logit Bandit Problem", "abstract": "Motivated by the phenomenon that companies introduce new products to keep abreast with customers\u2019 rapidly changing tastes, we consider a novel online learning setting where a profit-maximizing sell..."}}
