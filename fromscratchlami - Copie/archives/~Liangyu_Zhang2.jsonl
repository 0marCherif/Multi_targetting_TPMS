{"id": "ohk8bILFDkk", "cdate": 1652737503043, "mdate": null, "content": {"title": "Semi-infinitely Constrained Markov Decision Processes", "abstract": "We propose a generalization of constrained Markov decision processes (CMDPs) that we call the \\emph{semi-infinitely constrained Markov decision process} (SICMDP).\nParticularly, in a SICMDP model, we impose a continuum of constraints instead of a finite number of constraints as in the case of ordinary CMDPs.\nWe also devise a reinforcement learning algorithm for SICMDPs that we call SI-CRL.\nWe first transform the reinforcement learning problem into a linear semi-infinitely programming (LSIP) problem and then use the dual exchange method in the LSIP literature to solve it.\nTo the best of our knowledge, we are the first to apply tools from semi-infinitely programming (SIP) to solve reinforcement learning problems.\nWe present theoretical analysis for SI-CRL, identifying its sample complexity and iteration complexity.\nWe also conduct extensive numerical examples to illustrate the SICMDP model and validate the SI-CRL algorithm."}}
{"id": "QhsOyYzdyZ", "cdate": 1640995200000, "mdate": 1682318666377, "content": {"title": "Statistical Estimation of Confounded Linear MDPs: An Instrumental Variable Approach", "abstract": "In an Markov decision process (MDP), unobservable confounders may exist and have impacts on the data generating process, so that the classic off-policy evaluation (OPE) estimators may fail to identify the true value function of the target policy. In this paper, we study the statistical properties of OPE in confounded MDPs with observable instrumental variables. Specifically, we propose a two-stage estimator based on the instrumental variables and establish its statistical properties in the confounded MDPs with a linear structure. For non-asymptotic analysis, we prove a $\\mathcal{O}(n^{-1/2})$-error bound where $n$ is the number of samples. For asymptotic analysis, we prove that the two-stage estimator is asymptotically normal with a typical rate of $n^{1/2}$. To the best of our knowledge, we are the first to show such statistical results of the two-stage estimator for confounded linear MDPs via instrumental variables."}}
{"id": "KTEde38blNB", "cdate": 1601308187337, "mdate": null, "content": {"title": "Intervention Generative Adversarial Nets", "abstract": "In this paper we propose a novel approach for stabilizing the training process of Generative Adversarial Networks as well as alleviating the mode collapse problem. The main idea is to incorporate a regularization term that we call intervention into the objective. We refer to the resulting generative model as Intervention Generative Adversarial Networks (IVGAN). By perturbing the latent representations of real images obtained from an auxiliary encoder network with Gaussian invariant interventions and penalizing the dissimilarity of the distributions of the resulting generated images, the intervention term provides more informative gradient for the generator, significantly improving training stability and encouraging modecovering behaviour. We demonstrate the performance of our approach via solid theoretical analysis and thorough evaluation on standard real-world datasets as well as the stacked MNIST dataset.\n"}}
