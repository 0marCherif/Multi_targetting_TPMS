{"id": "x-1u5MXUy1z", "cdate": 1672531200000, "mdate": 1691529676839, "content": {"title": "M2Hub: Unlocking the Potential of Machine Learning for Materials Discovery", "abstract": "We introduce M$^2$Hub, a toolkit for advancing machine learning in materials discovery. Machine learning has achieved remarkable progress in modeling molecular structures, especially biomolecules for drug discovery. However, the development of machine learning approaches for modeling materials structures lag behind, which is partly due to the lack of an integrated platform that enables access to diverse tasks for materials discovery. To bridge this gap, M$^2$Hub will enable easy access to materials discovery tasks, datasets, machine learning methods, evaluations, and benchmark results that cover the entire workflow. Specifically, the first release of M$^2$Hub focuses on three key stages in materials discovery: virtual screening, inverse design, and molecular simulation, including 9 datasets that covers 6 types of materials with 56 tasks across 8 types of material properties. We further provide 2 synthetic datasets for the purpose of generative tasks on materials. In addition to random data splits, we also provide 3 additional data partitions to reflect the real-world materials discovery scenarios. State-of-the-art machine learning methods (including those are suitable for materials structures but never compared in the literature) are benchmarked on representative tasks. Our codes and library are publicly available at https://github.com/yuanqidu/M2Hub."}}
{"id": "lQf8L1L-ch", "cdate": 1672531200000, "mdate": 1681825306759, "content": {"title": "Time Series Contrastive Learning with Information-Aware Augmentations", "abstract": "Various contrastive learning approaches have been proposed in recent years and achieve significant empirical success. While effective and prevalent, contrastive learning has been less explored for time series data. A key component of contrastive learning is to select appropriate augmentations imposing some priors to construct feasible positive samples, such that an encoder can be trained to learn robust and discriminative representations. Unlike image and language domains where ``desired'' augmented samples can be generated with the rule of thumb guided by prefabricated human priors, the ad-hoc manual selection of time series augmentations is hindered by their diverse and human-unrecognizable temporal structures. How to find the desired augmentations of time series data that are meaningful for given contrastive learning tasks and datasets remains an open question. In this work, we address the problem by encouraging both high \\textit{fidelity} and \\textit{variety} based upon information theory. A theoretical analysis leads to the criteria for selecting feasible data augmentations. On top of that, we propose a new contrastive learning approach with information-aware augmentations, InfoTS, that adaptively selects optimal augmentations for time series representation learning. Experiments on various datasets show highly competitive performance with up to 12.0\\% reduction in MSE on forecasting tasks and up to 3.7\\% relative improvement in accuracy on classification tasks over the leading baselines."}}
{"id": "iVjxj5wlkcq", "cdate": 1672531200000, "mdate": 1691529676827, "content": {"title": "Time Series Contrastive Learning with Information-Aware Augmentations", "abstract": "Various contrastive learning approaches have been proposed in recent years and achieve significant empirical success. While effective and prevalent, contrastive learning has been less explored for time series data. A key component of contrastive learning is to select appropriate augmentations imposing some priors to construct feasible positive samples, such that an encoder can be trained to learn robust and discriminative representations. Unlike image and language domains where \"desired'' augmented samples can be generated with the rule of thumb guided by prefabricated human priors, the ad-hoc manual selection of time series augmentations is hindered by their diverse and human-unrecognizable temporal structures. How to find the desired augmentations of time series data that are meaningful for given contrastive learning tasks and datasets remains an open question. In this work, we address the problem by encouraging both high fidelity and variety based on information theory. A theoretical analysis leads to the criteria for selecting feasible data augmentations. On top of that, we propose a new contrastive learning approach with information-aware augmentations, InfoTS, that adaptively selects optimal augmentations for time series representation learning. Experiments on various datasets show highly competitive performance with up to a 12.0% reduction in MSE on forecasting tasks and up to 3.7% relative improvement in accuracy on classification tasks over the leading baselines."}}
{"id": "hpzm-9wlPs5", "cdate": 1672531200000, "mdate": 1682364023846, "content": {"title": "Xtal2DoS: Attention-based Crystal to Sequence Learning for Density of States Prediction", "abstract": "Modern machine learning techniques have been extensively applied to materials science, especially for property prediction tasks. A majority of these methods address scalar property predictions, while more challenging spectral properties remain less emphasized. We formulate a crystal-to-sequence learning task and propose a novel attention-based learning method, Xtal2DoS, which decodes the sequential representation of the material density of states (DoS) properties by incorporating the learned atomic embeddings through attention networks. Experiments show Xtal2DoS is faster than the existing models, and consistently outperforms other state-of-the-art methods on four metrics for two fundamental spectral properties, phonon and electronic DoS."}}
{"id": "-HeqUhI1lUl", "cdate": 1672531200000, "mdate": 1691529676834, "content": {"title": "InfoDiffusion: Representation Learning Using Information Maximizing Diffusion Models", "abstract": "While diffusion models excel at generating high-quality samples, their latent variables typically lack semantic meaning and are not suitable for representation learning. Here, we propose InfoDiffusion, an algorithm that augments diffusion models with low-dimensional latent variables that capture high-level factors of variation in the data. InfoDiffusion relies on a learning objective regularized with the mutual information between observed and hidden variables, which improves latent space quality and prevents the latents from being ignored by expressive diffusion-based decoders. Empirically, we find that InfoDiffusion learns disentangled and human-interpretable latent representations that are competitive with state-of-the-art generative and contrastive methods, while retaining the high sample quality of diffusion models. Our method enables manipulating the attributes of generated images and has the potential to assist tasks that require exploring a learned latent space to generate quality samples, e.g., generative design."}}
{"id": "Fw8PO9i5KG", "cdate": 1664248828009, "mdate": null, "content": {"title": "Xtal2DoS: Attention-based Crystal to Sequence Learning for Density of States Prediction", "abstract": "Modern machine learning techniques have been extensively applied to  materials science, especially for property prediction tasks. A majority of these methods address  scalar property predictions, while more challenging spectral properties remain less emphasized. We formulate a crystal-to-sequence learning task and propose a novel attention-based learning method, Xtal2DoS, which decodes the sequential representation of the material density of states (DoS) properties by incorporating the learned atomic embeddings through attention networks. Experiments show Xtal2DoS is faster than the existing models, and consistently outperforms other state-of-the-art methods on four metrics for two fundamental spectral properties, phonon and electronic DoS."}}
{"id": "wZWxv6zW0I8", "cdate": 1640995200000, "mdate": 1658539250465, "content": {"title": "Going Deeper into Permutation-Sensitive Graph Neural Networks", "abstract": "The invariance to permutations of the adjacency matrix, i.e., graph isomorphism, is an overarching requirement for Graph Neural Networks (GNNs). Conventionally, this prerequisite can be satisfied by the invariant operations over node permutations when aggregating messages. However, such an invariant manner may ignore the relationships among neighboring nodes, thereby hindering the expressivity of GNNs. In this work, we devise an efficient permutation-sensitive aggregation mechanism via permutation groups, capturing pairwise correlations between neighboring nodes. We prove that our approach is strictly more powerful than the 2-dimensional Weisfeiler-Lehman (2-WL) graph isomorphism test and not less powerful than the 3-WL test. Moreover, we prove that our approach achieves the linear sampling complexity. Comprehensive experiments on multiple synthetic and real-world datasets demonstrate the superiority of our model."}}
{"id": "ikuw0zov8D", "cdate": 1640995200000, "mdate": 1664243046582, "content": {"title": "Predicting the protein-ligand affinity from molecular dynamics trajectories", "abstract": "Accurate protein-ligand binding affinity prediction is essential in drug design and many other molecular recognition problems. Despite many advances in affinity prediction based on machine learning techniques, they are still limited since the protein-ligand binding is determined by the dynamics of atoms and molecules. To this end, we curated an MD dataset containing 3,218 dynamic protein-ligand complexes and further developed Dynaformer, a graph-based deep learning framework. Dynaformer can fully capture the dynamic binding modes by considering various geometric characteristics of the interaction. Our method shows superior performance on the benchmark dataset over the methods hitherto reported. Moreover, we performed virtual drug-screening on heat shock protein 90 (HSP90) by integrating our model with structure-based docking. We benchmarked our performance against the conventional knowledge-based approach, demonstrating that our method can identify two lead compounds with submicromolar activity (0.207\\textmu{}M and 0.517\\textmu{}M). We anticipate that large-scale MD dataset and machine learning models will form a new synergy, providing a new route toward accelerated drug discovery."}}
{"id": "era8ZHS1BHJ", "cdate": 1640995200000, "mdate": 1664243046577, "content": {"title": "Graph Emotion Decoding from Visually Evoked Neural Responses", "abstract": "Brain signal-based affective computing has recently drawn considerable attention due to its potential widespread applications. Most existing efforts exploit emotion similarities or brain region similarities to learn emotion representations. However, the relationships between emotions and brain regions are not explicitly incorporated into the representation learning process. Consequently, the learned representations may not be informative enough to benefit downstream tasks, e.g., emotion decoding. In this work, we propose a novel neural decoding framework, Graph Emotion Decoding (GED), which integrates the relationships between emotions and brain regions via a bipartite graph structure into the neural decoding process. Further analysis shows that exploiting such relationships helps learn better representations, verifying the rationality and effectiveness of GED. Comprehensive experiments on visually evoked emotion datasets demonstrate the superiority of our model. The code is publicly available at https://github.com/zhongyu1998/GED ."}}
{"id": "eO2Nr-Sn-sk", "cdate": 1640995200000, "mdate": 1658539250462, "content": {"title": "Going Deeper into Permutation-Sensitive Graph Neural Networks", "abstract": "The invariance to permutations of the adjacency matrix, i.e., graph isomorphism, is an overarching requirement for Graph Neural Networks (GNNs). Conventionally, this prerequisite can be satisfied b..."}}
