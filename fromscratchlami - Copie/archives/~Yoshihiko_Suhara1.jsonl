{"id": "Fm-IH-Gfg3fI", "cdate": 1642716263117, "mdate": 1642716263117, "content": {"title": "Extracting Salient Facts from Company Reviews with Scarce Labels", "abstract": "In this paper, we propose a task of extracting salient facts from online company reviews. Salient facts present unique and distinctive information about a company, which helps the user decide whether to apply to the company. We formulate the salient fact extraction task as a text classification problem and leverage pre-trained language models to tackle the problem. However, the scarcity of salient facts in company reviews causes a serious label imbalance issue, which makes it difficult to take full advantage of pre-trained language models. To address the issue, we develop two data enrichment methods: the first one, representation enrichment, which highlights uncommon tokens by appending special tokens, and the second one, label propagation, which creates pseudo positive examples from unlabeled data in an interactive manner. Experimental results on an online company review corpus show that our approach improves the performance of pre-trained language models by up to an F1 score of 0.24. We also confirm that our approach competitively performs well against the state-of-the-art data augmentation method on the SemEval 2019 benchmark, even when trained with only 20% of training data."}}
{"id": "tVn-yP8U4e", "cdate": 1640995200000, "mdate": 1681715161432, "content": {"title": "Comparative Opinion Summarization via Collaborative Decoding", "abstract": ""}}
{"id": "I4lUG5XdYh", "cdate": 1640995200000, "mdate": 1681715161430, "content": {"title": "Annotating Columns with Pre-trained Language Models", "abstract": "Inferring meta information about tables, such as column headers or relationships between columns, is an active research topic in data management as we find many tables are missing some of this information. In this paper, we study the problem of annotating table columns (i.e., predicting column types and the relationships between columns) using only information from the table itself. We develop a multi-task learning framework (called Doduo) based on pre-trained language models, which takes the entire table as input and predicts column types/relations using a single model. Experimental results show that Doduo establishes new state-of-the-art performance on two benchmarks for the column type prediction and column relation prediction tasks with up to 4.0% and 11.9% improvements, respectively. We report that Doduo can already outperform the previous state-of-the-art performance with a minimal number of tokens, only 8 tokens per column. We release a toolbox (https://github.com/megagonlabs/doduo) and confirm the effectiveness of Doduo on a real-world data science problem through a case study."}}
{"id": "t8RwMlcNaZb", "cdate": 1609459200000, "mdate": 1623881879994, "content": {"title": "Annotating Columns with Pre-trained Language Models", "abstract": "Inferring meta information about tables, such as column headers or relationships between columns, is an active research topic in data management as we find many tables are missing some of this information. In this paper, we study the problem of annotating table columns (i.e., predicting column types and the relationships between columns) using only information from the table itself. We develop a multi-task learning framework (called Doduo) based on pre-trained language models, which takes the entire table as input and predicts column types/relations using a single model. Experimental results show that Doduo establishes new state-of-the-art performance on two benchmarks for the column type prediction and column relation prediction tasks with up to 4.0% and 11.9% improvements, respectively. We report that Doduo can already outperform the previous state-of-the-art performance with a minimal number of tokens, only 8 tokens per column. We release a toolbox (https://github.com/megagonlabs/doduo) and confirm the effectiveness of Doduo on a real-world data science problem through a case study."}}
{"id": "i91sP7JDSOu", "cdate": 1609459200000, "mdate": 1634239926773, "content": {"title": "Validating Gravity-Based Market Share Models Using Large-Scale Transactional Data", "abstract": "Customer patronage behavior has been widely studied in market share modeling contexts, which is an essential step toward estimating retail sales and finding new store locations in a competitive setting. Existing studies have conducted surveys to estimate merchants' market share and factors of attractiveness to use in various proposed mathematical models. Recent trends in Big Data analysis allow us to better understand human behavior and decision making, potentially leading to location models with more realistic assumptions. In this article, we propose a novel approach for validating the Huff gravity market share model, using a large-scale transactional dataset that describes customer patronage behavior at a regional level. Although the Huff model has been well studied and widely used in the context of sales estimation, competitive facility location, and demand allocation, this article is the first in validating the Huff model with a real dataset. Our approach helps to easily apply the model in different regions and with different merchant categories. Experimental results show that the Huff model fits well when modeling customer shopping behavior for a number of shopping categories, including grocery stores, clothing stores, gas stations, and restaurants. We also conduct regression analysis to show that certain features such as gender diversity and marital status diversity lead to stronger validation of the Huff model. We believe we provide strong evidence, with the help of real-world data, that gravity-based market share models are viable assumptions for retail sales estimation and competitive facility location models."}}
{"id": "fP3IDnLA3R", "cdate": 1609459200000, "mdate": 1634239926769, "content": {"title": "Constructing Explainable Opinion Graphs from Reviews", "abstract": "The Web is a major resource of both factual and subjective information. While there are significant efforts to organize factual information into knowledge bases, there is much less work on organizing opinions, which are abundant in subjective data, into a structured format. We present ExplainIt, a system that extracts and organizes opinions into an opinion graph, which are useful for downstream applications such as generating explainable review summaries and facilitating search over opinion phrases. In such graphs, a node represents a set of semantically similar opinions extracted from reviews and an edge between two nodes signifies that one node explains the other. ExplainIt mines explanations in a supervised method and groups similar opinions together in a weakly supervised way before combining the clusters of opinions together with their explanation relationships into an opinion graph. We experimentally demonstrate that the explanation relationships generated in the opinion graph are of good quality and our labeled datasets for explanation mining and grouping opinions are publicly available at https://github.com/megagonlabs/explainit."}}
{"id": "Y-CoHHMV_i", "cdate": 1609459200000, "mdate": 1681715161432, "content": {"title": "Convex Aggregation for Opinion Summarization", "abstract": ""}}
{"id": "PN5s1so2_ee", "cdate": 1609459200000, "mdate": 1634239926771, "content": {"title": "Convex Aggregation for Opinion Summarization", "abstract": "Recent advances in text autoencoders have significantly improved the quality of the latent space, which enables models to generate grammatical and consistent text from aggregated latent vectors. As a successful application of this property, unsupervised opinion summarization models generate a summary by decoding the aggregated latent vectors of inputs. More specifically, they perform the aggregation via simple average. However, little is known about how the vector aggregation step affects the generation quality. In this study, we revisit the commonly used simple average approach by examining the latent space and generated summaries. We found that text autoencoders tend to generate overly generic summaries from simply averaged latent vectors due to an unexpected $L_2$-norm shrinkage in the aggregated latent vectors, which we refer to as summary vector degeneration. To overcome this issue, we develop a framework Coop, which searches input combinations for the latent vector aggregation using input-output word overlap. Experimental results show that Coop successfully alleviates the summary vector degeneration issue and establishes new state-of-the-art performance on two opinion summarization benchmarks. Code is available at \\url{https://github.com/megagonlabs/coop}."}}
{"id": "NvhWxrGaMf", "cdate": 1609459200000, "mdate": 1634239926672, "content": {"title": "Deep Entity Matching: Challenges and Opportunities", "abstract": "Entity matching refers to the task of determining whether two different representations refer to the same real-world entity. It continues to be a prevalent problem for many organizations where data resides in different sources and duplicates the need to be identified and managed. The term \u201centity matching\u201d also loosely refers to the broader problem of determining whether two heterogeneous representations of different entities should be associated together. This problem has an even wider scope of applications, from determining the subsidiaries of companies to matching jobs to job seekers, which has impactful consequences. In this article, we first report our recent system DITTO, which is an example of a modern entity matching system based on pretrained language models. Then we summarize recent solutions in applying deep learning and pre-trained language models for solving the entity matching task. Finally, we discuss research directions beyond entity matching, including the promise of synergistically integrating blocking and entity matching steps together, the need to examine methods to alleviate steep training data requirements that are typical of deep learning or pre-trained language models, and the importance of generalizing entity matching solutions to handle the broader entity matching problem, which leads to an even more pressing need to explain matching outcomes."}}
{"id": "Da1i4OKuMZh", "cdate": 1609459200000, "mdate": 1631218398732, "content": {"title": "Extractive Opinion Summarization in Quantized Transformer Spaces", "abstract": "We present the Quantized Transformer (QT), an unsupervised system for extractive opinion summarization. QT is inspired by Vector-Quantized Variational Autoencoders, which we repurpose for popularity-driven summarization. It uses a clustering interpretation of the quantized space and a novel extraction algorithm to discover popular opinions among hundreds of reviews, a significant step towards opinion summarization of practical scope. In addition, QT enables controllable summarization without further training, by utilizing properties of the quantized space to extract aspect-specific summaries. We also make publicly available SPACE, a large-scale evaluation benchmark for opinion summarizers, comprising general and aspect-specific summaries for 50 hotels. Experiments demonstrate the promise of our approach, which is validated by human studies where judges showed clear preference for our method over competitive baselines."}}
