{"id": "I29Kt0RwChs", "cdate": 1663850503018, "mdate": null, "content": {"title": "Robust Algorithms on Adaptive Inputs from Bounded Adversaries", "abstract": "We study dynamic algorithms robust to adaptive input generated from sources with bounded capabilities, such as sparsity or limited interaction. For example, we consider robust linear algebraic algorithms when the updates to the input are sparse but given by an adversary with access to a query oracle. We also study robust algorithms in the standard centralized setting, where an adversary queries an algorithm in an adaptive manner, but the number of interactions between the adversary and the algorithm is bounded. We first recall a unified framework of (Hassidim et al., 2020; Beimel et al., 2022; Attias et al., 2023) for answering $Q$ adaptive queries that incurs $\\widetilde{\\mathcal{O}}(\\sqrt{Q})$ overhead in space, which is roughly a quadratic improvement over the na\\\"{i}ve implementation, and only incurs a logarithmic overhead in query time. Although the general framework has diverse applications in machine learning and data science, such as adaptive distance estimation, kernel density estimation, linear regression, range queries, point queries,  and serves as a preliminary benchmark, we demonstrate even better algorithmic improvements for (1) reducing the pre-processing time for adaptive distance estimation and (2) permitting an unlimited number of adaptive queries for kernel density estimation. Finally, we complement our theoretical results with additional empirical evaluations. "}}
{"id": "M8rwWdaGa6x", "cdate": 1663850348206, "mdate": null, "content": {"title": "Optimal Scalarizations for Provable Multiobjective Optimization", "abstract": "Linear scalarization is a simple and widely-used technique that can be deployed in any multiobjective setting to combine diverse objectives into one reward function, but such heuristics are not theoretically understood. To that end, we perform a case study of the multiobjective stochastic linear bandits framework with $k$ objectives and our goal is to provably scalarize and explore a diverse set of optimal actions on the Pareto frontier, as measured by the dominated hypervolume. Even in this elementary convex setting, the choice of scalarizations and weight distribution surprisingly affects performance, and the natural use of linear scalarization with uniform weights is suboptimal due to a non-uniform Pareto curvature. Instead, we suggest the usage of the theoretically-inspired hypervolume scalarizations with non-adaptive uniform weights, showing that it comes with novel hypervolume regret bounds of  $\\tilde{O}( d T^{-1/2} + T^{-1/k})$, with optimal matching lower bounds of $\\Omega(T^{-1/k})$. We support our theory with strong empirical performance of the hypervolume scalarization that consistently outperforms both the linear and Chebyshev scalarizations in high dimensions."}}
{"id": "1wz-ksUupt2", "cdate": 1652737705135, "mdate": null, "content": {"title": "Optimal Query Complexities for Dynamic Trace Estimation", "abstract": "We consider the problem of minimizing the number of matrix-vector queries needed for accurate trace estimation in the dynamic setting where our underlying matrix is changing slowly, such as during an optimization process. Specifically, for any $m$ matrices $\\mathbf{A}_1,...,\\mathbf{A}_m$ with consecutive differences bounded in Schatten-$1$ norm by $\\alpha$, we provide a novel binary tree summation procedure that simultaneously estimates all $m$ traces up to $\\epsilon$ error with $\\delta$ failure probability with an optimal query complexity of $\\widetilde{O}(m \\alpha\\sqrt{\\log(1/\\delta)}/\\epsilon + m\\log(1/\\delta))$, improving the dependence on both $\\alpha$ and $\\delta$ from Dharangutte and Musco (NeurIPS, 2021). Our procedure works without additional norm bounds on $\\mathbf{A}_i$ and can be generalized to a bound for the $p$-th Schatten norm for $p \\in [1,2]$, giving a complexity of $\\widetilde{O}(m \\alpha(\\sqrt{\\log(1/\\delta)}/\\epsilon)^p +m \\log(1/\\delta))$. By using novel reductions to communication complexity and information-theoretic analyses of Gaussian matrices, we provide matching lower bounds for static and dynamic trace estimation in all relevant parameters, including the failure probability. Our lower bounds (1) give the first tight bounds for Hutchinson's estimator in the matrix-vector product model with Frobenius norm error {\\it even in the static setting}, and (2) are the first unconditional lower bounds for dynamic trace estimation, resolving open questions of prior work."}}
{"id": "r-6Z1SJbCpv", "cdate": 1652737437348, "mdate": null, "content": {"title": "Towards Learning Universal Hyperparameter Optimizers with Transformers", "abstract": "Meta-learning hyperparameter optimization (HPO) algorithms from prior experiments is a promising approach to improve optimization efficiency over objective functions from a similar distribution. However, existing methods are restricted to learning from experiments sharing the same set of hyperparameters. In this paper, we introduce the OptFormer, the first text-based Transformer HPO framework that provides a universal end-to-end interface for jointly learning policy and function prediction when trained on vast tuning data from the wild, such as Google\u2019s Vizier database, one of the world\u2019s largest HPO datasets. Our extensive experiments demonstrate that the OptFormer can simultaneously imitate at least 7 different HPO algorithms, which can be further improved via its function uncertainty estimates. Compared to a Gaussian Process, the OptFormer also learns a robust prior distribution for hyperparameter response functions, and can thereby provide more accurate and better calibrated predictions. This work paves the path to future extensions for training a Transformer-based model as a general HPO optimizer."}}
{"id": "rxud5HYKX55", "cdate": 1621630061540, "mdate": null, "content": {"title": "Optimal Sketching for Trace Estimation", "abstract": "Matrix trace estimation is ubiquitous in machine learning applications and has traditionally relied on Hutchinson's method, which requires $O(\\log(1/\\delta)/\\epsilon^2)$ matrix-vector product queries to achieve a $(1 \\pm \\epsilon)$-multiplicative approximation to $\\text{trace}(A)$ with failure probability $\\delta$ on positive-semidefinite input matrices $A$. Recently, the Hutch++ algorithm was proposed, which reduces the number of matrix-vector queries from $O(1/\\epsilon^2)$ to the optimal $O(1/\\epsilon)$, and the algorithm succeeds with constant probability. However, in the high probability setting, the non-adaptive Hutch++ algorithm suffers an extra $O(\\sqrt{\\log(1/\\delta)})$ multiplicative factor in its query complexity. Non-adaptive methods are important, as they correspond to sketching algorithms, which are mergeable, highly parallelizable, and provide low-memory streaming algorithms as well as low-communication distributed protocols. In this work, we close the gap between non-adaptive and adaptive algorithms, showing that even non-adaptive algorithms can achieve $O(\\sqrt{\\log(1/\\delta)}/\\epsilon + \\log(1/\\delta))$ matrix-vector products. In addition, we prove matching lower bounds demonstrating that, up to a $\\log \\log(1/\\delta)$ factor, no further improvement in the dependence on $\\delta$ or $\\epsilon$ is possible by any non-adaptive algorithm. Finally, our experiments demonstrate the superior performance of our sketch over the adaptive Hutch++ algorithm, which is less parallelizable, as well as over the non-adaptive Hutchinson's method."}}
{"id": "Fa3a14yX8zA", "cdate": 1601308257906, "mdate": null, "content": {"title": "Joint Descent: Training and Tuning Simultaneously", "abstract": "Typically in machine learning, training and tuning are done in an alternating manner: for a fixed set of hyperparameters $y$, we apply gradient descent to our objective $f(x, y)$ over trainable variables $x$ until convergence; then, we apply a tuning step over $y$ to find another promising setting of hyperparameters. Because the full training cycle is completed before a tuning step is applied, the optimization procedure greatly emphasizes the gradient step, which seems justified as first-order methods provides a faster convergence rate. In this paper, we argue that an equal emphasis on training and tuning lead to faster convergence both theoretically and empirically. We present Joint Descent (JD) and a novel theoretical analysis of acceleration via an unbiased gradient estimate to give an optimal iteration complexity of $O(\\sqrt{\\kappa}n_y\\log(n/\\epsilon))$, where $\\kappa$ is the condition number and $n_y$ is the dimension of $y$. This provably improves upon the naive classical bound and implies that we essentially train for free if we apply equal emphasis on training and tuning steps. Empirically, we observe that an unbiased gradient estimate achieves the best convergence results, supporting our theory. "}}
{"id": "uz5uw6gM0m", "cdate": 1601308048675, "mdate": null, "content": {"title": "One Network Fits All? Modular versus Monolithic Task Formulations in Neural Networks", "abstract": "Can deep learning solve multiple, very different tasks simultaneously? We investigate how the representations of the underlying tasks affect the ability of a single neural network to learn them jointly. We present theoretical and empirical findings that a single neural network is capable of simultaneously learning multiple tasks from a combined data set, for a variety of methods for representing tasks---for example, when the distinct tasks are encoded by well-separated clusters or decision trees over some task-code attributes. Indeed, more strongly, we present a novel analysis that shows that families of simple programming-like constructs for the codes encoding the tasks are learnable by two-layer neural networks with standard training. We study more generally how the complexity of learning such combined tasks grows with the complexity of the task codes; we find that learning many tasks can be provably hard, even though the individual tasks are easy to learn. We provide empirical support for the usefulness of the learning bounds by training networks on clusters, decision trees, and SQL-style aggregation."}}
{"id": "WovWS4NBqke", "cdate": 1577836800000, "mdate": null, "content": {"title": "Random Hypervolume Scalarizations for Provable Multi-Objective Black Box Optimization", "abstract": "Single-objective black box optimization (also known as zeroth-order optimization) is the process of minimizing a scalar objective $f(x)$, given evaluations at adaptively chosen inputs $x$. In this paper, we consider multi-objective optimization, where $f(x)$ outputs a vector of possibly competing objectives and the goal is to converge to the Pareto frontier. Quantitatively, we wish to maximize the standard hypervolume indicator metric, which measures the dominated hypervolume of the entire set of chosen inputs. In this paper, we introduce a novel scalarization function, which we term the hypervolume scalarization, and show that drawing random scalarizations from an appropriately chosen distribution can be used to efficiently approximate the hypervolume indicator metric. We utilize this connection to show that Bayesian optimization with our scalarization via common acquisition functions, such as Thompson Sampling or Upper Confidence Bound, provably converges to the whole Pareto frontier by deriving tight hypervolume regret bounds on the order of $\\widetilde{O}(\\sqrt{T})$. Furthermore, we highlight the general utility of our scalarization framework by showing that any provably convergent single-objective optimization process can be effortlessly converted to a multi-objective optimization process with provable convergence guarantees."}}
{"id": "Nf-01nZ7a0v", "cdate": 1577836800000, "mdate": null, "content": {"title": "Learning the gravitational force law and other analytic functions", "abstract": "Large neural network models have been successful in learning functions of importance in many branches of science, including physics, chemistry and biology. Recent theoretical work has shown explicit learning bounds for wide networks and kernel methods on some simple classes of functions, but not on more complex functions which arise in practice. We extend these techniques to provide learning bounds for analytic functions on the sphere for any kernel method or equivalent infinitely-wide network with the corresponding activation function trained with SGD. We show that a wide, one-hidden layer ReLU network can learn analytic functions with a number of samples proportional to the derivative of a related function. Many functions important in the sciences are therefore efficiently learnable. As an example, we prove explicit bounds on learning the many-body gravitational force function given by Newton's law of gravitation. Our theoretical bounds suggest that very wide ReLU networks (and the corresponding NTK kernel) are better at learning analytic functions as compared to kernel learning with Gaussian kernels. We present experimental evidence that the many-body gravitational force function is easier to learn with ReLU networks as compared to networks with exponential activations."}}
{"id": "B1guLAVFDB", "cdate": 1569439312453, "mdate": null, "content": {"title": "Span Recovery for Deep Neural Networks with Applications to Input Obfuscation", "abstract": "The tremendous success of deep neural networks has motivated the need to better understand the fundamental properties of these networks, but many of the theoretical results proposed have only been for shallow networks. In this paper, we study an important primitive for understanding the meaningful input space of a deep network: span recovery. For $k<n$, let $\\mathbf{A} \\in \\mathbb{R}^{k \\times n}$ be the innermost weight matrix of an arbitrary feed forward neural network $M: \\mathbb{R}^n \\to  \\mathbb{R}$, so $M(x)$ can be written as $M(x) = \\sigma(\\mathbf{A} x)$, for some network $\\sigma: \\mathbb{R}^k \\to  \\mathbb{R}$. The goal is then to recover the row span of $\\mathbf{A}$ given only oracle access to the value of $M(x)$. We show that if $M$ is a multi-layered network with ReLU activation functions, then partial recovery is possible: namely, we can provably recover $k/2$ linearly independent vectors in the row span of $\\mathbf{A}$ using poly$(n)$ non-adaptive queries to $M(x)$.  Furthermore, if $M$ has differentiable activation functions, we demonstrate that \\textit{full} span recovery is possible even when the output is first passed through a sign or $0/1$ thresholding function; in this case our algorithm is adaptive. Empirically, we confirm that full span recovery is not always possible, but only for unrealistically thin layers. For reasonably wide networks, we obtain full span recovery on both random networks and networks trained on MNIST data. Furthermore, we demonstrate the utility of span recovery as an attack by inducing neural networks to misclassify data obfuscated by controlled random noise as sensical inputs. \n"}}
