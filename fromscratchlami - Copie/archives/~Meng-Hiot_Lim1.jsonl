{"id": "Ueurb5KTo9C", "cdate": 1672531200000, "mdate": 1684292411508, "content": {"title": "Membrane Potential Distribution Adjustment and Parametric Surrogate Gradient in Spiking Neural Networks", "abstract": "As an emerging network model, spiking neural networks (SNNs) have aroused significant research attentions in recent years. However, the energy-efficient binary spikes do not augur well with gradient descent-based training approaches. Surrogate gradient (SG) strategy is investigated and applied to circumvent this issue and train SNNs from scratch. Due to the lack of well-recognized SG selection rule, most SGs are chosen intuitively. We propose the parametric surrogate gradient (PSG) method to iteratively update SG and eventually determine an optimal surrogate gradient parameter, which calibrates the shape of candidate SGs. In SNNs, neural potential distribution tends to deviate unpredictably due to quantization error. We evaluate such potential shift and propose methodology for potential distribution adjustment (PDA) to minimize the loss of undesired pre-activations. Experimental results demonstrate that the proposed methods can be readily integrated with backpropagation through time (BPTT) algorithm and help modulated SNNs to achieve state-of-the-art performance on both static and dynamic dataset with fewer timesteps."}}
{"id": "BbaSRgUHW3", "cdate": 1652737502383, "mdate": null, "content": {"title": "LTMD: Learning Improvement of Spiking Neural Networks with Learnable Thresholding Neurons and Moderate Dropout", "abstract": "Spiking Neural Networks (SNNs) have shown substantial promise in processing spatio-temporal data, mimicking biological neuronal mechanisms, and saving computational power. However, most SNNs use fixed model regardless of their locations in the network. This limits SNNs\u2019 capability of transmitting precise information in the network, which becomes worse for deeper SNNs. Some researchers try to use specified parametric models in different network layers or regions, but most still use preset or suboptimal parameters. Inspired by the neuroscience observation that different neuronal mechanisms exist in disparate brain regions, we propose a new spiking neuronal mechanism, named learnable thresholding, to address this issue. Utilizing learnable threshold values, learnable thresholding enables flexible neuronal mechanisms across layers, proper information flow within the network, and fast network convergence. In addition, we propose a moderate dropout method to serve as an enhancement technique to minimize inconsistencies between independent dropout runs. Finally, we evaluate the robustness of the proposed learnable thresholding and moderate dropout for image classification with different initial thresholds for various types of datasets. Our proposed methods produce superior results compared to other approaches for almost all datasets with fewer timesteps. Our codes are available at https://github.com/sq117/LTMD.git."}}
{"id": "zgE35wLQi4W", "cdate": 1640995200000, "mdate": 1684137491347, "content": {"title": "LTMD: Learning Improvement of Spiking Neural Networks with Learnable Thresholding Neurons and Moderate Dropout", "abstract": "Spiking Neural Networks (SNNs) have shown substantial promise in processing spatio-temporal data, mimicking biological neuronal mechanisms, and saving computational power. However, most SNNs use fixed model regardless of their locations in the network. This limits SNNs\u2019 capability of transmitting precise information in the network, which becomes worse for deeper SNNs. Some researchers try to use specified parametric models in different network layers or regions, but most still use preset or suboptimal parameters. Inspired by the neuroscience observation that different neuronal mechanisms exist in disparate brain regions, we propose a new spiking neuronal mechanism, named learnable thresholding, to address this issue. Utilizing learnable threshold values, learnable thresholding enables flexible neuronal mechanisms across layers, proper information flow within the network, and fast network convergence. In addition, we propose a moderate dropout method to serve as an enhancement technique to minimize inconsistencies between independent dropout runs. Finally, we evaluate the robustness of the proposed learnable thresholding and moderate dropout for image classification with different initial thresholds for various types of datasets. Our proposed methods produce superior results compared to other approaches for almost all datasets with fewer timesteps. Our codes are available at https://github.com/sq117/LTMD.git."}}
{"id": "Rh6a4bEhDfH", "cdate": 1640995200000, "mdate": 1684137491346, "content": {"title": "A hierarchical taxonomic survey of spiking neural networks", "abstract": "Artificial Neural Network (ANN) has served as an important pillar of machine learning which played a crucial role in fueling the robust artificial intelligence (AI) revival experienced in the last few years. Inspired by the biological brain architecture of living things, ANN has shown widespread success in pattern recognition, data analysis and classification tasks. Among the many models of neural networks conceptualized and developed over the years, the Spiking Neural Network (SNN) which was initiated in 1996 has shown great promise in the current push towards compact embedded AI. By combining both spatial and temporal information as features in the training and testing process, many inherent shortcomings of traditional ANNs can be overcome. With temporal features and event-driven updating of the network, SNNs hold the potential of improving computational and energy efficiency. In SNN, the most basic signal carrier element is the spike, bringing about a revolution in neural network weights updating compared to traditional methods that are widely applied in ANNs. In literature, there have been numerous SNN weights updating algorithms developed in recent years. With the active and dynamic research work on SNN, a consolidation of the state-of-the-art SNN research is beneficial. This paper is aimed at reviewing and surveying the current status of research pertaining to SNN, in particular highlighting the various novel SNN training techniques coupled with an objective comparison of the techniques. SNN applications and associated neuromorphic hardware systems are also covered in this survey, with some thoughts on the challenges in developing new SNN training algorithms and discussion on potential future research trends are presented in this survey."}}
{"id": "Uu9L3TR2kCP", "cdate": 1577836800000, "mdate": 1684293170481, "content": {"title": "Editorial", "abstract": ""}}
{"id": "pyPpZbOoaKw", "cdate": 1546300800000, "mdate": 1684293170514, "content": {"title": "Editorial", "abstract": ""}}
{"id": "kCLkYYBYs4", "cdate": 1546300800000, "mdate": 1684293170556, "content": {"title": "Domination landscape in evolutionary algorithms and its applications", "abstract": "Evolutionary algorithms (EAs) are usually required to solve problems based on domination relationship among solutions. Often, the domination relationship is almost the sole source of knowledge that EAs can utilize, especially when the problem solving engine concerned is taken as a black box. In this paper, the domination landscape (DL), onto which an optimization problem (OP) can be mapped, is introduced. A DL may correspond to a cluster of OPs, implying that a class of OPs may have the same DL. To illustrate DL, we consider its representation as a directed graph, with its corresponding matrix and function. Of the various properties of DL, the domination-preserving property is used for the analysis of DL-equivalent OPs, and for the basis for classification of OPs. Taking DL as a tool for theoretical analysis, parameters determination for fitness scaling, the convergence property of EAs and the analysis of robustness in light of fitness noise are presented. The study of DL in this paper establishes the necessary theoretical foundation for future applications of DL equality and similarity based optimization."}}
{"id": "g6qlZoNcJXl", "cdate": 1546300800000, "mdate": 1684293170547, "content": {"title": "Heterogeneous Multi-robot Mission Planning for Coordinated Tasks Execution", "abstract": "The use of robotics and autonomous systems to perform various missions has become increasingly popular and widely accepted. The scope of missions that can be performed by such systems includes complex tasks that require coordination and cooperation between multiple robots, not just simple repetitive tasks. Mission planner plays a vital role in making sure that the tasks performed by the robots are conducted in an efficient manner and meet all the mission requirements. In designing a mission planner, it is crucial to consider not only the functional aspect of the system but also its modularity, scalability, and interoperability. In this paper, we proposed an architecture of a heterogeneous multi-robot mission planner system that is based on robotic operating system (ROS). The system is designed to support heterogeneous multi-robot, where there are several types of robots having unique sets of capabilities and properties, which contributes greatly to the complexity of the mission planner."}}
{"id": "axB1oXZZJY", "cdate": 1546300800000, "mdate": 1684293170521, "content": {"title": "Editorial", "abstract": ""}}
{"id": "NnJuj2vpsML", "cdate": 1546300800000, "mdate": 1684293170518, "content": {"title": "Editorial", "abstract": ""}}
