{"id": "9t6OZi-PrR", "cdate": 1622132518036, "mdate": null, "content": {"title": "Fair Hierarchical Clustering", "abstract": "As machine learning has become more prevalent, researchers have begun to recog-nize the necessity of ensuring machine learning systems are fair. Recently, there hasbeen an interest in defining a notion of fairness that mitigates over-representationin traditional clustering.\n\nIn this paper we extend this notion to hierarchical clustering, where the goal is torecursively partition the data to optimize a specific objective. For various naturalobjectives, we obtain simple, efficient algorithms to find a provably good fairhierarchical clustering. Empirically, we show that our algorithms can find a fairhierarchical clustering, with only a negligible loss in the objective."}}
{"id": "TNy6GJ2q8V4", "cdate": 1577836800000, "mdate": null, "content": {"title": "Optimal Approximation - Smoothness Tradeoffs for Soft-Max Functions", "abstract": "A soft-max function has two main efficiency measures: (1) approximation - which corresponds to how well it approximates the maximum function, (2) smoothness - which shows how sensitive it is to changes of its input. Our goal is to identify the optimal approximation-smoothness tradeoffs for different measures of approximation and smoothness. This leads to novel soft-max functions, each of which is optimal for a different application. The most commonly used soft-max function, called exponential mechanism, has optimal tradeoff between approximation measured in terms of expected additive approximation and smoothness measured with respect to R\\'enyi Divergence. We introduce a soft-max function, called \"piecewise linear soft-max\", with optimal tradeoff between approximation, measured in terms of worst-case additive approximation and smoothness, measured with respect to $\\ell_q$-norm. The worst-case approximation guarantee of the piecewise linear mechanism enforces sparsity in the output of our soft-max function, a property that is known to be important in Machine Learning applications [Martins et al. '16, Laha et al. '18] and is not satisfied by the exponential mechanism. Moreover, the $\\ell_q$-smoothness is suitable for applications in Mechanism Design and Game Theory where the piecewise linear mechanism outperforms the exponential mechanism. Finally, we investigate another soft-max function, called power mechanism, with optimal tradeoff between expected \\textit{multiplicative} approximation and smoothness with respect to the R\\'enyi Divergence, which provides improved theoretical and practical results in differentially private submodular optimization."}}
{"id": "LSBMprFaTuI", "cdate": 1577836800000, "mdate": null, "content": {"title": "Smoothly Bounding User Contributions in Differential Privacy", "abstract": "A differentially private algorithm guarantees that the input of a single user won\u2019t significantly change the output distribution of the algorithm. When a user contributes more data points, more information can be collected to improve the algorithm\u2019s performance. But at the same time, more noise might need to be added to the algorithm in order to keep the algorithm differentially private and this might hurt the algorithm\u2019s performance. Amin et al. (2019) initiates the study on bounding user contributions and proposes a very natural algorithm which limits the number of samples each user can contribute by a threshold. For a better trade-off between utility and privacy guarantee, we propose a method which smoothly bounds user contributions by setting appropriate weights on data points and apply it to estimating the mean/quantiles, linear regression, and empirical risk minimization. We show that our algorithm provably outperforms the sample limiting algorithm. We conclude with experimental evaluations which validate our theoretical results."}}
{"id": "nHkcttFZu1Z", "cdate": 1546300800000, "mdate": null, "content": {"title": "Clustering without Over-Representation", "abstract": "In this paper we consider clustering problems in which each point is endowed with a color. The goal is to cluster the points to minimize the classical clustering cost but with the additional constraint that no color is over-represented in any cluster. This problem is motivated by practical clustering settings, e.g., in clustering news articles where the color of an article is its source, it is preferable that no single news source dominates any cluster.   For the most general version of this problem, we obtain an algorithm that has provable guarantees of performance; our algorithm is based on finding a fractional solution using a linear program and rounding the solution subsequently. For the special case of the problem where no color has an absolute majority in any cluster, we obtain a simpler combinatorial algorithm also with provable guarantees. Experiments on real-world data shows that our algorithms are effective in finding good clustering without over-representation."}}
{"id": "BJWmTZWOZS", "cdate": 1514764800000, "mdate": null, "content": {"title": "Incentive-Aware Learning for Large Markets", "abstract": "In a typical learning problem, one key step is to use training data to pick one model from a collection of models that optimizes an objective function. In many multi-agent settings, the training data is generated through the actions of the agents, and the model is used to make a decision (e.g., how to sell an item) that affects the agents. An illustrative example of this is the problem of learning the reserve price in an auction. In such cases, the agents have an incentive to influence the training data (e.g., by manipulating their bids in the case of an auction) to game the system and achieve a more favorable outcome. In this paper, we study such incentive-aware learning problem in a general setting and show that it is possible to approximately optimize the objective function under two assumptions: (i) each individual agent is a \"small\" (part of the market); and (ii) there is a cost associated with manipulation. For our illustrative application, this nicely translates to a mechanism for setting approximately optimal reserve prices in auctions where no individual agent has significant market share. For this application, we also show that the second assumption (that manipulations are costly) is not necessary since we can \"perturb\" any auction to make it costly for the agents to manipulate."}}
{"id": "rJbc4z-u-B", "cdate": 1483228800000, "mdate": null, "content": {"title": "Budget Management Strategies in Repeated Auctions", "abstract": "In online advertising, advertisers purchase ad placements by participating in a long sequence of repeated auctions. One of the most important features advertising platforms often provide, and advertisers often use, is budget management, which allows advertisers to control their cumulative expenditures. Advertisers typically declare the maximum daily amount they are willing to pay, and the platform adjusts allocations and payments to guarantee that cumulative expenditures do not exceed budgets. There are multiple ways to achieve this goal, and each one, when applied to all budget-constrained advertisers simultaneously, steers the system toward a different equilibrium. While previous research focused on online stochastic optimization techniques or game-theoretic equilibria of such settings, our goal in this paper is to compare the ``system equilibria'' of a range of budget management strategies in terms of the seller's profit and buyers' utility. In particular, we consider six different budget management strategies including probabilistic throttling, thresholding, bid shading, reserve pricing, and multiplicative boosting. We show these methods admit a system equilibrium in a rather general setting, and prove dominance relations between them in a simplified setting. Our study sheds light on the impact of budget management strategies on the tradeoff between the seller's profit and buyers' utility. Finally, we also empirically compare the system equilibria of these strategies using real ad auction data in sponsored search and randomly generated bids. The empirical study confirms our theoretical findings about the relative performances of budget management strategies."}}
{"id": "ryQIPPZ_ZH", "cdate": 1451606400000, "mdate": null, "content": {"title": "Community Detection on Evolving Graphs", "abstract": "Clustering is a fundamental step in many information-retrieval and data-mining applications. Detecting clusters in graphs is also a key tool for finding the community structure in social and behavioral networks. In many of these applications, the input graph evolves over time in a continual and decentralized manner, and, to maintain a good clustering, the clustering algorithm needs to repeatedly probe the graph. Furthermore, there are often limitations on the frequency of such probes, either imposed explicitly by the online platform (e.g., in the case of crawling proprietary social networks like twitter) or implicitly because of resource limitations (e.g., in the case of crawling the web). In this paper, we study a model of clustering on evolving graphs that captures this aspect of the problem. Our model is based on the classical stochastic block model, which has been used to assess rigorously the quality of various static clustering methods. In our model, the algorithm is supposed to reconstruct the planted clustering, given the ability to query for small pieces of local information about the graph, at a limited rate. We design and analyze clustering algorithms that work in this model, and show asymptotically tight upper and lower bounds on their accuracy. Finally, we perform simulations, which demonstrate that our main asymptotic results hold true also in practice."}}
{"id": "H1bdxjbuWS", "cdate": 1451606400000, "mdate": null, "content": {"title": "Pricing a Low-regret Seller", "abstract": "As the number of ad exchanges has grown, publishers have turned to low regret learning algorithms to decide which exchange offers the best price for their inventory. This in turn opens the followin..."}}
{"id": "nN3L21hJ1IJ", "cdate": 1420070400000, "mdate": null, "content": {"title": "Incentives in Large Random Two-Sided Markets", "abstract": "Many centralized two-sided markets form a matching between participants by running a stable matching algorithm. It is a well-known fact that no matching mechanism based on a stable matching algorithm can guarantee truthfulness as a dominant strategy for participants. However, we show that in a probabilistic setting where the preference lists on one side of the market are composed of only a constant (independent of the size of the market) number of entries, each drawn from an arbitrary distribution, the number of participants that have more than one stable partner is vanishingly small. This proves (and generalizes) a conjecture of Roth and Peranson [1999]. As a corollary of this result, we show that, with high probability, the truthful strategy is the best response for a random player when the other players are truthful. We also analyze equilibria of the deferred acceptance stable matching game. We show that the game with complete information has an equilibrium in which, in expectation, a (1\u2212o(1)) fraction of the strategies are truthful. In the more realistic setting of a game of incomplete information, we will show that the set of truthful stratiegs form a (1+o(1))-approximate Bayesian-Nash equilibrium for uniformly random preferences. Our results have implications in many practical settings and are inspired by the work of Roth and Peranson [1999] on the National Residency Matching Program."}}
{"id": "VTMUKEqeJ8a", "cdate": 1420070400000, "mdate": null, "content": {"title": "Sudoku Rectangle Completion (Extended Abstract)", "abstract": "Over the last decade, Sudoku, a combinatorial number-placement puzzle, has become a favorite pastimes of many all around the world. In this puzzle, the task is to complete a partially filled 9 \u00d7 9 square with numbers 1 through 9, subject to the constraint that each number must appear once in each row, each column, and each of the nine 3 \u00d7 3 blocks. Sudoku squares can be considered a subclass of the well-studied class of Latin squares. In this paper, we study natural extensions of a classical result on Latin square completion to Sudoku squares. Furthermore, we use the procedure developed in the proof to obtain asymptotic bounds on the number of Sudoku squares of order n."}}
