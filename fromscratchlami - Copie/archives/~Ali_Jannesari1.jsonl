{"id": "H9BGkFz-Sm", "cdate": 1677713814189, "mdate": null, "content": {"title": "Discerning  Self-Supervised Learning and Weakly Supervised Learning", "abstract": "The AI community has been a very rapidly growing community producing a vast amount of research in a very short span of time. These researches generate a lot of new methods and terminologies. With this scale of developments, it is very difficult to keep a track of terminologies, and under such conditions even more difficult to standardize the definitions. In the wake of such scenarios, we try to perform a detailed study of some terminologies in representation learning and form standard definitions of them. With this work, we establish a clear distinction between the concepts of Self-supervised learning and Weakly supervised learning."}}
{"id": "1WEPXTIjAd", "cdate": 1677713802684, "mdate": null, "content": {"title": "INTEGRATING INFORMATION FROM NATURAL LANGUAGE PARSE TREE TO CODE GENERATION", "abstract": "While more and more research works have considered Natural Language artifacts as the inputs of software engineering research, such as code generation, information about their  graph/tree representations needs to be carefully considered. In this work, we propose an approach for integrating information on NLPT on multiple problems in SE tasks. The preliminary experiment shows that augmenting information of NLPT can improve the code generation from pseudocode. "}}
{"id": "vUUrRRSEauF", "cdate": 1640995200000, "mdate": 1668022036287, "content": {"title": "Heterogeneous Graph Neural Networks for Software Effort Estimation", "abstract": "Background. Software effort can be measured by story point [35]. Story point estimation is important in software projects\u2019 planning. Current approaches for automatically estimating story points focus on applying pre-trained embedding models and deep learning for text regression to solve this problem. These approaches require expensive embedding models and confront challenges that the sequence of text might not be an efficient representation for software issues which can be the combination of text and code. Aims. We propose HeteroSP, a tool for estimating story points from textual input of Agile software project issues. We select GPT2SP [12] and Deep-SE [8] as the baselines for comparison. Method. First, from the analysis of the story point dataset [8], we conclude that software issues are actually a mixture of natural language sentences with quoted code snippets and have problems related to large-size vocabulary. Second, we provide a module to normalize the input text including words and code tokens of the software issues. Third, we design an algorithm to convert an input software issue to a graph with different types of nodes and edges. Fourth, we construct a heterogeneous graph neural networks model with the support of fastText [6] for constructing initial node embedding to learn and predict the story points of new issues. Results. We did the comparison over three scenarios of estimation, including within project, cross-project within the repository, and cross-project cross repository with our baseline approaches. We achieve the average Mean Absolute Error (MAE) as 2.38, 2.61, and 2.63 for three scenarios. We outperform GPT2SP in 2/3 of the scenarios while outperforming Deep-SE in the most challenging scenario with significantly less amount of running time. We also compare our approaches with different homogeneous graph neural network models and the results show that the heterogeneous graph neural networks model outperforms the homogeneous models in story point estimation. For time performance, we achieve about 570 seconds as the time performance in both three processes: node embedding initialization, model construction, and story point estimation. HeterpSP\u2019s artifacts are available at [22]. Conclusion. HeteroSP, a heterogeneous graph neural networks model for story point estimation, achieved good accuracy and running time."}}
{"id": "mII_ncpxxV", "cdate": 1640995200000, "mdate": 1668022036215, "content": {"title": "Learning Intermediate Representations using Graph Neural Networks for NUMA and Prefetchers Optimization", "abstract": "There is a large space of NUMA and hardware prefetcher configurations that can significantly impact the performance of an application. Previous studies have demonstrated how a model can automatically select configurations based on the dynamic properties of the code to achieve speedups. This paper demonstrates how the static Intermediate Representation (IR) of the code can guide NUMA/prefetcher optimizations without the prohibitive cost of performance profiling. We propose a method to create a comprehensive dataset that includes a diverse set of intermediate representations along with optimum configurations. We then apply a graph neural network model in order to validate this dataset. We show that our static intermediate representation based model achieves 80% of the performance gains provided by expensive dynamic performance profiling based strategies. We further develop a hybrid model that uses both static and dynamic information. Our hybrid model achieves the same gains as the dynamic models but at a reduced cost by only profiling 30% of the programs."}}
{"id": "gUkxrBXbio1", "cdate": 1640995200000, "mdate": 1668022036236, "content": {"title": "Scalable and Extensible Robinson-Foulds for Comparative Phylogenetics", "abstract": "Robinson-Foulds(RF) is a widely used metric in various phylogenetic analyses including clustering and generating consensus or most-parsimonious trees. Current methods are limited by one or more of the following: 1 versus 1 computation, limited to the basic RF calculation, use one tree collection, are not scalable, and restrict taxa. This paper presents Bipartition Frequency Hash Robinson-Foulds (BFHRF), a scalable and exten-sible approach for computing the average RF between disparate binary evolutionary tree collections. The novelty of our approach is utilizing a bipartition frequency hash data structure to perform parallelized tree versus hash comparisons in substitution of all possible tree versus tree comparisons. The data structure and updated computation algorithm results in an order of magnitude reduction in both runtime and memory usage. It is 39x faster and 22x reduction in memory compared to HashRF, a fast current method. Additionally, the tree collection distribution can be modified for RF variants and variable taxa due to the lack of restrictions imposed by the hash and retention of all bipartitions. Lastly, BFHRF is implemented in a modular way and provides an easy to use installation and interface for calculating the average RF of query trees against a collection of reference trees. https://github.comlachonlbfhrf"}}
{"id": "aaAlGf4q2hX", "cdate": 1640995200000, "mdate": 1668022036254, "content": {"title": "Heterogeneous Graph Neural Networks for Software Effort Estimation", "abstract": "Software effort can be measured by story point [35]. Current approaches for automatically estimating story points focus on applying pre-trained embedding models and deep learning for text regression to solve this problem which required expensive embedding models. We propose HeteroSP, a tool for estimating story points from textual input of Agile software project issues. We select GPT2SP [12] and Deep-SE [8] as the baselines for comparison. First, from the analysis of the story point dataset [8], we conclude that software issues are actually a mixture of natural language sentences with quoted code snippets and have problems related to large-size vocabulary. Second, we provide a module to normalize the input text including words and code tokens of the software issues. Third, we design an algorithm to convert an input software issue to a graph with different types of nodes and edges. Fourth, we construct a heterogeneous graph neural networks model with the support of fastText [6] for constructing initial node embedding to learn and predict the story points of new issues. We did the comparison over three scenarios of estimation, including within project, cross-project within the repository, and cross-project cross repository with our baseline approaches. We achieve the average Mean Absolute Error (MAE) as 2.38, 2.61, and 2.63 for three scenarios. We outperform GPT2SP in 2/3 of the scenarios while outperforming Deep-SE in the most challenging scenario with significantly less amount of running time. We also compare our approaches with different homogeneous graph neural network models and the results show that the heterogeneous graph neural networks model outperforms the homogeneous models in story point estimation. For time performance, we achieve about 570 seconds as the time performance in both three processes: node embedding initialization, model construction, and story point estimation."}}
{"id": "aZwnY4UeLa", "cdate": 1640995200000, "mdate": 1668022036425, "content": {"title": "Efficient Volume Estimation for Dynamic Environments using Deep Learning on the Edge", "abstract": "The utility of edge devices has increased in volume estimation of uneven terrains. Existing techniques utilize several geo-tagged images of the landscape, captured in-flight by an edge device mounted over a UAV, to generate 3D models and perform volume estimation through manual boundary marking. These methods, although accurate, require significant time, human effort and are heavily dependent on GPS. We present an efficient deep learning framework that detects the object of interest and automatically determines the volume (independent of GPS) of the detected object on-the-fly. Our method employs a stereo camera for depth sensing of the object and overlays a unit mesh grid over the object's boundary to perform volume estimation. We explore the accuracy vs computational complexity trade-off on variations of our technique. Experiments indicate that our method reduces the time for volume estimation by several orders of magnitude in contrast to existing methods and is independent of GPS as well. Also, to the best of our knowledge, this is the first method that can perform volume analysis in a dynamic environment."}}
{"id": "YrGZiT84cGn", "cdate": 1640995200000, "mdate": 1668022036320, "content": {"title": "Multi-View Learning for Parallelism Discovery of Sequential Programs", "abstract": "Identifying suitable parallelizable regions in sequential programs is a crucial task for performance optimizations. Traditional methods like static and dynamic analysis have flaws like insufficient accuracy or high overhead runtime. Recent studies are more interested in applying machine learning techniques to this topic. The crux of parallelism discovery with machine learning is to generate meaningful code representations. One promising route is to exploit the dependence graph through Graph Neural Networks (GNNS). In this paper, a novel multi-view framework is proposed to automatically detect potential parallelism opportunities. Sequential programs are first repre-sented by program execution graphs encompassing both semantic and structural information. Then two independent views are defined: namely, a structural pattern view and a node feature view. In the structural view, local graph structural patterns are captured via random anonymous walks and then fed into a Graph Convolutional Network (GCN). The node features, both dynamic and static, are fed into another GCN in the node feature view. In addition, a multi-view model is designed to unify the node features and the structural features for parallelism detection. Our approach achieves comparable state-of-the-art performance on parallel region classification with an accuracy up to 92.6 % when evaluated with popular parallel eomputing benchmarks."}}
{"id": "V1UF9QHOPl", "cdate": 1640995200000, "mdate": 1668022036331, "content": {"title": "Learning Intermediate Representations using Graph Neural Networks for NUMA and Prefetchers Optimization", "abstract": "There is a large space of NUMA and hardware prefetcher configurations that can significantly impact the performance of an application. Previous studies have demonstrated how a model can automatically select configurations based on the dynamic properties of the code to achieve speedups. This paper demonstrates how the static Intermediate Representation (IR) of the code can guide NUMA/prefetcher optimizations without the prohibitive cost of performance profiling. We propose a method to create a comprehensive dataset that includes a diverse set of intermediate representations along with optimum configurations. We then apply a graph neural network model in order to validate this dataset. We show that our static intermediate representation based model achieves 80 % of the performance gains provided by expensive dynamic performance profiling based strategies. We further develop a hybrid model that uses both static and dynamic information. Our hybrid model achieves the same gains as the dynamic models but at a reduced cost by only profiling 30 % of the programs."}}
{"id": "Kq58lRi5AF", "cdate": 1640995200000, "mdate": 1668022036393, "content": {"title": "Temporal shift reinforcement learning", "abstract": "The function approximators employed by traditional image-based Deep Reinforcement Learning (DRL) algorithms usually lack a temporal learning component and instead focus on learning the spatial component. We propose a technique, Temporal Shift Reinforcement Learning (TSRL), wherein both temporal, as well as spatial components are jointly learned. Moreover, TSRL does not require additional parameters to perform temporal learning. We show that TSRL outperforms the commonly used frame stacking heuristic on all of the Atari environments we test on while beating the SOTA for all except one of them. This investigation has implications in the robotics as well as sequential decision-making domains. Our code is available at - https://github.com/Deepakgthomas/TSM_RL"}}
