{"id": "Hs2mVP9hs-i", "cdate": 1696177163160, "mdate": 1696177163160, "content": {"title": "Distributionally Robust Model-based Reinforcement Learning with Large State Spaces", "abstract": "Three major challenges in reinforcement learning are the complex dynamical systems with large state spaces, the costly data acquisition processes, and the deviation of real-world dynamics from the training environment deployment. To overcome these issues, we study distributionally robust Markov decision processes with continuous state spaces under the widely used Kullback-Leibler, chi-square, and total variation uncertainty sets. We propose a model-based approach that utilizes Gaussian Processes and the maximum variance reduction algorithm to efficiently learn multi-output nominal transition dynamics, leveraging access to a generative model (i.e., simulator). We further demonstrate the statistical sample complexity of the proposed method for different uncertainty sets. These complexity bounds are independent of the number of states and extend beyond linear dynamics, ensuring the effectiveness of our approach in identifying near-optimal distributionally-robust policies. The proposed method can be further combined with other model-free distributionally robust reinforcement learning methods to obtain a near-optimal robust policy. Experimental results demonstrate the robustness of our algorithm to distributional shifts and its superior performance in terms of the number of samples needed."}}
{"id": "zCibhMlAJq", "cdate": 1683882602354, "mdate": 1683882602354, "content": {"title": "Efficient Algorithms for Minimizing Compositions of Convex Functions and Random Functions and Its Applications in Network Revenue Management", "abstract": "In this paper, we study a class of nonconvex stochastic optimization in the form of $\\min_{x\\in\\mathcal{X}} F(x):=\\EE_\\xi [f(\\phi(x,\\xi))]$, where the objective function $F$ is a composition of a convex function $f$ and a random function $\\phi$. Leveraging an (implicit) convex reformulation via a variable transformation $u=\\EE[\\phi(x,\\xi)]$, we develop stochastic gradient-based algorithms and establish their sample and gradient complexities for achieving an $\\eps$-global optimal solution. Interestingly, our proposed Mirror Stochastic Gradient (MSG) method operates only in the original $x$-space using gradient estimators of the original nonconvex objective $F$ and achieves $\\tilde \\cO(\\eps^{-2})$ sample and gradient complexities, which matches the lower bounds for solving stochastic convex optimization problems. Under booking limits control, we formulate the air-cargo network revenue management (NRM) problem with random two-dimensional capacity, random consumption, and routing flexibility as a special case of the stochastic nonconvex optimization, where the random function $\\phi(x,\\xi)=x\\wedge\\xi$, i.e., the random demand $\\xi$ truncates the booking limit decision $x$. Extensive numerical experiments demonstrate the superior performance of our proposed MSG algorithm for booking limit control with higher revenue and lower computation cost than state-of-the-art bid-price-based control policies, especially when the variance of random capacity is large."}}
{"id": "DHrBzIknkP", "cdate": 1683882449296, "mdate": 1683882449296, "content": {"title": "Biased Stochastic First-Order Methods for Conditional Stochastic Optimization and Applications in Meta Learning", "abstract": "Conditional stochastic optimization covers a variety of applications ranging from invariant learning and causal inference to meta-learning. However, constructing unbiased gradient estimators for such problems is challenging due to the composition structure. As an alternative, we propose a biased stochastic gradient descent (BSGD) algorithm and study the bias-variance tradeoff under different structural assumptions. We establish the sample complexities of BSGD for strongly convex, convex, and weakly convex objectives under smooth and non-smooth conditions. Our lower bound analysis shows that the sample complexities of BSGD cannot be improved for general convex objectives and nonconvex objectives except for smooth nonconvex objectives with Lipschitz continuous gradient estimator. For this special setting, we propose an accelerated algorithm called biased SpiderBoost (BSpiderBoost) that matches the lower bound complexity. We further conduct numerical experiments on invariant logistic regression and model-agnostic meta-learning to illustrate the performance of BSGD and BSpiderBoost."}}
{"id": "KieAKgwZar", "cdate": 1683882384135, "mdate": 1683882384135, "content": {"title": "Sample Complexity of Sample Average Approximation for Conditional Stochastic Optimization", "abstract": "In this paper, we study a class of stochastic optimization problems, referred to as the conditional stochastic optimization (CSO), in the form of minx\u2208X E\u03bef\u03be(E\u03b7|\u03be[g\u03b7(x,\u03be)]), which finds a wide spectrum of applications including portfolio selection, reinforcement learning, robust learning, and causal inference. Assuming availability of samples from the distribution P(\u03be) and samples from the conditional distribution P(\u03b7|\u03be), we establish the sample complexity of the sample average approximation (SAA) for CSO, under a variety of structural assumptions, such as Lipschitz continuity, smoothness, and error bound conditions. We show that the total sample complexity improves from O(d/\u03f54) to O(d/\u03f53) when assuming smoothness of the outer function, and further to O(1/\u03f52) when the empirical function satisfies the quadratic growth condition. We also establish the sample complexity of a modified SAA when \u03be and \u03b7 are independent. Several numerical experiments further support our theoretical findings."}}
{"id": "_AHlSVY2ebg", "cdate": 1664731450295, "mdate": null, "content": {"title": "Uniform Convergence and Generalization for Nonconvex Stochastic Minimax Problems", "abstract": "This paper studies the uniform convergence and generalization bounds for nonconvex-(strongly)-concave (NC-SC/NC-C) stochastic minimax optimization. We first establish the uniform convergence between the empirical minimax problem and the population minimax problem and show the $\\tilde{\\mathcal{O}}(d\\kappa^2\\epsilon^{-2})$ and $\\tilde{\\mathcal{O}}(d\\epsilon^{-4})$ sample complexities respectively for the NC-SC and NC-C settings, where $d$ is the dimension number and $\\kappa$ is the condition number. To the best of our knowledge, this is the first uniform convergence result measured by the first-order stationarity in  stochastic minimax optimization literature."}}
{"id": "I5f4e3udn2", "cdate": 1621629898923, "mdate": null, "content": {"title": "On the Bias-Variance-Cost Tradeoff of Stochastic Optimization", "abstract": "We consider stochastic optimization when one only has access to biased stochastic oracles of the objective, and obtaining stochastic gradients with low biases comes at high costs. This setting captures a variety of optimization paradigms widely used in machine learning, such as conditional stochastic optimization, bilevel optimization, and distributionally robust optimization. We examine a family of multi-level Monte Carlo (MLMC) gradient methods that exploit a delicate trade-off among the bias, the variance, and the oracle cost. We provide a systematic study of their convergences and total computation complexities for strongly convex, convex, and nonconvex objectives, and demonstrate their superiority over the naive biased stochastic gradient method. Moreover, when applied to conditional stochastic optimization, the MLMC gradient methods significantly improve the best-known sample complexity in the literature. "}}
