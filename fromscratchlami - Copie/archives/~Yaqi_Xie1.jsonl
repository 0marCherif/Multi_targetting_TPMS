{"id": "WIjuP6PvrJ_", "cdate": 1672531200000, "mdate": 1680553334215, "content": {"title": "Translating Natural Language to Planning Goals with Large-Language Models", "abstract": ""}}
{"id": "oCx90Ezdox_", "cdate": 1663849994964, "mdate": null, "content": {"title": "Don't Throw Your Old Policies Away: Knowledge-based Policy Recycling Protects Against Adversarial Attacks", "abstract": "Recent work has shown that Deep Reinforcement Learning (DRL) is vulnerable to adversarial attacks, in which minor perturbations of input signals cause agents to behave inappropriately and unexpectedly. Humans, on the other hand, appear robust to these particular sorts of input variations. We posit that this part of robustness stems from accumulated knowledge about the world.\nIn this work, we propose to leverage prior knowledge to defend against adversarial attacks in RL settings using a framework we call Knowledge-based Policy Recycling (KPR). Different from previous defense methods such as adversarial training and robust learning, KPR incorporates domain knowledge over a set of auxiliary tasks policies and learns relations among them from interactions with the environment via a Graph Neural Network (GNN). KPR can use any relevant policy as an auxiliary policy and, importantly, does not assume access or information regarding the adversarial attack. Empirically, KPR results in policies that are more robust to various adversarial attacks in Atari games and a simulated Robot Foodcourt environment. "}}
{"id": "7eC5OXsaCru", "cdate": 1609459200000, "mdate": 1680553334199, "content": {"title": "Embedding Symbolic Temporal Knowledge into Deep Sequential Models", "abstract": ""}}
{"id": "5FNNvCplsyB", "cdate": 1609459200000, "mdate": null, "content": {"title": "Embedding Symbolic Temporal Knowledge into Deep Sequential Models", "abstract": "Sequences and time-series often arise in robot tasks, e.g., in activity recognition and imitation learning. In recent years, deep neural networks (DNNs) have emerged as an effective data-driven methodology for processing sequences given sufficient training data and compute resources. However, when data is limited, simpler models such as logic/rule-based methods work surprisingly well, especially when relevant prior knowledge is applied in their construction. However, unlike DNNs, these \"structured\" models can be difficult to extend, and do not work well with raw unstructured data. In this work, we seek to learn flexible DNNs, yet leverage prior temporal knowledge when available. Our approach is to embed symbolic knowledge expressed as linear temporal logic (LTL) and use these embeddings to guide the training of deep models. Specifically, we construct semantic-based embeddings of automata generated from LTL formula via a Graph Neural Network. Experiments show that these learnt embeddings can lead to improvements in downstream robot tasks such as sequential action recognition and imitation learning."}}
{"id": "phFWaAlCCDz", "cdate": 1577836800000, "mdate": null, "content": {"title": "Multi-task trust transfer for human-robot interaction", "abstract": "Trust is essential in shaping human interactions with one another and with robots. In this article we investigate how human trust in robot capabilities transfers across multiple tasks. We present a human-subject study of two distinct task domains: a Fetch robot performing household tasks and a virtual reality simulation of an autonomous vehicle performing driving and parking maneuvers. The findings expand our understanding of trust and provide new predictive models of trust evolution and transfer via latent task representations: a rational Bayes model, a data-driven neural network model, and a hybrid model that combines the two. Experiments show that the proposed models outperform prevailing models when predicting trust over unseen tasks and users. These results suggest that (i) task-dependent functional trust models capture human trust in robot capabilities more accurately and (ii) trust transfer across tasks can be inferred to a good degree. The latter enables trust-mediated robot decision-making for fluent human\u2013robot interaction in multi-task settings."}}
{"id": "kyDySeBy0X", "cdate": 1546300800000, "mdate": 1680553334222, "content": {"title": "Semantically-Regularized Logic Graph Embeddings", "abstract": ""}}
{"id": "cgO_fA1q1r", "cdate": 1546300800000, "mdate": 1680553334225, "content": {"title": "Embedding Symbolic Knowledge into Deep Networks", "abstract": ""}}
{"id": "YEncqfeVI2l", "cdate": 1546300800000, "mdate": 1680553334228, "content": {"title": "Robot Capability and Intention in Trust-based Decisions across Tasks", "abstract": ""}}
{"id": "9fI8w8dON7Z", "cdate": 1546300800000, "mdate": null, "content": {"title": "Robot Capability and Intention in Trust-Based Decisions Across Tasks", "abstract": "In this paper, we present results from a human-subject study designed to explore two facets of human mental models of robots - inferred capability and intention - and their relationship to overall trust and eventual decisions. In particular, we examine delegation situations characterized by uncertainty, and explore how inferred capability and intention are applied across different tasks. We develop an online survey where human participants decide whether to delegate control to a simulated UAV agent. Our study shows that human estimations of robot capability and intent correlate strongly with overall self-reported trust. However, overall trust is not independently sufficient to determine whether a human will decide to trust (delegate) a given task to a robot. Instead, our study reveals that estimations of robot intention, capability, and overall trust are integrated when deciding to delegate. From a broader perspective, these results suggest that calibrating overall trust alone is insufficient; to make correct decisions, humans need (and use) multi-faceted mental models when collaborating with robots across multiple contexts."}}
