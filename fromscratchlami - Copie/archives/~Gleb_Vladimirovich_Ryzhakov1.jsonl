{"id": "iOJyX-LQUG", "cdate": 1672531200000, "mdate": 1682349487486, "content": {"title": "PROTES: Probabilistic Optimization with Tensor Sampling", "abstract": "We developed a new method PROTES for black-box optimization, which is based on the probabilistic sampling from a probability density function given in the low-parametric tensor train format. We tested it on complex multidimensional arrays and discretized multivariable functions taken, among others, from real-world applications, including unconstrained binary optimization and optimal control problems, for which the possible number of elements is up to $2^{100}$. In numerical experiments, both on analytic model functions and on complex problems, PROTES outperforms existing popular discrete optimization methods (Particle Swarm Optimization, Covariance Matrix Adaptation, Differential Evolution, and others)."}}
{"id": "6PIrhAx1j4i", "cdate": 1663850342174, "mdate": null, "content": {"title": "Understanding DDPM Latent Codes Through Optimal Transport", "abstract": "Diffusion models have recently outperformed alternative approaches to model the distribution of natural images. Such diffusion models allow for deterministic sampling via the probability flow ODE, giving rise to a latent space and an encoder map. While having important practical applications, such as the estimation of the likelihood, the theoretical properties of this map are not yet fully understood. In the present work, we partially address this question for the popular case of the VP-SDE (DDPM) approach. We show that, perhaps surprisingly, the DDPM encoder map coincides with the optimal transport map for common distributions; we support this claim by extensive numerical experiments using advanced tensor train solver for multidimensional Fokker-Planck equation. We provide additional theoretical evidence for the case of multivariate normal distributions."}}
{"id": "yLzLfM-Esnu", "cdate": 1663850037330, "mdate": null, "content": {"title": "Constructive TT-representation of the tensors given as index interaction functions with applications", "abstract": "This paper presents a method to build explicit tensor-train (TT) representations. We show that a wide class of tensors can be explicitly represented with sparse TT-cores, obtaining, in many cases, optimal TT-ranks. Numerical experiments show that our method outperforms the existing ones in several practical applications, including game theory problems. Theoretical estimations of the number of operations show that in some problems, such as permanent calculation, our methods are close to the known optimal asymptotics, which are obtained by a completely different type of methods."}}
{"id": "Y_dGWtAr8v", "cdate": 1640995200000, "mdate": 1682349487498, "content": {"title": "Black box approximation in the tensor train format initialized by ANOVA decomposition", "abstract": "Surrogate models can reduce computational costs for multivariable functions with an unknown internal structure (black boxes). In a discrete formulation, surrogate modeling is equivalent to restoring a multidimensional array (tensor) from a small part of its elements. The alternating least squares (ALS) algorithm in the tensor train (TT) format is a widely used approach to effectively solve this problem in the case of non-adaptive tensor recovery from a given training set (i.e., tensor completion problem). TT-ALS allows obtaining a low-parametric representation of the tensor, which is free from the curse of dimensionality and can be used for fast computation of the values at arbitrary tensor indices or efficient implementation of algebra operations with the black box (integration, etc.). However, to obtain high accuracy in the presence of restrictions on the size of the train data, a good choice of initial approximation is essential. In this work, we construct the ANOVA representation in the TT-format and use it as an initial approximation for the TT-ALS algorithm. The performed numerical computations for a number of multidimensional model problems, including the parametric partial differential equation, demonstrate a significant advantage of our approach for the commonly used random initial approximation. For all considered model problems we obtained an increase in accuracy by at least an order of magnitude with the same number of requests to the black box. The proposed approach is very general and can be applied in a wide class of real-world surrogate modeling and machine learning problems."}}
{"id": "WLx6BVk4OpZ", "cdate": 1640995200000, "mdate": 1682349487492, "content": {"title": "Constructive TT-representation of the tensors given as index interaction functions with applications", "abstract": "This paper presents a method to build explicit tensor-train (TT) representations. We show that a wide class of tensors can be explicitly represented with sparse TT-cores, obtaining, in many cases, optimal TT-ranks. Numerical experiments show that our method outperforms the existing ones in several practical applications, including game theory problems. Theoretical estimations of the number of operations show that in some problems, such as permanent calculation, our methods are close to the known optimal asymptotics, which are obtained by a completely different type of methods."}}
{"id": "KnH_jr-sgS6", "cdate": 1640995200000, "mdate": 1682349487513, "content": {"title": "Optimization of Functions Given in the Tensor Train Format", "abstract": "Tensor train (TT) format is a common approach for computationally efficient work with multidimensional arrays, vectors, matrices, and discretized functions in a wide range of applications, including computational mathematics and machine learning. In this work, we propose a new algorithm for TT-tensor optimization, which leads to very accurate approximations for the minimum and maximum tensor element. The method consists in sequential tensor multiplications of the TT-cores with an intelligent selection of candidates for the optimum. We propose the probabilistic interpretation of the method, and make estimates on its complexity and convergence. We perform extensive numerical experiments with random tensors and various multivariable benchmark functions with the number of input dimensions up to $100$. Our approach generates a solution close to the exact optimum for all model problems, while the running time is no more than $50$ seconds on a regular laptop."}}
{"id": "L9iN1UFiLj", "cdate": 1609459200000, "mdate": 1682349487521, "content": {"title": "Optimal soil sampling design based on the maxvol algorithm", "abstract": "Spatial soil sampling is an integral part of a soil survey aimed at creating a soil map. We propose considering the soil sampling procedure as a task of optimal design. In practical terms, optimal experiments can reduce experimentation costs, as they allow the researcher to obtain one optimal set of points. We present a sampling design, based on the fundamental idea of selecting sample locations by performing an optimal design method called the maxvol algorithm. It is shown that the maxvol-base algorithm has a high potential for practical usage. Our method outperforms popular sampling methods in soil taxa prediction based on topographical features of the site and deals with massive agricultural datasets in a reasonable time."}}
{"id": "CKmdAqAIza9", "cdate": 1609459200000, "mdate": 1682349487502, "content": {"title": "Two-phase approaches to optimal model-based design of experiments: how many experiments and which ones?", "abstract": ""}}
{"id": "nYMX0BSEarX", "cdate": 1514764800000, "mdate": null, "content": {"title": "Gradient Descent-based D-optimal Design for the Least-Squares Polynomial Approximation", "abstract": "In this work, we propose a novel sampling method for Design of Experiments. This method allows to sample such input values of the parameters of a computational model for which the constructed surrogate model will have the least possible approximation error. High efficiency of the proposed method is demonstrated by its comparison with other sampling techniques (LHS, Sobol' sequence sampling, and Maxvol sampling) on the problem of least-squares polynomial approximation. Also, numerical experiments for the Lebesgue constant growth for the points sampled by the proposed method are carried out."}}
