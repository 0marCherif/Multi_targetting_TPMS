{"id": "zuDyPgbAVU1", "cdate": 1672531200000, "mdate": 1681686454817, "content": {"title": "Multi-Channel Auction Design in the Autobidding World", "abstract": "Over the past few years, more and more Internet advertisers have started using automated bidding for optimizing their advertising campaigns. Such advertisers have an optimization goal (e.g. to maximize conversions), and some constraints (e.g. a budget or an upper bound on average cost per conversion), and the automated bidding system optimizes their auction bids on their behalf. Often, these advertisers participate on multiple advertising channels and try to optimize across these channels. A central question that remains unexplored is how automated bidding affects optimal auction design in the multi-channel setting. In this paper, we study the problem of setting auction reserve prices in the multi-channel setting. In particular, we shed light on the revenue implications of whether each channel optimizes its reserve price locally, or whether the channels optimize them globally to maximize total revenue. Motivated by practice, we consider two models: one in which the channels have full freedom to set reserve prices, and another in which the channels have to respect floor prices set by the publisher. We show that in the first model, welfare and revenue loss from local optimization is bounded by a function of the advertisers' inputs, but is independent of the number of channels and bidders. In stark contrast, we show that the revenue from local optimization could be arbitrarily smaller than those from global optimization in the second model."}}
{"id": "54z14YirfQm", "cdate": 1672531200000, "mdate": 1681686454820, "content": {"title": "Beyond Worst-Case Budget-Feasible Mechanism Design", "abstract": "Motivated by large-market applications such as crowdsourcing, we revisit the problem of budget-feasible mechanism design under a \"small-bidder assumption\". Anari, Goel, and Nikzad (2018) gave a mechanism that has optimal competitive ratio 1-1/e on worst-case instances. However, we observe that on many realistic instances, their mechanism is significantly outperformed by a simpler open clock auction by Ensthaler and Giebe (2014), although the open clock auction only achieves competitive ratio 1/2 in the worst case. Is there a mechanism that gets the best of both worlds, i.e., a mechanism that is worst-case optimal and performs favorably on realistic instances? To answer this question, we initiate the study of beyond worst-case budget-feasible mechanism design. Our first main result is the design and the analysis of a natural mechanism that gives an affirmative answer to our question above: - We prove that on every instance, our mechanism performs at least as good as all uniform mechanisms, including Anari, Goel, and Nikzad\u2019s and Ensthaler and Giebe\u2019s mechanisms. - Moreover, we empirically evaluate our mechanism on various realistic instances and observe that it beats the worst-case 1-1/e competitive ratio by a large margin and compares favorably to both mechanisms mentioned above. Our second main result is more interesting in theory: We show that in the semi-adversarial model of budget-smoothed analysis, where the adversary designs a single worst-case market for a distribution of budgets, our mechanism is optimal among all (including non-uniform) mechanisms; furthermore our mechanism guarantees a strictly better-than-(1-1/e) expected competitive ratio for any non-trivial budget distribution regardless of the market. (In contrast, given any bounded range of budgets, we can construct a single market where Anari, Goel, and Nikzad\u2019s mechanism achieves only 1-1/e competitive ratio for every budget in this range.) We complement the positive result with a characterization of the worst-case markets for any given budget distribution and prove a fairly robust hardness result that holds against any budget distribution and any mechanism."}}
{"id": "_cjexHE6VV", "cdate": 1640995200000, "mdate": 1681686454815, "content": {"title": "Maximizing Non-Monotone Submodular Functions over Small Subsets: Beyond 1/2-Approximation", "abstract": "In this work we give two new algorithms that use similar techniques for (non-monotone) submodular function maximization subject to a cardinality constraint. The first is an offline fixed-parameter tractable algorithm that guarantees a 0.539-approximation for all non-negative submodular functions. The second algorithm works in the random-order streaming model. It guarantees a (1/2+c)-approximation for symmetric functions, and we complement it by showing that no space-efficient algorithm can beat 1/2 for asymmetric functions. To the best of our knowledge this is the first provable separation between symmetric and asymmetric submodular function maximization."}}
{"id": "OprO2tHrW4_", "cdate": 1640995200000, "mdate": 1655210971002, "content": {"title": "Budget-Smoothed Analysis for Submodular Maximization", "abstract": "The greedy algorithm for monotone submodular function maximization subject to cardinality constraint is guaranteed to approximate the optimal solution to within a 1-1/e factor. Although it is well known that this guarantee is essentially tight in the worst case - for greedy and in fact any efficient algorithm, experiments show that greedy performs better in practice. We observe that for many applications in practice, the empirical distribution of the budgets (i.e., cardinality constraints) is supported on a wide range, and moreover, all the existing hardness results in theory break under a large perturbation of the budget. To understand the effect of the budget from both algorithmic and hardness perspectives, we introduce a new notion of budget-smoothed analysis. We prove that greedy is optimal for every budget distribution, and we give a characterization for the worst-case submodular functions. Based on these results, we show that on the algorithmic side, under realistic budget distributions, greedy and related algorithms enjoy provably better approximation guarantees, that hold even for worst-case functions, and on the hardness side, there exist hard functions that are fairly robust to all the budget distributions."}}
{"id": "7_t4Gvubkeo", "cdate": 1621629771089, "mdate": null, "content": {"title": "Cardinality constrained submodular maximization for random streams", "abstract": "We consider the problem of maximizing submodular functions in single-pass streaming and secretaries-with-shortlists models, both with random arrival order.\nFor cardinality constrained monotone functions, Agrawal, Shadravan, and Stein~\\cite{SMC19} gave a single-pass $(1-1/e-\\varepsilon)$-approximation algorithm using only linear memory, but their exponential dependence on $\\varepsilon$ makes it impractical even for $\\varepsilon=0.1$.\nWe simplify both the algorithm and the analysis, obtaining an exponential improvement in the $\\varepsilon$-dependence (in particular, $O(k/\\varepsilon)$ memory).\nExtending these techniques, we also give a simple $(1/e-\\varepsilon)$-approximation for non-monotone functions in $O(k/\\varepsilon)$ memory. For the monotone case, we also give a corresponding unconditional hardness barrier of $1-1/e+\\varepsilon$ for single-pass algorithms in randomly ordered streams, even assuming unlimited computation. \n\nFinally, we show that the algorithms are simple to implement and work well on real world datasets."}}
{"id": "ntLVR__qryA", "cdate": 1609459200000, "mdate": 1655210971063, "content": {"title": "Cardinality constrained submodular maximization for random streams", "abstract": "We consider the problem of maximizing submodular functions in single-pass streaming and secretaries-with-shortlists models, both with random arrival order.For cardinality constrained monotone functions, Agrawal, Shadravan, and Stein~\\cite{SMC19} gave a single-pass $(1-1/e-\\varepsilon)$-approximation algorithm using only linear memory, but their exponential dependence on $\\varepsilon$ makes it impractical even for $\\varepsilon=0.1$.We simplify both the algorithm and the analysis, obtaining an exponential improvement in the $\\varepsilon$-dependence (in particular, $O(k/\\varepsilon)$ memory).Extending these techniques, we also give a simple $(1/e-\\varepsilon)$-approximation for non-monotone functions in $O(k/\\varepsilon)$ memory. For the monotone case, we also give a corresponding unconditional hardness barrier of $1-1/e+\\varepsilon$ for single-pass algorithms in randomly ordered streams, even assuming unlimited computation. Finally, we show that the algorithms are simple to implement and work well on real world datasets."}}
{"id": "brxj2XnLxm2", "cdate": 1609459200000, "mdate": 1655210970910, "content": {"title": "The randomized communication complexity of revenue maximization", "abstract": "We study the communication complexity of incentive compatible auction-protocols between a monopolist seller and a single buyer with a combinatorial valuation function over n items [Rubinstein and Zhao 2021]. Motivated by the fact that revenue-optimal auctions are randomized [Thanassoulis 2004; Manelli and Vincent 2010; Briest et al. 2010; Pavlov 2011; Hart and Reny 2015] (as well as by an open problem of Babaioff, Gonczarowski, and Nisan [Babaioff et al. 2017]), we focus on the randomized communication complexity of this problem (in contrast to most prior work on deterministic communication). We design simple, incentive compatible, and revenue-optimal auction-protocols whose expected communication complexity is much (in fact infinitely) more efficient than their deterministic counterparts. We also give nearly matching lower bounds on the expected communication complexity of approximately-revenue-optimal auctions. These results follow from a simple characterization of incentive compatible auction-protocols that allows us to prove lower bounds against randomized auction-protocols. In particular, our lower bounds give the first approximation-resistant, exponential separation between communication complexity of incentivizing vs implementing a Bayesian incentive compatible social choice rule, settling an open question of Fadel and Segal [Fadel and Segal 2009]."}}
{"id": "_T5E2v-XhJu", "cdate": 1609459200000, "mdate": 1655210971148, "content": {"title": "The randomized communication complexity of randomized auctions", "abstract": "We study the communication complexity of incentive compatible auction-protocols between a monopolist seller and a single buyer with a combinatorial valuation function over n items. Motivated by the fact that revenue-optimal auctions are randomized (as well as by an open problem of Babaioff, Gonczarowski, and Nisan), we focus on the randomized communication complexity of this problem (in contrast to most prior work on deterministic communication). We design simple, incentive compatible, and revenue-optimal auction-protocols whose expected communication complexity is much (in fact infinitely) more efficient than their deterministic counterparts. We also give nearly matching lower bounds on the expected communication complexity of approximately-revenue-optimal auctions. These results follow from a simple characterization of incentive compatible auction-protocols that allows us to prove lower bounds against randomized auction-protocols. In particular, our lower bounds give the first approximation-resistant, exponential separation between communication complexity of incentivizing vs implementing a Bayesian incentive compatible social choice rule, settling an open question of Fadel and Segal."}}
{"id": "U0ZEEAav3RQ", "cdate": 1609459200000, "mdate": 1655210970948, "content": {"title": "Exponential communication separations between notions of selfishness", "abstract": "We consider the problem of implementing a fixed social choice function between multiple players (which takes as input a type ti from each player i and outputs an outcome f(t1,\u2026, tn)), in which each player must be incentivized to follow the protocol. In particular, we study the communication requirements of a protocol which: (a) implements f, (b) implements f and computes payments that make it ex-post incentive compatible (EPIC) to follow the protocol, and (c) implements f and computes payments in a way that makes it dominant-strategy incentive compatible (DSIC) to follow the protocol.                                                                                                                                                                   We show exponential separations between all three of these quantities, already for just two players. That is, we first construct an f such that f can be implemented in communication c, but any EPIC implementation of f (with any choice of payments) requires communication exp(c). This answers an open question of [Fadel and Segal, 2009; Babaioff et. al., 2013]. Second, we construct an f such that an EPIC protocol implements f with communication C, but all DSIC implementations of f require communication exp(C)."}}
{"id": "6bjbYr5S0q", "cdate": 1514764800000, "mdate": 1681686454843, "content": {"title": "Robust Maximization of Non-Submodular Objectives", "abstract": "We study the problem of maximizing a monotone set function subject to a cardinality constraint $k$ in the setting where some number of elements $\u03c4$ is deleted from the returned set. The focus of th..."}}
