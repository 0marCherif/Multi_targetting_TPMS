{"id": "j0ZGAEB00EI", "cdate": 1702532833725, "mdate": 1702532833725, "content": {"title": "DoCoGen: Domain Counterfactual Generation for Low Resource Domain Adaptation", "abstract": "Natural language processing (NLP) algorithms have become very successful, but they still struggle when applied to out-of-distribution examples. In this paper we propose a controllable generation approach in order to deal with this domain adaptation (DA) challenge. Given an input text example, our DoCoGen algorithm generates a domain-counterfactual textual example (D-con) - that is similar to the original in all aspects, including the task label, but its domain is changed to a desired one. Importantly, DoCoGen is trained using only unlabeled examples from multiple domains - no NLP task labels or parallel pairs of textual examples and their domain-counterfactuals are required. We show that DoCoGen can generate coherent counterfactuals consisting of multiple sentences. We use the D-cons generated by DoCoGen to augment a sentiment classifier and a multi-label intent classifier in 20 and 78 DA setups, respectively, where source-domain labeled data is scarce. Our model outperforms strong baselines and improves the accuracy of a state-of-the-art unsupervised DA algorithm."}}
{"id": "cspJFrsyRm", "cdate": 1686217732645, "mdate": 1686217732645, "content": {"title": "Model compression for domain adaptation through causal effect estimation", "abstract": "Recent improvements in the predictive quality of natural language processing systems are often dependent on a substantial increase in the number of model parameters. This has led to various attempts of compressing such models, but existing methods have not considered the differences in the predictive power of various model components or in the generalizability of the compressed models. To understand the connection between model compression and out-of-distribution generalization, we define the task of compressing language representation models such that they perform best in a domain adaptation setting. We choose to address this problem from a causal perspective, attempting to estimate the average treatment effect (ATE) of a model component, such as a single layer, on the model\u2019s predictions. Our proposed ATE-guided Model Compression scheme (AMoC), generates many model candidates, differing by the model components that were removed. Then, we select the best candidate through a stepwise regression model that utilizes the ATE to predict the expected performance on the target domain. AMoC outperforms strong baselines on dozens of domain pairs across three text classification and sequence tagging tasks."}}
{"id": "CqUMx8sFhb", "cdate": 1664928781588, "mdate": null, "content": {"title": "Useful Confidence Measures: Beyond the Max Score", "abstract": "An important component in deploying machine learning (ML) in safety-critic applications is having a reliable measure of confidence in the ML model's predictions. For a classifier $f$ producing a probability vector $f(x)$ over the candidate classes, the confidence is typically taken to be $\\max_i f(x)_i$. This approach is potentially limited, as it disregards the rest of the probability vector. In this work, we derive several confidence measures that depend on information beyond the maximum score, such as margin-based and entropy-based measures, and empirically evaluate their usefulness, focusing on NLP tasks with distribution shifts and Transformer-based models. We show that when models are evaluated on the out-of-distribution data ``out of the box'', using only the maximum score to inform the confidence measure is highly suboptimal. In the post-processing regime (where the scores of $f$ can be improved using additional in-distribution held-out data), this remains true, albeit less significant. Overall, our results suggest that entropy-based confidence is a surprisingly useful measure."}}
{"id": "SudRJjtGRz", "cdate": 1664928780874, "mdate": null, "content": {"title": "An Invariant Learning Characterization of Controlled Text Generation", "abstract": "Controlled generation refers to the problem of creating text that contains stylistic or semantic attributes of interest. \nMany approaches reduce this problem to building a predictor of the desired attribute.\nFor example, researchers hoping to deploy a large language model to produce non-toxic content may use a toxicity classifier to filter generated text. \nIn this paper, we show that the performance of controlled generation may be poor if the target distribution of text differs from the distribution the predictor was trained on. \nInstead, we take inspiration from causal representation learning and cast controlled generation under distribution shift as an invariant learning problem: the most effective predictor should be invariant across multiple text environments. Experiments demonstrate the promise and difficulty of adapting invariant learning methods, which have been primarily developed for vision, to text."}}
{"id": "zInaytkuzX", "cdate": 1664833378623, "mdate": null, "content": {"title": "An Invariant Learning Characterization of Controlled Text Generation", "abstract": "Controlled generation refers to the problem of creating text that contains stylistic or semantic attributes of interest. \nMany approaches reduce this problem to building a predictor of the desired attribute.\nFor example, researchers hoping to deploy a large language model to produce non-toxic content may use a toxicity classifier to filter generated text. \nIn this paper, we show that the performance of controlled generation may be poor if the target distribution of text differs from the distribution the predictor was trained on. \nInstead, we take inspiration from causal representation learning and cast controlled generation under distribution shift as an invariant learning problem: the most effective predictor should be invariant across multiple text environments. Experiments demonstrate the promise and difficulty of adapting invariant learning methods, which have been primarily developed for vision, to text."}}
{"id": "8FsfyRnb8b", "cdate": 1653904143120, "mdate": null, "content": {"title": "In the Eye of the Beholder: Robust Prediction with Causal User Modeling", "abstract": "Accurately predicting the relevance of items to users is crucial to the success of many social platforms. Conventional approaches train models on logged historical data; but recommendation systems, media services, and online marketplaces all exhibit a constant influx of new content---making relevancy a moving target, to which standard predictive models are not robust. In this paper, we propose a learning framework for relevance prediction that is robust to changes in the data distribution. Our key observation is that robustness can be obtained by accounting for \\emph{how users causally perceive the environment}. We model users as boundedly-rational decision makers whose causal beliefs are encoded by a causal graph, and show how minimal information regarding the graph can be used to contend with distributional changes. Experiments in multiple settings demonstrate the effectiveness of our approach."}}
{"id": "3AbigH4s-ml", "cdate": 1652737356101, "mdate": null, "content": {"title": "CEBaB: Estimating the Causal Effects of Real-World Concepts on NLP Model Behavior", "abstract": "The increasing size and complexity of modern ML systems has improved their predictive capabilities but made their behavior harder to explain. Many techniques for model explanation have been developed in response, but we lack clear criteria for assessing these techniques. In this paper, we cast model explanation as the causal inference problem of estimating causal effects of real-world concepts on the output behavior of ML models given actual input data. We introduce CEBaB, a new benchmark dataset for assessing concept-based explanation methods in Natural Language Processing (NLP). CEBaB consists of short restaurant reviews with human-generated counterfactual reviews in which an aspect (food, noise, ambiance, service) of the dining experience was modified. Original and counterfactual reviews are annotated with multiply-validated sentiment ratings at the aspect-level and review-level. The rich structure of CEBaB allows us to go beyond input features to study the effects of abstract, real-world concepts on model behavior. We use CEBaB to compare the quality of a range of concept-based explanation methods covering different assumptions and conceptions of the problem, and we seek to establish natural metrics for comparative assessments of these methods."}}
{"id": "ikXoMuy_H4", "cdate": 1652737299344, "mdate": null, "content": {"title": "In the Eye of the Beholder: Robust Prediction with Causal User Modeling", "abstract": "Accurately predicting the relevance of items to users is crucial to the success of many social platforms. Conventional approaches train models on logged historical data; but recommendation systems, media services, and online marketplaces all exhibit a constant influx of new content---making relevancy a moving target, to which standard predictive models are not robust. In this paper, we propose a learning framework for relevance prediction that is robust to changes in the data distribution. Our key observation is that robustness can be obtained by accounting for \\emph{how users causally perceive the environment}. We model users as boundedly-rational decision makers whose causal beliefs are encoded by a causal graph, and show how minimal information regarding the graph can be used to contend with distributional changes. Experiments in multiple settings demonstrate the effectiveness of our approach."}}
{"id": "w-nav4iM-nd", "cdate": 1640995200000, "mdate": 1681735550334, "content": {"title": "DoCoGen: Domain Counterfactual Generation for Low Resource Domain Adaptation", "abstract": ""}}
{"id": "sot0Z_Y4w0x", "cdate": 1640995200000, "mdate": 1681735550337, "content": {"title": "Section Classification in Clinical Notes with Multi-task Transformers", "abstract": ""}}
