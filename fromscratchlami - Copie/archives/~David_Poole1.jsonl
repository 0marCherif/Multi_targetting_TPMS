{"id": "rbb6s5es6QK", "cdate": 1591827637575, "mdate": null, "content": {"title": "Conditioning on \"and nothing else\": Simple Models of Missing Data between Naive Bayes and Logistic Regression", "abstract": "In situations where people report in a free-form way, we need to condition on the fact that someone \\emph{did not} report something. While we need to take into account that something was not reported, often there are too many statements that could be reported to consider each one; we only want to reason about those that were reported. In this paper we start with two simple, common models, namely Naive\nBayes and logistic regression, which are equivalent models that are trained differently as to how missing data is handled. Naive Bayes is traditionally trained in a generative way, to make optimal predictions assuming only one value is observed (and making independence assumptions for the rest) and logistic regression is traditionally trained in a discriminative way, assuming no data is missing. It is generally assumed that these are qualitatively different, but in this paper we show there is a continuum between them. In particular, we show a model that is more general than both, but still simple, that can be trained to condition on missing data. In particular, it conditions on ``and nothing else [was reported]'' enabling us to avoid reasoning about the myriad of things that were not reported, but still take them into account."}}
{"id": "fo9owgRAj6B", "cdate": 1577836800000, "mdate": null, "content": {"title": "Predicting Landslides Using Locally Aligned Convolutional Neural Networks", "abstract": "Landslides, movement of soil and rock under the influence of gravity, are common phenomena that cause significant human and economic losses every year. Experts use heterogeneous features such as slope, elevation, land cover, lithology, rock age, and rock family to predict landslides. To work with such features, we adapted convolutional neural networks to consider relative spatial information for the prediction task. Traditional filters in these networks either have a fixed orientation or are rotationally invariant. Intuitively, the filters should orient uphill, but there is not enough data to learn the concept of uphill; instead, it can be provided as prior knowledge. We propose a model called Locally Aligned Convolutional Neural Network, LACNN, that follows the ground surface at multiple scales to predict possible landslide occurrence for a single point. To validate our method, we created a standardized dataset of georeferenced images consisting of the heterogeneous features as inputs, and compared our method to several baselines, including linear regression, a neural network, and a convolutional network, using log-likelihood error and Receiver Operating Characteristic curves on the test set. Our model achieves 2-7% improvement in terms of accuracy and 2-15% boost in terms of log likelihood compared to the other proposed baselines."}}
{"id": "MgYfZePWf8G", "cdate": 1577836800000, "mdate": null, "content": {"title": "AISpace2: An Interactive Visualization Tool for Learning and Teaching Artificial Intelligence", "abstract": "AIspace is a set of tools used to learn and teach fundamental AI algorithms. The original version of AIspace was written in Java. There was not a clean separation of the algorithms and visualization; it was too complicated for students to modify the underlying algorithms. Its next generation, AIspace2, is built on AIPython, open source Python code that is designed to be as close as possible to pseudocode. AISpace2, visualized in JupyterLab, keeps the simple Python code, and uses hooks in AIPython to allow visualization of the algorithms. This allows students to see and modify the high-level algorithms in Python, and to visualize the output in a graphical form, aiming to better help them to build confidence and comfort in AI concepts and algorithms. So far we have tools for search, constraint satisfaction problems (CSP), planning and Bayesian network. In this paper we outline the tools and give some evaluations based on user feedback."}}
{"id": "IHhfLjBZluj", "cdate": 1577836800000, "mdate": null, "content": {"title": "Binarised Regression with Instance-Varying Costs: Evaluation using Impact Curves", "abstract": "Many evaluation methods exist, each for a particular prediction task, and there are a number of prediction tasks commonly performed including classification and regression. In binarised regression, binary decisions are generated from a learned regression model (or real-valued dependent variable), which is useful when the division between instances that should be predicted positive or negative depends on the utility. For example, in mining, the boundary between a valuable rock and a waste rock depends on the market price of various metals, which varies with time. This paper proposes impact curves to evaluate binarised regression with instance-varying costs, where some instances are much worse to be classified as positive (or negative) than other instances; e.g., it is much worse to throw away a high-grade gold rock than a medium-grade copper-ore rock, even if the mine wishes to keep both because both are profitable. We show how to construct an impact curve for a variety of domains, including examples from healthcare, mining, and entertainment. Impact curves optimize binary decisions across all utilities of the chosen utility function, identify the conditions where one model may be favoured over another, and quantitatively assess improvement between competing models."}}
{"id": "ryxIZR4tvS", "cdate": 1569439230369, "mdate": null, "content": {"title": "Knowledge Hypergraphs: Prediction Beyond Binary Relations", "abstract": "A Knowledge Hypergraph is a knowledge base where relations are defined on two or more entities. In this work, we introduce two embedding-based models that perform link prediction in knowledge hypergraphs:\n(1) HSimplE is a shift-based method that is inspired by an existing model operating on knowledge graphs, in which the representation of an entity is a function of its position in the relation, and (2) HypE is a convolution-based method which disentangles the representation of an entity from its position in the relation. We test our models on two new knowledge hypergraph datasets that we obtain from Freebase, and show that both HSimplE and HypE are more effective in predicting links in knowledge hypergraphs than the proposed baselines and existing methods.\nOur experiments show that HypE outperforms HSimplE when trained with fewer parameters and when tested on samples that contain at least one entity in a position never encountered during training."}}
{"id": "j5T9sWhBFAb_", "cdate": 1546300800000, "mdate": null, "content": {"title": "A Probabilistic Approach for Predicting Landslides by Learning a Self-Aligned Deep Convolutional Model", "abstract": "Landslides, movement of soil and rock under the influence of gravity, are common phenomena that cause significant human and economic losses every year. Experts use heterogeneous features such as slope, elevation, land cover, lithology, rock age, and rock family to predict landslides. To work with such features, we adapted convolutional neural networks to consider relative spatial information for the prediction task. Traditional filters in these networks either have a fixed orientation or are rotationally invariant. Intuitively, the filters should orient uphill, but there is not enough data to learn the concept of uphill; instead, it can be provided as prior knowledge. We propose a model called Locally Aligned Convolutional Neural Network, LACNN, that follows the ground surface at multiple scales to predict possible landslide occurrence for a single point. To validate our method, we created a standardized dataset of georeferenced images consisting of the heterogeneous features as inputs, and compared our method to several baselines, including linear regression, a neural network, and a convolutional network, using log-likelihood error and Receiver Operating Characteristic curves on the test set. Our model achieves 2-7% improvement in terms of accuracy and 2-15% boost in terms of log likelihood compared to the other proposed baselines."}}
{"id": "SoIwc1zg_TS", "cdate": 1546300800000, "mdate": null, "content": {"title": "Improved Knowledge Graph Embedding Using Background Taxonomic Information.", "abstract": "Knowledge graphs are used to represent relational information in terms of triples. To enable learning about domains, embedding models, such as tensor factorization models, can be used to make predictions of new triples. Often there is background taxonomic information (in terms of subclasses and subproperties) that should also be taken into account. We show that existing fully expressive (a.k.a. universal) models cannot provably respect subclass and subproperty information. We show that minimal modifications to an existing knowledge graph completion method enables injection of taxonomic information. Moreover, we prove that our model is fully expressive, assuming a lower-bound on the size of the embeddings. Experimental results on public knowledge graphs show that despite its simplicity our approach is surprisingly effective."}}
{"id": "37nHiJE-F_l", "cdate": 1546300800000, "mdate": null, "content": {"title": "Knowledge Hypergraphs: Extending Knowledge Graphs Beyond Binary Relations", "abstract": "Knowledge graphs store facts using relations between two entities. In this work, we address the question of link prediction in knowledge hypergraphs where relations are defined on any number of entities. While techniques exist (such as reification) that convert non-binary relations into binary ones, we show that current embedding-based methods for knowledge graph completion do not work well out of the box for knowledge graphs obtained through these techniques. To overcome this, we introduce HSimplE and HypE, two embedding-based methods that work directly with knowledge hypergraphs. In both models, the prediction is a function of the relation embedding, the entity embeddings and their corresponding positions in the relation. We also develop public datasets, benchmarks and baselines for hypergraph prediction and show experimentally that the proposed models are more effective than the baselines."}}
{"id": "sZtzPjJHni8", "cdate": 1514764800000, "mdate": null, "content": {"title": "Interactive Visualization for Group Decision Analysis", "abstract": "Identifying the best solutions to large infrastructure decisions is a context-dependent multi-dimensional multi-stakeholder challenge in which competing objectives must be identified and trade-offs..."}}
{"id": "fCSbduAUBKpb", "cdate": 1514764800000, "mdate": null, "content": {"title": "Structure Learning for Relational Logistic Regression: An Ensemble Approach", "abstract": "We consider the problem of learning Relational Logistic Regression (RLR). Unlike standard logistic regression, the features of RLRs are first-order formulae with associated weight vectors instead of scalar weights. We turn the problem of learning RLR to learning these vector-weighted formulae and develop a learning algorithm based on the recently successful functional-gradient boosting methods for probabilistic logic models. We derive the functional gradients and show how weights can be learned simultaneously in an efficient manner. Our empirical evaluation on standard and novel data sets demonstrates the superiority of our approach over other methods for learning RLR."}}
