{"id": "C2vrjRdeQl", "cdate": 1701388800000, "mdate": 1695371891980, "content": {"title": "Quantum autoencoders for communication-efficient cloud computing", "abstract": "In the model of quantum cloud computing, the server executes a computation on the quantum data provided by the client. In this scenario, it is important to reduce the amount of quantum communication between the client and the server. A possible approach is to transform the desired computation into a compressed version that acts on a smaller number of qubits, thereby reducing the amount of data exchanged between the client and the server. Here we propose quantum autoencoders for quantum gates (QAEGate) as a method for compressing quantum computations. We illustrate it in concrete scenarios of single-round and multi-round communication and validate it through numerical experiments. A bonus of our method is it does not reveal any information about the server\u2019s computation other than the information present in the output."}}
{"id": "rlzXULxlFYJ", "cdate": 1695960581981, "mdate": 1695960581981, "content": {"title": "Quantum autoencoders for communication-efficient cloud computing", "abstract": "In the model of quantum cloud computing, the server executes a computation on the quantum data provided by the client. In this scenario, it is important to reduce the amount of quantum communication between the client and the server. A possible approach is to transform the desired computation into a compressed version that acts on a smaller number of qubits, thereby reducing the amount of data exchanged between the client and the server. Here we propose quantum autoencoders for quantum gates (QAEGate) as a method for compressing quantum computations. We illustrate it in concrete scenarios of single-round and multi-round communication and validate it through numerical experiments. A bonus of our method is it does not reveal any information about the server\u2019s computation other than the information present in the output."}}
{"id": "gVhMxVoX9E", "cdate": 1672531200000, "mdate": 1695371892430, "content": {"title": "Quantum Lower Bounds for Finding Stationary Points of Nonconvex Functions", "abstract": "Quantum computing is an emerging technology that has been rapidly advancing in the past decades. In this paper, we conduct a systematic study of quantum lower bounds on finding $\\epsilon$-approxima..."}}
{"id": "e2tAvjX6P5O", "cdate": 1672531200000, "mdate": 1695371892429, "content": {"title": "Fast and Practical Quantum-Inspired Classical Algorithms for Solving Linear Systems", "abstract": "We propose fast and practical quantum-inspired classical algorithms for solving linear systems. Specifically, given sampling and query access to a matrix $A\\in\\mathbb{R}^{m\\times n}$ and a vector $b\\in\\mathbb{R}^m$, we propose classical algorithms that produce a data structure for the solution $x\\in\\mathbb{R}^{n}$ of the linear system $Ax=b$ with the ability to sample and query its entries. The resulting $x$ satisfies $\\|x-A^{+}b\\|\\leq\\epsilon\\|A^{+}b\\|$, where $\\|\\cdot\\|$ is the spectral norm and $A^+$ is the Moore-Penrose inverse of $A$. Our algorithm has time complexity $\\widetilde{O}(\\kappa_F^4/\\kappa\\epsilon^2)$ in the general case, where $\\kappa_{F} =\\|A\\|_F\\|A^+\\|$ and $\\kappa=\\|A\\|\\|A^+\\|$ are condition numbers. Compared to the prior state-of-the-art result [Shao and Montanaro, arXiv:2103.10309v2], our algorithm achieves a polynomial speedup in condition numbers. When $A$ is $s$-sparse, our algorithm has complexity $\\widetilde{O}(s \\kappa\\log(1/\\epsilon))$, matching the quantum lower bound for solving linear systems in $\\kappa$ and $1/\\epsilon$ up to poly-logarithmic factors [Harrow and Kothari]. When $A$ is $s$-sparse and symmetric positive-definite, our algorithm has complexity $\\widetilde{O}(s\\sqrt{\\kappa}\\log(1/\\epsilon))$. Technically, our main contribution is the application of the heavy ball momentum method to quantum-inspired classical algorithms for solving linear systems, where we propose two new methods with speedups: quantum-inspired Kaczmarz method with momentum and quantum-inspired coordinate descent method with momentum. Their analysis exploits careful decomposition of the momentum transition matrix and the application of novel spectral norm concentration bounds for independent random matrices. Finally, we also conduct numerical experiments for our algorithms on both synthetic and real-world datasets, and the experimental results support our theoretical claims."}}
{"id": "c4-SKpLZyDZ", "cdate": 1672531200000, "mdate": 1695371891979, "content": {"title": "Quantum Multi-Armed Bandits and Stochastic Linear Bandits Enjoy Logarithmic Regrets", "abstract": "Multi-arm bandit (MAB) and stochastic linear bandit (SLB) are important models in reinforcement learning, and it is well-known that classical algorithms for bandits with time horizon T suffer from the regret of at least the square root of T. In this paper, we study MAB and SLB with quantum reward oracles and propose quantum algorithms for both models with the order of the polylog T regrets, exponentially improving the dependence in terms of T. To the best of our knowledge, this is the first provable quantum speedup for regrets of bandit problems and in general exploitation in reinforcement learning. Compared to previous literature on quantum exploration algorithms for MAB and reinforcement learning, our quantum input model is simpler and only assumes quantum oracles for each individual arm."}}
{"id": "TpdU3j71kKl", "cdate": 1672531200000, "mdate": 1682327508358, "content": {"title": "Provably Efficient Exploration in Quantum Reinforcement Learning with Logarithmic Worst-Case Regret", "abstract": "While quantum reinforcement learning (RL) has attracted a surge of attention recently, its theoretical understanding is limited. In particular, it remains elusive how to design provably efficient quantum RL algorithms that can address the exploration-exploitation trade-off. To this end, we propose a novel UCRL-style algorithm that takes advantage of quantum computing for tabular Markov decision processes (MDPs) with $S$ states, $A$ actions, and horizon $H$, and establish an $\\mathcal{O}(\\mathrm{poly}(S, A, H, \\log T))$ worst-case regret for it, where $T$ is the number of episodes. Furthermore, we extend our results to quantum RL with linear function approximation, which is capable of handling problems with large state spaces. Specifically, we develop a quantum algorithm based on value target regression (VTR) for linear mixture MDPs with $d$-dimensional linear representation and prove that it enjoys $\\mathcal{O}(\\mathrm{poly}(d, H, \\log T))$ regret. Our algorithms are variants of UCRL/UCRL-VTR algorithms in classical RL, which also leverage a novel combination of lazy updating mechanisms and quantum estimation subroutines. This is the key to breaking the $\\Omega(\\sqrt{T})$-regret barrier in classical RL. To the best of our knowledge, this is the first work studying the online exploration in quantum RL with provable logarithmic worst-case regret."}}
{"id": "9SPVCXs0zV4", "cdate": 1672531200000, "mdate": 1695371891961, "content": {"title": "Near-Optimal Quantum Coreset Construction Algorithms for Clustering", "abstract": "k$-Clustering in $\\mathbb{R}^d$ (e.g., $k$-median and $k$-means) is a fundamental machine learning problem. While near-linear time approximation algorithms were known in the classical setting for a dataset with cardinality $n$, it remains open to find sublinear-time quantum algorithms. We give quantum algorithms that find coresets for $k$-clustering in $\\mathbb{R}^d$ with $\\tilde{O}(\\sqrt{nk}d^{3/2})$ query complexity. Our coreset reduces the input size from $n$ to $\\mathrm{poly}(k\\epsilon^{-1}d)$, so that existing $\\alpha$-approximation algorithms for clustering can run on top of it and yield $(1 + \\epsilon)\\alpha$-approximation. This eventually yields a quadratic speedup for various $k$-clustering approximation algorithms. We complement our algorithm with a nearly matching lower bound, that any quantum algorithm must make $\\Omega(\\sqrt{nk})$ queries in order to achieve even $O(1)$-approximation for $k$-clustering."}}
{"id": "6OdN6KgU-X1", "cdate": 1672531200000, "mdate": 1683879437359, "content": {"title": "Logarithmic-Regret Quantum Learning Algorithms for Zero-Sum Games", "abstract": "We propose the first online quantum algorithm for zero-sum games with $\\tilde O(1)$ regret under the game setting. Moreover, our quantum algorithm computes an $\\varepsilon$-approximate Nash equilibrium of an $m \\times n$ matrix zero-sum game in quantum time $\\tilde O(\\sqrt{m+n}/\\varepsilon^{2.5})$, yielding a quadratic improvement over classical algorithms in terms of $m, n$. Our algorithm uses standard quantum inputs and generates classical outputs with succinct descriptions, facilitating end-to-end applications. As an application, we obtain a fast quantum linear programming solver. Technically, our online quantum algorithm \"quantizes\" classical algorithms based on the optimistic multiplicative weight update method. At the heart of our algorithm is a fast quantum multi-sampling procedure for the Gibbs sampling problem, which may be of independent interest."}}
{"id": "09rdngGMfiJ", "cdate": 1672531200000, "mdate": 1695371892427, "content": {"title": "Near-Optimal Quantum Coreset Construction Algorithms for Clustering", "abstract": "k$-Clustering in $\\mathbb{R}^d$ (e.g., $k$-median and $k$-means) is a fundamental machine learning problem. While near-linear time approximation algorithms were known in the classical setting for a dataset with cardinality $n$, it remains open to find sublinear-time quantum algorithms. We give quantum algorithms that find coresets for $k$-clustering in $\\mathbb{R}^d$ with $\\tilde{O}(\\sqrt{nk}d^{3/2})$ query complexity. Our coreset reduces the input size from $n$ to $\\mathrm{poly}(k\\epsilon^{-1}d)$, so that existing $\\alpha$-approximation algorithms for clustering can run on top of it and yield $(1 + \\epsilon)\\alpha$-approximation. This eventually yields a quadratic speedup for various $k$-clustering approximation algorithms. We complement our algorithm with a nearly matching lower bound, that any quantum algorithm must make $\\Omega(\\sqrt{nk})$ queries in order to achieve even $O(1)$-approximation for $k$-clustering."}}
{"id": "zofwPmKL-DO", "cdate": 1652737663496, "mdate": null, "content": {"title": "Quantum Algorithms for Sampling Log-Concave Distributions and Estimating Normalizing Constants", "abstract": "Given a convex function $f\\colon\\mathbb{R}^{d}\\to\\mathbb{R}$, the problem of sampling from a distribution $\\propto e^{-f(x)}$ is called log-concave sampling. This task has wide applications in machine learning, physics, statistics, etc. In this work, we develop quantum algorithms for sampling log-concave distributions and for estimating their normalizing constants $\\int_{\\mathbb{R}^d}e^{-f(x)}\\mathrm{d} x$. First, we use underdamped Langevin diffusion to develop quantum algorithms that match the query complexity (in terms of the condition number $\\kappa$ and dimension $d$) of analogous classical algorithms that use gradient (first-order) queries, even though the quantum algorithms use only evaluation (zeroth-order) queries. For estimating normalizing constants, these algorithms also achieve quadratic speedup in the multiplicative error $\\epsilon$. Second, we develop quantum Metropolis-adjusted Langevin algorithms with query complexity $\\widetilde{O}(\\kappa^{1/2}d)$ and $\\widetilde{O}(\\kappa^{1/2}d^{3/2}/\\epsilon)$ for log-concave sampling and normalizing constant estimation, respectively, achieving polynomial speedups in $\\kappa,d,\\epsilon$ over the best known classical algorithms by exploiting quantum analogs of the Monte Carlo method and quantum walks. We also prove a $1/\\epsilon^{1-o(1)}$ quantum lower bound for estimating normalizing constants, implying near-optimality of our quantum algorithms in $\\epsilon$."}}
