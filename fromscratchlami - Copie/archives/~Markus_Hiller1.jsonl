{"id": "p_g2nHlMus", "cdate": 1652737331633, "mdate": null, "content": {"title": "Rethinking Generalization in Few-Shot Classification", "abstract": "Single image-level annotations only correctly describe an often small subset of an image\u2019s content, particularly when complex real-world scenes are depicted. While this might be acceptable in many classification scenarios, it poses a significant challenge for applications where the set of classes differs significantly between training and test time. In this paper, we take a closer look at the implications in the context of few-shot learning. Splitting the input samples into patches and encoding these via the help of Vision Transformers allows us to establish semantic correspondences between local regions across images and independent of their respective class. The most informative patch embeddings for the task at hand are then determined as a function of the support set via online optimization at inference time, additionally providing visual interpretability of \u2018what matters most\u2019 in the image. We build on recent advances in unsupervised training of networks via masked image modelling to overcome the lack of fine-grained labels and learn the more general statistical structure of the data while avoiding negative image-level annotation influence, aka supervision collapse. Experimental results show the competitiveness of our approach, achieving new state-of-the-art results on four popular few-shot classification benchmarks for 5-shot and 1-shot scenarios."}}
{"id": "G6cJsOOx2R3", "cdate": 1652737276288, "mdate": null, "content": {"title": "On Enforcing Better Conditioned Meta-Learning for Rapid Few-Shot Adaptation", "abstract": "Inspired by the concept of preconditioning, we propose a novel method to increase adaptation speed for gradient-based meta-learning methods without incurring extra parameters. We demonstrate that recasting the optimisation problem to a non-linear least-squares formulation provides a principled way to actively enforce a well-conditioned parameter space for meta-learning models based on the concepts of the condition number and local curvature. Our comprehensive evaluations show that the proposed method significantly outperforms its unconstrained counterpart especially during initial adaptation steps, while achieving comparable or better overall results on several few-shot classification tasks \u2013 creating the possibility of dynamically choosing the number of adaptation steps at inference time."}}
{"id": "WGl2dLKaGw", "cdate": 1609459200000, "mdate": 1668453079414, "content": {"title": "Looking Beyond Two Frames: End-to-End Multi-Object Tracking Using Spatial and Temporal Transformers", "abstract": "Tracking a time-varying indefinite number of objects in a video sequence over time remains a challenge despite recent advances in the field. Most existing approaches are not able to properly handle multi-object tracking challenges such as occlusion, in part because they ignore long-term temporal information. To address these shortcomings, we present MO3TR: a truly end-to-end Transformer-based online multi-object tracking (MOT) framework that learns to handle occlusions, track initiation and termination without the need for an explicit data association module or any heuristics. MO3TR encodes object interactions into long-term temporal embeddings using a combination of spatial and temporal Transformers, and recursively uses the information jointly with the input data to estimate the states of all tracked objects over time. The spatial attention mechanism enables our framework to learn implicit representations between all the objects and the objects to the measurements, while the temporal attention mechanism focuses on specific parts of past information, allowing our approach to resolve occlusions over multiple frames. Our experiments demonstrate the potential of this new approach, achieving results on par with or better than the current state-of-the-art on multiple MOT metrics for several popular multi-object tracking benchmarks."}}
{"id": "art_gFH9LLm", "cdate": 1546300800000, "mdate": 1681690154395, "content": {"title": "Learning Topometric Semantic Maps from Occupancy Grids", "abstract": "Today's mobile robots are expected to operate in complex environments they share with humans. To allow intuitive human-robot collaboration, robots require a human-like understanding of their surroundings in terms of semantically classified instances. In this paper, we propose a new approach for deriving such instance-based semantic maps purely from occupancy grids. We employ a combination of deep learning techniques to detect, segment and extract door hypotheses from a random-sized map. The extraction is followed by a post-processing chain to further increase the accuracy of our approach, as well as place categorization for the three classes room, door and corridor. All detected and classified entities are described as instances specified in a common coordinate system, while a topological map is derived to capture their spatial links. To train our two neural networks used for detection and map segmentation, we contribute a simulator that automatically creates and annotates the required training data. We further provide insight into which features are learned to detect doorways, and how the simulated training data can be augmented to train networks for the direct application on real-world grid maps. We evaluate our approach on several publicly available real-world data sets. Even though the used networks are solely trained on simulated data, our approach demonstrates high robustness and effectiveness in various real-world indoor environments."}}
{"id": "VNor_4Vtxn", "cdate": 1546300800000, "mdate": 1681690154390, "content": {"title": "Object Detection, Classification and Localization by Infrastructural Stereo Cameras", "abstract": ""}}
{"id": "UmsXq0V_GzN", "cdate": 1546300800000, "mdate": 1681690154392, "content": {"title": "Systematic Analysis of the PMBM, PHD, JPDA and GNN Multi-Target Tracking Filters", "abstract": "Multiple-target tracking has increasingly gained attention over the last 60 years, with the data association task being one of the most challenging aspects in sensor data fusion due to its computational burden. Hence, a plethora of algorithms has been proposed to solve this data association problem. However, most approaches are solely evaluated in comparison to algorithms of the same class. Therefore, this paper tries to give an overview and intends to evaluate systematically the four main classes of multiple-target tracking filters, namely the non-Bayesian data association filters, the Bayesian data association filters, the intensity filters and the multi-Bernoulli filters. These four classes are exemplified by respective filters, namely the Global Nearest Neighbor filter, the Joint Probabilistic Data Association filter, the Probability Hypothesis Density filter and the Poisson multi-Bernoulli mixture filter. These four filters are evaluated on two challenging simulated scenarios comprising situations with false measurements as well as birth and death of targets. The performance is assessed using the well-established GOSPA metric. It is shown that the Poisson multi-Bernoulli mixture filter outperforms the other three filters regarding the GOSPA metric in these scenarios, yielding a smaller mean error and deviation in its position estimates. This accuracy comes at the cost of a higher runtime performance, as the other three filter types require less computational time to produce their state estimates."}}
{"id": "GlfRc6jqXU", "cdate": 1546300800000, "mdate": 1681690154380, "content": {"title": "6DoF Pose-Estimation Pipeline for Texture-less Industrial Components in Bin Picking Applications", "abstract": "Over the next few years, autonomous robots and functionalities are expected to gain increased importance for the shop floor. Perception and the derivation of autonomous behavior is of crucial importance in this context. We present a combined object recognition and pose estimation pipeline to generate pose estimates with six degrees of freedom (6DoF) for bin picking, specifically targeting the suitability for challenging scenarios with texture-less, metallic parts in industrial environments. The pipeline is based on open source algorithms, combining Convolutional Neural Networks (CNNs) and feature-matching methods to create an effective 6DoF pose estimate. We evaluate our approach on several industrial components using a articulated arm robot to guarantee a high level of comparability during the different measurement runs. We further quantify the results using known error metrics for pose estimation, compare the results to established approaches and provide statistical insight into the achieved outcomes to assess the robustness and reliability."}}
{"id": "5H0wn_kdug", "cdate": 1546300800000, "mdate": 1681690154576, "content": {"title": "Neural Network Aided Potential Field Approach For Pedestrian Prediction", "abstract": "Autonomous driving is one of the key challenges in recent time. As pedestrians are the most vulnerable traffic participants, collisions with pedestrians have to be avoided under all circumstances. Hence, prediction of pedestrian trajectories is of high interest for automated vehicles. For this purpose, a plethora of algorithms has been proposed to model the pedestrian in the last decades, reaching from simple kinematic models to advanced microscopic models. In addition, the machine learning community started to learn the behavior of pedestrians and showed major improvements in complex scenarios or unexpected situations. However, as most of the machine learning algorithms are treated as black boxes, the safeguarding of the software is one key challenge which has to be solved. This contribution proposes to combine classic modeling of pedestrians with machine learning algorithms by learning the model errors between a simple physical model and real data. In particular, it is proposed to combine a physical model based on potential fields with a neural network to predict the future behavior of pedestrians. It is shown that the combined approach outperforms the physical model in learnable areas, whereas the physical model without the neural network is more robust in areas where almost no training data is available. In addition, different structures of neural networks are analyzed."}}
{"id": "-bu764hcrp", "cdate": 1546300800000, "mdate": 1681690154393, "content": {"title": "Efficient Localization Using Radio-Based Sensors and Odometry", "abstract": "One of the most important and diverse topics of the modern research landscape is Industry 4.0. Apart from tasks like management of energy or flexible production processes, autonomous industrial robots play a crucial role in this context. Because of the lacking accuracy of global navigation systems in indoor environments, other radio-based methods are required for indoor localization. In this paper, we present a cost-efficient approach that fuses the data of established sensors of autonomous robots with a radio-based method. Signal strength measurements are used for Direction of Arrival estimation, yielding the advantage that no prior information about the environment is required for localizing the object in contrast to the widespread Fingerprinting. The radio-based concept is supported in this work by odometry measurements of the mobile platform. By fusing these information, the concept of a low-cost and powerful localization method is introduced. To allow for an efficient fusion concept, we perform a detailed stochastic characterization of all utilized sensors and motion models. The potential of the localization approach is validated by various differing simulation scenarios and real life measurements."}}
{"id": "eaul6DcERV", "cdate": 1514764800000, "mdate": 1681690154405, "content": {"title": "Entropy-Based Intention Change Detection with a Multi-Hypotheses Filter", "abstract": "In the future, pedestrians and fully automated vehicles have to operate in an environment they share. To minimize the risk for pedestrians, it is very important to predict precisely their future movement. One important information source is the intention of the pedestrian. For the integration of the intention information, a Multi-Hypotheses filter is used, where different hypotheses for the intention of the pedestrian are considered. An intention change detector based on the Multi-Hypotheses filter utilizing an entropy-based confidence score is developed. With this contribution, critical real-world situations like a pedestrian crossing the street instead of following the sidewalk are tackled. The evaluation of the intention change detector is performed in simulation and for real-world data. Firstly, the proposed approach is evaluated using simulated trajectory data, where trajectories with intention changes are generated by a self-made trajectory generator (open source). Secondly, the course of the confidence score is evaluated for a real-world scenario, where the detection of the pedestrians is performed by the combination of a deep learning network (Tiny YOLO) and background subtraction. It is shown that the mean distance into the road from the sidewalk edge at the detection of the intention change is below 1.5 m, even in the case of high sensor noise. For lower sensor noise level, the intention change of the pedestrian is even detected before entering the street. Key contributions are the proposal of the Multi-Hypotheses filter, the derivation of the confidence score, the proposal of the intention detector based on the confidence score and the detection of the pedestrians and other obstacles by the fusion of background subtraction and a deep learning network."}}
