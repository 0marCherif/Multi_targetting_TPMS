{"id": "2JTJF0us4_", "cdate": 1664806786254, "mdate": null, "content": {"title": "Treatment-RSPN: Recurrent Sum-Product Networks for Sequential Treatment Regimes", "abstract": "Sum-product networks (SPNs) have recently emerged as a novel deep learning architecture enabling highly efficient probabilistic inference. Since their introduction, SPNs have been applied to a wide range of data modalities and extended to time-sequence data. In this paper, we propose a general framework for modelling sequential treatment decision-making behaviour and treatment response using recurrent sum-product networks (RSPNs). Models developed using our framework benefit from the full range of RSPN capabilities, including the abilities to model the full distribution of the data, to seamlessly handle latent variables, missing values and categorical data, and to efficiently perform marginal and conditional inference. Our methodology is complemented by a novel variant of the expectation-maximization algorithm for RSPNs, enabling efficient training of our models. We evaluate our approach on a synthetic dataset as well as real-world data from the MIMIC-IV intensive care unit medical database. Our evaluation demonstrates that our approach can closely match the ground-truth data generation process on synthetic data and achieve results close to neural and probabilistic baselines while using a tractable and interpretable model."}}
{"id": "j0Hum1fUjvTp", "cdate": 1621629190654, "mdate": null, "content": {"title": "Discrepancy Ratio: Evaluating Model Performance When Even Experts Disagree on the Truth", "abstract": "In most machine learning tasks unambiguous ground truth labels can easily be acquired. However, this luxury is often not afforded to many high-stakes, real-world scenarios such as medical image interpretation, where even expert human annotators typically exhibit very high levels of disagreement with one another. While prior works have focused on overcoming noisy labels during training, the question of how to evaluate models when annotators disagree about ground truth has remained largely unexplored. To address this, we propose the discrepancy ratio: a novel, task-independent and principled framework for validating machine learning models in the presence of high label noise. Conceptually, our approach evaluates a model by comparing its predictions to those of human annotators, taking into account the degree to which annotators disagree with one another. While our approach is entirely general, we show that in the special case of binary classification, our proposed metric can be evaluated in terms of simple, closed-form expressions that depend only on aggregate statistics of the labels and not on any individual label. Finally, we demonstrate how this framework can be used effectively to validate machine learning models using two real-world tasks from medical imaging. The discrepancy ratio metric reveals what conventional metrics do not: that our models not only vastly exceed the average human performance, but even exceed the performance of the best human experts in our datasets."}}
{"id": "BybgNKWOWB", "cdate": 1514764800000, "mdate": null, "content": {"title": "ExplainGAN: Model Explanation via Decision Boundary Crossing Transformations", "abstract": "We introduce a new method for interpreting computer vision models: visually perceptible, decision-boundary crossing transformations. Our goal is to answer a simple question: why did a model classify an image as being of class A instead of class B? Existing approaches to model interpretation, including saliency and explanation-by-nearest neighbor, fail to visually illustrate examples of transformations required for a specific input to alter a model\u2019s prediction. On the other hand, algorithms for creating decision-boundary crossing transformations (e.g., adversarial examples) produce differences that are visually imperceptible and do not enable insightful explanation. To address this we introduce ExplainGAN, a generative model that produces visually perceptible decision-boundary crossing transformations. These transformations provide high-level conceptual insights which illustrate how a model makes decisions. We validate our model using both traditional quantitative interpretation metrics and introduce a new validation scheme for our approach and generative models more generally."}}
{"id": "HJZWIPbOWH", "cdate": 1451606400000, "mdate": null, "content": {"title": "Hierarchical Deep Reinforcement Learning: Integrating Temporal Abstraction and Intrinsic Motivation", "abstract": "title> <meta name=\"citation_title\" content=\"Hierarchical Deep Reinforcement Learning: Integrating Temporal Abstraction and Intrinsic Motivation\" /> <meta name=\"citation_author\" content=\"Kulkarni, Tejas D.\" /> <meta name=\"citation_author\" content=\"Narasimhan, Karthik\" /> <meta name=\"citation_author\" content=\"Saeedi, Ardavan\" /> <meta name=\"citation_author\" content=\"Tenenbaum, Josh\" /> <meta name=\"citation_journal_title\" content=\"Advances in Neural Information Processing Systems\" /> <meta name=\"citation_volume\" content=\"29\" /> <meta name=\"citation_pdf_url\" content=\"https://proceedings.neurips.cc/paper/2016/file/f442d33fa06832082290ad8544a8da27-Paper.pdf\" /> <meta name=\"citation_publication_date\" content=\"2016\" /><!-- Bootstrap CSS --> <!-- https://codepen.io/surjithctly/pen/PJqKzQ --> <link rel=\"stylesheet\" href=\"https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css\" integrity=\"sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh\" crossorigin=\"anonymous\" /> <link href=\"/static/menus/css/menus.css\" rel=\"stylesheet\" id=\"bootstrap-css\" /> <link rel=\"stylesheet\" href=\"https://use.fontawesome.com/releases/v5.8.1/css/all.css\" integrity=\"sha384-50oBUHEmvpQ+1lW4y57PTFmhCaXp0ML5d60M1M7uH2+nqUivzIebhndOJK28anvf\" crossorigin=\"anonymous\" /> <script type=\"text/javascript\" async=\"async\" src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-MML-AM_CHTML\"></script> <script type=\"text/x-mathjax-config\"> <![CDATA[ MathJax.Hub.Config({ \"tex2jax\": { \"inlineMath\": [[\"$\",\"$\"], [\"\\\\(\",\"\\\\)\"]], \"displayMath\": [[\"\\\\[\",\"\\\\]\"]], \"processEscapes\": true } } ); ]]> </script> <style> <![CDATA[ @media (prefers-color-scheme: dark) { body { background-color: #333; color: #eee; } } .btn-spacer { margin: 2px; } .footer { position: fixed; left: 0; bottom: 0; width: 100%; background-color: #eee; color: black; } ]]> </style> <nav class=\"navbar navbar-expand-md navbar-light bg-light\"> <button class=\"navbar-toggler\" type=\"button\" data-toggle=\"collapse\" data-target=\"#navbarToggler6\" aria-controls=\"navbarToggler6\" aria-expanded=\"false\" aria-label=\"Toggle navigation\"><span class=\"navbar-toggler-icon\"></span></button> <div class=\"collapse navbar-collapse\" id=\"navbarToggler6\"> <a class=\"navbar-brand\" href=\"/\">NeurIPS Proceedings</a> <ul class=\"navbar-nav mr-auto mt-2 mt-md-0\"> <li class=\"nav-item\"> <a class=\"nav-link\" href=\"/admin/login/?next=/admin/\"><i class=\"fas fa-sign-in-alt\" title=\"Login\"></i></a> <li class=\"nav-item\"> <a class=\"nav-link\" href=\"/admin/logout/?nextp=/admin\"><i class=\"fas fa-sign-out-alt\" title=\"Logout\"></i></a> <form class=\"form-inline my-2 my-lg-0\" method=\"get\" role=\"search\" action=\"/papers/search\"> <input class=\"form-control mr-sm-2\" type=\"text\" name=\"q\" placeholder=\"Search\" aria-label=\"Search\" id=\"navsearch\" /> <button class=\"btn btn-outline-success my-2 my-sm-0\" type=\"submit\">Search</button>"}}
{"id": "H1-X1n-_Zr", "cdate": 1451606400000, "mdate": null, "content": {"title": "The Segmented iHMM: A Simple, Efficient Hierarchical Infinite HMM", "abstract": "We propose the segmented iHMM (siHMM), a hierarchical infinite hidden Markov model (iHMM) that supports a simple, efficient inference scheme. The siHMM is well suited to segmentation problems, wher..."}}
{"id": "BJWoqolO-B", "cdate": 1451606400000, "mdate": null, "content": {"title": "Nonparametric Spherical Topic Modeling with Word Embeddings", "abstract": "Traditional topic models do not account for semantic regularities in language. Recent distributional representations of words exhibit semantic consistency over directional metrics such as cosine similarity. However, neither categorical nor Gaussian observational distributions used in existing topic models are appropriate to leverage such correlations. In this paper, we propose to use the von Mises-Fisher distribution to model the density of words over a unit sphere. Such a representation is well-suited for directional data. We use a Hierarchical Dirichlet Process for our base topic model and propose an efficient inference algorithm based on Stochastic Variational Inference. This model enables us to naturally exploit the semantic structures of word embeddings while flexibly discovering the number of topics. Experiments demonstrate that our method outperforms competitive approaches in terms of topic coherence on two different text corpora while offering efficient inference."}}
{"id": "SkbpksWdWr", "cdate": 1420070400000, "mdate": null, "content": {"title": "JUMP-Means: Small-Variance Asymptotics for Markov Jump Processes", "abstract": "Markov jump processes (MJPs) are used to model a wide range of phenomenon from disease progression to RNA path folding. However, existing methods suffer from a number of shortcomings: degenerate tr..."}}
{"id": "HkbMEdWdZS", "cdate": 1293840000000, "mdate": null, "content": {"title": "Priors over Recurrent Continuous Time Processes", "abstract": "We introduce the Gamma-Exponential Process (GEP), a prior over a large family of continuous time stochastic processes. A hierarchical version of this prior (HGEP; the Hierarchical GEP) yields a useful model for analyzing complex time series. Models based on HGEPs display many attractive properties: conjugacy, exchangeability and closed-form predictive distribution for the waiting times, and exact Gibbs updates for the time scale parameters. After establishing these properties, we show how posterior inference can be carried efficiently using Particle MCMC methods [1]. This yields a MCMC algorithm that can resample entire sequences atomically while avoiding the complications of introducing slice and stick auxiliary variables of the beam sampler [2]. We applied our model to the problem of estimating the disease progression in multiple sclerosis [3], and to RNA evolutionary modeling [4]. In both domains, we found that our model outperformed the standard rate matrix estimation approach."}}
