{"id": "Cx9B85IlEVR", "cdate": 1681945075922, "mdate": null, "content": {"title": "CausalBench Challenge: Differences in Mean Expression", "abstract": "In this write-up, we describe our solution to the 2023 CausalBench Challenge. We describe our approaches to preprocessing the data, parameterizations of DCDI and GRNBoost, and modifications to the baseline algorithms."}}
{"id": "iNN14u6FHV7", "cdate": 1599925863539, "mdate": null, "content": {"title": "Learning to Crawl", "abstract": "Web crawling is the problem of keeping a cache of webpages fresh, i.e., having the most recent copy available when a page is requested. This problem is usually coupled with the natural restriction that the bandwidth available to the web crawler is limited. The corresponding optimization problem was solved optimally by Azar et al. [2018] under the assumption that, for each webpage, both the elapsed time between two changes and the elapsed time between two requests follow a Poisson distribution with known parameters. In this paper, we study the same control problem but under the assumption that the change rates are unknown a priori, and thus we need to estimate them in an online fashion using only partial observations (i.e., single-bit signals indicating whether the page has changed since the last refresh). As a point of departure, we characterise the conditions under which one can solve the problem with such partial observability. Next, we propose a practical estimator and compute confidence intervals for it in terms of the elapsed time between the observations. Finally, we show that the explore-and-commit algorithm achieves an \ue23b(T\u203e\u203e\u221a) regret with a carefully chosen exploration horizon. Our simulation study shows that our online policy scales well and achieves close to optimal performance for a wide range of the parameters."}}
{"id": "l-KKCzgp_1i", "cdate": 1577836800000, "mdate": null, "content": {"title": "Scale-invariant unconstrained online learning", "abstract": "We consider an online supervised learning problem, in which both the instances (input vectors) and the comparator (weight vector) are unconstrained. We exploit a natural scale invariance symmetry in our unconstrained setting: the predictions of the optimal comparator are invariant under any linear transformation of the instances. Our goal is to design online algorithms which also enjoy this property, i.e. are scale-invariant. We start with the case of coordinate-wise invariance, in which the individual coordinates (features) can be arbitrarily rescaled. We give an algorithm, which achieves essentially optimal regret bound in this setup, expressed by means of a coordinate-wise scale-invariant norm of the comparator. We then study general invariance with respect to arbitrary linear transformations. We first give a negative result, showing that no algorithm can achieve a meaningful bound in terms of scale-invariant norm of the comparator in the worst case. Next, we compliment this result with a positive one, providing an algorithm which \u201calmost\u201d achieves the desired bound, incurring only a logarithmic overhead in terms of the relative size of the instances. Previous article in issue Next article in issue"}}
{"id": "k7P258ooJSD", "cdate": 1546300800000, "mdate": null, "content": {"title": "Learning to Crawl", "abstract": "Web crawling is the problem of keeping a cache of webpages fresh, i.e., having the most recent copy available when a page is requested. This problem is usually coupled with the natural restriction that the bandwidth available to the web crawler is limited. The corresponding optimization problem was solved optimally by Azar et al. [2018] under the assumption that, for each webpage, both the elapsed time between two changes and the elapsed time between two requests follow a Poisson distribution with known parameters. In this paper, we study the same control problem but under the assumption that the change rates are unknown a priori, and thus we need to estimate them in an online fashion using only partial observations (i.e., single-bit signals indicating whether the page has changed since the last refresh). As a point of departure, we characterise the conditions under which one can solve the problem with such partial observability. Next, we propose a practical estimator and compute confidence intervals for it in terms of the elapsed time between the observations. Finally, we show that the explore-and-commit algorithm achieves an $\\mathcal{O}(\\sqrt{T})$ regret with a carefully chosen exploration horizon. Our simulation study shows that our online policy scales well and achieves close to optimal performance for a wide range of the parameters."}}
{"id": "HkZfKo-Obr", "cdate": 1546300800000, "mdate": null, "content": {"title": "Adaptive Scale-Invariant Online Algorithms for Learning Linear Models", "abstract": "We consider online learning with linear models, where the algorithm predicts on sequentially revealed instances (feature vectors), and is compared against the best linear function (comparator) in h..."}}
{"id": "pv0lAwbnfK", "cdate": 1514764800000, "mdate": null, "content": {"title": "Online Principal Component Analysis for Evolving Data Streams", "abstract": "We consider an online version of the Principal Component Analysis (PCA), where the goal is to keep track of a subspace of small dimension which captures most of the variance of the data arriving sequentially in a stream. We assume the data stream is evolving and hence the target subspace is changing over time. We cast this problem as a prediction problem, where the goal is to minimize the total compression loss on the data sequence. We review the most popular methods for online PCA and show that the state-of-the-art IPCA algorithm is unable to track the best subspace in this setting. We then propose two modifications of this algorithm, and show that they exhibit a much better predictive performance than the original version of IPCA. Our algorithms are compared against other popular method for online PCA in a computational experiment on real data sets from computer vision."}}
{"id": "O1D0xg5sKU", "cdate": 1514764800000, "mdate": null, "content": {"title": "The Many Faces of Exponential Weights in Online Learning", "abstract": "A standard introduction to online learning might place Online Gradient Descent at its center and then proceed to develop generalizations and extensions like Online Mirror Descent and second-order m..."}}
{"id": "BPpWcJWRVGC", "cdate": 1514764800000, "mdate": null, "content": {"title": "On minimaxity of Follow the Leader strategy in the stochastic setting", "abstract": "We consider the setting of prediction with expert advice with an additional assumption that each expert generates its losses i.i.d. according to some distribution. We first identify a class of \u201cadmissible\u201d strategies, which we call permutation invariant, and show that every strategy outside this class will perform not better than some permutation invariant strategy. We then show that when the losses are binary, a simple Follow the Leader (FL) algorithm is the minimax strategy for this game, where minimaxity is simultaneously achieved for the expected regret, the pseudo-regret, and the excess risk. Furthermore, FL has also the smallest regret, pseudo-regret, and excess risk over all permutation invariant prediction strategies, simultaneously for all distributions over binary losses. We generalize these minimax results to the case in which each expert generates its losses from a distribution belonging to a one-dimensional exponential family, as well as to the case of loss vectors generated jointly from a multinomial distribution. We also show that when the losses are in the interval [ 0 , 1 ] and the learner competes against all distributions over [ 0 , 1 ] , FL remains minimax only when an additional trick called \u201closs binarization\u201d is applied."}}
{"id": "sE8c34If3Y8", "cdate": 1483228800000, "mdate": null, "content": {"title": "Scale-invariant unconstrained online learning", "abstract": "We consider a variant of online convex optimization in which both the instances (input vectors) and the comparator (weight vector) are unconstrained. We exploit a natural scale invariance symmetry in our unconstrained setting: the predictions of the optimal comparator are invariant under any linear transformation of the instances. Our goal is to design online algorithms which also enjoy this property, i.e. are scale-invariant. We start with the case of coordinate-wise invariance, in which the individual coordinates (features) can be arbitrarily rescaled. We give an algorithm, which achieves essentially optimal regret bound in this setup, expressed by means of a coordinate-wise scale-invariant norm of the comparator. We then study general invariance with respect to arbitrary linear transformations. We first give a negative result, showing that no algorithm can achieve a meaningful bound in terms of scale-invariant norm of the comparator in the worst case. Next, we compliment this result with a positive one, providing an algorithm which \"almost\" achieves the desired bound, incurring only a logarithmic overhead in terms of the norm of the instances."}}
{"id": "rJWgZOWdZB", "cdate": 1483228800000, "mdate": null, "content": {"title": "Random Permutation Online Isotonic Regression", "abstract": "We revisit isotonic regression on linear orders, the problem of fitting monotonic functions to best explain the data, in an online setting. It was previously shown that online isotonic regression is unlearnable in a fully adversarial model, which lead to its study in the fixed design model. Here, we instead develop the more practical random permutation model. We show that the regret is bounded above by the excess leave-one-out loss for which we develop efficient algorithms and matching lower bounds. We also analyze the class of simple and popular forward algorithms and recommend where to look for algorithms for online isotonic regression on partial orders."}}
