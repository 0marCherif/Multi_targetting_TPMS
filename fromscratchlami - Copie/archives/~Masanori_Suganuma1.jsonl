{"id": "-zrjDz1PYE1", "cdate": 1699783068162, "mdate": 1699783068162, "content": {"title": "Unsupervised domain adaptation for semantic segmentation via cross-region alignment", "abstract": "Semantic segmentation requires a lot of training data, which necessitates costly annotation. There have been many studies on unsupervised domain adaptation (UDA) from one domain to another, e.g., from computer graphics to real images. However, there is still a gap in accuracy between UDA and supervised training on native domain data. It is arguably attributable to the class-level misalignment between the source and target domain data. To cope with this, we propose a method that applies adversarial training to align two feature distributions in the target domain. It uses a self-training framework to split the image into two regions (i.e., trusted and untrusted), which form two distributions to align in the feature space. We term this approach cross-region adaptation (CRA) to distinguish it from the previous methods of aligning different domain distributions, which we call cross-domain adaptation (CDA). CRA can be applied after any CDA method. Experimental results show that this always improves the accuracy of the combined CDA method."}}
{"id": "verb-lPsJp7", "cdate": 1672531200000, "mdate": 1699165888725, "content": {"title": "Visual Abductive Reasoning Meets Driving Hazard Prediction: Problem Formulation and Dataset", "abstract": "This paper addresses the problem of predicting hazards that drivers may encounter while driving a car. We formulate it as a task of anticipating impending accidents using a single input image captured by car dashcams. Unlike existing approaches to driving hazard prediction that rely on computational simulations or anomaly detection from videos, this study focuses on high-level inference from static images. The problem needs predicting and reasoning about future events based on uncertain observations, which falls under visual abductive reasoning. To enable research in this understudied area, a new dataset named the DHPR (Driving Hazard Prediction and Reasoning) dataset is created. The dataset consists of 15K dashcam images of street scenes, and each image is associated with a tuple containing car speed, a hypothesized hazard description, and visual entities present in the scene. These are annotated by human annotators, who identify risky scenes and provide descriptions of potential accidents that could occur a few seconds later. We present several baseline methods and evaluate their performance on our dataset, identifying remaining issues and discussing future directions. This study contributes to the field by introducing a novel problem formulation and dataset, enabling researchers to explore the potential of multi-modal AI for driving hazard prediction."}}
{"id": "o7xOK0bQgk", "cdate": 1672531200000, "mdate": 1704099130877, "content": {"title": "SBCFormer: Lightweight Network Capable of Full-size ImageNet Classification at 1 FPS on Single Board Computers", "abstract": "Computer vision has become increasingly prevalent in solving real-world problems across diverse domains, including smart agriculture, fishery, and livestock management. These applications may not require processing many image frames per second, leading practitioners to use single board computers (SBCs). Although many lightweight networks have been developed for mobile/edge devices, they primarily target smartphones with more powerful processors and not SBCs with the low-end CPUs. This paper introduces a CNN-ViT hybrid network called SBCFormer, which achieves high accuracy and fast computation on such low-end CPUs. The hardware constraints of these CPUs make the Transformer's attention mechanism preferable to convolution. However, using attention on low-end CPUs presents a challenge: high-resolution internal feature maps demand excessive computational resources, but reducing their resolution results in the loss of local image details. SBCFormer introduces an architectural design to address this issue. As a result, SBCFormer achieves the highest trade-off between accuracy and speed on a Raspberry Pi 4 Model B with an ARM-Cortex A72 CPU. For the first time, it achieves an ImageNet-1K top-1 accuracy of around 80% at a speed of 1.0 frame/sec on the SBC. Code is available at https://github.com/xyongLu/SBCFormer."}}
{"id": "nbPLwoEwhvZ", "cdate": 1672531200000, "mdate": 1704099130871, "content": {"title": "Network Pruning and Fine-tuning for Few-shot Industrial Image Anomaly Detection", "abstract": "This paper focuses on industrial image anomaly detection and localization under few-shot settings. Since acquiring sufficient anomalous data is difficult, unsupervised learning that uses only normal data is commonly used, but even obtaining enough anomaly-free training samples can be challenging. Moreover, applying data augmentations, which is a common strategy for few-shot learning to alleviate the lack of data, is limited to use for some industrial product images. To address the above issues, we propose a network pruning and fine-tuning (PF) framework that leverages the knowledge of a deep pre-trained model. Our approach distills the knowledge of normal samples into a pruned student network, followed by fine-tuning to restore its representation ability for normal data. During inference, discrepancies between features extracted by the teacher and student are used to determine the anomaly score. The proposed method could better utilize the strong representation ability of deep models and benefit the student training with limited data by network pruning. Our framework achieves state-of-the-art performance on the MVTec AD benchmark and is not limited to specific network pruning methods."}}
{"id": "lGI8SR7qGkO", "cdate": 1672531200000, "mdate": 1704099130931, "content": {"title": "That's BAD: Blind Anomaly Detection by Implicit Local Feature Clustering", "abstract": "Recent studies on visual anomaly detection (AD) of industrial objects/textures have achieved quite good performance. They consider an unsupervised setting, specifically the one-class setting, in which we assume the availability of a set of normal (\\textit{i.e.}, anomaly-free) images for training. In this paper, we consider a more challenging scenario of unsupervised AD, in which we detect anomalies in a given set of images that might contain both normal and anomalous samples. The setting does not assume the availability of known normal data and thus is completely free from human annotation, which differs from the standard AD considered in recent studies. For clarity, we call the setting blind anomaly detection (BAD). We show that BAD can be converted into a local outlier detection problem and propose a novel method named PatchCluster that can accurately detect image- and pixel-level anomalies. Experimental results show that PatchCluster shows a promising performance without the knowledge of normal data, even comparable to the SOTA methods applied in the one-class setting needing it."}}
{"id": "RUVt-NKL95", "cdate": 1672531200000, "mdate": 1704099103963, "content": {"title": "SBCFormer: Lightweight Network Capable of Full-size ImageNet Classification at 1 FPS on Single Board Computers", "abstract": "Computer vision has become increasingly prevalent in solving real-world problems across diverse domains, including smart agriculture, fishery, and livestock management. These applications may not require processing many image frames per second, leading practitioners to use single board computers (SBCs). Although many lightweight networks have been developed for mobile/edge devices, they primarily target smartphones with more powerful processors and not SBCs with the low-end CPUs. This paper introduces a CNN-ViT hybrid network called SBCFormer, which achieves high accuracy and fast computation on such low-end CPUs. The hardware constraints of these CPUs make the Transformer's attention mechanism preferable to convolution. However, using attention on low-end CPUs presents a challenge: high-resolution internal feature maps demand excessive computational resources, but reducing their resolution results in the loss of local image details. SBCFormer introduces an architectural design to address this issue. As a result, SBCFormer achieves the highest trade-off between accuracy and speed on a Raspberry Pi 4 Model B with an ARM-Cortex A72 CPU. For the first time, it achieves an ImageNet-1K top-1 accuracy of around 80% at a speed of 1.0 frame/sec on the SBC. Code is available at https://github.com/xyongLu/SBCFormer."}}
{"id": "KLAB3cFWwDO", "cdate": 1672531200000, "mdate": 1704099103949, "content": {"title": "Contextual Affinity Distillation for Image Anomaly Detection", "abstract": "Previous works on unsupervised industrial anomaly detection mainly focus on local structural anomalies such as cracks and color contamination. While achieving significantly high detection performance on this kind of anomaly, they are faced with logical anomalies that violate the long-range dependencies such as a normal object placed in the wrong position. In this paper, based on previous knowledge distillation works, we propose to use two students (local and global) to better mimic the teacher's behavior. The local student, which is used in previous studies mainly focuses on structural anomaly detection while the global student pays attention to logical anomalies. To further encourage the global student's learning to capture long-range dependencies, we design the global context condensing block (GCCB) and propose a contextual affinity loss for the student training and anomaly scoring. Experimental results show the proposed method doesn't need cumbersome training techniques and achieves a new state-of-the-art performance on the MVTec LOCO AD dataset."}}
{"id": "HYN_ICsYLj", "cdate": 1672531200000, "mdate": 1704099140592, "content": {"title": "SBCFormer: Lightweight Network Capable of Full-size ImageNet Classification at 1 FPS on Single Board Computers", "abstract": "Computer vision has become increasingly prevalent in solving real-world problems across diverse domains, including smart agriculture, fishery, and livestock management. These applications may not require processing many image frames per second, leading practitioners to use single board computers (SBCs). Although many lightweight networks have been developed for mobile/edge devices, they primarily target smartphones with more powerful processors and not SBCs with the low-end CPUs. This paper introduces a CNN-ViT hybrid network called SBCFormer, which achieves high accuracy and fast computation on such low-end CPUs. The hardware constraints of these CPUs make the Transformer's attention mechanism preferable to convolution. However, using attention on low-end CPUs presents a challenge: high-resolution internal feature maps demand excessive computational resources, but reducing their resolution results in the loss of local image details. SBCFormer introduces an architectural design to address this issue. As a result, SBCFormer achieves the highest trade-off between accuracy and speed on a Raspberry Pi 4 Model B with an ARM-Cortex A72 CPU. For the first time, it achieves an ImageNet-1K top-1 accuracy of around 80% at a speed of 1.0 frame/sec on the SBC. Code is available at https://github.com/xyongLu/SBCFormer."}}
{"id": "Fr2QgFBGbg", "cdate": 1672531200000, "mdate": 1704099130847, "content": {"title": "Contextual Affinity Distillation for Image Anomaly Detection", "abstract": "Previous works on unsupervised industrial anomaly detection mainly focus on local structural anomalies such as cracks and color contamination. While achieving significantly high detection performance on this kind of anomaly, they are faced with logical anomalies that violate the long-range dependencies such as a normal object placed in the wrong position. In this paper, based on previous knowledge distillation works, we propose to use two students (local and global) to better mimic the teacher's behavior. The local student, which is used in previous studies mainly focuses on structural anomaly detection while the global student pays attention to logical anomalies. To further encourage the global student's learning to capture long-range dependencies, we design the global context condensing block (GCCB) and propose a contextual affinity loss for the student training and anomaly scoring. Experimental results show the proposed method doesn't need cumbersome training techniques and achieves a new state-of-the-art performance on the MVTec LOCO AD dataset."}}
{"id": "7aVAjxlrNY", "cdate": 1672531200000, "mdate": 1704099103989, "content": {"title": "Network Pruning and Fine-tuning for Few-shot Industrial Image Anomaly Detection", "abstract": "This paper focuses on industrial image anomaly detection and localization under few-shot settings. Since acquiring sufficient anomalous data is difficult, unsupervised learning that uses only normal data is commonly used, but even obtaining enough anomaly-free training samples can be challenging. Moreover, applying data augmentations, which is a common strategy for few-shot learning to alleviate the lack of data, is limited to use for some industrial product images. To address the above issues, we propose a network pruning and fine-tuning (PF) framework that leverages the knowledge of a deep pre-trained model. Our approach distills the knowledge of normal samples into a pruned student network, followed by fine-tuning to restore its representation ability for normal data. During inference, discrepancies between features extracted by the teacher and student are used to determine the anomaly score. The proposed method could better utilize the strong representation ability of deep models and benefit the student training with limited data by network pruning. Our framework achieves state-of-the-art performance on the MVTec AD benchmark and is not limited to specific network pruning methods."}}
