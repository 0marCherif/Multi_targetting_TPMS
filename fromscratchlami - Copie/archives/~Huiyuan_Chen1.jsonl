{"id": "TkQ1sxd9P4", "cdate": 1663850161683, "mdate": null, "content": {"title": "Interpretable Debiasing of Vectorized Language Representations with Iterative Orthogonalization", "abstract": "We propose a new mechanism to augment a word vector embedding representation that offers improved bias removal while retaining the key information\u2014resulting in improved interpretability of the representation. Rather than removing the information associated with a concept that may induce bias, our proposed method identifies two concept subspaces and makes them orthogonal. The resulting representation has these two concepts uncorrelated. Moreover, because they are orthogonal, one can simply apply a rotation on the basis of the representation so that the resulting subspace corresponds with coordinates. This explicit encoding of concepts to coordinates works because they have been made fully orthogonal, which previous approaches do not achieve. Furthermore, we show that this can be extended to multiple subspaces. As a result, one can choose a subset of concepts to be represented transparently and explicitly, while the others are retained in the mixed but extremely expressive format of the representation."}}
{"id": "uFNRR_taEsq", "cdate": 1640995200000, "mdate": 1655095559371, "content": {"title": "Graph Neural Transport Networks with Non-local Attentions for Recommender Systems", "abstract": "Graph Neural Networks (GNNs) have emerged as powerful tools for collaborative filtering. A key challenge of recommendations is to distill long-range collaborative signals from user-item graphs. Typically, GNNs generate embeddings of users/items by propagating and aggregating the messages between local neighbors. Thus, the ability of GNNs to capture long-range dependencies heavily depends on their depths. However, simply training deep GNNs has several bottleneck effects, e.g., over-fitting & over-smoothing, which may lead to unexpected results if GNNs are not well regularized. Here we present Graph Optimal Transport Networks (GOTNet) to capture long-range dependencies without increasing the depths of GNNs. Specifically, we perform k-Means clustering on nodes\u2019 GNN embeddings to obtain graph-level representations (e.g., centroids). We then compute node-centroid attentions, which enable long-range messages to be communicated among distant but similar nodes. Our non-local attention operators work seamlessly with local operators in original GNNs. As such, GOTNet is able to capture both local and non-local messages in graphs by only using shallow GNNs, which avoids the bottleneck effects of deep GNNs. Experimental results demonstrate that GOTNet achieves better performance compared with state-of-the-art GNNs."}}
{"id": "ZaI7Rd11G4S", "cdate": 1632875424534, "mdate": null, "content": {"title": "Embedding Compression with Hashing for Efficient Representation Learning in Graph", "abstract": "Graph neural networks (GNNs) are deep learning models designed specifically for graph data, and they typically rely on node features as the input node representation to the first layer. When applying such type of networks on graph without node feature, one can extract simple graph-based node features (e.g., number of degrees) or learn the input node representation (i.e., embeddings) when training the network. While the latter approach, which trains node embeddings, more likely leads to better performance, the number of parameters associated with the embeddings grows linearly with the number of nodes. It is therefore impractical to train the input node embeddings together with GNNs within graphics processing unit (GPU) memory in an end-to-end fashion when dealing with industrial scale graph data. Inspired by the embedding compression methods developed for natural language processing (NLP) models, we develop a node embedding compression method where each node is compactly represented with a bit vector instead of a float-point vector. The parameters utilized in the compression method can be trained together with GNNs. We show that the proposed node embedding compression method achieves superior performance compared to the alternatives."}}
{"id": "JlpEzYRuPil", "cdate": 1609459200000, "mdate": 1631052732470, "content": {"title": "Structured Graph Convolutional Networks with Stochastic Masks for Recommender Systems", "abstract": "Graph Convolutional Networks (GCNs) are powerful for collaborative filtering. The key component of GCNs is to explore neighborhood aggregation mechanisms to extract high-level representations of users and items. However, real-world user-item graphs are often incomplete and noisy. Aggregating misleading neighborhood information may lead to sub-optimal performance if GCNs are not regularized properly. Also, the real-world user-item graphs are often sparse and low rank. These two intrinsic graph properties are widely used in shallow matrix completion models, but far less studied in graph neural models. Here we propose Structured Graph Convolutional Networks (SGCNs) to enhance the performance of GCNs by exploiting graph structural properties of sparsity and low rank. To achieve sparsity, we attach each layer of a GCN with a trainable stochastic binary mask to prune noisy and insignificant edges, resulting in a clean and sparsified graph. To preserve its low-rank property, the nuclear norm regularization is applied. We jointly learn the parameters of stochastic binary masks and original GCNs by solving a stochastic binary optimization problem. An unbiased gradient estimator is further proposed to better backpropagate the gradients of binary variables. Experimental results demonstrate that SGCNs achieve better performance compared with the state-of-the-art GCNs."}}
{"id": "J7ESIfxKNFe", "cdate": 1609459200000, "mdate": 1655095559420, "content": {"title": "Tops, Bottoms, and Shoes: Building Capsule Wardrobes via Cross-Attention Tensor Network", "abstract": "Fashion is more than Paris runways. Fashion is about how people express their interests, identity, mood, and cultural influences. Given an inventory of candidate garments from different categories, how to assemble them together would most improve their fashionability? This question presents an intriguing visual recommendation challenge to automatically create capsule wardrobes. Capsule wardrobe generation is a complex combinatorial problem that requires the understanding of how multiple visual items interact. The generative process often needs fashion experts to manually tease the combinations out, making it hard to scale. We introduce TensorNet, an approach that captures the key ingredients of visual compatibility among tops, bottoms, and shoes. TensorNet aims to provide actionable advice for full-body clothing outfits that mix and match well. Our TensorNet consists of two core modules: a Cross-Attention Message Passing module and a Wide&Deep Tensor Interaction module. As such, TensorNet is able to characterize the local region-based patterns as well as the global compatibility of the entire outfits. Our experimental results on the real-word datasets indicate that the proposed method is capable of learning visual compatibility and outperforms all the baselines. TensorNet opens up opportunities for fashion designers to narrow down the search space for multi-clothes combinations."}}
{"id": "BIbMEQ7L8O1", "cdate": 1609459200000, "mdate": 1655095559365, "content": {"title": "Error-bounded Approximate Time Series Joins using Compact Dictionary Representations of Time Series", "abstract": "The matrix profile is an effective data mining tool that provides similarity join functionality for time series data. Users of the matrix profile can either join a time series with itself using intra-similarity join (i.e., self-join) or join a time series with another time series using inter-similarity join. By invoking either or both types of joins, the matrix profile can help users discover both conserved and anomalous structures in the data. Since the introduction of the matrix profile five years ago, multiple efforts have been made to speed up the computation with approximate joins; however, the majority of these efforts only focus on self-joins. In this work, we show that it is possible to efficiently perform approximate inter-time series similarity joins with error bounded guarantees by creating a compact \"dictionary\" representation of time series. Using the dictionary representation instead of the original time series, we are able to improve the throughput of an anomaly mining system by at least 20X, with essentially no decrease in accuracy. As a side effect, the dictionaries also summarize the time series in a semantically meaningful way and can provide intuitive and actionable insights. We demonstrate the utility of our dictionary-based inter-time series similarity joins on domains as diverse as medicine and transportation."}}
{"id": "kESgENqnp7m", "cdate": 1577836800000, "mdate": 1631052732558, "content": {"title": "Neural Tensor Model for Learning Multi-Aspect Factors in Recommender Systems", "abstract": "Recommender systems often involve multi-aspect factors. For example, when shopping for shoes online, consumers usually look through their images, ratings, and product's reviews before making their decisions. To learn multi-aspect factors, many context-aware models have been developed based on tensor factorizations. However, existing models assume multilinear structures in the tensor data, thus failing to capture nonlinear feature interactions. To fill this gap, we propose a novel nonlinear tensor machine, which combines deep neural networks and tensor algebra to capture nonlinear interactions among multi-aspect factors. We further consider adversarial learning to assist the training of our model. Extensive experiments demonstrate the effectiveness of the proposed model."}}
{"id": "KWRd-Q1mE-U", "cdate": 1577836800000, "mdate": 1631052732468, "content": {"title": "Learning Data-Driven Drug-Target-Disease Interaction via Neural Tensor Network", "abstract": "Precise medicine recommendations provide more effective treatments and cause fewer drug side effects. A key step is to understand the mechanistic relationships among drugs, targets, and diseases. Tensor-based models have the ability to explore relationships of drug-target-disease based on large amount of labeled data. However, existing tensor models fail to capture complex nonlinear dependencies among tensor data. In addition, rich medical knowledge are far less studied, which may lead to unsatisfied results. Here we propose a Neural Tensor Network (NeurTN) to assist personalized medicine treatments. NeurTN seamlessly combines tensor algebra and deep neural networks, which offers a more powerful way to capture the nonlinear relationships among drugs, targets, and diseases. To leverage medical knowledge, we augment NeurTN with geometric neural networks to capture the structural information of both drugs\u2019 chemical structures and targets\u2019 sequences. Extensive experiments on real-world datasets demonstrate the effectiveness of the NeurTN model."}}
{"id": "5BTBUCa4vvl", "cdate": 1577836800000, "mdate": 1655095559371, "content": {"title": "iDrug: Integration of drug repositioning and drug-target prediction via cross-network embedding", "abstract": "Author summary Traditional high-throughput techniques for drug discovery are often expensive, time-consuming, and with high failure rates. Computational drug repositioning and drug-target prediction have thus become essential tasks in the early stage drug discovery. The emergence of large-scale heterogeneous biological networks has offered unprecedented opportunities for developing machine learning approaches to identify novel drug-disease or drug-target interactions. However, most existing works focused either on the drug-disease network or on the drug-target network, thus failed to capture the inherent dependencies between these two networks. These two biological networks are naturally connected since they involve the same drug feature space. In our opinion, ignoring this rich source of information is a major shortcoming of some existing works. In this paper, we present a novel approach called iDrug, which seamlessly integrates the drug-disease network and the drug-target network into one coherent model via cross-network embedding. As a result, iDrug is able to take full usage of the knowledge within these two biological networks to better exploit new biomedical insights of drug-target-disease. Therefore, iDrug has broad applications in drug discovery."}}
{"id": "zIZqfPK-cyS", "cdate": 1546300800000, "mdate": 1631052732463, "content": {"title": "Adversarial tensor factorization for context-aware recommendation", "abstract": "Contextual factors such as time, location, or tag, can affect user preferences for a particular item. Context-aware recommendations are thus critical to improve both quality and explainability of recommender systems, compared to traditional recommendations that are solely based on user-item interactions. Tensor factorization machines have achieved the state-of-the-art performance due to their capability of integrating users, items, and contextual factors in one unify way. However, few work has focused on the robustness of a context-aware recommender system. Improving the robustness of a tensor-based model is challenging due to the sparsity of the observed tensor and the multi-linear nature of tensor factorization. In this paper, we propose ATF, a model that combines tensor factorization and adversarial learning for context-aware recommendations. Doing so allows us to reap the benefits of tensor factorization, while enhancing the robustness of a recommender model, and thus improves its eventual performance. Empirical studies on two real-world datasets show that the proposed method outperforms standard tensor-based methods."}}
