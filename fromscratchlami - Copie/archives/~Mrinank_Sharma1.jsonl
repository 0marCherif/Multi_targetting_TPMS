{"id": "HfuFAY9e5oS", "cdate": 1683672077696, "mdate": 1683672077696, "content": {"title": "Mask wearing in community settings reduces SARS-CoV-2 transmission", "abstract": "The effectiveness of mask wearing at controlling severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) transmission has been unclear. While masks are known to substantially reduce disease transmission in healthcare settings [D. K. Chu et al., Lancet 395, 1973\u20131987 (2020); J. Howard et al., Proc. Natl. Acad. Sci. U.S.A. 118, e2014564118 (2021); Y. Cheng et al., Science eabg6296 (2021)], studies in community settings report inconsistent results [H. M. Ollila et al., medRxiv (2020); J. Brainard et al., Eurosurveillance 25, 2000725 (2020); T. Jefferson et al., Cochrane Database Syst. Rev. 11, CD006207 (2020)]. Most such studies focus on how masks impact transmission, by analyzing how effective government mask mandates are. However, we find that widespread voluntary mask wearing, and other data limitations, make mandate effectiveness a poor proxy for mask-wearing effectiveness. We directly analyze the effect of mask wearing on SARS-CoV-2 transmission, drawing on several datasets covering 92 regions on six continents, including the largest survey of wearing behavior (\ud835\udc5b=\n 20 million) [F. Kreuter et al., https://gisumd.github.io/COVID-19-API-Documentation (2020)]. Using a Bayesian hierarchical model, we estimate the effect of mask wearing on transmission, by linking reported wearing levels to reported cases in each region, while adjusting for mobility and nonpharmaceutical interventions (NPIs), such as bans on large gatherings. Our estimates imply that the mean observed level of mask wearing corresponds to a 19% decrease in the reproduction number R. We also assess the robustness of our results in 60 tests spanning 20 sensitivity analyses. In light of these results, policy makers can effectively reduce transmission by intervening to increase mask wearing."}}
{"id": "2JTsK7hlu0p", "cdate": 1683671864393, "mdate": 1683671864393, "content": {"title": "Understanding the effectiveness of government interventions against the resurgence of COVID-19 in Europe", "abstract": "European governments use non-pharmaceutical interventions (NPIs) to control resurging waves of COVID-19. However, they only have outdated estimates for how effective individual NPIs were in the first wave. We estimate the effectiveness of 17 NPIs in Europe\u2019s second wave from subnational case and death data by introducing a flexible hierarchical Bayesian transmission model and collecting the largest dataset of NPI implementation dates across Europe. Business closures, educational institution closures, and gathering bans reduced transmission, but reduced it less than they did in the first wave. This difference is likely due to organisational safety measures and individual protective behaviours\u2014such as distancing\u2014which made various areas of public life safer and thereby reduced the effect of closing them. Specifically, we find smaller effects for closing educational institutions, suggesting that stringent safety measures made schools safer compared to the first wave. Second-wave estimates outperform previous estimates at predicting transmission in Europe\u2019s third wave."}}
{"id": "NLBqU5tEL7T", "cdate": 1672531200000, "mdate": 1681913045999, "content": {"title": "Incorporating Unlabelled Data into Bayesian Neural Networks", "abstract": "Conventional Bayesian Neural Networks (BNNs) cannot leverage unlabelled data to improve their predictions. To overcome this limitation, we introduce Self-Supervised Bayesian Neural Networks, which use unlabelled data to learn improved prior predictive distributions by maximising an evidence lower bound during an unsupervised pre-training step. With a novel methodology developed to better understand prior predictive distributions, we then show that self-supervised prior predictives capture image semantics better than conventional BNN priors. In our empirical evaluations, we see that self-supervised BNNs offer the label efficiency of self-supervised methods and the uncertainty estimates of Bayesian methods, particularly outperforming conventional BNNs in low-to-medium data regimes."}}
{"id": "zuDV3xQXXL", "cdate": 1640995200000, "mdate": 1681913045989, "content": {"title": "Do Bayesian Neural Networks Need To Be Fully Stochastic?", "abstract": "We investigate the benefit of treating all the parameters in a Bayesian neural network stochastically and find compelling theoretical and empirical evidence that this standard construction may be unnecessary. To this end, we prove that expressive predictive distributions require only small amounts of stochasticity. In particular, partially stochastic networks with only $n$ stochastic biases are universal probabilistic predictors for $n$-dimensional predictive problems. In empirical investigations, we find no systematic benefit of full stochasticity across four different inference modalities and eight datasets; partially stochastic networks can match and sometimes even outperform fully stochastic networks, despite their reduced memory costs."}}
{"id": "dDwyNMuNdw", "cdate": 1640995200000, "mdate": 1681913045867, "content": {"title": "Prioritized Training on Points that are Learnable, Worth Learning, and Not Yet Learnt", "abstract": "Training on web-scale data can take months. But most computation and time is wasted on redundant and noisy points that are already learnt or not learnable. To accelerate training, we introduce Reducible Holdout Loss Selection (RHO-LOSS), a simple but principled technique which selects approximately those points for training that most reduce the model's generalization loss. As a result, RHO-LOSS mitigates the weaknesses of existing data selection methods: techniques from the optimization literature typically select 'hard' (e.g. high loss) points, but such points are often noisy (not learnable) or less task-relevant. Conversely, curriculum learning prioritizes 'easy' points, but such points need not be trained on once learned. In contrast, RHO-LOSS selects points that are learnable, worth learning, and not yet learnt. RHO-LOSS trains in far fewer steps than prior art, improves accuracy, and speeds up training on a wide range of datasets, hyperparameters, and architectures (MLPs, CNNs, and BERT). On the large web-scraped image dataset Clothing-1M, RHO-LOSS trains in 18x fewer steps and reaches 2% higher final accuracy than uniform data shuffling."}}
{"id": "_0BuLNlLGH5", "cdate": 1640995200000, "mdate": 1681913046007, "content": {"title": "Seasonal variation in SARS-CoV-2 transmission in temperate climates: A Bayesian modelling study in 143 European regions", "abstract": "Author Summary Building on two state-of-the-art observational models and datasets, we adapt a fully Bayesian method for estimating the association between seasonality and SARS-CoV-2 transmission in 143 temperate European regions. This approach overcomes limitations of previous analyses that do not account for the implementation of non-pharmaceutical interventions (NPIs) or mobility during the first year of the pandemic and hence may yield biased estimates of seasonal effects. We find that the seasonality of SARS-CoV-2 transmission is comparable in magnitude to the most effective individual NPIs but less than the combined effect of multiple interventions. Our findings provide valuable insights for long-term modelling and policy planning. As seasons change, it is vital that policymakers employ accurate estimates of seasonal effects. In the summer, reductions in transmission that owe to seasonality should not be misattributed to population immunity. In the winter, policymakers must avoid anticipating a greater reduction due to seasonality than will actually occur."}}
{"id": "L_MkT-TgTS", "cdate": 1640995200000, "mdate": 1681913045825, "content": {"title": "Prioritized Training on Points that are Learnable, Worth Learning, and not yet Learnt", "abstract": "Training on web-scale data can take months. But much computation and time is wasted on redundant and noisy points that are already learnt or not learnable. To accelerate training, we introduce Redu..."}}
{"id": "Y0cGpgUhSvp", "cdate": 1632875496469, "mdate": null, "content": {"title": "Prioritized training on points that are learnable, worth learning, and not yet learned", "abstract": "We introduce reducible held-out loss selection (RHOLS), a technique for faster model training which selects a sequence of training points that are \u201cjust right\u201d. We propose a tractable information-theoretic acquisition function\u2014the reducible heldout loss\u2014to efficiently choose training points that maximize information about a holdout set. We show that the \u201chard\u201d (e.g. high loss) points usually selected in the optimization literature are typically noisy, leading to deterioration on real-world datasets. At the same time, \u201ceasy\u201d (e.g. low noise) samples, often prioritized for curriculum learning, confer less information. In contrast, RHOLS chooses points that are \u201cjust right\u201d and trains in fewer steps than the above approaches."}}
{"id": "aNTx3gdgBFL", "cdate": 1609459200000, "mdate": 1627120341103, "content": {"title": "Prioritized training on points that are learnable, worth learning, and not yet learned", "abstract": "We introduce Goldilocks Selection, a technique for faster model training which selects a sequence of training points that are \"just right\". We propose an information-theoretic acquisition function -- the reducible validation loss -- and compute it with a small proxy model -- GoldiProx -- to efficiently choose training points that maximize information about a validation set. We show that the \"hard\" (e.g. high loss) points usually selected in the optimization literature are typically noisy, while the \"easy\" (e.g. low noise) samples often prioritized for curriculum learning confer less information. Further, points with uncertain labels, typically targeted by active learning, tend to be less relevant to the task. In contrast, Goldilocks Selection chooses points that are \"just right\" and empirically outperforms the above approaches. Moreover, the selected sequence can transfer to other architectures; practitioners can share and reuse it without the need to recreate it."}}
{"id": "l36YoST4D0", "cdate": 1577836800000, "mdate": null, "content": {"title": "How Robust are the Estimated Effects of Nonpharmaceutical Interventions against COVID-19?", "abstract": "To what extent are effectiveness estimates of nonpharmaceutical interventions (NPIs) against COVID-19 influenced by the assumptions our models make? To answer this question, we investigate 2 state-of-the-art NPI effectiveness models and propose 6 variants that make different structural assumptions. In particular, we investigate how well NPI effectiveness estimates generalise to unseen countries, and their sensitivity to unobserved factors. Models which account for noise in disease transmission compare favourably. We further evaluate how robust estimates are to different choices of epidemiological parameters and data. Focusing on models that assume transmission noise, we find that previously published results are robust across these choices and across different models. Finally, we mathematically ground the interpretation of NPI effectiveness estimates when certain common assumptions do not hold."}}
