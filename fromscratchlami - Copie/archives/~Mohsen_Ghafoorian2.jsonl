{"id": "fKkA94ojP2c", "cdate": 1698859171659, "mdate": 1698859171659, "content": {"title": "PVP: Personalized Video Prior for Editable Dynamic Portraits using StyleGAN", "abstract": "Portrait synthesis creates realistic digital avatars which enable users to interact with others in a compelling way. Recent advances in StyleGAN and its extensions have shown promising results in synthesizing photorealistic and accurate reconstruction of human faces. However, previous methods often focus on frontal face synthesis and most methods are not able to handle large head rotations due to the training data distribution of StyleGAN. In this work, our goal is to take as input a monocular video of a face, and create an editable dynamic portrait able to handle extreme head poses. The user can create novel viewpoints, edit the appearance, and animate the face. Our method utilizes pivotal tuning inversion (PTI) to learn a personalized video prior from a monocular video sequence. Then we can input pose and expression coefficients to MLPs and manipulate the latent vectors to synthesize different viewpoints and expressions of the subject. We also propose novel loss functions to further disentangle pose and expression in the latent space. Our algorithm shows much better performance over previous approaches on monocular video datasets, and it is also capable of running in real-time at 54 FPS on an RTX 3080."}}
{"id": "qJ1WhWzCi8", "cdate": 1620407049963, "mdate": null, "content": {"title": "Gambling Adversarial Nets for Hard Sample Mining and Structured Prediction: Application in Ultrasound Thyroid Nodule Segmentation", "abstract": "Most real-world datasets are characterized by long-tail distributions over classes or, more generally, over underlying visual representations. Consequently, not all samples contribute equally to the training of a model, and therefore, methods properly evaluating the importance/difficulty of the samples can considerably improve the training efficiency and effectivity. Moreover, preserving certain inter-pixel/voxel structural qualities and consistencies in the dense predictions of semantic\nsegmentation models is often highly desirable; accordingly, a recent trend of using adversarial training is clearly observable in the literature that aims for achieving higher-level structural qualities. However, as we argue and show, the common formulation of adversarial training for semantic segmentation is ill-posed, sub-optimal, and may result in side-effects, such as the disability to express uncertainties.\nIn this paper, we suggest using recently introduced Gambling Adversarial Networks that revise the conventional adversarial training for semantic segmentation, by reformulating the fake/real discrimination task into a correct/wrong distinction. This forms then a more effective training strategy that simultaneously serves for both hard sample mining as well as structured prediction. Applying the gambling networks to the ultrasound thyroid nodule segmentation task, the new adversarial training dynamics consistently improve the qualities of the predictions shown over different state-of-the-art semantic segmentation architectures and various metrics."}}
{"id": "hlZR6hwJYqa", "cdate": 1620406913072, "mdate": null, "content": {"title": "Find it if You Can: End-to-End Adversarial Erasing for Weakly-Supervised Semantic Segmentation", "abstract": "Semantic segmentation is a task that traditionally requires a large dataset of pixel-level ground truth labels, which is\ntime-consuming and expensive to obtain. Recent advancements in the weakly-supervised setting show that reasonable performance can be obtained by using only image-level labels. Classification is often used as a proxy task to train a deep neural network from which attention maps are extracted. However, the classification task needs only the minimum evidence to make predictions, hence it focuses on the most discriminative object regions. To overcome this problem, we propose a novel formulation of adversarial erasing of the attention maps. In contrast to previous adversarial\nerasing methods, we optimize two networks with opposing loss functions, which eliminates the requirement of certain\nsuboptimal strategies; for instance, having multiple training steps that complicate the training process or a weight sharing policy between networks operating on different distributions that might be suboptimal for performance. The proposed solution does not require saliency masks, instead, it uses a regularization loss to prevent the attention maps\nfrom spreading to less discriminative object regions. Our experiments on the Pascal VOC dataset demonstrate that our adversarial approach increases segmentation performance by 2.1 mIoU compared to our baseline and by 1.0 mIoU compared to previous adversarial erasing approaches."}}
{"id": "6UaRAEbQrSr", "cdate": 1599641110773, "mdate": null, "content": {"title": "EL-GAN: Embedding Loss Driven Generative Adversarial Networks for Lane Detection", "abstract": "Convolutional neural networks have been successfully applied to semantic segmentation problems. However, there are many problems that are inherently not pixel-wise classification problems but are nevertheless frequently formulated as semantic segmentation. This illposed formulation consequently necessitates hand-crafted scenario-specific and computationally expensive post-processing methods to convert the per pixel probability maps to final desired outputs. Generative adversarial networks (GANs) can be used to make the semantic segmentation network output to be more realistic or better structure-preserving, decreasing the dependency on potentially complex post-processing.\nIn this work, we propose EL-GAN: a GAN framework to mitigate the discussed problem using an embedding loss. With EL-GAN, we discriminate based on learned embeddings of both the labels and the prediction at the same time. This results in much more stable training due to having better discriminative information, benefiting from seeing both \u2018fake\u2019 and \u2018real\u2019 predictions at the same time. This substantially stabilizes the adversarial training process. We use the TuSimple lane marking challenge to demonstrate that with our proposed framework it is viable to overcome the inherent anomalies of posing it as a semantic segmentation problem. Not only is the output considerably more similar to the labels when compared to conventional methods, the subsequent post-processing is also simpler and crosses the competitive 96% accuracy threshold."}}
{"id": "9M94Bw6SfO", "cdate": 1583668354670, "mdate": null, "content": {"title": "I Bet You Are Wrong: Gambling Adversarial Networks for Structured Semantic Segmentation", "abstract": "Adversarial training has been recently employed for realizing structured semantic segmentation, in which the aim is to preserve higher-level scene structural consistencies in dense predictions. However, as we show, value-based discrimination between the predictions from the segmentation network and ground-truth annotations can hinder the training process from learning to improve structural qualities as well as disabling the network from properly expressing uncertainties. In this paper, we rethink adversarial training for semantic segmentation and propose to formulate the fake/real discrimination framework with a correct/incorrect training objective. More specifically, we replace the discriminator with a \"gambler\" network that learns to spot and distribute its budget in areas where the predictions are clearly wrong, while the segmenter network tries to leave no clear clues for the gambler where to bet. Empirical evaluation on two road-scene semantic segmentation tasks shows that not only does the proposed method re-enable expressing uncertainties, it also improves pixel-wise and structure-based metrics. "}}
