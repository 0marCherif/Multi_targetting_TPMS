{"id": "An5MaWw4L4I", "cdate": 1652737643425, "mdate": null, "content": {"title": "Finite-Time Regret of Thompson Sampling Algorithms for Exponential Family Multi-Armed Bandits", "abstract": "We study the regret of Thompson sampling (TS) algorithms for exponential family bandits, where the reward distribution is from a one-dimensional exponential family, which covers many common reward distributions including Bernoulli, Gaussian, Gamma, Exponential, etc. We propose a Thompson sampling algorithm, termed ExpTS, which uses a novel sampling distribution to avoid the under-estimation of the optimal arm. We provide a tight regret analysis for ExpTS, which simultaneously yields both the finite-time regret bound as well as the asymptotic regret bound. In particular, for a $K$-armed bandit with exponential family rewards, ExpTS over a horizon $T$ is sub-UCB (a strong criterion for the finite-time regret that is problem-dependent), minimax optimal up to a factor $\\sqrt{\\log K}$, and asymptotically optimal, for exponential family rewards. Moreover, we propose ExpTS$^+$, by adding a greedy exploitation step in addition to the sampling distribution used in ExpTS, to avoid the over-estimation of sub-optimal arms. ExpTS$^+$ is an anytime bandit algorithm and achieves the minimax optimality and asymptotic optimality simultaneously for exponential family reward distributions. Our proof techniques are general and conceptually simple and can be easily applied to analyze standard Thompson sampling with specific reward distributions."}}
{"id": "tAqko3SuFw", "cdate": 1640995200000, "mdate": 1672346726913, "content": {"title": "Finite-Time Regret of Thompson Sampling Algorithms for Exponential Family Multi-Armed Bandits", "abstract": ""}}
{"id": "xo4AlNO7zlrS", "cdate": 1609459200000, "mdate": 1632864003588, "content": {"title": "Almost Optimal Anytime Algorithm for Batched Multi-Armed Bandits", "abstract": "In batched multi-armed bandit problems, the learner can adaptively pull arms and adjust strategy in batches. In many real applications, not only the regret but also the batch complexity need to be ..."}}
{"id": "H6-aIuR8TPY", "cdate": 1609459200000, "mdate": 1640128358696, "content": {"title": "MOTS: Minimax Optimal Thompson Sampling", "abstract": "Thompson sampling is one of the most widely used algorithms in many online decision problems due to its simplicity for implementation and superior empirical performance over other state-of-the-art ..."}}
{"id": "GeJSizc9koo", "cdate": 1609459200000, "mdate": 1640128358703, "content": {"title": "Double Explore-then-Commit: Asymptotic Optimality and Beyond", "abstract": "We study the multi-armed bandit problem with subGaussian rewards. The explore-then-commit (ETC) strategy, which consists of an exploration phase followed by an exploitation phase, is one of the mos..."}}
{"id": "7kacTFslDm5", "cdate": 1609459200000, "mdate": 1632864003598, "content": {"title": "Optimal Streaming Algorithms for Multi-Armed Bandits", "abstract": "This paper studies two variants of the best arm identification (BAI) problem under the streaming model, where we have a stream of n arms with reward distributions supported on [0,1] with unknown me..."}}
{"id": "0p4he2-w1q", "cdate": 1609459200000, "mdate": 1682317738984, "content": {"title": "Unconstrained Submodular Maximization with Modular Costs: Tight Approximation and Application to Profit Maximization", "abstract": ""}}
{"id": "vQwJjN1xdZ8", "cdate": 1577836800000, "mdate": null, "content": {"title": "Realtime Index-Free Single Source SimRank Processing on Web-Scale Graphs", "abstract": ""}}
{"id": "qtznxI_qN3H", "cdate": 1577836800000, "mdate": null, "content": {"title": "Double Explore-then-Commit: Asymptotic Optimality and Beyond", "abstract": "We study the multi-armed bandit problem with subgaussian rewards. The explore-then-commit (ETC) strategy, which consists of an exploration phase followed by an exploitation phase, is one of the most widely used algorithms in a variety of online decision applications. Nevertheless, it has been shown in Garivier et al. (2016) that ETC is suboptimal in the asymptotic sense as the horizon grows, and thus, is worse than fully sequential strategies such as Upper Confidence Bound (UCB). In this paper, we show that a variant of ETC algorithm can actually achieve the asymptotic optimality for multi-armed bandit problems as UCB-type algorithms do and extend it to the batched bandit setting. Specifically, we propose a double explore-then-commit (DETC) algorithm that has two exploration and exploitation phases and prove that DETC achieves the asymptotically optimal regret bound. To our knowledge, DETC is the first non-fully-sequential algorithm that achieves such asymptotic optimality. In addition, we extend DETC to batched bandit problems, where (i) the exploration process is split into a small number of batches and (ii) the round complexity is of central interest. We prove that a batched version of DETC can achieve the asymptotic optimality with only a constant round complexity. This is the first batched bandit algorithm that can attain the optimal asymptotic regret bound and optimal round complexity simultaneously."}}
{"id": "jOhy7V9VLQp", "cdate": 1577836800000, "mdate": null, "content": {"title": "Realtime Index-Free Single Source SimRank Processing on Web-Scale Graphs", "abstract": "Given a graph G and a node u in G, a single source SimRank query evaluates the similarity between u and every node v in G. Existing approaches to single source SimRank computation incur either long query response time, or expensive pre-computation, which needs to be performed again whenever the graph G changes. Consequently, to our knowledge none of them is ideal for scenarios in which (i) query processing must be done in realtime, and (ii) the underlying graph G is massive, with frequent updates. Motivated by this, we propose SimPush, a novel algorithm that answers single source SimRank queries without any pre-computation, and at the same time achieves significantly higher query processing speed than even the fastest known index-based solutions. Further, SimPush provides rigorous result quality guarantees, and its high performance does not rely on any strong assumption of the underlying graph. Specifically, compared to existing methods, SimPush employs a radically different algorithmic design that focuses on (i) identifying a small number of nodes relevant to the query, and subsequently (ii) computing statistics and performing residue push from these nodes only. We prove the correctness of SimPush, analyze its time complexity, and compare its asymptotic performance with that of existing methods. Meanwhile, we evaluate the practical performance of SimPush through extensive experiments on 8 real datasets. The results demonstrate that SimPush consistently outperforms all existing solutions, often by over an order of magnitude. In particular, on a commodity machine, SimPush answers a single source SimRank query on a web graph containing over 133 million nodes and 5.4 billion edges in under 62 milliseconds, with 0.00035 empirical error, while the fastest index-based competitor needs 1.18 seconds."}}
