{"id": "lXkwyiBwVi", "cdate": 1672531200000, "mdate": 1674769244654, "content": {"title": "A Communication-Efficient Adaptive Algorithm for Federated Learning under Cumulative Regret", "abstract": "We consider the problem of online stochastic optimization in a distributed setting with $M$ clients connected through a central server. We develop a distributed online learning algorithm that achieves order-optimal cumulative regret with low communication cost measured in the total number of bits transmitted over the entire learning horizon. This is in contrast to existing studies which focus on the offline measure of simple regret for learning efficiency. The holistic measure for communication cost also departs from the prevailing approach that \\emph{separately} tackles the communication frequency and the number of bits in each communication round."}}
{"id": "xz-fiMaicsT", "cdate": 1640995200000, "mdate": 1674769244645, "content": {"title": "Kernel-based Federated Learning with Personalization", "abstract": "We study collaborative learning among distributed clients facilitated by a central server. Each client is interested in maximizing a personalized objective function that is a weighted sum of its local objective and a global objective. Each client has direct access to random bandit feedback on its local objective, but only has a partial view of the global objective and relies on information exchange with other clients for collaborative learning. We adopt the kernel-based bandit framework where the objective functions belong to a reproducing kernel Hilbert space. We propose an algorithm based on surrogate Gaussian process (GP) models and establish its order-optimal regret performance (up to polylogarithmic factors). We also show that the sparse approximations of the GP models can be employed to reduce the communication overhead across clients."}}
{"id": "eC-SrsCsOM", "cdate": 1640995200000, "mdate": 1674769244771, "content": {"title": "Provably and Practically Efficient Neural Contextual Bandits", "abstract": "We consider the neural contextual bandit problem. In contrast to the existing work which primarily focuses on ReLU neural nets, we consider a general set of smooth activation functions. Under this more general setting, (i) we derive non-asymptotic error bounds on the difference between an overparameterized neural net and its corresponding neural tangent kernel, (ii) we propose an algorithm with a provably sublinear regret bound that is also efficient in the finite regime as demonstrated by empirical studies. The non-asymptotic error bounds may be of broader interest as a tool to establish the relation between the smoothness of the activation functions in neural contextual bandits and the smoothness of the kernels in kernel bandits."}}
{"id": "XP5Iq_eFX54", "cdate": 1640995200000, "mdate": 1674769244663, "content": {"title": "Distributed Linear Bandits under Communication Constraints", "abstract": "We consider distributed linear bandits where $M$ agents learn collaboratively to minimize the overall cumulative regret incurred by all agents. Information exchange is facilitated by a central server, and both the uplink and downlink communications are carried over channels with fixed capacity, which limits the amount of information that can be transmitted in each use of the channels. We investigate the regret-communication trade-off by (i) establishing information-theoretic lower bounds on the required communications (in terms of bits) for achieving a sublinear regret order; (ii) developing an efficient algorithm that achieves the minimum sublinear regret order offered by centralized learning using the minimum order of communications dictated by the information-theoretic lower bounds. For sparse linear bandits, we show a variant of the proposed algorithm offers better regret-communication trade-off by leveraging the sparsity of the problem."}}
{"id": "DeRqEZuysG", "cdate": 1640995200000, "mdate": 1674769244761, "content": {"title": "Disagreement-Based Active Learning in Online Settings", "abstract": "We study online active learning for classifying streaming instances within the framework of statistical learning theory. At each time, the learner either queries the label of the current instance or predicts the label based on past seen examples. The objective is to minimize the number of queries while constraining the number of prediction errors over a horizon of length <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><tex-math notation=\"LaTeX\">$T$</tex-math></inline-formula> . We develop a disagreement-based online learning algorithm for a general hypothesis space and under the Tsybakov noise and establish its label complexity under a constraint of bounded regret in terms of classification errors. We further establish a matching (up to a poly-logarithmic factor) lower bound, demonstrating the order optimality of the proposed algorithm. We address the tradeoff between label complexity and regret and show that the algorithm can be modified to operate at a different point on the tradeoff curve."}}
{"id": "MR4I3CjpeCv", "cdate": 1621630059825, "mdate": null, "content": {"title": "A Domain-Shrinking based Bayesian Optimization Algorithm with Order-Optimal Regret Performance", "abstract": "We consider sequential optimization of an unknown function in a reproducing kernel Hilbert space. We propose a Gaussian process-based algorithm and establish its order-optimal regret performance (up to a poly-logarithmic factor). This is the first GP-based algorithm with an order-optimal regret guarantee. The proposed algorithm is rooted in the methodology of domain shrinking realized through a sequence of tree-based region pruning and refining to concentrate queries in increasingly smaller high-performing regions of the function domain. The search for high-performing regions is localized and guided by an iterative estimation of the optimal function value to ensure both learning efficiency and computational efficiency. Compared with the prevailing GP-UCB family of algorithms, the proposed algorithm reduces computational complexity by a factor of $O(T^{2d-1})$ (where $T$ is the time horizon and $d$ the dimension of the function domain)."}}
{"id": "raHxN_KwoOD", "cdate": 1609459200000, "mdate": 1674769244671, "content": {"title": "A Domain-Shrinking based Bayesian Optimization Algorithm with Order-Optimal Regret Performance", "abstract": "We consider sequential optimization of an unknown function in a reproducing kernel Hilbert space. We propose a Gaussian process-based algorithm and establish its order-optimal regret performance (up to a poly-logarithmic factor). This is the first GP-based algorithm with an order-optimal regret guarantee. The proposed algorithm is rooted in the methodology of domain shrinking realized through a sequence of tree-based region pruning and refining to concentrate queries in increasingly smaller high-performing regions of the function domain. The search for high-performing regions is localized and guided by an iterative estimation of the optimal function value to ensure both learning efficiency and computational efficiency. Compared with the prevailing GP-UCB family of algorithms, the proposed algorithm reduces computational complexity by a factor of $O(T^{2d-1})$ (where $T$ is the time horizon and $d$ the dimension of the function domain)."}}
{"id": "eePT6duonhb", "cdate": 1609459200000, "mdate": 1674769244636, "content": {"title": "An Order-Optimal Adaptive Test Plan for Noisy Group Testing Under Unknown Noise Models", "abstract": "We consider the problem of noisy group testing where the test results are corrupted by noise with an unknown distribution. We propose an adaptive test plan consisting of a hierarchy of biased random walks guided by a local sequential test which together lend adaptivity and agnosticism to the unknown noise model. We show that the proposed test plan is order optimal in both the population size and the error rate."}}
{"id": "S2rZBZnKKI", "cdate": 1609459200000, "mdate": 1674769244729, "content": {"title": "As Easy as ABC: Adaptive Binning Coincidence Test for Uniformity Testing", "abstract": "We consider the problem of uniformity testing of Lipschitz continuous distributions with bounded support. The alternative hypothesis is a composite set of Lipschitz continuous distributions that are at least $\\varepsilon$ away in $\\ell_1$ distance from the uniform distribution. We propose a sequential test that adapts to the unknown distribution under the alternative hypothesis. Referred to as the Adaptive Binning Coincidence (ABC) test, the proposed strategy adapts in two ways. First, it partitions the set of alternative distributions into layers based on their distances to the uniform distribution. It then sequentially eliminates the alternative distributions layer by layer in decreasing distance to the uniform, and subsequently takes advantage of favorable situations of a distant alternative by exiting early. Second, it adapts, across layers of the alternative distributions, the resolution level of the discretization for computing the coincidence statistic. The farther away the layer is from the uniform, the coarser the discretization is needed for eliminating/exiting this layer. It thus exits both early in the detection process and quickly by using a lower resolution to take advantage of favorable alternative distributions. The ABC test builds on a novel sequential coincidence test for discrete distributions, which is of independent interest. We establish the sample complexity of the proposed tests as well as a lower bound."}}
{"id": "e0VQCA_qQJl", "cdate": 1577836800000, "mdate": null, "content": {"title": "Stochastic Coordinate Minimization with Progressive Precision for Stochastic Convex Optimization", "abstract": "A framework based on iterative coordinate minimization (CM) is developed for stochastic convex optimization. Given that exact coordinate minimization is impossible due to the unknown stochastic nat..."}}
