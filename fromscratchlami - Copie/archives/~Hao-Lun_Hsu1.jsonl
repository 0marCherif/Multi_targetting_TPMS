{"id": "f3g6e68-al", "cdate": 1640995200000, "mdate": 1683900837098, "content": {"title": "Improving Safety in Deep Reinforcement Learning using Unsupervised Action Planning", "abstract": "One of the key challenges to deep reinforcement learning (deep RL) is to ensure safety at both training and testing phases. In this work, we propose a novel technique of unsupervised action planning to improve the safety of on-policy reinforcement learning algorithms, such as trust region policy optimization (TRPO) or proximal policy optimization (PPO). We design our safety-aware reinforcement learning by storing all the history of \u201crecovery\u201d actions that rescue the agent from dangerous situations into a separate \u201csafety\u201d buffer and finding the best recovery action when the agent encounters similar states. Because this functionality requires the algorithm to query similar states, we implement the proposed safety mechanism using an unsupervised learning algorithm, k-means clustering. We evaluate the proposed algorithm on six robotic control tasks that cover navigation and manipulation. Our results show that the proposed safe RL algorithm can achieve higher rewards compared with multiple baselines in both discrete and continuous control problems. The supplemental video can be found at: https://youtu.be/AFTeWSohILo."}}
{"id": "7Ez_YF6gZ82", "cdate": 1640995200000, "mdate": 1683900837103, "content": {"title": "Automated Tuning of Closed-loop Neuromodulation Control Systems using Bayesian Optimization", "abstract": "Tuning the parameters of controllers to attain the best performance is a challenging task in designing effective closed-loop neuromodulation systems. In this paper, we present a distributed architecture for automated tuning and adaptation of closed-loop neuromodulation control systems. We use this approach for the automated parameter tuning of a Proportional-Integral (PI) neuromodulation controller using Bayesian optimization. We use a biophysically-grounded mean-field model of neural populations under electrical stimulation as a simulation environment for testing and prototyping the proposed framework and characterizing its performance. Our results demonstrate the feasibility of using Bayesian optimization for performance-based automated tuning of a PI controller in closed-loop set-point neuromodulation control tasks."}}
