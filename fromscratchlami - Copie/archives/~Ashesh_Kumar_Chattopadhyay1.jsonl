{"id": "v22DfoLNt5c", "cdate": 1609459200000, "mdate": null, "content": {"title": "Towards physically consistent data-driven weather forecasting: Integrating data assimilation with equivariance-preserving deep spatial transformers", "abstract": "There is growing interest in data-driven weather prediction (DDWP), for example using convolutional neural networks such as U-NETs that are trained on data from models or reanalysis. Here, we propose 3 components to integrate with commonly used DDWP models in order to improve their physical consistency and forecast accuracy. These components are 1) a deep spatial transformer added to the latent space of the U-NETs to preserve a property called equivariance, which is related to correctly capturing rotations and scalings of features in spatio-temporal data, 2) a data-assimilation (DA) algorithm to ingest noisy observations and improve the initial conditions for next forecasts, and 3) a multi-time-step algorithm, which combines forecasts from DDWP models with different time steps through DA, improving the accuracy of forecasts at short intervals. To show the benefit/feasibility of each component, we use geopotential height at 500~hPa (Z500) from ERA5 reanalysis and examine the short-term forecast accuracy of specific setups of the DDWP framework. Results show that the equivariance-preserving networks (U-STNs) clearly outperform the U-NETs, for example improving the forecast skill by $45\\%$. Using a sigma-point ensemble Kalman (SPEnKF) algorithm for DA and U-STN as the forward model, we show that stable, accurate DA cycles are achieved even with high observation noise. The DDWP+DA framework substantially benefits from large ($O(1000)$) ensembles that are inexpensively generated with the data-driven forward model in each DA cycle. The multi-time-step DDWP+DA framework also shows promises, e.g., it reduces the average error by factors of 2-3."}}
{"id": "1--k9ZUZcCQ", "cdate": 1577836800000, "mdate": null, "content": {"title": "Deep spatial transformers for autoregressive data-driven forecasting of geophysical turbulence", "abstract": "A deep spatial transformer based encoder-decoder model has been developed to autoregressively predict the time evolution of the upper layer\u2019s stream function of a two-layered quasi-geostrophic (QG) system without any information about the lower layer\u2019s stream function. The spatio-temporal complexity of QG flow is comparable to the complexity of 500hPa Geopotential Height (Z500) of fully coupled climate models or even the Z500 which is observed in the atmosphere, based on the instantaneous attractor dimension metric. The ability to predict autoregressively, the turbulent dynamics of QG is the first step towards building data-driven surrogates for more complex climate models. We show that the equivariance preserving properties of modern spatial transformers incorporated within a convolutional encoder-decoder module can predict up to 9 days in a QG system (outperforming a baseline persistence model and a standard convolutional encoder decoder with a custom loss function). The proposed data-driven model remains stable for multiple years thus promising us of a stable and physical data-driven climate model."}}
{"id": "PS8-ADf6fpR", "cdate": 1546300800000, "mdate": null, "content": {"title": "Data-driven prediction of a multi-scale Lorenz 96 chaotic system using a hierarchy of deep learning methods: Reservoir computing, ANN, and RNN-LSTM", "abstract": "In this paper, the performance of three deep learning methods for predicting short-term evolution and for reproducing the long-term statistics of a multi-scale spatio-temporal Lorenz 96 system is examined. The methods are: echo state network (a type of reservoir computing, RC-ESN), deep feed-forward artificial neural network (ANN), and recurrent neural network with long short-term memory (RNN-LSTM). This Lorenz 96 system has three tiers of nonlinearly interacting variables representing slow/large-scale ($X$), intermediate ($Y$), and fast/small-scale ($Z$) processes. For training or testing, only $X$ is available; $Y$ and $Z$ are never known or used. We show that RC-ESN substantially outperforms ANN and RNN-LSTM for short-term prediction, e.g., accurately forecasting the chaotic trajectories for hundreds of numerical solver's time steps, equivalent to several Lyapunov timescales. The RNN-LSTM and ANN show some prediction skills as well; RNN-LSTM bests ANN. Furthermore, even after losing the trajectory, data predicted by RC-ESN and RNN-LSTM have probability density functions (PDFs) that closely match the true PDF, even at the tails. The PDF of the data predicted using ANN, however, deviates from the true PDF. Implications, caveats, and applications to data-driven and data-assisted surrogate modeling of complex nonlinear dynamical systems such as weather/climate are discussed."}}
{"id": "9wtoQHXchQ", "cdate": 1546300800000, "mdate": null, "content": {"title": "Analog forecasting of extreme-causing weather patterns using deep learning", "abstract": "Numerical weather prediction (NWP) models require ever-growing computing time/resources, but still, have difficulties with predicting weather extremes. Here we introduce a data-driven framework that is based on analog forecasting (prediction using past similar patterns) and employs a novel deep learning pattern-recognition technique (capsule neural networks, CapsNets) and impact-based auto-labeling strategy. CapsNets are trained on mid-tropospheric large-scale circulation patterns (Z500) labeled $0-4$ depending on the existence and geographical region of surface temperature extremes over North America several days ahead. The trained networks predict the occurrence/region of cold or heat waves, only using Z500, with accuracies (recalls) of $69\\%-45\\%$ $(77\\%-48\\%)$ or $62\\%-41\\%$ $(73\\%-47\\%)$ $1-5$ days ahead. CapsNets outperform simpler techniques such as convolutional neural networks and logistic regression. Using both temperature and Z500, accuracies (recalls) with CapsNets increase to $\\sim 80\\%$ $(88\\%)$, showing the promises of multi-modal data-driven frameworks for accurate/fast extreme weather predictions, which can augment NWP efforts in providing early warnings."}}
{"id": "Ft5y8SJPVNI", "cdate": 1514764800000, "mdate": null, "content": {"title": "A test case for application of convolutional neural networks to spatio-temporal climate data: Re-identifying clustered weather patterns", "abstract": "Convolutional neural networks (CNNs) can potentially provide powerful tools for classifying and identifying patterns in climate and environmental data. However, because of the inherent complexities of such data, which are often spatio-temporal, chaotic, and non-stationary, the CNN algorithms must be designed/evaluated for each specific dataset and application. Yet to start, CNN, a supervised technique, requires a large labeled dataset. Labeling demands (human) expert time, which combined with the limited number of relevant examples in this area, can discourage using CNNs for new problems. To address these challenges, here we (1) Propose an effective auto-labeling strategy based on using an unsupervised clustering algorithm and evaluating the performance of CNNs in re-identifying these clusters; (2) Use this approach to label thousands of daily large-scale weather patterns over North America in the outputs of a fully-coupled climate model and show the capabilities of CNNs in re-identifying the 4 clustered regimes. The deep CNN trained with $1000$ samples or more per cluster has an accuracy of $90\\%$ or better. Accuracy scales monotonically but nonlinearly with the size of the training set, e.g. reaching $94\\%$ with $3000$ training samples per cluster. Effects of architecture and hyperparameters on the performance of CNNs are examined and discussed."}}
{"id": "n1gpYfWQVNY", "cdate": 1451606400000, "mdate": null, "content": {"title": "A framework to integrate MFiX with Trilinos for high fidelity fluidized bed computations", "abstract": "A framework is developed to integrate MFiX, an open source multiphase flow solver, with state-of-the-art pre-conditioners and linear solver packages in Trilinos via MFIX, Fortran, C and CPP wrappers. The computations are carried out to simulate flow in a fluidized bed problem with MFiX as well as the integrated solver, MFiX-Trilinos. BiConjugate gradient stabilized method as well as GMRES is used to solve the linear system of equations. The linear system of equations for the flow variable are solved using the built-in solvers in MFiX. On the other hand, MFiX-Trilinos uses the solvers from AztecOO package in Trilinos. The performance of the integrated solver is tested on various computer architectures for variety of problem sizes. The flow from the solver with the integrated framework and MFiX are in good agreement. However, the solver in MFiX-Trilinos is, approximately 30% faster compared to the same solver in MFiX."}}
