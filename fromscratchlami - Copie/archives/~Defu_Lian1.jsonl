{"id": "88TXeWrZi5", "cdate": 1686808732348, "mdate": null, "content": {"title": "Learning to Substitute Spans towards Improving Compositional Generalization", "abstract": "Despite the rising prevalence of neural sequence models, recent empirical evidences suggest their deficiency in compositional generalization. One of the current de-facto solutions to this problem is compositional data augmentation, aiming to incur additional compositional inductive bias. Nonetheless, the improvement offered by existing handcrafted augmentation strategies is limited when successful systematic generalization of neural sequence models requires multi-grained compositional bias (i.e., not limited to either lexical or structural biases only) or differentiation of training sequences in an imbalanced difficulty distribution. To address the two challenges, we first propose a novel compositional augmentation strategy dubbed \\textbf{Span} \\textbf{Sub}stitution (SpanSub) that enables multi-grained composition of substantial substructures in the whole training set. Over and above that, we introduce the \\textbf{L}earning \\textbf{to} \\textbf{S}ubstitute \\textbf{S}pan (L2S2) framework which empowers the learning of span substitution probabilities in SpanSub in an end-to-end manner by maximizing the loss of neural sequence models, so as to outweigh those challenging compositions with elusive concepts and novel surroundings. Our empirical results on three standard compositional generalization benchmarks, including SCAN, COGS and GeoQuery (with an improvement of at most 66.5\\%, 10.3\\%, 1.2\\%, respectively), demonstrate the superiority of SpanSub, %the learning framework L2S2 and their combination."}}
{"id": "QP2eTkYjnRa", "cdate": 1683880888649, "mdate": 1683880888649, "content": {"title": "Preference-Adaptive Meta-Learning for Cold-Start Recommendation", "abstract": "In recommender systems, the cold-start problem is\na critical issue. To alleviate this problem, an emerging direction adopts meta-learning frameworks and\nachieves success. Most existing works aim to learn\nglobally shared prior knowledge across all users so\nthat it can be quickly adapted to a new user with\nsparse interactions. However, globally shared prior\nknowledge may be inadequate to discern users\u2019\ncomplicated behaviors and causes poor generalization. Therefore, we argue that prior knowledge\nshould be locally shared by users with similar preferences who can be recognized by social relations.\nTo this end, in this paper, we propose a PreferenceAdaptive Meta-Learning approach (PAML) to improve existing meta-learning frameworks with better generalization capacity. Specifically, to address\ntwo challenges imposed by social relations, we first\nidentify reliable implicit friends to strengthen a\nuser\u2019s social relations based on our defined palindrome paths. Then, a coarse-fine preference modeling method is proposed to leverage social relations\nand capture the preference. Afterwards, a novel\npreference-specific adapter is designed to adapt the\nglobally shared prior knowledge to the preferencespecific knowledge so that users who have similar\ntastes share similar knowledge. We conduct extensive experiments on two publicly available datasets.\nExperimental results validate the power of social\nrelations and the effectiveness of PAML."}}
{"id": "u5Cv-DhZ5X", "cdate": 1676850577605, "mdate": 1676850577605, "content": {"title": "A Relaxed Ranking-based Factor Model for Recommender System from Implicit Feedback", "abstract": "Implicit feedback based recommendation has recently been an important task with the accumulated user-item interaction data. However, it is very challenging to produce recommendations from implicit feedback due to the sparseness of data and the lack of negative feedback/rating. Although various factor models have been proposed to tackle this problem, they either focus on rating prediction that may lead to inaccurate top-k recommendations or are dependent on the sampling of negative feedback that often results in bias. To this end, we propose a Relaxed Ranking-based Factor Model, RRFM, to relax pairwise ranking into a SVM-like task, where positive and negative feedbacks are separated by the soft boundaries, and their non-separate property is employed to capture the characteristic of unobserved data. A smooth and scalable algorithm is developed to solve group- and instance- level\u2019s optimization and parameter estimation. Extensive experiments based on real-world datasets demonstrate the effectiveness and advantage of our approach."}}
{"id": "BGe37suxcna", "cdate": 1676850058438, "mdate": 1676850058438, "content": {"title": "Learning User\u2019s Intrinsic and Extrinsic Interests for Point-of-Interest Recommendation: A Uni\ufb01ed Approach", "abstract": "Point-of-Interest (POI) recommendation has been an important service on location-based social networks. However, it is very challenging to generate accurate recommendations due to the complex nature of user\u2019s interest in POI and the data sparseness. In this paper, we propose a novel uni\ufb01ed approach that could effectively learn \ufb01ne-grained and interpretable user\u2019s interest, and adaptively model the missing data. Speci\ufb01cally, a user\u2019s general interest in POI is modeled as a mixture of her intrinsic and extrinsic interests, upon which we formulate the ranking constraints in our uni\ufb01ed recommendation approach. Furthermore, a self-adaptive location-oriented method is proposed to capture the inherent property of missing data, which is formulated as squared error based loss in our uni\ufb01ed optimization objective. Extensive experiments on real-world datasets demonstrate the effectiveness and advantage of our approach."}}
{"id": "UiaUEICawgw", "cdate": 1663850058905, "mdate": null, "content": {"title": "Learned Index with Dynamic $\\epsilon$", "abstract": "Index structure is a fundamental component in database and facilitates broad data retrieval applications. Recent learned index methods show superior performance by learning hidden yet useful data distribution with the help of machine learning, and provide a guarantee that the prediction error is no more than a pre-defined $\\epsilon$. However, existing learned index methods adopt a fixed $\\epsilon$ for all the learned segments, neglecting the diverse characteristics of different data localities. In this paper, we propose a mathematically-grounded learned index framework with dynamic $\\epsilon$, which is efficient and pluggable to existing learned index methods. We theoretically analyze prediction error bounds that link $\\epsilon$ with data characteristics for an illustrative learned index method. Under the guidance of the derived bounds, we learn how to vary $\\epsilon$ and improve the index performance with a better space-time trade-off. Experiments with real-world datasets and several state-of-the-art methods demonstrate the efficiency, effectiveness and usability of the proposed framework.\n"}}
{"id": "3iEi-c8gjB", "cdate": 1661401596124, "mdate": null, "content": {"title": "HRCF: Enhancing Collaborative Filtering via Hyperbolic Geometric Regularization", "abstract": "In large-scale recommender systems, the user-item networks are generally scale-free or expand exponentially. The latent features (also known as embeddings) used to describe the user and item are determined by how well the embedding space fits the data distribution. Hyperbolic space offers a spacious room to learn embeddings with its negative curvature and metric properties, which can well fit data with tree-like structures. Recently, several hyperbolic approaches have been proposed to learn high-quality representations for the users and items. However, most of them concentrate on developing the hyperbolic similitude by designing appropriate projection operations, whereas many advantageous and exciting geometric properties of hyperbolic space have not been explicitly explored. For example, one of the most notable properties of hyperbolic space is that its capacity space increases exponentially with the radius, which indicates the area far away from the hyperbolic origin is much more embeddable. Regarding the geometric properties of hyperbolic space, we bring up a Hyperbolic Regularization powered Collaborative Filtering(HRCF) and design a geometric-aware hyperbolic regularizer. Specifically, the proposal boosts optimization procedure via the root alignment and origin-aware penalty, which is simple yet impressively effective. Through theoretical analysis, we further show that our proposal is able to tackle the over-smoothing problem caused by hyperbolic aggregation and also brings the models a better discriminative ability. We conduct extensive empirical analysis, comparing our proposal against a large set of baselines on several public benchmarks. The empirical results show that our approach achieves highly competitive performance and surpasses both the leading Euclidean and hyperbolic baselines by considerable margins."}}
{"id": "aUoCgjJfmY9", "cdate": 1652737685025, "mdate": null, "content": {"title": "Graph Convolution Network based Recommender Systems: Learning Guarantee and Item Mixture Powered Strategy", "abstract": "Inspired by their powerful representation ability on graph-structured data, Graph Convolution Networks (GCNs) have been widely applied to recommender systems, and have shown superior performance. Despite their empirical success, there is a lack of theoretical explorations such as generalization properties. In this paper, we take a first step towards establishing a generalization guarantee for GCN-based recommendation models under inductive and transductive learning. We mainly investigate the roles of graph normalization and non-linear activation, providing some theoretical understanding, and construct extensive experiments to further verify these findings empirically. Furthermore, based on the proven generalization bound and the challenge of existing models in discrete data learning, we propose Item Mixture (IMix) to enhance recommendation. It models discrete spaces in a continuous manner by mixing the embeddings of positive-negative item pairs, and its effectiveness can be strictly guaranteed from empirical and theoretical aspects."}}
{"id": "VRvMQq3d1l0", "cdate": 1652737533660, "mdate": null, "content": {"title": "Learned Index with Dynamic $\\epsilon$", "abstract": "Index structure is a fundamental component in database and facilitates broad data retrieval applications. Recent learned index methods show superior performance by learning hidden yet useful data distribution with the help of machine learning, and provide a guarantee that the prediction error is no more than a pre-defined $\\epsilon$. However, existing learned index methods adopt a fixed $\\epsilon$ for all the learned segments, neglecting the diverse characteristics of different data localities. In this paper, we propose a mathematically-grounded learned index framework with dynamic $\\epsilon$, which is efficient and pluggable to existing learned index methods. We theoretically analyze prediction error bounds that link $\\epsilon$ with data characteristics for an illustrative learned index method. Under the guidance of the derived bounds, we learn how to vary $\\epsilon$ and improve the index performance with a better space-time trade-off. Experiments with real-world datasets and several state-of-the-art methods demonstrate the efficiency, effectiveness and usability of the proposed framework."}}
{"id": "vt516zga8m", "cdate": 1652737402335, "mdate": null, "content": {"title": "Cache-Augmented Inbatch Importance Resampling for Training Recommender Retriever", "abstract": "Recommender retrievers aim to rapidly retrieve a fraction of items from the entire item corpus when a user query requests, with the representative two-tower model trained with the log softmax loss. For efficiently training recommender retrievers on modern hardwares, inbatch sampling, where the items in the mini-batch are shared as negatives to estimate the softmax function, has attained growing interest. However, existing inbatch sampling based strategies just correct the sampling bias of inbatch items with item frequency, being unable to distinguish the user queries within the mini-batch and still incurring significant bias from the softmax. In this paper, we propose a Cache-Augmented Inbatch Importance Resampling (XIR) for training recommender retrievers, which not only offers different negatives to user queries with inbatch items, but also adaptively achieves a more accurate estimation of the softmax distribution. Specifically, XIR resamples items from the given mini-batch training pairs based on certain probabilities, where a cache with more frequently sampled items is adopted to augment the candidate item set, with the purpose of reusing the historical informative samples. XIR enables to sample query-dependent negatives based on inbatch items and to capture dynamic changes of model training, which leads to a better approximation of the softmax and further contributes to better convergence. Finally, we conduct experiments to validate the superior performance of the proposed XIR compared with competitive approaches."}}
{"id": "Yc4MjP2Mnob", "cdate": 1652737366552, "mdate": null, "content": {"title": "Recommender Forest for Efficient Retrieval", "abstract": "Recommender systems (RS) have to select the top-N items from a massive item set. For the sake of efficient recommendation, RS usually represents user and item as latent embeddings, and relies on approximate nearest neighbour search (ANNs) to retrieve the recommendation result. Despite the reduction of running time, the representation learning is independent of ANNs index construction; thus, the two operations can be incompatible, which results in potential loss of recommendation accuracy. To overcome the above problem, we propose the Recommender Forest (a.k.a., RecForest), which jointly learns latent embedding and index for efficient and high-fidelity recommendation. RecForest consists of multiple k-ary trees, each of which is a partition of the item set via hierarchical balanced clustering such that each item is uniquely represented by a path from the root to a leaf. Given such a data structure, an encoder-decoder based routing network is developed: it first encodes the context, i.e., user information, into hidden states; then, leveraging a transformer-based decoder, it identifies the top-N items via beam search. Compared with the existing methods, RecForest brings in the following advantages: 1) the false partition of the boundary items can be effectively alleviated by the use of multiple trees; 2) the routing operation becomes much more accurate thanks to the powerful transformer decoder; 3) the tree parameters are shared across different tree levels, making the index to be extremely memory-efficient. The experimental studies are performed on five popular recommendation datasets: with a significantly simplified training cost, RecForest outperforms competitive baseline approaches in terms of both recommendation accuracy and efficiency. "}}
