{"id": "6tXnKkQgThS", "cdate": 1672531200000, "mdate": 1681511926191, "content": {"title": "Refinement for Absolute Pose Regression with Neural Feature Synthesis", "abstract": ""}}
{"id": "c5dQa9b93L", "cdate": 1640995200000, "mdate": 1681680697219, "content": {"title": "NoPe-NeRF: Optimising Neural Radiance Field with No Pose Prior", "abstract": "Training a Neural Radiance Field (NeRF) without pre-computed camera poses is challenging. Recent advances in this direction demonstrate the possibility of jointly optimising a NeRF and camera poses in forward-facing scenes. However, these methods still face difficulties during dramatic camera movement. We tackle this challenging problem by incorporating undistorted monocular depth priors. These priors are generated by correcting scale and shift parameters during training, with which we are then able to constrain the relative poses between consecutive frames. This constraint is achieved using our proposed novel loss functions. Experiments on real-world indoor and outdoor scenes show that our method can handle challenging camera trajectories and outperforms existing methods in terms of novel view rendering quality and pose estimation accuracy. Our project page is https://nope-nerf.active.vision."}}
{"id": "b4xZYv3bxwY", "cdate": 1640995200000, "mdate": 1667771810954, "content": {"title": "DFNet: Enhance Absolute Pose Regression with Direct Feature Matching", "abstract": ""}}
{"id": "SPUgwrQ-hDf7", "cdate": 1640995200000, "mdate": 1668203760521, "content": {"title": "DFNet: Enhance Absolute Pose Regression with Direct Feature Matching", "abstract": "We introduce a camera relocalization pipeline that combines absolute pose regression (APR) and direct feature matching. By incorporating exposure-adaptive novel view synthesis, our method successfully addresses photometric distortions in outdoor environments that existing photometric-based methods fail to handle. With domain-invariant feature matching, our solution improves pose regression accuracy using semi-supervised learning on unlabeled data. In particular, the pipeline consists of two components: Novel View Synthesizer and DFNet. The former synthesizes novel views compensating for changes in exposure and the latter regresses camera poses and extracts robust features that close the domain gap between real images and synthetic ones. Furthermore, we introduce an online synthetic data generation scheme. We show that these approaches effectively enhance camera pose estimation both in indoor and outdoor scenes. Hence, our method achieves a state-of-the-art accuracy by outperforming existing single-image APR methods by as much as 56%, comparable to 3D structure-based methods."}}
{"id": "yrDjZVaICNU", "cdate": 1609459200000, "mdate": 1667771810958, "content": {"title": "NeRF-: Neural Radiance Fields Without Known Camera Parameters", "abstract": "Considering the problem of novel view synthesis (NVS) from only a set of 2D images, we simplify the training process of Neural Radiance Field (NeRF) on forward-facing scenes by removing the requirement of known or pre-computed camera parameters, including both intrinsics and 6DoF poses. To this end, we propose NeRF$--$, with three contributions: First, we show that the camera parameters can be jointly optimised as learnable parameters with NeRF training, through a photometric reconstruction; Second, to benchmark the camera parameter estimation and the quality of novel view renderings, we introduce a new dataset of path-traced synthetic scenes, termed as Blender Forward-Facing Dataset (BLEFF); Third, we conduct extensive analyses to understand the training behaviours under various camera motions, and show that in most scenarios, the joint optimisation pipeline can recover accurate camera parameters and achieve comparable novel view synthesis quality as those trained with COLMAP pre-computed camera parameters. Our code and data are available at https://nerfmm.active.vision."}}
{"id": "lzNicsKTqzY", "cdate": 1609459200000, "mdate": 1667771810975, "content": {"title": "Ray-ONet: Efficient 3D Reconstruction From A Single RGB Image", "abstract": ""}}
{"id": "i_zXdenV6EP", "cdate": 1609459200000, "mdate": 1668203760294, "content": {"title": "Direct-PoseNet: Absolute Pose Regression with Photometric Consistency", "abstract": "We present a relocalization pipeline, which combines an absolute pose regression (APR) network with a novel view synthesis based direct matching module, offering superior accuracy while maintaining low inference time. Our contribution is twofold: i) we design a direct matching module that supplies a photometric supervision signal to refine the pose regression network via differentiable rendering; ii) we modify the rotation representation from the classical quaternion to SO(3) in pose regression, removing the need for balancing rotation and translation loss terms. As a result, our network Direct-PoseNet achieves state-of-the-art performance among all other single-image APR methods on the 7-Scenes benchmark and the LLFF dataset."}}
{"id": "bbADb174a0O", "cdate": 1609459200000, "mdate": 1668203954166, "content": {"title": "Ray-ONet: Efficient 3D Reconstruction From A Single RGB Image", "abstract": "We propose Ray-ONet to reconstruct detailed 3D models from monocular images efficiently. By predicting a series of occupancy probabilities along a ray that is back-projected from a pixel in the camera coordinate, our method Ray-ONet improves the reconstruction accuracy in comparison with Occupancy Networks (ONet), while reducing the network inference complexity to O($N^2$). As a result, Ray-ONet achieves state-of-the-art performance on the ShapeNet benchmark with more than 20$\\times$ speed-up at $128^3$ resolution and maintains a similar memory footprint during inference."}}
{"id": "UfNw6WiE4bu", "cdate": 1609459200000, "mdate": 1667771811009, "content": {"title": "Direct-PoseNet: Absolute Pose Regression with Photometric Consistency", "abstract": "We present a relocalization pipeline, which combines an absolute pose regression (APR) network with a novel view synthesis based direct matching module, offering superior accuracy while maintaining low inference time. Our contribution is twofold: i) we design a direct matching module that supplies a photometric supervision signal to refine the pose regression network via differentiable rendering; ii) we show that our method can easily cope with additional unlabeled data without the need for external supervision such as traditional visual odometry or pose graph optimization. As a result, our method achieves state-of-the-art performance among all other single-image APR methods on the 7-Scenes benchmark and the LLFF dataset."}}
{"id": "x8CuhO6MAyR", "cdate": 1577836800000, "mdate": 1667771810986, "content": {"title": "Neighbourhood-Insensitive Point Cloud Normal Estimation Network", "abstract": ""}}
