{"id": "gEPYdogG1W", "cdate": 1683880997285, "mdate": null, "content": {"title": "Open\u2010set learning under covariate shift", "abstract": "Open-set learning deals with the testing distribution where there exist samples from the classes that are unseen during training. They aim to classify the seen classes and recog- nize the unseen classes. Previous studies typically assume that the marginal distribution of the seen classes is fixed across the training and testing distributions. In many real-world applications, however, there may exist covariate shift between them, i.e., the marginal distribution of seen classes may shift. We call this kind of problem as open-set learning under covariate shift, aim to robustly classify the seen classes under covariate shift and be aware of the unseen classes.We present a new open-set learning framework with covari- ate generalization based on supervised contrastive learning, called SC\u2013OSG, inspired by the latent connection between contrastive learning and representation invariance. Specifi- cally, we theoretically justify supervised contrastive learning that could promote the con- ditional invariance of representations, a critical condition for covariate generalization. SC\u2013 OSG generates multi-source samples to promote the representation invariance and improve the covariate generalization. Based on this, we propose a detection score that is specific to the proposed training scheme. We evaluate the effectiveness of our method on several real-world datasets, on all of which we achieve competitive results with state-of-the-art methods."}}
{"id": "VdQWVdT_8v", "cdate": 1652737477376, "mdate": null, "content": {"title": "LOG: Active Model Adaptation for Label-Efficient OOD Generalization", "abstract": "This work discusses how to achieve worst-case Out-Of-Distribution (OOD) generalization for a variety of distributions based on a relatively small labeling cost. The problem has broad applications, especially in non-i.i.d. open-world scenarios. Previous studies either rely on a large amount of labeling cost or lack of guarantees about the worst-case generalization. In this work, we show for the first time that active model adaptation could achieve both good performance and robustness based on the invariant risk minimization principle. We propose \\textsc{Log}, an interactive model adaptation framework, with two sub-modules: active sample selection and causal invariant learning. Specifically, we formulate the active selection as a mixture distribution separation problem and present an unbiased estimator, which could find the samples that violate the current invariant relationship, with a provable guarantee. The theoretical analysis supports that both sub-modules contribute to generalization. A large number of experimental results confirm the promising performance of the new algorithm."}}
