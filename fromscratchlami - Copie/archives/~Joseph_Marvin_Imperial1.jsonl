{"id": "MjN3PdPu8V", "cdate": 1696590186069, "mdate": 1696590186069, "content": {"title": "Automatic Readability Assessment for Closely Related Languages", "abstract": "In recent years, the main focus of research on automatic readability assessment (ARA) has shifted towards using expensive deep learning-based methods with the primary goal of increasing models' accuracy. This, however, is rarely applicable for low-resource languages where traditional handcrafted features are still widely used due to the lack of existing NLP tools to extract deeper linguistic representations. In this work, we take a step back from the technical component and focus on how linguistic aspects such as mutual intelligibility or degree of language relatedness can improve ARA in a low-resource setting. We collect short stories written in three languages in the Philippines-Tagalog, Bikol, and Cebuano-to train readability assessment models and explore the interaction of data and features in various cross-lingual setups. Our results show that the inclusion of CrossNGO, a novel specialized feature exploiting n-gram overlap applied to languages with high mutual intelligibility, significantly improves the performance of ARA models compared to the use of off-the-shelf large multilingual language models alone. Consequently, when both linguistic representations are combined, we achieve state-of-the-art results for Tagalog and Cebuano, and baseline scores for ARA in Bikol.https://aclanthology.org/2023.findings-acl.331.pdf"}}
{"id": "ZPG6gnUZLz", "cdate": 1672531200000, "mdate": 1695973634132, "content": {"title": "Automatic Readability Assessment for Closely Related Languages", "abstract": ""}}
{"id": "J4yrd1u-1A", "cdate": 1672531200000, "mdate": 1686858804849, "content": {"title": "Automatic Readability Assessment for Closely Related Languages", "abstract": "In recent years, the main focus of research on automatic readability assessment (ARA) has shifted towards using expensive deep learning-based methods with the primary goal of increasing models' accuracy. This, however, is rarely applicable for low-resource languages where traditional handcrafted features are still widely used due to the lack of existing NLP tools to extract deeper linguistic representations. In this work, we take a step back from the technical component and focus on how linguistic aspects such as mutual intelligibility or degree of language relatedness can improve ARA in a low-resource setting. We collect short stories written in three languages in the Philippines-Tagalog, Bikol, and Cebuano-to train readability assessment models and explore the interaction of data and features in various cross-lingual setups. Our results show that the inclusion of CrossNGO, a novel specialized feature exploiting n-gram overlap applied to languages with high mutual intelligibility, significantly improves the performance of ARA models compared to the use of off-the-shelf large multilingual language models alone. Consequently, when both linguistic representations are combined, we achieve state-of-the-art results for Tagalog and Cebuano, and baseline scores for ARA in Bikol."}}
{"id": "DzQuQWYdoaO", "cdate": 1672531200000, "mdate": 1695973634137, "content": {"title": "Flesch or Fumble? Evaluating Readability Standard Alignment of Instruction-Tuned Language Models", "abstract": "Readability metrics and standards such as Flesch Kincaid Grade Level (FKGL) and the Common European Framework of Reference for Languages (CEFR) exist to guide teachers and educators to properly assess the complexity of educational materials before administering them for classroom use. In this study, we select a diverse set of open and closed-source instruction-tuned language models and investigate their performances in writing story completions and simplifying narratives$-$tasks that teachers perform$-$using standard-guided prompts controlling text readability. Our extensive findings provide empirical proof of how globally recognized models like ChatGPT may be considered less effective and may require more refined prompts for these generative tasks compared to other open-sourced models such as BLOOMZ and FlanT5$-$which have shown promising results."}}
{"id": "B0lg2tPwOxc", "cdate": 1645930372463, "mdate": null, "content": {"title": "NU HLT at CMCL 2022 Shared Task: Multilingual and Crosslingual Prediction of Human Reading Behavior in Universal Language Space", "abstract": "In this paper, we present a unified model that works for both multilingual and crosslingual prediction of reading times of words in various languages. The secret behind the success of this model is in the preprocessing step where all words are transformed to their universal language representation via the International Phonetic Alphabet (IPA). To the best of our knowledge, this is the first study to favorably exploit this phonological property of language for the two tasks. Various feature types were extracted covering basic frequencies, n-grams, information theoretic, and psycholinguistically-motivated predictors for model training. A finetuned Random Forest model obtained best performance for both tasks with 3.8031 and 3.9065 MAE scores for mean first fixation duration (FFDAvg) and mean total reading time (TRTAvg) respectively."}}
{"id": "w-WKvYDbYYG", "cdate": 1640995200000, "mdate": 1686858804847, "content": {"title": "A Baseline Readability Model for Cebuano", "abstract": "In this study, we developed the first baseline readability model for the Cebuano language. Cebuano is the second most-used native language in the Philippines with about 27.5 million speakers. As the baseline, we extracted traditional or surface-based features, syllable patterns based from Cebuano's documented orthography, and neural embeddings from the multilingual BERT model. Results show that the use of the first two handcrafted linguistic features obtained the best performance trained on an optimized Random Forest model with approximately 87% across all metrics. The feature sets and algorithm used also is similar to previous results in readability assessment for the Filipino language showing potential of crosslingual application. To encourage more work for readability assessment in Philippine languages such as Cebuano, we open-sourced both code and data."}}
{"id": "t_zXfXwJVA0", "cdate": 1640995200000, "mdate": 1686858804854, "content": {"title": "Uniform Complexity for Text Generation", "abstract": "Large pre-trained language models have shown promising results in a wide array of tasks such as narrative generation, question answering, and machine translation. Likewise, the current trend in literature has deeply focused on controlling salient properties of generated texts including sentiment, topic, and coherence to produce more human-like outputs. In this work, we introduce Uniform Complexity for Text Generation or UCTG which serves as a challenge to make existing models generate uniformly complex text with respect to inputs or prompts used. For example, if the reading level of an input text prompt is appropriate for low-leveled learners (ex. A2 in the CEFR), then the generated text by an NLG system should also assume this particular level for increased readability. In a controlled narrative generation task, we surveyed over 160 linguistic and cognitively-motivated features for evaluating text readability and found out that GPT-2 models and even humans struggle in preserving the linguistic complexity of input prompts used. Ultimately, we lay down potential methods and approaches which can be incorporated into the general framework of steering language models towards addressing this important challenge."}}
{"id": "pyAItPu-SR", "cdate": 1640995200000, "mdate": 1686858804853, "content": {"title": "NU HLT at CMCL 2022 Shared Task: Multilingual and Crosslingual Prediction of Human Reading Behavior in Universal Language Space", "abstract": "In this paper, we present a unified model that works for both multilingual and crosslingual prediction of reading times of words in various languages. The secret behind the success of this model is in the preprocessing step where all words are transformed to their universal language representation via the International Phonetic Alphabet (IPA). To the best of our knowledge, this is the first study to favorable exploit this phonological property of language for the two tasks. Various feature types were extracted covering basic frequencies, n-grams, information theoretic, and psycholinguistically-motivated predictors for model training. A finetuned Random Forest model obtained best performance for both tasks with 3.8031 and 3.9065 MAE scores for mean first fixation duration (FFDAvg) and mean total reading time (TRTAvg) respectively."}}
{"id": "oXuBleN4ov", "cdate": 1640995200000, "mdate": 1686858804845, "content": {"title": "On Applicability of Neural Language Models for Readability Assessment in Filipino", "abstract": "In the field of automatic readability assessment (ARA), the current trend in the research community focuses on the use of large neural language models such as BERT as evidenced from its high performance in other downstream NLP tasks. In this study, we dissect the BERT model and applied it to readability assessment in a low-resource setting using a dataset in the Filipino language. Results show that extracting embeddings separately from various layers of BERT obtain relatively similar performance with models trained using a diverse set of handcrafted features and substantially better than using conventional transfer learning approach."}}
{"id": "ejIXCLR5w8", "cdate": 1640995200000, "mdate": 1686858804844, "content": {"title": "Is Twitter an Echo Chamber? Connecting Online Public Sentiments to Actual Results From the 2019 Philippine Midterm Elections", "abstract": "Social media platforms like Twitter can act as a gateway towards understanding people's perspectives and viewpoints during national-level events such as elections. As such, one can estimate how likely a certain candidate's turnout would be in an election from reading targeted sentiments published online. In this study, we collected tweets during the 2019 Philippine midterm elections for senatorial positions and performed cluster-based analysis via k-means paired with SHAP to understand the winnability of a candidate with respect to associated words linked to them on Twitter. Results show multiple cases where candidates have won despite amassing extremely negative comments online."}}
