{"id": "-0AkTseVUn", "cdate": 1681652806074, "mdate": 1681652806074, "content": {"title": "Stochastic optimization with momentum: convergence, fluctuations, and traps avoidance", "abstract": "In this paper, a general stochastic optimization procedure is studied, unifying several variants of the stochastic gradient descent such as, among others, the stochastic heavy ball method, the Stochastic Nesterov Accelerated Gradient algorithm (S-NAG), and the widely used Adam algorithm. The algorithm is seen as a noisy Euler discretization of a non-autonomous ordinary differential equation, recently introduced by Belotto da Silva and Gazeau, which is analyzed in depth. Assuming that the objective function is non-convex and differentiable, the stability and the almost sure convergence of the iterates to the set of critical points are established. A noteworthy special case is the convergence proof of S-NAG in a non-convex setting. Under some assumptions, the convergence rate is provided under the form of a Central Limit Theorem. Finally, the non-convergence of the algorithm to undesired critical points, such as local maxima or saddle points, is established. Here, the main ingredient is a new avoidance of traps result for non-autonomous settings, which is of independent interest."}}
{"id": "EGAJFa1KcPD", "cdate": 1672531200000, "mdate": 1681652002476, "content": {"title": "Stochastic Policy Gradient Methods: Improved Sample Complexity for Fisher-non-degenerate Policies", "abstract": ""}}
{"id": "oaAtsE2LvB", "cdate": 1640995200000, "mdate": 1681652002306, "content": {"title": "Analysis of a Target-Based Actor-Critic Algorithm with Linear Function Approximation", "abstract": ""}}
{"id": "pdFnEPuqtc", "cdate": 1609459200000, "mdate": 1681652002476, "content": {"title": "Convergence and Dynamical Behavior of the ADAM Algorithm for Nonconvex Stochastic Optimization", "abstract": ""}}
{"id": "aa8BJSX8jwP", "cdate": 1609459200000, "mdate": 1681652002325, "content": {"title": "Contributions to non-convex stochastic optimization and reinforcement learning. (Contributions \u00e0 l'optimisation stochastique non convexe et \u00e0 l'apprentissage par renforcement)", "abstract": ""}}
{"id": "UD-2bAG3bI", "cdate": 1577836800000, "mdate": 1681652002310, "content": {"title": "Convergence Rates of a Momentum Algorithm with Bounded Adaptive Step Size for Nonconvex Optimization", "abstract": ""}}
{"id": "SyeYiyHFDH", "cdate": 1569439649238, "mdate": null, "content": {"title": "Convergence Analysis of a Momentum Algorithm with Adaptive Step Size for Nonconvex Optimization", "abstract": "Although Adam is a very popular algorithm for optimizing the weights of neural networks, it has been recently shown that it can diverge even in simple convex optimization examples. Therefore, several variants of Adam have been proposed to circumvent this convergence issue. In this work, we study the algorithm for smooth nonconvex optimization under a boundedness assumption on the adaptive learning rate. The bound on the adaptive step size depends on the Lipschitz constant of the gradient of the objective function and provides safe theoretical adaptive step sizes. Under this boundedness assumption, we show a novel first order convergence rate result in both deterministic and stochastic contexts. Furthermore, we establish convergence rates of the function value sequence using the Kurdyka-Lojasiewicz property."}}
