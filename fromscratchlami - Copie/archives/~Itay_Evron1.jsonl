{"id": "zSmWMITBgN", "cdate": 1672531200000, "mdate": 1695235427213, "content": {"title": "The Role of Codeword-to-Class Assignments in Error-Correcting Codes: An Empirical Study", "abstract": "Error-correcting codes (ECC) are used to reduce multiclass classification tasks to multiple binary classification subproblems. In ECC, classes are represented by the rows of a binary matrix, corres..."}}
{"id": "MaPTAfMTM-v", "cdate": 1640995200000, "mdate": 1657741921045, "content": {"title": "How catastrophic can catastrophic forgetting be in linear regression?", "abstract": "To better understand catastrophic forgetting, we study fitting an overparameterized linear model to a sequence of tasks with different input distributions. We analyze how much the model forgets the..."}}
{"id": "ryZ4idbd-B", "cdate": 1514764800000, "mdate": null, "content": {"title": "Efficient Loss-Based Decoding on Graphs for Extreme Classification", "abstract": "In extreme classification problems, learning algorithms are required to map instances to labels from an extremely large label set. We build on a recent extreme classification framework with logarithmic time and space (LTLS), and on a general approach for error correcting output coding (ECOC) with loss-based decoding, and introduce a flexible and efficient approach accompanied by theoretical bounds. Our framework employs output codes induced by graphs, for which we show how to perform efficient loss-based decoding to potentially improve accuracy. In addition, our framework offers a tradeoff between accuracy, model size and prediction time. We show how to find the sweet spot of this tradeoff using only the training data. Our experimental study demonstrates the validity of our assumptions and claims, and shows that our method is competitive with state-of-the-art algorithms."}}
