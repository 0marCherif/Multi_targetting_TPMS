{"id": "i5PKTtD2Qed", "cdate": 1672531200000, "mdate": 1681651954517, "content": {"title": "Augmented Language Models: a Survey", "abstract": ""}}
{"id": "gdNpaJ132pi", "cdate": 1672531200000, "mdate": 1681651954523, "content": {"title": "Can discrete information extraction prompts generalize across language models?", "abstract": ""}}
{"id": "XivPo2Sd0a", "cdate": 1672531200000, "mdate": 1681651954380, "content": {"title": "Toolformer: Language Models Can Teach Themselves to Use Tools", "abstract": ""}}
{"id": "76Gtw3T4nQ6", "cdate": 1672531200000, "mdate": 1681651954284, "content": {"title": "Referential communication in heterogeneous communities of pre-trained visual deep networks", "abstract": ""}}
{"id": "sbWVtxq8-zE", "cdate": 1663849873288, "mdate": null, "content": {"title": "Can discrete information extraction prompts generalize across language models?", "abstract": "We study whether automatically-induced prompts that effectively extract information from a language model can also be used, out-of-the-box, to probe other language models for the same information. After confirming that discrete prompts induced with the AutoPrompt algorithm outperform manual and semi-manual prompts on the slot-filling task, we demonstrate a drop in performance for AutoPrompt prompts learned on a model and tested on another. We introduce a way to induce prompts by mixing language models at training time that results in prompts that generalize well across models. We conduct an extensive analysis of the induced prompts, finding that the more general prompts include a larger proportion of existing English words and have a less order-dependent and more uniform distribution of information across their component tokens. Our work provides preliminary evidence that it's possible to generate discrete prompts that can be induced once and used with a number of different models, and gives insights on the properties characterizing such prompts."}}
{"id": "LSDta_is1h", "cdate": 1640995200000, "mdate": 1681651954342, "content": {"title": "Communication breakdown: On the low mutual intelligibility between human and neural captioning", "abstract": ""}}
{"id": "1AvtkM4H-y7", "cdate": 1621629864951, "mdate": null, "content": {"title": "Interpretable agent communication from scratch (with a generic visual processor emerging on the side)", "abstract": "As deep networks begin to be deployed as autonomous agents, the issue of how they can communicate with each other becomes important. Here, we train two deep nets from scratch to perform realistic referent identification through unsupervised emergent communication. We show that the largely interpretable emergent protocol allows the nets to successfully communicate even about object types they did not see at training time. The visual representations induced as a by-product of our training regime, moreover, show comparable quality, when re-used as generic visual features, to a recent self-supervised learning model. Our results provide concrete evidence of the viability of (interpretable) emergent deep net communication in a more realistic scenario than previously considered, as well as establishing an intriguing link between this field and self-supervised visual learning."}}
{"id": "tNGk7C1-Qf", "cdate": 1609459200000, "mdate": 1681651954325, "content": {"title": "Interpretable agent communication from scratch (with a generic visual processor emerging on the side)", "abstract": ""}}
{"id": "NsTsDov9g-", "cdate": 1609459200000, "mdate": 1681651954303, "content": {"title": "Can Transformers Jump Around Right in Natural Language? Assessing Performance Transfer from SCAN", "abstract": ""}}
{"id": "xWAwF7PdXj", "cdate": 1546300800000, "mdate": 1681651954402, "content": {"title": "Enhancing Transformer for End-to-end Speech-to-Text Translation", "abstract": ""}}
