{"id": "xYlJRpzZtsY", "cdate": 1663850222754, "mdate": null, "content": {"title": "ROSCOE: A Suite of Metrics for Scoring Step-by-Step Reasoning", "abstract": "Large language models show improved downstream task performance when prompted to generate step-by-step reasoning to justify their final answers. These reasoning steps greatly improve model interpretability and verification, but objectively studying their correctness (independent of the final answer) is difficult without reliable methods for automatic evaluation. We simply do not know how often the stated reasoning steps actually support the final end task predictions. In this work, we present ROSCOE, a suite of interpretable, unsupervised automatic scores that improve and extend previous text generation evaluation metrics. To evaluate ROSCOE against baseline metrics, we design a typology of reasoning errors and collect synthetic and human evaluation scores on commonly used reasoning datasets. In contrast with existing metrics, ROSCOE can measure semantic consistency, logicality, informativeness, fluency, and factuality \u2014 among other traits \u2014 by leveraging properties of step-by-step rationales. We empirically verify the strength of our metrics on five human annotated and six programmatically perturbed diagnostics datasets - covering a diverse set of tasks that require reasoning skills and show that ROSCOE can consistently outperform baseline metrics."}}
{"id": "shzNQDcu9iV", "cdate": 1620330185692, "mdate": null, "content": {"title": "Alexa Conversations: An Extensible Data-driven Approach for Building Task-oriented Dialogue Systems", "abstract": "Traditional goal-oriented dialogue systems rely on various components such as natural language understanding, dialogue state tracking, policy learning and response generation. Training each component requires annotations which are hard to obtain for every new domain, limiting scalability of such systems. Similarly, rule-based dialogue systems require extensive writing and maintenance of rules and do not scale either. End-to-End dialogue systems, on the other hand, do not require module-specific annotations but need a large amount of data for training. To overcome these problems, in this demo, we present Alexa Conversations, a new approach for building goal-oriented dialogue systems that is scalable, extensible as well as data efficient. The components of this system are trained in a data-driven manner, but instead of collecting annotated conversations for training, we generate them using a novel dialogue simulator based on a few seed dialogues and specifications of APIs and entities provided by the developer. Our approach provides out-of-the-box support for natural conversational phenomena like entity sharing across turns or users changing their mind during conversation without requiring developers to provide any such dialogue flows. We exemplify our approach using a simple pizza ordering task and showcase its value in reducing the developer burden for creating a robust experience. Finally, we evaluate our system using a typical movie ticket booking task and show that the dialogue simulator is an essential component of the system that leads to over 50% improvement in turn-level action signature prediction accuracy. "}}
{"id": "YlRFMj7j3nO", "cdate": 1620329175556, "mdate": null, "content": {"title": "Dialog Simulation with Realistic Variations for Training Goal-Oriented Conversational Systems", "abstract": "Goal-oriented dialog systems enable users to complete specific goals like requesting information about a movie or booking a ticket.  Typically the dialog system pipeline contains multiple ML models, including natural language understanding,state tracking and action prediction (policy learning).  These models are trained through a combination of supervised or reinforcement learning methods and there-fore require collection of labeled domain specific datasets.  However, collecting annotated datasets with language and dialog-flow variations is expensive, time-consuming and scales poorly due to human involvement. In this paper, we propose an approach for automatically creating a large corpus of annotated dialogs from a few thoroughly annotated sample dialogs and the dialog schema.  Our approach includes a novel goal-sampling technique for sampling plausible user goals and a dialog simulation technique that uses heuristic interplay between the user and the system (Alexa), where the user tries to achieve the sampled goal. We validate our approach by generating data and training three different downstream conversational ML models. We achieve 18\u221250% relative accuracy improvements on a held-out test set compared to a baseline dialog generation approach that only samples natural language and entity value variations from existing catalogs but does not generate any novel dialog flow variations. We also qualitatively establish that the proposed approach is better than the baseline. Moreover, several different conversational experiences have been built using this method, which enables customers to have a wide variety of conversations with Alexa."}}
{"id": "n3POYyXxqp", "cdate": 1600111489965, "mdate": null, "content": {"title": "Towards Personalized Dialog Policies for Conversational Skill Discovery", "abstract": "Many businesses and consumers are extending the capabilities of voice-based services such as Amazon Alexa, Google Home, Microsoft Cortana, and Apple Siri to create custom voice experiences (also known as skills). As the number of these experiences increases, a key problem is the discovery of skills that can be used to address a user\u2019s request. In this paper, we focus on conversational skill discovery and present a conversational agent which engages in a dialog with users to help them find the skills that fulfill their needs. To this end, we start with a rule-based agent and improve it by using reinforcement learning. In this way, we enable the agent to adapt to different user attributes and conversational styles as it interacts with users. We evaluate our approach in a real production setting by deploying the agent to interact with real users, and show the effectiveness of the conversational agent in helping users find the skills that serve their request."}}
{"id": "gW5mx8ps9ZHh", "cdate": 1600111342897, "mdate": null, "content": {"title": "Data Augmentation for Training Dialog Models Robust to Speech Recognition Errors", "abstract": "Speech-based virtual assistants, such as Amazon Alexa, Google assistant, and Apple Siri, typically convert users\u2019 audio signals to text data through automatic speech recognition (ASR) and feed the text to downstream dialog models for natural language understanding and response generation.  The ASR out-put is error-prone; however, the downstream dialog models are often trained on error-free text data, making them sensitive to ASR errors during inference time. To bridge the gap and make dialog models more robust to ASR errors, we leverage an ASR error simulator to inject noise into the error-free text data, and subsequently train the dialog models with the augmented data. Compared to other approaches for handling ASR errors, such as using ASR lattice or end-to-end methods, our data augmentation approach does not require any modification to the ASR or downstream dialog models; our approach also does not introduce any additional latency during inference time. We perform extensive experiments on benchmark data and show that our approach improves the performance of downstream dialog models in the presence of ASR errors, and it is particularly effective in the low-resource situations where there are constraints on model size or the training data is scarce."}}
{"id": "AtRSk4p5qbl", "cdate": 1600111141592, "mdate": null, "content": {"title": "Investigation of Error Simulation Techniques for Learning Dialog Policies for Conversational Error Recovery", "abstract": "Training dialog policies for speech-based virtual assistants requires a plethora of conversational data.  The data collection phase is often expensive and time consuming due to human involvement. To address this issue, a common solution is to build user simulators for data generation. For the successful deployment of the trained policies into real world domains, it is vital that the user simulator mimics realistic conditions. In particular, speech-based assistants are heavily affected by automatic speech recognition and language understanding errors, hence the user simulator should be able to simulate similar errors. In this paper, we review the existing error simulation methods that induce errors at audio, phoneme, text, or semantic level; and conduct detailed comparisons between the audio-level and text-level methods.  In the process, we improve the existing text-level method by introducing confidence score prediction and out-of-vocabulary word mapping.We also explore the impact of audio-level and text-level methods on learning a simple clarification dialog policy to recover from errors to provide insight on future improvement for both approaches."}}
{"id": "HklLWLU5PB", "cdate": 1569510910417, "mdate": null, "content": {"title": "Expert recommendation based on social drivers, social network analysis, and semantic data representation", "abstract": "\n\nKnowledge networks and recommender systems are especially important for expert finding within organizations and scientific communities. Useful recommendation of experts, however, is not an easy task for many reasons: It requires reasoning about multiple complex networks from heterogeneous sources (such as collaboration networks of individuals, article citation networks, and concept networks) and depends significantly on the needs of individuals in seeking recommendations.\n\nAlthough over the past decade much effort has gone into developing techniques to increase and evaluate the quality of recommendations, personalizing recommendations according to individuals' motivations has not received much attention. While previous work in the literature has focused primarily on identifying experts, our focus here is on personalizing the selection of an expert through a principled application of social science theories to model the user's motivation. In this paper, we present an expert recommender system capable of applying multiple theoretical mechanisms to the problem of personalized recommendations through profiling users' motivations and their relations. To this end, we use the Multi-Theoretical Multi-Level (MTML) framework which investigates social drivers for network formation in the communities with diverse goals. This framework serves as the theoretical basis for mapping motivations to the appropriate domain data, heuristic, and objective functions for the personalized expert recommendation.\n\nAs a proof of concept, we developed a prototype recommender grounded in social science theories, and utilizing computational techniques from social network analysis and representational techniques from the semantic web to facilitate combining and operating on data from heterogeneous sources. We evaluated the prototype's ability to predict collaborations for scientific research teams, using a simple off-line methodology. Preliminary results demonstrate encouraging success while offering significant personalization options and providing flexibility in customizing the recommendation heuristic based on users' motivations. In particular, recommendation heuristics based on different motivation profiles result in different recommendations, and taken as a whole better capture the diversity of observed expert collaboration.\n"}}
{"id": "rye2sB89PB", "cdate": 1569510819687, "mdate": null, "content": {"title": "Semantic matchmaking for job recruitment: an ontology-based hybrid approach", "abstract": "Human Resources Management (HRM) is the strategic management of the employees, who individually and collectively contribute to the achievement of the strategic goals of an organization. Many HRM tasks are based on locating and matching individuals to positions. In this paper we present an ontology-based hybrid approach to effectively match job seekers and job postings. The approach uses a deductive model to determine the kind of match between a job seeker and a posting, and applies a similarity-based approach to rank applicants."}}
{"id": "rJgk_HI5wS", "cdate": 1569510759277, "mdate": null, "content": {"title": "Learning robust dialog policies in noisy environments", "abstract": "Modern virtual personal assistants provide a convenient interface for completing daily tasks via voice commands. An important consideration for these assistants is the ability to recover from automatic speech recognition (ASR) and natural language understanding (NLU) errors. In this paper, we focus on learning robust dialog policies to recover from these errors. To this end, we develop a user simulator which interacts with the assistant through voice commands in realistic scenarios with noisy audio, and use it to learn dialog policies through deep reinforcement learning. We show that dialogs generated by our simulator are indistinguishable from human generated dialogs, as determined by human evaluators. Furthermore, preliminary experimental results show that the learned policies in noisy environments achieve the same execution success rate with fewer dialog turns compared to fixed rule-based policies. "}}
