{"id": "iH2e1gIx6MJ", "cdate": 1677628800000, "mdate": 1696076649140, "content": {"title": "A Weakly Supervised-Guided Soft Attention Network for Classification of Intracranial Hemorrhage", "abstract": "Intracranial hemorrhage (ICH) classification from computed tomography (CT) scans is important for accurate diagnosis of stroke in emergency centers. However, it is challenged by low image contrast and the complex appearance of the lesion. Therefore, the diagnosis results may vary from doctor to doctor under different situations. Existing auxiliary diagnosis algorithms treat the features of each location as equally important, and they do not impose any constraints on the learned features. The learned features used for classification in the model contain noise or features that have no diagnostic significance, which greatly limits the performance and reliability of systems. To facilitate the ICH treatment, we propose to use the auxiliary weak-segmentation-label supervision in multiscale CNN to classify ICH lesions on brain CT images, where the ICH lesions are segmented and used to guide the attention of the classification network. The weak segmentation labels we use are generated by an unsupervised algorithm and do not require additional annotations. We conduct experiments on the RSNA ICH detection data set, and the results demonstrate that our method can achieve an average ACC of 98.1% and an average <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"> <tex-math notation=\"LaTeX\">$F1$ </tex-math></inline-formula> score of 74.6% on the test set of nearly 80 000 CT images. The proposed weakly supervised-guided attention mechanism can accurately activate those neurons related to diagnosis, while inhibiting the activation of irrelevant areas and noise, thus achieving good performance."}}
{"id": "zCx1dOKJhYt", "cdate": 1672531200000, "mdate": 1696076649550, "content": {"title": "An Adaptive Spatial-Temporal Local Feature Difference Method for Infrared Small-moving Target Detection", "abstract": "Detecting small moving targets accurately in infrared (IR) image sequences is a significant challenge. To address this problem, we propose a novel method called spatial-temporal local feature difference (STLFD) with adaptive background suppression (ABS). Our approach utilizes filters in the spatial and temporal domains and performs pixel-level ABS on the output to enhance the contrast between the target and the background. The proposed method comprises three steps. First, we obtain three temporal frame images based on the current frame image and extract two feature maps using the designed spatial domain and temporal domain filters. Next, we fuse the information of the spatial domain and temporal domain to produce the spatial-temporal feature maps and suppress noise using our pixel-level ABS module. Finally, we obtain the segmented binary map by applying a threshold. Our experimental results demonstrate that the proposed method outperforms existing state-of-the-art methods for infrared small-moving target detection."}}
{"id": "xFHYEIkdPyz", "cdate": 1672531200000, "mdate": 1696076649245, "content": {"title": "A Self-Training Framework Based on Multi-Scale Attention Fusion for Weakly Supervised Semantic Segmentation", "abstract": "Weakly supervised semantic segmentation (WSSS) based on image-level labels is challenging since it is hard to obtain complete semantic regions. To address this issue, we propose a self-training method that utilizes fused multi-scale class-aware attention maps. Our observation is that attention maps of different scales contain rich complementary information, especially for large and small objects. Therefore, we collect information from attention maps of different scales and obtain multi-scale attention maps. We then apply denoising and reactivation strategies to enhance the potential regions and reduce noisy areas. Finally, we use the refined attention maps to retrain the network. Experiments showthat our method enables the model to extract rich semantic information from multi-scale images and achieves 72.4% mIou scores on both the PASCAL VOC 2012 validation and test sets. The code is available at https://bupt-ai-cz.github.io/SMAF."}}
{"id": "vp_BdPF4mOBB", "cdate": 1672531200000, "mdate": 1696076649598, "content": {"title": "Breast Cancer Immunohistochemical Image Generation: a Benchmark Dataset and Challenge Review", "abstract": "For invasive breast cancer, immunohistochemical (IHC) techniques are often used to detect the expression level of human epidermal growth factor receptor-2 (HER2) in breast tissue to formulate a precise treatment plan. From the perspective of saving manpower, material and time costs, directly generating IHC-stained images from Hematoxylin and Eosin (H&E) stained images is a valuable research direction. Therefore, we held the breast cancer immunohistochemical image generation challenge, aiming to explore novel ideas of deep learning technology in pathological image generation and promote research in this field. The challenge provided registered H&E and IHC-stained image pairs, and participants were required to use these images to train a model that can directly generate IHC-stained images from corresponding H&E-stained images. We selected and reviewed the five highest-ranking methods based on their PSNR and SSIM metrics, while also providing overviews of the corresponding pipelines and implementations. In this paper, we further analyze the current limitations in the field of breast cancer immunohistochemical image generation and forecast the future development of this field. We hope that the released dataset and the challenge will inspire more scholars to jointly study higher-quality IHC-stained image generation."}}
{"id": "ZKZiCR2y4Sn", "cdate": 1672531200000, "mdate": 1696076649860, "content": {"title": "Sample Prior Guided Robust Model Learning to Suppress Noisy Labels", "abstract": "Imperfect labels are ubiquitous in real-world datasets and seriously harm the model performance. Several recent effective methods for handling noisy labels have two key steps: 1) dividing samples into cleanly labeled and wrongly labeled sets by training loss, 2) using semi-supervised methods to generate pseudo-labels for samples in the wrongly labeled set. However, current methods always hurt the informative hard samples due to the similar loss distribution between the hard samples and the noisy ones. In this paper, we proposed PGDF (Prior Guided Denoising Framework), a novel framework to learn a deep model to suppress noisy label by using the training history to generate the sample prior knowledge, which is integrated into both sample dividing step and semi-supervised step. Our framework can save more informative hard clean samples into the cleanly labeled set. Besides, our framework also promotes the quality of pseudo-labels during the semi-supervised step by suppressing the noise in the current pseudo-labels generating scheme. To further enhance the hard samples, we reweight the samples in the cleanly labeled set during training. We evaluated our method using synthetic datasets based on CIFAR-10 and CIFAR-100, as well as on the real-world datasets WebVision and Clothing1M. The results demonstrate substantial improvements over state-of-the-art methods. The code is available at https://github.com/bupt-ai-cz/PGDF ."}}
{"id": "VF4Vj6O5v1O", "cdate": 1672531200000, "mdate": 1696076649281, "content": {"title": "A Self-Training Framework Based on Multi-Scale Attention Fusion for Weakly Supervised Semantic Segmentation", "abstract": "Weakly supervised semantic segmentation (WSSS) based on image-level labels is challenging since it is hard to obtain complete semantic regions. To address this issue, we propose a self-training method that utilizes fused multi-scale class-aware attention maps. Our observation is that attention maps of different scales contain rich complementary information, especially for large and small objects. Therefore, we collect information from attention maps of different scales and obtain multi-scale attention maps. We then apply denoising and reactivation strategies to enhance the potential regions and reduce noisy areas. Finally, we use the refined attention maps to retrain the network. Experiments showthat our method enables the model to extract rich semantic information from multi-scale images and achieves 72.4% mIou scores on both the PASCAL VOC 2012 validation and test sets. The code is available at https://bupt-ai-cz.github.io/SMAF."}}
{"id": "OZyF2av__mbb", "cdate": 1672531200000, "mdate": 1696076649407, "content": {"title": "Hard-aware Instance Adaptive Self-training for Unsupervised Cross-domain Semantic Segmentation", "abstract": "The divergence between labeled training data and unlabeled testing data is a significant challenge for recent deep learning models. Unsupervised domain adaptation (UDA) attempts to solve such problem. Recent works show that self-training is a powerful approach to UDA. However, existing methods have difficulty in balancing the scalability and performance. In this paper, we propose a hard-aware instance adaptive self-training framework for UDA on the task of semantic segmentation. To effectively improve the quality and diversity of pseudo-labels, we develop a novel pseudo-label generation strategy with an instance adaptive selector. We further enrich the hard class pseudo-labels with inter-image information through a skillfully designed hard-aware pseudo-label augmentation. Besides, we propose the region-adaptive regularization to smooth the pseudo-label region and sharpen the non-pseudo-label region. For the non-pseudo-label region, consistency constraint is also constructed to introduce stronger supervision signals during model optimization. Our method is so concise and efficient that it is easy to be generalized to other UDA methods. Experiments on GTA5 to Cityscapes, SYNTHIA to Cityscapes, and Cityscapes to Oxford RobotCar demonstrate the superior performance of our approach compared with the state-of-the-art methods."}}
{"id": "NG_Nnlrn6t", "cdate": 1672531200000, "mdate": 1696076649306, "content": {"title": "RestNet: Boosting Cross-Domain Few-Shot Segmentation with Residual Transformation Network", "abstract": "Cross-domain few-shot segmentation (CD-FSS) aims to achieve semantic segmentation in previously unseen domains with a limited number of annotated samples. Although existing CD-FSS models focus on cross-domain feature transformation, relying exclusively on inter-domain knowledge transfer may lead to the loss of critical intra-domain information. To this end, we propose a novel residual transformation network (RestNet) that facilitates knowledge transfer while retaining the intra-domain support-query feature information. Specifically, we propose a Semantic Enhanced Anchor Transform (SEAT) module that maps features to a stable domain-agnostic space using advanced semantics. Additionally, an Intra-domain Residual Enhancement (IRE) module is designed to maintain the intra-domain representation of the original discriminant space in the new space. We also propose a mask prediction strategy based on prototype fusion to help the model gradually learn how to segment. Our RestNet can transfer cross-domain knowledge from both inter-domain and intra-domain without requiring additional fine-tuning. Extensive experiments on ISIC, Chest X-ray, and FSS-1000 show that our RestNet achieves state-of-the-art performance. Our code will be available soon."}}
{"id": "JLSrs5vVqlYH", "cdate": 1672531200000, "mdate": 1696076649831, "content": {"title": "Semi-supervised Domain Adaptation via Prototype-based Multi-level Learning", "abstract": "In semi-supervised domain adaptation (SSDA), a few labeled target samples of each class help the model to transfer knowledge representation from the fully labeled source domain to the target domain. Many existing methods ignore the benefits of making full use of the labeled target samples from multi-level. To make better use of this additional data, we propose a novel Prototype-based Multi-level Learning (ProML) framework to better tap the potential of labeled target samples. To achieve intra-domain adaptation, we first introduce a pseudo-label aggregation based on the intra-domain optimal transport to help the model align the feature distribution of unlabeled target samples and the prototype. At the inter-domain level, we propose a cross-domain alignment loss to help the model use the target prototype for cross-domain knowledge transfer. We further propose a dual consistency based on prototype similarity and linear classifier to promote discriminative learning of compact target feature representation at the batch level. Extensive experiments on three datasets, including DomainNet, VisDA2017, and Office-Home demonstrate that our proposed method achieves state-of-the-art performance in SSDA."}}
{"id": "ISO_K3Ost49", "cdate": 1672531200000, "mdate": 1696076649765, "content": {"title": "Semi-supervised Domain Adaptation via Prototype-based Multi-level Learning", "abstract": "In semi-supervised domain adaptation (SSDA), a few labeled target samples of each class help the model to transfer knowledge representation from the fully labeled source domain to the target domain. Many existing methods ignore the benefits of making full use of the labeled target samples from multi-level. To make better use of this additional data, we propose a novel Prototype-based Multi-level Learning (ProML) framework to better tap the potential of labeled target samples. To achieve intra-domain adaptation, we first introduce a pseudo-label aggregation based on the intra-domain optimal transport to help the model align the feature distribution of unlabeled target samples and the prototype. At the inter-domain level, we propose a cross-domain alignment loss to help the model use the target prototype for cross-domain knowledge transfer. We further propose a dual consistency based on prototype similarity and linear classifier to promote discriminative learning of compact target feature representation at the batch level. Extensive experiments on three datasets, including DomainNet, VisDA2017, and Office-Home, demonstrate that our proposed method achieves state-of-the-art performance in SSDA. Our code is available at https://github.com/bupt-ai-cz/ProML."}}
