{"id": "3Ps3hMmPUDZ", "cdate": 1672531200000, "mdate": 1682499878126, "content": {"title": "Image Quality Assessment for Magnetic Resonance Imaging", "abstract": "Image quality assessment (IQA) algorithms aim to reproduce the human\u2019s perception of the image quality. The growing popularity of image enhancement, generation, and recovery models instigated the development of many methods to assess their performance. However, most IQA solutions are designed to predict image quality in the general domain, with the applicability to specific areas, such as medical imaging, remaining questionable. Moreover, the selection of these IQA metrics for a specific task typically involves intentionally induced distortions, such as manually added noise or artificial blurring; yet, the chosen metrics are then used to judge the output of real-life computer vision models. In this work, we aspire to fill these gaps by carrying out the most extensive IQA evaluation study for Magnetic Resonance Imaging (MRI) to date (14,700 subjective scores). We use outputs of neural network models trained to solve problems relevant to MRI, including image reconstruction in the scan acceleration, motion correction, and denoising. Our emphasis is on reflecting the radiologist\u2019s perception of the reconstructed images, gauging the most diagnostically influential criteria for the quality of MRI scans: signal-to-noise ratio, contrast-to-noise ratio, and the presence of art efacts. Seven trained radiologists assess these distorted images, with their verdicts then correlated with 35 different image quality metrics (full-reference, no-reference, and distribution-based metrics considered). The top performers\u2013 DISTS, HaarPSI, VSI, and FIDVGG16\u2013 are found to be efficient across three proposed quality criteria, for all considered anatomies and the target tasks."}}
{"id": "za_50tJZTH", "cdate": 1640995200000, "mdate": 1668515763627, "content": {"title": "PyTorch Image Quality: Metrics for Image Quality Assessment", "abstract": "Image Quality Assessment (IQA) metrics are widely used to quantitatively estimate the extent of image degradation following some forming, restoring, transforming, or enhancing algorithms. We present PyTorch Image Quality (PIQ), a usability-centric library that contains the most popular modern IQA algorithms, guaranteed to be correctly implemented according to their original propositions and thoroughly verified. In this paper, we detail the principles behind the foundation of the library, describe the evaluation strategy that makes it reliable, provide the benchmarks that showcase the performance-time trade-offs, and underline the benefits of GPU acceleration given the library is used within the PyTorch backend. PyTorch Image Quality is an open source software: https://github.com/photosynthesis-team/piq/."}}
{"id": "y0PHYbRsWto", "cdate": 1640995200000, "mdate": 1682499878303, "content": {"title": "Feather-Light Fourier Domain Adaptation in Magnetic Resonance Imaging", "abstract": "Generalizability of deep learning models may be severely affected by the difference in the distributions of the train (source domain) and the test (target domain) sets, e.g., when the sets are produced by different hardware. As a consequence of this domain shift, a certain model might perform well on data from one clinic, and then fail when deployed in another. We propose a very light and transparent approach to perform test-time domain adaptation. The idea is to substitute the target low-frequency Fourier space components that are deemed to reflect the style of an image. To maximize the performance, we implement the \u201coptimal style donor\u201d selection technique, and use a number of source data points for altering a single target scan appearance (Multi-Source Transferring). We study the effect of severity of domain shift on the performance of the method, and show that our training-free approach reaches the state-of-the-art level of complicated deep domain adaptation models. The code for our experiments is released ( https://github.com/kechua/Feather-Light-Fourier-Domain-Adaptation/ )."}}
{"id": "wGB8Z3X0ggf", "cdate": 1640995200000, "mdate": 1682499878068, "content": {"title": "LAMBO: Landmarks Augmentation With Manifold-Barycentric Oversampling", "abstract": "We propose the first data augmentation method based on optimal transport theory, with the generated data being guaranteed to belong to the original data manifold. The proposed algorithm randomly samples a clique in the nearest-neighbors graph representing the data knowledge and computes the Wasserstein barycenter between the neighbours with random uniform weights. Being extremely natural-looking, many such barycenters are then produced iteratively to overpopulate the original dataset. We apply this approach to the problem of landmarks detection in unsupervised and semi-supervised scenarios in the popular tasks of face keypoints extraction, pose detection, and the segmentation of anatomical contours in medical imaging. The barycentric oversampling approach is shown to outperform state-of-the-art data augmentation methods. The code is available at <uri xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">https://github.com/cviaai/LAMBO/</uri> ."}}
{"id": "uL0qeE2g5n", "cdate": 1640995200000, "mdate": 1668515763415, "content": {"title": "Bi-directional Encoding for Explicit Centerline Segmentation by Fully-Convolutional Networks", "abstract": "Localization of tube-shaped objects is an important topic in medical imaging. Previously it was mainly addressed via dense segmentation that may produce inconsistent results for long and narrow objects. In our work, we propose a point-based approach for explicit centerline segmentation that can be learned by fully-convolutional networks. We propose a new bi-directional encoding scheme that does not require any autoregressive blocks and is robust to various shapes and orientations of lines, being adaptive to the number of points in their centerlines. We present extensive evaluation of our approach on synthetic and real data (chest x-ray and coronary angiography) and show its advantage over the state-of-the-art segmentation models."}}
{"id": "oNKbkeR7sR", "cdate": 1640995200000, "mdate": 1668515763440, "content": {"title": "Tubular shape aware data generation for segmentation in medical imaging", "abstract": "Purpose Chest X-ray is one of the most widespread examinations of the human body. In interventional radiology, its use is frequently associated with the need to visualize various tube-like objects, such as puncture needles, guiding sheaths, wires, and catheters. Detection and precise localization of these tube-like objects in the X-ray images are, therefore, of utmost value, catalyzing the development of accurate target-specific segmentation algorithms. Similar to the other medical imaging tasks, the manual pixel-wise annotation of the tubes is a resource-consuming process. Methods In this work, we aim to alleviate the lack of annotated images by using artificial data. Specifically, we present an approach for synthetic generation of the tube-shaped objects, with a generative adversarial network being regularized with a prior-shape constraint. Namely, our model uses Frangi-based regularization to draw synthetic tubes in the predefined fake mask regions and, then, uses the adversarial component to preserve the global realistic appearance of the synthesized image. Results Our method eliminates the need for the paired image\u2013mask data and requires only a weakly labeled dataset, with fine-tuning on a small paired sample (10\u201320 images) proving sufficient to reach the accuracy of the fully supervised models. Conclusion We report the applicability of the approach for the task of segmenting tubes and catheters in the X-ray images, whereas the results should also hold for the other acquisition modalities and image computing applications that contain tubular objects."}}
{"id": "nCv7qiFOx85", "cdate": 1640995200000, "mdate": 1668515763609, "content": {"title": "Optimal MRI Undersampling Patterns for Pathology Localization", "abstract": "We investigate MRI acceleration strategies for the benefit of downstream image analysis tasks. Specifically, we propose to optimize the k-space undersampling patterns according to how well a sought-after pathology could be segmented or localized in the reconstructed images. We study the effect of the proposed paradigm on the segmentation task using two classical labeled medical datasets, and on the task of pathology visualization within the bounding boxes, using the recently released fastMRI+ annotations. We demonstrate a noticeable improvement of the target metrics when the sampling pattern is optimized, e.g., for the segmentation problem at $$\\times $$ 16 acceleration, we report up to 12% improvement in Dice score over the other undersampling strategies."}}
{"id": "kEa2ppQ-3n-", "cdate": 1640995200000, "mdate": 1682499878077, "content": {"title": "Autofocusing+: Noise-Resilient Motion Correction in Magnetic Resonance Imaging", "abstract": "Image corruption by motion artifacts is an ingrained problem in Magnetic Resonance Imaging (MRI). In this work, we propose a neural network-based regularization term to enhance Autofocusing, a classic optimization-based method to remove motion artifacts. The method takes the best of both worlds: the optimization-based routine iteratively executes the blind demotion and deep learning-based prior penalizes for unrealistic restorations and speeds up the convergence. We validate the method on three models of motion trajectories, using synthetic and real noisy data. The method proves resilient to noise and anatomic structure variation, outperforming the state-of-the-art demotion methods."}}
{"id": "ef37xdco_bZ", "cdate": 1640995200000, "mdate": 1668515763599, "content": {"title": "Image Quality Assessment for Magnetic Resonance Imaging", "abstract": "Image quality assessment (IQA) algorithms aim to reproduce the human's perception of the image quality. The growing popularity of image enhancement, generation, and recovery models instigated the development of many methods to assess their performance. However, most IQA solutions are designed to predict image quality in the general domain, with the applicability to specific areas, such as medical imaging, remaining questionable. Moreover, the selection of these IQA metrics for a specific task typically involves intentionally induced distortions, such as manually added noise or artificial blurring; yet, the chosen metrics are then used to judge the output of real-life computer vision models. In this work, we aspire to fill these gaps by carrying out the most extensive IQA evaluation study for Magnetic Resonance Imaging (MRI) to date (14,700 subjective scores). We use outputs of neural network models trained to solve problems relevant to MRI, including image reconstruction in the scan acceleration, motion correction, and denoising. Our emphasis is on reflecting the radiologist's perception of the reconstructed images, gauging the most diagnostically influential criteria for the quality of MRI scans: signal-to-noise ratio, contrast-to-noise ratio, and the presence of artifacts. Seven trained radiologists assess these distorted images, with their verdicts then correlated with 35 different image quality metrics (full-reference, no-reference, and distribution-based metrics considered). The top performers -- DISTS, HaarPSI, VSI, and FID-VGG16 -- are found to be efficient across three proposed quality criteria, for all considered anatomies and the target tasks."}}
{"id": "coFOXjM2owi", "cdate": 1640995200000, "mdate": 1668515763470, "content": {"title": "Self-supervised Physics-based Denoising for Computed Tomography", "abstract": "Computed Tomography (CT) imposes risk on the patients due to its inherent X-ray radiation, stimulating the development of low-dose CT (LDCT) imaging methods. Lowering the radiation dose reduces the health risks but leads to noisier measurements, which decreases the tissue contrast and causes artifacts in CT images. Ultimately, these issues could affect the perception of medical personnel and could cause misdiagnosis. Modern deep learning noise suppression methods alleviate the challenge but require low-noise-high-noise CT image pairs for training, rarely collected in regular clinical workflows. In this work, we introduce a new self-supervised approach for CT denoising Noise2NoiseTD-ANM that can be trained without the high-dose CT projection ground truth images. Unlike previously proposed self-supervised techniques, the introduced method exploits the connections between the adjacent projections and the actual model of CT noise distribution. Such a combination allows for interpretable no-reference denoising using nothing but the original noisy LDCT projections. Our experiments with LDCT data demonstrate that the proposed method reaches the level of the fully supervised models, sometimes superseding them, easily generalizes to various noise levels, and outperforms state-of-the-art self-supervised denoising algorithms."}}
