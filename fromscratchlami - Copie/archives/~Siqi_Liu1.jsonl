{"id": "RczPtvlaXPH", "cdate": 1652737812948, "mdate": null, "content": {"title": "Turbocharging Solution Concepts: Solving NEs, CEs and CCEs with Neural Equilibrium Solvers", "abstract": "Solution concepts such as Nash Equilibria, Correlated Equilibria, and Coarse Correlated Equilibria are useful components for many multiagent machine learning algorithms. Unfortunately, solving a normal-form game could take prohibitive or non-deterministic time to converge, and could fail. We introduce the Neural Equilibrium Solver which utilizes a special equivariant neural network architecture to approximately solve the space of all games of fixed shape, buying speed and determinism. We define a flexible equilibrium selection framework, that is capable of uniquely selecting an equilibrium that minimizes relative entropy, or maximizes welfare. The network is trained without needing to generate any supervised training data. We show remarkable zero-shot generalization to larger games. We argue that such a network is a powerful component for many possible multiagent algorithms."}}
{"id": "ygRKSmIvtQo", "cdate": 1640995200000, "mdate": 1681559408543, "content": {"title": "Simplex Neural Population Learning: Any-Mixture Bayes-Optimality in Symmetric Zero-sum Games", "abstract": ""}}
{"id": "xemuiO1gbo", "cdate": 1640995200000, "mdate": 1682327585217, "content": {"title": "From motor control to team play in simulated humanoid football", "abstract": "Learning to combine control at the level of joint torques with longer-term goal-directed behavior is a long-standing challenge for physically embodied artificial agents. Intelligent behavior in the..."}}
{"id": "x12lm6d1YIg", "cdate": 1640995200000, "mdate": 1652721643868, "content": {"title": "NeuPL: Neural Population Learning", "abstract": "Learning in strategy games (e.g. StarCraft, poker) requires the discovery of diverse policies. This is often achieved by iteratively training new policies against existing ones, growing a policy population that is robust to exploit. This iterative approach suffers from two issues in real-world games: a) under finite budget, approximate best-response operators at each iteration needs truncating, resulting in under-trained good-responses populating the population; b) repeated learning of basic skills at each iteration is wasteful and becomes intractable in the presence of increasingly strong opponents. In this work, we propose Neural Population Learning (NeuPL) as a solution to both issues. NeuPL offers convergence guarantees to a population of best-responses under mild assumptions. By representing a population of policies within a single conditional model, NeuPL enables transfer learning across policies. Empirically, we show the generality, improved performance and efficiency of NeuPL across several test domains. Most interestingly, we show that novel strategies become more accessible, not less, as the neural population expands."}}
{"id": "btbL0aFqdV", "cdate": 1640995200000, "mdate": 1672765495286, "content": {"title": "Developing, evaluating and scaling learning agents in multi-agent environments", "abstract": ""}}
{"id": "WfYmWJ-Wri", "cdate": 1640995200000, "mdate": 1672765495339, "content": {"title": "Developing, Evaluating and Scaling Learning Agents in Multi-Agent Environments", "abstract": ""}}
{"id": "PCCgope9fUL", "cdate": 1640995200000, "mdate": 1683652081581, "content": {"title": "Turbocharging Solution Concepts: Solving NEs, CEs and CCEs with Neural Equilibrium Solvers", "abstract": "Solution concepts such as Nash Equilibria, Correlated Equilibria, and Coarse Correlated Equilibria are useful components for many multiagent machine learning algorithms. Unfortunately, solving a normal-form game could take prohibitive or non-deterministic time to converge, and could fail. We introduce the Neural Equilibrium Solver which utilizes a special equivariant neural network architecture to approximately solve the space of all games of fixed shape, buying speed and determinism. We define a flexible equilibrium selection framework, that is capable of uniquely selecting an equilibrium that minimizes relative entropy, or maximizes welfare. The network is trained without needing to generate any supervised training data. We show remarkable zero-shot generalization to larger games. We argue that such a network is a powerful component for many possible multiagent algorithms."}}
{"id": "NURMA3iNAf", "cdate": 1640995200000, "mdate": 1683652081571, "content": {"title": "NeuPL: Neural Population Learning", "abstract": "Learning in strategy games (e.g. StarCraft, poker) requires the discovery of diverse policies. This is often achieved by iteratively training new policies against existing ones, growing a policy population that is robust to exploit. This iterative approach suffers from two issues in real-world games: a) under finite budget, approximate best-response operators at each iteration needs truncating, resulting in under-trained good-responses populating the population; b) repeated learning of basic skills at each iteration is wasteful and becomes intractable in the presence of increasingly strong opponents. In this work, we propose Neural Population Learning (NeuPL) as a solution to both issues. NeuPL offers convergence guarantees to a population of best-responses under mild assumptions. By representing a population of policies within a single conditional model, NeuPL enables transfer learning across policies. Empirically, we show the generality, improved performance and efficiency of NeuPL across several test domains. Most interestingly, we show that novel strategies become more accessible, not less, as the neural population expands."}}
{"id": "J54hJd2GXC", "cdate": 1640995200000, "mdate": 1683652082869, "content": {"title": "Turbocharging Solution Concepts: Solving NEs, CEs and CCEs with Neural Equilibrium Solvers", "abstract": "Solution concepts such as Nash Equilibria, Correlated Equilibria, and Coarse Correlated Equilibria are useful components for many multiagent machine learning algorithms. Unfortunately, solving a normal-form game could take prohibitive or non-deterministic time to converge, and could fail. We introduce the Neural Equilibrium Solver which utilizes a special equivariant neural network architecture to approximately solve the space of all games of fixed shape, buying speed and determinism. We define a flexible equilibrium selection framework, that is capable of uniquely selecting an equilibrium that minimizes relative entropy, or maximizes welfare. The network is trained without needing to generate any supervised training data. We show remarkable zero-shot generalization to larger games. We argue that such a network is a powerful component for many possible multiagent algorithms."}}
{"id": "9zNVHEFzCxo", "cdate": 1640995200000, "mdate": 1681559408542, "content": {"title": "Simplex Neural Population Learning: Any-Mixture Bayes-Optimality in Symmetric Zero-sum Games", "abstract": ""}}
