{"id": "lttBTwHp58b", "cdate": 1672531200000, "mdate": 1681651628271, "content": {"title": "Rethinking Collaborative Metric Learning: Toward an Efficient Alternative Without Negative Sampling", "abstract": ""}}
{"id": "er4GR0wHWQO", "cdate": 1652737323031, "mdate": null, "content": {"title": "Asymptotically Unbiased Instance-wise Regularized Partial AUC Optimization: Theory and Algorithm", "abstract": "    The Partial Area Under the ROC Curve (PAUC), typically including One-way Partial AUC (OPAUC) and Two-way Partial AUC (TPAUC), measures the average performance of a binary classifier within a specific false positive rate and/or true positive rate interval, which is a widely adopted measure when decision constraints must be considered. Consequently, PAUC optimization has naturally attracted increasing attention in the machine learning community within the last few years. Nonetheless, most of the existing methods could only optimize PAUC approximately, leading to inevitable biases that are not controllable. Fortunately, a recent work presents an unbiased formulation of the PAUC optimization problem via distributional robust optimization. However, it is based on the pair-wise formulation of AUC, which suffers from the limited scalability w.r.t. sample size and a slow convergence rate, especially for TPAUC. To address this issue, we present a simpler reformulation of the problem in an asymptotically unbiased and instance-wise manner. For both OPAUC and TPAUC, we come to a nonconvex strongly concave min-max regularized problem of instance-wise functions. On top of this, we employ an efficient solver that enjoys a linear per-iteration computational complexity w.r.t. the sample size and a time-complexity of $O(\\epsilon^{-1/3})$ to reach a $\\epsilon$ stationary point. Furthermore, we find that the min-max reformulation also facilitates the theoretical analysis of generalization error as a byproduct. Compared with the existing results, we present new error bounds that are much easier to prove and could deal with hypotheses with real-valued outputs. Finally, extensive experiments on several benchmark datasets demonstrate the effectiveness of our method."}}
{"id": "xubxAVbOsw", "cdate": 1652737271707, "mdate": null, "content": {"title": "The Minority Matters: A Diversity-Promoting Collaborative Metric Learning Algorithm", "abstract": "Collaborative Metric Learning (CML) has recently emerged as a popular method in recommendation systems (RS), closing the gap between metric learning and Collaborative Filtering. Following the convention of RS, existing methods exploit unique user representation in their model design. This paper focuses on a challenging scenario where a user has multiple categories of interests. Under this setting, we argue that the unique user representation might induce preference bias, especially when the item category distribution is imbalanced. To address this issue, we propose a novel method called Diversity-Promoting Collaborative Metric Learning (DPCML), with the hope of considering the commonly ignored minority interest of the user. The key idea behind DPCML is to include a multiple set of representations for each user in the system. Based on this embedding paradigm, user preference toward an item is aggregated from different embeddings by taking the minimum item-user distance among the user embedding set. Furthermore, we observe that the diversity of the embeddings for the same user also plays an essential role in the model. To this end, we propose a diversity control regularization term to accommodate the multi-vector representation strategy better. Theoretically, we show that DPCML could generalize well to unseen test data by tackling the challenge of the annoying operation that comes from the minimum value. Experiments over a range of benchmark datasets speak to the efficacy of DPCML."}}
{"id": "q63m9be38Vh", "cdate": 1640995200000, "mdate": 1681651628328, "content": {"title": "AdAUC: End-to-end Adversarial AUC Optimization Against Long-tail Problems", "abstract": ""}}
{"id": "j7aMlbuwNW", "cdate": 1640995200000, "mdate": 1681651628351, "content": {"title": "Asymptotically Unbiased Instance-wise Regularized Partial AUC Optimization: Theory and Algorithm", "abstract": ""}}
{"id": "fdZOMzvY9I3", "cdate": 1640995200000, "mdate": 1681651628419, "content": {"title": "The Minority Matters: A Diversity-Promoting Collaborative Metric Learning Algorithm", "abstract": ""}}
{"id": "fUUlTh3ShXz", "cdate": 1640995200000, "mdate": 1681651628419, "content": {"title": "Optimizing Two-way Partial AUC with an End-to-end Framework", "abstract": ""}}
{"id": "X7GdsA1uM6k", "cdate": 1640995200000, "mdate": 1681651628282, "content": {"title": "Learning With Multiclass AUC: Theory and Algorithms", "abstract": ""}}
{"id": "SjSyQAe8__c", "cdate": 1640995200000, "mdate": 1681651628300, "content": {"title": "Rethinking Collaborative Metric Learning: Toward an Efficient Alternative without Negative Sampling", "abstract": ""}}
{"id": "MZR2oMt6Si", "cdate": 1640995200000, "mdate": 1681651628319, "content": {"title": "AdAUC: End-to-end Adversarial AUC Optimization Against Long-tail Problems", "abstract": ""}}
