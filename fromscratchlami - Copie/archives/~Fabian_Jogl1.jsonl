{"id": "Oq5mzL-3SUV", "cdate": 1655802924303, "mdate": null, "content": {"title": "Weisfeiler and Leman Return with Graph Transformations", "abstract": "We propose novel graph transformations that allow standard message passing to achieve state-of-the-art expressiveness and predictive performance. Message passing graph neural networks are known to have limited expressiveness in distinguishing graphs. To mitigate this, one can either change message passing or modify the graphs. Changing message passing is powerful but requires significant changes to existing implementations and cannot easily be combined with other approaches. Modifying the graph requires no changes to the learning algorithm and works directly with off-the-shelf implementations. In this paper, we propose novel graph transformations and compare them to the state-of-the-art. We prove that they are at least as expressive as corresponding message passing algorithms when combined with the Weisfeiler-Leman test or a sufficiently powerful graph neural network. Furthermore, we empirically demonstrate that these transformations lead to competitive results on molecular graph datasets."}}
{"id": "HKUxAE-J6lq", "cdate": 1646223669541, "mdate": null, "content": {"title": "Reducing Learning on Cell Complexes to Graphs", "abstract": "Message passing graph neural networks (GNNs) are known to have a limited expressiveness in distinguishing graphs. A recent approach tackles this problem by transforming graphs to regular cell complexes. This makes it possible to model higher-order structures and yields algorithms that are more powerful than the Weisfeiler Leman test (WL) or GNNs. However, this approach cannot easily be combined with previous graph algorithms and implementations due to their fundamental differences. We develop Cell Encoding, a novel approach of transforming regular cell complexes to graphs. We show that cell encoding combined with WL or a suitably expressive GNN is at least as expressive as Cellular Weisfeiler Leman (CWL) in distinguishing cell complexes. This means that with a simple preprocessing one can use any GNN for learning tasks on cell complexes. Additionally, we show that this approach can make GNNs more expressive and give better results on graph classification datasets."}}
{"id": "5WFNkhFjkn", "cdate": 1640995200000, "mdate": 1681483614675, "content": {"title": "Historian: A Large-Scale Historical Film Dataset with Cinematographic Annotation", "abstract": ""}}
{"id": "thlvWSSmEj", "cdate": 1609459200000, "mdate": 1681483614684, "content": {"title": "On (Coalitional) Exchange-Stable Matching", "abstract": ""}}
{"id": "H3xmAK72Y86", "cdate": 1609459200000, "mdate": 1681483614683, "content": {"title": "On (Coalitional) Exchange-Stable Matching", "abstract": ""}}
