{"id": "RBPvr4Ehojh", "cdate": 1663939398872, "mdate": null, "content": {"title": "Tackling Personalized Federated Learning with Label Concept Drift via Hierarchical Bayesian Modeling", "abstract": "Federated Learning (FL) is a distributed learning scheme to train a shared model across clients. One fundamental challenge in FL is that the sets of data across clients could be non-identically distributed. Personalized Federated Learning (PFL) attempts to solve this challenge. Most methods in the literature of PFL focus on the data heterogeneity that clients differ in their label distributions. In this work, we focus on label concept drift which is a broad but relatively unexplored area. We present a general framework for PFL based on hierarchical Bayesian inference and propose a variational inference algorithm based on this framework. We demonstrate our methods through empirical studies on CIFAR100 and SUN397. Experimental results show our approach significantly outperforms the baselines when tackling the label concept drift across clients."}}
{"id": "06fUz_bJStS", "cdate": 1632875467586, "mdate": null, "content": {"title": "Differentially Private SGD with Sparse Gradients", "abstract": "A large number of recent studies reveal that networks and their optimization updates contain information about potentially private training data. To protect sensitive training data, differential privacy has been adopted in deep learning to provide rigorously defined and measurable privacy. However, differentially private stochastic gradient descent (DP-SGD) requires the injection of an amount of noise that scales with the number of gradient dimensions, while neural networks typically contain millions of parameters.  As a result, networks trained with DP-SGD typically have large performance drops compared to non-private training. Recent works propose to first project gradients into a lower dimensional subspace, which is found by application of the power method, and then inject noise in this subspace. Although better performance has been achieved, the use of the power method leads to a significantly increased memory footprint by storing sample gradients, and more computational cost by projection. In this work, we mitigate these disadvantages through a sparse gradient representation. Specifically, we randomly freeze a progressively increasing subset of parameters, which results in sparse gradient updates while maintaining or increasing accuracy over differentially private baselines. Our experiment shows that we can reduce up to 40\\% of the gradient dimension while achieve the same performance within the same training epochs. Additionally, sparsity of the gradient updates is beneficial for decreasing communication overhead when deployed in collaborative training, e.g. federated learning. When we apply our approach across various DP-SGD frameworks, we maintain accuracy while achieve up to 70\\% representation sparsity, which proves that our approach is a safe and effective add-on to a variety of methods. We further notice that our approach leads to improvement in accuracy in particular for large networks. Importantly, the additional computational cost of our approach is negligible, and results in reduced computation during training due to lower computational cost in power method iterations."}}
{"id": "oS0bCAkczE", "cdate": 1609459200000, "mdate": 1668433925393, "content": {"title": "R-GAP: Recursive Gradient Attack on Privacy", "abstract": "Federated learning frameworks have been regarded as a promising approach to break the dilemma between demands on privacy and the promise of learning from large collections of distributed data. Many..."}}
{"id": "RSU17UoKfJF", "cdate": 1601308135729, "mdate": null, "content": {"title": "R-GAP: Recursive Gradient Attack on Privacy", "abstract": "Federated learning frameworks have been regarded as a promising approach to break the dilemma between demands on privacy and the promise of learning from large collections of distributed data. Many such frameworks only ask collaborators to share their local update of a common model, i.e. gradients with respect to locally stored data, instead of exposing their raw data to other collaborators. However, recent optimization-based gradient attacks show that raw data can often be accurately recovered from gradients. It has been shown that minimizing the Euclidean distance between true gradients and those calculated from estimated data is often effective in fully recovering private data. However, there is a fundamental lack of theoretical understanding of how and when gradients can lead to unique recovery of original data. Our research fills this gap by providing a closed-form recursive procedure to recover data from gradients in deep neural networks. We name it Recursive Gradient Attack on Privacy (R-GAP). Experimental results demonstrate that R-GAP  works as well as or even better than optimization-based approaches at a fraction of the computation under certain conditions. Additionally, we propose a Rank Analysis method, which can be used to estimate the risk of gradient attacks inherent in certain network architectures, regardless of whether an optimization-based or closed-form-recursive attack is used. Experimental results demonstrate the utility of the rank analysis towards improving the network's security. Source code is available for download from https://github.com/JunyiZhu-AI/R-GAP."}}
{"id": "_a-wNQ3_9d", "cdate": 1546300800000, "mdate": 1668433925414, "content": {"title": "Learning Path Tracking for Real Car-like Mobile Robots From Simulation", "abstract": "In this paper we propose a Reinforcement Learning (RL) algorithm for path tracking of a real car-like robot. The RL network is trained in simulation and then evaluated on a small racing car without modification. We provide a big number of training data during off-line simulation using a random path generator to cover different curvatures and initial positions, headings and velocities of the vehicle for the RL agent. Comparing to similar RL based algorithms, we utilize Convolutional Neural Network (CNN) as image embedder for estimating useful information about current and future position of the vehicle relative to the path. Evaluations for running the trained agent on the real car show that the RL agent can control the car smoothly and reduce the velocity adaptively to follow a sample track. We also compared the proposed approach with a conventional lateral controller and results show smoother maneuvers and smaller cross-track errors for the proposed algorithm."}}
{"id": "CpfOMwqYcSu", "cdate": 1546300800000, "mdate": 1668433925436, "content": {"title": "Localization in Aerial Imagery with Grid Maps using LocGAN", "abstract": "In this work, we present LocGAN, our localization approach based on a geo-referenced aerial imagery and LiDAR grid maps. Currently, most self-localization approaches relate the current sensor observations to a map generated from previously acquired data. Unfortunately, this data is not always available and the generated maps are usually sensor setup specific. Global Navigation Satellite Systems (GNSS) can overcome this problem. However, they are not always reliable especially in urban areas due to multi-path and shadowing effects. Since aerial imagery is usually available, we can use it as prior information. To match aerial images with grid maps, we use conditional Generative Adversarial Networks (cGANs) which transform aerial images to the grid map domain. The transformation between the predicted and measured grid map is estimated using a localization network (LocNet). Given the geo-referenced aerial image transformation the vehicle pose can be estimated. Evaluations performed on the data recorded in region Karlsruhe, Germany show that our LocGAN approach provides reliable global localization results."}}
