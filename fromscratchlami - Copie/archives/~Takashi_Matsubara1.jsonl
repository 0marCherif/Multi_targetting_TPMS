{"id": "sKnG2PjXMSX", "cdate": 1664194169336, "mdate": null, "content": {"title": "Nonlinear and Commutative Editing in Pretrained GAN Latent Space", "abstract": "Semantic editing of images is a fundamental goal of computer vision. While generative adversarial networks (GANs) are gaining attention for their ability to produce high-quality images, they do not provide an inherent way to edit images semantically. Recent studies have investigated how to manipulate the latent variable to determine the images to be generated. However, methods that assume linear semantic arithmetic have limitations in the quality of image editing. Also, methods that discover nonlinear semantic pathways provide editing that is non-commutative, in other words, inconsistent when applied in different orders. This paper proposes a method for discovering semantic commutative vector fields. We theoretically demonstrate that thanks to commutativity, multiple editing along the vector fields depend only on the quantities of editing, not on the order of the editing. We also experimentally demonstrated that the nonlinear and commutative nature of editing provides higher quality editing than previous methods."}}
{"id": "tLScKVhcCR", "cdate": 1663849929821, "mdate": null, "content": {"title": "FINDE: Neural Differential Equations for Finding and Preserving Invariant Quantities", "abstract": "Many real-world dynamical systems are associated with first integrals (a.k.a. invariant quantities), which are quantities that remain unchanged over time. The discovery and understanding of first integrals are fundamental and important topics both in the natural sciences and in industrial applications. First integrals arise from the conservation laws of system energy, momentum, and mass, and from constraints on states; these are typically related to specific geometric structures of the governing equations. Existing neural networks designed to ensure such first integrals have shown excellent accuracy in modeling from data. However, these models incorporate the underlying structures, and in most situations where neural networks learn unknown systems, these structures are also unknown. This limitation needs to be overcome for scientific discovery and modeling of unknown systems. To this end, we propose first integral-preserving neural differential equation (FINDE). By leveraging the projection method and the discrete gradient method, FINDE finds and preserves first integrals from data, even in the absence of prior knowledge about underlying structures. Experimental results demonstrate that FINDE can predict future states of target systems much longer and find various quantities consistent with well-known first integrals in a unified manner."}}
{"id": "xiDyUQrOtzA", "cdate": 1653752161305, "mdate": null, "content": {"title": "Toward Human Cognition-inspired High-Level Decision Making For Hierarchical Reinforcement Learning Agents", "abstract": "The ability of humans to efficiently understand and learn to solve complex tasks with relatively limited data is attributed to our hierarchically organized decision-making process.\nMeanwhile, sample efficiency is a long-standing challenge for reinforcement learning (RL) agents, especially in long-horizon, sequential decision-making tasks with sparse and delayed rewards.\nHierarchical reinforcement learning (HRL) augments RL agents with temporal abstraction to improve their efficiency in such complex tasks.\nHowever, the decision-making process of most HRL methods is often based directly on dense low-level information, while also using fixed temporal abstraction.\nWe propose the hierarchical world model (HWM), which is geared toward capturing more flexible high-level, temporally abstract dynamics, as well as low-level dynamics of the task.\nPreliminary experiments on using the HWM with model-based RL resulted in improved sample efficiency and final performance.\nAn investigation of the state representations learned by the HWM also shows their alignment with human intuition and understanding.\nFinally, we provide a theoretical foundation for integrating the proposed HWM with the HRL framework, thus building toward RL agents with hierarchically structured decision-making which aligns with the theorized principles of human cognition and decision process."}}
{"id": "xDaoT2zlJ0r", "cdate": 1652737492459, "mdate": null, "content": {"title": "FINDE: Neural Differential Equations for Finding and Preserving Invariant Quantities", "abstract": "Neural networks have shown promise for modeling dynamical systems from data. Recent models, such as Hamiltonian neural networks, have been designed to ensure known geometric structures of target systems and have shown excellent modeling accuracy. However, in most situations where neural networks learn unknown systems, their underlying structures are also unknown. Even in such cases, one can expect that target systems are associated with first integrals (a.k.a. invariant quantities), which are quantities remaining unchanged over time. First integrals come from the conservation laws of system energy, momentum, and mass, from constraints on states, and from other features of governing equations. By leveraging projection methods and discrete gradient methods, we propose first integral-preserving neural differential equations (FINDE). The proposed FINDE finds and preserves first integrals from data, even in the absence of prior knowledge about the underlying structures. Experimental results demonstrate that the proposed FINDE is able to predict future states of given systems much longer and find various quantities consistent with well-known first integrals of the systems in a unified manner."}}
{"id": "4h4oqp-ATxb", "cdate": 1621630138537, "mdate": null, "content": {"title": "Neural Symplectic Form: Learning Hamiltonian Equations on General Coordinate Systems", "abstract": "In recent years, substantial research on the methods for learning Hamiltonian equations has been conducted. Although these approaches are very promising, the commonly used representation of the Hamilton equation uses the generalized momenta, which are generally unknown. Therefore, the training data must be represented in this unknown coordinate system, and this causes difficulty in applying the model to real data. Meanwhile, Hamiltonian equations also have a coordinate-free expression that is expressed by using the symplectic 2-form. In this study, we propose a model that learns the symplectic form from data using neural networks, thereby providing a method for learning Hamiltonian equations from data represented in general coordinate systems, which are not limited to the generalized coordinates and the generalized momenta. Consequently, the proposed method is capable not only of modeling target equations of both Hamiltonian and Lagrangian formalisms but also of extracting unknown Hamiltonian structures hidden in the data. For example, many polynomial ordinary differential equations such as the Lotka-Volterra equation are known to admit non-trivial Hamiltonian structures, and our numerical experiments show that such structures can be certainly learned from data. Technically, each symplectic 2-form is associated with a skew-symmetric matrix, but not all skew-symmetric matrices define the symplectic 2-form. In the proposed method, using the fact that symplectic 2-forms are derived as the exterior derivative of certain differential 1-forms, we model the differential 1-form by neural networks, thereby improving the efficiency of learning."}}
{"id": "46J_l-cpc1W", "cdate": 1621629891507, "mdate": null, "content": {"title": "Symplectic Adjoint Method for Exact Gradient of Neural ODE with Minimal Memory", "abstract": "A neural network model of a differential equation, namely neural ODE, has enabled the learning of continuous-time dynamical systems and probabilistic distributions with high accuracy. The neural ODE uses the same network repeatedly during a numerical integration. The memory consumption of the backpropagation algorithm is proportional to the number of uses times the network size. This is true even if a checkpointing scheme divides the computation graph into sub-graphs. Otherwise, the adjoint method obtains a gradient by a numerical integration backward in time. Although this method consumes memory only for a single network use, it requires high computational cost to suppress numerical errors. This study proposes the symplectic adjoint method, which is an adjoint method solved by a symplectic integrator. The symplectic adjoint method obtains the exact gradient (up to rounding error) with memory proportional to the number of uses plus the network size. The experimental results demonstrate that the symplectic adjoint method consumes much less memory than the naive backpropagation algorithm and checkpointing schemes, performs faster than the adjoint method, and is more robust to rounding errors."}}
{"id": "u7P-ezlYvuC", "cdate": 1609459200000, "mdate": null, "content": {"title": "Target-Oriented Deformation of Visual-Semantic Embedding Space", "abstract": "Multimodal embedding is a crucial research topic for cross-modal understanding, data mining, and translation. Many studies have attempted to extract r \u2026"}}
{"id": "VDARCNjjNnL", "cdate": 1609459200000, "mdate": null, "content": {"title": "Deep Generative Model of Individual Variability in fMRI Images of Psychiatric Patients", "abstract": "Neuroimaging techniques, such as the resting-state functional magnetic resonance imaging (fMRI), have been investigated to find objective biomarkers of neuro-logical and psychiatric disorders. Objective biomarkers potentially provide a refined diagnosis and quantitative measurements of the effects of treatment. However, fMRI images are sensitive to individual variability, such as functional topography and personal attributes. Suppressing the irrelevant individual variability is crucial for finding objective biomarkers for multiple subjects. Herein, we propose a structured generative model based on deep learning (i.e., a deep generative model) that considers such individual variability. The proposed model builds a joint distribution of (preprocessed) fMRI images, state (with or without a disorder), and individual variability. It can thereby discriminate individual variability from the subject's state. Experimental results demonstrate that the proposed model can diagnose unknown subjects with greater accuracy than conventional approaches. Moreover, the diagnosis is fairer to gender and state, because the proposed model extracts subject attributes (age, gender, and scan site) in an unsupervised manner."}}
{"id": "ye-LLoM7LBD", "cdate": 1577836800000, "mdate": null, "content": {"title": "Deep State-Space Model for Noise Tolerant Skeleton-Based Action Recognition", "abstract": "Action recognition using skeleton data (3D coordinates of human joints) is an attractive topic due to its robustness to the actor's appearance, camera \u2026"}}
{"id": "iVMeQRf6x8S", "cdate": 1577836800000, "mdate": null, "content": {"title": "Hybrid of Reinforcement and Imitation Learning for Human-Like Agents", "abstract": "Reinforcement learning methods achieve performance superior to humans in a wide range of complex tasks and uncertain environments. However, high perfo \u2026"}}
