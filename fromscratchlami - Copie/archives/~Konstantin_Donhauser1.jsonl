{"id": "w_BTcHEs22", "cdate": 1672531200000, "mdate": 1683884110670, "content": {"title": "Strong inductive biases provably prevent harmless interpolation", "abstract": "Classical wisdom suggests that estimators should avoid fitting noise to achieve good generalization. In contrast, modern overparameterized models can yield small test error despite interpolating noise -- a phenomenon often called \"benign overfitting\" or \"harmless interpolation\". This paper argues that the degree to which interpolation is harmless hinges upon the strength of an estimator's inductive bias, i.e., how heavily the estimator favors solutions with a certain structure: while strong inductive biases prevent harmless interpolation, weak inductive biases can even require fitting noise to generalize well. Our main theoretical result establishes tight non-asymptotic bounds for high-dimensional kernel regression that reflect this phenomenon for convolutional kernels, where the filter size regulates the strength of the inductive bias. We further provide empirical evidence of the same behavior for deep neural networks with varying filter sizes and rotational invariance."}}
{"id": "lwfLmhMdNd2", "cdate": 1672531200000, "mdate": 1683882154242, "content": {"title": "Sample-efficient private data release for Lipschitz functions under sparsity assumptions", "abstract": "Differential privacy is the de facto standard for protecting privacy in a variety of applications. One of the key challenges is private data release, which is particularly relevant in scenarios where limited information about the desired statistics is available beforehand. Recent work has presented a differentially private data release algorithm that achieves optimal rates of order $n^{-1/d}$, with $n$ being the size of the dataset and $d$ being the dimension, for the worst-case error over all Lipschitz continuous statistics. This type of guarantee is desirable in many practical applications, as for instance it ensures that clusters present in the data are preserved. However, due to the \"slow\" rates, it is often infeasible in practice unless the dimension of the data is small. We demonstrate that these rates can be significantly improved to $n^{-1/s}$ when only guarantees over s-sparse Lipschitz continuous functions are required, or to $n^{-1/(s+1)}$ when the data lies on an unknown s-dimensional subspace, disregarding logarithmic factors. We therefore obtain practically meaningful rates for moderate constants $s$ which motivates future work on computationally efficient approximate algorithms for this~problem."}}
{"id": "f9LfAf6AAxP", "cdate": 1671878794275, "mdate": 1671878794275, "content": {"title": "Fast rates for noisy interpolation require rethinking the effects of inductive bias", "abstract": "Good generalization performance on high-dimensional data crucially hinges on a simple structure of the ground truth and a corresponding strong inductive bias of the estimator. Even though this intuition is valid for regularized models, in this paper we caution against a strong inductive bias for interpolation in the presence of noise: Our results suggest that, while a stronger inductive bias encourages a simpler structure that is more aligned with the ground truth, it also increases the detrimental effect of noise. Specifically, for both linear regression and classification with a sparse ground truth, we prove that minimum -norm and maximum -margin interpolators achieve fast polynomial rates up to order  for  compared to a logarithmic rate for . Finally, we provide experimental evidence that this trade-off may also play a crucial role in understanding non-linear interpolating models used in practice."}}
{"id": "7i6OZa7oij", "cdate": 1663850332600, "mdate": null, "content": {"title": "Strong inductive biases provably prevent harmless interpolation", "abstract": "Classical wisdom suggests that estimators should avoid fitting noise to achieve good generalization. In contrast, modern overparameterized models can yield small test error despite interpolating noise \u2014 a phenomenon often called \"benign overfitting\" or \"harmless interpolation\". This paper argues that the degree to which interpolation is harmless hinges upon the strength of an estimator's inductive bias, i.e., how heavily the estimator favors solutions with a certain structure: while strong inductive biases prevent harmless interpolation, weak inductive biases can even require fitting noise to generalize well. Our main theoretical result establishes tight non-asymptotic bounds for high-dimensional kernel regression that reflect this phenomenon for convolutional kernels, where the filter size regulates the strength of the inductive bias. We further provide empirical evidence of the same behavior for deep neural networks with varying filter sizes and rotational invariance."}}
{"id": "yRwQbly0BM", "cdate": 1640995200000, "mdate": 1683279213405, "content": {"title": "Tight bounds for minimum \u21131-norm interpolation of noisy data", "abstract": "We provide matching upper and lower bounds of order $\\sigma^2/\\log(d/n)$ for the prediction error of the minimum $\\ell_1$-norm interpolator, a.k.a. basis pursuit. Our result is tight up to negligible terms when $d \\gg n$, and is the first to imply asymptotic consistency of noisy minimum-norm interpolation for isotropic features and sparse ground truths. Our work complements the literature on \"benign overfitting\" for minimum $\\ell_2$-norm interpolation, where asymptotic consistency can be achieved only when the features are effectively low-dimensional."}}
{"id": "Li_8TwVTeT1", "cdate": 1640995200000, "mdate": 1652964310649, "content": {"title": "Fast rates for noisy interpolation require rethinking the effects of inductive bias", "abstract": "Good generalization performance on high-dimensional data crucially hinges on a simple structure of the ground truth and a corresponding strong inductive bias of the estimator. Even though this intuition is valid for regularized models, in this paper we caution against a strong inductive bias for interpolation in the presence of noise: Our results suggest that, while a stronger inductive bias encourages a simpler structure that is more aligned with the ground truth, it also increases the detrimental effect of noise. Specifically, for both linear regression and classification with a sparse ground truth, we prove that minimum $\\ell_p$-norm and maximum $\\ell_p$-margin interpolators achieve fast polynomial rates up to order $1/n$ for $p > 1$ compared to a logarithmic rate for $p = 1$. Finally, we provide experimental evidence that this trade-off may also play a crucial role in understanding non-linear interpolating models used in practice."}}
{"id": "GgnaAXSo--", "cdate": 1640995200000, "mdate": 1683794218932, "content": {"title": "Tight bounds for maximum \ud835\udcc11-margin classifiers", "abstract": "Popular iterative algorithms such as boosting methods and coordinate descent on linear models converge to the maximum $\\ell_1$-margin classifier, a.k.a. sparse hard-margin SVM, in high dimensional regimes where the data is linearly separable. Previous works consistently show that many estimators relying on the $\\ell_1$-norm achieve improved statistical rates for hard sparse ground truths. We show that surprisingly, this adaptivity does not apply to the maximum $\\ell_1$-margin classifier for a standard discriminative setting. In particular, for the noiseless setting, we prove tight upper and lower bounds for the prediction error that match existing rates of order $\\frac{\\|w^*\\|_1^{2/3}}{n^{1/3}}$ for general ground truths. To complete the picture, we show that when interpolating noisy observations, the error vanishes at a rate of order $\\frac{1}{\\sqrt{\\log(d/n)}}$. We are therefore first to show benign overfitting for the maximum $\\ell_1$-margin classifier."}}
{"id": "7iJoF8Ro0br", "cdate": 1640995200000, "mdate": 1683794218933, "content": {"title": "Fast rates for noisy interpolation require rethinking the effect of inductive bias", "abstract": "Good generalization performance on high-dimensional data crucially hinges on a simple structure of the ground truth and a corresponding strong inductive bias of the estimator. Even though this intu..."}}
{"id": "JbStfP5JMkK", "cdate": 1634050027350, "mdate": 1634050027350, "content": {"title": "How rotational invariance of common kernels prevents generalization in high dimensions", "abstract": "Kernel ridge regression is well-known to achieve minimax optimal rates in low-dimensional settings. However, its behavior in high dimensions is much less understood. Recent work establishes consistency for kernel regression under certain assumptions on the ground truth function and the distribution of the input data. In this paper, we show that the rotational invariance property of commonly studied kernels (such as RBF, inner product kernels and fully-connected NTK of any depth) induces a bias towards low-degree polynomials in high dimensions. Our result implies a lower bound on the generalization error for a wide range of distributions and various choices of the scaling for kernels with different eigenvalue decays. This lower bound suggests that general consistency results for kernel ridge regression in high dimensions require a more refined analysis that depends on the structure of the kernel beyond its eigenvalue decay."}}
{"id": "ujQKWaxFkrL", "cdate": 1624022587735, "mdate": null, "content": {"title": "Maximizing the robust margin provably overfits on noiseless data", "abstract": "Numerous recent works show that overparameterization implicitly reduces variance, suggesting vanishing benefits for explicit regularization in high dimensions. However, this narrative has been challenged by empirical observations indicating that adversarially trained deep neural networks suffer from robust overfitting. While existing explanations attribute this phenomenon  to noise or problematic samples in the training data set, we prove that even on entirely noiseless data, achieving a vanishing adversarial logistic training loss is suboptimal compared to regularized counterparts."}}
