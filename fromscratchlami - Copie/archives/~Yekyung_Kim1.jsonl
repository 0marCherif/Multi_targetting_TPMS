{"id": "npQZLt-YOu", "cdate": 1609459200000, "mdate": 1648909836368, "content": {"title": "Learning Sub-Character level representation for Korean Named Entity Recognition", "abstract": "Most of the previous studies on the Korean Named Entity Recognition (NER) topic focused on utilizing morphological-level information because the language is rich in character diversity. This paper illustrates an improved unigram-level Korean NER model with sub-character level representation, jamo, which can represent a unique linguistic structure of Korean and its syntactic properties and morphological variations. The experimental result shows that exploiting sub-character gives us a boost of + (avg) 2 F1, also, our proposed C-GRAM model outperformed about 3 F1 comparing with the baseline."}}
{"id": "mvG-xgXdP2_", "cdate": 1609459200000, "mdate": 1648909836369, "content": {"title": "LINDA: Unsupervised Learning to Interpolate in Natural Language Processing", "abstract": "Despite the success of mixup in data augmentation, its applicability to natural language processing (NLP) tasks has been limited due to the discrete and variable-length nature of natural languages. Recent studies have thus relied on domain-specific heuristics and manually crafted resources, such as dictionaries, in order to apply mixup in NLP. In this paper, we instead propose an unsupervised learning approach to text interpolation for the purpose of data augmentation, to which we refer as \"Learning to INterpolate for Data Augmentation\" (LINDA), that does not require any heuristics nor manually crafted resources but learns to interpolate between any pair of natural language sentences over a natural language manifold. After empirically demonstrating the LINDA's interpolation capability, we show that LINDA indeed allows us to seamlessly apply mixup in NLP and leads to better generalization in text classification both in-domain and out-of-domain."}}
{"id": "mSX5tCZrfA", "cdate": 1609459200000, "mdate": 1682317606870, "content": {"title": "Learning Sub-Character level representation for Korean Named Entity Recognition", "abstract": "Most of the previous studies on the Korean Named Entity Recognition (NER) topic focused on utilizing morphological-level information because the language is rich in character diversity. This paper illustrates an improved unigram-level Korean NER model with sub-character level representation, jamo, which can represent a unique linguistic structure of Korean and its syntactic properties and morphological variations. The experimental result shows that exploiting sub-character gives us a boost of + (avg) 2 F1, also, our proposed C-GRAM model outperformed about 3 F1 comparing with the baseline."}}
{"id": "A21oN-aT_u", "cdate": 1577836800000, "mdate": 1648909836369, "content": {"title": "Deep Active Learning for Sequence Labeling Based on Diversity and Uncertainty in Gradient", "abstract": "Recently, several studies have investigated active learning (AL) for natural language processing tasks to alleviate data dependency. However, for query selection, most of these studies mainly rely on uncertainty-based sampling, which generally does not exploit the structural information of the unlabeled data. This leads to a sampling bias in the batch active learning setting, which selects several samples at once. In this work, we demonstrate that the amount of labeled training data can be reduced using active learning when it incorporates both uncertainty and diversity in the sequence labeling task. We examined the effects of our sequence-based approach by selecting weighted diverse in the gradient embedding approach across multiple tasks, datasets, models, and consistently outperform classic uncertainty-based sampling and diversity-based sampling."}}
{"id": "0xBRnJv9MSk", "cdate": 1451606400000, "mdate": 1648909836368, "content": {"title": "Metrics for Electronic-Nursing-Record-Based Narratives: cross-sectional analysis", "abstract": "p> <b>Objectives</b>We aimed to determine the characteristics of quantitative metrics for nursing narratives documented in electronic nursing records and their association with hospital admission traits and diagnoses in a large data set not limited to specific patient events or hypotheses.</p> <p> <b>Methods</b>We collected 135,406,873 electronic, structured coded nursing narratives from 231,494 hospital admissions of patients discharged between 2008 and 2012 at a tertiary teaching institution that routinely uses an electronic health records system. The standardized number of nursing narratives (i.e., the total number of nursing narratives divided by the length of the hospital stay) was suggested to integrate the frequency and quantity of nursing documentation.</p> <p> <b>Results</b>The standardized number of nursing narratives was higher for patients aged \u2265 70 years (median = 30.2 narratives/day, interquartile range [IQR] = 24.0\u201339.4 narratives/day), long (\u2265 8 days) hospital stays (median = 34.6 narratives/day, IQR = 27.2\u201343.5 narratives/day), and hospital deaths (median = 59.1 narratives/day, IQR = 47.0\u201374.8 narratives/day). The standardized number of narratives was higher in \u201cpregnancy, childbirth, and puerperium\u201d (median = 46.5, IQR = 39.0\u201354.7) and \u201cdiseases of the circulatory system\u201d admissions (median = 35.7, IQR = 29.0\u201343.4).</p> <p> <b>Conclusions</b>Diverse hospital admissions can be consistently described with nursing-documentderived metrics for similar hospital admissions and diagnoses. Some areas of hospital admissions may have consistently increasing volumes of nursing documentation across years. Usability of electronic nursing document metrics for evaluating healthcare requires multiple aspects of hospital admissions to be considered.</p> <p> <b>Citation:</b> Kim K, Jeong S, Lee K, Park H-A, Min YH, Lee JY, Kim Y, Yoo S, Doh G, Ahn S. Metrics for electronicnursing-record-based narratives: cross-sectional analysis.</p>"}}
{"id": "Hy-5vL-d-r", "cdate": 1388534400000, "mdate": null, "content": {"title": "#nowplaying the future billboard: mining music listening behaviors of twitter users for hit song prediction", "abstract": "Microblogs are rich sources of information because they provide platforms for users to share their thoughts, news, information, activities, and so on. Twitter is one of the most popular microblogs. Twitter users often use hashtags to mark specific topics and to link them with related tweets. In this study, we investigate the relationship between the music listening behaviors of Twitter users and a popular music ranking service by comparing information extracted from tweets with music-related hashtags and the Billboard chart. We collect users' music listening behavior from Twitter using music-related hashtags (e.g., #nowplaying). We then build a predictive model to forecast the Billboard rankings and hit music. The results show that the numbers of daily tweets about a specific song and artist can be effectively used to predict Billboard rankings and hits. This research suggests that users' music listening behavior on Twitter is highly correlated with general music trends and could play an important role in understanding consumers' music consumption patterns. In addition, we believe that Twitter users' music listening behavior can be applied in the field of Music Information Retrieval (MIR)."}}
