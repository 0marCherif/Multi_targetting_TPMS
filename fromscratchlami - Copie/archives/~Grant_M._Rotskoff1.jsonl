{"id": "mvtooHbjOwx", "cdate": 1622637627110, "mdate": null, "content": {"title": "Efficient Bayesian Sampling Using Normalizing Flows to Assist Markov Chain Monte Carlo Methods", "abstract": "Normalizing flows can generate complex target distributions and thus show promise in many applications in Bayesian statistics as an alternative or complement to MCMC for sampling posteriors.\nSince no data set from the target posterior distribution is available beforehand, the flow is typically trained using the reverse Kullback-Leibler (KL) divergence that only requires samples from a base distribution. This strategy  may perform poorly when the posterior is complicated and hard to sample with an untrained normalizing flow. \nHere we explore a distinct training strategy, using the direct KL divergence as loss, in which samples from  the posterior are generated by (i) assisting a local MCMC algorithm on the posterior with a normalizing flow to accelerate its mixing rate and (ii) using the data generated this way to train the flow. \nThe method only requires a limited amount of \\textit{a~priori} input about the posterior, and can be used to estimate the evidence required for model validation, as we illustrate on  examples."}}
{"id": "zZwlJTxqhVQ", "cdate": 1609459200000, "mdate": 1682339734892, "content": {"title": "Active Importance Sampling for Variational Objectives Dominated by Rare Events: Consequences for Optimization and Generalization", "abstract": ""}}
{"id": "hDmY0zJ8c7", "cdate": 1609459200000, "mdate": 1682339734851, "content": {"title": "Efficient Bayesian Sampling Using Normalizing Flows to Assist Markov Chain Monte Carlo Methods", "abstract": ""}}
{"id": "erp8gStUOXP", "cdate": 1577836800000, "mdate": null, "content": {"title": "A Dynamical Central Limit Theorem for Shallow Neural Networks", "abstract": "Recent theoretical work has characterized the dynamics and convergence properties for wide shallow neural networks trained via gradient descent; the asymptotic regime in which the number of parameters tends towards infinity has been dubbed the \"mean-field\" limit. At initialization, the randomly sampled parameters lead to a deviation from the mean-field limit that is dictated by the classical central limit theorem (CLT). However, the dynamics of training introduces correlations among the parameters raising the question of how the fluctuations evolve during training. Here, we analyze the mean-field dynamics as a Wasserstein gradient flow and prove that the deviations from the mean-field evolution scaled by the width, in the width-asymptotic limit, remain bounded throughout training. This observation has implications for both the approximation rate and the generalization: the upper bound we obtain is controlled by a Monte-Carlo type resampling error, which importantly does not depend on dimension. We also relate the bound on the fluctuations to the total variation norm of the measure to which the dynamics converges, which in turn controls the generalization error."}}
{"id": "_ZH8iHlSxmT", "cdate": 1577836800000, "mdate": 1683504991820, "content": {"title": "A mean-field analysis of two-player zero-sum games", "abstract": "Finding Nash equilibria in two-player zero-sum continuous games is a central problem in machine learning, e.g. for training both GANs and robust models. The existence of pure Nash equilibria requires strong conditions which are not typically met in practice. Mixed Nash equilibria exist in greater generality and may be found using mirror descent. Yet this approach does not scale to high dimensions. To address this limitation, we parametrize mixed strategies as mixtures of particles, whose positions and weights are updated using gradient descent-ascent. We study this dynamics as an interacting gradient flow over measure spaces endowed with the Wasserstein-Fisher-Rao metric. We establish global convergence to an approximate equilibrium for the related Langevin gradient-ascent dynamic. We prove a law of large numbers that relates particle dynamics to mean-field dynamics. Our method identifies mixed equilibria in high dimensions and is demonstrably effective for training mixtures of GANs."}}
{"id": "GiN9JRarBB", "cdate": 1577836800000, "mdate": 1683504991805, "content": {"title": "A mean-field analysis of two-player zero-sum games", "abstract": "Finding Nash equilibria in two-player zero-sum continuous games is a central problem in machine learning, e.g. for training both GANs and robust models. The existence of pure Nash equilibria requires strong conditions which are not typically met in practice. Mixed Nash equilibria exist in greater generality and may be found using mirror descent. Yet this approach does not scale to high dimensions. To address this limitation, we parametrize mixed strategies as mixtures of particles, whose positions and weights are updated using gradient descent-ascent. We study this dynamics as an interacting gradient flow over measure spaces endowed with the Wasserstein-Fisher-Rao metric. We establish global convergence to an approximate equilibrium for the related Langevin gradient-ascent dynamic. We prove a law of large numbers that relates particle dynamics to mean-field dynamics. Our method identifies mixed equilibria in high dimensions and is demonstrably effective for training mixtures of GANs."}}
{"id": "BRraJqo3tM", "cdate": 1577836800000, "mdate": 1682339734982, "content": {"title": "A Dynamical Central Limit Theorem for Shallow Neural Networks", "abstract": ""}}
{"id": "4_c1e8ssLwu", "cdate": 1577836800000, "mdate": null, "content": {"title": "A mean-field analysis of two-player zero-sum games.", "abstract": "Finding Nash equilibria in two-player zero-sum continuous games is a central problem in machine learning, e.g. for training both GANs and robust models. The existence of pure Nash equilibria requires strong conditions which are not typically met in practice. Mixed Nash equilibria exist in greater generality and may be found using mirror descent. Yet this approach does not scale to high dimensions. To address this limitation, we parametrize mixed strategies as mixtures of particles, whose positions and weights are updated using gradient descent-ascent. We study this dynamics as an interacting gradient flow over measure spaces endowed with the Wasserstein-Fisher-Rao metric. We establish global convergence to an approximate equilibrium for the related Langevin gradient-ascent dynamic. We prove a law of large numbers that relates particle dynamics to mean-field dynamics. Our method identifies mixed equilibria in high dimensions and is demonstrably effective for training mixtures of GANs."}}
{"id": "r1NxhsWO-H", "cdate": 1546300800000, "mdate": null, "content": {"title": "Neuron birth-death dynamics accelerates gradient descent and converges asymptotically", "abstract": "Neural networks with a large number of parameters admit a mean-field description, which has recently served as a theoretical explanation for the favorable training properties of models with a large..."}}
{"id": "NNxvNG3fMOx", "cdate": 1546300800000, "mdate": null, "content": {"title": "Global convergence of neuron birth-death dynamics", "abstract": "Neural networks with a large number of parameters admit a mean-field description, which has recently served as a theoretical explanation for the favorable training properties of \"overparameterized\" models. In this regime, gradient descent obeys a deterministic partial differential equation (PDE) that converges to a globally optimal solution for networks with a single hidden layer under appropriate assumptions. In this work, we propose a non-local mass transport dynamics that leads to a modified PDE with the same minimizer. We implement this non-local dynamics as a stochastic neuronal birth-death process and we prove that it accelerates the rate of convergence in the mean-field limit. We subsequently realize this PDE with two classes of numerical schemes that converge to the mean-field equation, each of which can easily be implemented for neural networks with finite numbers of parameters. We illustrate our algorithms with two models to provide intuition for the mechanism through which convergence is accelerated."}}
