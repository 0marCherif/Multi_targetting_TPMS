{"id": "GMB-UN9F04U", "cdate": 1668734786594, "mdate": null, "content": {"title": "Certifiable Metric One Class Learning with adversarially trained Lipschitz Classifier", "abstract": "We propose a new Novelty Detection and One Class classifier, based on the smoothness properties of orthogonal neural network, and on the properties of Hinge Kantorovich Rubinstein (HKR) function. The classifier benefits from robustness certificates against $l2$-attacks thanks to the Lipschitz constraint, whilst the HKR loss allows to provably approximate the signed distance function to the boundary of the distribution: the normality score induces by the classifier has a meaningful interpretation in term of distance to the support. Finally, gradient steps in the input space allows free generation of samples from the one class in a fashion that reminds GAN or VAE."}}
{"id": "DjiABzuN9tl", "cdate": 1668028595792, "mdate": 1668028595792, "content": {"title": "Achieving robustness in classification using optimal transport with hinge regularization", "abstract": "Adversarial examples have pointed out Deep Neural Networks vulnerability to small local noise. It has been shown that constraining their Lipschitz constant should enhance robustness, but make them harder to learn with classical loss functions. We propose a new framework for binary classification, based on optimal transport, which integrates this Lipschitz constraint as a theoretical requirement. We propose to learn 1-Lipschitz networks using a new loss that is an hinge regularized version of the Kantorovich-Rubinstein dual formulation for the Wasserstein distance estimation. This loss function has a direct interpretation in terms of adversarial robustness together with certifiable robustness bound. We also prove that this hinge regularized version is still the dual formulation of an optimal transportation problem, and has a solution. We also establish several geometrical properties of this optimal solution, and extend the approach to multi-class problems. Experiments show that the proposed approach provides the expected guarantees in terms of robustness without any significant accuracy drop. The adversarial examples, on the proposed models, visibly and meaningfully change the input providing an explanation for the classification."}}
{"id": "BRIL0EFvTgc", "cdate": 1652737302951, "mdate": null, "content": {"title": "Pay attention to your loss : understanding misconceptions about Lipschitz neural networks", "abstract": "Lipschitz constrained networks have gathered considerable attention in the deep learning community, with usages ranging from Wasserstein distance estimation to the training of certifiably robust classifiers. However they remain commonly considered as less accurate, and their properties in learning are still not fully understood. In this paper we clarify the matter: when it comes to classification 1-Lipschitz neural networks enjoy several advantages over their unconstrained counterpart. First, we show that these networks are as accurate as classical ones, and can fit arbitrarily difficult boundaries. Then, relying on a robustness metric that reflects operational needs we characterize the most robust classifier: the WGAN discriminator. Next, we show that 1-Lipschitz neural networks generalize well under milder assumptions. Finally, we show that hyper-parameters of the loss are crucial for controlling the accuracy-robustness trade-off. We conclude that they exhibit appealing properties to pave the way toward provably accurate, and provably robust neural networks.    "}}
{"id": "BkeGPJrtwB", "cdate": 1569439577988, "mdate": null, "content": {"title": "Fairness with Wasserstein Adversarial Networks", "abstract": "Quantifying, enforcing and implementing fairness emerged as a major topic in machine learning. We investigate these questions in the context of deep learning. Our main algorithmic and theoretical tool is the computational estimation of similarities between probability, ``\\`a la Wasserstein'', using adversarial networks. This idea is flexible enough to investigate different fairness constrained learning tasks, which we model by specifying properties of the underlying data generative process. The first setting considers bias in the generative model which should be filtered out. The second model is related to the presence of nuisance variables in the observations producing an unwanted bias for the learning task.  For both models, we devise a learning algorithm based on approximation of Wasserstein distances using adversarial networks. We provide formal arguments describing the fairness enforcing properties of these algorithm in relation with the underlying fairness generative processes. Finally we perform experiments, both on synthetic and real world data, to demonstrate empirically the superiority of our approach compared to state of the art fairness algorithms as well as concurrent GAN type adversarial architectures based on Jensen divergence."}}
{"id": "rJWwMsbOWS", "cdate": 1420070400000, "mdate": null, "content": {"title": "Entropy evaluation based on confidence intervals of frequency estimates : Application to the learning of decision trees", "abstract": "Entropy gain is widely used for learning decision trees. However, as we go deeper downward the tree, the examples become rarer and the faithfulness of entropy decreases. Thus, misleading choices an..."}}
{"id": "B14vrQMuZH", "cdate": 1104537600000, "mdate": null, "content": {"title": "Coping with exceptions in multiclass ILP problems using possibilistic logic", "abstract": "The handling of exceptions in multiclass problems is a tricky issue in inductive logic programming (ILP). In this paper we propose a new formalization of the ILP problem which accounts for default reasoning, and is encoded with first-order possibilistic logic. We show that this formalization allows us to handle rules with exceptions, and to prevent an example to be classified in more than one class. The possibilistic logic view of ILP problem, can be easily handled at the algorithmic level as an optimization problem."}}
