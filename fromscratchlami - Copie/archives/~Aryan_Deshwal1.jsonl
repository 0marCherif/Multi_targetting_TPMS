{"id": "uKuZrFD2OV", "cdate": 1684350534549, "mdate": 1684350534549, "content": {"title": "Bayesian Optimization over High-Dimensional Combinatorial Spaces via Dictionary-based Embeddings", "abstract": "We consider the problem of optimizing expensive black-box functions over high-dimensional\ncombinatorial spaces which arises in many science, engineering, and ML applications. We use\nBayesian Optimization (BO) and propose a novel\nsurrogate modeling approach for efficiently handling a large number of binary and categorical\nparameters. The key idea is to select a number of discrete structures from the input space\n(the dictionary) and use them to define an ordinal embedding for high-dimensional combinatorial structures. This allows us to use existing Gaussian process models for continuous\nspaces. We develop a principled approach based\non binary wavelets to construct dictionaries for\nbinary spaces, and propose a randomized construction method that generalizes to categorical\nspaces. We provide theoretical justification to\nsupport the effectiveness of the dictionary-based\nembeddings. Our experiments on diverse realworld benchmarks demonstrate the effectiveness\nof our proposed surrogate modeling approach\nover state-of-the-art BO methods"}}
{"id": "uZ4TbGZji0", "cdate": 1683892467588, "mdate": 1683892467588, "content": {"title": "GAUCHE: A Library for Gaussian Processes in Chemistry", "abstract": "We introduce GAUCHE, a library for GAUssian processes in CHEmistry. Gaussian processes have long been a cornerstone of probabilistic machine learning, affording particular advantages for uncertainty quantification and Bayesian optimisation. Extending Gaussian processes to chemical representations, however, is nontrivial, necessitating kernels defined over structured inputs such as graphs, strings and bit vectors. By defining such kernels in GAUCHE, we seek to open the door to powerful tools for uncertainty quantification and Bayesian optimisation in chemistry. Motivated by scenarios frequently encountered in experimental chemistry, we showcase applications for GAUCHE in molecular discovery and chemical reaction optimisation. The codebase is made available at this https URL"}}
{"id": "fxHzZlo4dxe", "cdate": 1621630108080, "mdate": null, "content": {"title": "Combining Latent Space and Structured Kernels for Bayesian Optimization over Combinatorial Spaces", "abstract": "We consider the problem of optimizing combinatorial spaces (e.g., sequences, trees, and graphs) using expensive black-box function evaluations. For example, optimizing molecules for drug design using physical lab experiments. Bayesian optimization (BO) is an efficient framework for solving such problems by intelligently selecting the inputs with high utility guided by a learned surrogate model. A recent BO approach for combinatorial spaces is through a reduction to BO over continuous spaces by learning a latent representation of structures using deep generative models (DGMs). The selected input from the continuous space is decoded into a discrete structure for performing function evaluation. However, the surrogate model over the latent space only uses the information learned by the DGM, which may not have the desired inductive bias to approximate the target black-box function. To overcome this drawback, this paper proposes a principled approach referred as LADDER. The key idea is to define a novel structure-coupled kernel that explicitly integrates the structural information from decoded structures with the learned latent space representation for better surrogate modeling. Our experiments on real-world benchmarks show that LADDER significantly improves over the BO over latent space method, and performs better or similar to state-of-the-art methods."}}
{"id": "L0eW8G6J6D", "cdate": 1621630108080, "mdate": null, "content": {"title": "Combining Latent Space and Structured Kernels for Bayesian Optimization over Combinatorial Spaces", "abstract": "We consider the problem of optimizing combinatorial spaces (e.g., sequences, trees, and graphs) using expensive black-box function evaluations. For example, optimizing molecules for drug design using physical lab experiments. Bayesian optimization (BO) is an efficient framework for solving such problems by intelligently selecting the inputs with high utility guided by a learned surrogate model. A recent BO approach for combinatorial spaces is through a reduction to BO over continuous spaces by learning a latent representation of structures using deep generative models (DGMs). The selected input from the continuous space is decoded into a discrete structure for performing function evaluation. However, the surrogate model over the latent space only uses the information learned by the DGM, which may not have the desired inductive bias to approximate the target black-box function. To overcome this drawback, this paper proposes a principled approach referred as LADDER. The key idea is to define a novel structure-coupled kernel that explicitly integrates the structural information from decoded structures with the learned latent space representation for better surrogate modeling. Our experiments on real-world benchmarks show that LADDER significantly improves over the BO over latent space method, and performs better or similar to state-of-the-art methods."}}
{"id": "LNkZZKFkaOTN", "cdate": 1600120351488, "mdate": null, "content": {"title": "Max-value Entropy Search for Multi-Objective Bayesian Optimization", "abstract": "We consider the problem of multi-objective (MO) blackbox optimization using\nexpensive function evaluations, where the goal is to approximate the true pareto-set\nof solutions by minimizing the number of function evaluations. For example, in\nhardware design optimization, we need to find the designs that trade-off performance, energy, and area overhead using expensive computational simulations. In\nthis paper, we propose a novel approach referred as Max-value Entropy Search for\nMulti-objective Optimization (MESMO) to solve this problem. MESMO employs\nan output-space entropy based acquisition function to efficiently select the sequence\nof inputs for evaluation to quickly uncover high-quality pareto-set solutions. We\nalso provide theoretical analysis to characterize the efficacy of MESMO. Our\nexperiments on several synthetic and real-world benchmark problems show that\nMESMO consistently outperforms the state-of-the-art algorithms."}}
{"id": "MGy4a9VFm-j", "cdate": 1598658556497, "mdate": null, "content": {"title": "Scalable Combinatorial Bayesian Optimization with Tractable Statistical models", "abstract": "We study the problem of optimizing expensive blackbox functions over combinatorial spaces (e.g., sets, sequences, trees, and graphs). BOCS (Baptista and Poloczek, 2018) is a state-of-the-art Bayesian optimization method for tractable statistical models, which performs semi-definite programming based acquisition function optimization (AFO) to select the next structure for evaluation. Unfortunately, BOCS scales poorly for large number of binary and/or categorical variables. Based on recent advances in submodular relaxation (Ito and Fujimaki, 2016) for solving Binary Quadratic Programs, we study an approach referred as Parametrized Submodular Relaxation (PSR) towards the goal of improving the scalability and accuracy of solving AFO problems for BOCS model. PSR approach relies on two key ideas. First, reformulation of AFO problem as submodular relaxation with some unknown parameters, which can be solved efficiently using minimum graph cut algorithms. Second, construction of an optimization problem to estimate the unknown parameters with close approximation to the true objective. Experiments on diverse benchmark problems show significant improvements with PSR for BOCS model. "}}
{"id": "MfLIOtADUUk", "cdate": 1577836800000, "mdate": null, "content": {"title": "Design and Optimization of Energy-Accuracy Tradeoff Networks for Mobile Platforms via Pretrained Deep Models.", "abstract": "Many real-world edge applications including object detection, robotics, and smart health are enabled by deploying deep neural networks (DNNs) on energy-constrained mobile platforms. In this article, we propose a novel approach to trade off energy and accuracy of inference at runtime using a design space called Learning Energy Accuracy Tradeoff Networks (LEANets). The key idea behind LEANets is to design classifiers of increasing complexity using pretrained DNNs to perform input-specific adaptive inference. The accuracy and energy consumption of the adaptive inference scheme depends on a set of thresholds, one for each classifier. To determine the set of threshold vectors to achieve different energy and accuracy tradeoffs, we propose a novel multiobjective optimization approach. We can select the appropriate threshold vector at runtime based on the desired tradeoff. We perform experiments on multiple pretrained DNNs including ConvNet, VGG-16, and MobileNet using diverse image classification datasets. Our results show that we get up to a 50% gain in energy for negligible loss in accuracy, and optimized LEANets achieve significantly better energy and accuracy tradeoff when compared to a state-of-the-art method referred to as Slimmable neural networks."}}
{"id": "wCVlLdkVCAw", "cdate": 1546300800000, "mdate": null, "content": {"title": "Learning and Inference for Structured Prediction: A Unifying Perspective.", "abstract": "In a structured prediction problem, one needs to learn a predictor that, given a structured input, produces a structured object, such as a sequence, tree, or clustering output. Prototypical structured prediction tasks include part-of-speech tagging (predicting POS tag sequence for an input sentence) and semantic segmentation of images (predicting semantic labels for pixels of an input image). Unlike simple classification problems, here there is a need to assign values to multiple output variables accounting for the dependencies between them. Consequently, the prediction step itself (aka ``inference\" or ``decoding\") is computationally-expensive, and so is the learning process, that typically requires making predictions as part of it. The key learning and inference challenge is due to the exponential size of the structured output space and depend on its complexity. In this paper, we present a unifying perspective of the different frameworks that address structured prediction problems and compare them in terms of their strengths and weaknesses. We also discuss important research directions including integration of deep learning advances into structured prediction, and learning from weakly supervised signals and active querying to overcome the challenges of building structured predictors from small amount of labeled data."}}
{"id": "p9iCq8njVX8", "cdate": 1546300800000, "mdate": null, "content": {"title": "Taming extreme heterogeneity via machine learning based design of autonomous manycore systems.", "abstract": "To avoid rewriting software code for new computer architectures and to take advantage of the extreme heterogeneous processing, communication and storage technologies, there is an urgent need for determining the right amount and type of specialization while making a heterogeneous system as programmable and flexible as possible. To enable both programmability and flexibility in the heterogeneous computing era, we propose a novel complex network inspired model of computation and efficient optimization algorithms for determining the optimal degree of parallelization from old software code. This mathematical framework allows us to determine the required number and type of processing elements, the amount and type of deep memory hierarchy, and the degree of reconfiguration for the communication infrastructure, thus opening new avenues to performance and energy efficiency. Our framework enables heterogeneous manycore systems to autonomously adapt from traditional switching techniques to network coding strategies in order to sustain on-chip communication in the order of terabytes. While this new programming model enables the design of self-programmable autonomous heterogeneous manycore systems, a number of open challenges will be discussed."}}
{"id": "bjLuTG4FEZq", "cdate": 1546300800000, "mdate": null, "content": {"title": "MOOS: A Multi-Objective Design Space Exploration and Optimization Framework for NoC Enabled Manycore Systems.", "abstract": "The growing needs of emerging applications has posed significant challenges for the design of optimized manycore systems. Network-on-Chip (NoC) enables the integration of a large number of processing elements (PEs) in a single die. To design optimized manycore systems, we need to establish suitable trade-offs among multiple objectives including power, performance, and thermal. Therefore, we consider multi-objective design space exploration (MO-DSE) problems arising in the design of NoC-enabled manycore systems: placement of PEs and communication links to optimize two or more objectives (e.g., latency, energy, and throughput). Existing algorithms to solve MO-DSE problems suffer from scalability and accuracy challenges as size of the design space and the number of objectives grow. In this paper, we propose a novel framework referred as Multi-Objective Optimistic Search (MOOS) that performs adaptive design space exploration using a data-driven model to improve the speed and accuracy of multi-objective design optimization process. We apply MOOS to design both 3D heterogeneous and homogeneous manycore systems using Rodinia, PARSEC, and SPLASH2 benchmark suites. We demonstrate that MOOS improves the speed of finding solutions compared to state-of-the-art methods by up to 13X while uncovering designs that are up to 20% better in terms of NoC. The optimized 3D manycore systems improve the EDP up to 38% when compared to 3D mesh-based designs optimized for the placement of PEs."}}
