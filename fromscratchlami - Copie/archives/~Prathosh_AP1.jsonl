{"id": "Ye0E-P70gj-", "cdate": 1695553461426, "mdate": 1695553461426, "content": {"title": "Adversarial Approximate Inference for Speech to Electroglottograph Conversion", "abstract": "Speech produced by human vocal apparatus conveys\nsubstantial non-semantic information including the gender of the\nspeaker, voice quality, affective state, abnormalities in the vocal\napparatus etc. Such information is attributed to the properties\nof the voice source signal, which is usually estimated from the\nspeech signal. However, most of the source estimation techniques\ndepend heavily on the goodness of the model assumptions and\nare prone to noise. A popular alternative is to indirectly obtain\nthe source information through the Electroglottographic (EGG)\nsignal that measures the electrical admittance around the vocal\nfolds using dedicated hardware. In this paper, we address the\nproblem of estimating the EGG signal directly from the speech\nsignal, devoid of any hardware. Sampling from the intractable\nconditional distribution of the EGG signal given the speech\nsignal is accomplished through optimization of an evidence\nlower bound. This is constructed via minimization of the KL-\ndivergence between the true and the approximated posteriors\nof a latent variable learned using a deep neural auto-encoder\nthat serves an informative prior. We demonstrate the ef\ufb01cacy of\nthe method at generating the EGG signal by conducting several\nexperiments on datasets comprising multiple speakers, voice\nqualities, noise settings and speech pathologies. The proposed\nmethod is evaluated on many benchmark metrics and is found to\nagree with the gold standard while proving better than the state-\nof-the-art algorithms on a few tasks such as epoch extraction."}}
{"id": "XEBHPi6k_7R", "cdate": 1695553180279, "mdate": 1695553180279, "content": {"title": "Mode matching in GANs through latent space learning and inversion", "abstract": "Generative adversarial networks (GANs) have shown re-\nmarkable success in generation of unstructured data, such\nas, natural images. However, discovery and separation of\nmodes in the generated space, essential for several tasks\nbeyond naive data generation, is still a challenge. In this\npaper, we address the problem of imposing desired modal\nproperties on the generated space using a latent distribu-\ntion, engineered in accordance with the modal properties of\nthe true data distribution. This is achieved by training a la-\ntent space inversion network in tandem with the generative\nnetwork using a divergence loss. The latent space is made\nto follow a continuous multimodal distribution generated by\nreparameterization of a pair of continuous and discrete ran-\ndom variables. In addition, the modal priors of the latent\ndistribution are learned to match with the true data distri-\nbution using minimal-supervision with negligible increment\nin number of learnable parameters. We validate our method\non multiple tasks such as mode separation, conditional gen-\neration, and attribute discovery on multiple real world im-\nage datasets and demonstrate its ef\ufb01cacy over other state-\nof-the-art methods."}}
{"id": "EUcEfCpyFRd", "cdate": 1695552968800, "mdate": null, "content": {"title": "Detection of Glottal Closure Instants from Raw Speech using Convolutional Neural Networks", "abstract": "Glottal Closure Instants (GCIs) correspond to the temporal lo-\ncations of signi\ufb01cant excitation to the vocal tract occurring dur-\ning the production of voiced speech. GCI detection from speech\nsignals is a well-studied problem given its importance in speech\nprocessing. Most of the existing approaches for GCI detection\nadopt a two-stage approach (i) Transformation of speech signal\ninto a representative signal where GCIs are localized better, (ii)\nextraction of GCIs using the representative signal obtained in\n\ufb01rst stage. The former stage is accomplished using signal pro-\ncessing techniques based on the principles of speech produc-\ntion and the latter with heuristic-algorithms such as dynamic-\nprogramming and peak-picking. These methods are thus task-\nspeci\ufb01c and rely on the methods used for representative signal\nextraction. However in this paper, we formulate the GCI detec-\ntion problem from a representation learning perspective where\nappropriate representation is implicitly learned from the raw-\nspeech data samples. Speci\ufb01cally, GCI detection is cast as a su-\npervised multi-task learning problem solved using a deep con-\nvolutional neural network jointly optimizing a classi\ufb01cation and\nregression cost. The learning capability is demonstrated with\nseveral experiments on standard datasets. The results compare\nwell with the state-of- the-art algorithms while performing bet-\nter in the case of presence of real-world non-stationary noise."}}
{"id": "zQP6GI28t3J", "cdate": 1678827836307, "mdate": 1678827836307, "content": {"title": "Unsupervised Domain Adaptation for Semantic Segmentation of NIR Images Through Generative Latent Search", "abstract": "Segmentation of the pixels corresponding to human skin is an essential first step in multiple applications ranging from surveillance to heart-rate estimation from remote-photoplethysmography. However, the existing literature considers the problem only in the visible-range of the EM-spectrum which limits their utility in low or no light settings where the criticality of the application is higher. To alleviate this problem, we consider the problem of skin segmentation from the Near-infrared images. However, Deep learning based state-of-the-art segmentation techniques demands large amounts of labelled data that is unavailable for the current problem. Therefore we cast the skin segmentation problem as that of target-independent Unsupervised Domain Adaptation (UDA) where we use the data from the Red-channel of the visible-range to develop skin segmentation algorithm on NIR images. We propose a method for target-independent segmentation where the \u2018nearest-clone\u2019 of a target image in the source domain is searched and used as a proxy in the segmentation network trained only on the source domain. We prove the existence of \u2018nearest-clone\u2019 and propose a method to find it through an optimization algorithm over the latent space of a Deep generative model based on variational inference. We demonstrate the efficacy of the proposed method for NIR skin segmentation over the state-of-the-art UDA segmentation methods on the two newly created skin segmentation datasets in NIR domain despite not having access to the target NIR data. Additionally, we report state-of-the-art results for adaption from Synthia to Cityscapes which is a popular setting in Unsupervised Domain Adaptation for semantic segmentation. The code and datasets are available at https://github.com/ambekarsameer96/GLSS."}}
{"id": "yWf4wxAUcDo", "cdate": 1664928780591, "mdate": null, "content": {"title": "Few Shot Generative Domain Adaptation Via Inference-Stage Latent Learning in GANs", "abstract": "In this study, we adapt generative models trained on large source datasets to scarce target domains. We adapt a pre-trained Generative Adversarial Network (GAN) without retraining the generator, avoiding catastrophic forgetting and over-fitting. Starting from the observation that target images can be `embedded' onto the latent space of a pre-trained source-GAN, our method finds the latent code corresponding to the target domain on the source latent manifold. Optimizing a latent learner network during inference generates a novel target embedding that is supplied to the source-GAN generator to generate target samples. Our method, albeit simple, can be used to generate data from multiple target distributions using a generator trained on a single source distribution."}}
{"id": "sCYXJr3QJM8", "cdate": 1663850140572, "mdate": null, "content": {"title": "Few-shot Cross-domain Image Generation via Inference-time Latent-code Learning", "abstract": "In this work, our objective is to adapt a Deep generative model trained on a large-scale source dataset to multiple target domains with scarce data. Specifically, we focus on adapting a pre-trained Generative Adversarial Network (GAN) to a target domain without re-training the generator. Our method draws the motivation from the fact that out-of-distribution samples can be `embedded' onto the latent space of a pre-trained source-GAN. We propose to train a small latent-generation network during the inference stage, each time a  batch of target samples is to be generated. These target latent codes are fed to the source-generator to obtain  novel target samples. Despite using the same small set of target samples and the source generator, multiple independent training episodes of the latent-generation network results in the diversity of the generated target samples. Our method, albeit simple, can be used to generate data from multiple target distributions using a generator trained on a single source distribution. We demonstrate the efficacy of our surprisingly simple method in generating multiple target datasets with only a single source generator and a few target samples."}}
{"id": "TnphqXOCUOj", "cdate": 1609459200000, "mdate": null, "content": {"title": "Domain Generalization via Inference-time Label-Preserving Target Projections", "abstract": "Generalization of machine learning models trained on a set of source domains on unseen target domains with different statistics, is a challenging problem. While many approaches have been proposed to solve this problem, they only utilize source data during training but do not take advantage of the fact that a single target example is available at the time of inference. Motivated by this, we propose a method that effectively uses the target sample during inference beyond mere classification. Our method has three components - (i) A label-preserving feature or metric transformation on source data such that the source samples are clustered in accordance with their class irrespective of their domain (ii) A generative model trained on the these features (iii) A label-preserving projection of the target point on the source-feature manifold during inference via solving an optimization problem on the input space of the generative model using the learned metric. Finally, the projected target is used in the classifier. Since the projected target feature comes from the source manifold and has the same label as the real target by design, the classifier is expected to perform better on it than the true target. We demonstrate that our method outperforms the state-of-the-art Domain Generalization methods on multiple datasets and tasks."}}
{"id": "2o0do0p8vI5", "cdate": 1609459200000, "mdate": null, "content": {"title": "Neural Compound-Word (Sandhi) Generation and Splitting in Sanskrit Language", "abstract": "This paper describes neural network based approaches to the process of the formation and splitting of word-compounding, respectively known as the Sandhi and Vichchhed, in Sanskrit language. Sandhi is an important idea essential to morphological analysis of Sanskrit texts. Sandhi leads to word transformations at word boundaries. The rules of Sandhi formation are well defined but complex, sometimes optional and in some cases, require knowledge about the nature of the words being compounded. Sandhi split or Vichchhed is an even more difficult task given its non uniqueness and context dependence. In this work, we propose the route of formulating the problem as a sequence to sequence prediction task, using modern deep learning techniques. Being the first fully data driven technique, we demonstrate that our model has an accuracy better than the existing methods on multiple standard datasets, despite not using any additional lexical or morphological resources. The code is being made available at https://github.com/IITD-DataScience/Sandhi_Prakarana"}}
{"id": "s-tVtFdS5hY", "cdate": 1577836800000, "mdate": null, "content": {"title": "Target-Independent Domain Adaptation for WBC Classification using Generative Latent Search", "abstract": "Automating the classification of camera-obtained microscopic images of White Blood Cells (WBCs) and related cell subtypes has assumed importance since it aids the laborious manual process of review and diagnosis. Several State-Of-The-Art (SOTA) methods developed using Deep Convolutional Neural Networks suffer from the problem of domain shift - severe performance degradation when they are tested on data (target) obtained in a setting different from that of the training (source). The change in the target data might be caused by factors such as differences in camera/microscope types, lenses, lighting-conditions etc. This problem can potentially be solved using Unsupervised Domain Adaptation (UDA) techniques albeit standard algorithms presuppose the existence of a sufficient amount of unlabelled target data which is not always the case with medical images. In this paper, we propose a method for UDA that is devoid of the need for target data. Given a test image from the target data, we obtain its 'closest-clone' from the source data that is used as a proxy in the classifier. We prove the existence of such a clone given that infinite number of data points can be sampled from the source distribution. We propose a method in which a latent-variable generative model based on variational inference is used to simultaneously sample and find the 'closest-clone' from the source distribution through an optimization procedure in the latent space. We demonstrate the efficacy of the proposed method over several SOTA UDA methods for WBC classification on datasets captured using different imaging modalities under multiple settings."}}
{"id": "pUMZqENyEY7", "cdate": 1577836800000, "mdate": null, "content": {"title": "Effect of the Latent Structure on Clustering With GANs", "abstract": "Generative adversarial networks (GANs) have shown remarkable success in the generation of data from natural data manifolds such as images. In several scenarios, it is desirable that generated data is well-clustered, especially when there is severe class imbalance. In this paper, we focus on the problem of clustering in the generated space of GANs and uncover its relationship with the characteristics of the latent space. We derive from first principles, the necessary and sufficient conditions needed to achieve faithful clustering in the GAN framework: (i) presence of a multimodal latent space with adjustable priors, (ii) existence of a latent space inversion mechanism and, (iii) imposition of the desired cluster priors on the latent space. We also identify the GAN models in the literature that partially satisfy these conditions and demonstrate the importance of all the components required, through ablative studies on multiple real-world image datasets. Additionally, we describe a procedure to construct a multimodal latent space which facilitates learning of cluster priors with sparse supervision. Codes for our implementation is available at https://github.com/NEMGAN/NEMGAN-P."}}
