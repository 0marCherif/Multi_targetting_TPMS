{"id": "xLr0I_xYGAs", "cdate": 1663849834783, "mdate": null, "content": {"title": "The Devil is in the Wrongly-classified Samples: Towards Unified Open-set Recognition", "abstract": "Open-set Recognition (OSR) aims to identify test samples whose classes are not seen during the training process. Recently, Unified Open-set Recognition (UOSR) has been proposed to reject not only unknown samples but also known but wrongly classified samples, which tends to be more practical in real-world applications. In this paper, we deeply analyze the UOSR task under different training and evaluation settings to shed light on this promising research direction. For this purpose, we first evaluate the UOSR performance of several OSR methods and show a significant finding that the uncertainty distribution of almost all these methods is actually closer to the expectation of UOSR than OSR. We show that the reason lies in the known but wrongly classified samples, as their uncertainty distribution is extremely close to unknown samples rather than known and correctly classified samples. Second, we analyze how the two training settings of OSR (i.e., pre-training and outlier exposure) influence the UOSR. We find although they are both beneficial for distinguishing known and correctly classified samples from unknown samples, pre-training is also helpful for identifying known but wrongly classified samples while outlier exposure is not. In addition to different training settings, we also formulate a new evaluation setting for UOSR which is called few-shot UOSR, where only one or five samples per unknown class are available during evaluation to help identify unknown samples. We propose FS-KNNS for the few-shot UOSR to achieve state-of-the-art performance under all settings."}}
{"id": "lCGYC7pXWNQ", "cdate": 1652737492865, "mdate": null, "content": {"title": "Learning a Condensed Frame for Memory-Efficient Video Class-Incremental Learning", "abstract": "Recent incremental learning for action recognition usually  stores representative videos to mitigate catastrophic forgetting. However, only a few bulky videos can be stored due to the limited memory. To address this problem, we propose FrameMaker, a memory-efficient video class-incremental learning approach that learns to produce a condensed frame for each selected video. Specifically, FrameMaker is mainly composed of two crucial components: Frame Condensing and Instance-Specific Prompt. The former is to reduce the memory cost by preserving only one condensed frame instead of the whole video, while the latter aims to compensate the lost spatio-temporal details in the Frame Condensing stage. By this means, FrameMaker enables a remarkable reduction in memory but keep enough information that can be applied to following incremental tasks. Experimental results on multiple challenging benchmarks, i.e., HMDB51, UCF101 and Something-Something V2, demonstrate that FrameMaker can achieve better performance to recent advanced methods while consuming only 20% memory. Additionally, under the same memory consumption conditions, FrameMaker significantly outperforms existing state-of-the-arts by a convincing margin. "}}
{"id": "sb0TQsIJoO5", "cdate": 1640995200000, "mdate": 1668775161109, "content": {"title": "Learning a Condensed Frame for Memory-Efficient Video Class-Incremental Learning", "abstract": "Recent incremental learning for action recognition usually stores representative videos to mitigate catastrophic forgetting. However, only a few bulky videos can be stored due to the limited memory. To address this problem, we propose FrameMaker, a memory-efficient video class-incremental learning approach that learns to produce a condensed frame for each selected video. Specifically, FrameMaker is mainly composed of two crucial components: Frame Condensing and Instance-Specific Prompt. The former is to reduce the memory cost by preserving only one condensed frame instead of the whole video, while the latter aims to compensate the lost spatio-temporal details in the Frame Condensing stage. By this means, FrameMaker enables a remarkable reduction in memory but keep enough information that can be applied to following incremental tasks. Experimental results on multiple challenging benchmarks, i.e., HMDB51, UCF101 and Something-Something V2, demonstrate that FrameMaker can achieve better performance to recent advanced methods while consuming only 20% memory. Additionally, under the same memory consumption conditions, FrameMaker significantly outperforms existing state-of-the-arts by a convincing margin."}}
{"id": "A0Rr_SmVDuN", "cdate": 1640995200000, "mdate": 1668775161094, "content": {"title": "Open-world Semantic Segmentation for LIDAR Point Clouds", "abstract": "Current methods for LIDARWang, Michael Yu\u00a0semantic segmentation are not robust enough for real-world applications, e.g., autonomous driving, since it is closed-set and static. The closed-set assumption makes the network only able to output labels of trained classes, even for objects never seen before, while a static network cannot update its knowledge base according to what it has seen. Therefore, in this work, we propose the open-world semantic segmentation task for LIDAR point clouds, which aims to 1) identify both old and novel classes using open-set semantic segmentation, and 2) gradually incorporate novel objects into the existing knowledge base using incremental learning without forgetting old classes. For this purpose, we propose a REdundAncy cLassifier (REAL) framework to provide a general architecture for both the open-set semantic segmentation and incremental learning problems. The experimental results show that REAL can simultaneously achieves state-of-the-art performance in the open-set semantic segmentation task on the SemanticKITTI and nuScenes datasets, and alleviate the catastrophic forgetting problem with a large margin during incremental learning."}}
{"id": "y3HSBibti7", "cdate": 1609459200000, "mdate": 1668775161071, "content": {"title": "Deep Metric Learning for Open World Semantic Segmentation", "abstract": "Classical close-set semantic segmentation networks have limited ability to detect out-of-distribution (OOD) objects, which is important for safety-critical applications such as autonomous driving. Incrementally learning these OOD objects with few annotations is an ideal way to enlarge the knowledge base of the deep learning models. In this paper, we propose an open world semantic segmentation system that includes two modules: (1) an open-set semantic segmentation module to detect both in-distribution and OOD objects. (2) an incremental few-shot learning module to gradually incorporate those OOD objects into its existing knowledge base. This open world semantic segmentation system behaves like a human being, which is able to identify OOD objects and gradually learn them with corresponding supervision. We adopt the Deep Metric Learning Network (DMLNet) with contrastive clustering to implement open-set semantic segmentation. Compared to other open-set semantic segmentation methods, our DMLNet achieves state-of-the-art performance on three challenging open-set semantic segmentation datasets without using additional data or generative models. On this basis, two incremental few-shot learning methods are further proposed to progressively improve the DMLNet with the annotations of OOD objects."}}
{"id": "j6FOg9_hHV", "cdate": 1609459200000, "mdate": 1668775161116, "content": {"title": "Open-set 3D Object Detection", "abstract": ""}}
{"id": "blfnZLoGLN", "cdate": 1609459200000, "mdate": 1668775161116, "content": {"title": "BORM: Bayesian Object Relation Model for Indoor Scene Recognition", "abstract": ""}}
{"id": "1aFOkBehWe6", "cdate": 1609459200000, "mdate": 1668775161066, "content": {"title": "Conflicts between Likelihood and Knowledge Distillation in Task Incremental Learning for 3D Object Detection", "abstract": "In autonomous driving scenarios, edge cases require perception algorithms, like 3D object detection, to incrementally learn new data during a long term. To achieve it, previous methods seek help from knowledge distillation and recursively transfer knowledge from old models to new models. However, conflicts exist between the likelihood term and the distillation regularizer on both old and new knowledge. In this paper, we discuss the drawback of knowledge distillation in the task-incremental-learning scenario for 3D object detection and propose a New-Task-Aware Biased Sampling and Knowledge-Distillation-Aware Detection Loss to solve the conflicts. Based on the KITTI dataset, we thoroughly evaluate our proposed method from the aspects of both forward and backward transfer in the task incremental-learning scenario. A great margin of improvement on the whole task sequence (5.6 mAP) demonstrates the effectiveness of our proposed method."}}
