{"id": "eZLdhVUG1hg", "cdate": 1663850180987, "mdate": null, "content": {"title": "Mixed Federated Learning: Joint Decentralized and Centralized Learning", "abstract": "Federated learning (FL) enables learning from decentralized privacy-sensitive data, with computations on raw data confined to take place at edge clients.  This paper introduces mixed FL, which incorporates an additional loss term calculated at the coordinating server (while maintaining FL\u2019s private data restrictions). For example, additional datacenter data can be leveraged to jointly learn from centralized (datacenter) and decentralized (federated) training data and better match an expected inference data distribution.Mixed FL also enables offloading some intensive computations (e.g., embedding regularization) to the server, greatly reducing communication and client computation load.  For these and other mixed FL use cases, we present three algorithms: PARALLEL TRAINING, 1-WAY GRADIENT TRANSFER, and 2-WAY GRADIENT TRANSFER.  We perform extensive experiments of the algorithms on three tasks, demonstrating that mixed FL can blend training data to achieve an oracle\u2019s accuracy on an inference distribution, and can reduce communication and computation overhead by more than 90%. Finally, we state convergence bounds for all algorithms, and give intuition on the mixed FL problems best suited to each. The theory confirms our empirical observations of how the algorithms perform under different mixed FL problem settings."}}
{"id": "s73HWNEtOcE", "cdate": 1633790967885, "mdate": null, "content": {"title": "Jointly Learning from Decentralized (Federated) and Centralized Data to Mitigate Distribution Shift", "abstract": "With privacy as a motivation, Federated Learning (FL) is an increasingly used paradigm where learning takes place collectively on edge devices, each with a cache of user-generated training examples that remain resident on the local device. These on-device training examples are gathered in situ during the course of users\u2019 interactions with their devices, and thus are highly reflective of at least part of the inference data distribution. Yet a distribution shift may still exist; the on-device training examples may lack for some data inputs expected to be encountered at inference time. This paper proposes a way to mitigate this shift: selective usage of datacenter data, mixed in with FL. By mixing decentralized (federated) and centralized (datacenter) data, we can form an effective training data distribution that better matches the inference data distribution, resulting in more useful models while still meeting the private training data access constraints imposed by FL."}}
{"id": "SJgaRA4FPH", "cdate": 1569439445081, "mdate": null, "content": {"title": "Generative Models for Effective ML on Private, Decentralized Datasets", "abstract": "To improve real-world applications of machine learning, experienced modelers develop intuition about their datasets, their models, and how the two interact. Manual inspection of raw data\u2014of representative samples, of outliers, of misclassifications\u2014is an essential tool in a) identifying and fixing problems in the data, b) generating new modeling hypotheses,\nand c) assigning or refining human-provided labels. However, manual data inspection is risky for privacy-sensitive datasets, such as those representing the behavior of real-world individuals. Furthermore, manual data inspection is impossible in the increasingly important setting of federated learning, where raw examples are stored at the edge and the modeler may only access aggregated outputs such as metrics or model parameters. This paper demonstrates that generative models\u2014trained using federated methods and with formal differential privacy guarantees\u2014can be used effectively to debug data issues even\nwhen the data cannot be directly inspected. We explore these methods in applications to text with differentially private federated RNNs and to images using a novel algorithm for differentially private federated GANs."}}
