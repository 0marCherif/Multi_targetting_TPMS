{"id": "Xe0xcAW-xnP", "cdate": 1672531200000, "mdate": 1682322511683, "content": {"title": "Logical Expressiveness of Graph Neural Network for Knowledge Graph Reasoning", "abstract": "Graph Neural Networks (GNNs) have been recently introduced to learn from knowledge graph (KG) and achieved state-of-the-art performance in KG reasoning. However, a theoretical certification for their good empirical performance is still absent. Besides, while logic in KG is important for inductive and interpretable inference, existing GNN-based methods are just designed to fit data distributions with limited knowledge of their logical expressiveness. We propose to fill the above gap in this paper. Specifically, we theoretically analyze GNN from logical expressiveness and find out what kind of logical rules can be captured from KG. Our results first show that GNN can capture logical rules from graded modal logic, providing a new theoretical tool for analyzing the expressiveness of GNN for KG reasoning; and a query labeling trick makes it easier for GNN to capture logical rules, explaining why SOTA methods are mainly based on labeling trick. Finally, insights from our theory motivate the development of an entity labeling method for capturing difficult logical rules. Experimental results are consistent with our theoretical results and verify the effectiveness of our proposed method."}}
{"id": "k0_3CVJQ6rC", "cdate": 1640995200000, "mdate": 1682322511690, "content": {"title": "Fast and Provable Nonconvex Tensor RPCA", "abstract": "In this paper, we study nonconvex tensor robust principal component analysis (RPCA) based on the $t$-SVD. We first propose an alternating projection method, i.e., APT, which converges linearly to t..."}}
{"id": "A-Nvq7GEIw", "cdate": 1640995200000, "mdate": 1682322511785, "content": {"title": "Robust Low-Tubal-Rank Tensor Recovery From Binary Measurements", "abstract": "Low-rank tensor recovery (LRTR) is a natural extension of low-rank matrix recovery (LRMR) to high-dimensional arrays, which aims to reconstruct an underlying tensor <inline-formula><tex-math notation=\"LaTeX\">$\\boldsymbol{\\mathcal {X}}$</tex-math></inline-formula> from incomplete linear measurements <inline-formula><tex-math notation=\"LaTeX\">$\\mathfrak {M}(\\boldsymbol{\\mathcal {X}})$</tex-math></inline-formula> . However, LRTR ignores the error caused by quantization, limiting its application when the quantization is low-level. In this work, we take into account the impact of extreme quantization and suppose the quantizer degrades into a comparator that only acquires the signs of <inline-formula><tex-math notation=\"LaTeX\">$\\mathfrak {M}(\\boldsymbol{\\mathcal {X}})$</tex-math></inline-formula> . We still hope to recover <inline-formula><tex-math notation=\"LaTeX\">$\\boldsymbol{\\mathcal {X}}$</tex-math></inline-formula> from these binary measurements. Under the tensor Singular Value Decomposition (t-SVD) framework, two recovery methods are proposed\u2014the first is a tensor hard singular tube thresholding method; the second is a constrained tensor nuclear norm minimization method. These methods can recover a real <inline-formula><tex-math notation=\"LaTeX\">$n_1\\times n_2\\times n_3$</tex-math></inline-formula> tensor <inline-formula><tex-math notation=\"LaTeX\">$\\boldsymbol{\\mathcal {X}}$</tex-math></inline-formula> with tubal rank <inline-formula><tex-math notation=\"LaTeX\">$r$</tex-math></inline-formula> from <inline-formula><tex-math notation=\"LaTeX\">$m$</tex-math></inline-formula> random Gaussian binary measurements with errors decaying at a polynomial speed of the oversampling factor <inline-formula><tex-math notation=\"LaTeX\">$\\lambda :=m/((n_1+n_2)n_3r)$</tex-math></inline-formula> . To improve the convergence rate, we develop a new quantization scheme under which the convergence rate can be accelerated to an exponential function of <inline-formula><tex-math notation=\"LaTeX\">$\\lambda$</tex-math></inline-formula> . Numerical experiments verify our results, and the applications to real-world data demonstrate the promising performance of the proposed methods."}}
{"id": "xkE2qOwiJrM", "cdate": 1609459200000, "mdate": 1667906186338, "content": {"title": "Non-Convex Sparse Deviation Modeling Via Generative Models", "abstract": "In this paper, the generative model is used to introduce the structural properties of the signal to replace the common sparse hypothesis, and a non-convex compressed sensing sparse deviation model based on the generative model (\u2113 <inf xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">q</inf> -Gen) is proposed. By establishing \u2113 <inf xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">q</inf> variant of the restricted isometry property (q-RIP) and Set-Restricted Eigenvalue Condition (q-S-REC), the error upper bound of the optimal decoder is derived when the recovered signal is within the sparse deviation range of the generator. Furthermore, it is proved that the Gaussian matrix satisfying a certain number of measurements is sufficient to ensure a good recovery for the generating function with high probability. Finally, a series of experiments are carried out to verify the effectiveness and superiority of the \u2113 <inf xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">q</inf> -Gen model."}}
{"id": "2yZ6nA65aw", "cdate": 1609459200000, "mdate": 1682322511704, "content": {"title": "Effective Snapshot Compressive-Spectral Imaging via Deep Denoising and Total Variation Priors", "abstract": "Snapshot compressive imaging (SCI) is a new type of compressive imaging system that compresses multiple frames of images into a single snapshot measurement, which enjoys low cost, low bandwidth, and high-speed sensing rate. By applying the existing SCI methods to deal with hyperspectral images, however, could not fully exploit the underlying structures, and thereby demonstrate unsatisfactory reconstruction performance. To remedy such issue, this paper aims to propose a new effective method by taking advantage of two intrinsic priors of the hyperspectral images, namely deep image denoising and total variation (TV) priors. Specifically, we propose an optimization objective to utilize these two priors. By solving this optimization objective, our method is equivalent to incorporate a weighted FFDNet and a 2DTV or 3DTV denoiser into the plug-and-play framework. Extensive numerical experiments demonstrate the outperformance of the proposed method over several state-of-the-art alternatives. Additionally, we provide a detailed convergence analysis of the resulting plug-and-play algorithm under relatively weak conditions such as without using diminishing step sizes. The code is available at https://github.com/ucker/SCI-TV-FFDNet."}}
