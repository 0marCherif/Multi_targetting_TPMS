{"id": "blCpfjAeFkn", "cdate": 1663850104967, "mdate": null, "content": {"title": "Addressing High-dimensional Continuous Action Space via Decomposed Discrete Policy-Critic", "abstract": "Reinforcement learning (RL) methods for discrete action spaces like DQNs are being widely used in tasks such as Atari games. However, they encounter difficulties when addressing continuous control tasks, since discretizing continuous action space incurs the curse-of-dimensionality. To tackle continuous control tasks via discretized actions, we propose a decomposed discrete policy-critic (D2PC) architecture, which was inspired by multi-agent RL (MARL) and associates with each action dimension a discrete policy, while leveraging a single critic network to provide a shared evaluation. Building on D2PC, we advocate soft stochastic D2PC (SD2PC)  and deterministic D2PC (D3PC) methods with a discrete stochastic or deterministic policy, which show comparable or  superior training performances relative to even continuous actor-critic methods. Additionally, we design a mechanism that allows D3PC to interact with continuous actor-critic methods, contributing to the Q-policy-critic (QPC) algorithm, which inherits the training efficiency of discrete RL and the near-optimal final performance of continuous RL algorithms. Substantial experimental results on several continuous benchmark tasks validate our claims."}}
{"id": "UQmLmS6MvY1", "cdate": 1621684097297, "mdate": null, "content": {"title": "Finite-Time Analysis of Decentralized Temporal-Difference Learning with Linear Function Approximation", "abstract": "Motivated by the emerging use of multi-agent reinforcement learning (MARL) in various engineering applications, we investigate\nthe policy evaluation problem in a fully decentralized setting, using temporal-di\u21b5erence (TD) learning with linear function approximation to handle large state spaces in practice. The goal of a group of agents is to collaboratively learn the value function of a given policy from locally private rewards observed in a shared environment, through exchanging local estimates with neighbors. Despite their simplicity and widespread use, our theoretical understanding of such decentralized TD learning algorithms remains limited. Existing results were obtained based on i.i.d. data samples, or by imposing an \u2018additional\u2019 projection step to control the \u2018gradient\u2019 bias incurred by the Markovian observations. In this paper, we provide a finite-sample analysis of the fully decentralized TD(0) learning under both i.i.d. as well as Markovian samples, and prove that all local estimates converge linearly to a neighborhood of the optimum. The resultant error bounds are the first of its type\u2014in the sense that they hold under the most practical assumptions\u2014 which is made possible by means of a novel multi-step Lyapunov analysis."}}
{"id": "sO4tOk2lg9I", "cdate": 1621629854891, "mdate": null, "content": {"title": "Collaborative Uncertainty in Multi-Agent Trajectory Forecasting", "abstract": "Uncertainty modeling is critical in trajectory-forecasting systems for both interpretation and safety reasons. To better predict the future trajectories of multiple agents, recent works have introduced interaction modules to capture interactions among agents. This approach leads to correlations among the predicted trajectories. However, the uncertainty brought by such correlations is neglected. To fill this gap, we propose a novel concept, collaborative uncertainty (CU), which models the uncertainty resulting from the interaction module. We build a general CU-based framework to make a prediction model learn the future trajectory and the corresponding uncertainty. The CU-based framework is integrated as a plugin module to current state-of-the-art (SOTA) systems and deployed in two special cases based on multivariate Gaussian and Laplace distributions. In each case, we conduct extensive experiments on two synthetic datasets and two public, large-scale benchmarks of trajectory forecasting. The results are promising: 1) The results of synthetic datasets show that CU-based framework allows the model to nicely rebuild the ground-truth distribution. 2) The results of trajectory forecasting benchmarks demonstrate that the CU-based framework steadily helps SOTA systems improve their performances. Specially, the proposed CU-based framework helps VectorNet improve by 57 cm regarding Final Displacement Error on nuScenes dataset. 3) The visualization results of CU illustrate that the value of CU is highly related to the amount of the interactive information among agents."}}
{"id": "wh4aFUgCWdPm", "cdate": 1577836800000, "mdate": null, "content": {"title": "Wireless Power Transmitter Deployment for Balancing Fairness and Charging Service Quality.", "abstract": "Wireless energy transfer (WET) has recently emerged as an appealing solution for power supplying mobile/Internet of Things (IoT) devices. As an enabling WET technology, resonant beam charging (RBC) is well documented for its long-range, high-power, and safe \u201cWiFi-like\u201d mobile power supply. To provide high-quality wireless charging services for multiple users in a given region, we formulate a deployment problem of multiple RBC transmitters for balancing the charging fairness and quality of charging service. Based on the RBC transmitter's coverage model and receiver's charging/discharging model, a genetic algorithm (GA)-based scheme and a particle swarm optimization (PSO)-based scheme are put forth to resolve the above issue. Moreover, we present a scheduling method to evaluate the performance of the proposed algorithms. The numerical results corroborate that the optimized deployment schemes outperform uniform and random deployment in 10%-20% charging efficiency improvement."}}
{"id": "MXkqrKkvIlI", "cdate": 1577836800000, "mdate": null, "content": {"title": "Robust PSSE Using Graph Neural Networks for Data-driven and Topology-aware Priors.", "abstract": "Distributed renewable generation, elastic loads, and purposeful manipulation of meter readings challenge the monitoring and control of today's power systems (PS). In this context, to maintain a comprehensive view of the system in real time, fast and robust state estimation (SE) methods are urgently needed. Conventional PSSE solvers typically entail minimizing a nonlinear and nonconvex least-squares by e.g., the workhorse Gauss-Newton method. Those iterative solvers however, are sensitive to initialization and may get stuck in local minima. To overcome these hurdles and inspired by recent image denoising techniques, this paper advocates a learnable regularization term for PSSE that uses a deep neural network (DNN) prior. For the resultant regularized PSSE problem, a \"Gauss-Newton-like\" alternating minimization solver is first developed. To accommodate real-time monitoring, a novel end-to-end DNN is constructed by unrolling the proposed alternating minimization solver. Interestingly, the power network topology can be easily incorporated into the DNN by designing a graph neural network (GNN) based prior. To further endow the physics-based DNN with robustness against bad data, an adversarial DNN training method is discussed. Numerical tests using real load data on the IEEE $118$-bus benchmark system showcase the improved estimation and robustness performance of the proposed scheme compared with several state-of-the-art alternatives."}}
{"id": "z9QCMA8QJY0i", "cdate": 1546300800000, "mdate": null, "content": {"title": "Resonant Beam Communications: Principles and Designs.", "abstract": "Wireless optical communications (WOC) has carriers up to several hundred terahertz, which offers several advantages, such as ultrawide bandwidth and no electromagnetic interference. Conventional WOC technologies that use light transmitters such as light emitting diodes (LEDs), directed LEDs, and lasers are facing major challenges in attenuation or tracking. Resonant beam communications (RBCom) meets the requirements of low attenuation, non-mechanical mobility, and multiple access. However, RBCom channel undergoes echo interference in contrast to common non-echo channels. An interference elimination method based on optical filtering is presented along with an exemplary interference-free RBCom system."}}
{"id": "x0BaoLhLquLS", "cdate": 1546300800000, "mdate": null, "content": {"title": "Analytical Models for Resonant Beam Communications.", "abstract": "Light is expected to be utilized as carrier in future high-rate mobile communication systems. Relying on wireless optical channels, resonant beam communications (RBCom) has advantages such as high signal-to-noise ratio (SNR), mobility, and multiple access. However, the RBCom channel is different from other radio or optical wireless communication channels, as it undergoes echo interference. To eliminate the echo interference and preserve the beam resonance, frequency shifting and optical filtering are proposed. Moreover, an exemplary design is presented to demonstrate the unique RBCom procedure and its practical merits."}}
{"id": "vyhgOkQnLm8", "cdate": 1546300800000, "mdate": null, "content": {"title": "Multiview Canonical Correlation Analysis over Graphs.", "abstract": "Multiview canonical correlation analysis (MCCA) looks for shared low-dimensional representations hidden in multiple transformations of common source signals. Existing MCCA approaches do not exploit the geometry of common sources, which can be either given a priori, or constructed from do- main knowledge. In this paper, a novel graph-regularized (G) MCCA is developed to account for such geometry-bearing in- formation via graph regularization in the classical maximum- variance MCCA model. GMCCA minimizes the distance between the sought canonical variables and the common sources, while incorporating the graph-induced prior of these sources. To capture nonlinear dependencies, GMCCA is fur- ther broadened to the graph-regularized kernel (GK) MCCA. Numerical tests using real datasets document the merits of G(K)MCCA in comparison with competing alternatives."}}
{"id": "tEbplmelDK", "cdate": 1546300800000, "mdate": null, "content": {"title": "Two-Timescale Voltage Regulation in Distribution Grids Using Deep Reinforcement Learning.", "abstract": "Frequent and sizeable voltage fluctuations become more pronounced with the increasing penetration of distributed renewable generation, and they considerably challenge distribution grids. Voltage regulation schemes so far have relied on either utility-owned devices (e.g., voltage transformers, and shunt capacitors), or more recently, smart power inverters that come with contemporary distributed generation units (e.g., photovoltaic systems, and wind turbines). Nonetheless, due to the distinct response times of those devices, as well as the discrete on-off commitment of capacitor units, joint control of both types of assets is challenging. In this context, a novel two-timescale voltage regulation scheme is developed here by coupling optimization with reinforcement learning advances. Shunt capacitors are configured on a slow timescale (e.g., daily basis) leveraging a deep reinforcement learning algorithm, while optimal setpoints of the power inverters are computed using a linearized distribution flow model on a fast timescale (e.g., every few seconds or minutes). Numerical experiments using a real-world 47-bus distribution feeder showcase the remarkable performance of the novel scheme."}}
{"id": "myEQ0nIaF1mD", "cdate": 1546300800000, "mdate": null, "content": {"title": "Finite-Sample Analysis of Decentralized Temporal-Difference Learning with Linear Function Approximation.", "abstract": "Motivated by the emerging use of multi-agent reinforcement learning (MARL) in engineering applications such as networked robotics, swarming drones, and sensor networks, we investigate the policy evaluation problem in a fully decentralized setting, using temporal-difference (TD) learning with linear function approximation to handle large state spaces in practice. The goal of a group of agents is to collaboratively learn the value function of a given policy from locally private rewards observed in a shared environment, through exchanging local estimates with neighbors. Despite their simplicity and widespread use, our theoretical understanding of such decentralized TD learning algorithms remains limited. Existing results were obtained based on i.i.d. data samples, or by imposing an `additional' projection step to control the `gradient' bias incurred by the Markovian observations. In this paper, we provide a finite-sample analysis of the fully decentralized TD(0) learning under both i.i.d. as well as Markovian samples, and prove that all local estimates converge linearly to a small neighborhood of the optimum. The resultant error bounds are the first of its type---in the sense that they hold under the most practical assumptions ---which is made possible by means of a novel multi-step Lyapunov analysis."}}
