{"id": "e0h_kxBWJ84", "cdate": 1676827111267, "mdate": null, "content": {"title": "Robust Gaussian Process Regression with the Trimmed Marginal Likelihood", "abstract": "Accurate outlier detection is not only a necessary preprocessing step, but can itself give important insights into the data. However, especially, for non-linear regression the detection of outliers is non-trivial, and actually ambiguous. \nWe propose a new method that identifies outliers by finding a subset of data points $T$ such that the marginal likelihood of all remaining data points $S$ is maximized. Though the idea is more general, it is particular appealing for Gaussian processes regression, where the marginal likelihood has an analytic solution. While maximizing the marginal likelihood for hyper-parameter optimization is a well established non-convex optimization problem, optimizing the set of data points $S$ is not. Indeed, even a greedy approximation is computationally challenging due to the high cost of evaluating the marginal likelihood. \nAs a remedy, we propose an efficient projected gradient descent method with provable convergence guarantees. Moreover, we also establish the breakdown point when jointly optimizing hyper-parameters and $S$. For various datasets and types of outliers, our experiments demonstrate that the proposed method can improve outlier detection and robustness when compared with several popular alternatives like the student-t likelihood."}}
{"id": "GUSnecv1ApL", "cdate": 1609459200000, "mdate": 1682332926080, "content": {"title": "Adaptive covariate acquisition for minimizing total cost of classification", "abstract": "In some applications, acquiring covariates comes at a cost which is not negligible. For example in the medical domain, in order to classify whether a patient has diabetes or not, measuring glucose tolerance can be expensive. Assuming that the cost of each covariate, and the cost of misclassification can be specified by the user, our goal is to minimize the (expected) total cost of classification, i.e. the cost of misclassification plus the cost of the acquired covariates. We formalize this optimization goal using the (conditional) Bayes risk and describe the optimal solution using a recursive procedure. Since the procedure is computationally infeasible, we consequently introduce two assumptions: (1) the optimal classifier can be represented by a generalized additive model, (2) the optimal sets of covariates are limited to a sequence of sets of increasing size. We show that under these two assumptions, a computationally efficient solution exists. Furthermore, on several medical datasets, we show that the proposed method achieves in most situations the lowest total costs when compared to various previous methods. Finally, we weaken the requirement on the user to specify all misclassification costs by allowing the user to specify the minimally acceptable recall (target recall). Our experiments confirm that the proposed method achieves the target recall while minimizing the false discovery rate and the covariate acquisition costs better than previous methods."}}
{"id": "0UQHM2u88KR", "cdate": 1609459200000, "mdate": 1682332926114, "content": {"title": "Convex covariate clustering for classification", "abstract": ""}}
{"id": "z7-L6QbQr7_", "cdate": 1577836800000, "mdate": null, "content": {"title": "Robust Bayesian model selection for variable clustering with the Gaussian graphical model", "abstract": "Variable clustering is important for explanatory analysis. However, only few dedicated methods for variable clustering with the Gaussian graphical model have been proposed. Even more severe, small insignificant partial correlations due to noise can dramatically change the clustering result when evaluating for example with the Bayesian information criteria (BIC). In this work, we try to address this issue by proposing a Bayesian model that accounts for negligible small, but not necessarily zero, partial correlations. Based on our model, we propose to evaluate a variable clustering result using the marginal likelihood. To address the intractable calculation of the marginal likelihood, we propose two solutions: one based on a variational approximation and another based on MCMC. Experiments on simulated data show that the proposed method is similarly accurate as BIC in the no noise setting, but considerably more accurate when there are noisy partial correlations. Furthermore, on real data the proposed method provides clustering results that are intuitively sensible, which is not always the case when using BIC or its extensions."}}
{"id": "oQbdPPaIE_", "cdate": 1577836800000, "mdate": null, "content": {"title": "Adaptive Covariate Acquisition for Minimizing Total Cost of Classification", "abstract": "In some applications, acquiring covariates comes at a cost which is not negligible. For example in the medical domain, in order to classify whether a patient has diabetes or not, measuring glucose tolerance can be expensive. Assuming that the cost of each covariate, and the cost of misclassification can be specified by the user, our goal is to minimize the (expected) total cost of classification, i.e. the cost of misclassification plus the cost of the acquired covariates. We formalize this optimization goal using the (conditional) Bayes risk and describe the optimal solution using a recursive procedure. Since the procedure is computationally infeasible, we consequently introduce two assumptions: (1) the optimal classifier can be represented by a generalized additive model, (2) the optimal sets of covariates are limited to a sequence of sets of increasing size. We show that under these two assumptions, a computationally efficient solution exists. Furthermore, on several medical datasets, we show that the proposed method achieves in most situations the lowest total costs when compared to various previous methods. Finally, we weaken the requirement on the user to specify all misclassification costs by allowing the user to specify the minimally acceptable recall (target recall). Our experiments confirm that the proposed method achieves the target recall while minimizing the false discovery rate and the covariate acquisition costs better than previous methods."}}
{"id": "b30kGxqcxXz", "cdate": 1577836800000, "mdate": null, "content": {"title": "POSTER: Detecting Suspicious Processes from Log-Data via a Bayesian Block Model", "abstract": "Analyzing the behavior of an attacker is critical for determining the scope of damage of a cyber attack, recovering, and fixing system vulnerabilities. However, finding all attacker's traces from log data is a laborsome task, where the performance of existing machine learning methods is still insufficient. In this work, we focus on the task of detecting all processes that were executed by the attacker. For this task, standard anomaly detection methods like Isolation Forest, perform poorly, due to many processes that are used by both the attacker and the client user. Therefore, we propose to incorporate prior knowledge about the temporal concentration of the attacker's activity. In general, we expect that an attacker is active only during a relatively small time window (block assumption), rather than being active at completely random time points. We propose a generative model that allows us to incorporate such prior knowledge effectively. Experiments on intrusion log data, shows that the proposed method achieves considerably better detection performance than a strong baseline method which also incorporates the block assumption."}}
{"id": "TUpPmQdU7Fe", "cdate": 1546300800000, "mdate": null, "content": {"title": "Efficient Bayes Risk Estimation for Cost-Sensitive Classification", "abstract": "In some real world applications, acquiring covariates for classification can be cost-intensive and should be limited as much as possible. For example, in the medical setting, a doctor cannot just p..."}}
{"id": "FTgUCteFgW9", "cdate": 1546300800000, "mdate": null, "content": {"title": "Analysis of the Use of Background Distribution for Naive Bayes Classifiers", "abstract": "The naive Bayes classifier is a popular classifier, as it is easy to train, requires no cross-validation for parameter tuning, and can be easily extended due to its generative model. Moreover, recently it was shown that the word probabilities (background distribution) estimated from large unlabeled corpora could be used to improve the parameter estimation of naive Bayes. However, previous methods do not explicitly allow to control how much the background distribution can influence the estimation of naive Bayes parameters. In contrast, we investigate an extension of the graphical model of naive Bayes such that a word is either generated from a background distribution or from a class-specific word distribution. We theoretically analyze this model and show the connection to Jelinek-Mercer smoothing. Experiments using four standard text classification data sets show that the proposed method can statistically significantly outperform previous methods that use the same background distribution."}}
{"id": "6CXSVO-lf8N", "cdate": 1546300800000, "mdate": null, "content": {"title": "LARIISA: an intelligent platform to help decision makers in the brazilian health public system", "abstract": "LARIISA is an intelligent framework for decision-making in public health systems. The project had its initial ideas conceived in 2009. Since then it has evolved in the academic and market perspective, becoming a product in 2018 called GISSA. This article presents the architectural evolution of LARIISA, the functionalities implemented, the scientific and commercial results achieved with GISSA. Ontology and Data Mining (DM) are technologies that support their inference mechanisms. A semantic portal is proposed for GISSA and a DM application is presented."}}
{"id": "fnvvUbyoPxz", "cdate": 1514764800000, "mdate": null, "content": {"title": "Leveraging knowledge bases for future prediction with memory comparison networks", "abstract": "Making predictions about what might happen in the future is important for reacting adequately in many situations. For example, observing that \u201cMan kidnaps girl\u201d may have the consequence that \u201cMan kills girl\u201d. While this is part of common sense reasoning for humans, it is not obvious how machines can acquire and generalize over such knowledge. In this article, we propose a new type of memory network that can predict the next future event also for observations that are not in the knowledge base. We evaluate our proposed method on two knowledge bases: Reuters KB (events from news articles) and Regneri KB (events from scripts). For both knowledge bases, our proposed method shows similar or better prediction accuracy on unseen events (or scripts) than recently proposed deep neural networks and rankSVM. We also demonstrate that the attention mechanism of our proposed method can be helpful for error analysis and manual expansion of the knowledge base."}}
