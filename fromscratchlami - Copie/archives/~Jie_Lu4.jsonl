{"id": "-xfwSaifkU", "cdate": 1681833044435, "mdate": null, "content": {"title": "Indirect Functional Bayesian Neural Networks", "abstract": "Bayesian neural networks (BNNs) have made significant contributions in improving the robustness and uncertainty quantification of deep neural networks but suffer from problematic priors for network weights. We propose a new kind of indirect functional BNNs (IFBNN) by building a Wasserstein bridge, which consists of a 2-Wasserstein distance between the approximate posterior and a bridging distribution of network weights, and a 1-Wasserstein distance between the bridging distribution over functions induced by weight distributions and a functional GP prior. It can avoid the potential risks of invalid or infinite functional KL divergence commonly used by most existing functional BNNs. We demonstrate the improved extrapolation and predictive performances of the proposed IFBNN empirically on both synthetic and real-world datasets."}}
{"id": "9NzCUqU7i1", "cdate": 1663849869765, "mdate": null, "content": {"title": "Learning from Interval-valued Data", "abstract": "The classification problem concerning crisp-valued data has been well resolved. However, interval-valued data, where all of the observations\u2019 features are described by intervals, is also a common type of data in real-world scenarios. For example, the data extracted by many measuring devices are not exact numbers but intervals. In this paper, we focus on a highly challenging problem called learning from interval-valued data (LIND), where we aim to learn a classifier with high performance on interval-valued observations. First, we obtain the estimation error bound of the LIND problem based on Rademacher complexity. Then, we give the theoretical analysis to show the strengths of multi-view learning on classification problems, which inspires us to construct a new framework called multi-view interval information extraction (Mv-IIE) approach for improving classification accuracy on interval-valued data. The experiment comparisons with several baselines on both synthetic and real-world datasets illustrate the superiority of the proposed framework in handling interval-valued data. Moreover, we describe an application of the Mv-IIE framework that we can prevent data privacy leakage by transforming crisp-valued (raw) data into interval-valued data."}}
{"id": "sde_7ZzGXOE", "cdate": 1652737281608, "mdate": null, "content": {"title": "Is Out-of-Distribution Detection Learnable?", "abstract": "Supervised learning aims to train a classifier under the assumption that training and test data are from the same distribution. To ease the above assumption, researchers have studied a more realistic setting: out-of-distribution (OOD) detection, where test data may come from classes that are unknown during training (i.e., OOD data). Due to the unavailability and diversity of OOD data, good generalization ability is crucial for effective OOD detection algorithms. To study the generalization of OOD detection, in this paper, we investigate the probably approximately correct (PAC) learning theory of OOD detection, which is proposed by researchers as an open problem. First, we find a necessary condition for the learnability of OOD detection. Then, using this condition, we prove several impossibility theorems for the learnability of OOD detection under some scenarios. Although the impossibility theorems are frustrating, we find that some conditions of these impossibility theorems may not hold in some practical scenarios. Based on this observation, we next give several necessary and sufficient conditions to characterize the learnability of OOD detection in some practical scenarios. Lastly, we also offer theoretical supports for several representative OOD detection works based on our OOD theory."}}
{"id": "EUlAerrk47Y", "cdate": 1621629964396, "mdate": null, "content": {"title": "Meta Two-Sample Testing: Learning Kernels for Testing with Limited Data ", "abstract": "Modern kernel-based two-sample tests have shown great success in distinguishing complex, high-dimensional distributions by learning appropriate kernels (or, as a special case, classifiers). Previous work, however, has assumed that many samples are observed from both of the distributions being distinguished. In realistic scenarios with very limited numbers of data samples, it can be challenging to identify a kernel powerful enough to distinguish complex distributions. We address this issue by introducing the problem of meta two-sample testing (M2ST), which aims to exploit (abundant) auxiliary data on related tasks to find an algorithm that can quickly identify a powerful test on new target tasks. We propose two specific algorithms for this task: a generic scheme which improves over baselines, and a more tailored approach which performs even better. We provide both theoretical justification and empirical evidence that our proposed meta-testing schemes outperform learning kernel-based tests directly from scarce observations, and identify when such schemes will be successful."}}
{"id": "zgv6KLVWDpg", "cdate": 1609459200000, "mdate": null, "content": {"title": "PAC-Bayes Bounds for Meta-learning with Data-Dependent Prior", "abstract": "By leveraging experience from previous tasks, meta-learning algorithms can achieve effective fast adaptation ability when encountering new tasks. However it is unclear how the generalization property applies to new tasks. Probably approximately correct (PAC) Bayes bound theory provides a theoretical framework to analyze the generalization performance for meta-learning. We derive three novel generalisation error bounds for meta-learning based on PAC-Bayes relative entropy bound. Furthermore, using the empirical risk minimization (ERM) method, a PAC-Bayes bound for meta-learning with data-dependent prior is developed. Experiments illustrate that the proposed three PAC-Bayes bounds for meta-learning guarantee a competitive generalization performance guarantee, and the extended PAC-Bayes bound with data-dependent prior can achieve rapid convergence ability."}}
{"id": "vooe0IaCgv", "cdate": 1609459200000, "mdate": null, "content": {"title": "Multi-source transfer regression via source-target pairwise segment", "abstract": "Transfer learning addresses the problem of how to leverage acquired knowledge from a source domain to improve the learning efficiency and accuracy of the target domain that has insufficient labeled data. Instead of one source domain, multiple domains could be the source domains that are available for knowledge transfer in practice. However, there are large differences between the source and target domains, how to extract the useful knowledge from these different source domains remains a problem. To solve this problem, we propose a source-target pairwise segment method for multi-source transfer regression (STPS-MTR). The STPS-MTR method adaptively segments the different source domains and the target domain into different similar parts, and it extracts the most similar part in different source domains as the transfer knowledge. The STPS-MTR method can effectively extract the transfer knowledge from different source domains even when the source domain and the target domain have relatively low similarity, and it can avoid the negative influence between different source domains to ensure the transfer performance. Experimental results using synthetic datasets and real-world datasets demonstrate that the proposed method has better performance than existing methods, particularly when there are significant differences between different source domains and the target domain."}}
{"id": "tRS2vbqKWTj", "cdate": 1609459200000, "mdate": null, "content": {"title": "Domain-specific meta-embedding with latent semantic structures", "abstract": "Meta-embedding aims at assembling pre-trained embeddings from various sources and producing more expressively powerful word representations. Many natural language processing (NLP) tasks in a specific domain benefit from meta-embedding, especially when the task suffers from low resources. This paper proposes an unsupervised meta-embedding method that jointly models background knowledge from the source embeddings and domain-specific knowledge from the task domain. Specifically, embeddings from multiple sources for a word are dynamically aggregated to a single meta-embedding by a differentiable attention module. The embeddings derived from pre-training on a large-scale corpus provide complete background knowledge of word usage. Then, the meta-embedding is further enriched by exploring domain-specific knowledge from each task domain in two ways. First, contextual information in the raw corpus is considered to capture the semantics of words. Second, a graph representing domain-specific semantic structures is extracted from the raw corpus to highlight the relationships between salient words, then the graph is modeled by a powerful graph convolution network to effectively capture rich semantic structures among words in the task domain. Experiments conducted on two tasks, i.e., text classification and relation extraction, show that our model outputs more accurate word meta-embeddings for the task domain, compared to other state-of-the-art competitors. ."}}
{"id": "qFrIwehdMQ2", "cdate": 1609459200000, "mdate": null, "content": {"title": "A cross-domain recommender system through information transfer for medical diagnosis", "abstract": "Highlights \u2022 A new cross-domain recommender system is developed to support medical diagnoses with insufficient medical records. \u2022 A new dissimilarity measurement is constructed to measure the dissimilarities between diagnoses with interval numbers. \u2022 A space alignment method is designed to handle the mismatch of the different symptom spaces in two domains. \u2022 The proposed method alleviates data sparsity in medical diagnosis and provides personalized recommendation for physicians. Abstract The electronic diagnostic records of patients, primarily collected by hospitals, comprise valuable data for the development of recommender systems to support physicians in predicting the risks associated with various diseases. For some diseases, the diagnostic record data are not sufficient to train a prediction model to generate recommendations; this is referred to as the data sparsity problem. Cross-domain recommender systems offer a solution to this problem by transferring knowledge from a similar domain (source domain) with sufficient data for modeling to facilitate prediction in the current domain (target domain). However, building a cross-domain recommender system for medical diagnosis presents two challenges: (1) uncertain representations, such as the symptoms characterized by interval numbers, are often used in medical records, and (2) given two different diseases, the feature spaces of the two diagnostic domains are often disparate because the diseases are only likely to share a few symptoms. This study addresses these challenges by proposing a cross-domain recommender system, named information transfer for medical diagnosis (ITMD), to provide physicians with personalized recommendations for disease risks. In ITMD, a novel dissimilarity measurement was performed for diagnosis, represented as interval numbers. The space alignment technique eliminated the feature space divergence caused by different symptoms between two diseases, and the development of collective matrix factorization enabled knowledge transfer between the source and target domains. Experiments and a case study using real-world data demonstrated that ITMD outperforms four baselines and improves the accuracy of recommendations for disease risks in patients to support physicians in determining a final medical diagnosis."}}
{"id": "iuEoXmCbOT_", "cdate": 1609459200000, "mdate": null, "content": {"title": "How does the Combined Risk Affect the Performance of Unsupervised Domain Adaptation Approaches?", "abstract": "Unsupervised domain adaptation (UDA) aims to train a target classifier with labeled samples from the source domain and unlabeled samples from the target domain. Classical UDA learning bounds show that target risk is upper bounded by three terms: source risk, distribution discrepancy, and combined risk. Based on the assumption that the combined risk is a small fixed value, methods based on this bound train a target classifier by only minimizing estimators of the source risk and the distribution discrepancy. However, the combined risk may increase when minimizing both estimators, which makes the target risk uncontrollable. Hence the target classifier cannot achieve ideal performance if we fail to control the combined risk. To control the combined risk, the key challenge takes root in the unavailability of the labeled samples in the target domain. To address this key challenge, we propose a method named E-MixNet. E-MixNet employs enhanced mixup, a generic vicinal distribution, on the labeled source samples and pseudo-labeled target samples to calculate a proxy of the combined risk. Experiments show that the proxy can effectively curb the increase of the combined risk when minimizing the source risk and distribution discrepancy. Furthermore, we show that if the proxy of the combined risk is added into loss functions of four representative UDA methods, their performance is also improved."}}
{"id": "djTbu3pE7ZC", "cdate": 1609459200000, "mdate": null, "content": {"title": "A Mobile Telematics Pattern Recognition Framework for Driving Behavior Extraction", "abstract": "Mobile telematics is a relatively new innovation that involves collecting data on driving behavior using the internal sensors in a smartphone rather than from an in-vehicle data recorder. However, telematics data are usually not labeled, which makes extracting driving patterns from them very difficult. Therefore, unsupervised learning algorithms play an important role in this field. In addition, most current research is based on datasets developed in a laboratory or from site investigations and questionnaires, which are very different from real-world driving behaviors. To advance unsupervised learning techniques in this field, and to fill the gap in findings based on real-world data, we have developed an unsupervised pattern recognition framework for mobile telematics data. The framework comprises three main components: a self-organizing map, a nine-layers deep auto-encoder, and partitive clustering algorithms. The SOM algorithm reduces the complexity of the data, the deep auto-encoder extracts the features, and the clustering algorithm groups driving events with similar patterns into behaviors. Further, given clustering with mobile telematics data is an under-researched area, we undertook an empirical comparison of five well-known clustering algorithms to determine the strengths and weaknesses of each method and which is best suited to categorizing driving styles. The study was conducted with a real-world insurance dataset containing 500,000 journeys by 2500 drivers, and the results were evaluated against three measures- Davis Boulding, Calinski Harabasz, and execution time. Overall, we find that k-means clustering and a self-organizing map were able to extract more accurate patterns than others. A statistical analysis of the 29 clusters produced by SOM and k-means, revealed 29 unique driving styles, all of which can be found in the transportation literature. The results from the study, with support from the corresponding literature review, demonstrate the efficacy of the presented framework in unsupervised settings. Additionally, the results provide a basis for developing a future risk analysis and automatic decision support system for usage-based insurance companies."}}
