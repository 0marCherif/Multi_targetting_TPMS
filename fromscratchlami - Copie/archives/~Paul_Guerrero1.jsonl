{"id": "tS7V6DM8_6", "cdate": 1672531200000, "mdate": 1681652426162, "content": {"title": "Unsupervised 3D Shape Reconstruction by Part Retrieval and Assembly", "abstract": ""}}
{"id": "ISZzaJrt-C", "cdate": 1668606840615, "mdate": 1668606840615, "content": {"title": "The Shape Part Slot Machine: Contact-based Reasoning for Generating 3D Shapes from Parts", "abstract": "We present the Shape Part Slot Machine, a new method for assembling novel 3D shapes from existing parts by performing contact-based reasoning. Our method represents each shape as a graph of ``slots,'' where each slot is a region of contact between two shape parts. Based on this representation, we design a graph-neural-network-based model for generating new slot graphs and retrieving compatible parts, as well as a gradient-descent-based optimization scheme for assembling the retrieved parts into a complete shape that respects the generated slot graph. This approach does not require any semantic part labels; interestingly, it also does not require complete part geometries -- reasoning about the slots proves sufficient to generate novel, high-quality 3D shapes. We demonstrate that our method generates shapes that outperform existing modeling-by-assembly approaches regarding quality, diversity, and structural complexity."}}
{"id": "OsiUM0A4ITP", "cdate": 1668071237707, "mdate": 1668071237707, "content": {"title": "iMapper: interaction-guided scene mapping from monocular videos", "abstract": "Next generation smart and augmented reality systems demand a computational understanding of monocular footage that captures humans in physical spaces to reveal plausible object arrangements and human-object interactions. Despite recent advances, both in scene layout and human motion analysis, the above setting remains challenging to analyze due to regular occlusions that occur between objects and human motions. We observe that the interaction between object arrangements and human actions is often strongly correlated, and hence can be used to help recover from these occlusions. We present iMapper, a data-driven method to identify such human-object interactions and utilize them to infer layouts of occluded objects. Starting from a monocular video with detected 2D human joint positions that are potentially noisy and occluded, we first introduce the notion of interaction-saliency as space-time snapshots where informative human-object interactions happen. Then, we propose a global optimization to retrieve and fit interactions from a database to the detected salient interactions in order to best explain the input video. We extensively evaluate the approach, both quantitatively against manually annotated ground truth and through a user study, and demonstrate that iMapper produces plausible scene layouts for scenes with medium to heavy occlusion. Code and data are available on the project page."}}
{"id": "ZEQlaywmMID", "cdate": 1667674904927, "mdate": 1667674904927, "content": {"title": "Pix2surf: Learning parametric 3d surface models of objects from images", "abstract": "\nWe investigate the problem of learning to generate 3D parametric surface representations for novel object instances, as seen from one or more views. Previous work on learning shape reconstruction from multiple views uses discrete representations such as point clouds or voxels, while continuous surface generation approaches lack multi-view consistency. We address these issues by designing neural networks capable of generating high-quality parametric 3D surfaces which are also consistent between views. Furthermore, the generated 3D surfaces preserve accurate image pixel to 3D surface point correspondences, allowing us to lift texture information to reconstruct shapes with rich geometry and appearance. Our method is supervised and trained on a public dataset of shapes from common object categories. Quantitative results indicate that our method significantly outperforms previous work, while qualitative results demonstrate the high quality of our reconstructions."}}
{"id": "khF4d1SRrGH", "cdate": 1663849993763, "mdate": null, "content": {"title": "COFS: COntrollable Furniture layout Synthesis", "abstract": "Realistic, scalable, and controllable generation of furniture layouts is essential for many applications in virtual reality, augmented reality, game development and synthetic data generation. The most successful current methods tackle this problem as a sequence generation problem which imposes a specific ordering on the elements of the layout, making it hard to exert fine-grained control over the attributes of a generated scene. Existing methods provide control through object-level conditioning, or scene completion, where generation can be conditioned on an arbitrary subset of furniture objects. However, attribute-level conditioning, where generation can be conditioned on an arbitrary subset of object attributes, is not supported. We propose COFS, a method to generate furniture layouts that enables fine-grained control through attribute-level conditioning. For example, COFS allows specifying only the scale and type of objects that should be placed in the scene and the generator chooses their positions and orientations; or the position that should be occupied by objects can be specified and the generator chooses their type, scale, orientation, etc. Our results show both qualitatively and quantitatively that we significantly outperform existing methods on attribute-level conditioning."}}
{"id": "RnjDFZmGqli", "cdate": 1652737462068, "mdate": null, "content": {"title": "NeuForm: Adaptive Overfitting for Neural Shape Editing", "abstract": "Neural representations are popular for representing shapes as they can be used for data cleanup, model completion, shape editing, and shape synthesis. Current neural representations can be categorized as either overfitting to a single object instance, or representing a collection of objects. However, neither allows accurate editing of neural scene representations: on the one hand, methods that overfit objects achieve highly accurate reconstructions but do not support editing, as they do not generalize to unseen object configurations; on the other hand, methods that represent a family of objects with variations do generalize but produce approximate reconstructions. We propose NeuForm to combine the advantages of both overfitted and generalizable representations by adaptively overfitting a generalizable representation to regions where reliable data is available, while using the generalizable representation everywhere else. We achieve this with a carefully designed architecture and an approach that blends the network weights of the two representations. We demonstrate edits that successfully reconfigure parts of human-made shapes, such as chairs, tables, and lamps, while preserving the accuracy of an overfitted shape representation. We compare with two state-of-the-art competitors and demonstrate clear improvements in terms of plausibility and fidelity of the resultant edits."}}
{"id": "z6hhYcUrDZ", "cdate": 1640995200000, "mdate": 1681652426391, "content": {"title": "LayoutEnhancer: Generating Good Indoor Layouts from Imperfect Data", "abstract": ""}}
{"id": "vM1T3aoYKS", "cdate": 1640995200000, "mdate": 1681652426288, "content": {"title": "Node Graph Optimization Using Differentiable Proxies", "abstract": ""}}
{"id": "qZZjy1lZTS2", "cdate": 1640995200000, "mdate": 1681652426385, "content": {"title": "Controlling Material Appearance by Examples", "abstract": ""}}
{"id": "l1baMJQ46lv", "cdate": 1640995200000, "mdate": 1681652426395, "content": {"title": "Search for Concepts: Discovering Visual Concepts Using Direct Optimization", "abstract": ""}}
