{"id": "fWgn_AHqAq_", "cdate": 1663793510529, "mdate": 1663793510529, "content": {"title": "A Language for Counterfactual Generative Models", "abstract": "We present Omega, a probabilistic programming language with support for counterfactual inference. Counterfactual inference means to observe some fact in the present, and infer what would have happened had some past intervention been taken, e.g. \u201cgiven that medication was not effective at dose x, what is the probability that it would have been effective at dose 2x?.\u201d We accomplish this by introducing a new operator to probabilistic programming akin to Pearl\u2019s do, define its formal semantics, provide an implementation, and demonstrate its utility through examples in a variety of simulation models. "}}
{"id": "Qw8eyl2_N_-", "cdate": 1633706939053, "mdate": null, "content": {"title": "AutumnSynth: Synthesis of Reactive Programs with Structured Latent State", "abstract": "The human ability to efficiently discover causal theories of their environments from observations is a feat of nature that remains elusive in machines. In this work, we attempt to make progress on this frontier by formulating the challenge of causal mechanism discovery from observed data as one of program synthesis. We focus on the domain of time-varying, Atari-like 2D grid worlds, and represent causal models in this domain using a programming language called Autumn. Discovering the causal structure underlying a sequence of observations is equivalent to identifying the program in the Autumn language that generates the observations. We introduce a novel program synthesis algorithm, called AutumnSynth, that approaches this synthesis challenge by integrating standard methods of synthesizing functions with an automata synthesis approach, used to discover the model's latent state. We evaluate our method on a suite of Autumn programs designed to express the richness of the domain, and our results signal the potential of our formulation."}}
{"id": "rO24tIDmtSr", "cdate": 1602617100592, "mdate": null, "content": {"title": "Causal Inductive Synthesis Corpus", "abstract": "We introduce the Causal Inductive Synthesis Corpus (CISC) -- a manually constructed collection of interactive domains.\nCISC domains abstract core causal concepts present in real world mechanisms and environments.  We formulate two synthesis challenges of causal model discovery: the passive discovery of a model of a CISC domain from observed data, and active discovery while interacting with the domain.   CISC problems are expressed in Autumn, a Turing-complete programming language for specifying causal probabilistic models.  Autumn allows succinct expression for models that vary dynamically through time, respond to external input, have internal state and memory, exhibit probabilistic non-determinism, and have complex causal dependencies between variables.\n"}}
{"id": "S1l8oANFDH", "cdate": 1569439390420, "mdate": null, "content": {"title": "Synthesizing Programmatic Policies that Inductively Generalize", "abstract": "Deep reinforcement learning has successfully solved a number of challenging control tasks. However, learned policies typically have difficulty generalizing to novel environments. We propose an algorithm for learning programmatic state machine policies that can capture repeating behaviors. By doing so, they have the ability to generalize to instances requiring an arbitrary number of repetitions, a property we call inductive generalization. However, state machine policies are hard to learn since they consist of a combination of continuous and discrete structures. We propose a learning framework called adaptive teaching, which learns a state machine policy by imitating a teacher; in contrast to traditional imitation learning, our teacher adaptively updates itself based on the structure of the student. We show that our algorithm can be used to learn policies that inductively generalize to novel environments, whereas traditional neural network policies fail to do so. "}}
{"id": "HJZU0cbuWH", "cdate": 1546300800000, "mdate": null, "content": {"title": "Predicate Exchange: Inference with Declarative Knowledge", "abstract": "Programming languages allow us to express complex predicates, but existing inference methods are unable to condition probabilistic models on most of them. To support a broader class of predicates, ..."}}
{"id": "BJVEEF9lx", "cdate": null, "mdate": null, "content": {"title": "Learning Approximate Distribution-Sensitive Data Structures", "abstract": "We present a computational model of mental representations as data-structures which are distribution sensitive, i.e., which exploit non-uniformity in their usage patterns to reduce time or space complexity.\nAbstract data types equipped with axiomatic specifications specify classes of concrete data structures with equivalent logical behavior.\nWe extend this formalism to distribution-sensitive data structures with the concept of a probabilistic axiomatic specification, which is implemented by a concrete data structure only with some probability.\nWe employ a number of approximations to synthesize several distribution-sensitive data structures from probabilistic specification as deep neural networks, such as a stack, queue, natural number, set, and binary tree."}}
