{"id": "04OL67rm6ok", "cdate": 1663850297127, "mdate": null, "content": {"title": "QUIC-FL: : Quick Unbiased Compression for Federated Learning", "abstract": "Distributed Mean Estimation (DME) is a fundamental building block in communication efficient federated learning. In DME, clients communicate their lossily compressed gradients to the parameter server, which estimates the average and updates the model. \nState of the art DME techniques apply either unbiased quantization methods, resulting in large estimation errors, or biased quantization methods, where unbiasing the result requires that the server decodes each gradient individually, which markedly slows the aggregation time.\nIn this paper, we propose QUIC-FL, a DME algorithm that achieves the best of all worlds. QUIC-FL is unbiased, offers fast aggregation time, and is competitive with the most accurate (slow aggregation) DME techniques. To achieve this, we formalize the problem in a novel way that allows us to use standard solvers to design near-optimal unbiased quantization schemes."}}
{"id": "zgFTfPPCM", "cdate": 1640995200000, "mdate": 1674492437051, "content": {"title": "FRANCIS: Fast Reaction Algorithms for Network Coordination In Switches", "abstract": "Distributed protocols are widely used to support network functions such as clock synchronization and multicast. As the network gets larger and faster, it is increasingly challenging for these protocols to react quickly to network events. The theory community has made significant progress in developing distributed message passing algorithms with improved convergence times. With the emerging programmability at switches, it now becomes feasible to adopt and adapt these theoretical advances for networking functions. In this paper, we propose FRANCIS, a new framework for running message passing algorithms on programmable switches to enable fast reactions to network events in large networks. We introduce an execution engine with computing and communication primitives for supporting message passing algorithms in P4 switches. We exemplify the framework's usefulness by improving the resiliency and reaction times of clock synchronization and source-routed multicast. In particular, our approach allows lower clock drift than Sundial and PTP, quickly recovers from multiple failures, and reduces the time uncertainty bound by up to 5x. Compared with state-of-the-art multicast solutions, our approach uses packet headers up to 33\\% smaller and has an order of magnitude faster reaction time."}}
{"id": "ur0a0kjmtQd", "cdate": 1640995200000, "mdate": 1674492437241, "content": {"title": "SQUID: Faster Analytics via Sampled Quantiles Data-structure", "abstract": "Measurement is a fundamental enabler of network applications such as load balancing, attack detection and mitigation, and traffic engineering. A key building block in many critical measurement tasks is \\emph{q-MAX}, where we wish to find the largest $q$ values in a number stream. A standard approach of maintaining a heap of the largest $q$ values ordered results in logarithmic runtime, which is too slow for large measurements. Modern approaches attain a constant runtime by removing small items in bulk and retaining the largest $q$ items at all times. Yet, these approaches are bottlenecked by an expensive quantile calculation method. We propose SQUID, a method that redesigns q-MAX to allow the use of \\emph{approximate quantiles}, which we can compute efficiently, thereby accelerating the solution and, subsequently, many measurement tasks. We demonstrate the benefit of our approach by designing a novel weighted heavy hitters data structure that is faster and more accurate than the existing alternatives. Here, we combine our previous techniques with a lazy deletion of small entries, which expiates the maintenance process and increases the accuracy. We also demonstrate the applicability of our algorithmic approach in a general algorithmic scope by implementing the LRFU cache policy with a constant update time. Furthermore, we also show the practicality of SQUID for improving real-world networked systems, by implementing a P4 prototype of SQUID for in-network caching and demonstrating how SQUID enables a wide spectrum of score-based caching policies directly on a P4 switch."}}
{"id": "lmxXKjSj7T", "cdate": 1640995200000, "mdate": 1674492437042, "content": {"title": "Memento: Making Sliding Windows Efficient for Heavy Hitters", "abstract": "Cloud operators require timely identification of Heavy Hitters (HH) and Hierarchical Heavy Hitters (HHH) for applications such as load balancing, traffic engineering, and attack mitigation. However, existing techniques are slow in detecting new heavy hitters. In this paper, we present the case for identifying heavy hitters through <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">sliding windows</i> . Sliding windows are quicker and more accurate to detect new heavy hitters than current interval-based methods, but to date had no practical algorithms. Accordingly, we introduce, design, and analyze the <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">Memento</i> family of sliding window algorithms for the HH and HHH problems in the single-device and network-wide settings. We use extensive evaluations to show that our single-device solutions are orders of magnitude faster than existing sliding window techniques and comparable in speed to state-of-the-art non-windowed sampling based technique. Furthermore, we exemplify our network-wide HHH detection capabilities on a realistic testbed. To that end, we implemented Memento as an open-source extension to the popular HAProxy cloud load-balancer. In our evaluations, using an HTTP flood by 50 subnets, our network-wide approach detected the new subnets faster and reduced the number of undetected flood requests by up to <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"> <tex-math notation=\"LaTeX\">$37\\times $ </tex-math></inline-formula> compared to the alternatives."}}
{"id": "lTmJ1iAtM2i", "cdate": 1640995200000, "mdate": 1674492437056, "content": {"title": "EDEN: Communication-Efficient and Robust Distributed Mean Estimation for Federated Learning", "abstract": "Distributed Mean Estimation (DME) is a central building block in federated learning, where clients send local gradients to a parameter server for averaging and updating the model. Due to communicat..."}}
{"id": "kwukeWSPaK1", "cdate": 1640995200000, "mdate": 1674492437152, "content": {"title": "Enabling Efficient and General Subpopulation Analytics in Multidimensional Data Streams", "abstract": ""}}
{"id": "kf7vbgd10jT", "cdate": 1640995200000, "mdate": 1674492437155, "content": {"title": "Enabling Efficient and General Subpopulation Analytics in Multidimensional Data Streams", "abstract": "Today's large-scale services (e.g., video streaming platforms, data centers, sensor grids) need diverse real-time summary statistics across multiple subpopulations of multidimensional datasets. However, state-of-the-art frameworks do not offer general and accurate analytics in real time at reasonable costs. The root cause is the combinatorial explosion of data subpopulations and the diversity of summary statistics we need to monitor simultaneously. We present Hydra, an efficient framework for multidimensional analytics that presents a novel combination of using a ``sketch of sketches'' to avoid the overhead of monitoring exponentially-many subpopulations and universal sketching to ensure accurate estimates for multiple statistics. We build Hydra as an Apache Spark plugin and address practical system challenges to minimize overheads at scale. Across multiple real-world and synthetic multidimensional datasets, we show that Hydra can achieve robust error bounds and is an order of magnitude more efficient in terms of operational cost and memory footprint than existing frameworks (e.g., Spark, Druid) while ensuring interactive estimation times."}}
{"id": "c_jyFp3eT30", "cdate": 1640995200000, "mdate": 1674492437048, "content": {"title": "DUET: A Generic Framework for Finding Special Quadratic Elements in Data Streams", "abstract": "Finding special items, like heavy hitters, top-k, and persistent items, has always been a hot issue in data stream processing for web analysis. While data streams nowadays are usually high-dimensional, most prior works focus on special items according to a certain primary dimension and yield little insight into the correlations between dimensions. Therefore, we propose to find special quadratic elements to reveal close correlations. Based on the items mentioned above, we extend our problem to three applications related to heavy hitters, top-k, and persistent items, and design a generic framework DUET to process them. Besides, we analyze the error bound of our algorithm and conduct extensive experiments on four data sets. Our experimental results show that DUET can achieve 3.5 times higher throughput and three orders of magnitude lower average relative error compared with cutting-edge algorithms."}}
{"id": "UV9B7sqAXKS", "cdate": 1640995200000, "mdate": 1674492437060, "content": {"title": "SQUAD: Combining Sketching and Sampling Is Better than Either for Per-item Quantile Estimation", "abstract": "Stream monitoring is fundamental in many data stream applications, such as financial data trackers, security, anomaly detection, and load balancing. In that respect, quantiles are of particular interest, as they often capture the user's utility. For example, if a video connection has high tail latency, the perceived quality will suffer, even if the average and median latencies are low. In this work, we consider the problem of approximating the per-item quantiles. Elements in our stream are (ID, latency) tuples, and we wish to track the latency quantiles for each ID. Existing quantile sketches are designed for a single number stream (e.g., containing just the latency). While one could allocate a separate sketch instance for each ID, this may require an infeasible amount of memory. Instead, we consider tracking the quantiles for the heavy hitters (most frequent items), which are often considered particularly important, without knowing them beforehand. We first present a simple sampling algorithm that serves as a benchmark. Then, we design an algorithm that augments a quantile sketch within each entry of a heavy hitter algorithm, resulting in similar space complexity but with a deterministic error guarantee. Finally, we present SQUAD, a method that combines sampling and sketching while improving the asymptotic space complexity. Intuitively, SQUAD uses a background sampling process to capture the behaviour of the latencies of an item before it is allocated with a sketch, thereby allowing us to use fewer samples and sketches. Our solutions are rigorously analyzed, and we demonstrate the superiority of our approach using extensive simulations."}}
{"id": "QKcD0bK1ce", "cdate": 1640995200000, "mdate": 1674492437045, "content": {"title": "Direct Telemetry Access", "abstract": "The emergence of programmable switches allows operators to collect a vast amount of fine-grained telemetry data in real time. However, consolidating the telemetry reports at centralized collectors to gain a network-wide view poses an immense challenge. The received data has to be transported from the switches, parsed, manipulated, and inserted in queryable data structures. As the network scales, this requires excessive CPU processing. RDMA is a transport protocol that bypasses the CPU and allows extremely high data transfer rates. Yet, RDMA is not designed for telemetry collection: it requires a stateful connection, supports only a small number of concurrent writers, and has limited writing primitives, which restricts its data aggregation applicability.   We introduce Direct Telemetry Access (DTA), a solution that allows fast and efficient telemetry collection, aggregation, and indexing. Our system establishes RDMA connections only from collectors' ToR switches, called \\emph{translators}, that process DTA reports from all other switches. DTA features novel and expressive reporting primitives such as Key-Write, Append, Sketch-Merge, and Key-Increment that allow integration of telemetry systems such as INT and others. The translators then aggregate, batch, and write the reports to collectors' memory in queryable form."}}
