{"id": "wsyT0j4E0j", "cdate": 1640995200000, "mdate": 1674044802748, "content": {"title": "Supervised and Reinforcement Learning from Observations in Reconnaissance Blind Chess", "abstract": ""}}
{"id": "gWUmQAKBhqE", "cdate": 1640995200000, "mdate": 1674044802747, "content": {"title": "GausSetExpander: A Simple Approach for Entity Set Expansion", "abstract": ""}}
{"id": "_j7u07L5QV", "cdate": 1640995200000, "mdate": 1674044802688, "content": {"title": "Comparing Boosting and Bagging for Decision Trees of Rankings", "abstract": ""}}
{"id": "Y1QDCkwePjR", "cdate": 1640995200000, "mdate": 1657208789281, "content": {"title": "Quantity vs Quality: Investigating the Trade-Off between Sample Size and Label Reliability", "abstract": "In this paper, we study learning in probabilistic domains where the learner may receive incorrect labels but can improve the reliability of labels by repeatedly sampling them. In such a setting, one faces the problem of whether the fixed budget for obtaining training examples should rather be used for obtaining all different examples or for improving the label quality of a smaller number of examples by re-sampling their labels. We motivate this problem in an application to compare the strength of poker hands where the training signal depends on the hidden community cards, and then study it in depth in an artificial setting where we insert controlled noise levels into the MNIST database. Our results show that with increasing levels of noise, resampling previous examples becomes increasingly more important than obtaining new examples, as classifier performance deteriorates when the number of incorrect labels is too high. In addition, we propose two different validation strategies; switching from lower to higher validations over the course of training and using chi-square statistics to approximate the confidence in obtained labels."}}
{"id": "XYY4EMNw05", "cdate": 1640995200000, "mdate": 1674044802694, "content": {"title": "A flexible class of dependence-aware multi-label loss functions", "abstract": ""}}
{"id": "JEisEeEzfOZ", "cdate": 1640995200000, "mdate": 1674044802648, "content": {"title": "Supervised and Reinforcement Learning from Observations in Reconnaissance Blind Chess", "abstract": ""}}
{"id": "DXWQDsa4WR", "cdate": 1640995200000, "mdate": 1674044802761, "content": {"title": "Incremental Update of Locally Optimal Classification Rules", "abstract": ""}}
{"id": "CiegBQcb04", "cdate": 1640995200000, "mdate": 1674044802738, "content": {"title": "On the Incremental Construction of Deep Rule Theories", "abstract": ""}}
{"id": "BWhNYpTJ_Nm", "cdate": 1640995200000, "mdate": 1674044802739, "content": {"title": "Towards Deep and Interpretable Rule Learning (invited paper)", "abstract": ""}}
{"id": "0cOeeAGz02", "cdate": 1640995200000, "mdate": 1674044802743, "content": {"title": "Unsupervised Alignment of Distributional Word Embeddings", "abstract": ""}}
