{"id": "2SLK9_PhwXe", "cdate": 1672531200000, "mdate": 1708517294328, "content": {"title": "Path Signatures for Diversity in Probabilistic Trajectory Optimisation", "abstract": "Motion planning can be cast as a trajectory optimisation problem where a cost is minimised as a function of the trajectory being generated. In complex environments with several obstacles and complicated geometry, this optimisation problem is usually difficult to solve and prone to local minima. However, recent advancements in computing hardware allow for parallel trajectory optimisation where multiple solutions are obtained simultaneously, each initialised from a different starting point. Unfortunately, without a strategy preventing two solutions to collapse on each other, naive parallel optimisation can suffer from mode collapse diminishing the efficiency of the approach and the likelihood of finding a global solution. In this paper we leverage on recent advances in the theory of rough paths to devise an algorithm for parallel trajectory optimisation that promotes diversity over the range of solutions, therefore avoiding mode collapses and achieving better global properties. Our approach builds on path signatures and Hilbert space representations of trajectories, and connects parallel variational inference for trajectory estimation with diversity promoting kernels. We empirically demonstrate that this strategy achieves lower average costs than competing alternatives on a range of problems, from 2D navigation to robotic manipulators operating in cluttered environments."}}
{"id": "v9Wq-mycD4r", "cdate": 1665251219589, "mdate": null, "content": {"title": "Variance Reduction in Off-Policy Deep Reinforcement Learning using Spectral Normalization", "abstract": "Off-policy deep reinforcement learning algorithms like Soft Actor Critic (SAC) have achieved state-of-the-art results in several high dimensional continuous control tasks. Despite their success, they are prone to instability due to the \\textit{deadly triad} of off-policy training, function approximation, and bootstrapping. Unstable training of off-policy algorithms leads to sample inefficient and sub-optimal asymptotic performance, thus preventing their real-world deployment. To mitigate these issues, previously proposed solutions have focused on advances like target networks to alleviate instability and the introduction of twin critics to address overestimation bias. However, these modifications fail to address the issue of noisy gradient estimation with excessive variance, resulting in instability and slow convergence. Our proposed method, Spectral Normalized Actor Critic (SNAC), regularizes the actor and the critics using spectral normalization to systematically bound the gradient norm. Spectral normalization constrains the magnitudes of the gradients resulting in smoother actor-critics with robust and sample-efficient performance thus making them suitable for deployment in stability-critical and compute-constrained applications. We present empirical results on several challenging reinforcement learning benchmarks and extensive ablation studies to demonstrate the effectiveness of our proposed method."}}
{"id": "uOii2cEN2w_", "cdate": 1652737684138, "mdate": null, "content": {"title": "Batch Bayesian optimisation via density-ratio estimation with guarantees", "abstract": "Bayesian optimisation (BO) algorithms have shown remarkable success in applications involving expensive black-box functions. Traditionally BO has been set as a sequential decision-making process which estimates the utility of query points via an acquisition function and a prior over functions, such as a Gaussian process. Recently, however, a reformulation of BO via density-ratio estimation (BORE) allowed reinterpreting the acquisition function as a probabilistic binary classifier, removing the need for an explicit prior over functions and increasing scalability. In this paper, we present a theoretical analysis of BORE's regret and an extension of the algorithm with improved uncertainty estimates. We also show that BORE can be naturally extended to a batch optimisation setting by recasting the problem as approximate Bayesian inference. The resulting algorithms come equipped with theoretical performance guarantees and are assessed against other batch and sequential BO baselines in a series of experiments."}}
{"id": "rKf78aHzXmV", "cdate": 1652251866449, "mdate": 1652251866449, "content": {"title": "Bayesian optimization with informative parametric models via sequential Monte Carlo", "abstract": "Bayesian optimization (BO) has been a successful approach to optimize expensive functions whose prior knowledge can\nbe specified by means of a probabilistic model. Due to their expressiveness and tractable closed-form predictive\ndistributions, Gaussian process (GP) surrogate models have been the default go-to choice when deriving BO frameworks.\nHowever, as nonparametric models, GPs offer very little in terms of interpretability and informative power when applied\nto model complex physical phenomena in scientific applications. In addition, the Gaussian assumption also limits the\napplicability of GPs to problems where the variables of interest may highly deviate from Gaussianity. In this article, we\ninvestigate an alternative modeling framework for BO which makes use of sequential Monte Carlo (SMC) to perform\nBayesian inference with parametric models. We propose a BO algorithm to take advantage of SMC\u2019s flexible posterior\nrepresentations and provide methods to compensate for bias in the approximations and reduce particle degeneracy.\nExperimental results on simulated engineering applications in detecting water leaks and contaminant source localization\nare presented showing performance improvements over GP-based BO approaches."}}
{"id": "SzGMOdIo5xc", "cdate": 1646077551929, "mdate": null, "content": {"title": "Generalized Bayesian Quadrature with Spectral Kernels", "abstract": "Bayesian probabilistic integration, or Bayesian quadrature (BQ), has arisen as a popular means of numerical integral estimation with quantified uncertainty for problems where computational cost limits data availability. BQ leverages flexible Gaussian processes (GPs) to model an integrand which can be subsequently analytically integrated through properties of Gaussian distributions. However, BQ is inherently limited by the fact that the method relies on the use of a strict set of kernels for use in the GP model of the integrand, reducing the flexibility of the method in modeling varied integrand types. In this paper, we present spectral Bayesian quadrature, a form of Bayesian quadrature that allows for the use of any shift-invariant kernel in the integrand GP model while still maintaining the analytical tractability of the integral posterior, increasing the flexibility of BQ methods to address varied problem settings. Additionally our method enables integration with respect to a uniform expectation, effectively computing definite integrals of challenging integrands. We derive the theory and error bounds for this model, as well as demonstrate GBQ's improved accuracy, flexibility, and data efficiency, compared to traditional BQ and other numerical integration methods, on a variety of quadrature problems."}}
{"id": "zh3getkxFTd", "cdate": 1640995200000, "mdate": 1655233359509, "content": {"title": "Adaptive Model Predictive Control by Learning Classifiers", "abstract": "Stochastic model predictive control has been a successful and robust control framework for many robotics tasks where the system dynamics model is slightly inaccurate or in the presence of environment disturbances. Despite the successes, it is still unclear how to best adjust control parameters to the current task in the presence of model parameter uncertainty and heteroscedastic noise. In this paper, we propose an adaptive MPC variant that automatically estimates control and model parameters by leveraging ideas from Bayesian optimisation (BO) and the classical expected improvement acquisition function. We leverage recent results showing that BO can be reformulated via density ratio estimation, which can be efficiently approximated by simply learning a classifier. This is then integrated into a model predictive path integral control framework yielding robust controllers for a variety of challenging robotics tasks. We demonstrate the approach on classical control problems under model uncertainty and robotics manipulation tasks."}}
{"id": "yoA_EUstg6Y", "cdate": 1640995200000, "mdate": 1708517294313, "content": {"title": "Value Function Approximations via Kernel Embeddings for No-Regret Reinforcement Learning", "abstract": "We consider the regret minimization problem in reinforcement learning (RL) in the episodic setting. In many real-world RL environments, the state and action spaces are continuous or very large. Existing approaches establish regret guarantees by either a low-dimensional representation of the stochastic transition model or an approximation of the $Q$-functions. However, the understanding of function approximation schemes for state-value functions largely remains missing. In this paper, we propose an online model-based RL algorithm, namely the CME-RL, that learns embeddings of the state-transition distribution in a reproducing kernel Hilbert space while carefully balancing the exploitation-exploration tradeoff. We demonstrate the efficiency of our algorithm by proving a frequentist (worst-case) regret bound that is of order $\\tilde{O}\\big(H\\gamma_N\\sqrt{N}\\big)$\\footnote{ $\\tilde{O}(\\cdot)$ hides only absolute constant and poly-logarithmic factors.}, where $H$ is the episode length, $N$ is the total number of time steps and $\\gamma_N$ is an information theoretic quantity relating the effective dimension of the state-action feature space. Our method bypasses the need for estimating transition probabilities and applies to any domain on which kernels can be defined. It also brings new insights into the general theory of kernel methods for approximate inference and RL regret minimization."}}
{"id": "ucRdCoV7Qg", "cdate": 1640995200000, "mdate": 1684315379143, "content": {"title": "Generalized Bayesian quadrature with spectral kernels", "abstract": "Bayesian probabilistic integration, or Bayesian quadrature (BQ), has arisen as a popular means of numerical integral estimation with quantified uncertainty for problems where computational cost lim..."}}
{"id": "lzyce0jQq2", "cdate": 1640995200000, "mdate": 1708517294443, "content": {"title": "Bayesian Optimisation for Robust Model Predictive Control under Model Parameter Uncertainty", "abstract": "We propose an adaptive optimisation approach for tuning stochastic model predictive control (MPC) hyper-parameters while jointly estimating probability distributions of the transition model parameters based on performance rewards. In particular, we develop a Bayesian optimisation (BO) algorithm with a heteroscedastic noise model to deal with varying noise across the MPC hyper-parameter and dynamics model parameter spaces. Typical homoscedastic noise models are unrealistic for tuning MPC since stochastic controllers are inherently noisy, and the level of noise is affected by their hyper-parameter settings. We evaluate the proposed optimisation algorithm in simulated control and robotics tasks where we jointly infer control and dynamics parameters. Experimental results demonstrate that our approach leads to higher cumulative rewards and more stable controllers."}}
{"id": "Ms8RQ3ZKO1", "cdate": 1640995200000, "mdate": 1708517294424, "content": {"title": "Batch Bayesian optimisation via density-ratio estimation with guarantees", "abstract": "Bayesian optimisation (BO) algorithms have shown remarkable success in applications involving expensive black-box functions. Traditionally BO has been set as a sequential decision-making process which estimates the utility of query points via an acquisition function and a prior over functions, such as a Gaussian process. Recently, however, a reformulation of BO via density-ratio estimation (BORE) allowed reinterpreting the acquisition function as a probabilistic binary classifier, removing the need for an explicit prior over functions and increasing scalability. In this paper, we present a theoretical analysis of BORE's regret and an extension of the algorithm with improved uncertainty estimates. We also show that BORE can be naturally extended to a batch optimisation setting by recasting the problem as approximate Bayesian inference. The resulting algorithms come equipped with theoretical performance guarantees and are assessed against other batch and sequential BO baselines in a series of experiments."}}
