{"id": "D6dN4eR9HiU", "cdate": 1577836800000, "mdate": 1652732643435, "content": {"title": "Sum-Product Network Decompilation", "abstract": "There exists a dichotomy between classical probabilistic graphical models, such as Bayesian networks (BNs), and modern tractable models, such as sum-product networks (SPNs). The former generally ha..."}}
{"id": "fRmBSHRckBH-", "cdate": 1546300800000, "mdate": 1652732643427, "content": {"title": "Sum-Product Network Decompilation", "abstract": "There exists a dichotomy between classical probabilistic graphical models, such as Bayesian networks (BNs), and modern tractable models, such as sum-product networks (SPNs). The former generally have intractable inference, but provide a high level of interpretability, while the latter admits a wide range of tractable inference routines, but are typically harder to interpret. Due to this dichotomy, tools to convert between BNs and SPNs are desirable. While one direction -- compiling BNs into SPNs -- is well discussed in Darwiche's seminal work on arithmetic circuit compilation, the converse direction -- decompiling SPNs into BNs -- has received surprisingly little attention. In this paper, we fill this gap by proposing SPN2BN, an algorithm that decompiles an SPN into a BN. SPN2BN has several salient features when compared to the only other two works decompiling SPNs. Most significantly, the BNs returned by SPN2BN are minimal independence-maps that are more parsimonious with respect to the introduction of latent variables. Secondly, the output BN produced by SPN2BN can be precisely characterized with respect to a compiled BN. More specifically, a certain set of directed edges will be added to the input BN, giving what we will call the moral-closure. Lastly, it is established that our compilation-decompilation process is idempotent. This has practical significance as it limits the size of the decompiled SPN."}}
{"id": "_Pcdq26BMZ", "cdate": 1546300800000, "mdate": 1673473632025, "content": {"title": "Exploiting Symmetry of Independence in d-Separation", "abstract": ""}}
{"id": "SiUZsWzxuaB", "cdate": 1546300800000, "mdate": null, "content": {"title": "Deep Convolutional Sum-Product Networks.", "abstract": "We give conditions under which convolutional neural networks (CNNs) define valid sum-product networks (SPNs). One subclass, called convolutional SPNs (CSPNs), can be implemented using tensors, but also can suffer from being too shallow. Fortunately, tensors can be augmented while maintaining valid SPNs. This yields a larger subclass of CNNs, which we call deep convolutional SPNs (DCSPNs), where the convolutional and sum-pooling layers form rich directed acyclic graph structures. One salient feature of DCSPNs is that they are a rigorous probabilistic model. As such, they can exploit multiple kinds of probabilistic reasoning, including marginal inference and most probable explanation (MPE) inference. This allows an alternative method for learning DCSPNs using vectorized differentiable MPE, which plays a similar role to the generator in generative adversarial networks (GANs). Image sampling is yet another application demonstrating the robustness of DCSPNs. Our preliminary results on image sampling are encouraging, since the DCSPN sampled images exhibit variability. Experiments on image completion show that DCSPNs significantly outperform competing methods by achieving several state-of-the-art mean squared error (MSE) scores in both left-completion and bottom-completion in benchmark datasets."}}
{"id": "M8gNM0CGkbF", "cdate": 1546300800000, "mdate": 1673473632309, "content": {"title": "Solving Influence Diagrams with Simple Propagation", "abstract": ""}}
{"id": "CwNkHp6hLrc", "cdate": 1546300800000, "mdate": 1673473632004, "content": {"title": "On the Tree Structure of Deep Convolutional Sum-Product Networks", "abstract": ""}}
{"id": "9gfmw78bic", "cdate": 1546300800000, "mdate": 1673473632053, "content": {"title": "Deep Convolutional Sum-Product Networks", "abstract": ""}}
{"id": "sYbJhxVGb5", "cdate": 1514764800000, "mdate": null, "content": {"title": "An Empirical Study of Methods for SPN Learning and Inference", "abstract": "In this study, we provide an empirical comparison of methods for \\emph{sum-product network} (SPN) learning and inference. LearnSPN is a popular algorithm for learning SPNs that utilizes chop and sl..."}}
{"id": "mFv0gDZROS", "cdate": 1514764800000, "mdate": 1673473631978, "content": {"title": "An empirical study of Bayesian network inference with simple propagation", "abstract": ""}}
{"id": "gDJfffKzX2t", "cdate": 1514764800000, "mdate": 1673473632163, "content": {"title": "An empirical study of testing independencies in Bayesian networks using rp-separation", "abstract": ""}}
