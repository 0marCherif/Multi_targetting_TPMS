{"id": "Scb9ynW865", "cdate": 1672106774249, "mdate": 1672106774249, "content": {"title": "Discovering Long-period Exoplanets using Deep Learning with Citizen Science Labels", "abstract": "Automated planetary transit detection has become vital to prioritize candidates for expert analysis given the scale of modern telescopic surveys. While current methods for short-period exoplanet detection work effectively due to periodicity in the light curves, there lacks a robust approach for detecting single-transit events. However, volunteer-labelled transits recently collected by the Planet Hunters TESS (PHT) project now provide an unprecedented opportunity to investigate a data-driven approach to long-period exoplanet detection. In this work, we train a 1-D convolutional neural network to classify planetary transits using PHT volunteer scores as training data. We find using volunteer scores significantly improves performance over synthetic data, and enables the recovery of known planets at a precision and rate matching that of the volunteers. Importantly, the model also recovers transits found by volunteers but missed by current automated methods."}}
{"id": "MXL81t3nM8", "cdate": 1672106629131, "mdate": null, "content": {"title": "Predicting the Outcomes of Material Syntheses with Deep Learning", "abstract": "A key bottleneck for material discovery is synthesis. While significant advances have been made in computational material design, synthesis pathways are still often determined through trial and error. In this work, we develop a method that predicts the major product of solid-state reactions. The main advance presented here is the construction of fixed-length, learned representations of reactions. Precursors are represented as nodes on a \u201creaction graph\u201d, and message-passing operations between nodes are used to embody the interactions between precursors in the reaction mixture. We show that this deep learning framework not only outperforms baseline methods but also more reliably assesses the uncertainty in its predictions. Moreover, our approach establishes a quantitative metric for inorganic reaction similarity, allowing the user to explain model predictions and retrieve relevant literature sources."}}
{"id": "b09t6GiqVNy", "cdate": 1672106385894, "mdate": null, "content": {"title": "Multi-Modal Fusion by Meta-Initialization", "abstract": "When experience is scarce, models may have insufficient information to adapt to a new task. In this case, auxiliary information - such as a textual description of the task - can enable improved task inference and adaptation. In this work, we propose an extension to the Model-Agnostic Meta-Learning algorithm (MAML), which allows the model to adapt using auxiliary information as well as task experience. Our method, Fusion by Meta-Initialization (FuMI), conditions the model initialization on auxiliary information using a hypernetwork, rather than learning a single, task-agnostic initialization. Furthermore, motivated by the shortcomings of existing multi-modal few-shot learning benchmarks, we constructed iNat-Anim - a large-scale image classification dataset with succinct and visually pertinent textual class descriptions. On iNat-Anim, FuMI significantly outperforms uni-modal baselines such as MAML in the few-shot regime. The code for this project and a dataset exploration tool for iNat-Anim are publicly available at https://github.com/s-a-malik/multi-few."}}
