{"id": "3XV95g8BIYj", "cdate": 1672531200000, "mdate": 1695965012253, "content": {"title": "Learning Formal Specifications from Membership and Preference Queries", "abstract": "Active learning is a well-studied approach to learning formal specifications, such as automata. In this work, we extend active specification learning by proposing a novel framework that strategically requests a combination of membership labels and pair-wise preferences, a popular alternative to membership labels. The combination of pair-wise preferences and membership labels allows for a more flexible approach to active specification learning, which previously relied on membership labels only. We instantiate our framework in two different domains, demonstrating the generality of our approach. Our results suggest that learning from both modalities allows us to robustly and conveniently identify specifications via membership and preferences."}}
{"id": "xjXN3wEvCGG", "cdate": 1652737624522, "mdate": null, "content": {"title": "Surprise-Guided Search for Learning Task Specifications From Demonstrations", "abstract": "This paper considers the problem of learning temporal task specifications, e.g. automata and temporal logic, from expert demonstrations. Task specifications are a class of sparse memory augmented rewards with explicit support for temporal and Boolean composition.  Three features make learning temporal task specifications difficult: (1) the (countably) infinite number of tasks under consideration, (2) an a-priori ignorance of what memory is needed to encode the task, and (3) the discrete solution space - typically addressed by (brute force) enumeration. To overcome these hurdles, we propose Demonstration Informed Specification Search (DISS): a family of algorithms requiring only black box access to (i) a maximum entropy planner and (ii) a task sampler from labeled examples. DISS works by alternating between (i) conjecturing labeled examples to make the provided demonstrations less surprising and (ii) sampling tasks consistent with the conjectured labeled examples. We provide a concrete implementation of DISS in the context of tasks described by Deterministic Finite Automata, and show that DISS is able to efficiently identify tasks from only one or two expert demonstrations."}}
{"id": "od3WDqKUDkA", "cdate": 1640995200000, "mdate": 1684253526500, "content": {"title": "Modeling and Influencing Human Attentiveness in Autonomy-to-Human Perception Hand-offs", "abstract": "It is not uncommon for autonomous systems (e.g., self-driving cars) to require the timely intervention of a human operator to ensure safe operation. It is important to design these systems such that the human is brought into the decision-making loop in a manner that enables them to make a timely and correct decision. In this paper, we consider one such ap-plication, which we refer to as the perception hand-off problem, which brings the driver into the loop when the perception module of an Autonomous Vehicle (AV) is uncertain about the environment. We formalize the perception hand-off problem by designing a Partially Observable Markov Decision Process (POMDP) model. This model captures the latent cognitive state (attention) of the driver which can be influenced through a proposed query-based active information gathering (AIG) system for Human-Machine Interface (HMI). We design a web-based human study to identify the model parameters, and demonstrate the impact of the proposed HMI system. Results from this study show that the state of attentiveness does indeed impact the human performance, and our proposed active information gathering (AIG) actions, i.e., queries to the human driver, result in 7% faster responses from the human. Simulations with the identified POMDP model show that a learnt policy for deploying the AIG actions improves the percentage of correct responses from the human in the perception hand-off by around 5.4%, outperforming other baselines while also using fewer of these actions."}}
{"id": "kIIdSBObMAT", "cdate": 1640995200000, "mdate": 1695965012271, "content": {"title": "Specifications from Demonstrations: Learning, Teaching, and Control", "abstract": "Author(s): Vazquez-Chanlatte, Marcell Jose | Advisor(s): Seshia, Sanjit A | Abstract: This dissertation considers the problem of learning and teaching Boolean task specifications, such as automata, using demonstrations. The resulting framework bridges grammatical inference and maximum-entropy inverse reinforcement learning with applications in human-robot interaction, formal synthesis, and multi-task reinforcement learning. In the context of inverse reinforcement learning, Boolean task specifications are a class of sparse memory augmented rewards with explicit support for temporal and Boolean composition. These properties make task specifications immune to certain classes of reward hacking bugs that emerge from ad-hoc composition or perturbations to the dynamics. Unfortunately, the discrete nature of task specifications combined with an a-priori ignorance of what historical features are needed to encode the demonstrated task make existing approaches to learning rewards from demonstrations inapplicable.In the context of specification mining and grammatical inference, demonstrations provide an ergonomic and sample efficient means to communicate formal languages and specifications. For example, this dissertation enables a user to partially specify the desired behavior of a system as example demonstrations and then find an automata or program that explains the user's behavior. Conversely, by synthesizing pedagogic demonstrations, this dissertation enables communicating the nuances of a specification that may be hard to intuit from a formal description.In either case, this thesis contributes a collection of algorithms and theoretical machinery for systematically mitigating combinatorial explosions inherent in (1) finding specifications that explain an agent's behavior (2) finding pedagogic demonstrations that help humans infer the specification and (3) robustly predicting the behavior of an agent adhering to a specification."}}
{"id": "SS1xKVI9CHn", "cdate": 1640995200000, "mdate": 1695965012301, "content": {"title": "Learning Deterministic Finite Automata Decompositions from Examples and Demonstrations", "abstract": "The identification of a deterministic finite automaton (DFA) from labeled examples is a well-studied problem in the literature; however, prior work focuses on the identification of monolithic DFAs. Although monolithic DFAs provide accurate descriptions of systems' behavior, they lack simplicity and interpretability; moreover, they fail to capture sub-tasks realized by the system and introduce inductive biases away from the inherent decomposition of the overall task. In this paper, we present an algorithm for learning conjunctions of DFAs from labeled examples. Our approach extends an existing SAT-based method to systematically enumerate Pareto-optimal candidate solutions. We highlight the utility of our approach by integrating it with a state-of-the-art algorithm for learning DFAs from demonstrations. Our experiments show that the algorithm learns sub-tasks realized by the labeled examples, and it is scalable in the domains of interest."}}
{"id": "Com52qTpxS", "cdate": 1640995200000, "mdate": 1695965012285, "content": {"title": "Learning Monitorable Operational Design Domains for Assured Autonomy", "abstract": "AI-based autonomous systems are increasingly relying on machine learning (ML) components to perform a variety of complex tasks in perception, prediction, and control. The use of ML components is projected to grow and with it the concern of using these components in systems that operate in safety-critical settings. To guarantee a safe operation of autonomous systems, it is important to run an ML component in its operational design domain (ODD), i.e., the conditions under which using the component does not endanger the safety of the system. Building safe and reliable autonomous systems which may use machine-learning-based components, calls therefore for automated techniques that allow to systematically capture the ODD of systems. In this paper, we present a framework for learning runtime monitors that capture the ODDs of black-box systems. A runtime monitor of an ODD predicts based on a sequence of monitorable observations whether the system is about to exit the ODD. We particularly investigate the learning of optimal monitors based on counterexample-guided refinement and conformance testing. We evaluate the applicability of our approach on a case study from the domain of autonomous driving."}}
{"id": "88M78Sap-U1", "cdate": 1640995200000, "mdate": 1695965012286, "content": {"title": "Learning Deterministic Finite Automata Decompositions from Examples and Demonstrations", "abstract": ""}}
{"id": "rL7bD0UnhZ5", "cdate": 1609459200000, "mdate": 1647261390624, "content": {"title": "Model Checking Finite-Horizon Markov Chains with Probabilistic Inference", "abstract": "We revisit the symbolic verification of Markov chains with respect to finite horizon reachability properties. The prevalent approach iteratively computes step-bounded state reachability probabilities. By contrast, recent advances in probabilistic inference suggest symbolically representing all horizon-length paths through the Markov chain. We ask whether this perspective advances the state-of-the-art in probabilistic model checking. First, we formally describe both approaches in order to highlight their key differences. Then, using these insights we develop Rubicon, a tool that transpiles Prism models to the probabilistic inference tool Dice. Finally, we demonstrate better scalability compared to probabilistic model checkers on selected benchmarks. All together, our results suggest that probabilistic inference is a valuable addition to the probabilistic model checking portfolio, with Rubicon as a first step towards integrating both perspectives."}}
{"id": "rCf4vAL23-q", "cdate": 1609459200000, "mdate": 1647261390686, "content": {"title": "Entropy-Guided Control Improvisation", "abstract": "High level declarative constraints provide a powerful (and popular) way to define and construct control policies; however, most synthesis algorithms do not support specifying the degree of randomness (unpredictability) of the resulting controller. In many contexts, e.g., patrolling, testing, behavior prediction,and planning on idealized models, predictable or biased controllers are undesirable. To address these concerns, we introduce the \\emph{Entropic Reactive Control Improvisation} (ERCI) framework and algorithm which supports synthesizing control policies for stochastic games that are declaratively specified by (i) a \\emph{hard constraint} specifying what must occur, (ii) a \\emph{soft constraint} specifying what typically occurs, and (iii) a \\emph{randomization constraint} specifying the unpredictability and variety of the controller, as quantified using causal entropy. This framework, extends the state of the art by supporting arbitrary combinations of adversarial and probabilistic uncertainty in the environment. ERCI enables a flexible modeling formalism which we argue, theoretically and empirically, remains tractable."}}
{"id": "MtJzGuoE0I1", "cdate": 1609459200000, "mdate": 1695965012357, "content": {"title": "Demonstration Informed Specification Search", "abstract": "This paper considers the problem of learning temporal task specifications, e.g. automata and temporal logic, from expert demonstrations. Task specifications are a class of sparse memory augmented rewards with explicit support for temporal and Boolean composition. Three features make learning temporal task specifications difficult: (1) the (countably) infinite number of tasks under consideration; (2) an a-priori ignorance of what memory is needed to encode the task; and (3) the discrete solution space - typically addressed by (brute force) enumeration. To overcome these hurdles, we propose Demonstration Informed Specification Search (DISS): a family of algorithms requiring only black box access to a maximum entropy planner and a task sampler from labeled examples. DISS then works by alternating between conjecturing labeled examples to make the provided demonstrations less surprising and sampling tasks consistent with the conjectured labeled examples. We provide a concrete implementation of DISS in the context of tasks described by Deterministic Finite Automata, and show that DISS is able to efficiently identify tasks from only one or two expert demonstrations."}}
