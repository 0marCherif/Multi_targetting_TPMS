{"id": "rCMsgBi8ri4", "cdate": 1649390921316, "mdate": 1649390921316, "content": {"title": "Contextual Rephrase Detection for Reducing Friction in Dialogue Systems", "abstract": "For voice assistants like Alexa, Google Assistant, and Siri, correctly interpreting users\u2019 intentions is of utmost importance. However, users sometimes experience friction with these assistants, caused by errors from different system components or user errors such as slips of the tongue. Users tend to rephrase their queries until they get a satisfactory response. Rephrase detection is used to identify the rephrases and has long been treated as a task with pairwise input, which does not fully utilize the contextual information (eg users\u2019 implicit feedback). To this end, we propose a contextual rephrase detection model ContReph to automatically identify rephrases from multi-turn dialogues. We showcase how to leverage the dialogue context and user-agent interaction signals, including the user\u2019s implicit feedback and the time gap between different turns, which can help significantly outperform the pairwise rephrase detection models."}}
{"id": "HHxxf5OnyZ9", "cdate": 1646409865688, "mdate": 1646409865688, "content": {"title": "VSCL: Automating Vulnerability Detection in Smart Contracts with Deep Learning", "abstract": "With the increase of the adoption of blockchain technology in providing decentralized solutions to various problems, smart contracts have become more popular to the point that billions of US Dollars are currently exchanged every day through such technology. Meanwhile, various vulnerabilities in smart contracts have been exploited by attackers to steal cryptocurrencies worth millions of dollars. The automatic detection of smart contract vulnerabilities therefore is an essential research problem. Existing solutions to this problem particularly rely on human experts to define features or different rules to detect vulnerabilities. However, this often causes many vulnerabilities to be ignored, and they are inefficient in detecting new vulnerabilities. In this study, to overcome such challenges, we propose the VSCL framework to automatically detect vulnerabilities in smart contracts on the blockchain. More specifically, first, we utilize novel feature vector generation techniques from bytecode of smart contract since the source code of smart contracts are rarely available in public. Next, the collected vectors are fed into our novel metric learning-based deep neural network(DNN) to get the detection result. We conduct comprehensive experiments on a large-scale benchmark, and the quantitative results demonstrate the effectiveness and efficiency of our approach."}}
{"id": "BdWlAhIhyWq", "cdate": 1646409398237, "mdate": null, "content": {"title": "CLEAR: Contrastive-Prototype Learning with Drift Estimation for Resource Constrained Stream Mining", "abstract": "Non-stationary data stream mining aims to classify large scale online instances that emerge continuously. The most apparent challenge compared with the offline learning manner is the issue of consecutive emergence of new categories, when tackling non-static categorical distribution. Non-stationary stream settings often appear in real-world applications, e.g., online classification in E-commerce systems that involves the incoming productions, or the summary of news topics on social networks (Twitter). Ideally, a learning model should be able to learn novel concepts from labeled data (in new tasks) and reduce the abrupt degradation of model performance on the old concept (also named catastrophic forgetting problem). In this work, we focus on improving the performance of the stream mining approach under the constrained resources, where both the memory resource of old data and labeled new instances are limited/scarce. We propose a simple yet efficient resource-constrained framework CLEAR to facilitate previous challenges during the one-pass stream mining. Specifically, CLEAR focuses on creating and calibrating the class representation (the prototype) in the embedding space. We first apply the contrastive-prototype learning on large amount of unlabeled data, and generate the discriminative prototype for each class in the embedding space. Next, for updating on new tasks/categories, we propose a drift estimation strategy to calibrate/compensate for the drift of each class representation, which could reduce the knowledge forgetting without storing any previous data. We perform experiments on public datasets (e.g., CUB200, CIFAR100) under stream setting, our approach is consistently and clearly better than many state-of-the-art methods, along with both the memory and annotation restriction."}}
{"id": "SnMxlrU3JWc", "cdate": 1646409271671, "mdate": null, "content": {"title": "PDFM: A Primal-Dual Fairness-Aware Framework for Meta-learning", "abstract": "The problem of learning to generalize to unseen classes during training, known as few-shot classification, has attracted\nconsiderable attention. Initialization based methods, such as the gradient-based model agnostic meta-learning (MAML) [1], tackle the\nfew-shot learning problem by \u201clearning to fine-tune\u201d. The goal of these approaches is to learn proper model initialization, so that the\nclassifiers for new classes can be learned from a few labeled examples with a small number of gradient update steps. Few shot\nmeta-learning is well-known with its fast-adapted capability and accuracy generalization onto unseen tasks. Learning fairly with unbiased\noutcomes is another significant hallmark of human intelligence, which is rarely touched in few-shot meta-learning. In this work, we\npropose a Primal-Dual Fair Meta-learning framework, namely PDFM, which learns to train fair machine learning models using only a few\nexamples based on data from related tasks. The key idea is to learn a good initialization of a fair model\u2019s primal and dual parameters so\nthat it can adapt to a new fair learning task via a few gradient update steps. Instead of manually tuning the dual parameters as\nhyperparameters via a grid search, PDFM optimizes the initialization of the primal and dual parameters jointly for fair meta-learning via a\nsubgradient primal-dual approach. We further instantiate examples of bias controlling using mean difference and decision boundary\ncovariance [2] as fairness constraints to each task for supervised regression and classification, respectively. We demonstrate the\nversatility of our proposed approach by applying our approach to various real-world datasets. Our experiments show substantial\nimprovements over the best prior work for this setting.\n"}}
{"id": "rAzeDJIhy-c", "cdate": 1646409183363, "mdate": null, "content": {"title": "A Primal-Dual Subgradient Approach for Fair Meta Learning", "abstract": "The problem of learning to generalize to unseen classes during training, known as few-shot classification, has attracted considerable attention. Initialization based methods, such as the gradient-based model agnostic meta-learning (MAML), tackle the few-shot learning problem by \"learning to fine-tune\". The goal of these approaches is to learn proper model initialization, so that the classifiers for new classes can be learned from a few labeled examples with a small number of gradient update steps. Few shot meta-learning is well-known with its fast-adapted capability and accuracy generalization onto unseen tasks. Learning fairly with unbiased outcomes is another significant hallmark of human intelligence, which is rarely touched in few-shot meta-learning. In this work, we propose a Primal-Dual Fair Meta-learning framework, namely PDFM, which learns to train fair machine learning models using only a few examples based on data from related tasks. The key idea is to learn a good initialization of a fair model's primal and dual parameters so that it can adapt to a new fair learning task via a few gradient update steps. Instead of manually tuning the dual parameters as hyperparameters via a grid search, PDFM optimizes the initialization of the primal and dual parameters jointly for fair meta-learning via a subgradient primal-dual approach. We further instantiate examples of bias controlling using mean difference and decision boundary covariance as fairness constraints to each task for supervised regression and classification, respectively. We demonstrate the versatility of our proposed approach by applying our approach to various real-world datasets. Our experiments show substantial improvements over the best prior work for this setting."}}
{"id": "PP_yrI-5Mv", "cdate": 1640995200000, "mdate": 1668097552852, "content": {"title": "Latent Coreset Sampling based Data-Free Continual Learning", "abstract": "Catastrophic forgetting poses a major challenge in continual learning where the old knowledge is forgotten when the model is updated on new tasks. Existing solutions tend to solve this challenge through generative models or exemplar-replay strategies. However, such methods may not alleviate the issue that the low-quality samples are generated or selected for the replay, which would directly reduce the effectiveness of the model, especially in the class imbalance, noise, or redundancy scenarios. Accordingly, how to select a suitable coreset during continual learning becomes significant in such setting. In this work, we propose a novel approach that leverages continual coreset sampling (CCS) to address these challenges. We aim to select the most representative subsets during each iteration. When the model is trained on new tasks, it closely approximates/matches the gradient of both the previous and current tasks with respect to the model parameters. This way, adaptation of the model to new datasets could be more efficient. Furthermore, different from the old data storage for maintaining the old knowledge, our approach choose to preserving them in the latent space. We augment the previous classes in the embedding space as the pseudo sample vectors from the old encoder output, strengthened by the joint training with selected new data. It could avoid data privacy invasions in a real-world application when we update the model. Our experiments validate the effectiveness of our proposed approach over various CV/NLP datasets under against current baselines, and we also indicate the obvious improvement of model adaptation and forgetting reduction in a data-free manner."}}
{"id": "OmRrHVb5Y3p", "cdate": 1640995200000, "mdate": 1671740342131, "content": {"title": "CAPT: Contrastive Pre-Training based Semi-Supervised Open-Set Learning", "abstract": "Deep Semi-Supervised Learning (SSL) has shown very effective performance in recent years, such methods are typically under assumptions of a closed-world setting, where instances in the labeled and unlabeled data share the same class set. However, in real-world applications, samples with novel classes may be contained in the unlabeled data during the model deployment (open-set scenario), i.e. new types of scene images may occur in a self-driving system. In this paper, we advocate a two-stage semi-supervised learning approach CAPT, a framework for handling this realistic sce-nario based on a self-supervised pre-training step. The key idea is to introduce the embedding from pre-training into the SSL open-set classifier, so that the model can recognize the seen classes and cluster the instances from novel categories simultaneously. Our framework first pre-train a semantically meaningful representation of all samples from the labeled and unlabeled dataset. Next, CAPT applies the learned embedding as initialization to build a semisupervised classifier for clustering novel classes. We thoroughly evaluate our framework on large-scale image benchmarks CIFAR10, CIFAR100, obtaining state-of-the-art results."}}
{"id": "F1Rfd40NMl", "cdate": 1640995200000, "mdate": 1682474817815, "content": {"title": "LPC: A Logits and Parameter Calibration Framework for Continual Learning", "abstract": ""}}
{"id": "z91-UMG_Tq0", "cdate": 1609459200000, "mdate": 1696456523007, "content": {"title": "An Episodic Learning based Geolocation Detection Framework for Imbalanced Data", "abstract": "A social media user's geographical location is vital to many applications like local search and event detection. The scarcity of publicly available location information motivates researchers to predict user geolocation based on information such as tweet text and social interaction data. In this paper, we investigate and improve on the task of predicting a Twitter user's city-level location based on the content of the user's historical tweets. In order to train a reliable location classifier, previous studies on this topic have typically assumed that there are sufficient amount of users living in each cities. However, they simply ignore the fact that different demographic groups may participate in social media platforms, which results in a highly imbalanced data distribution. Being aware of this population imbalance issue, we propose an episodic learning based framework to extract a single representative for each class (location), so that classifiers can later be trained on a balanced class distribution. To examine the effectiveness of our method, we design experiments which involve two kinds of baselines, the state-of-the-art geolocation detection methods and the well-known approaches handling imbalanced data in classification. The results of experiments on the data collected from Twitter demonstrated the superiority of our method when compared with baselines."}}
{"id": "pnga5V2mrO", "cdate": 1609459200000, "mdate": 1668097552880, "content": {"title": "Generating Point Cloud from Single Image in The Few Shot Scenario", "abstract": "Reconstructing point clouds from images would extremely benefit many practical CV applications, such as robotics, automated vehicles, and Augmented Reality. Fueled by the advances of deep neural network, many deep learning frameworks are proposed to address this problem recently. However, these frameworks generally rely on a large amount of labeled training data (e.g., image and point cloud pairs). Although we usually have numerous 2D images, corresponding 3D shapes are insufficient in practice. In addition, most available 3D data covers only a limited amount of classes, which further restricts the models' generalization ability to novel classes. To mitigate these issues, we propose a novel few-shot single-view point cloud generation framework by considering both class-specific and class-agnostic 3D shape priors. Specifically, we abstract each class by a prototype vector that embeds class-specific shape priors. Class-agnostic shape priors are modeled by a set of learnable shape primitives that encode universal 3D shape information shared across classes. Later, we combine the input image with class-specific prototypes and class-agnostic shape primitives to guide the point cloud generation process. Experiments on the popular ModelNet and ShapeNet datasets demonstrate that our method outperforms state-of-the-art methods in the few-shot setting."}}
