{"id": "ZswoPbTlNQ", "cdate": 1680732799532, "mdate": null, "content": {"title": "Long-Term Fairness with Unknown Dynamics", "abstract": "As populations adapt to algorithmic prediction, machine learning can myopically reinforce social inequalities or dynamically seek equitable outcomes. In this paper, we formalize prediction subject to long-term fairness as a constrained online reinforcement learning problem. This formulation can accommodate dynamical control objectives, such as inducing equitable population adaptations, that cannot be expressed by static formulations of fairness. By adapting recent work in  online learning, we provide the first algorithm that guarantees simultaneous, probabilistic bounds on cumulative loss and cumulative violations of fairness (defined as statistical regularities between demographic groups) in this setting. We compare this algorithm to an off-the-shelf, deep reinforcement learning algorithm that lacks such safety guarantees, and to a repeatedly retrained, myopic classifier, as a baseline. We demonstrate that a reinforcement learning framework for long-term fairness allows algorithms to adapt to unknown dynamics and sacrifice short-term profit or fairness to drive a classifier-population system towards more desirable equilibria. Our experiments model human populations according to evolutionary game theory, using real-world data to set an initial state."}}
{"id": "qTYIFstGktG", "cdate": 1680732799415, "mdate": null, "content": {"title": "Performative Federated Learning", "abstract": "We consider a federated learning (FL) system comprising multiple clients and a server, wherein the clients collaborate to learn a common decision model from their distributed data. Unlike the conventional FL framework, we consider the scenario where the clients' data distributions change with the deployed decision model. In this work, we propose a performative federated learning framework that formalizes model-dependent distribution shifts by leveraging the concept of distribution shift mappings in the performative prediction literature.\nWe introduce necessary and sufficient conditions for the existence of a unique performative stable solution and characterize its distance to the performative optimal solution. Under such conditions, we propose the performative FedAvg algorithm and show that it converges to the performative stable solution at a rate of O(1/T) under both full and partial participation schemes. In addition, we show how the clients' heterogeneity influences the convergence both theoretically and using numerical results."}}
{"id": "iRYk5sJBfCY", "cdate": 1672531200000, "mdate": 1683925038670, "content": {"title": "Performative Federated Learning: A Solution to Model-Dependent and Heterogeneous Distribution Shifts", "abstract": "We consider a federated learning (FL) system consisting of multiple clients and a server, where the clients aim to collaboratively learn a common decision model from their distributed data. Unlike the conventional FL framework that assumes the client's data is static, we consider scenarios where the clients' data distributions may be reshaped by the deployed decision model. In this work, we leverage the idea of distribution shift mappings in performative prediction to formalize this model-dependent data distribution shift and propose a performative federated learning framework. We first introduce necessary and sufficient conditions for the existence of a unique performative stable solution and characterize its distance to the performative optimal solution. Then we propose the performative FedAvg algorithm and show that it converges to the performative stable solution at a rate of O(1/T) under both full and partial participation schemes. In particular, we use novel proof techniques and show how the clients' heterogeneity influences the convergence. Numerical results validate our analysis and provide valuable insights into real-world applications."}}
{"id": "5xhwaHi04v", "cdate": 1672531200000, "mdate": 1683925038670, "content": {"title": "Long-Term Fairness with Unknown Dynamics", "abstract": "While machine learning can myopically reinforce social inequalities, it may also be used to dynamically seek equitable outcomes. In this paper, we formalize long-term fairness in the context of online reinforcement learning. This formulation can accommodate dynamical control objectives, such as driving equity inherent in the state of a population, that cannot be incorporated into static formulations of fairness. We demonstrate that this framing allows an algorithm to adapt to unknown dynamics by sacrificing short-term incentives to drive a classifier-population system towards more desirable equilibria. For the proposed setting, we develop an algorithm that adapts recent work in online learning. We prove that this algorithm achieves simultaneous probabilistic bounds on cumulative loss and cumulative violations of fairness (as statistical regularities between demographic groups). We compare our proposed algorithm to the repeated retraining of myopic classifiers, as a baseline, and to a deep reinforcement learning algorithm that lacks safety guarantees. Our experiments model human populations according to evolutionary game theory and integrate real-world datasets."}}
{"id": "10tgIzcC2vY", "cdate": 1663850205442, "mdate": null, "content": {"title": "Upcycled-FL: Improving Accuracy and Privacy with Less Computation in Federated Learning", "abstract": "Federated learning (FL) is a distributed learning paradigm that allows multiple decentralized edge devices to collaboratively learn toward a common objective without sharing local data. Although local data is not exposed directly, privacy concerns nonetheless exist as sensitive information can be inferred from intermediate computations. As the same data is repeatedly used over an iterative process, information leakage accumulates substantially over time, making it difficult to balance the trade-off between privacy and accuracy. In this paper we introduce Upcycled-FL, a novel federated learning framework, where first-order approximation is  applied at every even iteration. Under such a scheme, half of the steps incur no privacy loss and require much less computation. Theoretically, we establish the convergence rate performance of Upcycled-FL and provide privacy analysis based on objective and output perturbations. Experiments on  real-world data show that Upcycled-FL consistently outperforms existing methods over heterogeneous data, and significantly improves privacy-accuracy trade-off, while reducing 48% of the training time on average."}}
{"id": "UV1xM4vl1D", "cdate": 1609459200000, "mdate": 1684357844214, "content": {"title": "Network Games with Strategic Machine Learning", "abstract": "In this paper, we study the strategic machine learning problem with a planner (decision maker) and multiple agents. The planner is the first-mover, who designs, publishes, and commits to a decision rule. The agents then best-respond by manipulating their input features to obtain a desirable decision outcome so as to maximize their utilities. Earlier works in strategic machine learning assume that every agent\u2019s strategic action is independent of others\u2019. By contrast, we consider a different case where agents are connected in a network and can either benefit from their neighbors\u2019 positive decision outcomes from the planner or benefit from their neighbors\u2019 actions. We study the Stackelberg equilibrium in this new setting and highlight the similarities and differences between this model and the literature on network/graphical games and strategic machine learning."}}
