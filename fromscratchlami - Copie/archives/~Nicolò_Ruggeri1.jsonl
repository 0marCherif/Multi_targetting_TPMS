{"id": "jECB5SPk42", "cdate": 1671878839535, "mdate": 1671878839535, "content": {"title": "A Principled, Flexible and Efficient Framework for Hypergraph Benchmarking", "abstract": "In recent years hypergraphs have emerged as a powerful tool to study systems with multi-body interactions which cannot be trivially reduced to pairs. While highly structured benchmark models have proved fundamental for the standardized evaluation of algorithms and the statistical study of real-world networked data, these are scarcely available in the context of hypergraphs. Here we propose a flexible and efficient framework for the generation of hypergraphs with many nodes and large hyperedges, which allows to specify general community structures and tune different local statistics. We illustrate how to use our model to sample synthetic data with desired features (assortative or disassortative communities, mixed or hard community assignments, etc.), benchmark community detection algorithms, and generate hypergraphs structurally similar to real-world data. Overcoming previous limitations on the generation of synthetic hypergraphs, our work constitutes a substantial advancement in the statistical modeling of higher-order systems."}}
{"id": "f9LfAf6AAxP", "cdate": 1671878794275, "mdate": 1671878794275, "content": {"title": "Fast rates for noisy interpolation require rethinking the effects of inductive bias", "abstract": "Good generalization performance on high-dimensional data crucially hinges on a simple structure of the ground truth and a corresponding strong inductive bias of the estimator. Even though this intuition is valid for regularized models, in this paper we caution against a strong inductive bias for interpolation in the presence of noise: Our results suggest that, while a stronger inductive bias encourages a simpler structure that is more aligned with the ground truth, it also increases the detrimental effect of noise. Specifically, for both linear regression and classification with a sparse ground truth, we prove that minimum -norm and maximum -margin interpolators achieve fast polynomial rates up to order  for  compared to a logarithmic rate for . Finally, we provide experimental evidence that this trade-off may also play a crucial role in understanding non-linear interpolating models used in practice."}}
{"id": "0sBvXqyvgUT", "cdate": 1653100931056, "mdate": null, "content": {"title": "Provable Concept Learning for Interpretable Predictions Using Variational Autoencoders", "abstract": "In safety-critical applications, practitioners are reluctant to trust neural networks when no interpretable explanations are available. Many attempts to provide such explanations revolve around pixel-level attributions or use previously known concepts. In this paper we aim to provide explanations by provably identifying \\emph{high-level, previously unknown concepts}. To this end, we propose a probabilistic modeling framework to derive (C)oncept (L)earning and (P)rediction (CLAP) - a VAE-based classifier that uses visually interpretable concepts as linear predictors. Assuming that the data generating mechanism involves interpretable concepts, we prove that our method is able to identify them while attaining optimal classification accuracy. We use synthetic experiments for validation, and also show that on the ChestXRay dataset, CLAP effectively discovers interpretable factors for classifying diseases. "}}
{"id": "qO0tuXYhbyp", "cdate": 1577836800000, "mdate": 1633725357518, "content": {"title": "Sampling on networks: estimating spectral centrality measures and their impact in evaluating other relevant network measures", "abstract": "We perform an extensive analysis of how sampling impacts the estimate of several relevant network measures. In particular, we focus on how a sampling strategy optimized to recover a particular spectral centrality measure impacts other topological quantities. Our goal is on one hand to extend the analysis of the behavior of TCEC (Ruggeri and De Bacco, in: Cherifi, Gaito, Mendes, Moro, Rocha (eds) Complex networks and their applications VIII, Springer, Cham, pp 90\u2013101, 2020), a theoretically-grounded sampling method for eigenvector centrality estimation. On the other hand, to demonstrate more broadly how sampling can impact the estimation of relevant network properties like centrality measures different than the one aimed at optimizing, community structure and node attribute distribution. In addition, we analyze sampling behaviors in various instances of network generative models. Finally, we adapt the theoretical framework behind TCEC for the case of PageRank centrality and propose a sampling algorithm aimed at optimizing its estimation. We show that, while the theoretical derivation can be suitably adapted to cover this case, the resulting algorithm suffers of a high computational complexity that requires further approximations compared to the eigenvector centrality case. Main contributions (a) Extensive empirical analysis of the impact of the TCEC sampling method (optimized for eigenvector centrality recovery) on different centrality measures, community structure, node attributes and statistics related to specific network generative models; (b) extending TCEC to optimize PageRank estimation."}}
{"id": "UkR81hsp-4K", "cdate": 1546300800000, "mdate": 1633725357514, "content": {"title": "Sampling on Networks: Estimating Eigenvector Centrality on Incomplete Networks", "abstract": "We develop a new sampling method to estimate eigenvector centrality on incomplete networks. Our goal is to estimate this global centrality measure having at disposal a limited amount of data. This is the case in many real-world scenarios where data collection is expensive, the network is too big for data storage capacity or only partial information is available. The sampling algorithm is theoretically grounded by results derived from spectral approximation theory. We studied the problem on both synthetic and real data and tested the performance comparing with state-of-the-art methods. We show that approximations obtained from such methods are not always reliable and that our algorithm, while preserving computational scalability, improves performance under some relevant error measures."}}
