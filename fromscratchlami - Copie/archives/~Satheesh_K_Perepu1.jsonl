{"id": "4lCfx_vKDu", "cdate": 1672531200000, "mdate": 1683619346034, "content": {"title": "Domain Adaptation of Reinforcement Learning Agents based on Network Service Proximity", "abstract": "The dynamic and evolutionary nature of service requirements in wireless networks has motivated the telecom industry to consider intelligent self-adapting Reinforcement Learning (RL) agents for controlling the growing portfolio of network services. Infusion of many new types of services is anticipated with future adoption of 6G networks, and sometimes these services will be defined by applications that are external to the network. An RL agent trained for managing the needs of a specific service type may not be ideal for managing a different service type without domain adaptation. We provide a simple heuristic for evaluating a measure of proximity between a new service and existing services, and show that the RL agent of the most proximal service rapidly adapts to the new service type through a well defined process of domain adaptation. Our approach enables a trained source policy to adapt to new situations with changed dynamics without retraining a new policy, thereby achieving significant computing and cost-effectiveness. Such domain adaptation techniques may soon provide a foundation for more generalized RL-based service management under the face of rapidly evolving service types."}}
{"id": "arPhndwh3VY", "cdate": 1640995200000, "mdate": 1683619345987, "content": {"title": "A novel unsupervised method for root cause analysis of anomalies using sparse optimization techniques", "abstract": "Anomaly detection is an imperative problem associated with emerging fields such as the Internet of Things, Telecommunication and Manufacturing Industries. Timely detection of anomalies and attribution to its sources enables to enforce preventive measures so as to maintain optimal process operation and avoid undesirable down-times. In this work, we propose an unsupervised method which enables detection, quantification and diagnosis of amplitude anomalies from multivariate data. The proposed method utilizes the ideas of sparse optimization to effectively decompose the data contributions into with and without anomalies for the purpose of anomaly detection and quantification. Further, the ideas of the directed graph are implemented on the estimated anomaly-free data to determine the root cause of anomaly to enable preventive maintenance. The efficacy of the proposed method is demonstrated on two case studies comprising of synthetic and real-time datasets."}}
{"id": "HxBeGrLasw", "cdate": 1640995200000, "mdate": 1683619346010, "content": {"title": "Optimize Next State Prediction in Safe RL for 5G Ecosystem", "abstract": "Traditional supervised learning techniques need fairly a big number of data and computational power to train models, which is unavailable in the mobile ecosystem. However, in many situations, big data collection is completely difficult, and one may resort to Reinforcement Learning (RL) which enables the agent to learn from scratch by interacting with the environment. Since the agent learns from scratch by taking random actions, there is a possibility that an environment may transit to an unsafe state. In literature, we can find some methods which predict the transition to an unsafe state in advance and ensure that the specific action will not be executed. However, the underlying process is stochastic, and normal prediction methods will give poor accuracy. In this paper, we propose a method to predict the possible next transition state assuming that the labels are noisy. Results show that the proposed method can predict the next state with higher accuracy when compared with existing methods by considering the underlying stochasticity. The value addition of the proposed method is that it will make agents converge faster compared to traditional RL methods since we are modifying the expected trajectories in advance, and it can save a good number of computational resources. Three case studies related to 5G mobile networks were considered to explore the advantage of the proposed method."}}
{"id": "EtyJOPmCFc", "cdate": 1640995200000, "mdate": 1683619346010, "content": {"title": "Multi-agent reinforcement learning for intent-based service assurance in cellular networks", "abstract": "Recently, intent-based management has received good attention in telecom networks owing to stringent performance requirements for many of the use cases. Several approaches in the literature employ traditional closed-loop driven methods to fulfill the intents on the KPIs. However, these methods consider every closed-loop independent of each other which degrades the combined performance. Also, such existing methods are not easily scalable. Multi-agent reinforcement learning (MARL) techniques have shown significant promise in many areas in which traditional closed-loop control falls short, typically for complex coordination and conflict management among loops. In this work, we propose a method based on MARL to achieve intent-based management without the need for knowing a model of the underlying system. Moreover, when there are conflicting intents, the MARL agents can implicitly incentivize the loops to cooperate and promote trade-offs, without human interaction, by prioritizing the important KPIs. Experiments have been performed on a network emulator for optimizing KPIs of three services. Results obtained demonstrate that the proposed system performs quite well and is able to fulfill all existing intents when there are enough resources or prioritize the KPIs when resources are scarce."}}
{"id": "Ee36ZTxD0c2", "cdate": 1640995200000, "mdate": 1683619346005, "content": {"title": "Intent-based multi-agent reinforcement learning for service assurance in cellular networks", "abstract": "Recently, intent-based management is receiving good attention in telecom networks owing to stringent performance requirements for many of the use cases. Several approaches on the literature employ traditional methods in the telecom domain to fulfill intents on the KPIs, which can be defined as a closed loop. However, these methods consider every closed-loop independent of each other which degrades the combined closed-loop performance. Also, when many closed loops are needed, these methods are not easily scalable. Multi-agent reinforcement learning (MARL) techniques have shown significant promise in many areas in which traditional closed-loop control falls short, typically for complex coordination and conflict management among loops. In this work, we propose a method based on MARL to achieve intent-based management without the requirement of the model of the underlying system. Moreover, when there are conflicting intents, the MARL agents can implicitly incentivize the loops to cooperate, without human interaction, by prioritizing the important KPIs. Experiments have been performed on a network emulator on optimizing KPIs for three services and we observe the proposed system performs well and is able to fulfill all existing intents when there are enough resources or prioritize the KPIs when there are scarce resources."}}
{"id": "X59kvde4v1Y", "cdate": 1632875642748, "mdate": null, "content": {"title": "DSDF: Coordinated look-ahead strategy in stochastic multi-agent reinforcement learning", "abstract": "Multi-Agent reinforcement learning has received lot of attention in recent years and have applications in many different areas. Existing methods involving Centralized Training and Decentralized execution, attempts to train the agents towards learning a pattern of coordinated actions to arrive at optimal joint policy. However if some agents are stochastic in their action to varying degrees, the above methods provides poor coordination among agents. In this paper we show how the stochasticity of agents, which could be a result of malfunction  or aging of robots, can add to the uncertainty in coordination and thereby contribute to unsatisfactory global rewards. In such a scenario, the deterministic agents have to understand the behavior and limitations of the  stochastic agents while the stochastic agents have to plan taking in cognizance their own limitations. Our proposed method, Deep Stochastic Discounted Factor (DSDF), tunes the discounted factor for the agents by using a learning representation of uncertainty to update the utility networks of individual agents. DSDF also helps in imparting an extent of reliability in coordination thereby granting stochastic agents tasks which are immediate and of shorter trajectory with deterministic ones taking the tasks which involve longer planning. Results on benchmark environments shows the efficacy of the proposed approach when compared with existing deterministic approaches."}}
{"id": "s0Xx5mUd2kw", "cdate": 1609459200000, "mdate": 1683619346013, "content": {"title": "DSDF: An approach to handle stochastic agents in collaborative multi-agent reinforcement learning", "abstract": "Multi-Agent reinforcement learning has received lot of attention in recent years and have applications in many different areas. Existing methods involving Centralized Training and Decentralized execution, attempts to train the agents towards learning a pattern of coordinated actions to arrive at optimal joint policy. However if some agents are stochastic to varying degrees of stochasticity, the above methods often fail to converge and provides poor coordination among agents. In this paper we show how this stochasticity of agents, which could be a result of malfunction or aging of robots, can add to the uncertainty in coordination and there contribute to unsatisfactory global coordination. In this case, the deterministic agents have to understand the behavior and limitations of the stochastic agents while arriving at optimal joint policy. Our solution, DSDF which tunes the discounted factor for the agents according to uncertainty and use the values to update the utility networks of individual agents. DSDF also helps in imparting an extent of reliability in coordination thereby granting stochastic agents tasks which are immediate and of shorter trajectory with deterministic ones taking the tasks which involve longer planning. Such an method enables joint co-ordinations of agents some of which may be partially performing and thereby can reduce or delay the investment of agent/robot replacement in many circumstances. Results on benchmark environment for different scenarios shows the efficacy of the proposed approach when compared with existing approaches."}}
{"id": "hoIxqD_1Uz", "cdate": 1609459200000, "mdate": 1683619346015, "content": {"title": "Intelligent Question Answering using Knowledge Representation for Managed Services", "abstract": "Field service operations (FSO) personnel play a critical role to handle the issues in Managed Services for the telecommunication industry. It is required to support the FSO\u2019s by giving the necessary resources and make them to solve the problem in the most efficient way. Currently, in managed services related to different industries, the FSO has been provided with documentation of the product/s that they are dealing with, which span to hundreds and thousands of pages. However, solving a problem efficiently requires the information in a concise manner by considering FSO\u2019s legitimate time. In this paper, we propose two methods to extract necessary information from the thousands of pages of documents based on the issue the FSO is currently handling. The first method presents a hybrid methodology that combines effectively the results of both the models (term categorization and topic modelling) through the modified loss function to efficiently search through the knowledge graph representation for picking the relevant set of documents. As a second method, we have introduced a new fine-tuned Bidirectional Encoder Representations (BERT) model for Question and Answering (QA) purpose and it has been modelled as a classification problem. The proposed fine-tuned BERT approach automatically generates an answer to the FSO\u2019s questions during emergencies from the selected documents using the first method. We found both these methods are working effectively with >90% accuracy and efficiency in most of the cases relate to managed services."}}
{"id": "V0IxUuiDkMQ", "cdate": 1609459200000, "mdate": 1683619346007, "content": {"title": "Zero-Shot Federated Learning with New Classes for Audio Classification", "abstract": "Federated learning is an effective way of extracting insights from different user devices while preserving the privacy of users. However, new classes with completely unseen data distributions can stream across any device in a federated learning setting, whose data cannot be accessed by the global server or other users. To this end, we propose a unified zero-shot framework to handle these aforementioned challenges during federated learning. We simulate two scenarios here -- 1) when the new class labels are not reported by the user, the traditional FL setting is used; 2) when new class labels are reported by the user, we synthesize Anonymized Data Impressions by calculating class similarity matrices corresponding to each device's new classes followed by unsupervised clustering to distinguish between new classes across different users. Moreover, our proposed framework can also handle statistical heterogeneities in both labels and models across the participating users. We empirically evaluate our framework on-device across different communication rounds (FL iterations) with new classes in both local and global updates, along with heterogeneous labels and models, on two widely used audio classification applications -- keyword spotting and urban sound classification, and observe an average deterministic accuracy increase of ~4.041% and ~4.258% respectively."}}
{"id": "SaVupCrqLq", "cdate": 1609459200000, "mdate": 1683619346007, "content": {"title": "Zero-Shot Federated Learning with New Classes for Audio Classification", "abstract": "Federated learning is an effective way of extracting insights from different user devices while preserving the privacy of users. However, new classes with completely unseen data distributions can stream across any device in a federated learning setting, whose data cannot be accessed by the global server or other users. To this end, we propose a unified zero-shot framework to handle these aforementioned challenges during federated learning. We simulate two scenarios here \u2014 1) when the new class labels are not reported by the user, the traditional FL setting is used; 2) when new class labels are reported by the user, we synthesize Anonymized Data Impressions by calculating class similarity matrices corresponding to each device\u2019s new classes followed by unsupervised clustering to distinguish between new classes across different users. Moreover, our proposed framework can also handle statistical heterogeneities in both labels and models across the participating users. We empirically evaluate our framework on-device across different communication rounds (FL iterations) with new classes in both local and global updates, along with heterogeneous labels and models, on two widely used audio classification applications \u2014 keyword spotting and urban sound classification, and observe an average deterministic accuracy increase of ~4.041% and ~4.258% respectively."}}
