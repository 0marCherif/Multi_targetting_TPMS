{"id": "lIvrvSZr74Z", "cdate": 1672531200000, "mdate": 1695955591349, "content": {"title": "How Does Semi-supervised Learning with Pseudo-labelers Work? A Case Study", "abstract": ""}}
{"id": "e_nv7AFopD8", "cdate": 1672531200000, "mdate": 1682365432948, "content": {"title": "Benign Overfitting for Two-layer ReLU Networks", "abstract": "Modern deep learning models with great expressive power can be trained to overfit the training data but still generalize well. This phenomenon is referred to as benign overfitting. Recently, a few studies have attempted to theoretically understand benign overfitting in neural networks. However, these works are either limited to neural networks with smooth activation functions or to the neural tangent kernel regime. How and when benign overfitting can occur in ReLU neural networks remains an open problem. In this work, we seek to answer this question by establishing algorithm-dependent risk bounds for learning two-layer ReLU convolutional neural networks with label-flipping noise. We show that, under mild conditions, the neural network trained by gradient descent can achieve near-zero training loss and Bayes optimal test risk. Our result also reveals a sharp transition between benign and harmful overfitting under different conditions on data distribution in terms of test risk. Experiments on synthetic data back up our theory."}}
{"id": "SVXbK2VG1O", "cdate": 1672531200000, "mdate": 1695955591357, "content": {"title": "Benign Overfitting in Two-layer ReLU Convolutional Neural Networks", "abstract": "Modern deep learning models with great expressive power can be trained to overfit the training data but still generalize well. This phenomenon is referred to as benign overfitting. Recently, a few ..."}}
{"id": "Dzmd-Cc8OI", "cdate": 1663850436881, "mdate": null, "content": {"title": "How Does Semi-supervised Learning with Pseudo-labelers Work? A Case Study", "abstract": "Semi-supervised learning is a popular machine learning paradigm that utilizes a large amount of unlabeled data as well as a small amount of labeled data to facilitate learning tasks. While semi-supervised learning has achieved great success in training neural networks, its theoretical understanding remains largely open. In this paper, we aim to theoretically understand a semi-supervised learning approach based on pre-training and linear probing. In particular, the semi-supervised learning approach we consider first trains a two-layer neural network based on the unlabeled data with the help of pseudo-labelers. Then it linearly probes the pre-trained network on a small amount of labeled data. We prove that, under a certain toy data generation model and two-layer convolutional neural network, the semisupervised learning approach can achieve nearly zero test loss, while a neural network directly trained by supervised learning on the same amount of labeled data can only achieve constant test loss. Through this case study, we demonstrate a separation between semi-supervised learning and supervised learning in terms of test loss provided the same amount of labeled data."}}
{"id": "bw-nV0u4lUt", "cdate": 1640995200000, "mdate": 1682365432945, "content": {"title": "Certified Adversarial Robustness Under the Bounded Support Set", "abstract": "Deep neural networks (DNNs) have revealed severe vulnerability to adversarial perturbations, beside empirical adversarial training for robustness, the design of provably robust classifiers attracts..."}}
{"id": "_HFPHFbJrP-", "cdate": 1632875533007, "mdate": null, "content": {"title": "Certified Adversarial Robustness Under the Bounded Support Set", "abstract": "Deep neural networks (DNNs) have revealed severe vulnerability to adversarial perturbations, beside empirical adversarial training for robustness, the design of provably robust classifiers attracts more and more attention. Randomized smoothing method provides the certified robustness with agnostic architecture, which is further extended to a provable robustness framework using $f$-divergence. While these methods cannot be applied to smoothing measures with bounded support set such as uniform probability measure due to the use of likelihood ratio in their certification methods. In this paper, we introduce a framework that is able to deal with robustness properties of arbitrary smoothing measures including those with bounded support set by using Wasserstein distance as well as total variation distance. By applying our methodology to uniform probability measures with support set $B_{2}(O,r)$, we obtain certified robustness properties with respect to $l_{p}$-perturbations. And by applying to uniform probability measures with support set $B_{\\infty}(O,r)$, we obtain certified robustness properties with respect to $l_{1},l_{2},l_{\\infty}$-perturbations. We present experimental results on CIFAR-10 dataset with ResNet to validate our theory. It is worth mentioning that our certification procedure only costs constant computation time which is an improvement upon the state-of-the-art methods in terms of the computation time."}}
