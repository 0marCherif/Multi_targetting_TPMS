{"id": "T6QZmBPlfv6", "cdate": 1664928791006, "mdate": null, "content": {"title": "Reliability benchmarks for image segmentation", "abstract": "Recent work has shown the importance of reliability, where model performance is assessed under stress conditions pervasive in real-world deployment. In this work, we examine reliability tasks in the setting of semantic segmentation, a dense output problem that has typically only been evaluated using in-distribution predictive performance---for example, the mean intersection over union score on the Cityscapes validation set. To reduce the gap toward reliable deployment in the real world, we compile a benchmark involving existing (and newly constructed) distribution shifts and metrics. We evaluate current models and several baselines to determine how well segmentation models make robust predictions across multiple types of distribution shift and flag when they don\u2019t know.\n"}}
{"id": "6sBiAIpkUiO", "cdate": 1664725485447, "mdate": null, "content": {"title": "The Best Deep Ensembles Sacrifice Predictive Diversity", "abstract": "Ensembling remains a hugely popular method for increasing the performance of a given class of models. In the case of deep learning, the benefits of ensembling are often attributed to the diverse predictions of the individual ensemble members. Here we investigate a tradeoff between diversity and individual model performance, and find that--surprisingly--encouraging diversity during training almost always yields worse ensembles. We show that this tradeoff arises from the Jensen gap between the single model and ensemble losses, and show that Jensen gap is a natural measure of diversity for both the mean squared error and cross entropy loss functions. Our results suggest that to reduce the ensemble error, we should move away from efforts to increase predictive diversity, and instead we should construct ensembles from less diverse (but more accurate) component models. "}}
{"id": "6x0gB9gOHFg", "cdate": 1653595784051, "mdate": null, "content": {"title": "Plex: Towards Reliability using Pretrained Large Model Extensions", "abstract": "A recent trend in artificial intelligence is the use of pretrained models for language and vision tasks, which have achieved extraordinary performance but also puzzling failures. Probing these models' abilities in diverse ways is therefore critical to the field. In this paper, we explore the reliability of models, where we define a reliable model as one that not only achieves strong predictive performance but also performs well consistently over many decision-making tasks involving uncertainty (e.g., selective prediction, open set recognition), robust generalization (e.g., accuracy and proper scoring rules such as log-likelihood on in- and out-of-distribution datasets), and adaptation (e.g., active learning, few-shot uncertainty). We devise 10 types of tasks over 38 datasets in order to evaluate different aspects of reliability on both vision and language domains. To improve reliability, we developed ViT-Plex and T5-Plex, pretrained large model extensions (plex) for vision and language modalities, respectively. Plex greatly improves the state-of-the-art across reliability tasks, and simplifies the traditional protocol as it does not require designing scores or tuning the model for each individual task. We demonstrate scaling effects over model sizes up to 1B parameters and pretraining dataset sizes up to 4B examples. We also demonstrate Plex's capabilities on challenging tasks including zero-shot open set recognition, active learning, and uncertainty in conversational language understanding."}}
{"id": "Wl1ZIgMqLlq", "cdate": 1652737584667, "mdate": null, "content": {"title": "Deep Ensembles Work, But Are They Necessary?", "abstract": "Ensembling neural networks is an effective way to increase accuracy, and can often match the performance of individual larger models. This observation poses a natural question: given the choice between a deep ensemble and a single neural network with similar accuracy, is one preferable over the other? Recent work suggests that deep ensembles may offer distinct benefits beyond predictive power: namely, uncertainty quantification and robustness to dataset shift. In this work, we demonstrate limitations to these purported benefits, and show that a single (but larger) neural network can replicate these qualities. First, we show that ensemble diversity, by any metric, does not meaningfully contribute to an ensemble's ability to detect out-of-distribution (OOD) data, but is instead highly correlated with the relative improvement of a single larger model. Second, we show that the OOD performance afforded by ensembles is strongly determined by their in-distribution (InD) performance, and - in this sense - is not indicative of any \"effective robustness.\" While deep ensembles are a practical way to achieve improvements to predictive power, uncertainty quantification, and robustness, our results show that these improvements can be replicated by a (larger) single model."}}
{"id": "onOCUrJEILa", "cdate": 1601053282415, "mdate": null, "content": {"title": "Deep Graph Pose: a semi-supervised deep graphical model for improved animal pose tracking", "abstract": "Noninvasive behavioral tracking of animals is crucial for many scientific inves- tigations. Recent transfer learning approaches for behavioral tracking have con- siderably advanced the state of the art. Typically these methods treat each video frame and each object to be tracked independently. In this work, we improve on these methods (particularly in the regime of few training labels) by leveraging the rich spatiotemporal structures pervasive in behavioral video \u2014 specifically, the spatial statistics imposed by physical constraints (e.g., paw to elbow distance), and the temporal statistics imposed by smoothness from frame to frame. We pro- pose a probabilistic graphical model built on top of deep neural networks, Deep Graph Pose (DGP), to leverage these useful spatial and temporal constraints, and develop an efficient structured variational approach to perform inference in this model. The resulting semi-supervised model exploits both labeled and unlabeled frames to achieve significantly more accurate and robust tracking while requiring users to label fewer training frames. In turn, these tracking improvements enhance performance on downstream applications, including robust unsupervised segmen- tation of behavioral \u201csyllables,\u201d and estimation of interpretable \u201cdisentangled\u201d low-dimensional representations of the full behavioral video."}}
{"id": "e_Vl9_aTIT8", "cdate": 1597086661605, "mdate": null, "content": {"title": "Penalized matrix decomposition for denoising, compression, and improved demixing of functional imaging data", "abstract": "Calcium imaging has revolutionized systems neuroscience, providing the ability to image large neural populations with single-cell resolution. The resulting datasets are quite large (with scales of TB/hour in some cases), which has presented a barrier to routine open sharing of this data, slowing progress in reproducible research. State of the art methods for analyzing this data are based on non- negative matrix factorization (NMF); these approaches solve a non-convex optimization problem, and are highly effective when good initializations are available, but can break down e.g. in low-SNR settings where common initialization approaches fail.\nHere we introduce an improved approach to compressing and denoising functional imaging data. The method is based on a spatially-localized penalized matrix decomposition (PMD) of the data to separate (low-dimensional) signal from (temporally-uncorrelated) noise. This approach can be applied in parallel on local spatial patches and is therefore highly scalable, does not impose non- negativity constraints or require stringent identifiability assumptions (leading to significantly more robust results compared to NMF), and estimates all parameters directly from the data, so no hand-tuning is required. We have applied the method to a wide range of functional imaging data (including one-photon, two-photon, three-photon, widefield, somatic, axonal, dendritic, calcium, and voltage imaging datasets): in all cases, we observe \u223c2-4x increases in SNR and compression rates of 20-300x with minimal visible loss of signal, with no adjustment of hyperparameters; this in turn facilitates the process of demixing the observed activity into contributions from individual neurons. We focus on two challenging applications: dendritic calcium imaging data and voltage imaging data in the context of optogenetic stimulation. In both cases, we show that our new approach leads to faster and much more robust extraction of activity from the video data."}}
{"id": "o_a_bBItkeO", "cdate": 1597086466165, "mdate": null, "content": {"title": "Quantifying the behavioral dynamics of C. elegans with autoregressive hidden Markov models", "abstract": "In order to fully understand the neural activity of Caenorhabditis elegans, we need a rich, quantitative description of the behavioral outputs it gives rise to. To this end, we quantify the behavioral dynamics of the worm with autoregressive hidden Markov models (AR-HMMs), a class of models that has recently yielded some insight into mouse behavior [1]. These models explicitly encode three hy- potheses: (i) while the instantaneous posture of the worm is represented as a high- dimensional vector of points along the body, the first four principal components, or eigenworms, capture a significant fraction of the postural variance; (ii) within this four dimensional space, the postural dynamics are well-approximated with linear autoregressive models; and (iii) the linear autoregressive model switches over time as the worm transitions between different discrete behaviors, like forward crawling, reverse crawling, pausing, and turning. We show how AR-HMMs seg- ment recordings of freely crawling C. elegans into meaningful discrete behaviors, providing a quantitative description of postural dynamics and a rigorous framework for assessing, comparing, and simulating worm behavior."}}
