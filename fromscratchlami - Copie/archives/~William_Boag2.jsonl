{"id": "SHJ7wQyl4q", "cdate": 1696060655629, "mdate": 1696060655629, "content": {"title": "CliNER 2.0: Accessible and Accurate Clinical Concept Extraction", "abstract": "Clinical notes often describe important aspects of a patient's stay and are therefore critical to medical research. Clinical concept extraction (CCE) of named entities - such as problems, tests, and treatments - aids in forming an understanding of notes and provides a foundation for many downstream clinical decision-making tasks. Historically, this task has been posed as a standard named entity recognition (NER) sequence tagging problem, and solved with feature-based methods using handengineered domain knowledge. Recent advances, however, have demonstrated the efficacy of LSTM-based models for NER tasks, including CCE. This work presents CliNER 2.0, a simple-to-install, open-source tool for extracting concepts from clinical text. CliNER 2.0 uses a word- and character- level LSTM model, and achieves state-of-the-art performance. For ease of use, the tool also includes pre-trained models available for public use."}}
{"id": "JX6H-c57Bg3", "cdate": 1596469352574, "mdate": null, "content": {"title": "Clinical Collabsheets: 53 Questions to Guide a Clinical Collaboration", "abstract": "Clinical Machine Learning (ML) is a rapidly-growing field due to the digitization of hos- pital records, recent advances in ML techniques, and the ability to leverage increasing computational power for large and complex models. The high stakes and often unintuitive nature of clinical data make effective collaboration between clinicians and ML researchers one of the most important aspects of working in this interdisciplinary space. However, there are few resources codifying best practices for collaboration on Clinical ML projects. In this paper, we interviewed 18 experts in the Clinical ML field and distilled their ad- vice and experiences into a list of questions (a Helathcare Collabsheet) ML scientists and clinicians can use to promote effective discussion when working on a new project. We in- tend this for a broad audience as checklist of discussion points to hit at a kickoff meeting, even for experienced researchers. This resource will enable more successful partnerships in Clinical ML with improved interdisciplinary communication and organization."}}
{"id": "1e8oLKa9bsL", "cdate": 1589608816362, "mdate": null, "content": {"title": "Racial Disparities and Mistrust in End-of-Life Care", "abstract": "There are established racial disparities in healthcare, including during end-of-life care,\nwhen poor communication and trust can lead to suboptimal outcomes for patients and\ntheir families. In this work, we find that racial disparities which have been reported in\nexisting literature are also present in the MIMIC-III database. We hypothesize that one\nunderlying cause of this disparity is due to mistrust between patient and caregivers, and we\ndevelop multiple possible trust metric proxies (using coded interpersonal variables and clinical notes) to measure this phenomenon more directly. These metrics show even stronger\ndisparities in end-of-life care than race does, and they also tend to demonstrate statistically significant higher levels of mistrust for black patients than white ones. Finally, we\ndemonstrate that these metrics improve performance on three clinical tasks: in-hospital\nmortality, discharge against medical advice (AMA) and modified care status (e.g., DNR,\nDNI, etc.)."}}
{"id": "fF-ZwUtcs0M", "cdate": 1589608707207, "mdate": null, "content": {"title": " Baselines for Chest X-Ray Report Generation", "abstract": "With advances in deep learning and image captioning over the past few years, researchers\nhave recently begun applying computer vision methods to radiology report generation.\nTypically, these generated reports have been evaluated using general domain natural language generation (NLG) metrics like CIDEr and BLEU. However, there is little work assessing how appropriate these metrics are for healthcare, where correctness is critically\nimportant. In this work, we profile a number of models for automatic report generation\non this dataset, including: random report retrieval, nearest neighbor report retrieval, ngram language models, and neural network approaches. These models serve to calibrate\nour understanding for what the opaque general domain NLG metrics mean. In particular,\nwe find that the standard NLG metrics (e.g. BLEU, CIDEr) actually assign higher scores\nto random (but grammatical) clinical sentences over n-gram-derived sentences, despite the\nn-gram sentences achieving higher clinical accuracy. This casts doubt on the usefulness of\nthese domain-agnostic metrics, though unsurprisingly we find that the best performance\n\u2013 on both CIDEr/BLEU and clinical correctness \u2013 was achieved by more sophisticated\nmodels."}}
{"id": "Dgu7eNFRq7v", "cdate": 1588827929516, "mdate": null, "content": {"title": "Publicly Available Clinical BERT Embeddings", "abstract": "Contextual word embedding models such as ELMo (Peters et al., 2018) and BERT (De- vlin et al., 2018) have dramatically improved performance for many natural language pro- cessing (NLP) tasks in recent months. How- ever, these models have been minimally ex- plored on specialty corpora, such as clini- cal text; moreover, in the clinical domain, no publicly-available pre-trained BERT models yet exist. In this work, we address this need by exploring and releasing BERT models for clinical text: one for generic clinical text and another for discharge summaries specifically. We demonstrate that using a domain-specific model yields performance improvements on three common clinical NLP tasks as compared to nonspecific embeddings. These domain- specific models are not as performant on two clinical de-identification tasks, and argue that this is a natural consequence of the differences between de-identified source text and synthet- ically non de-identified task text."}}
{"id": "vdd5NiG59Vk", "cdate": 1514764800000, "mdate": null, "content": {"title": "Precision Medicine: matching cancer patients with relevant treatments", "abstract": "Author Summary The cortex is a highly modular structure with a large number of functionally specialized areas that communicate with each other through long-range cortical connections. It is has been suggested that communication between spiking neuronal networks (SNNs) requires synchronization of spiking activity which is either provided by the flow of neuronal activity across divergent/convergent connections, as suggested by computational models of SNNs, or by local oscillations in the gamma frequency band (30&ndash;100 Hz). However, such communication requires unphysiologically dense/strong connectivity, and the mechanisms required to synchronize separated local oscillators remain poorly understood. Here, we present a novel mechanism that alleviates these shortcomings and enables the propagation synchrony across weakly connected SNNs by locally amplifying feeble synchronization through resonance that naturally occurs in oscillating networks of excitatory and inhibitory neurons. We show that oscillatory stimuli at the network resonance frequencies generate a slowly propagating oscillation that is synchronized across the distributed networks. Moreover, communication with such oscillations depends on the dynamical state of the background activity in the SNN. Our results suggest that the emergence of synchronized oscillations can be viewed as a consequence of spiking activity propagation in weakly connected networks that is supported by resonance and modulated by the dynamics of the ongoing activity."}}
{"id": "9Tadh0Hwlgc", "cdate": 1514764800000, "mdate": null, "content": {"title": "Precision Medicine: matching cancer patients with clinical trials", "abstract": ""}}
{"id": "JYUWmPqFD89", "cdate": 1483228800000, "mdate": null, "content": {"title": "A Hybrid Approach to Precision Medicine-related Biomedical Article Retrieval and Clinical Trial Matching", "abstract": ""}}
{"id": "Fw7QkAS94d", "cdate": 1451606400000, "mdate": null, "content": {"title": "MUTT: Metric Unit TesTing for Language Generation Tasks", "abstract": "William Boag, Renan Campos, Kate Saenko, Anna Rumshisky. Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 2016."}}
{"id": "7zk6JzwZw9", "cdate": 1451606400000, "mdate": null, "content": {"title": "SimiHawk at SemEval-2016 Task 1: A Deep Ensemble System for Semantic Textual Similarity", "abstract": "Peter Potash, William Boag, Alexey Romanov, Vasili Ramanishka, Anna Rumshisky. Proceedings of the 10th International Workshop on Semantic Evaluation (SemEval-2016). 2016."}}
