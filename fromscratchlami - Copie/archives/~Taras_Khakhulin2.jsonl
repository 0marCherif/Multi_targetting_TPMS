{"id": "IMrlJR_F52", "cdate": 1690848000000, "mdate": 1700508826559, "content": {"title": "HumanRF: High-Fidelity Neural Radiance Fields for Humans in Motion", "abstract": "Representing human performance at high-fidelity is an essential building block in diverse applications, such as film production, computer games or videoconferencing. To close the gap to production-level quality, we introduce HumanRF1, a 4D dynamic neural scene representation that captures full-body appearance in motion from multi-view video input, and enables playback from novel, unseen viewpoints. Our novel representation acts as a dynamic video encoding that captures fine details at high compression rates by factorizing space-time into a temporal matrix-vector decomposition. This allows us to obtain temporally coherent reconstructions of human actors for long sequences, while representing high-resolution details even in the context of challenging motion. While most research focuses on synthesizing at resolutions of 4MP or lower, we address the challenge of operating at 12MP. To this end, we introduce ActorsHQ, a novel multi-view dataset that provides 12MP footage from 160 cameras for 16 sequences with high-fidelity, per-frame mesh reconstructions2. We demonstrate challenges that emerge from using such high-resolution data and show that our newly introduced HumanRF effectively leverages this data, making a significant step towards production-level quality novel view synthesis."}}
{"id": "Q29gTt7FyM", "cdate": 1672531200000, "mdate": 1680685128696, "content": {"title": "Self-improving Multiplane-to-layer Images for Novel View Synthesis", "abstract": ""}}
{"id": "lxUt2CEBeD", "cdate": 1640995200000, "mdate": 1668593532679, "content": {"title": "Realistic One-Shot Mesh-Based Head Avatars", "abstract": "We present a system for the creation of realistic one-shot mesh-based (ROME) human head avatars. From a single photograph, our system estimates the head mesh (with person-specific details in both the facial and non-facial head parts) as well as the neural texture encoding, local photometric and geometric details. The resulting avatars are rigged and can be rendered using a deep rendering network, which is trained alongside the mesh and texture estimators on a dataset of in-the-wild videos. In the experiments, we observe that our system performs competitively both in terms of head geometry recovery and the quality of renders, especially for cross-person reenactment."}}
{"id": "jNbjJk_guM", "cdate": 1640995200000, "mdate": 1667497804612, "content": {"title": "Stereo Magnification with Multi-Layer Images", "abstract": "Representing scenes with multiple semitransparent colored layers has been a popular and successful choice for real-time novel view synthesis. Existing approaches infer colors and transparency values over regularly spaced layers of planar or spherical shape. In this work, we introduce a new view synthesis approach based on multiple semitransparent layers with scene-adapted geometry. Our approach infers such representations from stereo pairs in two stages. The first stage produces the geometry of a small number of data-adaptive layers from a given pair of views. The second stage infers the color and transparency values for these layers, producing the final representation for novel view synthesis. Importantly, both stages are connected through a differentiable renderer and are trained end-to-end. In the experiments, we demonstrate the advantage of the proposed approach over the use of regularly spaced layers without adaptation to scene geometry. Despite being orders of magnitude faster during rendering, our approach also outperforms the recently proposed IBRNet system based on implicit geometry representation."}}
{"id": "N8hIwOuhFl", "cdate": 1640995200000, "mdate": 1667497804606, "content": {"title": "MegaPortraits: One-shot Megapixel Neural Head Avatars", "abstract": ""}}
{"id": "3PEIpPYFd1s", "cdate": 1609459200000, "mdate": 1655670154115, "content": {"title": "Image Generators With Conditionally-Independent Pixel Synthesis", "abstract": "Existing image generator networks rely heavily on spatial convolutions and, optionally, self-attention blocks in order to gradually synthesize images in a coarse-to-fine manner. Here, we present a new architecture for image generators, where the color value at each pixel is computed independently given the value of a random latent vector and the coordinate of that pixel. No spatial convolutions or similar operations that propagate information across pixels are involved during the synthesis. We analyze the modeling capabilities of such generators when trained in an adversarial fashion, and observe the new generators to achieve similar generation quality to state-of-the-art convolutional generators. We also investigate several interesting properties unique to the new architecture."}}
{"id": "aZ7wAnYs9v1", "cdate": 1602926478103, "mdate": null, "content": {"title": "Learning Elimination Ordering for Tree Decomposition Problem", "abstract": "We propose a Reinforcement Learning-based approach to approximately solve the Tree Decomposition problem. \nRecently, it was shown that learned heuristics could successfully solve combinatorial problems. \nWe establish that our approach successfully generalizes from small graphs, where an optimal Tree Decomposition can be found by exact algorithms, to large instances of practical interest, while still having very low time-to-solution.\nOn the other hand, the agent-based approach surpasses all classical greedy heuristics by the quality of the solution."}}
{"id": "OAKTe7W7gg", "cdate": 1577836800000, "mdate": 1655670154115, "content": {"title": "High-Resolution Daytime Translation Without Domain Labels", "abstract": "Modeling daytime changes in high resolution photographs, e.g., re-rendering the same scene under different illuminations typical for day, night, or dawn, is a challenging image manipulation task. We present the high-resolution daytime translation (HiDT) model for this task. HiDT combines a generative image-to-image model and a new upsampling scheme that allows to apply image translation at high resolution. The model demonstrates competitive results in terms of both commonly used GAN metrics and human evaluation. Importantly, this good performance comes as a result of training on a dataset of still landscape images with no daytime labels available."}}
{"id": "Nea1qFbiOnu", "cdate": 1514764800000, "mdate": 1655670154115, "content": {"title": "Robust Word Vectors: Context-Informed Embeddings for Noisy Texts", "abstract": "Valentin Malykh, Varvara Logacheva, Taras Khakhulin. Proceedings of the 2018 EMNLP Workshop W-NUT: The 4th Workshop on Noisy User-generated Text. 2018."}}
