{"id": "sUsujm1Ief", "cdate": 1672531200000, "mdate": 1694399245895, "content": {"title": "RanPAC: Random Projections and Pre-trained Models for Continual Learning", "abstract": "Continual learning (CL) aims to incrementally learn different tasks (such as classification) in a non-stationary data stream without forgetting old ones. Most CL works focus on tackling catastrophic forgetting under a learning-from-scratch paradigm. However, with the increasing prominence of foundation models, pre-trained models equipped with informative representations have become available for various downstream requirements. Several CL methods based on pre-trained models have been explored, either utilizing pre-extracted features directly (which makes bridging distribution gaps challenging) or incorporating adaptors (which may be subject to forgetting). In this paper, we propose a concise and effective approach for CL with pre-trained models. Given that forgetting occurs during parameter updating, we contemplate an alternative approach that exploits training-free random projectors and class-prototype accumulation, which thus bypasses the issue. Specifically, we inject a frozen Random Projection layer with nonlinear activation between the pre-trained model's feature representations and output head, which captures interactions between features with expanded dimensionality, providing enhanced linear separability for class-prototype-based CL. We also demonstrate the importance of decorrelating the class-prototypes to reduce the distribution disparity when using pre-trained representations. These techniques prove to be effective and circumvent the problem of forgetting for both class- and domain-incremental continual learning. Compared to previous methods applied to pre-trained ViT-B/16 models, we reduce final error rates by between 10\\% and 62\\% on seven class-incremental benchmark datasets, despite not using any rehearsal memory. We conclude that the full potential of pre-trained models for simple, effective, and fast continual learning has not hitherto been fully tapped."}}
{"id": "Zm-kppsQ1F", "cdate": 1640995200000, "mdate": 1684390081797, "content": {"title": "Modern Value Based Reinforcement Learning: A Chronological Review", "abstract": "Investigation of value based Reinforcement Learning algorithms exhibited a resurgence into mainstream research in 2015 following demonstration of super-human performance when applied to Atari 2600 games. Since then, significant media attention and hype have accompanied this area, and the field of Artificial Intelligence generally, spread across distinct categories. This review paper is focused exclusively on the progression of value based Reinforcement Learning in the last five years. We aim to distill the incremental improvements to stability and performance in this period, highlighting the minimal changes to the base algorithm over this time. This holds true with all but the one exception of the Recurrent Experience Replay in Distributed Reinforcement Learning algorithm, representing a fundamental shift and increase in agent performance through an advanced memory representation. We suggest a new focus area for value based Reinforcement Learning research."}}
{"id": "htXcfHa9l0", "cdate": 1609459200000, "mdate": 1684390081806, "content": {"title": "The quest for better clinical word vectors: Ontology based and lexical vector augmentation versus clinical contextual embeddings", "abstract": ""}}
{"id": "qQw63tCIZ6", "cdate": 1577836800000, "mdate": 1684390081801, "content": {"title": "End-to-End Phoneme Recognition using Models from Semantic Image Segmentation", "abstract": "We train fully convolutional neural networks with no recurrent layers for the end-to-end phoneme recognition task, using the Connectionist Temporal Classification (CTC) loss function. The adopted network, U-Net, was introduced initially for semantic image segmentation tasks, and is often applied to segmenting features in medical imaging and remote sensing. The similarities between CTC-based automatic speech recognition and semantic segmentation problems are discussed. We extend the encoder-decoder architecture of U-Net and show it is capable of good performance in the acoustic modelling of a speech recognition system. We investigate the importance of the concatenation step in the design of U-net, and report results using the core test set of the TIMIT corpus."}}
{"id": "VEzvWY2JWUc", "cdate": 1577836800000, "mdate": 1684390081804, "content": {"title": "The Impact of Pan-Sharpening and Spectral Resolution on Vineyard Segmentation through Machine Learning", "abstract": "Precision viticulture benefits from the accurate detection of vineyard vegetation from remote sensing, without a priori knowledge of vine locations. Vineyard detection enables efficient, and potentially automated, derivation of spatial measures such as length and area of crop, and hence required volumes of water, fertilizer, and other resources. Machine learning techniques have provided significant advancements in recent years in the areas of image segmentation, classification, and object detection, with neural networks shown to perform well in the detection of vineyards and other crops. However, what has not been extensively quantitatively examined is the extent to which the initial choice of input imagery impacts detection/segmentation accuracy. Here, we use a standard deep convolutional neural network (CNN) to detect and segment vineyards across Australia using DigitalGlobe Worldview-2 images at \u223c50 cm (panchromatic) and \u223c2 m (multispectral) spatial resolution. A quantitative assessment of the variation in model performance with input parameters during model training is presented from a remote sensing perspective, with combinations of panchromatic, multispectral, pan-sharpened multispectral, and the spectral Normalised Difference Vegetation Index (NDVI) considered. The impact of image acquisition parameters\u2014namely, the off-nadir angle and solar elevation angle\u2014on the quality of pan-sharpening is also assessed. The results are synthesised into a \u2018recipe\u2019 for optimising the accuracy of vineyard segmentation, which can provide a guide to others aiming to implement or improve automated crop detection and classification."}}
{"id": "I6HDxa5hXO", "cdate": 1577836800000, "mdate": 1684390081799, "content": {"title": "Acoustic Scene Classification Using Deep Residual Networks with Late Fusion of Separated High and Low Frequency Paths", "abstract": "We investigate the problem of acoustic scene classification, using a deep residual network applied to log-mel spectrograms complemented by log-mel deltas and delta-deltas. We design the network to take into account that the temporal and frequency axes in spectrograms represent fundamentally different information. In particular, we use two pathways in the residual network: one for high frequencies and one for low frequencies, that were fused just two convolutional layers prior to the network output. We conduct experiments using two public 2019 DCASE datasets for acoustic scene classification; the first with binaural audio inputs recorded by a single device, and the second with single-channel audio inputs recorded through various devices. We show the performance of our models are significantly enhanced by the use of log-mel deltas, and that overall our approach is capable of training strong single models, without use of any supplementary data from outside the official challenge dataset, with excellent generalization to unknown devices. In particular, our approach achieved second place in 2019 DCASE Task 1b (0.4% behind the winning entry), and the best Task 1B evaluation results (by a large margin of over 5%) on test data from a device not used to record any training data."}}
{"id": "iuqFZkD9d-", "cdate": 1546300800000, "mdate": 1684390082010, "content": {"title": "Degradation of Performance in Reinforcement Learning with State Measurement Uncertainty", "abstract": "We detail the use of open source training environments to investigate the applicability of standard reinforcement learning techniques to inherently error prone tasks expected in real world application of artificial intelligence. Numerical experiments were conducted in which the performance of both Q Learning and Policy Gradient agents' ability to obtain high reward was compared as the observation state measurement uncertainty was increased. The purpose of the research was to assess the applicability of reinforcement learning to real world applications of self-protection of military platforms, where it is expected that the observed state space is uncertain at best. We found in our experiments that Q Learning is more stable in the presence of state uncertainty than policy gradient learning."}}
{"id": "ijVVzrtOSQ", "cdate": 1546300800000, "mdate": 1684390082004, "content": {"title": "Single-bit-per-weight deep convolutional neural networks without batch-normalization layers for embedded systems", "abstract": "Batch-normalization (BN) layers are thought to be an integrally important layer type in today's state-of-the-art deep convolutional neural networks for computer vision tasks such as classification and detection. However, BN layers introduce complexity and computational overheads that are highly undesirable for training and/or inference on low-power custom hardware implementations of real-time embedded vision systems such as UAVs, robots and Internet of Things (IoT) devices. They are also problematic when batch sizes need to be very small during training, and innovations such as residual connections introduced more recently than BN layers could potentially have lessened their impact. In this paper we aim to quantify the benefits BN layers offer in image classification networks, in comparison with alternative choices. In particular, we study networks that use shifted-ReLU layers instead of BN layers. We found, following experiments with wide residual networks applied to the ImageNet, CIFAR 10 and CIFAR 100 image classification datasets, that BN layers do not consistently offer a significant advantage. We found that the accuracy margin offered by BN layers depends on the data set, the network size, and the bit-depth of weights. We conclude that in situations where BN layers are undesirable due to speed, memory or complexity costs, that using shifted-ReLU layers instead should be considered; we found they can offer advantages in all these areas, and often do not impose a significant accuracy cost."}}
{"id": "aRLW2sSaAFf", "cdate": 1546300800000, "mdate": 1684390081808, "content": {"title": "Using Style-Transfer to Understand Material Classification for Robotic Sorting of Recycled Beverage Containers", "abstract": "Robotic sorting machines are increasingly being investigated for use in recycling centers. We consider the problem of automatically classifying images of recycled beverage containers by material type, i.e. glass, plastic, metal or liquid-packaging-board, when the containers are not in their original condition, meaning their shape and size may be deformed, and coloring and packaging labels may be damaged or dirty. We describe a retrofitted computer vision system and deep convolutional neural network classifier designed for this purpose, that enabled a sorting machine's accuracy and speed to reach commercially viable benchmarks. We investigate what was more important for highly accurate container material recognition: shape, size, color, texture or all of these? To help answer this question, we made use of style-transfer methods from the field of deep learning. We found that removing either texture or shape cues significantly reduced the accuracy in container material classification, while removing color had a minor negative effect. Unlike recent work on generic objects in ImageNet, networks trained to classify by container material type learned better from object shape than texture. Our findings show that commercial sorting of recycled beverage containers by material type at high accuracy is feasible, even when the containers are in poor condition. Furthermore, we reinforce the recent finding that convolutional neural networks can learn predominantly either from texture cues or shape."}}
{"id": "ZH8Zxhm7gWd", "cdate": 1546300800000, "mdate": 1684390081799, "content": {"title": "Predicting Financial Well-Being Using Observable Features and Gradient Boosting", "abstract": "Financial well-being and its measurement are well researched topics in personal finance, yet there is no universally agreed definition of financial well-being. Machine learning is proliferating into new application domains. In this study we investigate the use of state-of-the-art gradient boosting methods for predicting subjective levels of financial well-being, using the Consumer Finance Protection Bureau (CFPB) National Financial Well-being dataset. To enable interpretability, we identify the most important observable features required for accurate predictions. These important features are then analysed using factor analysis to understand hidden themes in the data."}}
