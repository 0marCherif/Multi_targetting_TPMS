{"id": "zii5xe0SOs", "cdate": 1680307200000, "mdate": 1681796429347, "content": {"title": "D\u2192K\u2192I: Data-Knowledge-Driven Group Intelligence Framework for Smart Service in Education Metaverse", "abstract": "Metaverse is the fusion of cyber\u2013physical\u2013social intelligence, and the fusion becomes the core and fundamental property of the metaverse. As an important part of social operationalization, the education domain leads to the birth of the education metaverse. This article answers three basic questions about smart services in the education metaverse: 1) learning scene; 2) technical framework; and 3) initial expansion. Specifically, four key elements constitute the learning scene in the education metaverse: 1) the learner; 2) its time; 3) space; and 4) learning event. In this learning scene, we propose a novel data-knowledge-driven group intelligence framework, aiming to transform data in the education metaverse into knowledge, and intersect and integrate intelligence with knowledge; based on this framework, we apply it to specific services, i.e., transaction and management services. We hope that our work opens the door to research on smart services in the education metaverse and more scholars will work for these challenges."}}
{"id": "p49j0qg8n3", "cdate": 1640995200000, "mdate": 1681796429355, "content": {"title": "IPGAN: Identity-Preservation Generative Adversarial Network for unsupervised photo-to-caricature translation", "abstract": ""}}
{"id": "a_aoAKR3sc", "cdate": 1640995200000, "mdate": 1681796429344, "content": {"title": "Computational knowledge vision: paradigmatic knowledge based prescriptive learning and reasoning for perception and vision", "abstract": "This paper outlines a novel advanced framework that combines structurized knowledge and visual models\u2014Computational Knowledge Vision. In advanced studies of image and visual perception, a visual model\u2019s understanding and reasoning ability often determines whether it works well in complex scenarios. This paper presents the state-of-the-art mainstream of vision models for visual perception. This paper then proposes a concept and basic framework of Computational Knowledge Vision that extends the knowledge engineering methodology to the computer vision field. In this paper, we first retrospect prior work related to Computational Knowledge Vision in the light of the connectionist and symbolist streams. We discuss neural network models, meta-learning models, graph models, and Transformer models in detail. We then illustrate a basic framework for Computational Knowledge Vision, whose essential techniques include structurized knowledge, knowledge projection, and conditional feedback. The goal of the framework is to enable visual models to gain the ability of representation, understanding, and reasoning. We also describe in-depth works in Computational Knowledge Vision and its extensions in other fields."}}
{"id": "TeUFx6j1IB", "cdate": 1640995200000, "mdate": 1681796429429, "content": {"title": "An ACP-Based Parallel Approach for Color Image Encryption Using Redundant Blocks", "abstract": "Public concerns on image encryption grow significantly as the development and application of edge computing and the Internet of Things intensified recently. However, most existing image cryptosystems are not sophisticated enough to resist the two major attack strategies available currently, that is: 1) differential attacks and 2) chosen-plaintext attacks, which are famous for their destructive power, especially their capability of exploiting cryptosystems\u2019 features to recover the secret key. In this article, we propose an artificial image, computational experiment, and parallel execution (ACP)-based color image encryption approach using redundant blocks. First, a redundant blocks strategy with redundant spaces is proposed to prevent differential attacks and accelerate operating speed while guaranteeing the security of image cryptosystems. Second, real-world chaotic data (e.g., stock data) are obtained to generate artificial images and conduct computational experiments. Furthermore, artificial images are encrypted via real-world chaos, while the original images are encrypted via simulated chaos (such as Chen\u2019s hyperchaos). Finally, we design the process of parallel execution for image encryption and use DNA XOR to merge two groups of encrypted subimages to fuse the effect of the chaotic characteristics in both the real world and the simulation. The final encrypted image is realized through the recovery of redundant blocks. The ACP mechanism of color image encryption achieves the goal of improving the sophistication of chaos-based cryptosystems and resists both the differential and chosen-plaintext attacks. Experimental results and security analysis show that our approach provides not only excellent encryption but also security sufficient to prevent known attacks."}}
{"id": "5FjrgSFl1_n", "cdate": 1640995200000, "mdate": 1681796429376, "content": {"title": "Fuzzy Deep Forest With Deep Contours Feature for Leaf Cultivar Classification", "abstract": "Deep learning is a compelling technique for feature extraction due to its adaptive capacity of processing and providing deeper image information. However, for the task of leaf cultivar classification, the deep learning-based classifier model is unable to extract contour features of leaf images deeply due to the lack of large specialized datasets and expert knowledge annotations. Also, the scale/size of the current leaf cultivar dataset does not meet the needs of deep neural networks (DNNs). In particular, the high model complexity of DNNs implies that deep-learning-based neural networks seem to must require a large dataset to achieve good performance, but facing the fact that the leaf cultivar dataset often is small, even some classes in this kind of datasets contain less than ten images/examples. To overcome these problems and inspired by the resounding success of fuzzy logic, we propose a novel fuzzy ensemble model for leaf cultivar classification. To extract the contours of leaves, we first propose generative adversarial networks-based methods. Second, to improve the ability of feature representation, we present a data augmentation method to transform our contour features. Third, to get the essential features of leaves, we design a novel generation of the <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">fuzzy random forest</i> . Finally, to achieve accurate classification, we design a novel deep learning strategy, namely <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">deep fuzzy representation learning</i> , integrating and cascading a lot of our fuzzy random forests. Experimental results show that our model outperforms other existing state-of-the-arts on three real-world datasets, and performs much better than the original deep forest and DNN-based algorithms particularly."}}
{"id": "3eMfV-MVacF", "cdate": 1640995200000, "mdate": 1681796429439, "content": {"title": "Meta-learning meets the Internet of Things: Graph prototypical models for sensor-based human activity recognition", "abstract": ""}}
{"id": "ptdNzrxryc6", "cdate": 1609459200000, "mdate": 1681796429545, "content": {"title": "Learning From the Web: Webly Supervised Meta-Learning for Masked Face Recognition", "abstract": "Mask wearing has been considered as an effective measure to prevent the spread of COVID-19 during the current pandemic. However, most advanced face recognition approaches are not adequate for masked face recognition, particularly in dealing with the issue of training through the datasets covering only a limited number of images with ground-truth labels. In this work, we propose to learn from the large scale of web images and corresponding tags without any manual annotations along with limited fully annotated datasets. In particular, inspired by the recent success of webly supervised learning in deep neural networks, we capitalize on readily-available web images with noisy annotations to learn a robust representation for masked faces. Besides, except for the conventional spatial representation learning, we propose to leverage the power of frequency domain to capture the local representative information of unoccluded facial parts. This approach learns robust feature embeddings derived from our feature fusion architecture to make joint and full use of information from both spatial and frequency domains. Experimental results on seven benchmarks show that the proposed approach significantly improves the performance compared with other state-of-theart methods."}}
{"id": "ovhN5jSNVu", "cdate": 1609459200000, "mdate": 1681796429443, "content": {"title": "Joint image-to-image translation with denoising using enhanced generative adversarial networks", "abstract": ""}}
{"id": "jd4MC59gfE", "cdate": 1609459200000, "mdate": 1681796429422, "content": {"title": "GAN-Based Key Secret-Sharing Scheme in Blockchain", "abstract": "In this article, we propose a key secret-sharing technology based on generative adversarial networks (GANs) to address three major problems in the blockchain: 1) low security; 2) hard recovery of lost keys; and 3) low communication efficiency. In our scheme, the proposed network plays the role of a dealer and treats the secret-sharing process as a classification issue. The key idea is to view the secret as an image during the secret-sharing process. If the user's private key is text, we can covert the key text into an image called the original image. Specifically, we first divide the original image into original subimages by the image segmentation. Next, we encode each original subimage by DNA coding. Finally, we train the proposed network to find the key secret-sharing results. Our proposed scheme is not only a significant extension of the GANs but also a new direction for the key secret-sharing technology. The simulation results show that the scheme is secure, and both flexible and efficient in communication."}}
{"id": "gO4o2DQks_p", "cdate": 1609459200000, "mdate": 1681796429453, "content": {"title": "Two Heads are Better Than One: Hypergraph-Enhanced Graph Reasoning for Visual Event Ratiocination", "abstract": "Even with a still image, humans can ratiocinate various visual cause-and-effect descriptions before, at present, and after, as well as beyond the given image. However, it is challenging for models ..."}}
