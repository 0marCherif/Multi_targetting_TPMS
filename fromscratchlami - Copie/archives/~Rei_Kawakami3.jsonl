{"id": "hSQ6FbH79gM", "cdate": 1683879982411, "mdate": 1683879982411, "content": {"title": "Learning with Partial Forgetting in Modern Hopfield Networks", "abstract": "It has been known by neuroscience studies that partial and transient forgetting of memory often plays an important role in the brain to improve performance for certain intellectual activities. In machine learning, associative memory models such as classical and modern Hopfield networks have been proposed to express memories as attractors in the feature space of a closed recurrent network. In this work, we propose learning with partial forgetting (LwPF), where a partial forgetting functionality is designed by element-wise non-bijective projections, for memory neurons in modern Hopfield networks to improve model performance. We incorporate LwPF into the attention mechanism also, whose process has been shown to be identical to the update rule of a certain modern Hopfield network, by modifying the corresponding Lagrangian. We evaluated the effectiveness of LwPF on three diverse tasks such as bit-pattern classification, immune repertoire classification for computational biology, and image classification for computer vision, and confirmed that LwPF consistently improves the performance of existing neural networks including DeepRC and vision transformers."}}
{"id": "wgnRMKw7FZ", "cdate": 1640995200000, "mdate": 1668039649494, "content": {"title": "Pass Receiver Prediction in Soccer using Video and Players' Trajectories", "abstract": ""}}
{"id": "eKejqCJ-vY", "cdate": 1640995200000, "mdate": 1668039649481, "content": {"title": "Feature Space Particle Inference for Neural Network Ensembles", "abstract": "Ensembles of deep neural networks demonstrate improved performance over single models. For enhancing the diversity of ensemble members while keeping their performance, particle-based inference meth..."}}
{"id": "eEI55-7ZDP", "cdate": 1640995200000, "mdate": 1668039649652, "content": {"title": "Anomaly Detection Using Spatio-Temporal Context Learned by Video Clip Sorting", "abstract": ""}}
{"id": "3Zx7-25HCA", "cdate": 1640995200000, "mdate": 1668039649526, "content": {"title": "PoF: Post-Training of Feature Extractor for Improving Generalization", "abstract": "It has been intensively investigated that the local shape, especially flatness, of the loss landscape near a minimum plays an important role for generalization of deep models. We developed a traini..."}}
{"id": "2FE0NwK3Jbn", "cdate": 1633790964305, "mdate": null, "content": {"title": "Smooth Transfer Learning for Source-to-Target Generalization", "abstract": "Transfer learning for deep models has shown great success for various recognition tasks. Typically, a backbone network is pre-trained on a source dataset, then fine-tuned on a target dataset. We considered that when both datasets are at hand, learning them simultaneously at least for some period of iterations would yield higher test performance rather than the step-wise optimization. We propose Smooth Transfer Learning, which uses a learnable scheduler function for the loss coefficients so that degrees of contributions from two datasets can be smoothly changed along training time for optimal target performance. The scheduler function is designed so that it can express either pre-training-then-fine-tuning or multi-task learning with fixed weights as special cases. Our method consistently outperforms these special cases in object classification with CIFAR-10 and CIFAR-100, and in digit classification with SVHN and MNIST."}}
{"id": "Z9ajSmTZ4b4", "cdate": 1609459200000, "mdate": 1668039649399, "content": {"title": "Disentangling Latent Groups Of Factors", "abstract": ""}}
{"id": "OivsaTTHYK5", "cdate": 1577836800000, "mdate": 1668039649536, "content": {"title": "RNN-based Motion Prediction in Competitive Fencing Considering Interaction between Players", "abstract": ""}}
{"id": "s_nDZOJ7Vyq", "cdate": 1546300800000, "mdate": 1668039649591, "content": {"title": "Cross-Connected Networks for Multi-Task Learning of Detection and Segmentation", "abstract": ""}}
{"id": "YVTDdw4XjK9", "cdate": 1546300800000, "mdate": 1668039649480, "content": {"title": "Classification-Reconstruction Learning for Open-Set Recognition", "abstract": "Open-set classification is a problem of handling 'unknown' classes that are not contained in the training dataset, whereas traditional classifiers assume that only known classes appear in the test environment. Existing open-set classifiers rely on deep networks trained in a supervised manner on known classes in the training set; this causes specialization of learned representations to known classes and makes it hard to distinguish unknowns from knowns. In contrast, we train networks for joint classification and reconstruction of input data. This enhances the learned representation so as to preserve information useful for separating unknowns from knowns, as well as to discriminate classes of knowns. Our novel Classification-Reconstruction learning for Open-Set Recognition (CROSR) utilizes latent representations for reconstruction and enables robust unknown detection without harming the known-class classification accuracy. Extensive experiments reveal that the proposed method outperforms existing deep open-set classifiers in multiple standard datasets and is robust to diverse outliers."}}
