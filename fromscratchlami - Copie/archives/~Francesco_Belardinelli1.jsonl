{"id": "6Qzf6ntpCX", "cdate": 1677628800000, "mdate": 1681674403836, "content": {"title": "An abstraction-refinement framework for verifying strategic properties in multi-agent systems with imperfect information", "abstract": ""}}
{"id": "wT_OYYpaM_", "cdate": 1672531200000, "mdate": 1696079318196, "content": {"title": "Defining Deception in Structural Causal Games", "abstract": "Deceptive agents are a challenge for the safety, trustworthiness, and cooperation of AI systems. We focus on the problem that agents might deceive in order to achieve their goals. There are a number of existing definitions of deception in the literature on game theory and symbolic AI, but there is no overarching theory of deception for learning agents in games. We introduce a functional definition of deception in structural causal games, grounded in the philosophical literature. We present several examples to establish that our formal definition captures philosophical desiderata for deception."}}
{"id": "uru_Ju_fRlt", "cdate": 1672531200000, "mdate": 1696079318195, "content": {"title": "Scalable Verification of Strategy Logic through Three-Valued Abstraction", "abstract": "The model checking problem for multi-agent systems against Strategy Logic specifications is known to be non-elementary. On this logic several fragments have been defined to tackle this issue but at the expense of expressiveness. In this paper, we propose a three-valued semantics for Strategy Logic upon which we define an abstraction method. We show that the latter semantics is an approximation of the classic two-valued one for Strategy Logic. Furthermore, we extend MCMAS, an open-source model checker for multi-agent specifications, to incorporate our abstraction method and present some promising experimental results."}}
{"id": "trMhtHbqwV", "cdate": 1672531200000, "mdate": 1696079318197, "content": {"title": "Strategic Abilities of Forgetful Agents in Stochastic Environments", "abstract": "In this paper, we investigate the probabilistic variants of the strategy logics ATL and ATL* under imperfect information. Specifically, we present novel decidability and complexity results when bot..."}}
{"id": "qC8gBD3YbFm", "cdate": 1672531200000, "mdate": 1694425134616, "content": {"title": "Approximate Model-Based Shielding for Safe Reinforcement Learning", "abstract": "Reinforcement learning (RL) has shown great potential for solving complex tasks in a variety of domains. However, applying RL to safety-critical systems in the real-world is not easy as many algorithms are sample-inefficient and maximising the standard RL objective comes with no guarantees on worst-case performance. In this paper we propose approximate model-based shielding (AMBS), a principled look-ahead shielding algorithm for verifying the performance of learned RL policies w.r.t. a set of given safety constraints. Our algorithm differs from other shielding approaches in that it does not require prior knowledge of the safety-relevant dynamics of the system. We provide a strong theoretical justification for AMBS and demonstrate superior performance to other safety-aware approaches on a set of Atari games with state-dependent safety-labels."}}
{"id": "l2H7P0SvoM6", "cdate": 1672531200000, "mdate": 1695949586111, "content": {"title": "Beyond Strict Competition: Approximate Convergence of Multi-agent Q-Learning Dynamics", "abstract": "The behaviour of multi-agent learning in competitive settings is often considered under the restrictive assumption of a zero-sum game. Only under this strict requirement is the behaviour of learning well understood; beyond this, learning dynamics can often display non-convergent behaviours which prevent fixed-point analysis. Nonetheless, many relevant competitive games do not satisfy the zero-sum assumption. Motivated by this, we study a smooth variant of Q-Learning, a popular reinforcement learning dynamics which balances the agents' tendency to maximise their payoffs with their propensity to explore the state space. We examine this dynamic in games which are `close' to network zero-sum games and find that Q-Learning converges to a neighbourhood around a unique equilibrium. The size of the neighbourhood is determined by the `distance' to the zero-sum game, as well as the exploration rates of the agents. We complement these results by providing a method whereby, given an arbitrary network game, the `nearest' network zero-sum game can be found efficiently. Importantly, our theoretical guarantees are widely applicable in different game settings, regardless of whether the dynamics ultimately reach an equilibrium, or remain non convergent."}}
{"id": "kYzqOEZ9GPP", "cdate": 1672531200000, "mdate": 1681674403850, "content": {"title": "Program Semantics and Verification Technique for AI-Centred Programs", "abstract": "We give a general-purpose programming language in which programs can reason about their own knowledge. To specify what these intelligent programs know, we define a \u201cprogram epistemic\u201d logic, akin to a dynamic epistemic logic for programs. Our logic properties are complex, including programs introspecting into future state of affairs, i.e., reasoning now about facts that hold only after they and other threads will execute. To model aspects anchored in privacy, our logic is interpreted over partial observability of variables, thus capturing that each thread can \u201csee\u201d only a part of the global space of variables. We verify program-epistemic properties on such AI-centred programs. To this end, we give a sound translation of the validity of our program-epistemic logic into first-order validity, using a new weakest-precondition semantics and a book-keeping of variable assignment. We implement our translation and fully automate our verification method for well-established examples using SMT solvers."}}
{"id": "cqm0ousmM1u", "cdate": 1672531200000, "mdate": 1694425134615, "content": {"title": "Approximate Shielding of Atari Agents for Safe Exploration", "abstract": "Balancing exploration and conservatism in the constrained setting is an important problem if we are to use reinforcement learning for meaningful tasks in the real world. In this paper, we propose a principled algorithm for safe exploration based on the concept of shielding. Previous approaches to shielding assume access to a safety-relevant abstraction of the environment or a high-fidelity simulator. Instead, our work is based on latent shielding - another approach that leverages world models to verify policy roll-outs in the latent space of a learned dynamics model. Our novel algorithm builds on this previous work, using safety critics and other additional features to improve the stability and farsightedness of the algorithm. We demonstrate the effectiveness of our approach by running experiments on a small set of Atari games with state dependent safety labels. We present preliminary results that show our approximate shielding algorithm effectively reduces the rate of safety violations, and in some cases improves the speed of convergence and quality of the final agent."}}
{"id": "c3fUBFRyAp", "cdate": 1672531200000, "mdate": 1696079317748, "content": {"title": "Automatically Verifying Expressive Epistemic Properties of Programs", "abstract": "We propose a new approach to the verification of epistemic properties of programmes. First, we introduce the new ``program-epistemic'' logic L_PK, which is strictly richer and more general than similar formalisms appearing in the literature. To solve the verification problem in an efficient way, we introduce a translation from our language L_PK into first-order logic. Then, we show and prove correct a reduction from the model checking problem for program-epistemic formulas to the satisfiability of their first-order translation. Both our logic and our translation can handle richer specification w.r.t. the state of the art, allowing us to express the knowledge of agents about facts pertaining to programs (i.e., agents' knowledge before a program is executed as well as after is has been executed). Furthermore, we implement our translation in Haskell in a general way (i.e., independently of the programs in the logical statements), and we use existing SMT-solvers to check satisfaction of L_PK formulas on a benchmark example in the AI/agency field."}}
{"id": "YE_BfgLmzk", "cdate": 1672531200000, "mdate": 1696079317752, "content": {"title": "Characterising Decision Theories with Mechanised Causal Graphs", "abstract": "How should my own decisions affect my beliefs about the outcomes I expect to achieve? If taking a certain action makes me view myself as a certain type of person, it might affect how I think others view me, and how I view others who are similar to me. This can influence my expected utility calculations and change which action I perceive to be best. Whether and how it should is subject to debate, with contenders for how to think about it including evidential decision theory, causal decision theory, and functional decision theory. In this paper, we show that mechanised causal models can be used to characterise and differentiate the most important decision theories, and generate a taxonomy of different decision theories."}}
