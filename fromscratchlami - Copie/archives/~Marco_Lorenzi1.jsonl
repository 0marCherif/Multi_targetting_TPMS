{"id": "eJ1l8ZfSkW", "cdate": 1684163355918, "mdate": 1684163355918, "content": {"title": "Enhanced Distribution Modelling via Augmented Architectures For Neural ODE Flows", "abstract": "While the neural ODE formulation of normalizing flows such as in FFJORD enables us to calculate the determinants of free form Jacobians in O(D) time, the flexibility of the transformation underlying neural ODEs has been shown to be suboptimal. In this paper, we present AFFJORD, a neural ODE-based normalizing flow which enhances the representation power of FFJORD by defining the neural ODE through special augmented transformation dynamics which preserve the topology of the space. Furthermore, we derive the Jacobian determinant of the general augmented form by generalizing the chain rule in the continuous sense into the 'cable rule', which expresses the forward sensitivity of ODEs with respect to their initial conditions. The cable rule gives an explicit expression for the Jacobian of a neural ODE transformation, and provides an elegant proof of the instantaneous change of variable. Our experimental results on density estimation in synthetic and high dimensional data, such as MNIST, CIFAR-10 and CelebA 32x32, show that AFFJORD outperforms the baseline FFJORD through the improved flexibility of the underlying vector field. "}}
{"id": "NoOWCe4PuH", "cdate": 1681720868104, "mdate": 1681720868104, "content": {"title": " A General Theory for Federated Optimization with Asynchronous and Heterogeneous Clients Updates ", "abstract": "We propose a novel framework to study asynchronous federated learning optimization with delays in gradient updates. Our theoretical framework extends the standard FedAvg aggregation scheme by introducing stochastic aggregation weights to represent the variability of the clients update time, due for example to heterogeneous hardware capabilities. Our formalism applies to the general federated setting where clients have heterogeneous datasets and perform at least one step of stochastic gradient descent (SGD). We demonstrate convergence for such a scheme and provide sufficient conditions for the related minimum to be the optimum of the federated problem. We show that our general framework applies to existing optimization schemes including centralized learning, FedAvg, asynchronous FedAvg, and FedBuff. The theory here provided allows drawing meaningful guidelines for designing a federated learning experiment in heterogeneous conditions. In particular, we develop in this work FedFix, a novel extension of FedAvg enabling efficient asynchronous federated training while preserving the convergence stability of synchronous aggregation. We empirically demonstrate our theory on a series of experiments showing that asynchronous FedAvg leads to fast convergence at the expense of stability, and we finally demonstrate the improvements of FedFix over synchronous and asynchronous FedAvg. "}}
{"id": "mN2ZFNKzQD", "cdate": 1678276781340, "mdate": 1678276781340, "content": {"title": " Privacy Preserving Image Registration ", "abstract": " Image registration is a key task in medical imaging applications, allowing to represent medical images in a common spatial reference frame. Current literature on image registration is generally based on the assumption that images are usually accessible to the researcher, from which the spatial transformation is subsequently estimated. This common assumption may not be met in current practical applications, since the sensitive nature of medical images may ultimately require their analysis under privacy constraints, preventing to share the image content in clear form. In this work, we formulate the problem of image registration under a privacy preserving regime, where images are assumed to be confidential and cannot be disclosed in clear. We derive our privacy preserving image registration framework by extending classical registration paradigms to account for advanced cryptographic tools, such as secure multi-party computation and homomorphic encryption, that enable the execution of operations without leaking the underlying data. To overcome the problem of performance and scalability of cryptographic tools in high dimensions, we first propose to optimize the underlying image registration operations using gradient approximations. We further revisit the use of homomorphic encryption and use a packing method to allow the encryption and multiplication of large matrices more efficiently. We demonstrate our privacy preserving framework in linear and non-linear registration problems, evaluating its accuracy and scalability with respect to standard image registration. Our results show that privacy preserving image registration is feasible and can be adopted in sensitive medical imaging applications."}}
{"id": "kdEpgKAtg_", "cdate": 1678276698952, "mdate": 1678276698952, "content": {"title": "Sequential Informed Federated Unlearning: Efficient and Provable Client Unlearning in Federated Optimization", "abstract": "The aim of Machine Unlearning (MU) is to provide theoretical guarantees on the removal of the contribution of a given data point from a training procedure. Federated Unlearning (FU) consists in extending MU to unlearn a given client's contribution from a federated training routine. Current FU approaches are generally not scalable, and do not come with sound theoretical quantification of the effectiveness of unlearning. In this work we present Informed Federated Unlearning (IFU), a novel efficient and quantifiable FU approach. Upon unlearning request from a given client, IFU identifies the optimal FL iteration from which FL has to be reinitialized, with unlearning guarantees obtained through a randomized perturbation mechanism. The theory of IFU is also extended to account for sequential unlearning requests. Experimental results on different tasks and dataset show that IFU leads to more efficient unlearning procedures as compared to basic re-training and state-of-the-art FU approaches."}}
{"id": "GgM5DiAb6A2", "cdate": 1654178847611, "mdate": null, "content": {"title": "FLamby: Datasets and Benchmarks for Cross-Silo Federated Learning in Realistic Healthcare Settings", "abstract": "Federated Learning (FL) is a novel approach enabling several clients holding sensitive data to collaboratively train machine learning models, without centralizing data. The cross-silo FL setting corresponds to the case of few ($2$--$50$) reliable clients, each holding medium to large datasets, and is typically found in applications such as healthcare, finance, or industry. While previous works have proposed representative datasets for cross-device FL, few realistic healthcare cross-silo FL datasets exist, thereby slowing algorithmic research in this critical application. In this work, we propose a novel cross-silo dataset suite focused on healthcare, FLamby (Federated Learning AMple Benchmark of Your cross-silo strategies), to bridge the gap between theory and practice of cross-silo FL.\nFLamby encompasses 7 healthcare datasets with natural splits, covering multiple tasks, modalities, and data volumes, each accompanied with baseline training code. As an illustration, we additionally benchmark standard FL algorithms on all datasets.\nOur flexible and modular suite allows researchers to easily download datasets, reproduce results and re-use the different components for their research. FLamby is available at~\\url{www.github.com/owkin/flamby}."}}
{"id": "treZ5Y3pUDP", "cdate": 1640184639254, "mdate": 1640184639254, "content": {"title": "Differences in topological progression profile among neurodegenerative diseases from imaging data", "abstract": "The spatial distribution of atrophy in neurodegenerative diseases suggests that brain connectivity mediates disease propagation. Different descriptors of the connectivity graph potentially relate to different underlying mechanisms of propagation. Previous approaches for evaluating the influence of connectivity on neurodegeneration consider each descriptor in isolation and match predictions against late-stage atrophy patterns. We introduce the notion of a topological profile \u2014 a characteristic combination of topological descriptors that best describes the propagation of pathology in a particular disease. By drawing on recent advances in disease progression modeling, we estimate topological profiles from the full course of pathology accumulation, at both cohort and individual levels. Experimental results comparing topological profiles for Alzheimer\u2019s disease, multiple sclerosis and normal ageing show that topological profiles explain the observed data better than single descriptors. Within each condition, most individual profiles cluster around the cohort-level profile, and individuals whose profiles align more closely with other cohort-level profiles show features of that cohort. The cohort-level profiles suggest new insights into the biological mechanisms underlying pathology propagation in each disease."}}
{"id": "Tu1qSHIl9k", "cdate": 1640184524052, "mdate": 1640184524052, "content": {"title": "Investigating hypotheses of neurodegeneration by learning dynamical systems of protein propagation in the brain", "abstract": "We introduce a theoretical framework for estimating, comparing and interpreting mechanistic hypotheses on long term protein propagation across brain networks in neurodegenerative disorders (ND). The model is ex- pressed within a Bayesian non-parametric regression setting, where mechanisms of protein dynamics are inferred by means of gradient matching on dynamical systems (DS). The Bayesian formalism, combined with stochastic variational inference, naturally allows for model comparison via assessment of model evidence, while provid- ing uncertainty quantification of causal relationship underlying protein progressions. When applied to in\u2013vivo AV45-PET brain imaging data measuring topographic amyloid deposition in Alzheimer\u2019s disease (AD), our model identified the mechanisms of accumulation, clearance and propagation as the best suited DS for bio-mechanical description of amyloid dynamics in AD, enabling realistic and accurate personalized simulation of amyloidosis."}}
{"id": "edN_G_4njyi", "cdate": 1632875506154, "mdate": null, "content": {"title": "On the Impact of Client Sampling on Federated Learning Convergence", "abstract": "While clients' sampling is a central operation of current state-of-the-art federated learning (FL) approaches, the impact of this procedure on the convergence and speed of FL remains under-investigated.In this work we introduce a novel decomposition theorem for the convergence of FL, allowing to clearly quantify the impact of client sampling on the global model update. Contrarily to previous convergence analyses, our theorem provides the exact decomposition of a given convergence step, thus enabling accurate considerations about the role of client sampling and heterogeneity. First, we provide a theoretical ground for previously reported experimental results on the relationship between FL convergence and the variance of the aggregation weights. Second, we prove for the first time that the quality of FL convergence is also impacted by the resulting \\emph{covariance} between aggregation weights. Our theory is general, and is here applied to Multinomial Distribution (MD) and Uniform sampling, the two default client sampling schemes of FL, and demonstrated through a series of experiments in non-iid and unbalanced scenarios. Our results suggest that MD sampling should be used as default sampling scheme, due to the resilience to the changes in data ratio during the learning process, while Uniform sampling is superior only in the special case when clients have the same amount of data."}}
{"id": "I75lYL63h6f", "cdate": 1620396956988, "mdate": null, "content": {"title": "A Probabilistic Framework for Modeling the Variability Across Federated Datasets of Heterogeneous Multi-View Observations ", "abstract": "We propose a novel federated learning paradigm to model data variability among heterogeneous clients in multi-centric studies. Our method is expressed through a hierarchical Bayesian latent variable model, where client-specific parameters are assumed to be realization from a global distribution at the master level, which is in turn estimated to account for data bias and variability across clients. We show that our framework can be effectively optimized through expectation maximization over latent master's distribution and clients' parameters. We tested our method on the analysis of multi-modal medical imaging data and clinical scores from distributed clinical datasets of patients affected by Alzheimer's disease. We demonstrate that our method is robust when data is distributed either in iid and non-iid manners: it allows to quantify the variability of data, views and centers, while guaranteeing high-quality data reconstruction as compared to the state-of-the-art autoencoding models and federated learning schemes.\n"}}
{"id": "j1AC-cjmWYa", "cdate": 1620396684788, "mdate": null, "content": {"title": "Free-rider Attacks on Model Aggregation in Federated Learning ", "abstract": "Free-rider attacks against federated learning consist in dissimulating participation to the federated learning process with the goal of obtaining the final aggregated model without actually contributing with any data. This kind of attacks are critical in sensitive applications of federated learning when data is scarce and the model has high commercial value. We introduce here the first theoretical and experimental analysis of free-rider attacks on federated learning schemes based on iterative parameters aggregation, such as FedAvg or FedProx, and provide formal guarantees for these attacks to converge to the aggregated models of the fair participants. We first show that a straightforward implementation of this attack can be simply achieved by not updating the local parameters during the iterative federated optimization. As this attack can be detected by adopting simple countermeasures at the server level, we subsequently study more complex disguising schemes based on stochastic updates of the free-rider parameters. We demonstrate the proposed strategies on a number of experimental scenarios, in both iid and non-iid settings. We conclude by providing recommendations to avoid free-rider attacks in real world applications of federated learning, especially in sensitive domains where security of data and models is critical. "}}
