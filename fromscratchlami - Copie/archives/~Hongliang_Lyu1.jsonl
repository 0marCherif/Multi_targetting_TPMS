{"id": "aUii2gYOSlJ", "cdate": 1632892874990, "mdate": 1632892874990, "content": {"title": "Finding signatures of the nuclear symmetry energy in heavy-ion collisions with deep learning", "abstract": "A deep convolutional neural network (CNN) is developed to study symmetry energy (Esym(\u03c1)) effects by\nlearning the mapping between the symmetry energy and the two-dimensional (transverse momentum and rapid-\nity) distributions of protons and neutrons in heavy-ion collisions. Supervised training is performed with labelled\ndata-set from the ultrarelativistic quantum molecular dynamics (UrQMD) model simulation. It is found that, by\nusing proton spectra on event-by-event basis as input, the accuracy for classifying the soft and stiff Esym(\u03c1)is\nabout 60% due to large event-by-event \ufb02uctuations, while by setting event-summed proton spectra as input, the\nclassi\ufb01cation accuracy increases to 98%. The accuracy for 5-label (5 different Esym(\u03c1)) classi\ufb01cation task are\nabout 58% and 72% by using proton and neutron spectra, respectively. For the regression task, the mean abso-\nlute error (MAE) which measures the average magnitude of the absolute differences between the predicted and\nactual L(the slope parameter of Esym(\u03c1)) are about 20.4 and 14.8 MeV by using proton and neutron spectra,\nrespectively. Fingerprints of the density-dependent nuclear symmetry energy on the transverse momentum and\nrapidity distributions of protons and neutrons can be identi\ufb01ed by convolutional neural network algorithm."}}
{"id": "pwKSHw1Zia7", "cdate": 1632892821680, "mdate": 1632892821680, "content": {"title": "Machine learning the nuclear mass", "abstract": "Background: The masses of about 2500 nuclei have been measured experimentally, however more than 7000 isotopes are predicted to exist in the nuclear landscape from H (Z=1) to Og (Z=118) based on various theoretical calculations. Exploring the mass of the remains is a hot topic in nuclear physics. Machine learning has been served as a powerful tool in learning complex representations of big data in many fields. Purpose: We use Light Gradient Boosting Machine (LightGBM) which is a highly efficient machine learning algorithm to predict the masses of unknown nuclei and to explore the nuclear landscape in neutron-rich side from learning the measured nuclear masses. Results: By using the experimental data of 80 percent of known nuclei as the training dataset, the root mean square deviation (RMSD) between the predicted and the experimental binding energy of the remaining 20% is about 0.234 MeV, 0.213 MeV, 0.170 MeV, and 0.222 MeV for the LightGBM-refined LDM, DZ, WS4, and FRDM models, respectively. These values are of about 90%, 65%, 40%, and 60% smaller than the corresponding origin mass models. The RMSD for 66 newly measured nuclei that appeared in AME2020 is also significantly improved on the same foot. One-neutron and two-neutron separation energies predicted by these refined models are in consistence with several theoretical predictions based on various physical models. Conclusions: LightGBM can be used to refine theoretical nuclear mass models so as to predict the binding energy of unknown nuclei. Moreover, the correlation between the input characteristic quantities and the output can be interpreted by SHapley Additive exPlanations (SHAP, a popular explainable artificial intelligence tool), this may provide new insights on developing theoretical nuclear mass models."}}
{"id": "Hj6EgKxggC2", "cdate": 1632892718070, "mdate": null, "content": {"title": "Application of machine learning in the determination of impact parameter in the 132Sn+124Sn system", "abstract": "Background: 132Sn+124Sn collisions at a beam energy of 270 MeV/nucleon were performed at the Radioactive Isotope Beam Factory (RIBF) in RIKEN to investigate the nuclear equation of state. Reconstructing the impact parameter is one of the important tasks in the experiment as it relates to many observables.\n\nPurpose: In this work, we employ three commonly used algorithms in machine learning, the artificial neural network (ANN), the convolutional neural network (CNN), and the light gradient boosting machine (LightGBM), to determine the impact parameter by analyzing either the charged particle spectra or several features simulated with events from the ultrarelativistic quantum molecular dynamics (UrQMD) model.\n\nMethod: To closely imitate experimental data and investigate the generalizability of the trained machine learning algorithms, incompressibility of nuclear equation of state and the in-medium nucleon-nucleon cross sections are varied in the UrQMD model to generate the training data.\n\nResults: The mean absolute error \u0394b between the true and the predicted impact parameter is smaller than 0.45 fm if training and testing sets are sampled from the UrQMD model with the same parameter set. However, if training and testing sets are sampled with different parameter sets, \u0394b would increase to 0.8 fm.\n\nConclusion: The generalizability of the trained machine learning algorithms suggests that these machine learning algorithms can be used reliably to reconstruct the impact parameter in experiments."}}
{"id": "6sZb2NjBjb", "cdate": 1621798227961, "mdate": null, "content": {"title": "Application of artificial intelligence in the determination of impact parameter in heavy-ion collisions at intermediate energies", "abstract": "The impact parameter is one of the crucial physical quantities of heavy-ion collisions, and can affect obviously many observables at the final state, such as the multifragmentation and the collective flow. Usually, it cannot be measured directly in experiments but might be inferred from observables at the final state. Artificial intelligence has had great success in learning complex representations of data, which enables novel modeling and data processing approaches in physical sciences. In this article, we employ two of commonly used algorithms in the field of artificial intelligence, the convolutional neural networks (CNN) and light gradient boosting machine (LightGBM), to improve the accuracy of determining impact parameter by analyzing the proton spectra in transverse momentum and rapidity on the event-by-event basis. Au + Au collisions with the impact parameter of 0  < b <  10 fm at intermediate energies (Elab = 0.2\u20131.0 GeV/nucleon) are simulated with the ultrarelativistic quantum molecular dynamics model to generate the proton spectra data. It is found that the average difference between the true impact parameter and the estimated one can be smaller than 0.1 fm. The LightGBM algorithm shows an improved performance with respect to the CNN on the task in this work. By using the LightGBM\u2019s visualization algorithm, one can obtain the important feature map of the distribution of transverse momentum and rapidity, which may be helpful in inferring the impact parameter or centrality in heavy-ion experiments."}}
{"id": "r1xLV3jDDr", "cdate": 1569336366509, "mdate": null, "content": {"title": "Bayesian nonparametric priors for hidden Markov random fields", "abstract": "One of the central issues in statistics and machine learning is how to select an adequate model that can automatically adapt its complexity to the observed data. In the present paper, we focus on the issue of determining the structure of clustered data, both in terms of finding the appropriate number of clusters and of modelling the right dependence structure between the observations. Bayesian nonparametric (BNP) models, which do not impose an upper limit on the number of clusters, are appropriate to avoid the required guess on the number of clusters but have been mainly developed for independent data. In contrast, Markov random fields (MRF) have been extensively used to model dependencies in a tractable manner but usually reduce to finite cluster numbers when clustering tasks are addressed. Our main contribution is to propose a general scheme to design tractable BNP-MRF priors that combine both features: no commitment to an arbitrary number of clusters and a dependence modelling. A key ingredient in this construction is the availability of a stick-breaking representation which has the threefold advantage to allowing us to extend standard discrete MRFs to infinite state space, to design a tractable estimation algorithm using variational approximation and to derive theoretical properties on the predictive distribution and the number of clusters of the proposed model. This approach is illustrated on a challenging natural image segmentation task for which it shows good performance with respect to the literature."}}
{"id": "H1xPSqovwr", "cdate": 1569335870773, "mdate": null, "content": {"title": "Approximate Bayesian computation via the energy statistic", "abstract": "Approximate Bayesian computation (ABC) has become an essential part of the Bayesian toolbox for addressing problems in which the likelihood is prohibitively expensive or entirely unknown, making it intractable. ABC defines a quasi-posterior by comparing observed data with simulated data, traditionally based on some summary statistics, the elicitation of which is regarded as a key difficulty. In recent years, a number of data discrepancy measures bypassing the construction of summary statistics have been proposed, including the Kullback--Leibler divergence, the Wasserstein distance and maximum mean discrepancies. Here we propose a novel importance-sampling (IS) ABC algorithm relying on the so-called two-sample energy statistic. We establish a new asymptotic result for the case where both the observed sample size and the simulated data sample size increase to infinity, which highlights to what extent the data discrepancy measure impacts the asymptotic pseudo-posterior. The result holds in the broad setting of IS-ABC methodologies, thus generalizing previous results that have been established only for rejection ABC algorithms. Furthermore, we propose a consistent V-statistic estimator of the energy statistic, under which we show that the large sample result holds. Our proposed energy statistic based ABC algorithm is demonstrated on a variety of models, including a Gaussian mixture, a moving-average model of order two, a bivariate beta and a multivariate g-and-k distribution. We find that our proposed method compares well with alternative discrepancy measures."}}
