{"id": "_er_LGi1VSa", "cdate": 1672531200000, "mdate": 1680562048024, "content": {"title": "The CLEF-2023 CheckThat! Lab: Checkworthiness, Subjectivity, Political Bias, Factuality, and Authority", "abstract": ""}}
{"id": "CDOPHRu6PK", "cdate": 1672531200000, "mdate": 1680521574039, "content": {"title": "MEDIC: a multi-task learning dataset for disaster image classification", "abstract": ""}}
{"id": "z4dst0rmOx_", "cdate": 1640995200000, "mdate": 1682357992505, "content": {"title": "ArCovidVac: Analyzing Arabic Tweets About COVID-19 Vaccination", "abstract": "The emergence of the COVID-19 pandemic and the first global infodemic have changed our lives in many different ways. We relied on social media to get the latest information about the COVID-19 pandemic and at the same time to disseminate information. The content in social media consisted not only health related advises, plans, and informative news from policy makers, but also contains conspiracies and rumors. It became important to identify such information as soon as they are posted to make actionable decisions (e.g., debunking rumors, or taking certain measures for traveling). To address this challenge, we develop and publicly release the first largest manually annotated Arabic tweet dataset, ArCovidVac, for the COVID-19 vaccination campaign, covering many countries in the Arab region. The dataset is enriched with different layers of annotation, including, (i) Informativeness (more vs. less importance of the tweets); (ii) fine-grained tweet content types (e.g., advice, rumors, restriction, authenticate news/information); and (iii) stance towards vaccination (pro-vaccination, neutral, anti-vaccination). Further, we performed in-depth analysis of the data, exploring the popularity of different vaccines, trending hashtags, topics and presence of offensiveness in the tweets. We studied the data for individual types of tweets and temporal changes in stance towards vaccine. We benchmarked the ArCovidVac dataset using transformer architectures for informativeness, content types, and stance detection."}}
{"id": "wbj96uljiO", "cdate": 1640995200000, "mdate": 1682357992478, "content": {"title": "Assisting the Human Fact-Checkers: Detecting All Previously Fact-Checked Claims in a Document", "abstract": ""}}
{"id": "vZyECuwGolw", "cdate": 1640995200000, "mdate": 1682357992475, "content": {"title": "Overview of the WANLP 2022 Shared Task on Propaganda Detection in Arabic", "abstract": ""}}
{"id": "uWsTAyjCLxP", "cdate": 1640995200000, "mdate": 1662877963054, "content": {"title": "Detecting the Role of an Entity in Harmful Memes: Techniques and Their Limitations", "abstract": "Harmful or abusive online content has been increasing over time, raising concerns for social media platforms, government agencies, and policymakers. Such harmful or abusive content can have major negative impact on society, e.g., cyberbullying can lead to suicides, rumors about COVID-19 can cause vaccine hesitance, promotion of fake cures for COVID-19 can cause health harms and deaths. The content that is posted and shared online can be textual, visual, or a combination of both, e.g., in a meme. Here, we describe our experiments in detecting the roles of the entities (hero, villain, victim) in harmful memes, which is part of the CONSTRAINT-2022 shared task, as well as our system for the task. We further provide a comparative analysis of different experimental settings (i.e., unimodal, multimodal, attention, and augmentation). For reproducibility, we make our experimental code publicly available. \\url{https://github.com/robi56/harmful_memes_block_fusion}"}}
{"id": "sE-H3S731C", "cdate": 1640995200000, "mdate": 1682351086871, "content": {"title": "Analyzing Encoded Concepts in Transformer Language Models", "abstract": "We propose a novel framework ConceptX, to analyze how latent concepts are encoded in representations learned within pre-trained language models. It uses clustering to discover the encoded concepts and explains them by aligning with a large set of human-defined concepts. Our analysis on seven transformer language models reveal interesting insights: i) the latent space within the learned representations overlap with different linguistic concepts to a varying degree, ii) the lower layers in the model are dominated by lexical concepts (e.g., affixation), whereas the core-linguistic concepts (e.g., morphological or syntactic relations) are better represented in the middle and higher layers, iii) some encoded concepts are multi-faceted and cannot be adequately explained using the existing human-defined concepts."}}
{"id": "reroQOrJto", "cdate": 1640995200000, "mdate": 1682357992476, "content": {"title": "ArabGend: Gender Analysis and Inference on Arabic Twitter", "abstract": ""}}
{"id": "m-U-x4aUNsr", "cdate": 1640995200000, "mdate": 1662877963005, "content": {"title": "QCRI's COVID-19 Disinformation Detector: A System to Fight the COVID-19 Infodemic in Social Media", "abstract": "Fighting the ongoing COVID-19 infodemic has been declared as one of the most important focus areas by the World Health Organization since the onset of the COVID-19 pandemic. While the information that is consumed and disseminated consists of promoting fake cures, rumors, and conspiracy theories to spreading xenophobia and panic, at the same time there is information (e.g., containing advice, promoting cure) that can help different stakeholders such as policy-makers. Social media platforms enable the infodemic and there has been an effort to curate the content on such platforms, analyze and debunk them. While a majority of the research efforts consider one or two aspects (e.g., detecting factuality) of such information, in this study we focus on a multifaceted approach, including an API,\\url{https://app.swaggerhub.com/apis/yifan2019/Tanbih/0.8.0/} and a demo system,\\url{https://covid19.tanbih.org}, which we made freely and publicly available. We believe that this will facilitate researchers and different stakeholders. A screencast of the API services and demo is available.\\url{https://youtu.be/zhbcSvxEKMk}"}}
{"id": "lvCB9hiRZz", "cdate": 1640995200000, "mdate": 1682351086627, "content": {"title": "On the Transformation of Latent Space in Fine-Tuned NLP Models", "abstract": "We study the evolution of latent space in fine-tuned NLP models. Different from the commonly used probing-framework, we opt for an unsupervised method to analyze representations. More specifically, we discover latent concepts in the representational space using hierarchical clustering. We then use an alignment function to gauge the similarity between the latent space of a pre-trained model and its fine-tuned version. We use traditional linguistic concepts to facilitate our understanding and also study how the model space transforms towards task-specific information. We perform a thorough analysis, comparing pre-trained and fine-tuned models across three models and three downstream tasks. The notable findings of our work are: i) the latent space of the higher layers evolve towards task-specific concepts, ii) whereas the lower layers retain generic concepts acquired in the pre-trained model, iii) we discovered that some concepts in the higher layers acquire polarity towards the output class, and iv) that these concepts can be used for generating adversarial triggers."}}
