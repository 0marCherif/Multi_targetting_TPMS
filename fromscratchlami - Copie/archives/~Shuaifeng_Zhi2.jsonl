{"id": "xI1ZTtVOtlz", "cdate": 1663850003400, "mdate": null, "content": {"title": "Evidential Uncertainty and Diversity Guided Active Learning for Scene Graph Generation", "abstract": "Scene Graph Generation (SGG) has already shown its great potential in various downstream tasks, but it comes at the price of a prohibitively expensive annotation process. To reduce the annotation cost, we propose using Active Learning (AL) for sampling the most informative data. However, directly porting current AL methods to the SGG task poses the following challenges: 1) unreliable uncertainty estimates, and 2) data bias problems. To deal with these challenges, we propose EDAL (\\textbf{E}vidential Uncertainty and \\textbf{D}iversity Guided Deep \\textbf{A}ctive \\textbf{L}earning), a novel AL framework tailored for the SGG task. For challenge 1), we start with Evidential Deep Learning (EDL) coupled with a global relationship mining approach to estimate uncertainty, which can effectively overcome the perturbations of open-set relationships and background-relationships to obtain reliable uncertainty estimates. To address challenge 2), we seek the diversity-based method and design the Context Blocking Module (CBM) and Image Blocking Module (IBM) to alleviate context-level bias and image-level bias, respectively. Experiments show that our AL framework can approach the performance of a fully supervised SGG model with only about $10\\%$ annotation cost. Furthermore, our ablation studies indicate that introducing AL into the SGG will face many challenges not observed in other vision tasks that are successfully overcome by our new modules. "}}
{"id": "6u6N8WWwYSM", "cdate": 1632875466261, "mdate": null, "content": {"title": "Bootstrapping Semantic Segmentation with Regional Contrast", "abstract": "We present ReCo, a contrastive learning framework designed at a regional level to assist learning in semantic segmentation. ReCo performs pixel-level contrastive learning on a sparse set of hard negative pixels, with minimal additional memory footprint. ReCo is easy to implement, being built on top of off-the-shelf segmentation networks, and consistently improves performance, achieving more accurate segmentation boundaries and faster convergence. The strongest effect is in semi-supervised learning with very few labels. With ReCo, we achieve high quality semantic segmentation model, requiring only 5 examples of each semantic class. "}}
{"id": "if4jeWCJn1W", "cdate": 1609459200000, "mdate": 1653223188330, "content": {"title": "In-Place Scene Labelling and Understanding with Implicit Scene Representation", "abstract": "Semantic labelling is highly correlated with geometry and radiance reconstruction, as scene entities with similar shape and appearance are more likely to come from similar classes. Recent implicit neural reconstruction techniques are appealing as they do not require prior training data, but the same fully self-supervised approach is not possible for semantics because labels are human-defined properties.We extend neural radiance fields (NeRF) to jointly encode semantics with appearance and geometry, so that complete and accurate 2D semantic labels can be achieved using a small amount of in-place annotations specific to the scene. The intrinsic multi-view consistency and smoothness of NeRF benefit semantics by enabling sparse labels to efficiently propagate. We show the benefit of this approach when labels are either sparse or very noisy in room-scale scenes. We demonstrate its advantageous properties in various interesting applications such as an efficient scene labelling tool, novel semantic view synthesis, label denoising, super-resolution, label interpolation and multi-view semantic label fusion in visual semantic mapping systems."}}
{"id": "I8l6rBxHaB3", "cdate": 1609459200000, "mdate": 1653223460779, "content": {"title": "Bootstrapping Semantic Segmentation with Regional Contrast", "abstract": "We present ReCo, a contrastive learning framework designed at a regional level to assist learning in semantic segmentation. ReCo performs semi-supervised or supervised pixel-level contrastive learning on a sparse set of hard negative pixels, with minimal additional memory footprint. ReCo is easy to implement, being built on top of off-the-shelf segmentation networks, and consistently improves performance in both semi-supervised and supervised semantic segmentation methods, achieving smoother segmentation boundaries and faster convergence. The strongest effect is in semi-supervised learning with very few labels. With ReCo, we achieve high-quality semantic segmentation models, requiring only 5 examples of each semantic class. Code is available at https://github.com/lorenmt/reco."}}
{"id": "S7ZdEmldTH", "cdate": 1546300800000, "mdate": null, "content": {"title": "SceneCode: Monocular Dense Semantic Reconstruction Using Learned Encoded Scene Representations.", "abstract": "Systems which incrementally create 3D semantic maps from image sequences must store and update representations of both geometry and semantic entities. However, while there has been much work on the correct formulation for geometrical estimation, state-of-the-art systems usually rely on simple semantic representations which store and update independent label estimates for each surface element (depth pixels, surfels, or voxels). Spatial correlation is discarded, and fused label maps are incoherent and noisy. We introduce a new compact and optimisable semantic representation by training a variational auto-encoder that is conditioned on a colour image. Using this learned latent space, we can tackle semantic label fusion by jointly optimising the low-dimenional codes associated with each of a set of overlapping images, producing consistent fused label maps which preserve spatial correlation. We also show how this approach can be used within a monocular keyframe based semantic mapping system where a similar code approach is used for geometry. The probabilistic formulation allows a flexible formulation where we can jointly estimate motion, geometry and semantics in a unified optimisation."}}
{"id": "T559mdfnP1", "cdate": 1514764800000, "mdate": 1653223187019, "content": {"title": "Toward real-time 3D object recognition: A lightweight volumetric CNN framework using multitask learning", "abstract": ""}}
{"id": "yZvC6cfxIIf", "cdate": 1483228800000, "mdate": 1653223187018, "content": {"title": "LightNet: A Lightweight 3D Convolutional Neural Network for Real-Time 3D Object Recognition", "abstract": "With the rapid growth of 3D data, accurate and efficient 3D object recognition becomes a major problem. Machine learning methods have achieved the state-of-the-art performance in the area, especially for deep convolutional neural networks. However, existing network models have high computational cost and are unsuitable for real-time 3D object recognition applications. In this paper, we propose LightNet, a lightweight 3D convolutional neural network for real-time 3D object recognition. It achieves comparable accuracy to the state-of-the-art methods with a single model and extremely low computational cost. Experiments have been conducted on the ModelNet and Sydney Urban Objects datasets. It is shown that our model improves the VoxNet model by relative 17.4% and 23.1% on the ModelNet10 and ModelNet40 benchmarks with less than 67% of training parameters. It is also demonstrated that the model can be applied in real-time scenarios."}}
