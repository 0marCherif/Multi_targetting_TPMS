{"id": "IaUmThUmq6m", "cdate": 1672057304342, "mdate": 1672057304342, "content": {"title": "BioGPT: Generative Pre-trained Transformer for Biomedical Text Generation and Mining", "abstract": "Pre-trained language models have attracted increasing attention in the biomedical domain, inspired by their great success in the general natural language domain. Among the two main branches of pre-trained language models in the general language domain, i.e. BERT (and its variants) and GPT (and its variants), the first one has been extensively studied in the biomedical domain, such as BioBERT and PubMedBERT. While they have achieved great success on a variety of discriminative downstream biomedical tasks, the lack of generation ability constrains their application scope. In this paper, we propose BioGPT, a domain-specific generative Transformer language model pre-trained on large-scale biomedical literature. We evaluate BioGPT on six biomedical natural language processing tasks and demonstrate that our model outperforms previous models on most tasks. Especially, we get 44.98%, 38.42% and 40.76% F1 score on BC5CDR, KD-DTI and DDI end-to-end relation extraction tasks, respectively, and 78.2% accuracy on PubMedQA, creating a new record. Our case study on text generation further demonstrates the advantage of BioGPT on biomedical literature to generate fluent descriptions for biomedical terms."}}
{"id": "bIC0BfWzCs", "cdate": 1671592012424, "mdate": null, "content": {"title": "What are the Desired Characteristics of Calibration Sets? Identifying Correlates on Long Form Scientific Summarization", "abstract": "Summarization models are typically trained to maximize the likelihood of a single reference (MLE). As a consequence, during inference, the probabilities assigned to model generations are often poorly calibrated to quality metrics. To address this, after an initial MLE step, recent work has added a calibration step, which exposes a model its own ranked outputs to improve relevance or, in a separate line of work, contrasts positive and negative sets to improve faithfulness. While effective, much of the work has focused on how to generate and optimize these sets. Less is known about why one setup is more effective than another. In this work, we aim to uncover the underlying characteristics of effective candidate sets for both relevance and faithfulness calibration.  For each training instance, we form a large, diverse pool of candidates and systematically vary the subsets used for calibration fine-tuning.  Each selection strategy targets distinct aspects of the sets, such as lexical diversity or the size of the gap between positive and negatives. On three diverse scientific long-form summarization datasets (spanning biomedical, clinical, and chemical domains), we find, among others, that faithfulness calibration is optimal when the negative sets are extractive and more likely to be generated, whereas for relevance calibration, the metric margin between ranked candidates should be maximized and surprise minimized.\n"}}
{"id": "4K2SRejNGEI", "cdate": 1663850483323, "mdate": null, "content": {"title": "Boosting Drug-Target Affinity Prediction from Nearest Neighbors", "abstract": "Precisely predicting Drug-Target binding Affinity (DTA) is essential for drug discovery. \nRecently, deep learning methods have been popular with DTA prediction. However, the prediction accuracy is still far from satisfaction. \nIn this work, inspired by the recent success of retrieval methods, we propose $k$NN-DTA, a non-parametric embedding-based retrieval method adopted on a pre-trained DTA prediction model, which can extend the power of the neural DTA model with no or negligible cost. \nCompared to traditional chemical similarity retrieval, our embedding-based retrieval shows extremely high efficiency.\nDifferent from existing methods, we introduce two neighbor aggregation ways from both embedding space and label space that are integrated in a unified framework. \nSpecifically, we propose a \\emph{label aggregation} with \\emph{pair-wise retrieval} and a \\emph{representation aggregation} with \\emph{point-wise retrieval} of the nearest neighbors. \nThis method executes in the inference phase and can efficiently boost the DTA prediction performance with no training cost.\nIn addition, we propose an extension, Ada-$k$NN-DTA, an instance-wise and adaptive aggregation with lightweight learning.\nResults on four benchmark datasets show that $k$NN-DTA brings significant improvements, outperforming previous state-of-the-art (SOTA) results, e.g, on BindingDB IC$_{50}$ and $K_i$ testbeds, $k$NN-DTA obtains new records of RMSE scores $\\bf{0.687}$ and $\\bf{0.748}$ with both $\\bf{4}$ point improvement. \nThe extended Ada-$k$NN-DTA can further improve the performance, e.g., another $\\bf{1}$ point gain on BindingDB. These results strongly prove the effectiveness and efficiency of our method.\nResults on other settings and comprehensive studies/analyses also show the great potential of our $k$NN-DTA approach."}}
{"id": "5cFfz6yMVPU", "cdate": 1663850340329, "mdate": null, "content": {"title": "$\\mathcal{O}$-GNN: incorporating ring priors into molecular modeling", "abstract": "Cyclic compounds that contain at least one ring play an important role in drug design. Despite the recent success of molecular modeling with graph neural networks (GNNs), few models explicitly take rings in compounds into consideration, consequently limiting the expressiveness of the models. In this work, we design a new variant of GNN, ring-enhanced GNN ($\\mathcal{O}$-GNN), that explicitly models rings in addition to atoms and bonds in compounds. In $\\mathcal{O}$-GNN,  each ring is represented by a latent vector, which contributes to and is iteratively updated by atom and bond representations. Theoretical analysis shows that $\\mathcal{O}$-GNN is able to distinguish two isomorphic subgraphs lying on different rings using only one layer while conventional graph convolutional neural networks require multiple layers to distinguish, demonstrating that $\\mathcal{O}$-GNN is more expressive. Through experiments, $\\mathcal{O}$-GNN shows good performance on $\\bf{11}$ public datasets. In particular, it achieves state-of-the-art validation result on the PCQM4Mv1 benchmark (outperforming the previous KDDCup champion solution) and the drug-drug interaction prediction task on DrugBank. Furthermore, $\\mathcal{O}$-GNN outperforms strong baselines (without modeling rings) on the molecular property prediction and retrosynthesis prediction tasks."}}
{"id": "Q_Jexl8-qDi", "cdate": 1663849843137, "mdate": null, "content": {"title": "De Novo Molecular Generation via Connection-aware Motif Mining", "abstract": "De novo molecular generation is an essential task for science discovery. Recently, fragment-based deep generative models have attracted much research attention due to their flexibility in generating novel molecules based on existing molecule fragments. However, the motif vocabulary, i.e., the collection of frequent fragments, is usually built upon heuristic rules, which brings difficulties to capturing common substructures from large amounts of molecules. In this work, we propose MiCaM to generate molecules based on mined connection-aware motifs. Specifically, it leverages a data-driven algorithm to automatically discover motifs from a molecule library by iteratively merging subgraphs based on their frequency. The obtained motif vocabulary consists of not only molecular motifs (i.e., the frequent fragments), but also their connection information, indicating how the motifs are connected with each other. Based on the mined connection-aware motifs, MiCaM builds a connection-aware generator, which simultaneously picks up motifs and determines how they are connected. We test our method on distribution-learning benchmarks (i.e., generating novel molecules to resemble the distribution of a given training set) and goal-directed benchmarks (i.e., generating molecules with target properties), and achieve significant improvements over previous fragment-based baselines. Furthermore, we demonstrate that our method can effectively mine domain-specific motifs for different tasks."}}
{"id": "kcrIligNnl", "cdate": 1632875662379, "mdate": null, "content": {"title": "Direct Molecular Conformation Generation", "abstract": "Molecular conformation generation, which is to generate 3 dimensional coordinates of all the atoms in a molecule, is an important task for bioinformatics and pharmacology. Most existing machine learning based methods first predict interatomic distances and then generate conformations based on them. This two-stage approach has a potential limitation that the predicted distances may conflict with each other, e.g., violating the triangle inequality. In this work, we propose a method that directly outputs the coordinates of atoms, so that there is no violation of constraints. The conformation generator of our method stacks multiple blocks, and each block outputs a conformation which is then refined by the following block.  We adopt the variational auto-encoder (VAE) framework and use a latent variable to generate diverse conformations. To handle the roto-translation equivariance, we adopt a loss that is invariant to rotation and translation of molecule coordinates, by computing the minimal achievable distance after any rotation and translation. Our method outperforms strong baselines on four public datasets, which shows the effectiveness of our method and the great potential of the direct approach. The code is released at \\url{https://github.com/DirectMolecularConfGen/DMCG}. "}}
{"id": "XK4GN6UCTfH", "cdate": 1632875654499, "mdate": null, "content": {"title": "MS$^2$-Transformer: An End-to-End Model for MS/MS-assisted Molecule Identification", "abstract": "Mass spectrometry (MS) acts as an important technique for measuring the mass-to-charge ratios of ions and identifying the chemical structures of unknown metabolites.  Practically, tandem mass spectrometry (MS/MS), which couples multiple standard MS in series and outputs fine-grained spectrum with fragmental information, has been popularly used.  Manually interpreting the MS/MS spectrum into the molecules (i.e., the simplified molecular-input line-entry system, SMILES) is often costly and cumbersome, mainly due to the synthesis and labeling of isotopes and the requirement of expert knowledge.  In this work, we regard molecule identification as a spectrum-to-sequence conversion problem and propose an end-to-end model, called MS$^2$-Transformer, to address this task.  The chemical knowledge, defined through a fragmentation tree from the MS/MS spectrum, is incorporated into MS$^2$-Transformer.  Our method achieves state-of-the-art results on two widely used benchmarks in molecule identification. To our best knowledge, MS$^2$-Transformer is the first machine learning model that can accurately identify the structures (e.g., molecular graph) from experimental MS/MS rather than chemical formula/categories only (e.g., C$_6$H$_{12}$O$_6$/organic compound), demonstrating it the great application potential in biomedical studies."}}
{"id": "pz1euXohm4H", "cdate": 1632875634382, "mdate": null, "content": {"title": "Target-Side Input Augmentation for Sequence to Sequence Generation", "abstract": "Autoregressive sequence generation, a prevalent task in machine learning and natural language processing, generates every target token conditioned on both a source input and previously generated target tokens. Previous data augmentation methods, which have been shown to be effective for the task, mainly enhance source inputs (e.g., injecting noise into the source sequence by random swapping or masking, back translation, etc.) while overlooking the target-side augmentation. In this work, we propose a target-side augmentation method for sequence generation. In training, we use the decoder output probability distributions as soft indicators, which are multiplied with target token embeddings, to build pseudo tokens. These soft pseudo tokens are then used as target tokens to enhance the training. We conduct comprehensive experiments on various sequence generation tasks, including dialog generation, machine translation, and abstractive summarization. Without using any extra labeled data or introducing additional model parameters, our method significantly outperforms strong baselines. The code is available at https://github.com/TARGET-SIDE-DATA-AUG/TSDASG."}}
{"id": "Mop0QMT5yei", "cdate": 1623112989535, "mdate": null, "content": {"title": "A Benchmark of Discovering Drug-Target Interaction from Biomedical Literature", "abstract": "As millions of papers come out every year in the biomedical domain, automatic knowledge discovery (KD) from biomedical literature becomes an urgent demand in the industry. While KD in the biomedical domain attracts much research attention in recent years, the lack of benchmark datasets significantly hinders its progress. In this work, we create a dataset, KD-DTI, for discovering <drug, target, interaction> triplets from literature, which is one of the most important KD tasks in the biomedical domain. KD-DTI contains 14k unique biomedical papers, each of which is associated with at least one drug, target, interaction triplet. We also provide a semi-supervised dataset with 139k unique papers. We present and analyze multiple solutions, including several extractive/generative models and two data enhancement methods. The results show that the performance of those models is far from industry demand, indicating that the dataset presents a challenging research problem for the community. The dataset will be freely accessible after the review process."}}
{"id": "khZGbgRQjjM", "cdate": 1621629827233, "mdate": null, "content": {"title": "Stylized Dialogue Generation with Multi-Pass Dual Learning", "abstract": "Stylized dialogue generation, which aims to generate a given-style response for an input context, plays a vital role in intelligent dialogue systems. Considering there is no parallel data between the contexts and the responses of target style S_1, existing works mainly use back translation to generate stylized synthetic data for training, where the data about context, target style S_1 and an intermediate style S_0 is used. However, the interaction among these texts is not fully exploited, and the pseudo contexts are not adequately modeled. To overcome the above difficulties, we propose multi-pass dual learning (MPDL), which leverages the duality among the context, response of style S_1 and response of style S_0. MPDL builds mappings among the above three domains, where the context should be reconstructed by the MPDL framework, and the reconstruction error is used as the training signal. To evaluate the quality of synthetic data, we also introduce discriminators that effectively measure how a pseudo sequence matches the specific domain, and the evaluation result is used as the weight for that data. Evaluation results indicate that our method obtains significant improvement over previous baselines.\n"}}
