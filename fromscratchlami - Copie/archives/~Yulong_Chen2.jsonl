{"id": "t6KLk_wudZ", "cdate": 1672531200000, "mdate": 1690909548323, "content": {"title": "UniSumm and SummZoo: Unified Model and Diverse Benchmark for Few-Shot Summarization", "abstract": "Yulong Chen, Yang Liu, Ruochen Xu, Ziyi Yang, Chenguang Zhu, Michael Zeng, Yue Zhang. Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 2023."}}
{"id": "oGaVnPmdLp", "cdate": 1672531200000, "mdate": 1690909548321, "content": {"title": "Revisiting Cross-Lingual Summarization: A Corpus-based Study and A New Benchmark with Improved Annotation", "abstract": "Most existing cross-lingual summarization (CLS) work constructs CLS corpora by simply and directly translating pre-annotated summaries from one language to another, which can contain errors from both summarization and translation processes. To address this issue, we propose ConvSumX, a cross-lingual conversation summarization benchmark, through a new annotation schema that explicitly considers source input context. ConvSumX consists of 2 sub-tasks under different real-world scenarios, with each covering 3 language directions. We conduct thorough analysis on ConvSumX and 3 widely-used manually annotated CLS corpora and empirically find that ConvSumX is more faithful towards input text. Additionally, based on the same intuition, we propose a 2-Step method, which takes both conversation and summary as input to simulate human annotation process. Experimental results show that 2-Step method surpasses strong baselines on ConvSumX under both automatic and human evaluation. Analysis shows that both source input text and summary are crucial for modeling cross-lingual summaries."}}
{"id": "d4HL2b4UHa", "cdate": 1672531200000, "mdate": 1690909548187, "content": {"title": "Revisiting Cross-Lingual Summarization: A Corpus-based Study and A New Benchmark with Improved Annotation", "abstract": "Yulong Chen, Huajian Zhang, Yijie Zhou, Xuefeng Bai, Yueguan Wang, Ming Zhong, Jianhao Yan, Yafu Li, Judy Li, Xianchao Zhu, Yue Zhang. Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 2023."}}
{"id": "A1O7Z45UIp", "cdate": 1672531200000, "mdate": 1687852633082, "content": {"title": "EASE: An Easily-Customized Annotation System Powered by Efficiency Enhancement Mechanisms", "abstract": "The performance of current supervised AI systems is tightly connected to the availability of annotated datasets. Annotations are usually collected through annotation tools, which are often designed for specific tasks and are difficult to customize. Moreover, existing annotation tools with an active learning mechanism often only support limited use cases. To address these limitations, we present EASE, an Easily-Customized Annotation System Powered by Efficiency Enhancement Mechanisms. \\sysname provides modular annotation units for building customized annotation interfaces and also provides multiple back-end options that suggest annotations using (1) multi-task active learning; (2) demographic feature based active learning; (3) a prompt system that can query the API of large language models. We conduct multiple experiments and user studies to evaluate our system's flexibility and effectiveness. Our results show that our system can meet the diverse needs of NLP researchers and significantly accelerate the annotation process."}}
{"id": "Fvn4ay9s-HW", "cdate": 1653669417898, "mdate": 1653669417898, "content": {"title": "The Cross-lingual Conversation Summarization Challenge", "abstract": "We propose the shared task of cross-lingual conversation summarization, ConvSumX Challenge, opening new avenues for researchers to investigate solutions that integrate conversation summarization and machine translation. This task can be particularly useful due to the emergence of online meetings and conferences. We construct a new benchmark, covering 2 real-world scenarios and 3 language directions, including a low-resource language. We hope that ConvSumX can motivate researches to go beyond English and break the barrier for non-English speakers to benefit from recent advances of conversation summarization."}}
{"id": "ZKXlBCYAo8R", "cdate": 1649656758702, "mdate": 1649656758702, "content": {"title": "Graph Pre-training for AMR Parsing and Generation", "abstract": "Abstract meaning representation (AMR) high- lights the core semantic information of text in a graph structure. Recently, pre-trained language models (PLMs) have advanced tasks of AMR parsing and AMR-to-text generation, respectively. However, PLMs are typically pre-trained on textual data, thus are sub-optimal for modelling structural knowledge. To this end, we investigate graph self-supervised training to improve the structure awareness of PLMs over AMR graphs. In particular, we introduce two graph auto-encoding strategies for graph-to-graph pre-training and four tasks to integrate text and graph information during pre-training. We further design a unified framework to bridge the gap between pre-training and fine-tuning tasks. Experiments on both AMR parsing and AMR-to-text generation show the superiority of our model. To our knowledge, we are the first to consider pre-training on semantic graphs."}}
{"id": "rcgbPskVkza", "cdate": 1640995200000, "mdate": 1671889611559, "content": {"title": "Graph Pre-training for AMR Parsing and Generation", "abstract": ""}}
{"id": "omvPoplBfXW", "cdate": 1640995200000, "mdate": 1671889611481, "content": {"title": "DialogSum Challenge: Results of the Dialogue Summarization Shared Task", "abstract": "We report the results of DialogSum Challenge, the shared task on summarizing real-life scenario dialogues at INLG 2022. Four teams participate in this shared task and three submit their system reports, exploring different methods to improve the performance of dialogue summarization. Although there is a great improvement over the baseline models regarding automatic evaluation metrics, such as Rouge scores, we find that there is a salient gap between model generated outputs and human annotated summaries by human evaluation from multiple aspects. These findings demonstrate the difficulty of dialogue summarization and suggest that more fine-grained evaluatuion metrics are in need."}}
{"id": "mdFf1vHSNR", "cdate": 1640995200000, "mdate": 1671889611408, "content": {"title": "Recent Advances in Text-to-SQL: A Survey of What We Have and What We Expect", "abstract": ""}}
{"id": "aRbVaz4w1g", "cdate": 1640995200000, "mdate": 1671889611437, "content": {"title": "MACSum: Controllable Summarization with Mixed Attributes", "abstract": "Controllable summarization allows users to generate customized summaries with specified attributes. However, due to the lack of designated annotations of controlled summaries, existing works have to craft pseudo datasets by adapting generic summarization benchmarks. Furthermore, most research focuses on controlling single attributes individually (e.g., a short summary or a highly abstractive summary) rather than controlling a mix of attributes together (e.g., a short and highly abstractive summary). In this paper, we propose MACSum, the first human-annotated summarization dataset for controlling mixed attributes. It contains source texts from two domains, news articles and dialogues, with human-annotated summaries controlled by five designed attributes (Length, Extractiveness, Specificity, Topic, and Speaker). We propose two simple and effective parameter-efficient approaches for the new task of mixed controllable summarization based on hard prompt tuning and soft prefix tuning. Results and analysis demonstrate that hard prompt models yield the best performance on all metrics and human evaluations. However, mixed-attribute control is still challenging for summarization tasks. Our dataset and code are available at https://github.com/psunlpgroup/MACSum."}}
