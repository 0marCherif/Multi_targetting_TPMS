{"id": "7D_cO8GISi6", "cdate": 1623588457874, "mdate": 1623588457874, "content": {"title": "Task-Aware Representation of Sentences for Generic Text Classification", "abstract": "State-of-the-art approaches for text classification leverage a transformer architecture with a linear layer on top that outputs a class distribution for a given prediction problem. While effective, this approach suffers from conceptual limitations that affect its utility in few-shot or zero-shot transfer learning scenarios. First, the number of classes to predict needs to be pre-defined. In a transfer learning setting, in which new classes are added to an already trained classifier, all information contained in a linear layer is therefore discarded, and a new layer is trained from scratch. Second, this approach only learns the semantics of classes implicitly from training examples, as opposed to leveraging the explicit semantic information provided by the natural language names of the classes. For instance, a classifier trained to predict the topics of news articles might have classes like \u201cbusiness\u201d or \u201csports\u201d that themselves carry semantic information. Extending a classifier to predict a new class named \u201cpolitics\u201d with only a handful of training examples would benefit from both leveraging the semantic information in the name of a new class and using the information contained in the already trained linear layer. This paper presents a novel formulation of text classification that addresses these limitations. It imbues the notion of the task at hand into the transformer model itself by factorizing arbitrary classification problems into a generic binary classification problem. We present experiments in few-shot and zero-shot transfer learning that show that our approach significantly outperforms previous approaches on small training data and can even learn to predict new classes with no training examples at all. The implementation of our model is publicly available at: https://github.com/flairNLP/flair."}}
{"id": "WiGQBFuVRv", "cdate": 1601308045185, "mdate": null, "content": {"title": "Multivariate Probabilistic Time Series Forecasting via Conditioned Normalizing Flows", "abstract": "Time series forecasting is often fundamental to scientific and engineering problems and enables decision making. With ever increasing data set sizes, a trivial solution to scale up predictions is to assume independence between interacting time series. However, modeling statistical dependencies can improve accuracy and enable analysis of interaction effects. Deep learning methods are well suited for this problem, but multi-variate models often assume a simple parametric distribution and do not scale to high dimensions. In this work we model the multi-variate temporal dynamics of time series via an autoregressive deep learning model, where the data distribution  is represented by a conditioned normalizing flow. This combination retains the power of autoregressive models, such as good performance in extrapolation into the future, with the flexibility of flows as a general purpose high-dimensional distribution model, while remaining computationally tractable. We show that it improves over the state-of-the-art for standard metrics on many real-world data sets with several thousand interacting time-series."}}
{"id": "S1gINCVYDH", "cdate": 1569439278465, "mdate": null, "content": {"title": "Posterior Sampling: Make Reinforcement Learning Sample Efficient Again", "abstract": "Machine learning thrives on leveraging structure in data, and many breakthroughs (e.g.\\ convolutional networks) have been made by designing algorithms which exploit the underlying structure of a distribution. Reinforcement Learning agents interact with worlds that are similarly full of structure. For example, no sequence of actions an agent takes will ever cause the laws of physics to change, therefore an agent which learns to generalize such laws through time and space will have an advantage. Sample efficient reinforcement learning can be accomplished when assuming that the world has structure and designing learning algorithms which exploit this assumption without knowing the actual structure beforehand. Posterior Sampling for Reinforcement Learning (PSRL) \\citep{strens2000bayesian} is such a method which assumes structure in the world and exploits it for learning. A PSLR learning agent first samples models of the environment which conform to both prior assumptions on the world's structure and past observations and then interacts with the true environment using a policy guided by the sampled model of the environment. While PSRL delivers theoretical Bayesian regret bounds, there are many open issues which must be addressed before PSRL can be applied to current benchmark continuous reinforcement reinforcement tasks. In this work, we identify these issues and find practical solutions to them leading to a novel algorithm we call Neural-PSRL. We validate the algorithm's effectiveness by achieving state of the art results in the HalfCheetah-v3 and Hopper-v3 domains."}}
{"id": "r1ZsLQbdbS", "cdate": 1546300800000, "mdate": null, "content": {"title": "Pooled Contextualized Embeddings for Named Entity Recognition", "abstract": "Alan Akbik, Tanja Bergmann, Roland Vollgraf. Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers). 2019."}}
{"id": "Syb4ymb_-S", "cdate": 1546300800000, "mdate": null, "content": {"title": "FLAIR: An Easy-to-Use Framework for State-of-the-Art NLP", "abstract": "Alan Akbik, Tanja Bergmann, Duncan Blythe, Kashif Rasul, Stefan Schweter, Roland Vollgraf. Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics (Demonstrations). 2019."}}
{"id": "HJWE3WfOZr", "cdate": 1483228800000, "mdate": null, "content": {"title": "The Projector: An Interactive Annotation Projection Visualization Tool", "abstract": "Recent advances in image classification methods, along with the availability of associated tools, has seen their use become widespread in many domains. This paper presents a novel application of current image classification approaches in the area of emergency situation awareness. We discuss image classification based on low level features as well as methods built on top of pre-trained classifiers. The performance of the classifiers are assessed in terms of accuracy along with consideration to computational aspects given the size of the image database. Specifically, we investigate image classification in the context of a bush fire emergency in the Australian state of NSW where images associated with Tweets during the emergency were used to train and test classification approaches. Emergency service operators are interested in having images relevant to such fires reported as extra information to help manage evolving emergencies. We show that these methodologies can classify images into fire and not fire related classes with an accuracy of 86%."}}
{"id": "BJZjlh-OZB", "cdate": 1483228800000, "mdate": null, "content": {"title": "Learning Texture Manifolds with the Periodic Spatial GAN", "abstract": "This paper introduces a novel approach to texture synthesis based on generative adversarial networks (GAN) (Goodfellow et al., 2014), and call this technique Periodic Spatial GAN (PSGAN). The PSGAN..."}}
{"id": "BkWDiU-uZB", "cdate": 1041379200000, "mdate": null, "content": {"title": "Nonlinear Filtering of Electron Micrographs by Means of Support Vector Regression", "abstract": "Nonlinear (cid:12)ltering can solve very complex problems, but typically involve very time consuming calculations. Here we show that for (cid:12)lters that are constructed as a RBF network with Gaussian basis functions, a decomposition into linear (cid:12)lters exists, which can be computed e(cid:14)ciently in the frequency domain, yielding dramatic improvement in speed. We present an application of this idea to image processing. In electron micrograph images of photoreceptor terminals of the fruit (cid:13)y, Drosophila, synaptic vesicles containing neurotransmitter should be detected and labeled automatically. We use hand labels, provided by human experts, to learn a RBF (cid:12)lter using Support Vector Regression with Gaussian kernels. We will show that the resulting nonlinear (cid:12)lter solves the task to a degree of accuracy, which is close to what can be achieved by human experts. This allows the very time consuming task of data evaluation to be done e(cid:14)ciently."}}
{"id": "rkVtSvbdZB", "cdate": 978307200000, "mdate": null, "content": {"title": "Multi Dimensional ICA to Separate Correlated Sources", "abstract": "We present a new method for the blind separation of sources, which do not fulfill the independence assumption. In contrast to standard methods we consider groups of neighboring samples (\"patches\") within the observed mixtures. First we extract independent features from the observed patches. It turns out that the average dependencies between these features in different sources is in general lower than the dependencies be(cid:173) tween the amplitudes of different sources. We show that it might be the case that most of the dependencies is carried by only a small number of features. Is this case - provided these features can be identified by some heuristic - we project all patches into the subspace which is orthogonal to the subspace spanned by the \"correlated\" features. Standard ICA is then performed on the elements of the transformed patches (for which the independence assumption holds) and ro(cid:173) bustly yields a good estimate of the mixing matrix."}}
