{"id": "-aEuKX6zQKmr", "cdate": 1663850190028, "mdate": null, "content": {"title": "EmbedDistill: A geometric knowledge distillation for information retrieval", "abstract": "Large neural models (such as Transformers) achieve state-of-the-art performance for information retrieval. In this paper, we aim to improve distillation methods that pave the way for the deployment of such models in practice. The proposed distillation approach supports both retrieval and re-ranking stages and crucially leverages the relative geometry among queries and documents learned by the large teacher model. It goes beyond existing distillation methods in the information retrieval literature, which simply rely on the teacher's scalar scores over the training data, on two fronts: providing stronger signals about local geometry via embedding matching and attaining better coverage of data manifold globally via query generation. Embedding matching provides a stronger signal to align the representations of the teacher and student models. At the same time, query generation explores the data manifold to reduce the discrepancies between the student and teacher where the training data is sparse. Our distillation approach is theoretically justified and applies to both dual encoder (DE) and cross-encoder (CE) models. Furthermore, for distilling a CE model to a DE model via embedding matching, we propose a novel dual pooling-based scorer for the CE model that facilitates a more distillation-friendly embedding geometry, especially for DE student models."}}
{"id": "_jg6Sf6tuF7", "cdate": 1652737741771, "mdate": null, "content": {"title": "Post-hoc estimators for learning to defer to an expert", "abstract": "Many practical settings allow a learner to defer predictions to one or more costly experts. For example, the learning to defer paradigm allows a learner to defer to a human expert, at some monetary cost. Similarly, the adaptive inference paradigm allows a base model to defer to one or more large models, at some computational cost. The goal in these settings is to learn classification and deferral mechanisms to optimise a suitable accuracy-cost tradeoff. To achieve this, a central issue studied in prior work is the design of a coherent loss function for both mechanisms. In this work, we demonstrate that existing losses have two subtle limitations: they can encourage underfitting when there is a high cost of deferring, and the deferral function can have a weak dependence on the base model predictions. To resolve these issues, we propose a post-hoc training scheme: we train a deferral function on top of a base model, with the objective of predicting to defer when the base model's error probability exceeds the cost of the expert model. This may be viewed as applying a partial surrogate to the ideal deferral loss, which can lead to a tighter approximation and thus better performance. Empirically, we verify the efficacy of post-hoc training on benchmarks for learning to defer and adaptive inference."}}
{"id": "2yITmG7YIFT", "cdate": 1632875735469, "mdate": null, "content": {"title": "HD-cos Networks: Efficient Neural Architechtures for Secure Multi-Party Computation", "abstract": "Multi-party computation (MPC) is a branch of cryptography where multiple non-colluding  parties execute a well designed protocol to securely compute a function. With the non-colluding party assumption, MPC has a cryptographic guarantee that the parties will not learn sensitive information from the computation process, making it an appealing framework for applications that involve privacy-sensitive user data.\nIn this paper, we study  training and inference of neural networks under the MPC setup. This is challenging because the elementary operations of neural networks such as the ReLU activation function and matrix-vector multiplications are very expensive to compute due to the added multi-party communication overhead. \nTo address this, we propose the HD-cos network that uses 1) cosine as activation function, 2) the Hadamard-Diagonal transformation to replace the unstructured linear transformations. We show that both of the approaches enjoy strong theoretical motivations and efficient computation under the MPC setup. We demonstrate on multiple public datasets that HD-cos matches the quality of the more expensive baselines. "}}
{"id": "wRuDYxclcAn", "cdate": 1620675964220, "mdate": null, "content": {"title": "Learning Kernel Tests Without Data Splitting", "abstract": "Modern large-scale kernel-based tests such as maximum mean discrepancy (MMD) and kernelized Stein discrepancy (KSD) optimize kernel hyperparameters on a held-out sample via data splitting to obtain the most powerful test statistics. While data splitting results in a tractable null distribution, it suffers from a reduction in test power due to smaller test sample size. Inspired by the selective inference framework, we propose an approach that enables learning the hyperparameters and testing on the full sample without data splitting. Our approach can correctly calibrate the test in the presence of such dependency, and yield a test threshold in closed form. At the same significance level, our approach\u2019s test power is empirically larger than that of the data-splitting approach, regardless of its split proportion."}}
{"id": "cuNvTV0YLBU", "cdate": 1620675851670, "mdate": null, "content": {"title": "Kernel Stein Tests for Multiple Model Comparison", "abstract": "We address the problem of nonparametric multiple model comparison: given l candidate models, decide whether each candidate is as good as the best one(s) in the list (negative), or worse (positive). We propose two statistical tests, each controlling a different notion of decision errors. The first test, building on the post selection inference framework, provably controls the fraction of best models that are wrongly declared worse (false positive rate). The second test is based on multiple correction, and controls the fraction of the models declared worse that are in fact as good as the best (false discovery rate). We prove that under some conditions the first test can yield a higher true positive rate than the second. Experimental results on toy and real (CelebA, Chicago Crime data) problems show that the two tests have high true positive rates with well-controlled error rates. By contrast, the naive approach of choosing the model with the lowest score without correction leads to a large number of false positives."}}
{"id": "O4QRO3XV4r_", "cdate": 1620675722124, "mdate": null, "content": {"title": "Testing Goodness of Fit of Conditional Density Models with Kernels", "abstract": "We propose two nonparametric statistical tests of goodness of fit for conditional distributions: given a conditional probability density function p(y|x) and a joint sample, decide whether the sample is drawn from p(y|x)rx(x) for some density rx. Our tests, formulated with a Stein operator, can be applied to any differentiable conditional density model, and require no knowledge of the normalizing constant. We show that 1) our tests are consistent against any fixed alternative conditional model; 2) the statistics can be estimated easily, requiring no density estimation as an intermediate step; and 3) our second test offers an interpretable test result providing insight on where the conditional model does not fit well in the domain of the covariate. We demonstrate the interpretability of our test on a task of modeling the distribution of New York City\u2019s taxi drop-off location given a pick-up point. To our knowledge, our work is the first to propose such conditional goodness-of-fit tests that simultaneously have all these desirable properties."}}
{"id": "1_AUkYqx7Th", "cdate": 1588842905515, "mdate": null, "content": {"title": "Kernel Conditional Moment Test via Maximum Moment Restriction", "abstract": "We propose a new family of specification tests called kernel conditional moment (KCM) tests. Our tests are built on conditional moment\nembeddings (CMME)\u2014a novel representation of conditional moment\nrestrictions in a reproducing kernel Hilbert space (RKHS). After transforming the conditional moment restrictions into a continuum of unconditional counterparts, the test statistic is defined as the maximum\nmoment restriction within the unit ball of the RKHS. We show that\nthe CMME fully characterizes the original conditional moment restrictions, leading to consistency in both hypothesis testing and parameter\nestimation. The proposed test also has an analytic expression that is\neasy to compute as well as closed-form asymptotic distributions. Our\nempirical studies show that the KCM test has a promising finite-sample\nperformance compared to existing tests."}}
{"id": "rk-GUnbdWS", "cdate": 1546300800000, "mdate": null, "content": {"title": "Kernel Mean Matching for Content Addressability of GANs", "abstract": "We propose a novel procedure which adds \"content-addressability\" to any given unconditional implicit model e.g., a generative adversarial network (GAN). The procedure allows users to control the generative process by specifying a set (arbitrary size) of desired examples based on which similar samples are generated from the model. The proposed approach, based on kernel mean matching, is applicable to any generative models which transform latent vectors to samples, and does not require retraining of the model. Experiments on various high-dimensional image generation problems (CelebA-HQ, LSUN bedroom, bridge, tower) show that our approach is able to generate images which are consistent with the input set, while retaining the image quality of the original model. To our knowledge, this is the first work that attempts to construct, at test time, a content-addressable generative model from a trained marginal model."}}
{"id": "r1-34dZ_ZS", "cdate": 1514764800000, "mdate": null, "content": {"title": "Informative Features for Model Comparison", "abstract": "Given two candidate models, and a set of target observations, we address the problem of measuring the relative goodness of fit of the two models. We propose two new statistical tests which are nonparametric, computationally efficient (runtime complexity is linear in the sample size), and interpretable. As a unique advantage, our tests can produce a set of examples (informative features) indicating the regions in the data domain where one model fits significantly better than the other. In a real-world problem of comparing GAN models, the test power of our new test matches that of the state-of-the-art test of relative goodness of fit, while being one order of magnitude faster."}}
{"id": "r14klh-dbr", "cdate": 1483228800000, "mdate": null, "content": {"title": "An Adaptive Test of Independence with Analytic Kernel Embeddings", "abstract": "A new computationally efficient dependence measure, and an adaptive statistical test of independence, are proposed. The dependence measure is the difference between analytic embeddings of the joint..."}}
