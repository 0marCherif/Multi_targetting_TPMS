{"id": "yDv_2iBFEj", "cdate": 1672531200000, "mdate": 1681491669985, "content": {"title": "Raising the Cost of Malicious AI-Powered Image Editing", "abstract": ""}}
{"id": "Din42zykEHM", "cdate": 1672531200000, "mdate": 1681491670115, "content": {"title": "TRAK: Attributing Model Behavior at Scale", "abstract": ""}}
{"id": "74UfM1WeBx", "cdate": 1664928787637, "mdate": null, "content": {"title": "A Unified Framework for Comparing Learning Algorithms", "abstract": "Understanding model biases is crucial to understanding how models will perform out-of-distribution (OOD). These biases often stem from particular design choices (e.g., architecture or data augmentation). We propose a framework for (learning) algorithm comparisons, wherein the goal is to find similarities and differences between models trained with two different learning algorithms. We begin by formalizing the goal of algorithm comparison as finding distinguishing feature transformations, input transformations that change the predictions of models trained with one learning algorithm but not the other. We then present a two-stage method for algorithm comparisons based on comparing how models use the training data, leveraging the recently proposed datamodel representations [IPE+22]. We demonstrate our framework through a case study comparing classifiers trained on the Waterbirds [SKH+20] dataset with/without ImageNet pre-training.\n"}}
{"id": "Ew9gIwAQ7wr", "cdate": 1663850120326, "mdate": null, "content": {"title": "FFCV: Accelerating Training by Removing Data Bottlenecks", "abstract": "We present FFCV, a library for easy, fast, resource-efficient training of machine learning models. FFCV speeds up model training by eliminating (often subtle) data bottlenecks from the training process. In particular, we combine techniques such as an efficient file storage format, caching, data pre-loading, asynchronous data transfer, and just-in-time compilation to (a) make data loading and transfer significantly more efficient, ensuring that GPUs can reach full utilization; and (b) offload as much data processing as possible to the CPU asynchronously, freeing GPU up capacity for training. Using FFCV, we train ResNet-18 and ResNet-50 on the ImageNet dataset with a state-of-the-art tradeoff between accuracy and training time. For example, across the range of ResNet-50 models we test, we obtain the same accuracy as the best baselines in half the time. We demonstrate FFCV's performance, ease-of-use, extensibility, and ability to adapt to resource constraints through several case studies."}}
{"id": "4NT3umNU3D0", "cdate": 1663850116789, "mdate": null, "content": {"title": "Backdoor or Feature? A New Perspective on Data Poisoning", "abstract": "In a backdoor attack, an adversary adds maliciously constructed (\"backdoor\") examples into a training set to make the resulting model\nvulnerable to manipulation. Defending against such attacks---that is, finding and removing the backdoor examples---typically involves viewing these examples as outliers and using techniques from robust statistics to detect and remove them.\n\nIn this work, we present a new perspective on backdoor attacks. We argue that without structural information on the training data distribution, backdoor attacks are indistinguishable from naturally-occuring features in the data (and thus impossible to ``detect'' in a general sense). To circumvent this impossibility, we assume that a backdoor attack corresponds to the strongest feature in the training data. Under this assumption---which we make formal---we develop a new framework for detecting backdoor attacks. Our framework naturally gives rise to a corresponding algorithm whose efficacy we show both theoretically and experimentally."}}
{"id": "dYQnWPqCCAs", "cdate": 1663850028258, "mdate": null, "content": {"title": "A Unified Framework for Comparing Learning Algorithms", "abstract": "We propose a framework for {\\em (learning) algorithm comparisons}, wherein the goal is to find similarities and differences between models trained with two different learning algorithms. We begin by formalizing the goal of algorithm comparison as finding {\\em distinguishing feature transformations}, input transformations that change the predictions of models trained with one learning algorithm but not the other. We then present a two-stage method for algorithm comparisons based on comparing how models use the training data, leveraging the recently proposed datamodel representations [Ilyas et al., 2022]. We demonstrate our framework through three case studies that compare models trained with/without standard data augmentation, with/without pre-training, and with different optimizer hyperparameters. "}}
{"id": "r7bFgAGRkpL", "cdate": 1663850023188, "mdate": null, "content": {"title": "When does Bias Transfer in Transfer Learning?", "abstract": "Using transfer learning to adapt a pre-trained \"source model\" to a downstream \"target task\" can dramatically increase performance with seemingly no downside. In this work, we demonstrate that there can exist a downside after all: bias transfer, or the tendency for biases of the source model to persist even after adapting the model to the target class. Through a combination of synthetic and natural experiments, we show that bias transfer both (a) arises in realistic settings (such as when pre-training on ImageNet or other standard datasets) and (b) can occur even when the target dataset is explicitly de-biased. As transfer-learned models are increasingly deployed in the real world, our work highlights the importance of understanding the limitations of pre-trained source models."}}
{"id": "dRgHxaOJsiV", "cdate": 1652737393234, "mdate": null, "content": {"title": "3DB: A Framework for Debugging Computer Vision Models", "abstract": "We introduce 3DB: an extendable, unified framework for testing and debugging vision models using photorealistic simulation.  We demonstrate, through a wide range of use cases, that 3DB allows users to discover vulnerabilities in computer vision systems and gain insights into how models make decisions. 3DB captures and generalizes many robustness analyses from prior work, and enables one to study their interplay. Finally, we find that the insights generated by the system transfer to the physical world. 3DB will be released as a library alongside a set of examples and documentation. We attach 3DB to the submission."}}
{"id": "cpcY6KWlZE", "cdate": 1640995200000, "mdate": 1668797182803, "content": {"title": "When does Bias Transfer in Transfer Learning?", "abstract": "Using transfer learning to adapt a pre-trained \"source model\" to a downstream \"target task\" can dramatically increase performance with seemingly no downside. In this work, we demonstrate that there can exist a downside after all: bias transfer, or the tendency for biases of the source model to persist even after adapting the model to the target class. Through a combination of synthetic and natural experiments, we show that bias transfer both (a) arises in realistic settings (such as when pre-training on ImageNet or other standard datasets) and (b) can occur even when the target dataset is explicitly de-biased. As transfer-learned models are increasingly deployed in the real world, our work highlights the importance of understanding the limitations of pre-trained source models. Code is available at https://github.com/MadryLab/bias-transfer"}}
{"id": "aaZigYuRDl", "cdate": 1640995200000, "mdate": 1681491669433, "content": {"title": "Estimation of Standard Auction Models", "abstract": ""}}
