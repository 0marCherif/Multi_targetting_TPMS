{"id": "c-Zrtovs3b", "cdate": 1684345354271, "mdate": 1684345354271, "content": {"title": "Mimic the raw domain: Accelerating action recognition in the compressed domain", "abstract": "Video understanding usually requires expensive computation that prohibits its deployment, yet videos contain significant spatiotemporal redundancy that can be exploited.\nIn particular, operating directly on the motion vectors and\nresiduals in the compressed video domain can significantly\naccelerate the compute, by not using the raw videos which\ndemand colossal storage capacity. Existing methods approach this task as a multiple modalities problem. In this\npaper we are approaching the task in a completely different\nway; we are looking at the data from the compressed stream\nas a one unit clip and propose that the residual frames can\nreplace the original RGB frames from the raw domain. Furthermore, we are using teacher-student method to aid the\nnetwork in the compressed domain to mimic the teacher network in the raw domain. We show experiments on three\nleading datasets (HMDB51, UCF1, and Kinetics) that approach state-of-the-art accuracy on raw video data by using\ncompressed data. Our model MFCD-Net outperforms prior\nmethods in the compressed domain and more importantly,\nour model has 11X fewer parameters and 3X fewer Flops,\ndramatically improving the efficiency of video recognition\ninference. This approach enables applying neural networks\nexclusively in the compressed domain without compromising accuracy while accelerating performance"}}
{"id": "-6vS_4Kfz0", "cdate": 1601308410486, "mdate": null, "content": {"title": "Optimizing Memory Placement using Evolutionary Graph Reinforcement Learning", "abstract": "For deep neural network accelerators, memory movement is both energetically expensive and can bound computation. Therefore, optimal mapping of tensors to memory hierarchies is critical to performance. The growing complexity of neural networks calls for automated memory mapping instead of manual heuristic approaches; yet the search space of neural network computational graphs have previously been prohibitively large. We introduce Evolutionary Graph Reinforcement Learning (EGRL), a method designed for large search spaces, that combines graph neural networks, reinforcement learning, and evolutionary search. A set of fast, stateless policies guide the evolutionary search to improve its sample-efficiency. We train and validate our approach directly on the Intel NNP-I chip for inference. EGRL outperforms policy-gradient, evolutionary search and dynamic programming baselines on BERT, ResNet-101 and ResNet-50. We additionally achieve 28-78% speed-up compared to the native NNP-I compiler on all three workloads.  "}}
{"id": "V8jrrnwGbuc", "cdate": 1601308408220, "mdate": null, "content": {"title": "On the geometry of generalization and memorization in deep neural networks", "abstract": "Understanding how large neural networks avoid memorizing training data is key to explaining their high generalization performance. To examine the structure of when and where memorization occurs in a deep network, we use a recently developed replica-based mean field theoretic geometric analysis method. We find that all layers preferentially learn from examples which share features, and link this behavior to generalization performance. Memorization predominately occurs in the deeper layers, due to decreasing object manifolds\u2019 radius and dimension, whereas early layers are minimally affected. This predicts that generalization can be restored by reverting the final few layer weights to earlier epochs before significant memorization occurred, which is confirmed by the experiments. Additionally, by studying generalization under different model sizes, we reveal the connection between the double descent phenomenon and the underlying model geometry. Finally, analytical analysis shows that networks avoid memorization early in training because close to initialization, the gradient contribution from permuted examples are small. These findings provide quantitative evidence for the structure of memorization across layers of a deep neural network, the drivers for such structure, and its connection to manifold geometric properties.\n"}}
{"id": "mhEd8uOyNTI", "cdate": 1601308282394, "mdate": null, "content": {"title": "Representational correlates of hierarchical phrase structure in deep language models", "abstract": "While contextual representations from Transformer-based architectures have set a new standard for many NLP tasks, there is not yet a complete accounting of their inner workings. In particular, it is not entirely clear what aspects of sentence-level syntax are captured by these representations, nor how (if at all) they are built along the stacked layers of the network. In this paper, we aim to address such questions with a general class of input perturbation-based analyses of representations from Transformer networks pretrained on self-supervised objectives. Importing from computational and cognitive neuroscience the notion of representational invariance, we perform a series of probes designed to test the sensitivity of Transformer representations to several kinds of structure in sentences. Each probe involves swapping words in a sentence and comparing the representations from perturbed sentences against the original. We experiment with three different perturbations: (1) random permutations of n-grams of varying width, to test the scale at which a representation is sensitive to word position; (2) swapping of two spans which do or do not form a syntactic phrase, to test sensitivity to global phrase structure; and (3) swapping of two adjacent words which do or do not break apart a syntactic phrase, to test sensitivity to local phrase structure. We also connect our probe results to the Transformer architecture by relating the attention mechanism to syntactic distance between two words. Results from the three probes collectively suggest that Transformers build sensitivity to larger parts of the sentence along their layers, and that hierarchical phrase structure plays a role in this process. In particular, sensitivity to local phrase structure increases along deeper layers. Based on our analysis of attention, we show that this is at least partly explained by generally larger attention weights between syntactically distant words."}}
{"id": "Bkxe2AVtPS", "cdate": 1569439399817, "mdate": null, "content": {"title": "Shifted and Squeezed 8-bit Floating Point format for Low-Precision Training of Deep Neural Networks", "abstract": "Training with larger number of parameters while keeping fast iterations is an increasingly\nadopted strategy and trend for developing better performing Deep Neural\nNetwork (DNN) models. This necessitates increased memory footprint and\ncomputational requirements for training. Here we introduce a novel methodology\nfor training deep neural networks using 8-bit floating point (FP8) numbers.\nReduced bit precision allows for a larger effective memory and increased computational\nspeed. We name this method Shifted and Squeezed FP8 (S2FP8). We\nshow that, unlike previous 8-bit precision training methods, the proposed method\nworks out of the box for representative models: ResNet50, Transformer and NCF.\nThe method can maintain model accuracy without requiring fine-tuning loss scaling\nparameters or keeping certain layers in single precision. We introduce two\nlearnable statistics of the DNN tensors - shifted and squeezed factors that are used\nto optimally adjust the range of the tensors in 8-bits, thus minimizing the loss in\ninformation due to quantization."}}
{"id": "HJlaikhc6N", "cdate": 1559048101193, "mdate": null, "content": {"title": "Probing emergent geometry in speech models via replica theory", "abstract": "The success of deep neural networks in visual tasks have motivated recent theoretical and empirical work to understand how these networks operate. Meanwhile, deep neural networks have also achieved impressive performance in audio processing applications, both as sub-components of larger systems or as complete end-to-end systems. In this work, we employ a recently developed statistical mechanical theory that connects geometric properties of network representations with class separability to probe how information is untangled within neural networks trained to recognize speech. We find that speech recognition models carry out significant layerwise and temporal untangling of words by efficiently extracting task-relevant features. This untangling results from a decrease in the per-class radius and dimension, and a reduction in the correlation between class centers."}}
{"id": "r1eqsNXgdV", "cdate": 1553114274389, "mdate": null, "content": {"title": "Heuristics for Image Generation from Scene Graphs", "abstract": "Generating realistic images from scene graphs requires neural networks to be able to reason about object relationships and compositionality. Learning a sufficiently rich representation to facilitate this reasoning is challenging due to dataset limitations. Synthetic scene graphs from COCO only have basic geometric relationships, and Visual Genome scene graphs are replete with missing relations or mislabeled nodes. Existing scene graph to image models have two stages: (1) a scene composition stage, and an (2) image generation stage. In this paper, we propose two methods to improve the intermediate representation of these stages. First, we use visual heuristics to augment relationships between pairs of objects. Second, we introduce a graph convolution-based network to generate a scene graph context representation that enriches the image generation. These contributions significantly improve the scene composition (relation score of 59.8% compared to 51.2%) and image generation (74% versus 64% in mean relation opinion score). Introspection shows that these heuristics are particularly effective in learning differentiated representations for scenes with multiple instances of the same object category. Obtaining accurate and complete scene graph annotations is costly, and our use of heuristics and prior structure to enhance intermediate representations allows our model to compensate for limited or incomplete data."}}
{"id": "H7R-3NmxuaH", "cdate": 1546300800000, "mdate": null, "content": {"title": "Compact Scene Graphs for Layout Composition and Patch Retrieval.", "abstract": "Structured representations such as scene graphs serve as an efficient and compact representation that can be used for downstream rendering or retrieval tasks. However, existing efforts to generate realistic images from scene graphs perform poorly on scene composition for cluttered or complex scenes. We propose two contributions to improve the scene composition. First, we enhance the scene graph representation with heuristic-based relations, which add minimal storage overhead. Second, we use extreme points representation to supervise the learning of the scene composition network. These methods achieve significantly higher performance over existing work (69.0% vs 51.2% in relation score metric). We additionally demonstrate how scene graphs can be used to retrieve pose-constrained image patches that are semantically similar to the source query. Improving structured scene graph representations for rendering or retrieval are an important step towards realistic image generation."}}
{"id": "BkZSqo-_Wr", "cdate": 1546300800000, "mdate": null, "content": {"title": "DoubleSqueeze: Parallel Stochastic Gradient Descent with Double-pass Error-Compensated Compression", "abstract": "A standard approach in large scale machine learning is distributed stochastic gradient training, which requires the computation of aggregated stochastic gradients over multiple nodes on a network. ..."}}
{"id": "BQwrX7eOaH", "cdate": 1546300800000, "mdate": null, "content": {"title": "Channel Attention Networks.", "abstract": "Multi-band images beyond RGB are becoming popular in both commercial applications and research datasets, yet existing deep learning models were designed for academic RGB datasets. In this talk, we propose Channel Attention Networks (CAN), a deep learning model that uses soft attention on individual channels. We jointly train this model end-to-end on Spacenet, a challenging multi-spectral semantic segmentation dataset. In a comparative study, CAN outperforms previous models. We also demonstrate that CAN is significantly more robust to noise in individual bands than the other models, because the attention network allocates attention away from the noisy channels. Our proposed method marks the first step in designing deep learning algorithms specifically for multi-spectral imagery."}}
