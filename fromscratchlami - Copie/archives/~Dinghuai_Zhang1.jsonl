{"id": "U_MhWQ7vECt", "cdate": 1676827067364, "mdate": null, "content": {"title": "Stochastic Generative Flow Networks", "abstract": "Generative Flow Networks (or GFlowNets for short) are a family of probabilistic agents that learn to sample complex combinatorial structures through the lens of ``inference as control''. They have shown great potential in generating high-quality and diverse candidates from a given energy landscape. However, existing GFlowNets can be applied only to deterministic environments, and fail in more general tasks with stochastic dynamics, which can limit their applicability. To overcome this challenge, this paper introduces Stochastic GFlowNets, a new algorithm that extends GFlowNets to stochastic environments. By decomposing state transitions into two steps, Stochastic GFlowNets isolate environmental stochasticity and learn a dynamics model to capture it. Extensive experimental results demonstrate that Stochastic GFlowNets offer significant advantages over standard GFlowNets as well as MCMC- and RL-based approaches, on a variety of standard benchmarks with stochastic dynamics."}}
{"id": "_aff9_iVY-", "cdate": 1672531200000, "mdate": 1681650306251, "content": {"title": "Better Training of GFlowNets with Local Credit and Incomplete Trajectories", "abstract": ""}}
{"id": "XqBIzC0usYM", "cdate": 1672531200000, "mdate": 1681650306064, "content": {"title": "Stochastic Generative Flow Networks", "abstract": ""}}
{"id": "WExGHeNRn2G", "cdate": 1672531200000, "mdate": 1681700515898, "content": {"title": "A theory of continuous generative flow networks", "abstract": "Generative flow networks (GFlowNets) are amortized variational inference algorithms that are trained to sample from unnormalized target distributions over compositional objects. A key limitation of GFlowNets until this time has been that they are restricted to discrete spaces. We present a theory for generalized GFlowNets, which encompasses both existing discrete GFlowNets and ones with continuous or hybrid state spaces, and perform experiments with two goals in mind. First, we illustrate critical points of the theory and the importance of various assumptions. Second, we empirically demonstrate how observations about discrete GFlowNets transfer to the continuous case and show strong results compared to non-GFlowNet baselines on several previously studied tasks. This work greatly widens the perspectives for the application of GFlowNets in probabilistic inference and various modeling settings."}}
{"id": "FV2UiY5w6Ca", "cdate": 1672531200000, "mdate": 1681650305661, "content": {"title": "Distributional GFlowNets with Quantile Flows", "abstract": ""}}
{"id": "RgzRdzFdAN", "cdate": 1665069640477, "mdate": null, "content": {"title": "Cooperation or Competition: Avoiding Player Domination for Multi-target Robustness by Adaptive Budgets", "abstract": "Despite incredible advances, deep learning has been shown to be susceptible to adversarial attacks. Numerous approaches were proposed to train robust networks both empirically and certifiably. However, most of them defend against only a single type of attack, while recent work steps forward at defending against multiple attacks. In this paper, to understand multi-target robustness, we view this problem as a bargaining game in which different players (adversaries) negotiate to reach an agreement on a joint direction of parameter updating. We identify a phenomenon named \\emph{player domination} in the bargaining game, and show that with this phenomenon, some of the existing max-based approaches such as MAX and MSD do not converge. Based on our theoretical results, we design a novel framework that adjusts the budgets of different adversaries to avoid player domination. Experiments on two benchmarks show that employing the proposed framework to the existing approaches significantly advances multi-target robustness."}}
{"id": "y2lE3X4LUJK", "cdate": 1664639492957, "mdate": 1664639492957, "content": {"title": "Biological Sequence Design with GFlowNets", "abstract": "Design of de novo biological sequences with desired properties, like protein and DNA sequences, often involves an active loop with several rounds of molecule ideation and expensive wet-lab evaluations. These experiments can consist of multiple stages, with increasing levels of precision and cost of evaluation, where candidates are filtered. This makes the diversity of proposed candidates a key consideration in the ideation phase. In this work, we propose an active learning algorithm leveraging epistemic uncertainty estimation and the recently proposed GFlowNets as a generator of diverse candidate solutions, with the objective to obtain a diverse batch of useful (as defined by some utility function, for example, the predicted anti-microbial activity of a peptide) and informative candidates after each round. We also propose a scheme to incorporate existing labeled datasets of candidates, in addition to a reward function, to speed up learning in GFlowNets. We present empirical results on several biological sequence design tasks, and we find that our method generates more diverse and novel batches with high scoring candidates compared to existing approaches."}}
{"id": "-AbmbsV1pp3", "cdate": 1664637549998, "mdate": 1664637549998, "content": {"title": "Unifying Generative Models with GFlowNets", "abstract": "There are many frameworks for deep generative modeling, each often presented with their own specific training algorithms and inference methods. We present a short note on the connections between existing deep generative models and the GFlowNet framework, shedding light on their overlapping traits and providing a unifying viewpoint through the lens of learning with Markovian trajectories. This provides a means for unifying training and inference algorithms, and provides a route to construct an agglomeration of generative models."}}
{"id": "5ly-lDmUtHK", "cdate": 1664255719013, "mdate": 1664255719013, "content": {"title": "Generative Flow Networks for Discrete Probabilistic Modeling", "abstract": "We present energy-based generative flow networks (EB-GFN), a novel probabilistic modeling algorithm for high-dimensional discrete data.\nBuilding upon the theory of generative flow networks (GFlowNets; Bengio et al., 2021b), we model the generation process by a stochastic data construction policy and thus amortize expensive MCMC exploration into a fixed number of actions sampled from a GFlowNet. We\nshow how GFlowNets can approximately perform large-block Gibbs sampling to mix between modes. We propose a framework to jointly train a GFlowNet with an energy function, so that the GFlowNet learns to sample from the energy distribution, while the energy learns with an approximate MLE objective with negative samples from the GFlowNet. We demonstrate EB-GFN\u2019s effectiveness on various probabilistic modeling tasks. Code is publicly available at github.com/zdhNarsil/EB-GFN."}}
{"id": "Lmff9URfo5", "cdate": 1663850434198, "mdate": null, "content": {"title": "Cooperation or Competition: Avoiding Player Domination for Multi-target Robustness by Adaptive Budgets", "abstract": "Despite incredible advances, deep learning has been shown to be susceptible to adversarial attacks. Numerous approaches were proposed to train robust networks both empirically and certifiably. However, most of them defend against only a single type of attack, while recent work steps forward at defending against multiple attacks. In this paper, to understand multi-target robustness, we view this problem as a bargaining game in which different players (adversaries) negotiate to reach an agreement on a joint direction of parameter updating. We identify a phenomenon named \\emph{player domination} in the bargaining game, and show that with this phenomenon, some of the existing max-based approaches such as MAX and MSD do not converge. Based on our theoretical results, we design a novel framework that adjusts the budgets of different adversaries to avoid player domination. Experiments on two benchmarks show that employing the proposed framework to the existing approaches significantly advances multi-target robustness."}}
