{"id": "BEpJFTH50iT", "cdate": 1663850119861, "mdate": null, "content": {"title": "Searching optimal adjustment features for treatment effect estimation", "abstract": "Most efforts devoted to causal inference focus on controlling the adjustment features to further alleviate the confounding effect. In realistic applications, the collected covariates often contain variables correlating to only one of the treatment (e.g., instrumental variables) and the outcome (e.g., precision variables). Due to the absence of prior knowledge, the brute-force approach for the practitioner is to include every covariate for adjustment. However, previous literature shows that adjusting the former covariates (treatment-only) hurts the treatment effect estimation, while adjusting the latter covariates (outcome-only) brings benefits. Consequently, it is meaningful to find an optimal adjustment set rather than the brute-force approach for more efficient treatment effect estimation. To this end, we establish a variance metric which is computationally tractable to measure the optimality of the adjustment set. From the non-parametric viewpoint, we theoretically show that our metric is minimized if and only if the adjustment features contain the confounders and the outcome-only variables. As optimizing the proposed variance metric is a combinational optimization problem, we incorporate the Reinforcement Learning (RL) to search the corresponding optimal adjustment set. More specifically, we adopt the encoder-decoder model as the actor to generate the binary feature mask on the original covariates, which serves as the differentiable policy. Meanwhile, the proposed variance metric serves as the reward to guide the policy update. Empirical results on synthetic and real-world datasets demonstrate that ~(a) our method successfully searches the optimal adjustment sets and (b) the searched adjustment features achieve more precise treatment effect estimation."}}
{"id": "uJzSlJruEjk", "cdate": 1663849950386, "mdate": null, "content": {"title": "Novel Class Discovery under Unreliable Sampling", "abstract": "When sampling data of specific classes (i.e., known classes) for a scientific task, collectors may encounter unknown classes (i.e., novel classes). Since these novel classes might be valuable for future research, collectors will also sample them and assign them to several clusters with the help of known-class data. This assigning process is also known as novel class discovery (NCD). However, sampling errors are common in practice and may make the NCD process unreliable. To tackle this problem, this paper introduces a new and more realistic setting, where collectors may misidentify known classes and even confuse known classes with novel classes - we name it NCD under unreliable sampling (NUSA). We find that NUSA will empirically degrade existing NCD methods if taking no care of sampling errors. To handle NUSA, we propose an effective solution, named hidden-prototype-based discovery network (HPDN). HPDN first trains a deep network to fully fit the wrongly sampled data, then applies the relatively clean hidden representations yielded by this network into a novel mini-batch K-means algorithm, which further prevents them overfitting to residual errors by detaching noisy supervision timely. Experiments demonstrate that, under NUSA, HPDN significantly outperforms competitive baselines (e.g., 6% more than the best baseline on CIFAR-10) and keeps robust even encountering serious sampling errors."}}
{"id": "vhPFTgH2Js", "cdate": 1640995200000, "mdate": 1668780945844, "content": {"title": "Climate, CO2, and Anthropogenic Drivers of Accelerated Vegetation Greening in the Haihe River Basin", "abstract": "Vegetation regulates the exchange of terrestrial carbon and water fluxes and connects the biosphere, hydrosphere, and atmosphere. Over the last four decades, vegetation greening has been observed worldwide using satellite technology. China has also experienced a notably widespread greening trend. However, the responsiveness of vegetation dynamics to elevated CO2 concentration, climate change, and human activities remains unclear. In this study, we attempted to explore the impact of natural (precipitation, air temperature), biogeochemical (CO2), and anthropogenic drivers (nighttime light, afforestation area) on changes in vegetation greenness in the Haihe River Basin (HRB) during 2002\u20132018 at the county-level. We further determined the major factors affecting the variation in satellite-derived normalized difference vegetation index (NDVI) from moderate resolution imaging spectroradiometer (MODIS) for each county. The results indicated that over 85% of the counties had a significantly increased NDVI trend, and the average linear trend of annual NDVI across the study region was 0.0037 per year. The largest contributor to the NDVI trend was CO2 (mean contribution 45%), followed by human activities (mean contribution of 27%). Additionally, afforestation was a pronounced driving force for NDVI changes in mountainous areas, resulting from ecosystem restoration efforts. Our findings emphasize the crucial role of CO2 fertilization in vegetation cover change, while considering CO2 concentration, climate change, and human activities, and shed light on the significant influences of afforestation programs on water resources, especially in mountainous areas."}}
{"id": "tg3BMrWbuG", "cdate": 1640995200000, "mdate": 1668780945810, "content": {"title": "Meta Discovery: Learning to Discover Novel Classes given Very Limited Data", "abstract": "In novel class discovery (NCD), we are given labeled data from seen classes and unlabeled data from unseen classes, and we train clustering models for the unseen classes. However, the implicit assumptions behind NCD are still unclear. In this paper, we demystify assumptions behind NCD and find that high-level semantic features should be shared among the seen and unseen classes. Based on this finding, NCD is theoretically solvable under certain assumptions and can be naturally linked to meta-learning that has exactly the same assumption as NCD. Thus, we can empirically solve the NCD problem by meta-learning algorithms after slight modifications. This meta-learning-based methodology significantly reduces the amount of unlabeled data needed for training and makes it more practical, as demonstrated in experiments. The use of very limited data is also justified by the application scenario of NCD: since it is unnatural to label only seen-class data, NCD is sampling instead of labeling in causality. Therefore, unseen-class data should be collected on the way of collecting seen-class data, which is why they are novel and first need to be clustered."}}
{"id": "qr_CyhrvfFW", "cdate": 1640995200000, "mdate": 1668780945861, "content": {"title": "Safety Verification for Neural Networks Based on Set-boundary Analysis", "abstract": "Neural networks (NNs) are increasingly applied in safety-critical systems such as autonomous vehicles. However, they are fragile and are often ill-behaved. Consequently, their behaviors should undergo rigorous guarantees before deployment in practice. In this paper we propose a set-boundary reachability method to investigate the safety verification problem of NNs from a topological perspective. Given an NN with an input set and a safe set, the safety verification problem is to determine whether all outputs of the NN resulting from the input set fall within the safe set. In our method, the homeomorphism property of NNs is mainly exploited, which establishes a relationship mapping boundaries to boundaries. The exploitation of this property facilitates reachability computations via extracting subsets of the input set rather than the entire input set, thus controlling the wrapping effect in reachability analysis and facilitating the reduction of computation burdens for safety verification. The homeomorphism property exists in some widely used NNs such as invertible NNs. Notable representations are invertible residual networks (i-ResNets) and Neural ordinary differential equations (Neural ODEs). For these NNs, our set-boundary reachability method only needs to perform reachability analysis on the boundary of the input set. For NNs which do not feature this property with respect to the input set, we explore subsets of the input set for establishing the local homeomorphism property, and then abandon these subsets for reachability computations. Finally, some examples demonstrate the performance of the proposed method."}}
{"id": "o8u4Zf65nE", "cdate": 1640995200000, "mdate": 1668780945821, "content": {"title": "GANet: Goal Area Network for Motion Forecasting", "abstract": "Predicting the future motion of road participants is crucial for autonomous driving but is extremely challenging due to staggering motion uncertainty. Recently, most motion forecasting methods resort to the goal-based strategy, i.e., predicting endpoints of motion trajectories as conditions to regress the entire trajectories, so that the search space of solution can be reduced. However, accurate goal coordinates are hard to predict and evaluate. In addition, the point representation of the destination limits the utilization of a rich road context, leading to inaccurate prediction results in many cases. Goal area, i.e., the possible destination area, rather than goal coordinate, could provide a more soft constraint for searching potential trajectories by involving more tolerance and guidance. In view of this, we propose a new goal area-based framework, named Goal Area Network (GANet), for motion forecasting, which models goal areas rather than exact goal coordinates as preconditions for trajectory prediction, performing more robustly and accurately. Specifically, we propose a GoICrop (Goal Area of Interest) operator to effectively extract semantic lane features in goal areas and model actors' future interactions, which benefits a lot for future trajectory estimations. GANet ranks the 1st on the leaderboard of Argoverse Challenge among all public literature (till the paper submission), and its source codes will be released."}}
{"id": "gpT3DGcJaG", "cdate": 1640995200000, "mdate": 1668780945874, "content": {"title": "Placement Optimization for UAV-Enabled Wireless Networks with Multi-Hop Backhauls in Urban Environments", "abstract": "In surveillance or search scenarios, exploiting unmanned aerial vehicles (UAVs) as relays to provide wireless data access for task-oriented ground robots (GRs) with remote base station have emerged as a promising application. This paper considers a UAV-enabled wireless network, where communication links could be line-of-sight (LoS) and non-line-of-sight (NLoS) due to obstacles in urban environments. Existing works typically adopted the free-space path loss model or the statistical channel model, which either ignored the impact of obstacles or assumed uniformly distributed obstacles and therefore might fail in practical NLoS scenarios. In this paper, taking the information of randomly distributed obstacles in environments into consideration, we aim to optimize the placement for the UAV-enabled multi-hop network to transfer more data collected by GRs and minimize the time delay in data transmission while satisfying the required communication quality. By reconstructing this complex non-convex optimization problem into two subprob-lems and solving them alternatively, we propose the multi-hop UAVs placement (mUP) method to get the solution, which contains the air-to-ground network formation (ATG-NF) algorithm and the communication quality-aware UAV placement (CQA-UP) algorithm. Simulation results show that in four types of typical urban environments or with different numbers of UAVs, the proposed mUP method achieves substantial performance gains in terms of communication quality and task performance compared to other placement approaches based on statistical channel models. We further discuss the robustness of the mUP method towards terrain measurement error."}}
{"id": "LwF3mmmlPE2", "cdate": 1640995200000, "mdate": 1668780945791, "content": {"title": "Online Semisupervised Active Classification for Multiview PolSAR Data", "abstract": "Polarimetric synthetic aperture radar (PolSAR) data are sequentially acquired and have multiple views obtained from different feature extractors or multiple frequency bands. The fast and accurate classification of PolSAR data in dynamically changing environments is a critical and challenging task. Online learning can handle this task by learning a classifier incrementally from a stream of samples. In this article, we propose an online semisupervised active learning framework for multiview PolSAR data classification, called OSAM. First, a novel online active learning strategy is designed based on the relationships among multiple views and a randomized rule, which allows to only query the labels of some informative incoming samples. Then, in order to utilize both the incoming labeled and unlabeled samples to update the classifiers, a novel online semisupervised learning model is proposed based on co-regularized multiview learning and graph regularization. In addition, the proposed method can deal with the dynamic large-scale multifeature or multifrequency PolSAR data where not only the amount of data but also the number of classes gradually increases in the learning process. Moreover, the mistake bound of the proposed method is derived rigorously. Extensive experiments are conducted on real PolSAR data to evaluate the performance of our algorithm, and the results demonstrate the effectiveness of the proposed method."}}
{"id": "BB0fM1IF9_", "cdate": 1640995200000, "mdate": 1668780945843, "content": {"title": "Recent Advances for Quantum Neural Networks in Generative Learning", "abstract": "Quantum computers are next-generation devices that hold promise to perform calculations beyond the reach of classical computers. A leading method towards achieving this goal is through quantum machine learning, especially quantum generative learning. Due to the intrinsic probabilistic nature of quantum mechanics, it is reasonable to postulate that quantum generative learning models (QGLMs) may surpass their classical counterparts. As such, QGLMs are receiving growing attention from the quantum physics and computer science communities, where various QGLMs that can be efficiently implemented on near-term quantum machines with potential computational advantages are proposed. In this paper, we review the current progress of QGLMs from the perspective of machine learning. Particularly, we interpret these QGLMs, covering quantum circuit born machines, quantum generative adversarial networks, quantum Boltzmann machines, and quantum autoencoders, as the quantum extension of classical generative learning models. In this context, we explore their intrinsic relation and their fundamental differences. We further summarize the potential applications of QGLMs in both conventional machine learning tasks and quantum physics. Last, we discuss the challenges and further research directions for QGLMs."}}
{"id": "MEpKGLsY8f", "cdate": 1632875520831, "mdate": null, "content": {"title": "Meta Discovery: Learning to Discover Novel Classes given Very Limited Data", "abstract": "In novel class discovery (NCD), we are given labeled data from seen classes and unlabeled data from unseen classes, and we train clustering models for the unseen classes. However, the implicit assumptions behind NCD are still unclear. In this paper, we demystify assumptions behind NCD and find that high-level semantic features should be shared among the seen and unseen classes. Based on this finding, NCD is theoretically solvable under certain assumptions and can be naturally linked to meta-learning that has exactly the same assumption as NCD. Thus, we can empirically solve the NCD problem by meta-learning algorithms after slight modifications. This meta-learning-based methodology significantly reduces the amount of unlabeled data needed for training and makes it more practical, as demonstrated in experiments. The use of very limited data is also justified by the application scenario of NCD: since it is unnatural to label only seen-class data, NCD is sampling instead of labeling in causality. Therefore, unseen-class data should be collected on the way of collecting seen-class data, which is why they are novel and first need to be clustered."}}
