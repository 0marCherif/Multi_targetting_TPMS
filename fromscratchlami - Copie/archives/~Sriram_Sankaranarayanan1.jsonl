{"id": "X4228W0QpvN", "cdate": 1655376348961, "mdate": null, "content": {"title": "Safe Robot Learning in Assistive Devices through Neural Network Repair", "abstract": "Assistive robotic devices are a particularly promising field of application for neural networks (NN) due to the need for personalization and hard-to-model human-machine interaction dynamics. However, NN based estimators and controllers may produce potentially unsafe outputs over previously unseen data points. In this paper, we introduce an algorithm for updating NN control policies to satisfy a given set of formal safety constraints, while also optimizing the original loss function.  Given a set of mixed-integer linear constraints, we define the NN repair problem as a Mixed Integer Quadratic Program (MIQP). In extensive experiments, we demonstrate the efficacy of our repair method in generating safe policies for a lower-leg prosthesis."}}
{"id": "JErNvd_lKHr", "cdate": 1655376345953, "mdate": null, "content": {"title": "Verified Path Following Using Neural Control Lyapunov Functions", "abstract": "We present a framework that uses control Lyapunov functions (CLFs) to implement provably stable path-following controllers for autonomous mobile platforms. Our approach is based on learning a guaranteed CLF for path following by using recent approaches --- combining machine learning with automated theorem proving --- to train a neural network feedback law along with a CLF that guarantees stabilization for driving along low-curvature reference paths. We discuss how key properties of the CLF can be exploited to extend the range of  the curvatures for which the stability guarantees remain valid. We then demonstrate that our approach yields a controller that obeys theoretical guarantees in simulation, but also performs well in practice. We show our method is both a verified method of control and better than a common MPC implementation in computation time. Additionally, we implement the controller on-board on a $\\frac18$-scale autonomous vehicle testing platform and present results for various robust path following scenarios."}}
{"id": "yoBaCtx_a3", "cdate": 1652737806290, "mdate": null, "content": {"title": "An Algorithm for Learning Switched Linear Dynamics from Data", "abstract": "We present an algorithm for learning switched linear dynamical systems in discrete time from noisy observations of the system's full state or output. Switched linear systems use multiple linear dynamical modes to fit the data within some desired tolerance. They arise quite naturally in  applications to  robotics and cyber-physical systems.  Learning  switched systems  from  data is a NP-hard problem that is nearly identical  to the $k$-linear regression problem of fitting $k > 1$ linear models to the data.  A direct mixed-integer linear programming (MILP) approach  yields time  complexity that is  exponential in the number of data points. In this paper, we modify the problem formulation  to yield an algorithm that is linear in the size of the data while remaining exponential in the number of state variables and the desired number of modes. To do so, we combine classic ideas from the ellipsoidal method for solving convex optimization problems, and well-known oracle separation results in non-smooth optimization.  We demonstrate our approach on a set of microbenchmarks and a few interesting real-world problems. Our evaluation  suggests that the benefits of this algorithm can be made practical even against highly optimized off-the-shelf MILP solvers."}}
{"id": "LQtlOn64EK6Y", "cdate": 1601258688680, "mdate": null, "content": {"title": "Output Range Analysis for Deep Feedforward Neural Networks", "abstract": "Given a neural network (NN) and a set of possible inputs to the net-work described by polyhedral constraints, we aim to compute a safe over-approximation of the set of possible output values. This operation is a fundamental primitive enabling the formal analysis of neural networks that are extensively used in a variety of machine learning tasks such as perception and control of autonomous systems. Increasingly, they are deployed in high-assurance applications, leading to a compelling use case for formal verification approaches. In this paper, we present an efficient range estimation algorithm that iterates between an expensive global combinatorial search using mixed-integer linear programming problems,and a relatively inexpensive local optimization that repeatedly seeks a local op-timum of the function represented by the NN. We implement our approach and compare it with Reluplex, a recently proposed solver for deep neural networks.We demonstrate applications of our approach to computing flowpipes for neural network-based feedback controllers. We show that the use of local search in con-junction with mixed-integer linear programming solvers effectively reduces the combinatorial search over possible combinations of active neurons in the network by pruning away sub-optimal nodes"}}
