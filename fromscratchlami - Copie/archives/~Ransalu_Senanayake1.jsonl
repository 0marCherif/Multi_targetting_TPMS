{"id": "xc4cvqWrDR", "cdate": 1684179485547, "mdate": 1684179485547, "content": {"title": "How Do We Fail? Stress Testing Perception in Autonomous Vehicles", "abstract": "Autonomous vehicles (AVs) rely on environment perception and behavior prediction to reason about agents in their surroundings. These perception systems must be robust to adverse weather such as rain, fog, and snow. However, validation of these systems is challenging due to their complexity and dependence on observation histories. This paper presents a method for characterizing failures of LiDAR-based perception systems for AVs in adverse weather conditions. We develop a methodology based in reinforcement learning to find likely failures in object tracking and trajectory prediction due to sequences of disturbances. We apply disturbances using a physics-based data augmentation technique for simulating LiDAR point clouds in adverse weather conditions. Experiments performed across a wide range of driving scenarios from a real-world driving dataset show that our proposed approach finds high likelihood failures with smaller input disturbances compared to baselines while remaining computationally tractable. Identified failures can inform future development of robust perception systems for AVs."}}
{"id": "1iy7rdPCt_", "cdate": 1624022581615, "mdate": null, "content": {"title": "Out of Distribution Detection and Adversarial Attacks on Deep Neural Networks for Robust Medical Image Analysis", "abstract": "Deep learning models have become a popular choice for medical image analysis. However, the poor generalization performance of deep learning models limits them from being deployed in the real world as robustness is critical for medical applications. For instance, the state-of-the-art Convolutional Neural Networks (CNNs) fail to detect samples drawn statistically far away from the\ntraining distribution or adversarially. In this work, we experimentally evaluate the robustness of a Mahalanobis distance-based \nconfidence score, a simple yet effective method for detecting abnormal input samples, in classifying malaria parasitized cells and uninfected cells. Results indicated that the Mahalanobis confidence score detector exhibits improved performance and robustness of deep learning models, and achieves state-of-the-art performance on both out-of-distribution and adversarial samples. "}}
{"id": "rqjfa49ODLE", "cdate": 1621629820029, "mdate": null, "content": {"title": "Evidential Softmax for Sparse Multimodal Distributions in Deep Generative Models", "abstract": "Many applications of generative models rely on the marginalization of their high-dimensional output probability distributions. Normalization functions that yield sparse probability distributions can make exact marginalization more computationally tractable. However, sparse normalization functions usually require alternative loss functions for training since the log-likelihood is undefined for sparse probability distributions. Furthermore, many sparse normalization functions often collapse the multimodality of distributions. In this work, we present ev-softmax, a sparse normalization function that preserves the multimodality of probability distributions. We derive its properties, including its gradient in closed-form, and introduce a continuous family of approximations to ev-softmax that have full support and can be trained with probabilistic loss functions such as negative log-likelihood and Kullback-Leibler divergence. We evaluate our method on a variety of generative models, including variational autoencoders and auto-regressive architectures. Our method outperforms existing dense and sparse normalization techniques in distributional accuracy. We demonstrate that ev-softmax successfully reduces the dimensionality of probability distributions while maintaining multimodality."}}
{"id": "NXNogZhXB6e", "cdate": 1621024576443, "mdate": null, "content": {"title": "Out-of-Distribution Detection for Automotive Perception", "abstract": "Neural networks (NNs) are widely used for object recognition tasks in autonomous driving. However, NNs can fail on input data not well represented by the training dataset, known as out-of-distribution (OOD) data. A mechanism to detect OOD samples is important in safety-critical applications, such as automotive perception, in order to trigger a safe fallback mode. NNs often rely on softmax normalization for confidence estimation, which can lead to high confidences being assigned to OOD samples, thus hindering the detection of failures. This paper presents a simple but effective method for determining whether inputs are OOD. We propose an OOD detection approach that combines auxiliary training techniques with post hoc statistics. Unlike other approaches, our proposed\nmethod does not require OOD data during training, and it does not increase the computational cost during inference. The latter\nproperty is especially important in automotive applications with limited computational resources and real-time constraints. Our\nproposed method outperforms state-of-the-art methods on real world automotive datasets."}}
{"id": "IeHHV9FSbF", "cdate": 1621023645966, "mdate": null, "content": {"title": "Double-Prong ConvLSTM for Spatiotemporal Occupancy Prediction in Dynamic Environments", "abstract": "Predicting the future occupancy state of an environment is important to enable informed decisions for autonomous vehicles. Common challenges in occupancy prediction include vanishing dynamic objects and blurred predictions, especially for long prediction horizons. In this work, we propose a double-prong neural network architecture to predict the spatiotemporal evolution of the environment occupancy state. One prong is dedicated to predicting how the static environment will be observed by the moving ego vehicle. The other prong predicts how the dynamic objects in the environment will move. Experiments conducted on the real-world Waymo Open Dataset indicate that the fused output of the two prongs is capable of retaining dynamic objects and reducing blurriness in the predictions for longer time horizons than baseline models."}}
{"id": "tAKeDbW6_xp", "cdate": 1621023281556, "mdate": null, "content": {"title": "Evidential Sparsification of Multimodal Latent Spaces in Conditional Variational Autoencoders", "abstract": "Discrete latent spaces in variational autoencoders have been shown to effectively capture the data distribution for many real-world problems such as natural language understanding, human intent prediction, and visual scene representation. However, discrete latent spaces need to be sufficiently large to capture the complexities of real-world data, rendering downstream tasks computationally challenging. For instance, performing motion planning in a high-dimensional latent representation of the environment could be intractable. We consider the problem of sparsifying the discrete latent space of a trained conditional variational autoencoder, while preserving its learned multimodality. As a post hoc latent space reduction technique, we use evidential theory to identify the latent classes that receive direct evidence from a particular input condition and filter out those that do not. Experiments on diverse tasks, such as image generation and human behavior prediction, demonstrate the effectiveness of our proposed technique at reducing the discrete latent sample space size of a model while maintaining its learned multimodality."}}
{"id": "bklHGbpmcez", "cdate": 1594404503814, "mdate": null, "content": {"title": "Online Domain Adaptation for Occupancy Mapping", "abstract": "Creating  accurate  spatial  representations  that  take into  account  uncertainty  is  critical  for  autonomous  robots  to safely  navigate  in  unstructured  environments.  Although  recent LIDAR  based  mapping  techniques  can  produce  robust  occupancy  maps,  learning  the  parameters  of  such  models  demand considerable computational time, discouraging them from being used in real-time and large-scale applications such as autonomous driving.  Recognizing  the  fact  that  real-world  structures  exhibit similar  geometric  features  across  a  variety  of  urban  environments,  in  this  paper,  we  argue  that  it  is  redundant  to  learn all  geometry  dependent  parameters  from  scratch.  Instead,  we propose  a  theoretical  framework  building  upon  the  theory  of optimal  transport -fidelity  driving  simulators and  real-world  datasets,  we  demonstrate  how  parameters  of  2Dand 3D occupancy maps can be automatically adapted to accord with local spatial changes. We validate various domain adaptation paradigms  through  a  series  of  experiments,  ranging  from  inter-domain feature transfer to simulation-to-real-world feature trans-fer. Experiments verified the possibility of estimating parameters with a negligible computational and memory cost, enabling large-scale  probabilistic  mapping  in  urban  environments."}}
{"id": "BJgnty2NYr", "cdate": 1571237763635, "mdate": null, "content": {"title": "Optimal Transport for Distribution Adaptation in Bayesian Hilbert Maps", "abstract": "Parameters are one of the most critical components of machine learning models. As datasets and learning domains change, it is often necessary and time-consuming to re-learn entire models. Rather than re-learning the parameters from scratch, replacing learning with optimization, we propose a framework building upon the theory of \\emph{optimal transport} to adapt model parameters by discovering correspondences between models and data, significantly amortizing the training cost. We demonstrate our idea on the challenging problem of creating probabilistic spatial representations for autonomous robots. Although recent mapping techniques have facilitated robust occupancy mapping, learning all spatially-diverse parameters in such approximate Bayesian models demand considerable computational time, discouraging them to be used in real-world robotic mapping. Considering the fact that the geometric features a robot would observe with its sensors are similar across various environments, in this paper, we demonstrate how to re-use parameters and hyperparameters learned in different domains. This adaptation is computationally more efficient than variational inference and Monte Carlo techniques. A series of experiments conducted on realistic settings verified the possibility of transferring thousands of such parameters with a negligible time and memory cost, enabling large-scale mapping in urban environments."}}
{"id": "SkZGRTxuWH", "cdate": 1514764800000, "mdate": null, "content": {"title": "Building Continuous Occupancy Maps With Moving Robots", "abstract": "Mapping the occupancy level of an environment is important for a robot to navigate in unknown and unstructured environments. To this end, continuous occupancy mapping techniques which express the probability of a location as a function are used. In this work, we provide a theoretical analysis to compare and contrast the two major branches of Bayesian continuous occupancy mapping techniques---Gaussian process occupancy maps and Bayesian Hilbert maps---considering the fact that both utilize kernel functions to operate in a rich high-dimensional implicit feature space and use variational inference to learn parameters. Then, we extend the recent Bayesian Hilbert maps framework which is so far only used for stationary robots, to map large environments with moving robots. Finally, we propose convolution of kernels as a powerful tool to improve different aspects of continuous occupancy mapping. Our claims are also experimentally validated with both simulated and real-world datasets."}}
{"id": "H1gwPOLAW", "cdate": 1509488472930, "mdate": null, "content": {"title": "Deep occupancy maps: a continuous mapping technique for dynamic environments", "abstract": "Learning a model of an environment that is correctly able to distinguish occupied and unoccupied areas is important for maneuvering robots in unstructured environments. A common technique to tackle such problems is to train a classifier with hand-crafted features that encode occupancy information. However, finding good features quickly becomes computationally prohibitive and impractical for complex and large environments. In this paper, we propose a ``fully'' convolutional neural network which can build global continuous occupancy maps by learning from raw local unorganized point cloud data, conveniently captured using a range sensor such as LIDAR. We propose a novel way of, 1) transforming data into a grid representation, and 2) perform convolution on robot's position rather than on occupancy levels. With this formulation, the map can produce both static and long-term maps in large environments without altering the model. Since the model is a function of locations, it is possible to query the occupancy probability at any position in the environment. Experiments indicate both computationally-efficient and accurate results over other continuous occupancy mapping techniques that require manual feature extraction. "}}
