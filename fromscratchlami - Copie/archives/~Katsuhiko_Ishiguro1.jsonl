{"id": "V6WHleb2nV", "cdate": 1601308071949, "mdate": null, "content": {"title": "Data Transfer Approaches to Improve Seq-to-Seq Retrosynthesis", "abstract": "Retrosynthesis is a problem to infer reactant compounds to synthesize a given\nproduct compound through chemical reactions. Recent studies on retrosynthesis\nfocus on proposing more sophisticated prediction models, but the dataset to feed\nthe models also plays an essential role in achieving the best generalizing models.\nGenerally, a dataset that is best suited for a specific task tends to be small. In\nsuch a case, it is the standard solution to transfer knowledge from a large or\nclean dataset in the same domain. In this paper, we conduct a systematic and\nintensive examination of data transfer approaches on end-to-end generative models,\nin application to retrosynthesis. Experimental results show that typical data transfer\nmethods can improve test prediction scores of an off-the-shelf Transformer baseline\nmodel. Especially, the pre-training plus fine-tuning approach boosts the accuracy\nscores of the baseline, achieving the new state-of-the-art. In addition, we conduct a\nmanual inspection for the erroneous prediction results. The inspection shows that\nthe pre-training plus fine-tuning models can generate chemically appropriate or\nsensible proposals in almost all cases."}}
{"id": "_jQi35AXan5", "cdate": 1577836800000, "mdate": null, "content": {"title": "Learning Structured Latent Factors from Dependent Data: A Generative Model Framework from Information-Theoretic Perspective", "abstract": "Learning controllable and generalizable representation of multivariate data with desired structural properties remains a fundamental problem in machine learning. In this paper, we present a novel framework for learning generative models with various underlying structures in the latent space. We represent the inductive bias in the form of mask variables to model the dependency structure in the graphical model and extend the theory of multivariate information bottleneck to enforce it. Our model provides a principled approach to learn a set of semantically meaningful latent factors that reflect various types of desired structures like capturing correlation or encoding invariance, while also offering the flexibility to automatically estimate the dependency structure from data. We show that our framework unifies many existing generative models and can be applied to a variety of tasks including multi-modal data modeling, algorithmic fairness, and invariant risk minimization."}}
{"id": "Y8LsNmKyC0", "cdate": 1577836800000, "mdate": null, "content": {"title": "Weisfeiler-Lehman Embedding for Molecular Graph Neural Networks", "abstract": "A graph neural network (GNN) is a good choice for predicting the chemical properties of molecules. Compared with other deep networks, however, the current performance of a GNN is limited owing to the \"curse of depth.\" Inspired by long-established feature engineering in the field of chemistry, we expanded an atom representation using Weisfeiler-Lehman (WL) embedding, which is designed to capture local atomic patterns dominating the chemical properties of a molecule. In terms of representability, we show WL embedding can replace the first two layers of ReLU GNN -- a normal embedding and a hidden GNN layer -- with a smaller weight norm. We then demonstrate that WL embedding consistently improves the empirical performance over multiple GNN architectures and several molecular graph datasets."}}
{"id": "Vd0ljd33OQ7", "cdate": 1577836800000, "mdate": null, "content": {"title": "Learning Structured Latent Factors from Dependent Data:A Generative Model Framework from Information-Theoretic Perspective", "abstract": "Learning controllable and generalizable representation of multivariate data with desired structural properties remains a fundamental problem in machine learning. In this paper, we present a novel f..."}}
{"id": "ryxQ6T4YwB", "cdate": 1569439162864, "mdate": null, "content": {"title": "GraphNVP: an Invertible Flow-based Model for Generating Molecular Graphs", "abstract": "We propose GraphNVP, an invertible flow-based molecular graph generation model. Existing flow-based models only handle node attributes of a graph with invertible maps. In contrast, our model is the first invertible model for the whole graph components: both of dequantized node attributes and adjacency tensor are converted into latent vectors through two novel invertible flows. This decomposition yields the exact likelihood maximization on graph-structured data. We decompose the generation of a graph into two steps: generation of (i) an adjacency tensor and(ii) node attributes. We empirically demonstrate that our model and the two-step generation efficiently generates valid molecular graphs with almost no duplicated molecules, although there are no domain-specific heuristics ingrained in the model. We also confirm that the sampling (generation) of graphs is faster in magnitude than other models in our implementation. In addition, we observe that the learned latent space can be used to generate molecules with desired chemical properties"}}
{"id": "SyepHTNFDS", "cdate": 1569439045362, "mdate": null, "content": {"title": "Graph Residual Flow for Molecular Graph Generation", "abstract": "Statistical generative models for molecular graphs attract attention from many researchers from the fields of bio- and chemo-informatics. Among these models, invertible flow-based approaches are not fully explored yet. In this paper, we propose a powerful invertible flow for molecular graphs, called Graph Residual Flow (GRF). The GRF is based on residual flows, which are known for more flexible and complex non-linear mappings than traditional coupling flows. We theoretically derive non-trivial conditions such that GRF is invertible, and present a way of keeping the entire flows invertible throughout the training and sampling. Experimental results show that a generative model based on the proposed GRF achieve comparable generation performance, with much smaller number of trainable parameters compared to the existing flow-based model. "}}
{"id": "S1l66nNFvB", "cdate": 1569438916637, "mdate": null, "content": {"title": "Graph Warp Module: an Auxiliary Module for Boosting the Power of Graph Neural Networks in Molecular Graph Analysis", "abstract": "Graph Neural Network (GNN) is a popular architecture for the analysis of chemical molecules, and it has numerous applications in material and medicinal science.\nCurrent lines of GNNs developed for molecular analysis, however, do not fit well on the training set, and their performance does not scale well with the complexity of the network. \nIn this paper, we propose an auxiliary module to be attached to a GNN that can boost the representation power of the model without hindering the original GNN architecture. \nOur auxiliary module can improve the representation power and the generalization ability of a wide variety of GNNs, including those that are used commonly in biochemical applications. "}}
{"id": "DWa80Sk43T_", "cdate": 1546300800000, "mdate": null, "content": {"title": "Graph Warp Module: an Auxiliary Module for Boosting the Power of Graph Neural Networks", "abstract": "Graph Neural Network (GNN) is a popular architecture for the analysis of chemical molecules, and it has numerous applications in material and medicinal science. Current lines of GNNs developed for molecular analysis, however, do not fit well on the training set, and their performance does not scale well with the complexity of the network. In this paper, we propose an auxiliary module to be attached to a GNN that can boost the representation power of the model without hindering with the original GNN architecture. Our auxiliary module can be attached to a wide variety of GNNs, including those that are used commonly in biochemical applications. With our auxiliary architecture, the performances of many GNNs used in practice improve more consistently, achieving the state-of-the-art performance on popular molecular graph datasets."}}
{"id": "dN_uiq-CE0y", "cdate": 1483228800000, "mdate": null, "content": {"title": "Robust unsupervised cluster matching for network data", "abstract": "Unsupervised cluster matching is a task to find matching between clusters of objects in different domains. Examples include matching word clusters in different languages without dictionaries or parallel sentences and matching user communities across different friendship networks. Existing methods assume that every object is assigned into a cluster. However, in real-world applications, some objects would not form clusters. These irrelevant objects deteriorate the cluster matching performance since mistakenly estimated matching affect on estimation of matching of other objects. In this paper, we propose a probabilistic model for robust unsupervised cluster matching that discovers relevance of objects and matching of object clusters, simultaneously, given multiple networks. The proposed method finds correspondence only for relevant objects, and keeps irrelevant objects unmatched, which enables us to improve the matching performance since the adverse impact of irrelevant objects is eliminated. With the proposed method, relevant objects in different networks are clustered into a shared set of clusters by assuming that different networks are generated from a common network probabilistic model, which is an extension of stochastic block models. Objects assigned into the same clusters are considered as matched. Edges for irrelevant objects are assumed to be generated from a noise distribution irrespective of cluster assignments. We present an efficient Bayesian inference procedure of the proposed model based on collapsed Gibbs sampling. In our experiments, we demonstrate the effectiveness of the proposed method using synthetic and real-world data sets, including multilingual corpora and movie ratings."}}
{"id": "S1-lel-_-r", "cdate": 1451606400000, "mdate": null, "content": {"title": "Infinite Plaid Models for Infinite Bi-Clustering", "abstract": "We propose a probabilistic model for non-exhaustive and overlapping (NEO) bi-clustering. Our goal is to extract a few sub-matrices from the given data matrix, where entries of a sub-matrix are characterized by a specific distribution or parameters. Existing NEO bi-clustering methods typically require the number of sub-matrices to be extracted, which is essentially difficult to fix a priori. In this paper, we extend the plaid model, known as one of the best NEO bi-clustering algorithms, to allow infinite bi-clustering; NEO bi-clustering without specifying the number of sub-matrices. Our model can represent infinite sub-matrices formally. We develop a MCMC inference without the finite truncation, which potentially addresses all possible numbers of sub-matrices. Experiments quantitatively and qualitatively verify the usefulness of the proposed model. The results reveal that our model can offer more precise and in-depth analysis of sub-matrices."}}
