{"id": "VVsNTPK1FBp", "cdate": 1652737609062, "mdate": null, "content": {"title": "Diversified Recommendations for Agents with Adaptive Preferences", "abstract": "When an Agent visits a platform recommending a menu of content to select from, their choice of item depends not only on immutable preferences, but also on their prior engagements with the platform. The Recommender's primary objective is typically to encourage content consumption which optimizes some reward, such as ad revenue, but they often additionally aim to ensure that a sufficiently wide variety of content is consumed by the Agent over time. We formalize this problem as an adversarial bandit task. At each step, the Recommender presents a menu of $k$ (out of $n$) items to the Agent, who selects one item in the menu according to their unknown {\\it preference model}, which maps their history of past items to relative selection probabilities. The Recommender then observes the Agent's selected item and receives bandit feedback of the item's (adversarial) reward. In addition to optimizing  reward from the selected items at each step, the Recommender must also ensure that the total distribution of chosen items has sufficiently high entropy. \n\nWe define a class of preference models which are {\\it locally learnable}, i.e.\\ behavior over the entire domain can be estimated by only observing behavior in a small region; this includes models representable by bounded-degree polynomials as well as functions with a sparse Fourier basis. For this class, we give an algorithm for the Recommender which obtains $\\tilde{O}(T^{3/4})$ regret against all  item distributions satisfying two conditions: they are sufficiently diversified, and they are {\\it instantaneously  realizable} at any history by some distribution over menus. We show that these conditions are closely connected:  all sufficiently high-entropy distributions are instantaneously realizable at any history of selected items. We also give a set of negative results justifying our assumptions, in the form of a runtime lower bound for non-local learning and linear regret lower bounds for alternate benchmarks."}}
{"id": "5JdyRvTrK0q", "cdate": 1652737354282, "mdate": null, "content": {"title": "Private Synthetic Data for Multitask Learning and Marginal Queries", "abstract": "We provide a differentially private algorithm for producing  synthetic data simultaneously useful for multiple tasks: marginal queries and multitask machine learning (ML). A key innovation in our algorithm is the ability to directly handle numerical features, in contrast to a number of related prior approaches which require numerical features to be first converted into {high cardinality} categorical features via {a binning strategy}. Higher binning granularity is required for better accuracy, but this negatively impacts scalability. Eliminating the need for binning allows us to produce synthetic data preserving large numbers of statistical queries such as marginals on numerical features, and class conditional linear threshold queries. Preserving the latter means that the fraction of points of each class label above a particular half-space is roughly the same in both the real and synthetic data. This is the property that is needed to train a linear classifier in a multitask setting. Our algorithm also allows us to produce high quality synthetic data for mixed marginal queries, that combine both categorical  and numerical features. Our method consistently runs 2-5x faster than the best comparable techniques, and provides significant accuracy improvements in both marginal queries and linear prediction tasks for mixed-type datasets.  "}}
{"id": "YiOkBqmC0z", "cdate": 1577836800000, "mdate": 1683882368472, "content": {"title": "Targeted Intervention in Random Graphs", "abstract": "We consider a setting where individuals interact in a network, each choosing actions which optimize utility as a function of neighbors\u2019 actions. A central authority aiming to maximize social welfare at equilibrium can intervene by paying some cost to shift individual incentives, and the optimal intervention can be computed using the spectral decomposition of the graph, yet this is infeasible in practice if the adjacency matrix is unknown. In this paper, we study the question of designing intervention strategies for graphs where the adjacency matrix is unknown and is drawn from some distribution. For several commonly studied random graph models, we show that there is a single intervention, proportional to the first eigenvector of the expected adjacency matrix, which is near-optimal for almost all generated graphs when the budget is sufficiently large. We also provide several efficient sampling-based approaches for approximately recovering the first eigenvector when we do not know the distribution. On the whole, our analysis compares three categories of interventions: those which use no data about the network, those which use some data (such as distributional knowledge or queries to the graph), and those which are fully optimal. We evaluate these intervention strategies on synthetic and real-world network data, and our results suggest that analysis of random graph models can be useful for determining when certain heuristics may perform well in practice."}}
{"id": "XvmYbcR0MpE", "cdate": 1577836800000, "mdate": 1683882368480, "content": {"title": "The Use of Change Point Detection to Identify Software Performance Regressions in a Continuous Integration System", "abstract": "We describe our process for automatic detection of performance changes for a software product in the presence of noise. A large collection of tests run periodically as changes to our software product are committed to our source repository, and we would like to identify the commits responsible for performance regressions. Previously, we relied on manual inspection of time series graphs to identify significant changes. That was later replaced with a threshold-based detection system, but neither system was sufficient for finding changes in performance in a timely manner. This work describes our recent implementation of a change point detection system built upon the E-Divisive means algorithm. The algorithm produces a list of change points representing significant changes from a given history of performance results. A human reviews the list of change points for actionable changes, which are then triaged for further inspection. Using change point detection has had a dramatic impact on our ability to detect performance changes. Quantitatively, it has dramatically dropped our false positive rate for performance changes, while qualitatively it has made the entire performance evaluation process easier, more productive (ex. catching smaller regressions), and more timely."}}
