{"id": "4-frAljEgcD", "cdate": 1688169600000, "mdate": 1683767532619, "content": {"title": "HoLoCo: Holistic and local contrastive learning network for multi-exposure image fusion", "abstract": ""}}
{"id": "2o1QziUr1qa", "cdate": 1672531200000, "mdate": 1681626432819, "content": {"title": "Rethinking general underwater object detection: Datasets, challenges, and solutions", "abstract": ""}}
{"id": "1yP3MMIVG2", "cdate": 1663770050977, "mdate": 1663770050977, "content": {"title": "Target-aware Dual Adversarial Learning and a Multi-scenario Multi-Modality Benchmark to Fuse Infrared and Visible for Object Detection.", "abstract": "This study addresses the issue of fusing infrared and visible images that appear differently for object detection. Aiming at generating an image of high visual quality, previous approaches discover commons underlying the two modalities and fuse upon the common space either by iterative optimization or deep networks. These approaches neglect that modality differences implying the complementary information are extremely important for both fusion and subsequent detection task. This paper proposes a bilevel optimization formulation for the joint problem of fusion and detection, and then unrolls to a target-aware Dual Adversarial Learning (TarDAL) network for fusion and a commonly used detection network. The fusion network with one generator and dual discriminators seeks commons while learning from differences, which preserves structural information of targets from the infrared and textural details from the visible. Furthermore, we build a synchronized imaging system with calibrated infrared and optical sensors, and collect currently the most comprehensive benchmark covering a wide range of scenarios. Extensive experiments on several public datasets and our benchmark demonstrate that our method outputs not only visually appealing fusion but also averagely 10:9% higher detection mAP than the stateof- the-art approaches on various challenging scenarios."}}
{"id": "FbWuTTNxIa", "cdate": 1663769835679, "mdate": 1663769835679, "content": {"title": "Toward Fast, Flexible, and Robust Low-Light Image Enhancement.", "abstract": "Existing low-light image enhancement techniques are mostly not only difficult to deal with both visual quality and computational efficiency but also commonly invalid in unknown complex scenarios. In this paper, we develop a new Self-Calibrated Illumination (SCI) learning framework for fast, flexible, and robust brightening images in real-world low-light scenarios. To be specific, we establish a cascaded illumination learning process with weight sharing to handle this task. Considering the computational burden of the cascaded pattern, we construct the selfcalibrated module which realizes the convergence between results of each stage, producing the gains that only use the single basic block for inference (yet has not been exploited in previous works), which drastically diminishes computation cost. We then define the unsupervised training loss to elevate the model capability that can adapt general scenes. Further, we make comprehensive explorations to excavate SCI' s inherent properties (lacking in existing works) including operation-insensitive adaptability (acquiring stable performance under the settings of different simple operations) and model-irrelevant generality (can be applied to illumination-based existing works to improve performance). Finally, plenty of experiments and ablation studies fully indicate our superiority in both quality and efficiency. Applications on low-light face detection and nighttime semantic segmentation fully reveal the latent practical values for SCI. The source code will be made publicly available.\n\n"}}
{"id": "yLwbtjRNSK", "cdate": 1640995200000, "mdate": 1681626433800, "content": {"title": "Attention-Guided Global-Local Adversarial Learning for Detail-Preserving Multi-Exposure Image Fusion", "abstract": ""}}
{"id": "yERSQA4ivqQ", "cdate": 1640995200000, "mdate": 1681626434428, "content": {"title": "Best of Both Worlds: See and Understand Clearly in the Dark", "abstract": ""}}
{"id": "sP1zcypz-5", "cdate": 1640995200000, "mdate": 1681626433798, "content": {"title": "Learning a Deep Multi-Scale Feature Ensemble and an Edge-Attention Guidance for Image Fusion", "abstract": ""}}
{"id": "o-DTsfgmWH", "cdate": 1640995200000, "mdate": 1681626433800, "content": {"title": "Hierarchical Bilevel Learning with Architecture and Loss Search for Hadamard-based Image Restoration", "abstract": ""}}
{"id": "js3UmJ_9tmu", "cdate": 1640995200000, "mdate": 1681626434116, "content": {"title": "Twin Adversarial Contrastive Learning for Underwater Image Enhancement and Beyond", "abstract": ""}}
{"id": "iGsCBSQAiD", "cdate": 1640995200000, "mdate": 1681626433460, "content": {"title": "Global structure-guided learning framework for underwater image enhancement", "abstract": ""}}
