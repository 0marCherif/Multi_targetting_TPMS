{"id": "84POoMVeje7", "cdate": 1676591079853, "mdate": null, "content": {"title": "Task-Agnostic Continual Reinforcement Learning: Gaining Insights and Overcoming Challenges", "abstract": "We study methods for task-agnostic continual reinforcement learning (TACRL). TACRL combines the difficulties of partially observable RL (due to task agnosticism) and the challenges of continual learning (CL), which involves learning on a non-stationary sequence of tasks. As such, TACRL is important in real-world applications where agents must continuously adapt to changing environments. Our focus is on a previously unexplored and straightforward baseline for TACRL called replay-based recurrent RL (3RL). This approach augments an RL algorithm with recurrent mechanisms to mitigate partial observability and experience replay mechanisms to prevent catastrophic forgetting in CL. We pose a counterintuitive hypothesis that 3RL could outperform its soft upper bounds prescribed by previous literature: multi-task learning (MTL) methods that do not have to deal with non-stationary data distributions, as well as task-aware methods that can operate under full observability. Specifically, we believe that the challenges that arise in certain training regimes could be best overcome by 3RL enabled by its ability to perform \\emph{fast adaptation}, compared to task-aware approaches, which focus on task memorization.\nWe extensively test our hypothesis by performing a large number of experiments on synthetic data as well as continuous-action multi-task and continual learning benchmarks where our results provide strong evidence that validates our hypothesis. "}}
{"id": "mencEcrobES", "cdate": 1663850272882, "mdate": null, "content": {"title": "GAML: geometry-aware meta-learning via a fully adaptive preconditioner", "abstract": "Model-Agnostic Meta-Learning (MAML) is one of the most successful meta-learning algorithms. It has a bi-level optimization structure, where the outer-loop process learns the shared initialization and the inner-loop process optimizes the task-specific weights. Although MAML relies on the standard gradient descent in the inner-loop, recent works have shown that it can be beneficial to control the inner loop's gradient descent with a meta-learned preconditioner. The existing preconditioners, however, cannot adapt in a task-specific and path-dependent way at the same time. Also, most of them do not consider the geometry of the loss surface. In this work, we propose Geometry-Aware Meta-Learning (GAML) that can overcome the limitations. GAML can efficiently meta-learn a preconditioner that is dependent on the task-specific parameters and its preconditioner can be shown to be a Riemannian metric that defines the geometry of the loss surface. Therefore, we can perform a fully-adaptive and geometry-aware optimization in the inner-loop. Experiment results show that GAML outperforms the state-of-the-art MAML family and PGD-MAML family for a variety of few-shot learning tasks."}}
{"id": "ZGi3bDRXkx", "cdate": 1653752161687, "mdate": null, "content": {"title": "Adaptive Interest for Emphatic Reinforcement Learning", "abstract": "Emphatic algorithms have shown great promise in stabilizing and improving reinforcement learning by selectively emphasizing the update rule. Although the emphasis fundamentally depends on an interest function which defines the intrinsic importance of each state, most approaches simply adopt a uniform interest over all states (except where a hand-designed interest is possible based on domain knowledge). In this paper, we investigate adaptive methods that allow the interest function to dynamically vary over states and iterations. In particular, we leverage meta-gradients to automatically discover online an interest function that would accelerate the agent\u2019s learning process. Empirical evaluations on a wide range of environments show that adapting the interest is key to provide significant gains. Qualitative analysis indicates that the learned interest function emphasizes states of particular importance, such as bottlenecks, which can be especially useful in a transfer learning setting."}}
{"id": "zkG3N8uff3V", "cdate": 1653595786466, "mdate": null, "content": {"title": "Efficient Task Adaptation by Mixing Discovered Skills", "abstract": "Unsupervised skill discovery is one of the approaches by which the agent learns potentially useful and distinct behaviors without any explicit reward. The agent is then expected to quickly solve downstream tasks by properly using a set of discovered skills rather than learning everything from scratch. However, it is non-trivial to optimally utilize the discovered skills for each task, which can be viewed as a fine-tuning method, and this has been less considered in the literature in spite of its importance. In this paper, we compare some fine-tuning methods showing how they inefficiently utilize the discovered skills and also propose new methods, which are sample-efficient and effective by interpreting the skills as a perspective of how an agent transforms the input state. Our code is available at https://github.com/jsrimr/unsupervisedRL"}}
{"id": "QTjJMy-UNO", "cdate": 1652737862772, "mdate": null, "content": {"title": "Adaptive Interest for Emphatic Reinforcement Learning", "abstract": "Emphatic algorithms have shown great promise in stabilizing and improving reinforcement learning by selectively emphasizing the update rule. Although the emphasis fundamentally depends on an interest function which defines the intrinsic importance of each state, most approaches simply adopt a uniform interest over all states (except where a hand-designed interest is possible based on domain knowledge). In this paper, we investigate adaptive methods that allow the interest function to dynamically vary over states and iterations. In particular, we leverage meta-gradients to automatically discover online an interest function that would accelerate the agent\u2019s learning process. Empirical evaluations on a wide range of environments show that adapting the interest is key to provide significant gains. Qualitative analysis indicates that the learned interest function emphasizes states of particular importance, such as bottlenecks, which can be especially useful in a transfer learning setting."}}
{"id": "Cl9dcH6Xkcj", "cdate": 1652737627681, "mdate": null, "content": {"title": "Faster Deep Reinforcement Learning with Slower Online Network", "abstract": "Deep reinforcement learning algorithms often use two networks for value function optimization: an online network, and a target network that tracks the online network with some delay. Using two separate networks enables the agent to hedge against issues that arise when performing bootstrapping. In this paper we endow two popular deep reinforcement learning algorithms, namely DQN and Rainbow, with updates that incentivize the online network to remain in the proximity of the target network. This improves the robustness of deep reinforcement learning in presence of noisy updates. The resultant agents, called DQN Pro and Rainbow Pro, exhibit significant performance improvements over their original counterparts on the Atari benchmark demonstrating the effectiveness of this simple idea in deep reinforcement learning. The code for our paper is available here: Github.com/amazon-research/fast-rl-with-slow-updates."}}
{"id": "otvlmDIbDk", "cdate": 1582513082850, "mdate": null, "content": {"title": "Fast AutoAugment", "abstract": "Data augmentation is an essential technique for improving generalization ability\nof deep learning models. Recently, AutoAugment [3] has been proposed as an\nalgorithm to automatically search for augmentation policies from a dataset and has\nsignificantly enhanced performances on many image recognition tasks. However,\nits search method requires thousands of GPU hours even for a relatively small\ndataset. In this paper, we propose an algorithm called Fast AutoAugment that finds\neffective augmentation policies via a more efficient search strategy based on density\nmatching. In comparison to AutoAugment, the proposed algorithm speeds up the\nsearch time by orders of magnitude while achieves comparable performances on\nimage recognition tasks with various models and datasets including CIFAR-10,\nCIFAR-100, SVHN, and ImageNet."}}
{"id": "rygNFSBeIS", "cdate": 1567802748002, "mdate": null, "content": {"title": "Variational Temporal Abstraction", "abstract": "We introduce a variational approach to learning and inference of temporally hierarchical structure and representation for sequential data. We propose the Variational Temporal Abstraction, a hierarchical recurrent state space model that can infer the latent temporal structure while also learning the sequential state distribution. This further enables to do jumpy future prediction with reduced computations based on the learned temporal abstraction. In experiments, we demonstrate our proposed model on 2D and 3D visual sequence datasets showing inferred temporal structures and temporally-extended future imagination."}}
{"id": "S1lhkdKkeV", "cdate": 1544685540021, "mdate": null, "content": {"title": "Scalable Neural Architecture Search for 3D Medical Image Segmentation", "abstract": "In this paper, a neural architecture search (NAS) framework is formulated for 3D medical image segmentation, to automatically optimize a neural architecture from a large design space. For this, a novel NAS framework is proposed to produce the structure of each layer including neural connectivities and operation types in both of the encoder and decoder of a target 3D U-Net. In the proposed NAS framework, having a sufficiently large search space is important in generating an improved network architecture, however optimizing over such a large space is difficult due to the extremely large memory usage and the long run-time originated from high-resolution 3D medical images. Therefore, a novel stochastic sampling algorithm based on the continuous relaxation on the discrete architecture parameters is also proposed for scalable joint optimization of both of the architecture parameters and the neural operation parameters. This makes it possible to maintain a large search space with small computational cost as well as to obtain an unbiased architecture by reducing the discrepancy between the training-time and test-time architectures. On the 3D medical image segmentation tasks with a benchmark dataset, an automatically designed 3D U-Net by the proposed NAS framework outperforms the previous human-designed 3D U-Net as well as the randomly designed 3D U-Net, and moreover this optimized architecture is more compact and also well suited to be transferred for similar but different tasks."}}
{"id": "rJUYGxbCW", "cdate": 1518730173088, "mdate": null, "content": {"title": "PixelDefend: Leveraging Generative Models to Understand and Defend against Adversarial Examples", "abstract": "Adversarial perturbations of normal images are usually imperceptible to humans, but they can seriously confuse state-of-the-art machine learning models. What makes them so special in the eyes of image classifiers? In this paper, we show empirically that adversarial examples mainly lie in the low probability regions of the training distribution, regardless of attack types and targeted models. Using statistical hypothesis testing, we find that modern neural density models are surprisingly good at detecting imperceptible image perturbations. Based on this discovery, we devised PixelDefend, a new approach that purifies a maliciously perturbed image by moving it back towards the distribution seen in the training data. The purified image is then run through an unmodified classifier, making our method agnostic to both the classifier and the attacking method. As a result, PixelDefend can be used to protect already deployed models and be combined with other model-specific defenses. Experiments show that our method greatly improves resilience across a wide variety of state-of-the-art attacking methods, increasing accuracy on the strongest attack from 63% to 84% for Fashion MNIST and from 32% to 70% for CIFAR-10."}}
