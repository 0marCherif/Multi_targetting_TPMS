{"id": "7psPmlNffvg", "cdate": 1611733248893, "mdate": null, "content": {"title": "Improving MRI-based Knee Disorder Diagnosis with Pyramidal Feature Details", "abstract": "This paper presents MRPyrNet, a new convolutional neural network (CNN) architecture that improves the capabilities of CNN-based pipelines for knee injury detection via magnetic resonance imaging (MRI). Existing works showed that anomalies are localized in small-sized knee regions that appear in particular areas of MRI scans. Based on such facts, MRPyrNet exploits a Feature Pyramid Network to enhance small appearing features and Pyramidal Detail Pooling to capture such relevant information in a robust way. Experimental results on two publicly available datasets demonstrate that MRPyrNet improves the ACL tear and meniscal tear diagnosis capabilities of two state-of-the-art methodologies. Code is available at https://git.io/JtMPH.\n"}}
{"id": "HXbFhfg_aH", "cdate": 1546300800000, "mdate": null, "content": {"title": "Aggregating Deep Pyramidal Representations for Person Re-Identification.", "abstract": "Learning discriminative, view-invariant and multi-scale representations of person appearance with different semantic levels is of paramount importance for person Re-Identification (Re-ID). A surge of effort has been spent by the community to learn deep Re-ID models capturing a holistic single semantic level feature representation. To improve the achieved results, additional visual attributes and body part-driven models have been considered. However, these require extensive human annotation labor or demand additional computational efforts. We argue that a pyramid-inspired method capturing multi-scale information may overcome such requirements. Precisely, multi-scale stripes that represent visual information of a person can be used by a novel architecture factorizing them into latent discriminative factors at multiple semantic levels. A multi-task loss is combined with a curriculum learning strategy to learn a discriminative and invariant person representation which is exploited for triplet-similarity learning. Results on three benchmark Re-ID datasets demonstrate that better performance than existing methods are achieved (e.g., more than 90% accuracy on the Duke-MTMC dataset)."}}
{"id": "SkZhpxMdZB", "cdate": 1483228800000, "mdate": null, "content": {"title": "Group Re-identification via Unsupervised Transfer of Sparse Features Encoding", "abstract": "Person re-identification is best known as the problem of associating a single person that is observed from one or more disjoint cameras. The existing literature has mainly addressed such an issue, neglecting the fact that people usually move in groups, like in crowded scenarios. We believe that the additional information carried by neighboring individuals provides a relevant visual context that can be exploited to obtain a more robust match of single persons within the group. Despite this, re-identifying groups of people compound the common single person re-identification problems by introducing changes in the relative position of persons within the group and severe self-occlusions. In this paper, we propose a solution for group re-identification that grounds on transferring knowledge from single person reidentification to group re-identification by exploiting sparse dictionary learning. First, a dictionary of sparse atoms is learned using patches extracted from single person images. Then, the learned dictionary is exploited to obtain a sparsity-driven residual group representation, which is finally matched to perform the re-identification. Extensive experiments on the i-LIDS groups and two newly collected datasets show that the proposed solution outperforms stateof-the-art approaches."}}
{"id": "H1W_NqW_br", "cdate": 1451606400000, "mdate": null, "content": {"title": "Temporal Model Adaptation for Person Re-identification", "abstract": "Person re-identification is an open and challenging problem in computer vision. Majority of the efforts have been spent either to design the best feature representation or to learn the optimal matching metric. Most approaches have neglected the problem of adapting the selected features or the learned model over time. To address such a problem, we propose a temporal model adaptation scheme with human in the loop. We first introduce a similarity-dissimilarity learning method which can be trained in an incremental fashion by means of a stochastic alternating directions methods of multipliers optimization procedure. Then, to achieve temporal adaptation with limited human effort, we exploit a graph-based approach to present the user only the most informative probe-gallery matches that should be used to update the model. Results on three datasets have shown that our approach performs on par or even better than state-of-the-art approaches while reducing the manual pairwise labeling effort by about $$80\\,\\%$$ ."}}
{"id": "ByV8_WGOWH", "cdate": 1420070400000, "mdate": null, "content": {"title": "Person Re-Identification Ranking Optimisation by Discriminant Context Information Analysis", "abstract": "Person re-identification is an open and challenging problem in computer vision. Existing re-identification approaches focus on optimal methods for features matching (e.g., metric learning approaches) or study the inter-camera transformations of such features. These methods hardly ever pay attention to the problem of visual ambiguities shared between the first ranks. In this paper, we focus on such a problem and introduce an unsupervised ranking optimization approach based on discriminant context information analysis. The proposed approach refines a given initial ranking by removing the visual ambiguities common to first ranks. This is achieved by analyzing their content and context information. Extensive experiments on three publicly available benchmark datasets and different baseline methods have been conducted. Results demonstrate a remarkable improvement in the first positions of the ranking. Regardless of the selected dataset, state-of-the-art methods are strongly outperformed by our method."}}
{"id": "Bjjv6oElupr", "cdate": 1420070400000, "mdate": null, "content": {"title": "Re-Identification in the Function Space of Feature Warps.", "abstract": "Person re-identification in a non-overlapping multicamera scenario is an open challenge in computer vision because of the large changes in appearances caused by variations in viewing angle, lighting, background clutter, and occlusion over multiple cameras. As a result of these variations, features describing the same person get transformed between cameras. To model the transformation of features, the feature space is nonlinearly warped to get the \u201cwarp functions\u201d. The warp functions between two instances of the same target form the set of feasible warp functions while those between instances of different targets form the set of infeasible warp functions. In this work, we build upon the observation that feature transformations between cameras lie in a nonlinear function space of all possible feature transformations. The space consisting of all the feasible and infeasible warp functions is the warp function space (WFS). We propose to learn a discriminating surface separating these two sets of warp functions in the WFS and to re-identify persons by classifying a test warp function as feasible or infeasible. Towards this objective, a Random Forest (RF) classifier is employed which effectively chooses the warp function components according to their importance in separating the feasible and the infeasible warp functions in the WFS. Extensive experiments on five datasets are carried out to show the superior performance of the proposed approach over state-of-the-art person re-identification methods. We show that our approach outperforms all other methods when large illumination variations are considered. At the same time it has been shown that our method reaches the best average performance over multiple combinations of the datasets, thus, showing that our method is not designed only to address a specific challenge posed by a particular dataset."}}
{"id": "SkNOBYWOWB", "cdate": 1388534400000, "mdate": null, "content": {"title": "Saliency Weighted Features for Person Re-identification", "abstract": "In this work we propose a novel person re-identification approach. The solution, inspired by human gazing capabilities, wants to identify the salient regions of a given person. Such regions are used as a weighting tool in the image feature extraction process. Then, such novel representation is combined with a set of other visual features in a pairwise-based multiple metric learning framework. Finally, the learned metrics are fused to get the distance between image pairs and to re-identify a person. The proposed method is evaluated on three different benchmark datasets and compared with best state-of-the-art approaches to show its overall superior performance."}}
{"id": "Sk4rBA-_Zr", "cdate": 1325376000000, "mdate": null, "content": {"title": "Re-identify people in wide area camera network", "abstract": "Tracking individuals within a wide area camera network is a tough problem. Obtaining information across uncovered areas is an open issue that person re-identification methods deal with. A novel appearance-based method for person re-identification is proposed. The approach computes a novel discriminative signature by exploiting multiple local features. A novel signature distance measure is given by exploiting a body part division approach. The method has been compared to state-of-the-art methods using a re-identification benchmark dataset. A new dataset acquired from non-overlapping cameras has been built to validate the method against a real wide area camera network scenario. The method has proven to be robust against low resolution images, viewpoint and illumination changes, occlusions and pose variations. Results show that the proposed approach outperforms state-of-the-art methods used for comparison."}}
