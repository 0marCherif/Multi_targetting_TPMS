{"id": "ryWzQXbuZr", "cdate": 1546300800000, "mdate": null, "content": {"title": "Scaling Multi-Domain Dialogue State Tracking via Query Reformulation", "abstract": "Pushpendre Rastogi, Arpit Gupta, Tongfei Chen, Mathias Lambert. Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Industry Papers). 2019."}}
{"id": "Sk-7nBWuZH", "cdate": 1514764800000, "mdate": null, "content": {"title": "Neural Variational Entity Set Expansion for Automatically Populated Knowledge Graphs", "abstract": ""}}
{"id": "H1-cpS-_ZS", "cdate": 1483228800000, "mdate": null, "content": {"title": "Predicting Asymmetric Transitive Relations in Knowledge Bases", "abstract": ""}}
{"id": "BkNDeUZ_Wr", "cdate": 1483228800000, "mdate": null, "content": {"title": "Training Relation Embeddings under Logical Constraints", "abstract": ""}}
{"id": "BJbjvXZ_ZH", "cdate": 1451606400000, "mdate": null, "content": {"title": "Weighting Finite-State Transductions With Neural Context", "abstract": ""}}
{"id": "rJW8R3luWr", "cdate": 1420070400000, "mdate": null, "content": {"title": "FrameNet+: Fast Paraphrastic Tripling of FrameNet", "abstract": "We increase the lexical coverage of FrameNet through automatic paraphrasing. We use crowdsourcing to manually filter out bad paraphrases in order to ensure a high-precision resource. Our expanded FrameNet contains an additional 22K lexical units, a 3-fold increase over the current FrameNet, and achieves 40% better coverage when evaluated in a practical setting on New York Times data."}}
{"id": "SybCvfMd-H", "cdate": 1420070400000, "mdate": null, "content": {"title": "Script Induction as Language Modeling", "abstract": "The narrative cloze is an evaluation metric commonly used for work on automatic script induction. While prior work in this area has focused on count-based methods from distributional semantics, such as pointwise mutual information, we argue that the narrative cloze can be productively reframed as a language modeling task. By training a discriminative language model for this task, we attain improvements of up to 27 percent over prior methods on standard narrative cloze metrics."}}
{"id": "S1EhwolObS", "cdate": 1420070400000, "mdate": null, "content": {"title": "PPDB 2.0: Better paraphrase ranking, fine-grained entailment relations, word embeddings, and style classification", "abstract": "We present a new release of the Paraphrase Database. PPDB 2.0 includes a discriminatively re-ranked set of paraphrases that achieve a higher correlation with human judgments than PPDB 1.0\u2019s heuristic rankings. Each paraphrase pair in the database now also includes finegrained entailment relations, word embedding similarities, and style annotations."}}
{"id": "BJVBIXZOWH", "cdate": 1420070400000, "mdate": null, "content": {"title": "Multiview LSA: Representation Learning via Generalized CCA", "abstract": "Multiview LSA (MVLSA) is a generalization of Latent Semantic Analysis (LSA) that supports the fusion of arbitrary views of data and relies on Generalized Canonical Correlation Analysis (GCCA). We present an algorithm for fast approximate computation of GCCA, which when coupled with methods for handling missing values, is general enough to approximate some recent algorithms for inducing vector representations of words. Experiments across a comprehensive collection of test-sets show our approach to be competitive with the state of the art."}}
