{"id": "vqGi8Kp0wM", "cdate": 1632875740513, "mdate": null, "content": {"title": "Mind the Gap: Domain Gap Control for Single Shot Domain Adaptation for Generative Adversarial Networks", "abstract": "We present a new method for one shot domain adaptation. The input to our method is trained GAN that can produce images in domain A and a single reference image I_B from domain B. The proposed algorithm can translate any output of the trained GAN from domain A to domain B. There are two main advantages of our method compared to the current state of the art: First, our solution achieves higher visual quality, e.g. by noticeably reducing overfitting. Second, our solution allows for more degrees of freedom to control the domain gap, i.e. what aspects of image I_B are used to define the domain B. Technically, we realize the new method by building on a pre-trained StyleGAN generator as GAN and a pre-trained CLIP model for representing the domain gap. We propose several new regularizers for controlling the domain gap to optimize the weights of the pre-trained StyleGAN generator to output images in domain B instead of domain A. The regularizers prevent the optimization from taking on too many attributes of the single reference image. Our results show significant visual improvements over the state of the art as well as multiple applications that highlight improved control."}}
{"id": "Kao09W-oe8", "cdate": 1601308147178, "mdate": null, "content": {"title": "Channel-Directed Gradients for Optimization of Convolutional Neural Networks", "abstract": "We introduce optimization methods for convolutional neural networks that can be used to improve existing gradient-based optimization in terms of generalization error. The method requires only simple processing of existing stochastic gradients, can be used in conjunction with any optimizer, and has only a linear overhead (in the number of parameters) compared to computation of the stochastic gradient. The method works by computing the gradient of the loss function with respect to output-channel directed re-weighted L2 or Sobolev metrics, which has the effect of smoothing components of the gradient across a certain direction of the parameter tensor. We show that defining the gradients along the output channel direction leads to a performance boost, while other directions can be detrimental. We present the continuum theory of such gradients, its discretization, and application to deep networks. Experiments on benchmark datasets, several networks, and baseline optimizers show that optimizers can be improved in generalization error by simply computing the stochastic gradient with respect to output-channel directed metrics."}}
{"id": "xMU0FxgXyG9", "cdate": 1600305005030, "mdate": null, "content": {"title": "Channel-Directed Gradients for Optimization of Convolutional Neural Networks", "abstract": "We introduce optimization methods for convolutional neural networks that can be\nused to improve existing gradient-based optimization in terms of generalization\nerror. The method requires only simple processing of existing stochastic gradients,\ncan be used in conjunction with any optimizer, and has only a linear overhead (in\nthe number of parameters) compared to computation of the stochastic gradient.\nThe method works by computing the gradient of the loss function with respect to\noutput-channel directed re-weighted L2 or Sobolev metrics, which has the effect of\nsmoothing components of the gradient across a certain direction of the parameter\ntensor. We show that defining the gradients along the output channel direction\nleads to a performance boost, while other directions can be detrimental. We present\nthe continuum theory of such gradients, its discretization, and application to deep\nnetworks. Experiments on benchmark datasets, several networks and baseline\noptimizers show that optimizers can be improved in generalization error by simply\ncomputing the stochastic gradient with respect to output-channel directed metrics."}}
{"id": "wU5ZMV9wGSxh", "cdate": 1577836800000, "mdate": null, "content": {"title": "Channel-Directed Gradients for Optimization of Convolutional Neural Networks", "abstract": "We introduce optimization methods for convolutional neural networks that can be used to improve existing gradient-based optimization in terms of generalization error. The method requires only simple processing of existing stochastic gradients, can be used in conjunction with any optimizer, and has only a linear overhead (in the number of parameters) compared to computation of the stochastic gradient. The method works by computing the gradient of the loss function with respect to output-channel directed re-weighted L2 or Sobolev metrics, which has the effect of smoothing components of the gradient across a certain direction of the parameter tensor. We show that defining the gradients along the output channel direction leads to a performance boost, while other directions can be detrimental. We present the continuum theory of such gradients, its discretization, and application to deep networks. Experiments on benchmark datasets, several networks and baseline optimizers show that optimizers can be improved in generalization error by simply computing the stochastic gradient with respect to output-channel directed metrics."}}
{"id": "VNmnpE79xFo", "cdate": 1577836800000, "mdate": null, "content": {"title": "StyleFlow: Attribute-conditioned Exploration of StyleGAN-Generated Images using Conditional Continuous Normalizing Flows", "abstract": "High-quality, diverse, and photorealistic images can now be generated by unconditional GANs (e.g., StyleGAN). However, limited options exist to control the generation process using (semantic) attributes, while still preserving the quality of the output. Further, due to the entangled nature of the GAN latent space, performing edits along one attribute can easily result in unwanted changes along other attributes. In this paper, in the context of conditional exploration of entangled latent spaces, we investigate the two sub-problems of attribute-conditioned sampling and attribute-controlled editing. We present StyleFlow as a simple, effective, and robust solution to both the sub-problems by formulating conditional exploration as an instance of conditional continuous normalizing flows in the GAN latent space conditioned by attribute features. We evaluate our method using the face and the car latent space of StyleGAN, and demonstrate fine-grained disentangled edits along various attributes on both real photographs and StyleGAN generated images. For example, for faces, we vary camera pose, illumination variation, expression, facial hair, gender, and age. Finally, via extensive qualitative and quantitative comparisons, we demonstrate the superiority of StyleFlow to other concurrent works."}}
{"id": "GcDQ61wJvxy", "cdate": 1577836800000, "mdate": null, "content": {"title": "SEAN: Image Synthesis With Semantic Region-Adaptive Normalization", "abstract": "We propose semantic region-adaptive normalization (SEAN), a simple but effective building block for Generative Adversarial Networks conditioned on segmentation masks that describe the semantic regions in the desired output image. Using SEAN normalization, we can build a network architecture that can control the style of each semantic region individually, e.g., we can specify one style reference image per region. SEAN is better suited to encode, transfer, and synthesize style than the best previous method in terms of reconstruction quality, variability, and visual quality. We evaluate SEAN on multiple datasets and report better quantitative metrics (e.g. FID, PSNR) than the current state of the art. SEAN also pushes the frontier of interactive image editing. We can interactively edit images by changing segmentation masks or the style for any given region. We can also interpolate styles from two reference images per region."}}
{"id": "cHSeTaD0cOH", "cdate": 1546300800000, "mdate": null, "content": {"title": "SEAN: Image Synthesis with Semantic Region-Adaptive Normalization", "abstract": "We propose semantic region-adaptive normalization (SEAN), a simple but effective building block for Generative Adversarial Networks conditioned on segmentation masks that describe the semantic regions in the desired output image. Using SEAN normalization, we can build a network architecture that can control the style of each semantic region individually, e.g., we can specify one style reference image per region. SEAN is better suited to encode, transfer, and synthesize style than the best previous method in terms of reconstruction quality, variability, and visual quality. We evaluate SEAN on multiple datasets and report better quantitative metrics (e.g. FID, PSNR) than the current state of the art. SEAN also pushes the frontier of interactive image editing. We can interactively edit images by changing segmentation masks or the style for any given region. We can also interpolate styles from two reference images per region."}}
