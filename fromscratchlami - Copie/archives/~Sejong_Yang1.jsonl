{"id": "6nNO2iscsQL", "cdate": 1696317887931, "mdate": null, "content": {"title": "THMM-DiT:  Talking Head Motion Modeling with Diffusion Transformer", "abstract": "Generating natural talking head motion is a challenging task due to the one-to-many nature of speech-to-motion mapping, the high dimensionality of RGB video, and the difficulty of modeling dynamic head poses. In this technical report, we propose a new approach to generating natural talking head motion that addresses these challenges. Our approach uses a diffusion model to generate a distribution of possible head poses, which is then conditioned on the given audio to produce a natural-looking talking head. We also use a face template to reduce the computational resources required to generate high-quality RGB videos. Finally, we employ long clue frames with spatio-temporal attention of transformer to generate natural long-term sequences of head poses. Our approach is able to generate dynamic head poses in the long term while accurately synchronizing mouth shapes with the given audio."}}
{"id": "m67FNFdgLO9", "cdate": 1652737272319, "mdate": null, "content": {"title": "Dense Interspecies Face Embedding", "abstract": "Dense Interspecies Face Embedding (DIFE) is a new direction for understanding faces of various animals by extracting common features among animal faces including human face. There are three main obstacles for interspecies face understanding: (1) lack of animal data compared to human, (2) ambiguous connection between faces of various animals, and (3) extreme shape and style variance. To cope with the lack of data, we utilize multi-teacher knowledge distillation of CSE and StyleGAN2 requiring no additional data or label. Then we synthesize pseudo pair images through the latent space exploration of StyleGAN2 to find implicit associations between different animal faces. Finally, we introduce the semantic matching loss to overcome the problem of extreme shape differences between species. To quantitatively evaluate our method over possible previous methodologies like unsupervised keypoint detection, we perform interspecies facial keypoint transfer on MAFL and AP-10K. Furthermore, the results of other applications like interspecies face image manipulation and dense keypoint transfer are provided. The code is available at https://github.com/kingsj0405/dife."}}
{"id": "j2d7SiPm1h", "cdate": 1609459200000, "mdate": 1667352749223, "content": {"title": "SRFlow-DA: Super-Resolution Using Normalizing Flow With Deep Convolutional Block", "abstract": "Multiple high-resolution (HR) images can be generated from a single low-resolution (LR) image, as super-resolution (SR) is an underdetermined problem. Recently, the conditional normalizing flow-based model, SRFlow, shows remarkable performance by learning an exact mapping from HR image manifold to a latent space. The flow-based SR model allows sampling multiple output images from a learned SR space with a given LR image. In this work, we propose SRFlow-DA which has a more suitable architecture for the SR task based on the original SRFlow model. Specifically, our approach enlarges the receptive field by stacking more convolutional layers in the affine couplings, and so our model can get more expressive power. At the same time, we reduce the total number of model parameters for efficiency. Compared to SRFlow, our SRFlow-DA achieves better or comparable PSNR and LPIPS for x4 and x8 SR tasks, while having a reduced number of parameters. In addition, our method generates visually clear results without excessive sharpness artifacts."}}
{"id": "dDXm5cJFzU", "cdate": 1577836800000, "mdate": 1667347842187, "content": {"title": "NTIRE 2020 Challenge on Perceptual Extreme Super-Resolution: Methods and Results", "abstract": "This paper reviews the NTIRE 2020 challenge on perceptual extreme super-resolution with focus on proposed solutions and results. The challenge task was to super-resolve an input image with a magnification factor 16 based on a set of prior examples of low and corresponding high resolution images. The goal is to obtain a network design capable to produce high resolution results with the best perceptual quality and similar to the ground truth. The track had 280 registered participants, and 19 teams submitted the final results. They gauge the state-of-the-art in single image super-resolution."}}
{"id": "NJFcjg3V-i-", "cdate": 1577836800000, "mdate": 1667352749487, "content": {"title": "Investigating Loss Functions for Extreme Super-Resolution", "abstract": "The performance of image super-resolution (SR) has been greatly improved by using convolutional neural networks. Most of the previous SR methods have been studied up to x4 upsampling, and few were studied for x16 upsampling. The general approach for perceptual x4 SR is using GAN with VGG based perceptual loss, however, we found that it creates inconsistent details for perceptual x16 SR. To this end, we have investigated loss functions and we propose to use GAN with LPIPS loss for perceptual extreme SR. In addition, we use U-net structure discriminator together to consider both the global and local context of an input image. Experimental results show that our method outperforms the conventional perceptual loss, and we achieved second place in preliminary results of NTIRE 2020 perceptual extreme SR challenge."}}
{"id": "-BnYNRgY4E", "cdate": 1577836800000, "mdate": 1667347842011, "content": {"title": "NTIRE 2020 Challenge on Perceptual Extreme Super-Resolution: Methods and Results", "abstract": "This paper reviews the NTIRE 2020 challenge on perceptual extreme super-resolution with focus on proposed solutions and results. The challenge task was to super-resolve an input image with a magnification factor 16 based on a set of prior examples of low and corresponding high resolution images. The goal is to obtain a network design capable to produce high resolution results with the best perceptual quality and similar to the ground truth. The track had 280 registered participants, and 19 teams submitted the final results. They gauge the state-of-the-art in single image superresolution."}}
