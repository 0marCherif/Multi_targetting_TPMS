{"id": "s7K_OZpJj-", "cdate": 1672531200000, "mdate": 1681699964827, "content": {"title": "CAT-Seg: Cost Aggregation for Open-Vocabulary Semantic Segmentation", "abstract": "Existing works on open-vocabulary semantic segmentation have utilized large-scale vision-language models, such as CLIP, to leverage their exceptional open-vocabulary recognition capabilities. However, the problem of transferring these capabilities learned from image-level supervision to the pixel-level task of segmentation and addressing arbitrary unseen categories at inference makes this task challenging. To address these issues, we aim to attentively relate objects within an image to given categories by leveraging relational information among class categories and visual semantics through aggregation, while also adapting the CLIP representations to the pixel-level task. However, we observe that direct optimization of the CLIP embeddings can harm its open-vocabulary capabilities. In this regard, we propose an alternative approach to optimize the image-text similarity map, i.e. the cost map, using a novel cost aggregation-based method. Our framework, namely CAT-Seg, achieves state-of-the-art performance across all benchmarks. We provide extensive ablation studies to validate our choices. Project page: https://ku-cvlab.github.io/CAT-Seg/."}}
{"id": "bZzS_kkJes", "cdate": 1652737363236, "mdate": null, "content": {"title": "Neural Matching Fields: Implicit Representation of Matching Fields for Visual Correspondence", "abstract": "Existing pipelines of semantic correspondence commonly include extracting high-level semantic features for the invariance against intra-class variations and background clutters. This architecture, however, inevitably results in a low-resolution matching field that additionally requires an ad-hoc interpolation process as a post-processing for converting it into a high-resolution one, certainly limiting the overall performance of matching results. To overcome this, inspired by recent success of implicit neural representation, we present a novel method for semantic correspondence, called Neural Matching Field (NeMF). However, complicacy and high-dimensionality of a 4D matching field are the major hindrances, which we propose a cost embedding network to process a coarse cost volume to use as a guidance for establishing high-precision matching field through the following fully-connected network. Nevertheless, learning a high-dimensional matching field remains challenging mainly due to computational complexity, since a na\\\"ive exhaustive inference would require querying from all pixels in the 4D space to infer pixel-wise correspondences. To overcome this, we propose adequate training and inference procedures, which in the training phase, we randomly sample matching candidates and in the inference phase, we iteratively performs PatchMatch-based inference and coordinate optimization at test time. With these combined, competitive results are attained on several standard benchmarks for semantic correspondence. Code and pre-trained weights are available at~\\url{https://ku-cvlab.github.io/NeMF/}."}}
{"id": "wj0RFJVwmWG", "cdate": 1640995200000, "mdate": 1668175504357, "content": {"title": "MIDMs: Matching Interleaved Diffusion Models for Exemplar-based Image Translation", "abstract": ""}}
{"id": "wVcEUFKn3iE", "cdate": 1640995200000, "mdate": 1668175504358, "content": {"title": "Cost Aggregation with 4D Convolutional Swin Transformer for Few-Shot Segmentation", "abstract": ""}}
{"id": "wSae-6AnPb", "cdate": 1640995200000, "mdate": 1668175504357, "content": {"title": "Neural Matching Fields: Implicit Representation of Matching Fields for Visual Correspondence", "abstract": ""}}
{"id": "umOdRCrDFo", "cdate": 1640995200000, "mdate": 1668175504358, "content": {"title": "CATs++: Boosting Cost Aggregation with Convolutions and Transformers", "abstract": ""}}
{"id": "Pzn4VUlQ_T", "cdate": 1640995200000, "mdate": 1668175504209, "content": {"title": "Cost Aggregation with 4D Convolutional Swin Transformer for Few-Shot Segmentation", "abstract": ""}}
{"id": "H3cKrPMtkmp", "cdate": 1640995200000, "mdate": 1681699965032, "content": {"title": "Cost Aggregation with 4D Convolutional Swin Transformer for Few-Shot Segmentation", "abstract": "This paper presents a novel cost aggregation network, called Volumetric Aggregation with Transformers (VAT), for few-shot segmentation. The use of transformers can benefit correlation map aggregation through self-attention over a global receptive field. However, the tokenization of a correlation map for transformer processing can be detrimental, because the discontinuity at token boundaries reduces the local context available near the token edges and decreases inductive bias. To address this problem, we propose a 4D Convolutional Swin Transformer, where a high-dimensional Swin Transformer is preceded by a series of small-kernel convolutions that impart local context to all pixels and introduce convolutional inductive bias. We additionally boost aggregation performance by applying transformers within a pyramidal structure, where aggregation at a coarser level guides aggregation at a finer level. Noise in the transformer output is then filtered in the subsequent decoder with the help of the query\u2019s appearance embedding. With this model, a new state-of-the-art is set for all the standard benchmarks in few-shot segmentation. It is shown that VAT attains state-of-the-art performance for semantic correspondence as well, where cost aggregation also plays a central role. Code and trained models are available at\u00a0 https://seokju-cho.github.io/VAT/ ."}}
{"id": "GvcOeoInZ6", "cdate": 1640995200000, "mdate": 1668175504360, "content": {"title": "AggMatch: Aggregating Pseudo Labels for Semi-Supervised Learning", "abstract": ""}}
{"id": "ErLPeP0fXsJ", "cdate": 1640995200000, "mdate": 1668175504364, "content": {"title": "Integrative Feature and Cost Aggregation with Transformers for Dense Correspondence", "abstract": ""}}
