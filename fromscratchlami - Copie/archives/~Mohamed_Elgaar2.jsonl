{"id": "AC0WKugmVD", "cdate": 1672531200000, "mdate": 1689951750560, "content": {"title": "HuCurl: Human-induced Curriculum Discovery", "abstract": ""}}
{"id": "LGTmlJ10Kes", "cdate": 1632875753817, "mdate": null, "content": {"title": "Curriculum Discovery through an Encompassing Curriculum Learning Framework", "abstract": "We describe a curriculum learning framework capable of discovering optimal curricula in addition to performing standard curriculum learning. We show that this framework encompasses existing curriculum learning approaches such as difficulty-based data sub-sampling, data pruning, and loss re-weighting. We employ the proposed framework to address the following key questions in curriculum learning research: (a) What is the best curriculum to train a given model on a given dataset? (b) What are the characteristics of optimal curricula for different datasets and different difficulty scoring functions? We show that our framework outperforms competing state-of-the-art curriculum learning approaches in natural language inference and other text classification tasks. In addition, exhaustive experiments illustrate the generalizability of the discovered curricula across the three datasets and two difficulty scoring functions."}}
{"id": "1j6DCl6R7f", "cdate": 1577836800000, "mdate": 1651298949077, "content": {"title": "Multi-Speaker and Multi-Domain Emotional Voice Conversion Using Factorized Hierarchical Variational Autoencoder", "abstract": "Due to the complexity of emotional features, there has been limited success in emotional voice conversion. One major challenge is that conversion between more than two kinds of emotions often accompanies distortion of voice signal.The factorized hierarchical variational autoencoder (FHVAE) [1] was previously shown to have an ability, called sequence-level regularization, to generate disentangled representations of both sequence-level (such as speaker identity) and segment-level features. This study exploits the FHVAE pipeline to produce disentangled representations of emotion, making it possible to greatly facilitate emotional voice conversion.We propose three versions of algorithms for improving the quality of disentangled representation and audio synthesis. We conducted three mean opinion score (MOS) surveys to assess the performance of our models in terms of 1) speaker\u2019s voice preservation, 2) emotion conversion, and 3) audio naturalness."}}
