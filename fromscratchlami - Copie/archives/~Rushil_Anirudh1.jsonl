{"id": "RU7fr0-M8N", "cdate": 1673287848353, "mdate": null, "content": {"title": "Know Your Space: Inlier and Outlier Construction for Calibrating Medical OOD Detectors", "abstract": "We focus on the problem of producing well-calibrated out-of-distribution (OOD) detectors, in order to enable safe deployment of medical image classifiers. Motivated by the difficulty of curating suitable calibration datasets, synthetic augmentations have become highly prevalent for inlier/outlier specification. While there have been rapid advances in data augmentation techniques, this paper makes a striking finding that the space in which the inliers and outliers are synthesized, in addition to the type of augmentation, plays a critical role in calibrating OOD detectors. Using the popular energy-based OOD detection framework, we find that the optimal protocol is to synthesize latent-space inliers along with diverse pixel-space outliers. Based on empirical studies with multiple medical imaging benchmarks, we demonstrate that our approach consistently leads to superior OOD detection ($15\\% - 35\\%$ in AUROC) over the state-of-the-art in a variety of open-set recognition settings."}}
{"id": "j0J9upqN5va", "cdate": 1652737802849, "mdate": null, "content": {"title": "Single Model Uncertainty Estimation via Stochastic Data Centering", "abstract": "  We are interested in estimating the uncertainties of deep neural networks, which play an important role in many scientific and engineering problems. In this paper, we present a striking new finding that an ensemble of neural networks with the same weight initialization, trained on datasets that are shifted by a constant bias gives rise to slightly inconsistent trained models, where the differences in predictions are a strong indicator of epistemic uncertainties. Using the neural tangent kernel (NTK), we demonstrate that this phenomena occurs in part because the NTK is not shift-invariant. Since this is achieved via a trivial input transformation, we show that this behavior can therefore be approximated by training a single neural network -- using a technique that we call $\\Delta-$UQ -- that estimates uncertainty around prediction by marginalizing out the effect of the biases during inference. We show that $\\Delta-$UQ's uncertainty estimates are superior to many of the current methods on a variety of benchmarks-- outlier rejection, calibration under distribution shift, and sequential design optimization of black box functions. Code for $\\Delta-$UQ can be accessed at github.com/LLNL/DeltaUQ\n"}}
{"id": "Bk1hklAuZyh", "cdate": 1633790968480, "mdate": null, "content": {"title": "Unsupervised Attribute Alignment for Characterizing Distribution Shift", "abstract": "Detecting and addressing distribution shift is an important task in machine learning. However, most of the machine learning solutions to deal with distribution shift lack the capability to identify the key characteristics of such a shift and present it to humans in an interpretable way. In this work, we propose a novel framework to compare two datasets and identify distribution shifts between the datasets. The key challenge is to identify generative factors of variation, which we refer to as attributes, that characterize the similarities and differences between the datasets. Producing this characterization requires finding a set of attributes that can be aligned between the two datasets and sets that are unique. We address this challenge through a novel approach that performs both attribute discovery and attribute alignment across the two distributions. We evaluate our algorithm's effectiveness at accurately identifying these attributes in two separate experiments, one involving two variants of MNIST and a second experiment involving two versions of dSprites."}}
{"id": "o2Pgj6cCPXt", "cdate": 1632875714206, "mdate": null, "content": {"title": "A Biology-Informed Similarity Metric for Simulated Patches of Human Cell Membrane", "abstract": "Complex scientific inquiries rely increasingly upon large and autonomous multiscale simulation campaigns, which fundamentally require similarity metrics to quantify \"sufficient'' changes among data and/or configurations. However, subject matter experts are often unable to articulate similarity precisely or in terms of well-formulated definitions, especially when new hypotheses are to be explored, making it challenging to design a meaningful metric.  Furthermore, the key to practical usefulness of such metrics to enable autonomous simulations lies in in situ inference, which requires generalization to possibly substantial distributional shifts in unseen, future data. \n\nHere, we address these challenges in a cancer biology application and develop a meaningful similarity metric for \"patches\" --- regions of simulated human cell membrane that express interactions between certain proteins of interest and relevant lipids. In the absence of well-defined conditions for similarity, we leverage several biology-informed notions about data and the underlying simulations to impose inductive biases on our metric learning framework, resulting in a suitable similarity metric that also generalizes well to significant distributional shifts encountered during the deployment. We combine these intuitions to organize the learned metric space in a multiscale manner, which makes the metric robust to incomplete and even contradictory intuitions. Our approach delivers a metric that not only performs well on the conditions used for its development and other relevant criteria, but also learns key temporal relationships from statistical mechanics without ever being exposed to any such information during training."}}
{"id": "qXBpzbrH7xS", "cdate": 1626450727628, "mdate": 1626450727628, "content": {"title": "MULTIPLE SUBSPACE ALIGNMENT IMPROVES DOMAIN ADAPTATION", "abstract": "We present a novel unsupervised domain adaptation (DA)\nmethod for cross-domain visual recognition. Though subspace methods have found success in DA, their performance\nis often limited due to the assumption of approximating an\nentire dataset using a single low-dimensional subspace. Instead, we develop a method to effectively represent the source\nand target datasets via a collection of low-dimensional subspaces, and subsequently align them by exploiting the natural\ngeometry of the space of subspaces, on the Grassmann manifold. We demonstrate the effectiveness of this approach,\nusing empirical studies on two widely used benchmarks, with\nstate of the art domain adaptation performance."}}
{"id": "cEkN1lA21kM", "cdate": 1596127052823, "mdate": null, "content": {"title": "Unsupervised Audio Source Separation using Generative Priors", "abstract": "State-of-the-art under-determined audio source separation systems rely on supervised end-end training of carefully tailored neural network architectures operating either in the time or the spectral domain. However, these methods are severely challenged in terms of requiring access to expensive source level labeled data and being specific to a given set of sources and the mixing process, which demands complete re-training when those assumptions change. This strongly emphasizes the need for unsupervised methods that can leverage the recent advances in data-driven modeling, and compensate for the lack of labeled data through meaningful priors. To this end, we propose a novel approach for audio source separation based on generative priors trained on individual sources. Through the use of projected gradient descent optimization, our approach simultaneously searches in the source-specific latent spaces to effectively recover the constituent sources. Though the generative priors can be defined in the time domain directly, e.g. WaveGAN, we find that using spectral domain loss functions for our optimization leads to good-quality source estimates. Our empirical studies on standard spoken digit and instrument datasets clearly demonstrate the effectiveness of our approach over classical as well as state-of-the-art unsupervised baselines.\n"}}
{"id": "POSc6CYf28Y", "cdate": 1596126952627, "mdate": null, "content": {"title": "Improved Surrogates in Inertial Confinement Fusion with Manifold and Cycle Consistencies", "abstract": "Neural networks have become the method of choice in surrogate modeling because of their ability to characterize arbitrary, high-dimensional functions in a data-driven fashion. This paper advocates for the training of surrogates that are 1) consistent with the physical manifold, resulting in physically meaningful predictions, and 2) cyclically consistent with a jointly trained inverse model; i.e., backmapping predictions through the inverse results in the original input parameters. We find that these two consistencies lead to surrogates that are superior in terms of predictive performance, are more resilient to sampling artifacts, and tend to be more data efficient. Using inertial confinement fusion (ICF) as a test-bed problem, we model a one-dimensional semianalytic numerical simulator and demonstrate the effectiveness of our approach.\n"}}
{"id": "G8d0chPpaM4", "cdate": 1596126874531, "mdate": null, "content": {"title": "Rate-Invariant Autoencoding of Time-Series", "abstract": "For time-series classification and retrieval applications, an important requirement is to develop representations/metrics that\nare robust to re-parametrization of the time-axis. Temporal\nre-parametrization as a model can account for variability in\nthe underlying generative process, sampling rate variations, or\nplain temporal mis-alignment. In this paper, we extend prior\nwork in disentangling latent spaces of autoencoding models,\nto design a novel architecture to learn rate-invariant latent\ncodes in a completely unsupervised fashion. Unlike conventional neural network architectures, this method allows to explicitly disentangle temporal parameters in the form of orderpreserving diffeomorphisms with respect to a learnable template. This makes the latent space more easily interpretable.\nWe show the efficacy of our approach on a synthetic dataset\nand a real dataset for hand action-recognition."}}
{"id": "uniyuqCRcw", "cdate": 1596126722372, "mdate": null, "content": {"title": "Generative Patch Priors for Practical Compressive Image Recovery", "abstract": "In this paper, we propose the generative patch prior (GPP) that defines a generative prior for compressive image recovery, based on patch-manifold models. Unlike learned, image-level priors that are restricted to the range space of a pre-trained generator, GPP can recover a wide variety of natural images using a pre-trained patch generator. Additionally, GPP retains the benefits of generative priors like high reconstruction quality at extremely low sensing rates, while also being much more generally applicable. We show that GPP outperforms several unsupervised and supervised techniques on three different sensing models -- linear compressive sensing with known, and unknown calibration settings, and the non-linear phase retrieval problem. Finally, we propose an alternating optimization strategy using GPP for joint calibration-and-reconstruction which performs favorably against several baselines on a real world, un-calibrated compressive sensing dataset."}}
{"id": "u2cgwjYPzZ", "cdate": 1578682307558, "mdate": null, "content": {"title": "MimicGAN: Robust Projection onto Image Manifolds with Corruption Mimicking", "abstract": "In the past few years, generative models like Generative\nAdversarial Networks (GANs) have dramatically advanced\nour ability to represent and parameterize high-dimensional,\nnon-linear image manifolds. As a result, they have been\nwidely adopted across a variety of applications, ranging\nfrom challenging inverse problems like image completion, to\nbeing used as a prior in problems such as anomaly detection\nand adversarial defense. A recurring theme in many of these\napplications is the notion of projecting an image observation\nonto the manifold that is inferred by the generator. In this\ncontext, Projected Gradient Descent (PGD) has been the\nmost popular approach, which essentially searches for a latent representation with the goal of minimizing discrepancy\nbetween a generated image and the given observation. However, PGD is an extremely brittle optimization technique that\nfails to identify the right projection when the observation\nis corrupted, even by a small amount. Unfortunately, such\ncorruptions are common in the real world, for example arbitrary images with unknown crops, rotations, missing pixels,\nor other kinds of distribution shifts requiring a more robust\nprojection technique. In this paper we propose corruptionmimicking, a new strategy that utilizes a surrogate network\nto approximate the unknown corruption directly at test time,\nwithout the need for additional supervision or data augmentation. The proposed projection technique significantly\nimproves the robustness of PGD under a wide variety of\ncorruptions, thereby enabling a more effective use of GANs\nin real-world applications. More importantly, we show that\nour approach produces state-of-the-art performance in several GAN-based applications \u2013 anomaly detection, domain\nadaptation, and adversarial defense, that rely on an accurate\nprojection."}}
