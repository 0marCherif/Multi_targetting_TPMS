{"id": "1jT2hXdeOp8", "cdate": 1679993969834, "mdate": 1679993969834, "content": {"title": "On the Existence of Monge Maps for the Gromov-Wasserstein Problem", "abstract": "In this work, we study the structure of minimizers of the quadratic Gromov\u2013Wasserstein (GW)\nproblem on Euclidean spaces for two different costs. The first one is the scalar product for which we\nprove that it is always possible to find optimizers as Monge maps and we detail the structure of such\noptimal maps. The second cost is the squared Euclidean distance for which we show that the worst\ncase scenario is the existence of a bi-map structure. Both results are direct and indirect consequences\nof an existence result of optimal maps in the standard optimal transportation problem for costs\nthat are defined by submersions. In dimension one for the squared Euclidean distance, we show\nnumerical evidence for a negative answer to the existence of a Monge map under the conditions of\nBrenier\u2019s theorem, suggesting that our result cannot be improved in general. In addition, we show\nthat a monotone map is optimal in some non-symmetric situations, thereby giving insight on why\nsuch a map often appears to be optimal in numerical experiments."}}
{"id": "WMnoLsXoZxd", "cdate": 1661412808064, "mdate": 1661412808064, "content": {"title": "Topological Uncertainty: Monitoring trained neural networks through persistence of activation graphs", "abstract": "Although neural networks are capable of reaching\nastonishing performances on a wide variety of con-\ntexts, properly training networks on complicated\ntasks requires expertise and can be expensive from\na computational perspective. In industrial appli-\ncations, data coming from an open-world setting\nmight widely differ from the benchmark datasets on\nwhich a network was trained. Being able to monitor\nthe presence of such variations without retraining\nthe network is of crucial importance. In this article,\nwe develop a method to monitor trained neural net-\nworks based on the topological properties of their\nactivation graphs. To each new observation, we as-\nsign a Topological Uncertainty, a score that aims to\nassess the reliability of the predictions by investi-\ngating the whole network instead of its final layer\nonly, as typically done by practitioners. Our ap-\nproach entirely works at a post-training level and\ndoes not require any assumption on the network\narchitecture, optimization scheme, nor the use of\ndata augmentation or auxiliary datasets; and can be\nfaithfully applied on a large range of network ar-\nchitectures and data types. We showcase experi-\nmentally the potential of Topological Uncertainty\nin the context of trained network selection, Out-Of-\nDistribution detection, and shift-detection, both on\nsynthetic and real datasets of images and graphs."}}
{"id": "f5fpOEZhN-n", "cdate": 1661412688185, "mdate": 1661412688185, "content": {"title": "Estimation and Quantization of Expected Persistence Diagrams", "abstract": "Persistence diagrams (PDs) are the most com-\nmon descriptors used to encode the topology of\nstructured data appearing in challenging learn-\ning tasks; think e.g. of graphs, time series or\npoint clouds sampled close to a manifold. Given\nrandom objects and the corresponding distribu-\ntion of PDs, one may want to build a statisti-\ncal summary\u2014such as a mean\u2014of these random\nPDs, which is however not a trivial task as the\nnatural geometry of the space of PDs is not lin-\near. In this article, we study two such summaries,\nthe Expected Persistence Diagram (EPD), and its\nquantization. The EPD is a measure supported\non R2, which may be approximated by its em-\npirical counterpart. We prove that this estimator\nis optimal from a minimax standpoint on a large\nclass of models with a parametric rate of conver-\ngence. The empirical EPD is simple and efficient\nto compute, but possibly has a very large sup-\nport, hindering its use in practice. To overcome\nthis issue, we propose an algorithm to compute\na quantization of the empirical EPD, a measure\nwith small support which is shown to approxi-\nmate with near-optimal rates a quantization of the\ntheoretical EPD."}}
{"id": "EuqlcetAax", "cdate": 1661412640099, "mdate": 1661412640099, "content": {"title": "An Homogeneous Unbalanced Regularized Optimal Transport model with applications to Optimal Transport with Boundary", "abstract": "This work studies how the introduction of the entropic regularization term in unbalanced\nOptimal Transport (OT) models may alter their homogeneity with respect to the input measures.\nWe observe that in common settings (including balanced OT and unbalanced OT with Kullback-\nLeibler divergence to the marginals), although the optimal transport cost itself is not homogeneous,\noptimal transport plans and the so-called Sinkhorn divergences are indeed homogeneous. However,\nhomogeneity does not hold in more general Unbalanced Regularized Optimal Transport (UROT)\nmodels, for instance those using the Total Variation as divergence to the marginals. We propose\nto modify the entropic regularization term to retrieve an UROT model that is homogeneous while\npreserving most properties of the standard UROT model. We showcase the importance of using\nour Homogeneous UROT (HUROT) model when it comes to regularize Optimal Transport with\nBoundary, a transportation model involving a spatially varying divergence to the marginals for\nwhich the standard (inhomogeneous) UROT model would yield inappropriate behavior."}}
{"id": "yJCYZb5WxDX", "cdate": 1661412601315, "mdate": 1661412601315, "content": {"title": "A Gradient Sampling Algorithm for Stratified Maps with Applications to Topological Data Analysis", "abstract": "We introduce a novel gradient descent algorithm extending the well-known Gradient Sampling\nmethodology to the class of stratifiably smooth objective functions, which are defined as locally Lipschitz\nfunctions that are smooth on some regular pieces\u2014called the strata\u2014of the ambient Euclidean space. For\nthis class of functions, our algorithm achieves a sub-linear convergence rate. We then apply our method\nto objective functions based on the (extended) persistent homology map computed over lower-star\nfilters, which is a central tool of Topological Data Analysis. For this, we propose an efficient exploration\nof the corresponding stratification by using the Cayley graph of the permutation group. Finally, we\nprovide benchmark and novel topological optimization problems, in order to demonstrate the utility\nand applicability of our framework"}}
{"id": "SeZlCN-ypgq", "cdate": 1646223669811, "mdate": null, "content": {"title": "RipsNet: a general architecture for fast and robust estimation of the persistent homology of point clouds", "abstract": "The use of topological descriptors in modern machine learning applications, such as Persistence Diagrams (PDs) arising from Topological Data Analysis (TDA), has shown great potential in various domains.\nHowever, their practical use in applications is often hindered by two major limitations: the computational complexity required to compute such descriptors exactly, and their sensitivity to even low-level proportions of outliers. In this work, we propose to bypass these two burdens in a data-driven setting by entrusting the estimation of (vectorization of) PDs built on top of point clouds to a neural network architecture that we call RipsNet. Once trained on a given data set, RipsNet can estimate topological descriptors on test data very efficiently with generalization capacity. Furthermore, we prove that RipsNet is robust to input perturbations in terms of the 1-Wasserstein distance, a major improvement over the standard computation of PDs that only enjoys Hausdorff stability, yielding RipsNet to substantially outperform exactly-computed PDs in noisy settings. We showcase the use of RipsNet on both synthetic and real-world data. Our implementation will be made freely and publicly available as part of an open-source library."}}
{"id": "VAavmuiylZ", "cdate": 1622445402320, "mdate": null, "content": {"title": "Understanding the topology and the geometry of the persistence diagram space via optimal partial transport.", "abstract": "Despite the obvious similarities between the metrics used in topological data analysis and those of optimal transport, an optimal-transport based formalism to study persistence diagrams and similar topological descriptors has yet to come. In this article, by considering the space of persistence diagrams as a measure space, and by observing that its metrics can be expressed as solutions of optimal partial transport problems, we introduce a generalization of persistence diagrams, namely Radon measures supported on the upper half plane. Such measures naturally appear in topological data analysis when considering continuous representations of persistence diagrams (e.g. persistence surfaces) but also as limits for laws of large numbers on persistence diagrams or as expectations of probability distributions on the persistence diagrams space. We study the topological properties of this new space, which will also hold for the closed subspace of persistence diagrams. New results include a characterization of convergence with respect to transport metrics, the existence of Fr\u00e9chet means for any distribution of diagrams, and an exhaustive description of continuous linear representations of persistence diagrams. We also showcase the usefulness of this framework to study random persistence diagrams by providing several statistical results made meaningful thanks to this new formalism."}}
{"id": "NPMJt7eKB4Y", "cdate": 1615281330166, "mdate": null, "content": {"title": "PersLay: A Neural Network Layer for Persistence Diagrams andNew Graph Topological Signatures", "abstract": "Persistence diagrams, the most common de-scriptors of Topological Data Analysis, en-code topological properties of data and havealready proved pivotal in many different ap-plications of data science. However, since themetric space of persistence diagrams is notHilbert, they end up being difficult inputs formost Machine Learning techniques. To ad-dress this concern, several vectorization meth-ods have been put forward that embed persis-tence diagrams into either finite-dimensionalEuclidean space or implicit infinite dimen-sional Hilbert space with kernels.In this work, we focus on persistence diagramsbuilt on top of graphs. Relying on extendedpersistence theory and the so-called heat ker-nel signature, we show how graphs can beencoded by (extended) persistence diagramsin a provably stable way. We then propose ageneral and versatile framework for learningvectorizations of persistence diagrams, whichencompasses most of the vectorization tech-niques used in the literature. We finally show-case the experimental strength of our setup byachieving competitive scores on classificationtasks on real-life graph datasets."}}
{"id": "ry-8CuZdbr", "cdate": 1514764800000, "mdate": null, "content": {"title": "Large Scale computation of Means and Clusters for Persistence Diagrams using Optimal Transport", "abstract": "Persistence diagrams (PDs) are now routinely used to summarize the underlying topology of complex data. Despite several appealing properties, incorporating PDs in learning pipelines can be challenging because their natural geometry is not Hilbertian. Indeed, this was recently exemplified in a string of papers which show that the simple task of averaging a few PDs can be computationally prohibitive. We propose in this article a tractable framework to carry out standard tasks on PDs at scale, notably evaluating distances, estimating barycenters and performing clustering. This framework builds upon a reformulation of PD metrics as optimal transport (OT) problems. Doing so, we can exploit recent computational advances: the OT problem on a planar grid, when regularized with entropy, is convex can be solved in linear time using the Sinkhorn algorithm and convolutions. This results in scalable computations that can stream on GPUs. We demonstrate the efficiency of our approach by carrying out clustering with diagrams metrics on several thousands of PDs, a scale never seen before in the literature."}}
