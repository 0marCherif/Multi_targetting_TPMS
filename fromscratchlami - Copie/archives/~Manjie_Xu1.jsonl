{"id": "wfzsvaDS7BC", "cdate": 1683945679936, "mdate": null, "content": {"title": "Artificial Social Intelligence: A Comparative and Holistic View", "abstract": "In  addition  to  a  physical  comprehension  of  the  world,  humans  possess  a  high  social  intelligence\u2014the  intelligence  that  senses\nsocial events, infers the goals and intents of others, and facilitates social interaction. Notably, humans are distinguished from their\nclosest primate cousins by their social cognitive skills as opposed to their physical counterparts. We believe that artificial social\nintelligence (ASI) will play a crucial role in shaping the future of artificial intelligence (AI). This article begins with a review of ASI\nfrom a cognitive science standpoint, including social perception, theory of mind (ToM), and social interaction. Next, we examine the\nrecently-emerged computational counterpart in the AI community. Finally, we provide an in-depth discussion on topics related to\nASI."}}
{"id": "0DTpO6lLIN", "cdate": 1663850041322, "mdate": null, "content": {"title": "On the Complexity of Bayesian Generalization", "abstract": "We consider the concept generalization at a large scale in a diverse and natural visual spectrum. Established computational modes (\\ie, rule-based or similarity-based) are primarily studied isolated and focus on confined and abstract problem spaces. In this work, we study the two modes when the problem space scales up and the *complexity* of concepts becomes diverse. Specifically, at the **representational level**, we seek to answer how the complexity varies when a visual concept is mapped to the representation space. Prior psychology literature has shown that two types of complexities (*i.e.*, subjective complexity and visual complexity)  (Griffiths and Tenenbaum, 2003) build an inverted-U relation (Donderi, 2006; Sun and Firestone, 2021). Leveraging *Representativeness of Attribute* (RoA), we computationally confirm the following observation: Models use attributes with high RoA to describe visual concepts, and the description length falls in an inverted-U relation with the increment on visual complexity. Meanwhile, at the **computational level**, we aim to answer how the complexity of representation affects the shift between the rule- and similarity-based generalization. We hypothesize that category-conditioned visual modeling estimates the co-occurrence frequency between visual and categorical attributes, thus having the potential to serve as the prior for the natural visual world. Experimental results show that representations with relatively high subjective complexity outperform those with relatively low subjective complexity in the rule-based generalization, while the trend is opposite in the similarity-based generalization."}}
{"id": "0MqQ88Z2Kta", "cdate": 1663849883834, "mdate": null, "content": {"title": "Evaluating and Inducing Personality in Pre-trained Language Models", "abstract": "Originated as a philosophical quest, personality discerns how individuals differ from each other in terms of thinking, feeling, and behaving. Toward building social machines that work with humans on a daily basis, we are motivated to ask: (1) Do existing Large Language Models (LLMs) possess personalities, akin to their human counterparts? (2) If so, how can we evaluate them? (3) Further, given this evaluation framework, how can we induce a certain personality in a fully controllable fashion? To tackle these three questions, we propose the Machine Personality Inventory (MPI) dataset for evaluating the machine personality; MPI follows standardized personality tests, built upon the Big Five Personality Factors (Big Five) theory and personality assessment inventories. By evaluating models with MPI, we provide the first piece of evidence showing the existence of personality in LLMs. We further devise a Chain Prompting method to induce LLMs with a specific personality in a controllable manner, capable of producing diversified behaviors. We hope to shed light on future studies by adopting personality as the essential guide for various downstream tasks, building more human-like and in situ dialogue agents."}}
{"id": "rxvj1wYAAsX", "cdate": 1640995200000, "mdate": 1667357182320, "content": {"title": "EST: Evaluating Scientific Thinking in Artificial Agents", "abstract": "Theoretical ideas and empirical research have shown us a seemingly surprising result: children, even very young toddlers, demonstrate learning and thinking in a strikingly similar manner to scientific reasoning in formal research. Encountering a novel phenomenon, children make hypotheses against data, conduct causal inference from observation, test their theory via experimentation, and correct the proposition if inconsistency arises. Rounds of such processes continue until the underlying mechanism is found. Towards building machines that can learn and think like people, one natural question for us to ask is: whether the intelligence we achieve today manages to perform such a scientific thinking process, and if any, at what level. In this work, we devise the EST environment for evaluating the scientific thinking ability in artificial agents. Motivated by the stream of research on causal discovery, we build our interactive EST environment based on Blicket detection. Specifically, in each episode of EST, an agent is presented with novel observations and asked to figure out all objects' Blicketness. At each time step, the agent proposes new experiments to validate its hypothesis and updates its current belief. By evaluating Reinforcement Learning (RL) agents on both a symbolic and visual version of this task, we notice clear failure of today's learning methods in reaching a level of intelligence comparable to humans. Such inefficacy of learning in scientific thinking calls for future research in building humanlike intelligence."}}
{"id": "k--MOzEGTP", "cdate": 1640995200000, "mdate": 1667455784150, "content": {"title": "MPI: Evaluating and Inducing Personality in Pre-trained Language Models", "abstract": "Originated as a philosophical quest, personality discerns how individuals differ from each other in terms of thinking, feeling, and behaving. Towards building social machines that work with humans on a daily basis, we are motivated to ask: (1) Do existing pre-trained language models possess personality, akin to their human counterpart? If so, (2) how can we evaluate them? Further, given this evaluation framework, (3) how can we induce a certain personality in a fully controllable fashion? To tackle these three questions, we propose the Machine Personality Inventory (MPI) dataset for evaluating the machine personality; MPI follows standardized personality tests, built upon the Big Five Personality Factors (Big Five) theory and personality assessment inventories. By evaluating models with MPI, we provide the first piece of evidence showing the existence of personality in pre-trained language models. We further devise a Chain Prompting method to induce the language model with a specific personality in a controllable manner, capable of producing diversified behaviors. We hope to shed light on future studies by adopting personality as the essential psychological guidance for various downstream tasks, building more human-like and in situ dialogue agents."}}
{"id": "aE3-ZGcRqZ-", "cdate": 1640995200000, "mdate": 1667455784145, "content": {"title": "EST: Evaluating Scientific Thinking in Artificial Agents", "abstract": "Theoretical ideas and empirical research have shown us a seemingly surprising result: children, even very young toddlers, demonstrate learning and thinking in a strikingly similar manner to scientific reasoning in formal research. Encountering a novel phenomenon, children make hypotheses against data, conduct causal inference from observation, test their theory via experimentation, and correct the proposition if inconsistency arises. Rounds of such processes continue until the underlying mechanism is found. Towards building machines that can learn and think like people, one natural question for us to ask is: whether the intelligence we achieve today manages to perform such a scientific thinking process, and if any, at what level. In this work, we devise the EST environment for evaluating the scientific thinking ability in artificial agents. Motivated by the stream of research on causal discovery, we build our interactive EST environment based on Blicket detection. Specifically, in each episode of EST, an agent is presented with novel observations and asked to figure out all objects' Blicketness. At each time step, the agent proposes new experiments to validate its hypothesis and updates its current belief. By evaluating Reinforcement Learning (RL) agents on both a symbolic and visual version of this task, we notice clear failure of today's learning methods in reaching a level of intelligence comparable to humans. Such inefficacy of learning in scientific thinking calls for future research in building humanlike intelligence."}}
{"id": "Jos0P6i59K", "cdate": 1640995200000, "mdate": 1681662208032, "content": {"title": "To think inside the box, or to think out of the box? Scientific discovery via the reciprocation of insights and concepts", "abstract": "If scientific discovery is one of the main driving forces of human progress, insight is the fuel for the engine, which has long attracted behavior-level research to understand and model its underlying cognitive process. However, current tasks that abstract scientific discovery mostly focus on the emergence of insight, ignoring the special role played by domain knowledge. In this concept paper, we view scientific discovery as an interplay between $thinking \\ out \\ of \\ the \\ box$ that actively seeks insightful solutions and $thinking \\ inside \\ the \\ box$ that generalizes on conceptual domain knowledge to keep correct. Accordingly, we propose Mindle, a semantic searching game that triggers scientific-discovery-like thinking spontaneously, as infrastructure for exploring scientific discovery on a large scale. On this basis, the meta-strategies for insights and the usage of concepts can be investigated reciprocally. In the pilot studies, several interesting observations inspire elaborated hypotheses on meta-strategies, context, and individual diversity for further investigations."}}
{"id": "F5ETDIQ1ofO", "cdate": 1640995200000, "mdate": 1681550025574, "content": {"title": "On the Complexity of Bayesian Generalization", "abstract": ""}}
{"id": "EUoifqKuqQ", "cdate": 1640995200000, "mdate": 1667357182296, "content": {"title": "MPI: Evaluating and Inducing Personality in Pre-trained Language Models", "abstract": "Originated as a philosophical quest, personality discerns how individuals differ from each other in terms of thinking, feeling, and behaving. Towards building social machines that work with humans on a daily basis, we are motivated to ask: (1) Do existing pre-trained language models possess personality, akin to their human counterpart? If so, (2) how can we evaluate them? Further, given this evaluation framework, (3) how can we induce a certain personality in a fully controllable fashion? To tackle these three questions, we propose the Machine Personality Inventory (MPI) dataset for evaluating the machine personality; MPI follows standardized personality tests, built upon the Big Five Personality Factors (Big Five) theory and personality assessment inventories. By evaluating models with MPI, we provide the first piece of evidence showing the existence of personality in pre-trained language models. We further devise a Chain Prompting method to induce the language model with a specific personality in a controllable manner, capable of producing diversified behaviors. We hope to shed light on future studies by adopting personality as the essential psychological guidance for various downstream tasks, building more human-like and in situ dialogue agents."}}
