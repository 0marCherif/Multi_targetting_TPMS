{"id": "lR8o0lDSBo1", "cdate": 1672531200000, "mdate": 1680359029447, "content": {"title": "Measuring uncertainty in human visual segmentation", "abstract": ""}}
{"id": "jKMtN7JfR2", "cdate": 1640995200000, "mdate": 1680359029579, "content": {"title": "Unsupervised Video Segmentation Algorithms Based On Flexibly Regularized Mixture Models", "abstract": ""}}
{"id": "WOBL26_jZ_j", "cdate": 1631697520854, "mdate": 1631697520854, "content": {"title": "The Portilla-Simoncelli Texture Model: towards Understanding the Early Visual Cortex ", "abstract": "Texture synthesis is a prolific subarea in computer vision where statistical methods are often successful. The Portilla and Simoncelli (PS) texture algorithm is one of such methods that became very popular and has influenced visual perception studies. For many reasons it can still be considered as a state-of-the art texture synthesis algorithm: (i) it generates textures that are often indistinguishable from the original without scrutiny; (ii) it relies on few parameters compared to recent deep learning methods; (iii) recent algorithms often compare to it. Here, we review the scientific impact of this algorithm and give a detailed explanation. Briefly, the PS algorithm synthesizes a new texture by iteratively imposing to a Gaussian white noise image a set of high-order statistics of wavelet coefficients precomputed on a texture example. After few iterations the initial white noise image is transformed into a texture that is similar to the texture example. We provide a fast C++ implementation, evaluate the effect of the algorithm parameters and illustrate its capabilities with many synthesis examples. In addition, we propose two notable new features to the original implementation: (i) the possibility to interpolate between two textures; (ii) the possibility to handle non-periodicity using the 'periodic+smooth' decomposition."}}
{"id": "baO3q2q7MTi", "cdate": 1631697428156, "mdate": 1631697428156, "content": {"title": "Flexibly Regularized Mixture Models and Application to Image Segmentation", "abstract": "Probabilistic finite mixture models are widely used for unsupervised clustering. These models can often be improved by adapting them to the topology of the data. For instance, in order to classify spatially adjacent data points similarly, it is common to introduce a Laplacian constraint on the posterior probability that each data point belongs to a class. Alternatively, the mixing probabilities can be treated as free parameters, while assuming Gauss-Markov or more complex priors to regularize those mixing probabilities. However, these approaches are constrained by the shape of the prior and often lead to complicated or intractable inference. Here, we propose a new parametrization of the Dirichlet distribution to flexibly regularize the mixing probabilities of over-parametrized mixture distributions. Using the Expectation-Maximization algorithm, we show that our approach allows us to define any linear update rule for the mixing probabilities, including spatial smoothing regularization as a special case. We then show that this flexible design can be extended to share class information between multiple mixture models. We apply our algorithm to artificial and natural image segmentation tasks, and we provide quantitative and qualitative comparison of the performance of Gaussian and Student-t mixtures on the Berkeley Segmentation Dataset. We also demonstrate how to propagate class information across the layers of deep convolutional neural networks in a probabilistically optimal way, suggesting a new interpretation for feedback signals in biological visual systems. Our flexible approach can be easily generalized to adapt probabilistic mixture models to arbitrary data topologies. "}}
{"id": "ehm7fUZ9kR", "cdate": 1609459200000, "mdate": 1680359029445, "content": {"title": "The Portilla-Simoncelli Texture Model: towards Understanding the Early Visual Cortex", "abstract": ""}}
{"id": "C27RTX2HBY2", "cdate": 1577836800000, "mdate": null, "content": {"title": "Texture Interpolation for Probing Visual Perception", "abstract": "Texture synthesis models are important tools for understanding visual processing. In particular, statistical approaches based on neurally relevant features have been instrumental in understanding aspects of visual perception and of neural coding. New deep learning-based approaches further improve the quality of synthetic textures. Yet, it is still unclear why deep texture synthesis performs so well, and applications of this new framework to probe visual perception are scarce. Here, we show that distributions of deep convolutional neural network (CNN) activations of a texture are well described by elliptical distributions and therefore, following optimal transport theory, constraining their mean and covariance is sufficient to generate new texture samples. Then, we propose the natural geodesics (ie the shortest path between two points) arising with the optimal transport metric to interpolate between arbitrary textures. Compared to other CNN-based approaches, our interpolation method appears to match more closely the geometry of texture perception, and our mathematical framework is better suited to study its statistical nature. We apply our method by measuring the perceptual scale associated to the interpolation parameter in human observers, and the neural sensitivity of different areas of visual cortex in macaque monkeys."}}
{"id": "dIcIPLxX9x4", "cdate": 1546300800000, "mdate": null, "content": {"title": "Combining mixture models with linear mixing updates: multilayer image segmentation and synthesis", "abstract": "Probabilistic finite mixture models are widely used for unsupervised clustering. These models can often be improved by adapting them to the topology of the data. For instance, in order to classify spatially adjacent data points similarly, it is common to introduce a Laplacian constraint on the posterior probability that each data point belongs to a class. Alternatively, the mixing probabilities can be treated as free parameters, while assuming Gauss-Markov or more complex priors to regularize those mixing probabilities. However, these approaches are constrained by the shape of the prior and often lead to complicated or intractable inference. Here, we propose a new parametrization of the Dirichlet distribution to flexibly regularize the mixing probabilities of over-parametrized mixture distributions. Using the Expectation-Maximization algorithm, we show that our approach allows us to define any linear update rule for the mixing probabilities, including spatial smoothing regularization as a special case. We then show that this flexible design can be extended to share class information between multiple mixture models. We apply our algorithm to artificial and natural image segmentation tasks, and we provide quantitative and qualitative comparison of the performance of Gaussian and Student-t mixtures on the Berkeley Segmentation Dataset. We also demonstrate how to propagate class information across the layers of deep convolutional neural networks in a probabilistically optimal way, suggesting a new interpretation for feedback signals in biological visual systems. Our flexible approach can be easily generalized to adapt probabilistic mixture models to arbitrary data topologies."}}
{"id": "N6ZrYDJ9C-V", "cdate": 1514764800000, "mdate": null, "content": {"title": "Control Synthesis for Stochastic Switched Systems using the Tamed Euler Method", "abstract": "In this paper, we explain how, under the one-sided Lipschitz (OSL) hypothesis, one can find an error bound for a variant of the Euler-Maruyama approximation method for stochastic switched systems. We then explain how this bound can be used to control stochastic switched switched system in order to stabilize them in a given region. The method is illustrated on several examples of the literature."}}
{"id": "DG0i0iX7xsi", "cdate": 1514764800000, "mdate": null, "content": {"title": "Bayesian Modeling of Motion Perception Using Dynamical Stochastic Textures", "abstract": "A common practice to account for psychophysical biases in vision is to frame them as consequences of a dynamic process relying on optimal inference with respect to a generative model. The study presented here details the complete formulation of such a generative model intended to probe visual motion perception with a dynamic texture model. It is derived in a set of axiomatic steps constrained by biological plausibility. We extend previous contributions by detailing three equivalent formulations of this texture model. First, the composite dynamic textures are constructed by the random aggregation of warped patterns, which can be viewed as three-dimensional gaussian fields. Second, these textures are cast as solutions to a stochastic partial differential equation (sPDE). This essential step enables real-time, on-the-fly texture synthesis using time-discretized autoregressive processes. It also allows for the derivation of a local motion-energy model, which corresponds to the log likelihood of the probability density. The log likelihoods are essential for the construction of a Bayesian inference framework. We use the dynamic texture model to psychophysically probe speed perception in humans using zoom-like changes in the spatial frequency content of the stimulus. The human data replicate previous findings showing perceived speed to be positively biased by spatial frequency increments. A Bayesian observer who combines a gaussian likelihood centered at the true speed and a spatial frequency dependent width with a \u201cslow-speed prior\u201d successfully accounts for the perceptual bias. More precisely, the bias arises from a decrease in the observer's likelihood width estimated from the experiments as the spatial frequency increases. Such a trend is compatible with the trend of the dynamic texture likelihood width."}}
{"id": "1h71aJp8uZp", "cdate": 1514764800000, "mdate": null, "content": {"title": "An Ideal Observer Model to Probe Human Visual Segmentation of Natural Images", "abstract": "Visual segmentation is a key perceptual function that partitions visual space and allows for detection, recognition and discrimination of objects in complex environments. The processes underlying human segmentation of natural images are still poorly understood. In part, this is because we lack segmentation models consistent with experimental and theoretical knowledge in visual neuroscience. Biological sensory systems have been shown to approximate probabilistic inference to interpret their inputs. This requires a generative model that captures both the statistics of the sensory inputs and expectations about the causes of those inputs. Following this hypothesis, we propose a probabilistic generative model of visual segmentation that combines knowledge about 1) the sensitivity of neurons in the visual cortex to statistical regularities in natural images; and 2) the preference of humans to form contiguous partitions of visual space. We develop an efficient algorithm for training and inference based on expectation-maximization and validate it on synthetic data. Importantly, with the appropriate choice of the prior, we derive an intuitive closed--form update rule for assigning pixels to segments: at each iteration, the pixel assignment probabilities to segments is the sum of the evidence (i.e. local pixel statistics) and prior (i.e. the assignments of neighboring pixels) weighted by their relative uncertainty. The model performs competitively on natural images from the Berkeley Segmentation Dataset (BSD), and we illustrate how the likelihood and prior components improve segmentation relative to traditional mixture models. Furthermore, our model explains some variability across human subjects as reflecting local uncertainty about the number of segments. Our model thus provides a viable approach to probe human visual segmentation."}}
