{"id": "qLYJu_VMrLX", "cdate": 1640995200000, "mdate": 1667822622257, "content": {"title": "HarrisZ+: Harris corner selection for next-gen image matching pipelines", "abstract": ""}}
{"id": "AGARD2sNPjH", "cdate": 1640995200000, "mdate": 1667822622259, "content": {"title": "OpenGlue: Open Source Graph Neural Net Based Pipeline for Image Matching", "abstract": "We present OpenGlue: a free open-source framework for image matching, that uses a Graph Neural Network-based matcher inspired by SuperGlue \\cite{sarlin20superglue}. We show that including additional geometrical information, such as local feature scale, orientation, and affine geometry, when available (e.g. for SIFT features), significantly improves the performance of the OpenGlue matcher. We study the influence of the various attention mechanisms on accuracy and speed. We also present a simple architectural improvement by combining local descriptors with context-aware descriptors. The code and pretrained OpenGlue models for the different local features are publicly available."}}
{"id": "iej8kWRnPD", "cdate": 1609459200000, "mdate": 1667335559487, "content": {"title": "Efficient Initial Pose-Graph Generation for Global SfM", "abstract": "We propose ways to speed up the initial pose-graph generation for global Structure-from-Motion algorithms. To avoid forming tentative point correspondences by FLANN and geometric verification by RANSAC, which are the most time-consuming steps of the pose-graph creation, we propose two new methods -- built on the fact that image pairs usually are matched consecutively. Thus, candidate relative poses can be recovered from paths in the partly-built pose-graph. We propose a heuristic for the A* traversal, considering global similarity of images and the quality of the pose-graph edges. Given a relative pose from a path, descriptor-based feature matching is made \"light-weight\" by exploiting the known epipolar geometry. To speed up PROSAC-based sampling when RANSAC is applied, we propose a third method to order the correspondences by their inlier probabilities from previous estimations. The algorithms are tested on 402130 image pairs from the 1DSfM dataset and they speed up the feature matching 17 times and pose estimation 5 times. The source code will be made public."}}
{"id": "OTkDvOMyyq", "cdate": 1609459200000, "mdate": 1667822622378, "content": {"title": "Learning and Crafting for the Wide Multiple Baseline Stereo", "abstract": "This thesis introduces the wide multiple baseline stereo (WxBS) problem. WxBS, a generalization of the standard wide baseline stereo problem, considers the matching of images that simultaneously differ in more than one image acquisition factor such as viewpoint, illumination, sensor type, or where object appearance changes significantly, e.g., over time. A new dataset with the ground truth, evaluation metric and baselines has been introduced. The thesis presents the following improvements of the WxBS pipeline. (i) A loss function, called HardNeg, for learning a local image descriptor that relies on hard negative mining within a mini-batch and on the maximization of the distance between the closest positive and the closest negative patches. (ii) The descriptor trained with the HardNeg loss, called HardNet, is compact and shows state-of-the-art performance in standard matching, patch verification and retrieval benchmarks. (iii) A method for learning the affine shape, orientation, and potentially other parameters related to geometric and appearance properties of local features. (iv) A tentative correspondences generation strategy which generalizes the standard first to second closest distance ratio is presented. The selection strategy, which shows performance superior to the standard method, is applicable to either hard-engineered descriptors like SIFT, LIOP, and MROGH or deeply learned like HardNet. (v) A feedback loop is introduced for the two-view matching problem, resulting in MODS -- matching with on-demand view synthesis -- algorithm. MODS is an algorithm that handles a viewing angle difference even larger than the previous state-of-the-art ASIFT algorithm, without a significant increase of computational cost over \"standard\" wide and narrow baseline approaches. Last, but not least, a comprehensive benchmark for local features and robust estimation algorithms is introduced."}}
{"id": "9XDrNEkmiM", "cdate": 1609459200000, "mdate": 1668113701083, "content": {"title": "Image Matching Across Wide Baselines: From Paper to Practice", "abstract": "We introduce a comprehensive benchmark for local features and robust estimation algorithms, focusing on the downstream task\u2014the accuracy of the reconstructed camera pose\u2014as our primary metric. Our pipeline\u2019s modular structure allows easy integration, configuration, and combination of different methods and heuristics. This is demonstrated by embedding dozens of popular algorithms and evaluating them, from seminal works to the cutting edge of machine learning research. We show that with proper settings, classical solutions may still outperform the perceived state of the art. Besides establishing the actual state of the art, the conducted experiments reveal unexpected properties of structure from motion pipelines that can help improve their performance, for both algorithmic and learned methods. Data and code are online ( https://github.com/ubc-vision/image-matching-benchmark ), providing an easy-to-use and flexible framework for the benchmarking of local features and robust estimation methods, both alongside and against top-performing methods. This work provides a basis for the Image Matching Challenge ( https://image-matching-challenge.github.io )."}}
{"id": "qIT2IaVmhrH", "cdate": 1596126639962, "mdate": null, "content": {"title": "Image Matching across Wide Baselines: From Paper to Practice", "abstract": "We introduce a comprehensive benchmark for local features and robust estimation algorithms, focusing on the downstream task \u2013 the accuracy of the reconstructed camera pose \u2013 as our primary metric. Our pipeline\u2019s modular structure allows us to easily integrate, configure, and combine different methods and heuristics. We demonstrate this by embedding dozens of popular algorithms and evaluating them, from seminal works to the cutting edge of machine learning research. We show that with proper settings, classical solutions may still outperform the perceived state of the art.\nBesides establishing the actual state of the art, the experiments conducted in this paper reveal unexpected properties of Structure from Motion (SfM) pipelines that can be exploited to help improve their performance, for both algorithmic and learned methods. Data and code are online, providing an easy-to-use and flexible framework for the benchmarking of local features and robust estimation methods, both alongside and against top-performing methods. This work provides the basis for an open challenge on wide-baseline image matching."}}
{"id": "pYxlvhKDUWtd", "cdate": 1577836800000, "mdate": 1664224087756, "content": {"title": "Saddle: Fast and repeatable features with good coverage", "abstract": ""}}
{"id": "21JTGKq72b", "cdate": 1577836800000, "mdate": 1667822622257, "content": {"title": "Kornia: an Open Source Differentiable Computer Vision Library for PyTorch", "abstract": "This work presents Kornia - an open source computer vision library which consists of a set of differentiable routines and modules to solve generic computer vision problems. The package uses PyTorch as its main backend both for efficiency and to take advantage of the reverse-mode auto-differentiation to define and compute the gradient of complex functions. Inspired by OpenCV, Kornia is composed of a set of modules containing operators that can be inserted inside neural networks to train models to perform image transformations, camera calibration, epipolar geometry, and low level image processing techniques, such as filtering and edge detection that operate directly on high dimensional tensor representations. Examples of classical vision problems implemented using our framework are provided including a benchmark comparing to existing vision libraries."}}
{"id": "HJgSs_7rar", "cdate": 1575463069027, "mdate": null, "content": {"title": "Saddle: Fast and repeatable features with good coverage", "abstract": "A novel similarity-covariant feature detector that extracts points whose neighborhoods, when treated as a 3D intensity surface, have a saddle-like intensity profile is presented. The saddle condition is verified efficiently by intensity comparisons on two concentric rings that must have exactly two dark-to-bright and two bright-to-dark transitions satisfying certain geometric constraints. Saddle is a fast approximation of Hessian detector as ORB, that implements the FAST detector, is for Harris detector. We propose to use the matching strategy called the first geometric inconsistent with binary descriptors that is suitable for our feature detector, including experiments with fix point descriptors hand-crafted and learned.\n\nExperiments show that the Saddle features are general, evenly spread and appearing in high density in a range of images. The Saddle detector is among the fastest proposed. In comparison with detector with similar speed, the Saddle features show superior matching performance on number of challenging datasets. Compared to recently proposed deep-learning based interest point detectors and popular hand-crafted keypoint detectors, evaluated for repeatability in the ApolloScape dataset, the Saddle detectors shows the best performance in most of the street-level view sequences a.k.a. traversals."}}
{"id": "B1ls4aNwDB", "cdate": 1569307954911, "mdate": null, "content": {"title": "MODS: Fast and Robust Method for Two-View Matching", "abstract": "A novel algorithm for wide-baseline matching called MODS \u2013 Matching On\nDemand with view Synthesis \u2013 is presented. The MODS algorithm is experimentally shown to solve a broader range of wide-baseline problems than the state\nof the art while being nearly as fast as standard matchers on simple problems.\nThe apparent robustness vs. speed trade-off is finessed by the use of progressively more time-consuming feature detectors and by on-demand generation of\nsynthesized images that is performed until a reliable estimate of geometry is\nobtained.\nWe introduce an improved method for tentative correspondence selection,\napplicable both with and without view synthesis. A modification of the standard\nfirst to second nearest distance rule increases the number of correct matches by\n5-20% at no additional computational cost.\nPerformance of the MODS algorithm is evaluated on several standard publicly available datasets, and on a new set of geometrically challenging wide baseline problems that is made public together with the ground truth. Experiments\nshow that the MODS outperforms the state-of-the-art in robustness and speed.\nMoreover, MODS performs well on other classes of difficult two-view problems\nlike matching of images from different modalities, with wide temporal baseline\nor with significant lighting changes."}}
