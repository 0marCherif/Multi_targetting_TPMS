{"id": "BGZmoPuUovM", "cdate": 1664500778913, "mdate": 1664500778913, "content": {"title": "ZEROGEN: Efficient Zero-shot Learning via Dataset Generation", "abstract": "There is a growing interest in dataset generation recently due to the superior generative\ncapacity of large pre-trained language models\n(PLMs). In this paper, we study a flexible\nand efficient zero-short learning method, ZEROGEN. Given a zero-shot task, we first\ngenerate a dataset from scratch using PLMs\nin an unsupervised manner. Then, we train\na tiny task model (e.g., LSTM) under the\nsupervision of the synthesized dataset. This\napproach allows highly efficient inference as\nthe final task model only has orders of magnitude fewer parameters comparing to PLMs\n(e.g., GPT2-XL). Apart from being annotationfree and efficient, we argue that ZEROGEN can\nalso provide useful insights from the perspective of data-free model-agnostic knowledge\ndistillation, and unreferenced text generation\nevaluation. Experiments and analysis on different NLP tasks, namely, text classification,\nquestion answering, and natural language inference), show the effectiveness of ZEROGEN."}}
{"id": "lH1PV42cbF", "cdate": 1663850447263, "mdate": null, "content": {"title": "Binding Language Models in Symbolic Languages", "abstract": "Though end-to-end neural approaches have recently been dominating NLP tasks in both performance and ease-of-use, they lack interpretability and robustness. We propose Binder, a training-free neural-symbolic framework that maps the task input to a program, which (1) allows binding a unified API of language model (LM) functionalities to a programming language (e.g., SQL, Python) to extend its grammar coverage and thus tackle more diverse questions, (2) adopts an LM as both the program parser and the underlying model called by the API during execution, and (3) requires only a few in-context exemplar annotations. Specifically, we employ GPT-3 Codex as the LM. In the parsing stage, with only a few in-context exemplars, Codex is able to identify the part of the task input that cannot be answerable by the original programming language, correctly generate API calls to prompt Codex to solve the unanswerable part, and identify where to place the API calls while being compatible with the original grammar. In the execution stage, Codex can perform versatile functionalities (e.g., commonsense QA, information extraction) given proper prompts in the API calls. Binder achieves state-of-the-art results on WikiTableQuestions and TabFact datasets, with explicit output programs that benefit human debugging. Note that previous best systems are all finetuned on tens of thousands of task-specific samples, while Binder only uses dozens of annotations as in-context exemplars without any training. Our code is available at anonymized."}}
{"id": "qY1hlv7gwg", "cdate": 1663849929111, "mdate": null, "content": {"title": "Selective Annotation Makes Language Models Better Few-Shot Learners", "abstract": "Many recent approaches to natural language tasks are built on the remarkable abilities of large language models. Large language models can perform in-context learning, where they learn a new task from a few task demonstrations, without any parameter updates. This work examines the implications of in-context learning for the creation of datasets for new natural language tasks. Departing from recent in-context learning methods, we formulate an annotation-efficient, two-step framework: selective annotation that chooses a pool of examples to annotate from unlabeled data in advance, followed by prompt retrieval that retrieves task examples from the annotated pool at test time. Based on this framework, we propose an unsupervised, graph-based selective annotation method, voke-k, to select diverse, representative examples to annotate. Extensive experiments on 10 datasets (covering classification, commonsense reasoning, dialogue, and text/code generation) demonstrate that our selective annotation method improves the task performance by a large margin. On average, vote-k achieves a 12.9%/11.4% relative gain under an annotation budget of 18/100, as compared to randomly selecting examples to annotate. Compared to state-of-the-art supervised finetuning approaches, it yields similar performance with 10-100x less annotation cost across 10 tasks. We further analyze the effectiveness of our framework in various scenarios: language models with varying sizes, alternative selective annotation methods, and cases where there is a test data domain shift. We hope that our studies will serve as a basis for data annotations as large language models are increasingly applied to new tasks."}}
{"id": "q-SJBQQ4REj", "cdate": 1609459200000, "mdate": 1631920270300, "content": {"title": "SummerTime: Text Summarization Toolkit for Non-experts", "abstract": "Recent advances in summarization provide models that can generate summaries of higher quality. Such models now exist for a number of summarization tasks, including query-based summarization, dialogue summarization, and multi-document summarization. While such models and tasks are rapidly growing in the research field, it has also become challenging for non-experts to keep track of them. To make summarization methods more accessible to a wider audience, we develop SummerTime by rethinking the summarization task from the perspective of an NLP non-expert. SummerTime is a complete toolkit for text summarization, including various models, datasets and evaluation metrics, for a full spectrum of summarization-related tasks. SummerTime integrates with libraries designed for NLP researchers, and enables users with easy-to-use APIs. With SummerTime, users can locate pipeline solutions and search for the best model with their own data, and visualize the differences, all with a few lines of code. We also provide explanations for models and evaluation metrics to help users understand the model behaviors and select models that best suit their needs. Our library, along with a notebook demo, is available at https://github.com/Yale-LILY/SummerTime."}}
{"id": "dEwV5YuNVb9", "cdate": 1609459200000, "mdate": 1633925741400, "content": {"title": "GraPPa: Grammar-Augmented Pre-Training for Table Semantic Parsing", "abstract": "We present GraPPa, an effective pre-training approach for table semantic parsing that learns a compositional inductive bias in the joint representations of textual and tabular data. We construct synthetic question-SQL pairs over high-quality tables via a synchronous context-free grammar (SCFG). We pre-train our model on the synthetic data to inject important structural properties commonly found in semantic parsing into the pre-training language model. To maintain the model's ability to represent real-world data, we also include masked language modeling (MLM) on several existing table-related datasets to regularize our pre-training process. Our proposed pre-training strategy is much data-efficient. When incorporated with strong base semantic parsers, GraPPa achieves new state-of-the-art results on four popular fully supervised and weakly supervised table semantic parsing tasks."}}
{"id": "b8uPBlg082T", "cdate": 1609459200000, "mdate": 1633925741400, "content": {"title": "SCoRe: Pre-Training for Context Representation in Conversational Semantic Parsing", "abstract": "Conversational Semantic Parsing (CSP) is the task of converting a sequence of natural language queries to formal language (e.g., SQL, SPARQL) that can be executed against a structured ontology (e.g. databases, knowledge bases). To accomplish this task, a CSP system needs to model the relation between the unstructured language utterance and the structured ontology while representing the multi-turn dynamics of the dialog. Pre-trained language models (LMs) are the state-of-the-art for various natural language processing tasks. However, existing pre-trained LMs that use language modeling training objectives over free-form text have limited ability to represent natural language references to contextual structural data. In this work, we present SCORE, a new pre-training approach for CSP tasks designed to induce representations that capture the alignment between the dialogue flow and the structural context. We demonstrate the broad applicability of SCORE to CSP tasks by combining SCORE with strong base systems on four different tasks (SPARC, COSQL, MWOZ, and SQA). We show that SCORE can improve the performance over all these base systems by a significant margin and achieves state-of-the-art results on three of them."}}
{"id": "aNVAcW9OTEw", "cdate": 1609459200000, "mdate": 1623817503373, "content": {"title": "QMSum: A New Benchmark for Query-based Multi-domain Meeting Summarization", "abstract": "Ming Zhong, Da Yin, Tao Yu, Ahmad Zaidi, Mutethia Mutuma, Rahul Jha, Ahmed Hassan Awadallah, Asli Celikyilmaz, Yang Liu, Xipeng Qiu, Dragomir Radev. Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. 2021."}}
{"id": "9FoXWdHAni", "cdate": 1609459200000, "mdate": 1633925741401, "content": {"title": "DART: Open-Domain Structured Data Record to Text Generation", "abstract": "Linyong Nan, Dragomir Radev, Rui Zhang, Amrit Rau, Abhinand Sivaprasad, Chiachun Hsieh, Xiangru Tang, Aadit Vyas, Neha Verma, Pranav Krishna, Yangxiaokang Liu, Nadia Irwanto, Jessica Pan, Faiaz Rahman, Ahmad Zaidi, Mutethia Mutuma, Yasin Tarabar, Ankit Gupta, Tao Yu, Yi Chern Tan, Xi Victoria Lin, Caiming Xiong, Richard Socher, Nazneen Fatema Rajani. Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. 2021."}}
{"id": "5ip8nV7F4Qn", "cdate": 1602617099782, "mdate": null, "content": {"title": "SCoRe: Pre-Training for Context Representation in Conversational Semantic Parsing", "abstract": "Conversational Semantic Parsing (CSP) is the task of converting a sequence of natural language queries to formal queries (e.g., SQL, SPARQL) to be executed against a structured ontology (e.g.  databases, KBs). A CSP system needs to model the alignment between the unstructured language utterance and the structured ontology in the context of multi-turn dialog dynamics. Pre-trained language models have limited ability to represent NL references to structural data. We present SCoRe, a new pre-training approach for CSP tasks designed to induce representations that capture the alignment between the conversational flow and the structural context. By combining SCoRe with strong base systems on four different tasks (SParC, CoSQL, MWoZ, and SQA), we improve the performance over all baselines by a significant margin and achieve state-of-the-art results on three of them.\n"}}
{"id": "oyZxhRI2RiE", "cdate": 1601308420009, "mdate": null, "content": {"title": "SCoRe: Pre-Training for Context Representation in Conversational Semantic Parsing", "abstract": "Conversational Semantic Parsing (CSP) is the task of converting a sequence of natural language queries to formal language (e.g., SQL, SPARQL) that can be executed against a structured ontology (e.g.  databases, knowledge bases).  To accomplish  this  task,  a  CSP  system  needs  to  model  the  relation  between  the unstructured language utterance and the structured ontology while representing the multi-turn dynamics of the dialog. Pre-trained language models (LMs) are the state-of-the-art for various natural language processing tasks. However, existing pre-trained LMs that use language modeling training objectives over free-form text have limited ability to represent natural language references to contextual structural data. In this work, we present SCORE, a new pre-training approach for CSP tasks designed to induce representations that capture the alignment between the dialogue flow and the structural context. We demonstrate the broad applicability of SCORE to CSP tasks by combining SCORE with strong base systems on four different tasks (SPARC, COSQL, MWOZ, and SQA). We show that SCORE can improve the performance over all these base systems by a significant margin and achieves state-of-the-art results on three of them."}}
