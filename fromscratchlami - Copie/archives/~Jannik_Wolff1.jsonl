{"id": "R5o0wj-3aL", "cdate": 1674994752152, "mdate": 1674994752152, "content": {"title": "Mixture-of-experts VAEs can disregard variation in surjective multimodal data", "abstract": "Machine learning systems are often deployed in domains that entail data from multiple modalities, for example, phenotypic and genotypic characteristics describe patients in healthcare. Previous works have developed multimodal variational autoencoders (VAEs) that generate several modalities. We consider subjective data, where single datapoints from one modality (such as class labels) describe multiple datapoints from another modality (such as images). We theoretically and empirically demonstrate that multimodal VAEs with a mixture of experts posterior can struggle to capture variability in such surjective data.\n"}}
{"id": "U9DScusYQto", "cdate": 1640995200000, "mdate": 1674994839046, "content": {"title": "Mixture-of-experts VAEs can disregard variation in surjective multimodal data", "abstract": "Machine learning systems are often deployed in domains that entail data from multiple modalities, for example, phenotypic and genotypic characteristics describe patients in healthcare. Previous works have developed multimodal variational autoencoders (VAEs) that generate several modalities. We consider subjective data, where single datapoints from one modality (such as class labels) describe multiple datapoints from another modality (such as images). We theoretically and empirically demonstrate that multimodal VAEs with a mixture of experts posterior can struggle to capture variability in such surjective data."}}
{"id": "4V4TZG7i7L_", "cdate": 1632875682508, "mdate": null, "content": {"title": "Hierarchical Multimodal Variational Autoencoders", "abstract": "Humans find structure in natural phenomena by absorbing stimuli from multiple input sources such as vision, text, and speech. We study the use of deep generative models that generate multimodal data from latent representations. Existing approaches generate samples using a single shared latent variable, sometimes with marginally independent latent variables to capture modality-specific variations. However, there are cases where modality-specific variations depend on the kind of structure shared across modalities. To capture such heterogeneity, we propose a hierarchical multimodal VAE (HMVAE) that represents modality-specific variations using latent variables dependent on a shared top-level variable. Our experiments on the CUB and the Oxford Flower datasets show that the HMVAE can represent multimodal heterogeneity and outperform existing methods in sample generation quality and quantitative measures as the held-out log-likelihood."}}
{"id": "BYZWerpEGXq", "cdate": 1577836800000, "mdate": 1648672055828, "content": {"title": "Learning Graph-Based Priors for Generalized Zero-Shot Learning", "abstract": "The task of zero-shot learning (ZSL) requires correctly predicting the label of samples from classes which were unseen at training time. This is achieved by leveraging side information about class labels, such as label attributes or word embeddings. Recently, attention has shifted to the more realistic task of generalized ZSL (GZSL) where test sets consist of seen and unseen samples. Recent approaches to GZSL have shown the value of generative models, which are used to generate samples from unseen classes. In this work, we incorporate an additional source of side information in the form of a relation graph over labels. We leverage this graph in order to learn a set of prior distributions, which encourage an aligned variational autoencoder (VAE) model to learn embeddings which respect the graph structure. Using this approach we are able to achieve improved performance on the CUB and SUN benchmarks over a strong baseline."}}
{"id": "rpP-eBT4MQq", "cdate": 1546300800000, "mdate": 1648672055813, "content": {"title": "Low-Shot Learning From Imaginary 3D Model", "abstract": "Since the advent of deep learning, neural networks have demonstrated remarkable results in many visual recognition tasks, constantly pushing the limits. However, the state-of-the-art approaches are largely unsuitable in scarce data regimes. To address this shortcoming, this paper proposes employing a 3D model, which is derived from training images. Such a model can then be used to hallucinate novel viewpoints and poses for the scarce samples of the few-shot learning scenario. A self-paced learning approach allows for the selection of a diverse set of high-quality images, which facilitates the training of a classifier. The performance of the proposed approach is showcased on the fine-grained CUB-200-2011 dataset in a few-shot setting and significantly improves our baseline accuracy."}}
{"id": "SnGWeBaVGQc", "cdate": 1546300800000, "mdate": 1648672055814, "content": {"title": "Low-Shot Learning from Imaginary 3D Model", "abstract": "Since the advent of deep learning, neural networks have demonstrated remarkable results in many visual recognition tasks, constantly pushing the limits. However, the state-of-the-art approaches are largely unsuitable in scarce data regimes. To address this shortcoming, this paper proposes employing a 3D model, which is derived from training images. Such a model can then be used to hallucinate novel viewpoints and poses for the scarce samples of the few-shot learning scenario. A self-paced learning approach allows for the selection of a diverse set of high-quality images, which facilitates the training of a classifier. The performance of the proposed approach is showcased on the fine-grained CUB-200-2011 dataset in a few-shot setting and significantly improves our baseline accuracy."}}
{"id": "B8cWgB6EMXq", "cdate": 1514764800000, "mdate": 1648672055828, "content": {"title": "Developing a Distributed Drone Delivery System with a Hybrid Behavior Planning System", "abstract": "The demand for fast and reliable parcel shipping is globally rising. Conventional delivery by land requires good infrastructure and causes high costs, especially on the last mile. We present a distributed and scalable drone delivery system based on the contract net protocol for task allocation and the ROS hybrid behaviour planner (RHBP) for goal-oriented task execution. The solution is tested on a modified multi-agent systems simulation platform (MASSIM). Within this environment, the solution scales up well and is profitable across different configurations."}}
