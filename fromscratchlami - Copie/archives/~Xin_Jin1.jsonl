{"id": "xLYksqVpqi", "cdate": 1706745600000, "mdate": 1710850347463, "content": {"title": "GPU Accelerated Full Homomorphic Encryption Cryptosystem, Library, and Applications for IoT Systems", "abstract": "Deep learning, such as convolutional neural networks (CNNs), has been utilized in a number of cloud-based Internet of Things (IoT) applications. Security and privacy are two key considerations in any commercial deployment. Fully homomorphic encryption (FHE) is a popular privacy protection approach, and there have been attempts to integrate FHE with CNNs. However, a simple integration may lead to inefficiency in single-user services and fail to support many of the requirements in real-time applications. In this article, we propose a novel confused modulo projection-based FHE algorithm (CMP-FHE) that is designed to support floating-point operations. Then, we developed a parallelized runtime library based on CMP-FHE and compared it with the widely employed FHE library. Our results show that our library achieves faster speeds. Furthermore, we compared it with the state-of-the-art confused modulo projection-based library and the results demonstrated a speed improvement of 841.67 to 3056.25 times faster. Additionally, we construct a real-time homomorphic CNN (RT-HCNN) under the ciphertext-based framework using CMP-FHE, as well as using graphics processing units (GPUs) to facilitate acceleration. To demonstrate utility, we evaluate the proposed approach on the MNIST data set. Findings demonstrate that our proposed approach achieves a high accuracy rate of 99.13%. Using GPUs acceleration for ciphertext prediction results in us achieving a single prediction time of 79.5 ms. This represents the first homomorphic CNN capable of supporting real-time application and is approximately 58 times faster than Microsoft\u2019s Lola scheme."}}
{"id": "tBFvScHaQTC", "cdate": 1672531200000, "mdate": 1710850347920, "content": {"title": "An Order-Complexity Model for Aesthetic Quality Assessment of Homophony Music Performance", "abstract": "Although computational aesthetics evaluation has made certain achievements in many fields, its research of music performance remains to be explored. At present, subjective evaluation is still a ultimate method of music aesthetics research, but it will consume a lot of human and material resources. In addition, the music performance generated by AI is still mechanical, monotonous and lacking in beauty. In order to guide the generation task of AI music performance, and to improve the performance effect of human performers, this paper uses Birkhoff's aesthetic measure to propose a method of objective measurement of beauty. The main contributions of this paper are as follows: Firstly, we put forward an objective aesthetic evaluation method to measure the music performance aesthetic; Secondly, we propose 10 basic music features and 4 aesthetic music features. Experiments show that our method performs well on performance assessment."}}
{"id": "qEelYRSCDr", "cdate": 1672531200000, "mdate": 1710850347923, "content": {"title": "Language Guidance Generation Using Aesthetic Attribute Comparison for Human Photography and AIGC", "abstract": "With the proliferation of mobile photography technology, leading mobile phone manufacturers are racing to enhance the shooting capabilities of their equipment and the photo beautification algorithm of their software. However, the development of intelligent equipment and algorithms cannot supplant human subjective photography techniques. Simultaneously, with the rapid advancement of AIGC technology, AI simulation shooting has become an integral part of people's daily lives. If it were possible to assist human photography and AIGC with language guidance, this would be a significant step forward in subjectively improving the aesthetic quality of photographic images. In this paper, we propose Aesthetic Language Guidance of Image (ALG) and present a series of language guidance rules (ALG Rules). ALG is divided into ALG-T and ALG-I based on whether the guiding rules are derived from photography templates or reference images, respectively. ALG-T and ALG-I both provide guidance for photography based on three attributes of color, light, and composition of images. ALG-T and ALG-I provide aesthetic language guidance for two types of input images, landscape and portrait images. We employ two methods to conduct confirmatory experiments, human photography, and AIGC imitation shooting. In the experiments, by comparing the aesthetic scores of original and modified images, the results show that our proposed guidance scheme significantly improves the aesthetic quality of photos in terms of color, composition, and lighting attributes."}}
{"id": "aZddA7dmZC", "cdate": 1672531200000, "mdate": 1710850347913, "content": {"title": "Predicting Scores of Various Aesthetic Attribute Sets by Learning from Overall Score Labels", "abstract": "Now many mobile phones embed deep-learning models for evaluation or guidance on photography. These models cannot provide detailed results like human pose scores or scene color scores because of the rare of corresponding aesthetic attribute data. However, the annotation of image aesthetic attribute scores requires experienced artists and professional photographers, which hinders the collection of large-scale fully-annotated datasets. In this paper, we propose to replace image attribute labels with feature extractors. First, a novel aesthetic attribute evaluation framework based on attribute features is proposed to predict attribute scores and overall scores. We call it the F2S (attribute features to attribute scores) model. We use networks from different tasks to provide attribute features to our F2S models. Then, we define an aesthetic attribute contribution to describe the role of aesthetic attributes throughout an image and use it with the attribute scores and the overall scores to train our F2S model. Sufficient experiments on publicly available datasets demonstrate that our F2S model achieves comparable performance with those trained on the datasets with fully-annotated aesthetic attribute score labels. Our method makes it feasible to learn meaningful attribute scores for various aesthetic attribute sets in different types of images with only overall aesthetic scores."}}
{"id": "YWUn_QipjW", "cdate": 1672531200000, "mdate": 1710850347585, "content": {"title": "Aesthetics-Driven Virtual Time-Lapse Photography Generation", "abstract": "Time-lapse videos can visualize the temporal change of dynamic scenes and present wonderful sights with drastic variance in color appearance and rapid movement that interests people. We propose an aesthetics-driven virtual time-lapse photography framework to explore the automatic generation of time-lapse videos in the virtual world, which has potential applications like artistic creation and entertainment in the virtual space. We first define shooting parameters to parameterize the time-lapse photography process and accordingly propose image, video, and time-lapse aesthetic assessments to optimize these parameters, enabling the process to be autonomous and adaptive. We also build an interactive interface to visualize the shooting process and help users conduct virtual time-lapse photography by personalizing shooting parameters according to their aesthetic preferences. Finally, we present a two-stream time-lapse aesthetic model and a time-lapse aesthetic dataset, which can evaluate the aesthetic quality of time-lapse videos. Experimental results demonstrate our method can automatically generate time-lapse videos comparable to those of professional photographers and is more efficient."}}
{"id": "Xd1C8JSZWS", "cdate": 1672531200000, "mdate": 1710850347453, "content": {"title": "TBFormer: Two-Branch Transformer for Image Forgery Localization", "abstract": "Image forgery localization aims to identify forged regions by capturing subtle traces from high-quality discriminative features. In this paper, we propose a Transformer-style network with two feature extraction branches for image forgery localization, and it is named as Two-Branch Transformer (TBFormer). Firstly, two feature extraction branches are elaborately designed, taking advantage of the discriminative stacked Transformer layers, for both RGB and noise domain features. Secondly, an Attention-aware Hierarchical-feature Fusion Module (AHFM) is proposed to effectively fuse hierarchical features from two different domains. Although the two feature extraction branches have the same architecture, their features have significant differences since they are extracted from different domains. We adopt position attention to embed them into a unified feature domain for hierarchical feature investigation. Finally, a Transformer decoder is constructed for feature reconstruction to generate the predicted mask. Extensive experiments on publicly available datasets demonstrate the effectiveness of the proposed model."}}
{"id": "Unb6kj9yuLe", "cdate": 1672531200000, "mdate": 1710850347426, "content": {"title": "Homomorphic Comparison Method Based on Dynamically Polynomial Composite Approximating Sign Function", "abstract": "Performing comparison operations between two numbers is one of the most commonly used operations in some applications. However, performing non-arithmetic operations, such as comparison, on data encrypted with fully homomorphic encryption that only supports addition and multiplication operations, has always been a challenging task. Recently, Cheon et al.(Asiacrypt 2020) proposed a new comparison method in homomorphic encryption using composite polynomial approximation of the sign function, and proved that their method has optimal asymptotic complexity. In this paper, we propose a new comparison method using dynamic polynomial composition to approximate the sign function. We analyze the optimality of the depth consumption and computational complexity of this approximation method. Additionally, we extend this comparison algorithm to multiple applications, such as Min/Max algorithm and k-way sorting network algorithm. Our numerical analysis shows that for computing the approximate comparison of any two 32-bit integers encrypted by HEAAN, our homomorphic comparison algorithm (for $\\epsilon=2^{-16},\\alpha=2^{-32}$) requires 0.83ms in amortized running time. This reduces the running time by about 25% compared to the previous optimal method."}}
{"id": "KnNXnDteMXF", "cdate": 1672531200000, "mdate": 1710850347585, "content": {"title": "An Order-Complexity Aesthetic Assessment Model for Aesthetic-aware Music Recommendation", "abstract": "Computational aesthetic evaluation has made remarkable contribution to visual art works, but its application to music is still rare. Currently, subjective evaluation is still the most effective form of evaluating artistic works. However, subjective evaluation of artistic works will consume a lot of human and material resources. The popular AI generated content (AIGC) tasks nowadays have flooded all industries, and music is no exception. While compared to music produced by humans, AI generated music still sounds mechanical, monotonous, and lacks aesthetic appeal. Due to the lack of music datasets with rating annotations, we have to choose traditional aesthetic equations to objectively measure the beauty of music. In order to improve the quality of AI music generation and further guide computer music production, synthesis, recommendation and other tasks, we use Birkhoff's aesthetic measure to design a aesthetic model, objectively measuring the aesthetic beauty of music, and form a recommendation list according to the aesthetic feeling of music. Experiments show that our objective aesthetic model and recommendation method are effective."}}
{"id": "DUyDfNM5BgZ", "cdate": 1672531200000, "mdate": 1710850347923, "content": {"title": "TBFormer: Two-Branch Transformer for Image Forgery Localization", "abstract": "Image forgery localization aims to identify forged regions by capturing subtle traces from high-quality discriminative features. In this paper, we propose a Transformer-style network with two feature extraction branches for image forgery localization, and it is named as Two-Branch Transformer (TBFormer). Firstly, two feature extraction branches are elaborately designed, taking advantage of the discriminative stacked Transformer layers, for both RGB and noise domain features. Secondly, an Attention-aware Hierarchical-feature Fusion Module (AHFM) is proposed to effectively fuse hierarchical features from two different domains. Although the two feature extraction branches have the same architecture, their features have significant differences since they are extracted from different domains. We adopt position attention to embed them into a unified feature domain for hierarchical feature investigation. Finally, a Transformer decoder is constructed for feature reconstruction to generate the predicted mask. Extensive experiments on publicly available datasets demonstrate the effectiveness of the proposed model."}}
{"id": "Atk1xIGhQeh", "cdate": 1672531200000, "mdate": 1710850347927, "content": {"title": "An Order-Complexity Model for Aesthetic Quality Assessment of Symbolic Homophony Music Scores", "abstract": "Computational aesthetics evaluation has made great achievements in the field of visual arts, but the research work on music still needs to be explored. Although the existing work of music generation is very substantial, the quality of music score generated by AI is relatively poor compared with that created by human composers. The music scores created by AI are usually monotonous and devoid of emotion. Based on Birkhoff\u2019s aesthetic measure, this paper proposes an objective quantitative evaluation method for homophony music score aesthetic quality assessment. The main contributions of our work are as follows: first, we put forward a homophony music score aesthetic model to objectively evaluate the quality of music score as a baseline model; second, we put forward eight basic music features and four music aesthetic features."}}
