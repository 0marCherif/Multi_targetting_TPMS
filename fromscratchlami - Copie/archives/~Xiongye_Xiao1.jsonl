{"id": "qzpVxhzIYG4", "cdate": 1672531200000, "mdate": 1681162948137, "content": {"title": "Coupled Multiwavelet Neural Operator Learning for Coupled Partial Differential Equations", "abstract": ""}}
{"id": "kIo_C6QmMOM", "cdate": 1663850530163, "mdate": null, "content": {"title": "Coupled Multiwavelet Operator Learning for Coupled Differential Equations", "abstract": "Coupled partial differential equations (PDEs) are key tasks in modeling the complex dynamics of many physical processes. Recently, neural operators have shown the ability to solve PDEs by learning the integral kernel directly in Fourier/Wavelet space, so the difficulty of solving the coupled PDEs depends on dealing with the coupled mappings between the functions. Towards this end, we propose a \\textit{coupled multiwavelets neural operator} (CMWNO) learning scheme by decoupling the coupled integral kernels during the multiwavelet decomposition and reconstruction procedures in the Wavelet space. The proposed model achieves significantly higher accuracy compared to previous learning-based solvers in solving the coupled PDEs including Gray-Scott (GS) equations and the non-local mean field game (MFG) problem. According to our experimental results, the proposed model exhibits a $2X-4X$ improvement relative $L$2 error compared to the best results from the state-of-the-art models."}}
{"id": "nmfTPUZD7X", "cdate": 1640995200000, "mdate": 1681162948161, "content": {"title": "Non-Linear Operator Approximations for Initial Value Problems", "abstract": ""}}
{"id": "d2TT6gK9qZn", "cdate": 1632875697638, "mdate": null, "content": {"title": "Non-Linear Operator Approximations for Initial Value Problems", "abstract": "Time-evolution of partial differential equations is the key to model several dynamical processes, events forecasting but the operators associated with such problems are non-linear. We propose a Pad\u00e9 approximation based exponential neural operator scheme for efficiently learning the map between a given initial condition and activities at a later time. The multiwavelets bases are used for space discretization. By explicitly embedding the exponential operators in the model, we reduce the training parameters and make it more data-efficient which is essential in dealing with scarce real-world datasets. The Pad\u00e9 exponential operator uses a $\\textit{recurrent structure with shared parameters}$ to model the non-linearity compared to recent neural operators that rely on using multiple linear operator layers in succession. We show theoretically that the gradients associated with the recurrent Pad\u00e9 network are bounded across the recurrent horizon. We perform experiments on non-linear systems such as Korteweg-de Vries (KdV) and Kuramoto\u2013Sivashinsky (KS) equations to show that the proposed approach achieves the best performance and at the same time is data-efficient. We also show that urgent real-world problems like Epidemic forecasting (for example, COVID-19) can be formulated as a 2D time-varying operator problem. The proposed Pad\u00e9 exponential operators yield better prediction results ($\\textbf{53\\%} (\\textbf{52\\%})$ better MAE than best neural operator (non-neural operator deep learning model)) compared to state-of-the-art forecasting models."}}
{"id": "LZDiWaC9CGL", "cdate": 1621630149275, "mdate": null, "content": {"title": "Multiwavelet-based Operator Learning for Differential Equations", "abstract": "The solution of a partial differential equation can be obtained by computing the inverse operator map between the input and the solution space. Towards this end, we introduce a $\\textit{multiwavelet-based neural operator learning scheme}$ that compresses the associated operator's kernel using fine-grained wavelets. By explicitly embedding the inverse multiwavelet filters, we learn the projection of the kernel onto fixed multiwavelet polynomial bases. The projected kernel is trained at multiple scales derived from using repeated computation of multiwavelet transform. This allows learning the complex dependencies at various scales and results in a resolution-independent scheme. Compare to the prior works, we exploit the fundamental properties of the operator's kernel which enable numerically efficient representation. We perform experiments on the Korteweg-de Vries (KdV) equation, Burgers' equation, Darcy Flow, and Navier-Stokes equation. Compared with the existing neural operator approaches, our model shows significantly higher accuracy and achieves state-of-the-art in a range of datasets. For the time-varying equations, the proposed method exhibits a ($2X-10X$) improvement ($0.0018$ ($0.0033$) relative $L2$ error for Burgers' (KdV) equation). By learning the mappings between function spaces, the proposed method has the ability to find the solution of a high-resolution input after learning from lower-resolution data."}}
{"id": "r98mr5H2DE", "cdate": 1609459200000, "mdate": 1681162948533, "content": {"title": "Multiwavelet-based Operator Learning for Differential Equations", "abstract": ""}}
{"id": "c2fDLNFW_d", "cdate": 1609459200000, "mdate": 1681162948252, "content": {"title": "Multiwavelet-based Operator Learning for Differential Equations", "abstract": ""}}
{"id": "Fl0Z_hLNBK", "cdate": 1577836800000, "mdate": 1681162948160, "content": {"title": "Biomorphic structural batteries for robotics", "abstract": ""}}
