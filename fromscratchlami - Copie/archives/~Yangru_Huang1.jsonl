{"id": "m16lH6XJsbb", "cdate": 1652737560149, "mdate": null, "content": {"title": "Spectrum Random Masking for Generalization in Image-based Reinforcement Learning", "abstract": "Generalization in image-based reinforcement learning (RL) aims to learn a robust policy that could be applied directly on unseen visual environments, which is a challenging task since agents usually tend to overfit to their training environment. To handle this problem, a natural approach is to increase the data diversity by image based augmentations. However, different with most vision tasks such as classification and detection, RL tasks are not always invariant to spatial based augmentations due to the entanglement of environment dynamics and visual appearance.  In this paper, we argue with two principles for augmentations in RL: First, the augmented observations should facilitate learning a universal policy, which is robust to various distribution shifts. Second, the augmented data should be invariant to the learning signals such as action and reward. Following these rules, we revisit image-based RL tasks from the view of frequency domain and propose a novel augmentation method, namely Spectrum Random Masking (SRM),which is able to help agents to learn the whole frequency spectrum of observation for coping with various distributions and compatible with the pre-collected action and reward corresponding to original observation. Extensive experiments conducted on DMControl Generalization Benchmark   demonstrate the proposed SRM achieves the state-of-the-art performance with strong generalization potentials."}}
{"id": "qN2DnKVxeS", "cdate": 1640995200000, "mdate": 1683790240574, "content": {"title": "Spectrum Random Masking for Generalization in Image-based Reinforcement Learning", "abstract": "Generalization in image-based reinforcement learning (RL) aims to learn a robust policy that could be applied directly on unseen visual environments, which is a challenging task since agents usually tend to overfit to their training environment. To handle this problem, a natural approach is to increase the data diversity by image based augmentations. However, different with most vision tasks such as classification and detection, RL tasks are not always invariant to spatial based augmentations due to the entanglement of environment dynamics and visual appearance. In this paper, we argue with two principles for augmentations in RL: First, the augmented observations should facilitate learning a universal policy, which is robust to various distribution shifts. Second, the augmented data should be invariant to the learning signals such as action and reward. Following these rules, we revisit image-based RL tasks from the view of frequency domain and propose a novel augmentation method, namely Spectrum Random Masking (SRM),which is able to help agents to learn the whole frequency spectrum of observation for coping with various distributions and compatible with the pre-collected action and reward corresponding to original observation. Extensive experiments conducted on DMControl Generalization Benchmark demonstrate the proposed SRM achieves the state-of-the-art performance with strong generalization potentials."}}
{"id": "vnqOUU2A22b", "cdate": 1577836800000, "mdate": 1683772310922, "content": {"title": "Masked Face Recognition with Latent Part Detection", "abstract": "This paper focuses on a novel task named masked faces recognition (MFR), which aims to match masked faces with common faces and is important especially during the global outbreak of COVID-19. It is challenging to identify masked faces for two main reasons. Firstly, there is no large-scale training data and test data with ground truth for MFR. Collecting and annotating millions of masked faces is labor-consuming. Secondly, since most facial cues are occluded by mask, it is necessary to learn representations which are both discriminative and robust to mask wearing. To handle the first challenge, this paper collects two datasets designed for MFR: MFV with 400 pairs of 200 identities for verification, and MFI which contains 4,916 images of 669 identities for identification. As is known, a robust face recognition model needs images of millions of identities to train, and hundreds of identities is far from enough. Hence, MFV and MFI are only considered as test datasets to evaluate algorithms. Besides, a data augmentation method for training data is introduced to automatically generate synthetic masked face images from existing common face datasets. In addition, a novel latent part detection (LPD) model is proposed to locate the latent facial part which is robust to mask wearing, and the latent part is further used to extract discriminative features. The proposed LPD model is trained in an end-to-end manner and only utilizes the original and synthetic training data. Experimental results on MFV, MFI and synthetic masked LFW demonstrate that LPD model generalizes well on both realistic and synthetic masked data and outperforms other methods by a large margin."}}
{"id": "r7VyWbk1Xr", "cdate": 1577836800000, "mdate": 1683772310905, "content": {"title": "Masked Face Recognition with Generative Data Augmentation and Domain Constrained Ranking", "abstract": "Masked faces recognition (MFR) aims to match a masked face with its corresponding full face, which is an important task especially during the global outbreak of COVID-19. However, most existing face recognition models generalize poorly in this case, and it is hard to train a robust MFR model due to two main reasons: 1) the absence of large scale training data as well as ground truth testing data, and 2) the presence of large intra-class variation between masked faces and full faces. To address the first challenge, this paper firstly contributes a new dataset denoted as MFSR, which consists of two parts. The first part contains 9,742 masked face images with mask region segmentation annotation. The second part contains 11,615 images of 1,004 identities, and each identity has masked and full face images with various orientations, lighting conditions and mask types. However, it is still not enough for training MFR models with deep learning. To obtain sufficient training data, based on the MFSR, we introduce a novel Identity Aware Mask GAN (IAMGAN) with segmentation guided multi-level identity preserve module to generate the synthetic masked face images from the full face images. In addition, to tackle the second challenge, a Domain Constrained Ranking (DCR) loss is proposed by adopting a center-based cross-domain ranking strategy. For each identity, two centers are designed which correspond to the full face images and the masked face images respectively. The DCR forces the feature of masked faces getting closer to its corresponding full face center and vice-versa. Experimental results on the MFSR dataset demonstrate the effectiveness of the proposed approaches."}}
{"id": "_bEHvdukTa", "cdate": 1577836800000, "mdate": 1683790240622, "content": {"title": "Towards Imbalanced Image Classification: A Generative Adversarial Network Ensemble Learning Method", "abstract": "Learning from minority class has been a significant and challenging task which has many potential applications. Weather classification is such a case of imbalanced label distribution. This is because in places like Beijing, some types of weather, such as rain and snow, are relatively rare compared to sunny and haze days. Existing methods are primary to classify the weather conditions relying on expensive sensors or human assistance, which however usually are expensive and time-consuming. In this paper, we propose a new ensemble framework based on the advanced generative adversarial network and an effective data cleaning way to address the class imbalance problem for weather classification. The proposed method not only generates new and reliable samples for the minority class to restore balance, but also filters those generated samples which are unreliable. Experiments show that our approach outperforms the state-of-the-art methods by a huge margin for imbalanced weather classification on several benchmark data sets."}}
{"id": "DVi8I1h1lQ", "cdate": 1577836800000, "mdate": null, "content": {"title": "Domain Adaptive Attention Learning for Unsupervised Person Re-Identification", "abstract": "Person re-identification (Re-ID) across multiple datasets is a challenging task due to two main reasons: the presence of large cross-dataset distinctions and the absence of annotated target instances. To address these two issues, this paper proposes a domain adaptive attention learning approach to reliably transfer discriminative representation from the labeled source domain to the unlabeled target domain. In this approach, a domain adaptive attention model is learned to separate the feature map into domain-shared part and domain-specific part. In this manner, the domain-shared part is used to capture transferable cues that can compensate cross-dataset distinctions and give positive contributions to the target task, while the domain-specific part aims to model the noisy information to avoid the negative transfer caused by domain diversity. A soft label loss is further employed to take full use of unlabeled target data by estimating pseudo labels. Extensive experiments on the Market-1501, DukeMTMC-reID and MSMT17 benchmarks demonstrate the proposed approach outperforms the state-of-the-arts."}}
{"id": "B4Qtxx0QDc", "cdate": 1577836800000, "mdate": 1683790240556, "content": {"title": "Discriminative Spatial Feature Learning for Person Re-Identification", "abstract": "Person re-identification (ReID) aims to match detected pedestrian images from multiple non-overlapping cameras. Most existing methods employ a backbone CNN to extract a vectorized feature representation by performing some global pooling operations (such as global average pooling and global max pooling) on the 3D feature map (i.e., the output of the backbone CNN). Although simple and effective in some situations, the global pooling operation only focuses on the statistical properties and ignores the spatial distribution of the feature map. Hence, it can not distinguish two feature maps when they have similar response values located in totally different positions. To handle this challenge, a novel method is proposed to learn the discriminative spatial features. Firstly, a self-constrained spatial transformer network (SC-STN) is introduced to handle the misalignments caused by detection errors. Then, based on the prior knowledge that the spatial structure of a pedestrian often keeps robust in vertical orientation of images, a novel vertical convolution network (VCN) is proposed to extract the spatial feature in vertical. Extensive experimental evaluations on several benchmarks demonstrate that the proposed method achieves state-of-the-art performances by introducing only a few parameters to the backbone."}}
{"id": "p1gvpNKdHDz7", "cdate": 1546300800000, "mdate": null, "content": {"title": "Domain Adaptive Attention Model for Unsupervised Cross-Domain Person Re-Identification", "abstract": "Person re-identification (Re-ID) across multiple datasets is a challenging yet important task due to the possibly large distinctions between different datasets and the lack of training samples in practical applications. This work proposes a novel unsupervised domain adaption framework which transfers discriminative representations from the labeled source domain (dataset) to the unlabeled target domain (dataset). We propose to formulate the domain adaption task as an one-class classification problem with a novel domain similarity loss. Given the feature map of any image from a backbone network, a novel domain adaptive attention model (DAAM) first automatically learns to separate the feature map of an image to a domain-shared feature (DSH) map and a domain-specific feature (DSP) map simultaneously. Specially, the residual attention mechanism is designed to model DSP feature map for avoiding negative transfer. Then, a DSH branch and a DSP branch are introduced to learn DSH and DSP feature maps respectively. To reduce domain divergence caused by that the source and target datasets are collected from different environments, we force to project the DSH feature maps from different domains to a new nominal domain, and a novel domain similarity loss is proposed based on one-class classification. In addition, a novel unsupervised person Re-ID loss is proposed to take full use of unlabeled target data. Extensive experiments on the Market-1501 and DukeMTMC-reID benchmarks demonstrate state-of-the-art performance of the proposed method. Code will be released to facilitate further studies on the cross-domain person re-identification task."}}
{"id": "TcQ855JUey", "cdate": 1546300800000, "mdate": 1683790240627, "content": {"title": "Unsupervised Person Re-identification Based on Clustering and Domain-Invariant Network", "abstract": "Person re-identification (Re-ID) is a task which aims to determine whether a pedestrian in a camera has emerged in other cameras. Earlier works stress importance of the supervised learning methods, however, creating labels by hand is too slow and expensive. Hence, supervised methods are always limited in real-world applications. To address the problem, we propose a novel domain adaptation framework for unsupervised person Re-ID. First, target data are clustered and selected to add relative reliable supervised information for target domain. Second, a novel domain adaptive network is designed to decompose the representations to person-related and domain-related part. The former aims at learning domain-invariant and discriminative representation by a adversarial loss and a Re-ID loss with the label smoothing regularization. And the latter further improve a model\u2019s ability of extracting domain-invariant features by separating the domain unique features. What\u2019s more, during learning representation for target domain, a labeled source data not only is utilized to initialize the model but also participate in the training as a beneficial supervision information to generalize the Re-ID model. Experimental results on Market-1501 and DukeMTMC-reID evidence the superior performance of the proposed model over state-of-the-art methods."}}
