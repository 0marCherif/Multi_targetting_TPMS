{"id": "HEVfOwxrmQh", "cdate": 1621630234581, "mdate": null, "content": {"title": "Better Algorithms for Individually Fair $k$-Clustering", "abstract": "We study data clustering problems with $\\ell_p$-norm objectives (e.g. \\textsc{$k$-Median} and \\textsc{$k$-Means}) in the context of individual fairness. The dataset consists of $n$ points, and we want to find $k$ centers such that (a) the objective is minimized, while (b) respecting the individual fairness constraint that every point $v$ has a center within a distance at most $r(v)$, where $r(v)$ is $v$'s distance to its $(n/k)$th nearest point. Jung, Kannan, and Lutz [FORC 2020] introduced this concept and designed a clustering algorithm with provable (approximate) fairness and objective guarantees for the $\\ell_\\infty$ or \\textsc{$k$-Center} objective.  Mahabadi and Vakilian [ICML 2020] revisited this problem to give a local-search algorithm for all $\\ell_p$-norms. Empirically, their algorithms outperform Jung et. al.'s by a large margin in terms of cost (for \\textsc{$k$-Median} and \\textsc{$k$-Means}), but they incur a reasonable loss in fairness. \nIn this paper, our main contribution is to use Linear Programming (LP) techniques to obtain better algorithms for this problem, both in theory and in practice. We prove that by modifying known LP rounding techniques, one gets a worst-case guarantee on the objective which is much better than in MV20, and empirically, this objective is extremely close to the optimal.  Furthermore, our theoretical fairness guarantees are comparable with MV20 in theory, and empirically, we obtain noticeably fairer solutions.\nAlthough solving the LP {\\em exactly} might be prohibitive, we demonstrate that in practice, a simple sparsification technique drastically improves the run-time of our algorithm."}}
{"id": "BklDtVBgUH", "cdate": 1567802494736, "mdate": null, "content": {"title": "Fair Algorithms for Clustering", "abstract": "We study the problem of finding low-cost {\\em fair clusterings} in data where each data point may belong to many protected groups. Our work significantly generalizes the seminal work of Chierichetti \\etal (NIPS 2017) as follows.     - We allow the user to specify the parameters that define fair representation. More precisely, these parameters define the maximum over- and minimum under-representation of any group in any cluster.     - Our clustering algorithm works on any $\\ell_p$-norm objective (e.g. $k$-means, $k$-median, and $k$-center). Indeed, our algorithm transforms any vanilla clustering solution into a fair one incurring only a slight loss in quality.     - Our algorithm also allows individuals to lie in multiple protected groups.      In other words, we do not need the protected groups to partition the data and we can maintain fairness across different groups simultaneously.  Our experiments show that on established data sets, our algorithm performs much better in practice than what our theoretical results suggest."}}
