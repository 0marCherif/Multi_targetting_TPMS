{"id": "Q0HBcFnOR4", "cdate": 1679902904669, "mdate": 1679902904669, "content": {"title": "Nearly Optimal Algorithms for Level Set Estimation", "abstract": "The level set estimation problem seeks to find all points in a domain $\\X$ where the value of an unknown function $f:\\X\\rightarrow \\mathbb{R}$ exceeds a threshold $\\alpha$. The estimation is based on noisy function evaluations that may be acquired at sequentially and adaptively chosen locations in $\\X$. The threshold value $\\alpha$ can either be \\emph{explicit} and provided a priori, or \\emph{implicit} and defined relative to the optimal function value, i.e.  $\\alpha = (1-\\epsilon)f(\\bx_\\ast)$ for a given $\\epsilon > 0$ where $f(\\bx_\\ast)$ is the maximal function value and is unknown.  In this work we provide a new approach to the level set estimation problem by relating it to recent adaptive experimental design methods for linear bandits in the Reproducing Kernel Hilbert Space (RKHS) setting. We assume that $f$ can be approximated by a function in the RKHS up to an unknown misspecification and provide novel algorithms for both the implicit and explicit cases in this setting with strong theoretical guarantees. Moreover, in the linear (kernel) setting, we show that our bounds are nearly optimal, namely, our upper bounds match existing lower bounds for threshold linear bandits. To our knowledge this work provides the first instance-dependent, non-asymptotic upper bounds on sample complexity of level-set estimation that match information theoretic lower bounds."}}
{"id": "fdyxLGHE6bU", "cdate": 1652737765046, "mdate": null, "content": {"title": "Active Learning with Safety Constraints", "abstract": "Active learning methods have shown great promise in reducing the number of samples necessary for learning. As automated learning systems are adopted into real-time, real-world decision-making pipelines, it is increasingly important that such algorithms are designed with safety in mind. In this work we investigate the complexity of learning the best safe decision in interactive environments. We reduce this problem to a safe linear bandits problem, where our goal is to find the best arm satisfying certain (unknown) safety constraints. We propose an adaptive experimental design-based algorithm, which we show efficiently trades off between the difficulty of showing an arm is unsafe vs suboptimal. To our knowledge, our results are the first on best-arm identification in linear bandits with safety constraints. In  practice, we demonstrate that this approach performs well on synthetic and real world datasets."}}
{"id": "aoXERVeC7cC", "cdate": 1621630098570, "mdate": null, "content": {"title": "Selective Sampling for Online Best-arm Identification", "abstract": "This work considers the problem of selective-sampling for best-arm identification. Given a set of potential options $\\mathcal{Z}\\subset\\mathbb{R}^d$, a learner aims to compute with probability greater than $1-\\delta$, $\\arg\\max_{z\\in \\mathcal{Z}} z^{\\top}\\theta_{\\ast}$ where $\\theta_{\\ast}$ is unknown. At each time step, a potential measurement $x_t\\in \\mathcal{X}\\subset\\mathbb{R}^d$ is drawn IID and the learner can either choose to take the measurement, in which case they observe a noisy measurement of $x^{\\top}\\theta_{\\ast}$, or to abstain from taking the measurement and wait for a potentially more informative point to arrive in the stream. Hence the learner faces a fundamental trade-off between the number of labeled samples they take and when they have collected enough evidence to declare the best arm and stop sampling. The main results of this work precisely characterize this trade-off between labeled samples and stopping time and provide an algorithm that nearly-optimally achieves the minimal label complexity given a desired stopping time. In addition, we show that the optimal decision rule has a simple geometric form based on deciding whether a point is in an ellipse or not. Finally, our framework is general enough to capture binary classification improving upon previous works. "}}
