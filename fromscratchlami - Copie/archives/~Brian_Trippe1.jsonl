{"id": "zzZNO7PtFXQ", "cdate": 1683560829423, "mdate": 1683560829423, "content": {"title": "SE(3) diffusion model with application to protein backbone generation", "abstract": "The design of novel protein structures remains a challenge in protein engineering for applications across biomedicine and chemistry. In this line of work, a diffusion model over rigid bodies in 3D (referred to as frames) has shown success in generating novel, functional protein backbones that have not been observed in nature. However, there exists no principled methodological framework for diffusion on SE(3), the space of orientation preserving rigid motions in R3, that operates on frames and confers the group invariance. We address these shortcomings by developing theoretical foundations of SE(3) invariant diffusion models on multiple frames followed by a novel framework, FrameDiff, for learning the SE(3) equivariant score over multiple frames. We apply FrameDiff on monomer backbone generation and find it can generate designable monomers up to 500 amino acids without relying on a pretrained protein structure prediction network that has been integral to previous methods. We find our samples are capable of generalizing beyond any known protein structure."}}
{"id": "g-VLxmqLrn", "cdate": 1675970198235, "mdate": null, "content": {"title": "Gaussian processes at the Helm(holtz): A more fluid model for ocean currents", "abstract": "Oceanographers are interested in predicting ocean currents and identifying divergences in a current vector field based on sparse observations of buoy velocities. Since we expect current dynamics to be smooth but highly non-linear, Gaussian processes (GPs) offer an attractive model. But we show that applying a GP with a standard stationary kernel directly to buoy data can struggle at both current prediction and divergence identification -- due to some physically unrealistic prior assumptions. To better reflect known physical properties of currents, we propose to instead put a standard stationary kernel on the divergence and curl-free components of a vector field obtained through a Helmholtz decomposition. We show that, because this decomposition relates to the original vector field just via mixed partial derivatives, we can still perform inference given the original data with only a small constant multiple of additional computational expense. We illustrate the benefits of our method on synthetic and real ocean data."}}
{"id": "6TxBxqNME1Y", "cdate": 1663849960157, "mdate": null, "content": {"title": "Diffusion Probabilistic Modeling of Protein Backbones in 3D for the motif-scaffolding problem", "abstract": "Construction of a scaffold structure that supports a desired motif, conferring protein function, shows promise for the design of vaccines and enzymes. But a general solution to this motif-scaffolding problem remains open. Current machine-learning techniques for scaffold design are either limited to unrealistically small scaffolds (up to length 20) or struggle to produce multiple diverse scaffolds. We propose to learn a distribution over diverse and longer protein backbone structures via an E(3)-equivariant graph neural network. We develop SMCDiff to efficiently sample scaffolds from this distribution conditioned on a given motif; our algorithm is the first to theoretically guarantee conditional samples from a diffusion model in the large-compute limit. We evaluate our designed backbones by how well they align with AlphaFold2-predicted structures. We show that our method can (1) sample scaffolds up to 80 residues and (2) achieve structurally diverse scaffolds for a fixed motif."}}
{"id": "VU2hnPztsV3", "cdate": 1640995200000, "mdate": 1653871839455, "content": {"title": "Many processors, little time: MCMC for partitions via optimal transport couplings", "abstract": "Markov chain Monte Carlo (MCMC) methods are often used in clustering since they guarantee asymptotically exact expectations in the infinite-time limit. In finite time, though, slow mixing often leads to poor performance. Modern computing environments offer massive parallelism, but naive implementations of parallel MCMC can exhibit substantial bias. In MCMC samplers of continuous random variables, Markov chain couplings can overcome bias. But these approaches depend crucially on paired chains meetings after a small number of transitions. We show that straightforward applications of existing coupling ideas to discrete clustering variables fail to meet quickly. This failure arises from the \"label-switching problem\": semantically equivalent cluster relabelings impede fast meeting of coupled chains. We instead consider chains as exploring the space of partitions rather than partitions\u2019 (arbitrary) labelings. Using a metric on the partition space, we formulate a practical algorithm using optimal transport couplings. Our theory confirms our method is accurate and efficient. In experiments ranging from clustering of genes or seeds to graph colorings, we show the benefits of our coupling in the highly parallel, time-limited regime."}}
{"id": "28NikxkK6kJ", "cdate": 1621630230070, "mdate": null, "content": {"title": "For high-dimensional hierarchical models, consider exchangeability of effects across covariates instead of across datasets", "abstract": "Hierarchical Bayesian methods enable information sharing across regression problems on multiple groups of data. While standard practice is to model regression parameters (effects) as (1) exchangeable across the groups and (2) correlated to differing degrees across covariates, we show that this approach exhibits poor statistical performance when the number of covariates exceeds the number of groups. For instance, in statistical genetics, we might regress dozens of traits (defining groups) for thousands of individuals (responses) on up to millions of genetic variants (covariates). When an analyst has more covariates than groups, we argue that it is often preferable to instead model effects as (1) exchangeable across covariates and (2) correlated to differing degrees across groups. To this end, we propose a hierarchical model expressing our alternative perspective. We devise an empirical Bayes estimator for learning the degree of correlation between groups. We develop theory that demonstrates that our method outperforms the classic approach when the number of covariates dominates the number of groups, and corroborate this result empirically on several high-dimensional multiple regression and classification problems."}}
{"id": "gtdX0yWygoI", "cdate": 1609459200000, "mdate": 1653871839463, "content": {"title": "For high-dimensional hierarchical models, consider exchangeability of effects across covariates instead of across datasets", "abstract": "Hierarchical Bayesian methods enable information sharing across regression problems on multiple groups of data. While standard practice is to model regression parameters (effects) as (1) exchangeable across the groups and (2) correlated to differing degrees across covariates, we show that this approach exhibits poor statistical performance when the number of covariates exceeds the number of groups. For instance, in statistical genetics, we might regress dozens of traits (defining groups) for thousands of individuals (responses) on up to millions of genetic variants (covariates). When an analyst has more covariates than groups, we argue that it is often preferable to instead model effects as (1) exchangeable across covariates and (2) correlated to differing degrees across groups. To this end, we propose a hierarchical model expressing our alternative perspective. We devise an empirical Bayes estimator for learning the degree of correlation between groups. We develop theory that demonstrates that our method outperforms the classic approach when the number of covariates dominates the number of groups, and corroborate this result empirically on several high-dimensional multiple regression and classification problems."}}
{"id": "luJa4Gy5GYW", "cdate": 1606146134447, "mdate": null, "content": {"title": "Optimal Transport Couplings of Gibbs Samplers on Partitions for Unbiased Estimation", "abstract": "Computational couplings of Markov chains provide a practical route to unbiased Monte Carlo estimation that can utilize parallel computation.  However, these approaches depend crucially on chains meeting after a small number of transitions.  For models that assign data into groups, e.g.\\ mixture models, the obvious approaches to couple Gibbs samplers fail to meet quickly.  This failure owes to the so-called `label-switching' problem; semantically equivalent relabelings of the groups contribute well-separated posterior modes that impede fast mixing and cause large meeting times.  We here demonstrate how to avoid label switching by considering chains as exploring the space of partitions rather than labelings.  Using a metric on this space, we employ an optimal transport coupling of the Gibbs conditionals.  This coupling outperforms alternative couplings that rely on labelings\nand, on a real dataset, provides estimates more precise than usual ergodic averages in the limited time regime.\nCode is available at github.com/tinnguyen96/coupling-Gibbs-partition."}}
{"id": "BybtHjbuWr", "cdate": 1546300800000, "mdate": null, "content": {"title": "LR-GLM: High-Dimensional Bayesian Inference Using Low-Rank Data Approximations", "abstract": "Due to the ease of modern data collection, applied statisticians often have access to a large set of covariates that they wish to relate to some observed outcome. Generalized linear models (GLMs) o..."}}
{"id": "ByZaE3WuZS", "cdate": 1546300800000, "mdate": null, "content": {"title": "The Kernel Interaction Trick: Fast Bayesian Discovery of Pairwise Interactions in High Dimensions", "abstract": "Discovering interaction effects on a response of interest is a fundamental problem faced in biology, medicine, economics, and many other scientific disciplines. In theory, Bayesian methods for disc..."}}
