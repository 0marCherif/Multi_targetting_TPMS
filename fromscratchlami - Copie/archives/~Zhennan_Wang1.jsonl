{"id": "sEmgwJZ2TeJ", "cdate": 1672531200000, "mdate": 1681713546446, "content": {"title": "Multi-granularity Interaction Simulation for Unsupervised Interactive Segmentation", "abstract": "Interactive segmentation enables users to segment as needed by providing cues of objects, which introduces human-computer interaction for many fields, such as image editing and medical image analysis. Typically, massive and expansive pixel-level annotations are spent to train deep models by object-oriented interactions with manually labeled object masks. In this work, we reveal that informative interactions can be made by simulation with semantic-consistent yet diverse region exploration in an unsupervised paradigm. Concretely, we introduce a Multi-granularity Interaction Simulation (MIS) approach to open up a promising direction for unsupervised interactive segmentation. Drawing on the high-quality dense features produced by recent self-supervised models, we propose to gradually merge patches or regions with similar features to form more extensive regions and thus, every merged region serves as a semantic-meaningful multi-granularity proposal. By randomly sampling these proposals and simulating possible interactions based on them, we provide meaningful interaction at multiple granularities to teach the model to understand interactions. Our MIS significantly outperforms non-deep learning unsupervised methods and is even comparable with some previous deep-supervised methods without any annotation."}}
{"id": "RMTItDpPD5", "cdate": 1640995200000, "mdate": 1668131934239, "content": {"title": "Locality Guidance for Improving Vision Transformers on Tiny Datasets", "abstract": ""}}
{"id": "Aajl2P6kdsk", "cdate": 1609459200000, "mdate": 1682332382052, "content": {"title": "DPR-CAE: Capsule Autoencoder with Dynamic Part Representation for Image Parsing", "abstract": "Parsing an image into a hierarchy of objects, parts, and relations is important and also challenging in many computer vision tasks. This paper proposes a simple and effective capsule autoencoder to address this issue, called DPR-CAE. In our approach, the encoder parses the input into a set of part capsules, including pose, intensity, and dynamic vector. The decoder introduces a novel dynamic part representation (DPR) by combining the dynamic vector and a shared template bank. These part representations are then regulated by corresponding capsules to composite the final output in an interpretable way. Besides, an extra translation-invariant module is proposed to avoid directly learning the uncertain scene-part relationship in our DPR-CAE, which makes the resulting method achieves a promising performance gain on $rm$-MNIST and $rm$-Fashion-MNIST. % to model the scene-object relationship DPR-CAE can be easily combined with the existing stacked capsule autoencoder and experimental results show it significantly improves performance in terms of unsupervised object classification. Our code is available in the Appendix."}}
{"id": "sHSO_niyzH", "cdate": 1577836800000, "mdate": 1668131934236, "content": {"title": "MMA Regularization: Decorrelating Weights of Neural Networks by Maximizing the Minimal Angles", "abstract": ""}}
{"id": "oLomAw_5C1", "cdate": 1577836800000, "mdate": 1668131934209, "content": {"title": "Matrix Capsule Convolutional Projection for Deep Feature Learning", "abstract": ""}}
{"id": "eurApX2gY5", "cdate": 1577836800000, "mdate": 1668131934195, "content": {"title": "DMA Regularization: Enhancing Discriminability of Neural Networks by Decreasing the Minimal Angle", "abstract": ""}}
{"id": "UzGxhrzQeL", "cdate": 1546300800000, "mdate": 1668131934195, "content": {"title": "PR Product: A Substitute for Inner Product in Neural Networks", "abstract": ""}}
