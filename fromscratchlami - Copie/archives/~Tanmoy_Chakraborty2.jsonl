{"id": "JKFSUPa70W6M", "cdate": 1663850530046, "mdate": null, "content": {"title": "Don\u2019t Bet on Sparsity: Designing Brain-inspired Distance-preserving Encoder", "abstract": "Multi-headed self-attention-based Transformers have been a central area of research for quite some time. Albeit showing a significant improvement in understanding short-term and long-term contexts from sequences, encoders of Transformer and its variants fail to preserve layer-wise contextual information. Further, text representations learned by Transformer-based encoders are usually of low entropy with low variance, which contradicts typical human brain functions. In this work, we propose TransJect, an encoder model that guarantees a theoretical bound for layer-wise distance preservation between any pair of tokens. We propose a simple alternative to dot product attention to ensure Lipschitz continuity that allows TransJect to learn injective mappings to transform token representations to different manifolds and preserve Euclidean distance between every pair of tokens in subsequent layers. Our evaluation on several benchmark short- and long-sequence classification tasks shows a remarkable improvement of 3.1% and 11%, on average, respectively. Furthermore, empirical results suggest that TransJect is layer-agnostic; in fact, it prefers shallower architectures than deeper ones and prevents layer-wise incremental learning beyond a threshold. Our empirical analyses also show the generalization capabilities of TransJect and the robustness under different hyperparameter configurations. We conduct detailed statistical analysis to confirm the necessity of high-entropic representations to achieve human-like cognition. "}}
{"id": "xbhsFMxORxV", "cdate": 1652737731737, "mdate": null, "content": {"title": "Public Wisdom Matters! Discourse-Aware Hyperbolic Fourier Co-Attention for Social Text Classification", "abstract": "Social media has become the fulcrum of all forms of communication. Classifying social texts such as fake news, rumour, sarcasm, etc. has gained significant attention. The surface-level signals expressed by a social-text itself may not be adequate for such tasks; therefore, recent methods attempted to incorporate other intrinsic signals such as user behavior and the underlying graph structure. Oftentimes, the public wisdom expressed through the comments/replies to a social-text acts as a surrogate of crowd-sourced view and may provide us with complementary signals. State-of-the-art methods on social-text classification tend to ignore such a rich hierarchical signal. Here, we propose Hyphen, a discourse-aware hyperbolic spectral co-attention network. Hyphen is a fusion of hyperbolic graph representation learning with a novel Fourier co-attention mechanism in an attempt to generalise the social-text classification tasks by incorporating public discourse. We parse public discourse as an Abstract Meaning Representation (AMR) graph and use the powerful hyperbolic geometric representation to model graphs with hierarchical structure. Finally, we equip it with a novel Fourier co-attention mechanism to capture the correlation between the source post and public discourse. Extensive experiments on four different social-text classification tasks, namely detecting fake news, hate speech, rumour, and sarcasm, show that Hyphen generalises well, and achieves state-of-the-art results on ten benchmark datasets. We also employ a sentence-level fact-checked and annotated dataset to evaluate how Hyphen is capable of producing explanations as analogous evidence to the final prediction."}}
{"id": "e2gqGkFjDHg", "cdate": 1621630274197, "mdate": null, "content": {"title": "Redesigning the Transformer Architecture with Insights from Multi-particle Dynamical Systems", "abstract": "The Transformer and its variants have been proven to be efficient sequence learners in many different domains. Despite their staggering success, a critical issue has been the enormous number of parameters that must be trained (ranging from $10^7$ to $10^{11}$) along with the quadratic complexity of dot-product attention. In this work, we investigate the problem of approximating the two central components of the Transformer --- multi-head self-attention and point-wise feed-forward transformation, with reduced parameter space and computational complexity. We build upon recent developments in analyzing deep neural networks as numerical solvers of ordinary differential equations. Taking advantage of an analogy between Transformer stages and the evolution of a dynamical system of multiple interacting particles, we formulate a temporal evolution scheme, \\name, to bypass costly dot-product attention over multiple stacked layers.  We perform exhaustive experiments with \\name\\ on well-known encoder-decoder as well as encoder-only tasks. We observe that the degree of approximation (or inversely, the degree of parameter reduction) has different effects on the performance, depending on the task. While in the encoder-decoder regime, \\name\\ delivers performances comparable to the original Transformer, in encoder-only tasks it consistently outperforms Transformer along with several subsequent variants."}}
{"id": "Sj-Ez-zx_pH", "cdate": 1546300800000, "mdate": null, "content": {"title": "Incorporating Network Embedding into Markov Random Field for Better Community Detection.", "abstract": "Recent research on community detection focuses on learning representations of nodes using different network embedding methods, and then feeding them as normal features to clustering algorithms. However, we find that though one may have good results by direct clustering based on such network embedding features, there is ample room for improvement. More seriously, in many real networks, some statisticallysignificant nodes which play pivotal roles are often divided into incorrect communities using network embedding methods. This is because while some distance measures are used to capture the spatial relationship between nodes by embedding, the nodes after mapping to feature vectors are essentially not coupled any more, losing important structural information. To address this problem, we propose a general Markov Random Field (MRF) framework to incorporate coupling in network embedding which allows better detecting network communities. By smartly utilizing properties of MRF, the new framework not only preserves the advantages of network embedding (e.g. low complexity, high parallelizability and applicability for traditional machine learning), but also alleviates its core drawback of inadequate representations of dependencies via making up the missing coupling relationships. Experiments on real networks show that our new approach improves the accuracy of existing embedding methods (e.g. Node2Vec, DeepWalk and MNMF), and corrects most wrongly-divided statistically-significant nodes, which makes network embedding essentially suitable for real community detection applications. The new approach also outperforms other state-of-the-art conventional community detection methods."}}
{"id": "HsU93hMx_ar", "cdate": 1546300800000, "mdate": null, "content": {"title": "Bag-Of-Lies: A Multimodal Dataset for Deception Detection.", "abstract": "Deception detection is a pervasive issue in security. It has been widely studied using traditional modalities, such as video, audio and transcripts; however, there has been a lack of investigation in using modalities such as EEG and Gaze data due to the scarcity of a publicly available dataset. In this paper, a new multimodal dataset is presented, which provides data for deception detection by the aid of various modalities, such as video, audio, EEG and gaze data. The dataset explores the cognitive aspect of deception and combines it with vision. The presented dataset is collected in a realistic scenario and has 35 unique subjects providing 325 annotated data points with an even distribution of truth (163) and lie (162). The benefits provided by incorporating multiple modalities for fusion on the proposed dataset is also investigated. It is our assertion that the availability of this dataset will facilitate the development of better deception detection algorithms which are more relevant to real world scenarios."}}
{"id": "B7bJJMg_aB", "cdate": 1546300800000, "mdate": null, "content": {"title": "GIRNet: Interleaved Multi-Task Recurrent State Sequence Models.", "abstract": "In several natural language tasks, labeled sequences are available in separate domains (say, languages), but the goal is to label sequences with mixed domain (such as code-switched text). Or, we may have available models for labeling whole passages (say, with sentiments), which we would like to exploit toward better position-specific label inference (say, target-dependent sentiment annotation). A key characteristic shared across such tasks is that different positions in a primary instance can benefit from different \u2018experts\u2019 trained from auxiliary data, but labeled primary instances are scarce, and labeling the best expert for each position entails unacceptable cognitive burden. We propose GIRNet, a unified position-sensitive multi-task recurrent neural network (RNN) architecture for such applications. Auxiliary and primary tasks need not share training instances. Auxiliary RNNs are trained over auxiliary instances. A primary instance is also submitted to each auxiliary RNN, but their state sequences are gated and merged into a novel composite state sequence tailored to the primary inference task. Our approach is in sharp contrast to recent multi-task networks like the crossstitch and sluice networks, which do not control state transfer at such fine granularity. We demonstrate the superiority of GIRNet using three applications: sentiment classification of code-switched passages, part-of-speech tagging of codeswitched text, and target position-sensitive annotation of sentiment in monolingual passages. In all cases, we establish new state-of-the-art performance beyond recent competitive baselines."}}
{"id": "ryWd6lb_-H", "cdate": 1514764800000, "mdate": null, "content": {"title": "Metadata vs. Ground-truth: A Myth behind the Evolution of Community Detection Methods", "abstract": "A community detection (CD) method is usually evaluated by what extent it is able to discover the 'ground-truth' community structure of a network. A certain 'node-centric metadata' is used to define the ground-truth partition. However, nodes in real networks often have multiple metadata types (e.g., occupation, location); each can potentially form a ground-truth partition. Our experiment with 10 CD methods on 5 datasets (having multiple metadata-based ground-truth partitions) show that the metadata-based evaluation is misleading because there is no single CD method that can outperform others by detecting all types of metadata-based partitions. We further show that the community structure obtained from the CD methods is usually topologically stronger than any metadata-based partitions. Finally, we suggest a new task-based evaluation framework for CD methods and show that a certain type of CD methods is useful for a certain type of task."}}
{"id": "ry4RUWbdWr", "cdate": 1514764800000, "mdate": null, "content": {"title": "WWW'18 Workshop on Exploitation of Social Media for Emergency Relief and Preparedness: Chairs' Welcome & Organization", "abstract": "User-generated content on online social media (OSM) platforms has become an important source of real-time information during emergency events. The SMERP workshop series aims to provide a forum for researchers working on utilizing OSM for emergency preparedness and aiding post-emergency relief operations. The workshop aims to bring together researchers from diverse fields - Information Retrieval, Data Mining and Machine Learning, Natural Language Processing, Social Network Analysis, Computational Social Science, Human Computer Interaction - who can potentially contribute to utilizing social media for emergency relief and preparedness. The first SMERP workshop was held in April 2017 in conjunction with the ECIR 2017 conference. This 2nd SMERP Workshop with The Web Conference 2018 includes two keynote talks, a peer-reviewed research paper track, and a panel discussion."}}
{"id": "SyNbR--dZH", "cdate": 1514764800000, "mdate": null, "content": {"title": "Collective Classification of Spam Campaigners on Twitter: A Hierarchical Meta-Path Based Approach", "abstract": "Cybercriminals have leveraged the popularity of a large user base available on Online Social Networks~(OSNs) to spread spam campaigns by propagating phishing URLs, attaching malicious contents, etc. However, another kind of spam attacks using phone numbers has recently become prevalent on OSNs, where spammers advertise phone numbers to attract users\u00bb attention and convince them to make a call to these phone numbers. The dynamics of phone number based spam is different from URL-based spam due to an inherent trust associated with a phone number. While previous work has proposed strategies to mitigate URL-based spam attacks, phone number based spam attacks have received less attention. In this paper, we aim to detect spammers that use phone numbers to promote campaigns on Twitter. To this end, we collected information (tweets, user meta-data, etc.) about 3,370 campaigns spread by 670,251 users. We model the Twitter dataset as a heterogeneous network by leveraging various interconnections between different types of nodes present in the dataset. In particular, we make the following contributions -- (i) We propose a simple yet effective metric, called Hierarchical Meta-Path Score (HMPS) to measure the proximity of an unknown user to the other known pool of spammers. (ii) We design a feedback-based active learning strategy and show that it significantly outperforms three state-of-the-art baselines for the task of spam detection. Our method achieves 6.9% and 67.3% higher F1-score and AUC, respectively compared to the best baseline method. (iii) To overcome the problem of less training instances for supervised learning, we show that our proposed feedback strategy achieves 25.6% and 46% higher F1-score and AUC respectively than other oversampling strategies. Finally, we perform a case study to show how our method is capable of detecting those users as spammers who have not been suspended by Twitter (and other baselines) yet."}}
{"id": "HJNdxM-dWr", "cdate": 1514764800000, "mdate": null, "content": {"title": "VIZ-Wiki: Generating Visual Summaries to Factoid Threads in Community Question Answering Services", "abstract": "In this demo, we present VIZ-Wiki, a browser extension which generates an overview of summarizable threads in Question Answering forums. It reduces a user's effort to go through lengthy text-based, sarcastic and highly critiqued answers. Our tool can be used to collect community opinion from popular discussion sites like Quora, Yahoo! Answers, Reddit etc. as well as topic-centric ones such as Askubuntu, Stackoverflow. We rely on textual information of these forums to extract insightful summaries for a reader. VIZ-Wiki provides users a pie-graph view marking popular choices when such a question link is raised. A button guides them to detailed statistics and relevant list of answers. It further highlights sentences relevant to an answer choice in the text. VIZ-Wiki deals with answers contradicted by other users, prioritizes highly-recommended ones and avoids sarcasm. We test our model on the factoid questions dataset of Yahoo! Answers and obtain a macro precision of 0.6 on displayed answers and a macro recall of 0.69, beating the baseline significantly. To the best of our knowledge, VIZ-Wiki is the first attempt to visualize answers for questions in community question answering services. In the spirit of reproducibility, we have released the code and a demonstration video public at \\urlhttp://goo.gl/cyx3EF and \\urlhttps://youtu.be/XNmRa_jtmC8 respectively"}}
