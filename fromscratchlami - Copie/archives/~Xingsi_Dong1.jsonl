{"id": "Y0Bm5tL92lg", "cdate": 1652737412141, "mdate": null, "content": {"title": "Adaptation Accelerating Sampling-based Bayesian Inference in Attractor Neural Networks", "abstract": "The brain performs probabilistic Bayesian inference to interpret the external world. The sampling-based view assumes that the brain represents the stimulus posterior distribution via samples of stochastic neuronal responses. Although the idea of sampling-based inference is appealing, it faces a critical challenge of whether stochastic sampling is fast enough to match the rapid computation of the brain. In this study, we explore how latent stimulus sampling can be accelerated in neural circuits. Specifically, we consider a canonical neural circuit model called continuous attractor neural networks (CANNs) and investigate how sampling-based inference of latent continuous variables is accelerated in CANNs. Intriguingly, we find that by including noisy adaptation in the neuronal dynamics, the CANN is able to speed up the sampling process significantly. We theoretically derive that the CANN with noisy adaptation implements the efficient sampling method called Hamiltonian dynamics with friction, where noisy adaption effectively plays the role of momentum. We theoretically analyze the sampling performances of the network and derive the condition when the acceleration has the maximum effect. Simulation results confirm our theoretical analyses. We further extend the model to coupled CANNs and demonstrate that noisy adaptation accelerates the sampling of the posterior distribution of multivariate stimuli. We hope that this study enhances our understanding of how Bayesian inference is realized in the brain."}}
{"id": "Pvzqji3at5", "cdate": 1621629774590, "mdate": null, "content": {"title": "Noisy Adaptation Generates L\u00e9vy Flights in Attractor Neural Networks", "abstract": "L\u00e9vy flights describe a special class of random walks whose step sizes satisfy a power-law tailed distribution. As being an efficient\nsearching strategy in unknown environments, L\u00e9vy flights are widely observed in animal foraging behaviors. Recent studies further showed that human cognitive functions also exhibit the characteristics of L\u00e9vy flights.  Despite being a general phenomenon, the neural mechanism at the circuit level for generating L\u00e9vy flights remains unresolved. Here, we investigate how L\u00e9vy flights can be achieved in attractor neural networks. To elucidate the underlying mechanism clearly, we first study continuous attractor neural networks (CANNs), and find that noisy neural adaptation, exemplified by spike frequency adaptation (SFA) in this work,  can generate L\u00e9vy flights representing transitions of the network state in the attractor space. Specifically, the strength of SFA defines a travelling wave boundary, below which the network state displays local Brownian motion, and above which the network state displays long-jump motion. Noises in neural adaptation causes the network state to intermittently switch between these two motion modes, manifesting the characteristics of L\u00e9vy flights. We further extend the study to a general attractor neural network, and demonstrate that our model can explain the L\u00e9vy-flight phenomenon observed during free memory retrieval of humans. We hope that this study will give us insight into understanding the neural mechanism for optimal information processing in the brain."}}
