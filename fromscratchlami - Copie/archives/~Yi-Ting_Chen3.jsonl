{"id": "wA6G6giB6F", "cdate": 1640995200000, "mdate": 1666880917060, "content": {"title": "MetaDIP: Accelerating Deep Image Prior with Meta Learning", "abstract": "Deep image prior (DIP) is a recently proposed technique for solving imaging inverse problems by fitting the reconstructed images to the output of an untrained convolutional neural network. Unlike pretrained feedforward neural networks, the same DIP can generalize to arbitrary inverse problems, from denoising to phase retrieval, while offering competitive performance at each task. The central disadvantage of DIP is that, while feedforward neural networks can reconstruct an image in a single pass, DIP must gradually update its weights over hundreds to thousands of iterations, at a significant computational cost. In this work we use meta-learning to massively accelerate DIP-based reconstructions. By learning a proper initialization for the DIP weights, we demonstrate a 10x improvement in runtimes across a range of inverse imaging tasks. Moreover, we demonstrate that a network trained to quickly reconstruct faces also generalizes to reconstructing natural image patches."}}
{"id": "hh5M4XH438Y", "cdate": 1609459200000, "mdate": 1666880917072, "content": {"title": "Multimodal Object Detection via Bayesian Fusion", "abstract": "Object detection with multimodal inputs can improve many safety-critical systems such as autonomous vehicles (AVs). Motivated by AVs that operate in both day and night, we study multimodal object detection with RGB and thermal cameras, since the latter provides much stronger object signatures under poor illumination. We explore strategies for fusing information from different modalities. Our key contribution is a probabilistic ensembling technique, ProbEn, a simple non-learned method that fuses together detections from multi-modalities. We derive ProbEn from Bayes' rule and first principles that assume conditional independence across modalities. Through probabilistic marginalization, ProbEn elegantly handles missing modalities when detectors do not fire on the same object. Importantly, ProbEn also notably improves multimodal detection even when the conditional independence assumption does not hold, e.g., fusing outputs from other fusion methods (both off-the-shelf and trained in-house). We validate ProbEn on two benchmarks containing both aligned (KAIST) and unaligned (FLIR) multimodal images, showing that ProbEn outperforms prior work by more than 13% in relative performance!"}}
{"id": "rXFW1bQlOaS", "cdate": 1546300800000, "mdate": null, "content": {"title": "FSA-Net: Learning Fine-Grained Structure Aggregation for Head Pose Estimation From a Single Image.", "abstract": "This paper proposes a method for head pose estimation from a single image. Previous methods often predict head poses through landmark or depth estimation and would require more computation than necessary. Our method is based on regression and feature aggregation. For having a compact model, we employ the soft stagewise regression scheme. Existing feature aggregation methods treat inputs as a bag of features and thus ignore their spatial relationship in a feature map. We propose to learn a fine-grained structure mapping for spatially grouping features before aggregation. The fine-grained structure provides part-based information and pooled values. By utilizing learnable and non-learnable importance over the spatial location, different model variants can be generated and form a complementary ensemble. Experiments show that our method outperforms the state-of-the-art methods including both the landmark-free ones and the ones based on landmark or depth estimation. With only a single RGB frame as input, our method even outperforms methods utilizing multi-modality information (RGB-D, RGB-Time) on estimating the yaw angle. Furthermore, the memory overhead of our model is 100 times smaller than those of previous methods."}}
{"id": "Kw6pf6GaCd", "cdate": 1546300800000, "mdate": 1666880917067, "content": {"title": "FSA-Net: Learning Fine-Grained Structure Aggregation for Head Pose Estimation From a Single Image", "abstract": "This paper proposes a method for head pose estimation from a single image. Previous methods often predict head poses through landmark or depth estimation and would require more computation than necessary. Our method is based on regression and feature aggregation. For having a compact model, we employ the soft stagewise regression scheme. Existing feature aggregation methods treat inputs as a bag of features and thus ignore their spatial relationship in a feature map. We propose to learn a fine-grained structure mapping for spatially grouping features before aggregation. The fine-grained structure provides part-based information and pooled values. By utilizing learnable and non-learnable importance over the spatial location, different model variants can be generated and form a complementary ensemble. Experiments show that our method outperforms the state-of-the-art methods including both the landmark-free ones and the ones based on landmark or depth estimation. With only a single RGB frame as input, our method even outperforms methods utilizing multi-modality information (RGB-D, RGB-Time) on estimating the yaw angle. Furthermore, the memory overhead of our model is 100 times smaller than those of previous methods."}}
{"id": "NDiO9Ou3CVu", "cdate": 1514764800000, "mdate": 1666880917078, "content": {"title": "SRIANN: Sphere Ring Intersection for Approximate Nearest Neighbor Search in Videos", "abstract": "In the field of approximate nearest neighbor (ANN) search, rare of the existing approaches are tailored for video applications. The Ring Intersection Approximate Nearest Neighbor (RIANN) is the first ANN search algorithm for videos. It achieves real-time by performing the ANN search on the sparse grid and interpolating others. For some applications, the dense ANN search is needed to ensure the searching accuracy. To achieve dense ANN search in real-time, we consider the parallel computing as a solution. However, the RIANN algorithm is not suitable for parallel computing as the algorithm itself suffers from bad thread coherency. In this paper, we propose the Sphere Ring Intersection Approximate Nearest Neighbor (SRIANN), which solves the problem of bad thread coherency and improves the accuracy of ANN search compared to the original RIANN method. The experimental results show that the proposed method is the only one able to perform dense ANN search for CIF videos in real-time."}}
{"id": "LNJytkMG1XM", "cdate": 1451606400000, "mdate": 1666880917056, "content": {"title": "Fast video super-resolution via approximate nearest neighbor search", "abstract": "Image super-resolution has gained much attention in these years, while video super-resolution remains almost unchanged. In this paper, we propose a fast super-resolution method for video. We exploit recent development of learning-based technique that achieves state-of-the-art in accuracy and efficiency for image super-resolution. We leverage the temporal coherency of video contents to approximate the nearest neighbor search in learning-based SR. Experimental results show that our method is able to produce visually similar or better results while being 20 times faster than baseline frame-by-frame fast image SR and being orders of magnitude faster than complex optimization-based video SR."}}
