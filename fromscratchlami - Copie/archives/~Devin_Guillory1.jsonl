{"id": "cPhfgGIbVfZ", "cdate": 1663850442243, "mdate": null, "content": {"title": "ErrorAug: Making Errors to Find Errors in Semantic Segmentation", "abstract": "In order to develop trustworthy downstream applications for semantic segmentation models, it is important to not only understand the performance of a model on  datasets, but to localize areas where the model may produce errors.\nPixel-wise error prediction of semantic segmentation maps is a challenging problem in which prior work relies on complicated image resynthesis pipelines.\nWe introduce \\it{error augmentation}, a framework which enables us to learn robust error detectors by applying data transformations independently on the predicted segmentation maps.\nThis approach enables direct prediction of pixel-wise error in semantic segmentation maps, an approach explored as a naive baseline in prior works, to achieve state of the art performance.  \nAs a proof-of-concept we propose a series of three simple transformations that generate challenging segmentation errors by swapping pixel predictions within a segmentation map.\nOur approach outperforms previous methods of error detection for semantic segmentation across all metrics and improves performance by over $7.8\\%$ on AUPR-Error.\nAdditionally, we show that our approach not only generalizes to unseen test examples, but remains reliable despite significant shifts in the target domain.\n"}}
{"id": "eR2dG8yjnQ", "cdate": 1663850372267, "mdate": null, "content": {"title": "Using Language to Extend to Unseen Domains", "abstract": "It is expensive to collect training data for every possible domain that a vision model may encounter when deployed. We instead consider how simply $\\textit{verbalizing}$ the training domain (e.g.``photos of birds'') as well as domains we want to extend to but do not have data for (e.g.``paintings of birds'') can improve robustness. Using a multimodal model with a joint image and language embedding space, our method $\\textit{LADS}$ learns a transformation of the image embeddings from the source domain to each target domain, while preserving task relevant information. Without using any images from the target domain, we show that over the $\\textit{extended}$ domain containing both source and target, $\\textit{LADS}$ outperforms standard fine-tuning and ensemble approaches over a suite of 4 benchmarks targeting domain adaptation and dataset bias."}}
{"id": "ZfcosR9vZ-j", "cdate": 1632875602883, "mdate": null, "content": {"title": "Pyramid Mini-Batching for Optimal Transport", "abstract": "Optimal transport theory provides a useful tool to measure the differences between two distributions.\nAligning distributions by minimizing optimal transport distances has been shown to be effective in a variety of machine learning settings, including generative modeling and domain adaptation. However, computing optimal transport distances over large numbers of data points is very time-consuming and intractable for measuring the distances between discrete distributions with large numbers of data points. In this work we propose a geometric sampling scheme which partitions the datasets into pyramid-based encodings. Our approach, Pyramid Mini-Batching, significantly improves the quality of optimal transport approximations and downstream alignments with minimal computational overhead. We perform experiments over the Discrete Optimal Transport benchmark to demonstrate the effectiveness of this strategy over multiple established optimal transport settings and see that our approach improves estimates of OT distances by nearly $30\\%$ for single pass estimation. Furthermore, we see that when attempting to minimize optimal transport distance our approach is ten times more effective than with random mini-batch sampling. To highlight the practical benefits of this approach, we use optimal transport distance in domain adaptation settings and show our approach produces state of the results on large-scale domain adaptation problems VisDA17 and DomainNet. Ablation studies indicate that our sampling approach could be combined with conventional distribution alignment approaches and over substantial improvements to their results."}}
{"id": "r1bKDEZuZH", "cdate": 1483228800000, "mdate": null, "content": {"title": "An Ensemble-based Approach to Click-Through Rate Prediction for Promoted Listings at Etsy", "abstract": "Etsy1 is a global marketplace where people across the world connect to make, buy and sell unique goods. Sellers at Etsy can promote their product listings via advertising campaigns similar to traditional sponsored search ads. Click-Through Rate (CTR) prediction is an integral part of online search advertising systems where it is utilized as an input to auctions which determine the final ranking of promoted listings to a particular user for each query. In this paper, we provide a holistic view of Etsy's promoted listings' CTR prediction system and propose an ensemble learning approach which is based on historical or behavioral signals for older listings as well as content-based features for new listings. We obtain representations from texts and images by utilizing state-of-the-art deep learning techniques and employ multimodal learning to combine these different signals. We compare the system to non-trivial baselines on a large-scale real world dataset from Etsy, demonstrating the effectiveness of the model and strong correlations between offline experiments and online performance. The paper is also the first technical overview to this kind of product in e-commerce context."}}
{"id": "47Lo6H5Ugv", "cdate": 1451606400000, "mdate": null, "content": {"title": "A Probabilistic Framework for Real-time 3D Segmentation using Spatial, Temporal, and Semantic Cues", "abstract": ""}}
