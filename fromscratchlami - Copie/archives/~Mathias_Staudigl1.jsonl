{"id": "p9s1Vn_rXkn", "cdate": 1577836800000, "mdate": null, "content": {"title": "Incentive compatibility in sender-receiver stopping games.", "abstract": "We introduce a model of sender-receiver stopping games, where the state of the world follows an iid--process throughout the game. At each period, the sender observes the current state, and sends a message to the receiver, suggesting either to stop or to continue. The receiver, only seeing the message but not the state, decides either to stop the game, or to continue which takes the game to the next period. The payoff to each player is a function of the state when the receiver quits, with higher states leading to better payoffs. The horizon of the game can be finite or infinite. We prove existence and uniqueness of responsive (i.e. non-babbling) Perfect Bayesian Equilibrium (PBE) under mild conditions on the game primitives in the case where the players are sufficiently patient. The responsive PBE has a remarkably simple structure, which builds on the identification of an easy-to-implement and compute class of threshold strategies for the sender. With the help of these threshold strategies, we derive simple expressions describing this PBE. It turns out that in this PBE the receiver obediently follows the recommendations of the sender. Hence, surprisingly, the sender alone plays the decisive role, and regardless of the payoff function of the receiver the sender always obtains the best possible payoff for himself."}}
{"id": "2vX4TiOQoPa", "cdate": 1577836800000, "mdate": null, "content": {"title": "Self-concordant analysis of Frank-Wolfe algorithms.", "abstract": "Projection-free optimization via different variants of the Frank-Wolfe (FW), a.k.a. Conditional Gradient method has become one of the cornerstones in optimization for machine learning since in many cases the linear minimization oracle is much cheaper to implement than projections and some sparsity needs to be preserved. In a number of applications, e.g. Poisson inverse problems or quantum state tomography, the loss is given by a self-concordant (SC) function having unbounded curvature, implying absence of theoretical guarantees for the existing FW methods. We use the theory of SC functions to provide a new adaptive step size for FW methods and prove global convergence rate O(1/k) after k iterations. If the problem admits a stronger local linear minimization oracle, we construct a novel FW method with linear convergence rate for SC functions."}}
{"id": "zConuRH2d3n", "cdate": 1546300800000, "mdate": null, "content": {"title": "Distributed forward-backward (half) forward algorithms for generalized Nash equilibrium seeking.", "abstract": "We present two distributed algorithms for the computation of a generalized Nash equilibrium in monotone games. The first algorithm follows from a forward-backward-forward operator splitting, while the second, which requires the pseudo-gradient mapping of the game to be cocoercive, follows from the forward-backward-half-forward operator splitting. Finally, we compare them with the distributed, preconditioned, forward-backward algorithm via numerical experiments."}}
{"id": "lpHo_OTTWbJ", "cdate": 1546300800000, "mdate": null, "content": {"title": "Inducing strong convergence of trajectories in dynamical systems associated to monotone inclusions with composite structure.", "abstract": "In this work we investigate dynamical systems designed to approach the solution sets of inclusion problems involving the sum of two maximally monotone operators. Our aim is to design methods which guarantee strong convergence of trajectories towards the minimum norm solution of the underlying monotone inclusion problem. To that end, we investigate in detail the asymptotic behavior of dynamical systems perturbed by a Tikhonov regularization where either the maximally monotone operators themselves, or the vector field of the dynamical system is regularized. In both cases we prove strong convergence of the trajectories towards minimum norm solutions to an underlying monotone inclusion problem, and we illustrate numerically qualitative differences between these two complementary regularization strategies. The so-constructed dynamical systems are either of Krasnoselskii-Mann, of forward-backward type or of forward-backward-forward type, and with the help of injected regularization we demonstrate seminal results on the strong convergence of Hilbert space valued evolutions designed to solve monotone inclusion and equilibrium problems."}}
{"id": "eJq1qtiQHv", "cdate": 1546300800000, "mdate": null, "content": {"title": "Generalized Self-concordant Hessian-barrier algorithms.", "abstract": "Many problems in statistical learning, imaging, and computer vision involve the optimization of a non-convex objective function with singularities at the boundary of the feasible set. For such challenging instances, we develop a new interior-point technique building on the Hessian-barrier algorithm recently introduced in Bomze, Mertikopoulos, Schachinger and Staudigl, [SIAM J. Opt. 2019 29(3), pp. 2100-2127], where the Riemannian metric is induced by a generalized self-concordant function. This class of functions is sufficiently general to include most of the commonly used barrier functions in the literature of interior point methods. We prove global convergence to an approximate stationary point of the method, and in cases where the feasible set admits an easily computable self-concordant barrier, we verify worst-case optimal iteration complexity of the method. Applications in non-convex statistical estimation and $L^{p}$-minimization are discussed to given the efficiency of the method."}}
{"id": "4jVLQ2odDfr", "cdate": 1546300800000, "mdate": null, "content": {"title": "Hessian Barrier Algorithms for Linearly Constrained Optimization Problems.", "abstract": "In this paper, we propose an interior-point method for linearly constrained---and possibly nonconvex---optimization problems. The method---which we call the Hessian barrier algorithm (HBA)---combines a forward Euler discretization of Hessian--Riemannian gradient flows with an Armijo backtracking step-size policy. In this way, HBA can be seen as an alternative to mirror descent, and contains as special cases the affine scaling algorithm, regularized Newton processes, and several other iterative solution methods. Our main result is that, modulo a nondegeneracy condition, the algorithm converges to the problem's critical set; hence, in the convex case, the algorithm converges globally to the problem's minimum set. In the case of linearly constrained quadratic programs (not necessarily convex), we also show that the method's convergence rate is $O(1/k\\rho)$ for some $\\rho\\in(0,1]$ that depends only on the choice of kernel function (i.e., not on the problem's primitives). These theoretical results are validated by numerical experiments in standard nonconvex test functions and large-scale traffic assignment problems."}}
{"id": "395eLDnhekE", "cdate": 1546300800000, "mdate": null, "content": {"title": "Forward-backward-forward methods with variance reduction for stochastic variational inequalities.", "abstract": "We develop a new stochastic algorithm with variance reduction for solving pseudo-monotone stochastic variational inequalities. Our method builds on Tseng's forward-backward-forward (FBF) algorithm, which is known in the deterministic literature to be a valuable alternative to Korpelevich's extragradient method when solving variational inequalities over a convex and closed set governed by pseudo-monotone, Lipschitz continuous operators. The main computational advantage of Tseng's algorithm is that it relies only on a single projection step and two independent queries of a stochastic oracle. Our algorithm incorporates a variance reduction mechanism and leads to almost sure (a.s.) convergence to an optimal solution. To the best of our knowledge, this is the first stochastic look-ahead algorithm achieving this by using only a single projection at each iteration.."}}
{"id": "PBFJA1d6aRb", "cdate": 1514764800000, "mdate": null, "content": {"title": "Stochastic Mirror Descent Dynamics and Their Convergence in Monotone Variational Inequalities.", "abstract": "We examine a class of stochastic mirror descent dynamics in the context of monotone variational inequalities (including Nash equilibrium and saddle-point problems). The dynamics under study are formulated as a stochastic differential equation, driven by a (single-valued) monotone operator and perturbed by a Brownian motion. The system\u2019s controllable parameters are two variable weight sequences, that, respectively, pre- and post-multiply the driver of the process. By carefully tuning these parameters, we obtain global convergence in the ergodic sense, and we estimate the average rate of convergence of the process. We also establish a large deviations principle, showing that individual trajectories exhibit exponential concentration around this average."}}
{"id": "LLKzUMGu4a", "cdate": 1514764800000, "mdate": null, "content": {"title": "Sample Path Large Deviations for Stochastic Evolutionary Game Dynamics.", "abstract": "We study a model of stochastic evolutionary game dynamics in which the probabilities that agents choose suboptimal actions are dependent on payoff consequences. We prove a sample path large deviati..."}}
{"id": "H7zLvMf_iU", "cdate": 1514764800000, "mdate": null, "content": {"title": "Learning in time-varying games.", "abstract": "We examine the long-run behavior of multi-agent online learning in games that evolve over time. Specifically, we focus on a wide class of policies based on mirror descent, and we show that the induced sequence of play (a) converges to Nash equilibrium in time-varying games that stabilize in the long run to a strictly monotone limit; and (b) it stays asymptotically close to the evolving equilibrium of the sequence of stage games (assuming they are strongly monotone). Our results apply to both gradient-based and payoff-based feedback - i.e., the \"bandit feedback\" case where players only get to observe the payoffs of their chosen actions."}}
