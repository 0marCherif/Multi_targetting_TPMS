{"id": "oaY_9as0yC", "cdate": 1672531200000, "mdate": 1683848954517, "content": {"title": "Clinically Relevant Latent Space Embedding of Cancer Histopathology Slides through Variational Autoencoder Based Image Compression", "abstract": "In this paper, we introduce a Variational Autoencoder (VAE) based training approach that can compress and decompress cancer pathology slides at a compression ratio of 1:512, which is better than the previously reported state of the art (SOTA) in the literature, while still maintaining accuracy in clinical validation tasks. The compression approach was tested on more common computer vision datasets such as CIFAR10, and we explore which image characteristics enable this compression ratio on cancer imaging data but not generic images. We generate and visualize embeddings from the compressed latent space and demonstrate how they are useful for clinical interpretation of data, and how in the future such latent embeddings can be used to accelerate search of clinical imaging data."}}
{"id": "dUgeM8RRSDq", "cdate": 1640995200000, "mdate": 1683848954775, "content": {"title": "Generalized Reinforcement Learning: Experience Particles, Action Operator, Reinforcement Field, Memory Association, and Decision Concepts", "abstract": "Learning a control policy capable of adapting to time-varying and potentially evolving system dynamics has been a great challenge to the mainstream reinforcement learning (RL). Mainly, the ever-changing system properties would continuously affect how the RL agent interacts with the state space through its actions, which effectively (re-)introduces concept drifts to the underlying policy learning process. We postulated that higher adaptability for the control policy can be achieved by characterizing and representing actions with extra \"degrees of freedom\" and thereby, with greater flexibility, adjusts to variations from the action's \"behavioral\" outcomes, including how these actions get carried out in real time and the shift in the action set itself. This paper proposes a Bayesian-flavored generalized RL framework by first establishing the notion of parametric action model to better cope with uncertainty and fluid action behaviors, followed by introducing the notion of reinforcement field as a physics-inspired construct established through \"polarized experience particles\" maintained in the RL agent's working memory. These particles effectively encode the agent's dynamic learning experience that evolves over time in a self-organizing way. Using the reinforcement field as a substrate, we will further generalize the policy search to incorporate high-level decision concepts by viewing the past memory as an implicit graph structure, in which the memory instances, or particles, are interconnected with their degrees of associability/similarity defined and quantified such that the \"associative memory\" principle can be consistently applied to establish and augment the learning agent's evolving world model."}}
{"id": "Wd0dSha6Q-", "cdate": 1640995200000, "mdate": 1683848955195, "content": {"title": "Learning Hierarchical Traversability Representations for Efficient Multi-Resolution Path Planning*", "abstract": "Path planning on grid-based obstacle maps is an essential and much-studied problem with applications in robotics and autonomy. Traditionally, in the AI community, heuristic search methods (e.g., based on Dijkstra, $\\text{A}^{*}$, or random trees) are used to solve this problem. This search, however, incurs a high computational cost that grows with the size and resolution of the obstacle grid and has to be mitigated with effective heuristics to allow path planning in real-time. This work introduces a learning framework using a deep neural network with a stackable convolution kernel to establish a hierarchy of directional traversability representations with decreasing resolution that can serve as an efficient heuristic to guide a multi-resolution path planner. This path planner finds paths efficiently, starting on the lowest resolution traversability representation and then refining the path incrementally through the hierarchy until it addresses the original obstacle constraints. We demonstrate the benefits and applicability of this approach on datasets of maps created to represent both indoor and outdoor environments to represent different real-world applications. The conducted experiments show that our method can accelerate path planning by 40% in indoor environments and 65% in outdoor environments compared to the same heuristic search method applied to the original obstacle map, which demonstrates the effectiveness of this method."}}
{"id": "UkBAaVKCSTn", "cdate": 1640995200000, "mdate": 1683848954747, "content": {"title": "An AI-based Approach for Improved Sign Language Recognition using Multiple Videos", "abstract": "People with hearing and speaking disabilities face significant hurdles in communication. The knowledge of sign language can help mitigate these hurdles, but most people without disabilities, including relatives, friends, and care providers, cannot understand sign language. The availability of automated tools can allow people with disabilities and those around them to communicate ubiquitously and in a variety of situations with non-signers. There are currently two main approaches for recognizing sign language gestures. The first is a hardware-based approach, involving gloves or other hardware to track hand position and determine gestures. The second is a software-based approach, where a video is taken of the hands and gestures are classified using computer vision techniques. However, some hardware, such as a phone's internal sensor or a device worn on the arm to track muscle data, is less accurate, and wearing them can be cumbersome or uncomfortable. The software-based approach, on the other hand, is dependent on the lighting conditions and on the contrast between the hands and the background. We propose a hybrid approach that takes advantage of low-cost sensory hardware and combines it with a smart sign-recognition algorithm with the goal of developing a more efficient gesture recognition system. The Myo band-based approach using the Support Vector Machine method achieves an accuracy of only 49%. The software-based approach uses the Convolutional Neural Network (CNN) and Recurrent Neural Network (RNN) methods to train the Myo-based module and achieves an accuracy of over 80% in our experiments. Our method combines the two approaches and shows the potential for improvement. Our experiments are done with a dataset of nine gestures generated from multiple videos, each repeated five times for a total of 45 trials for both the software-based and hardware-based modules. Apart from showing the performance of each approach, our results show that with a more improved hardware module, the accuracy of the combined approach can be significantly improved."}}
{"id": "KsdIIs0tYcl", "cdate": 1640995200000, "mdate": 1683848954844, "content": {"title": "2D Fingertip Localization on Depth Videos Using Paired Video-to-Video Translation", "abstract": "We propose a two-stage pipeline and formulate 2D hand keypoint localization as a problem of conditional video generation. The goal is to learn a mapping function from an input depth video in the source domain to an output depth video along with 5 color marks on each fingertip by enforcing temporal consistency constraints. Next, by applying color segmentation techniques in HSV domain, we extract the center of each segmented part as 2D coordinates of fingertips on the translated video. To the best of our knowledge, this is the first work on fingertip localization on depth videos through domain adaptation. Our comparative experimental results with the state-of-the-art single-frame hand pose estimation on the challenging NYU dataset demonstrates that by exploiting temporal information, our model manifests better hand appearance consistency in video-to-video synthesis stage which leads to accurate estimations of 2D hand poses under motion blur by fast hand motion."}}
{"id": "3s-7ZMrAu4W", "cdate": 1640995200000, "mdate": 1683848954865, "content": {"title": "A SSIM Guided cGAN Architecture For Clinically Driven Generative Image Synthesis of Multiplexed Spatial Proteomics Channels", "abstract": "Here we present a structural similarity index measure (SSIM) guided conditional Generative Adversarial Network (cGAN) that generatively performs image-to-image (i2i) synthesis to generate photo-accurate protein channels in multiplexed spatial proteomics images. This approach can be utilized to accurately generate missing spatial proteomics channels that were not included during experimental data collection either at the bench or the clinic. Experimental spatial proteomic data from the Human BioMolecular Atlas Program (HuBMAP) was used to generate spatial representations of missing proteins through a U-Net based image synthesis pipeline. HuBMAP channels were hierarchically clustered by the (SSIM) as a heuristic to obtain the minimal set needed to recapitulate the underlying biology represented by the spatial landscape of proteins. We subsequently prove that our SSIM based architecture allows for scaling of generative image synthesis to slides with up to 100 channels, which is better than current state of the art algorithms which are limited to data with 11 channels. We validate these claims by generating a new experimental spatial proteomics data set from human lung adenocarcinoma tissue sections and show that a model trained on HuBMAP can accurately synthesize channels from our new data set. The ability to recapitulate experimental data from sparsely stained multiplexed histological slides containing spatial proteomic will have tremendous impact on medical diagnostics and drug development, and also raises important questions on the medical ethics of utilizing data produced by generative image synthesis in the clinical setting. The algorithm that we present in this paper will allow researchers and clinicians to save time and costs in proteomics based histological staining while also increasing the amount of data that they can generate through their experiments."}}
{"id": "0rx6xP35nFW", "cdate": 1640995200000, "mdate": 1683848954587, "content": {"title": "Person Identification And Tinetti Score Prediction Using Balance Parameters : A Machine Learning Approach To Determine Fall Risk", "abstract": "This paper presents a Machine Learning approach using sensor data from a Smart Floor aimed at addressing a substantial health problem among the elderly population, namely falls. Studies show that one-third of community-dwelling people over age 65 will experience one or more falls each year. Balance and walking patterns are useful indicators to determine the fall risk and are influenced by several parameters and conditions. The Tinetti test is widely used to assess the gait and balance in elder adults to determine the perception of balance and stability during daily activities and fear of falling. It is considered a good indicator of the fall risk. In this research, we aimed to provide a new way for fall risk reduction and early detection of the onset of chronic health conditions by creating a Machine Learning model for predicting Tinetti scores based on foot pressure data arising in common everyday activities. The goal is for this to help improve eldercare through constant monitoring. This paper focuses on designing algorithms to extract balance parameters from standing instances arising during normal everyday life and to build individualized models capable of differentiating normal or abnormal patterns for an individual. A variety of time and frequency domain parameters are built based on the center of pressure (CoP) values obtained from time-series data from a pressure monitoring floor sensor. A classification model is build using a support vector machine for distinguishing 30 individuals based solely on these balance parameters. Further, using these parameters, a regression model is built to predict the balance and the Tinetti score of an individual which is used to predict the fall risk. This novel approach for Tinetti score prediction by just using balance analysis could be used in isolation or in combination with other assessments to assess health changes and to prevent falls before they happen."}}
{"id": "tf4Crz2oOCz", "cdate": 1609459200000, "mdate": 1669138240497, "content": {"title": "Learning the Next Best View for 3D Point Clouds via Topological Features", "abstract": "In this paper, we introduce a reinforcement learning approach utilizing a novel topology-based information gain metric for directing the next best view of a noisy 3D sensor. The metric combines the disjoint sections of an observed surface to focus on high-detail features such as holes and concave sections. Experimental results show that our approach can aid in establishing the placement of a robotic sensor to optimize the information provided by its streaming point cloud data. Furthermore, a labeled dataset of 3D objects, a CAD design for a custom robotic manipulator, and software for the transformation, union, and registration of point clouds has been publicly released to the research community."}}
{"id": "qE8EeuWc1VP", "cdate": 1609459200000, "mdate": 1683848954537, "content": {"title": "An Automatic Calibration Technique for Force Sensors in a Dynamic Smart Floor Environment", "abstract": "Pressure-sensitive smart floors deployed within homes can give great insight to the health and activity level of individuals through gait and location information. Due to the ever-changing dynamic nature of household deployments involving furniture movement, floor tile shifts, and sensor drift, challenges arise in ensuring the constant reliability of floor sensor readings over time. This paper presents a procedure to automatically calibrate a smart floor\u2019s force sensors without specialized physical effort. The calibration algorithm automatically filters out non-human static weight while retaining weight generated by human activity. This technique is designed to correctly translate sensor values to weight units even when direct access to the force sensors is not available and when a shared tile floor sits above the sensor grid. These calibrated sensor values can then feed machine learning techniques used to extract individual contact points generated by a person\u2019s walking cycle. Using known human weights but no knowledge of the human\u2019s location or walking trajectory, this calibration technique resulted in small percentage differences of -7.8%, -4.8%, and -1.6% for the mean, median, and mode of calibrated smart floor walking sequences, respectively."}}
{"id": "nqrq8vfeGEv", "cdate": 1609459200000, "mdate": null, "content": {"title": "Learning the Next Best View for 3D Point Clouds via Topological Features", "abstract": "In this paper, we introduce a reinforcement learning approach utilizing a novel topology-based information gain metric for directing the next best view of a noisy 3D sensor. The metric combines the disjoint sections of an observed surface to focus on high-detail features such as holes and concave sections. Experimental results show that our approach can aid in establishing the placement of a robotic sensor to optimize the information provided by its streaming point cloud data. Furthermore, a labeled dataset of 3D objects, a CAD design for a custom robotic manipulator, and software for the transformation, union, and registration of point clouds has been publicly released to the research community."}}
