{"id": "Du7eR4no7lU", "cdate": 1691264829270, "mdate": 1691264829270, "content": {"title": "Mind the Gap between the Application Track and the Real World", "abstract": "Recent advances in NLP have led to a rise in inter-disciplinary and application-oriented research. While this demonstrates the growing real-world impact of the field, research papers frequently feature experiments that do not account for the complexities of realistic data and environments. To explore the extent of this gap, we investigate the relationship between the real-world motivations described in NLP papers and the models and evaluation which comprise the proposed solution. We first survey papers from the NLP Applications track from ACL 2020 and EMNLP 2020, asking which papers have differences between their stated motivation and their experimental setting, and if so, mention them. We find that many papers fall short of considering real-world input and output conditions due to adopting simplified modeling or evaluation settings. As a case study, we then empirically show that the performance of an educational dialog understanding system deteriorates when used in a realistic classroom environment."}}
{"id": "oQQDrjb17MW", "cdate": 1686160744316, "mdate": 1686160744316, "content": {"title": "A comparative analysis of automatic speech recognition errors in small group classroom discourse.", "abstract": "In collaborative learning environments, effective intelligent\n  learning systems need to accurately analyze and understand the collaborative\n  discourse between learners (i.e., group modeling) to provide adaptive support. We\n  investigate how automatic speech recognition~(ASR) errors influence\n  discourse models of small group collaboration in noisy real-world\n  classrooms. Our dataset consisted of 30 students recorded by\n  consumer off-the-shelf microphones~(Yeti Blue) while engaging in\n  dyadic- and triadic- collaborative learning in a multi-day STEM\n  curriculum unit. We found that two state-of-the-art ASR systems\n  (Google Speech and OpenAI Whisper) yielded very high word error rates\n  (0.822, 0.847) but very different profiles of error with Google\n  being more conservative, rejecting 38\\% of utterances instead of\n  12\\% for Whisper. Next, we examined how these ASR errors influenced\n  down-stream small group modeling based on pre-trained large language\n  models for three tasks: Abstract Meaning Representation\n  parsing~(\\NameAMR), on-task/off-task detection~(\\NameOnTask), and\n  Accountable Productive Talk prediction~(\\NameAPT). As expected,\n  models trained on clean human transcripts yielded degraded\n  performance on all three tasks, measured by the transfer ratio~(TR). However, the TR of the specific\n  sentence-level \\NameAMR~task~(.39 - .62) was much lower than that of the\n  abstract discourse-level \\NameOnTask~(.63- .94) and \\NameAPT~\n  tasks~(.64-.72). Furthermore, different training strategies that\n  incorporated ASR transcripts alone or as augmentations of human\n  transcripts increased accuracy for the discourse-level\n  tasks~(\\NameOnTask~and \\NameAPT) but not \\NameAMR. Simulation\n  experiments suggested that the models were tolerant of missing\n  utterances in the dialog context, and that jointly improving ASR\n  accuracy on important word classes~(e.g., verbs and nouns) can\n  improve performance across all tasks. Overall, our results\n  provide insights into how different types of NLP-based tasks might\n  be tolerant of ASR errors under extremely noisy conditions and\n  provide suggestions for how to improve accuracy in small group\n  modeling settings for a more equitable, engaging, and adaptive\ncollaborative learning environment."}}
{"id": "TUcx1OF8Qh", "cdate": 1685702334548, "mdate": 1685702334548, "content": {"title": "Generate Me a Bedtime Story: Leveraging Natural Language Processing for Early Vocabulary Enhancement", "abstract": "A young child\u2019s vocabulary size is correlated with their level of personal wellbeing and future academic success. Yet, interventions aimed at increasing early vocabulary would ideally be tailored to each individual child\u2019s needs and interests, and such personalization would be impossible without technological support. Here, we explore if and how natural language processing can be used to create individual- ized bedtime stories around target words to be learned by preschoolers. Generating stories from scratch is challenging and often results in stories of low quality. Thus, we propose an alternative approach: completing phrase-level gaps within prewritten stories. On this task, we explore the performance of GPT-3 with and without finetuning as well as with and without providing a word which is semantically related to the target word. Manual evaluation of the generated stories shows that GPT-3 and GPT-3- based models perform well on the task. Using GPT-3 without finetuning and including a con- text word into the prompt is the best performing approach."}}
{"id": "Qbh40sZsyU", "cdate": 1671632601197, "mdate": 1671632601197, "content": {"title": "A Comprehensive Comparison of Neural Networks as Cognitive Models of Inflection", "abstract": "Neural networks have long been at the center of a debate around the cognitive mechanism by which humans process inflectional morphology. This debate has gravitated into NLP by way of the question: Are neural networks a feasible account for human behavior in morphological inflection? We address that question by measuring the correlation between human judgments and neural network probabilities for unknown word inflections. We test a larger range of architectures than previously studied on two important tasks for the cognitive processing debate: English past tense, and German number inflection. We find evidence that the Transformer may be a better account of human behavior than LSTMs on these datasets, and that LSTM features known to increase inflection accuracy do not always result in more human-like behavior."}}
{"id": "snqvEDhDktl", "cdate": 1671632523438, "mdate": 1671632523438, "content": {"title": "Morphological Processing of Low-Resource Languages: Where We Are and What's Next", "abstract": "Automatic morphological processing can aid downstream natural language processing applications, especially for low-resource languages, and assist language documentation efforts for endangered languages. Having long been multilingual, the field of computational morphology is increasingly moving towards approaches suitable for languages with minimal or no annotated resources. First, we survey recent developments in computational morphology with a focus on low-resource languages. Second, we argue that the field is ready to tackle the logical next challenge: understanding a language's morphology from raw text alone. We perform an empirical study on a truly unsupervised version of the paradigm completion task and show that, while existing state-of-the-art models bridged by two newly proposed models we devise perform reasonably, there is still much room for improvement. The stakes are high: solving this task will increase the language coverage of morphological resources by a number of magnitudes."}}
{"id": "fJ67se4mA1K", "cdate": 1670987861816, "mdate": 1670987861816, "content": {"title": "Match the Script, Adapt if Multilingual: Analyzing the Effect of Multilingual Pretraining on Cross-lingual Transferability", "abstract": "Pretrained multilingual models enable zero-shot learning even for unseen languages, and that performance can be further improved via adaptation prior to finetuning. However, it is unclear how the number of pretraining languages influences a model\u2019s zero-shot learning for languages unseen during pretraining. To fill this gap, we ask the following research questions: (1) How does the number of pretraining languages influence zero-shot performance on unseen target languages? (2) Does the answer to that question change with model adaptation? (3) Do the findings for our first question change if the languages used for pretraining are all related? Our experiments on pretraining with related languages indicate that choosing a diverse set of languages is crucial. Without model adaptation, surprisingly, increasing the number of pretraining languages yields better results up to adding related languages, after which performance plateaus.In contrast, with model adaptation via continued pretraining, pretraining on a larger number of languages often gives further improvement, suggesting that model adaptation is crucial to exploit additional pretraining languages."}}
{"id": "ByZ6CfbdWS", "cdate": 1546300800000, "mdate": null, "content": {"title": "Subword-Level Language Identification for Intra-Word Code-Switching", "abstract": "Manuel Mager, \u00d6zlem \u00c7etino\u011flu, Katharina Kann. Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers). 2019."}}
{"id": "Hy4_NMM_bH", "cdate": 1514764800000, "mdate": null, "content": {"title": "Neural Transductive Learning and Beyond: Morphological Generation in the Minimal-Resource Setting", "abstract": "Neural state-of-the-art sequence-to-sequence (seq2seq) models often do not perform well for small training sets. We address paradigm completion, the morphological task of, given a partial paradigm, generating all missing forms. We propose two new methods for the minimal-resource setting: (i) Paradigm transduction: Since we assume only few paradigms available for training, neural seq2seq models are able to capture relationships between paradigm cells, but are tied to the idiosyncracies of the training set. Paradigm transduction mitigates this problem by exploiting the input subset of inflected forms at test time. (ii) Source selection with high precision (SHIP): Multi-source models which learn to automatically select one or multiple sources to predict a target inflection do not perform well in the minimal-resource setting. SHIP is an alternative to identify a reliable source if training data is limited. On a 52-language benchmark dataset, we outperform the previous state of the art by up to 9.71% absolute accuracy."}}
{"id": "Bybu2MZOZB", "cdate": 1514764800000, "mdate": null, "content": {"title": "Fortification of Neural Morphological Segmentation Models for Polysynthetic Minimal-Resource Languages", "abstract": "Morphological segmentation for polysynthetic languages is challenging, because a word may consist of many individual morphemes and training data can be extremely scarce. Since neural sequence-to-sequence (seq2seq) models define the state of the art for morphological segmentation in high-resource settings and for (mostly) European languages, we first show that they also obtain competitive performance for Mexican polysynthetic languages in minimal-resource settings. We then propose two novel multi-task training approaches -one with, one without need for external unlabeled resources-, and two corresponding data augmentation methods, improving over the neural baseline for all languages. Finally, we explore cross-lingual transfer as a third way to fortify our neural model and show that we can train one single multi-lingual model for related languages while maintaining comparable or even improved performance, thus reducing the amount of parameters by close to 75%. We provide our morphological segmentation datasets for Mexicanero, Nahuatl, Wixarika and Yorem Nokki for future research."}}
{"id": "ry7R9oxuWS", "cdate": 1483228800000, "mdate": null, "content": {"title": "One-Shot Neural Cross-Lingual Transfer for Paradigm Completion", "abstract": "We present a novel cross-lingual transfer method for paradigm completion, the task of mapping a lemma to its inflected forms, using a neural encoder-decoder model, the state of the art for the monolingual task. We use labeled data from a high-resource language to increase performance on a low-resource language. In experiments on 21 language pairs from four different language families, we obtain up to 58% higher accuracy than without transfer and show that even zero-shot and one-shot learning are possible. We further find that the degree of language relatedness strongly influences the ability to transfer morphological knowledge."}}
