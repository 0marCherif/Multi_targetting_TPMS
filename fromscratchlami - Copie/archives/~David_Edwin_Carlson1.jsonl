{"id": "7XBkGedeIZ", "cdate": 1672954698454, "mdate": null, "content": {"title": "Incorporating Prior Knowledge into Neural Networks through an Implicit Composite Kernel", "abstract": "It is challenging to guide neural network (NN) learning with prior knowledge. In contrast, many known properties, such as spatial smoothness or seasonality, are straightforward to model by choosing an appropriate kernel in a Gaussian process (GP). Many deep learning applications could be enhanced by modeling such known properties. For example, convolutional neural networks (CNNs) are frequently used in remote sensing, which is subject to strong seasonal effects. We propose to blend the strengths of deep learning and the clear modeling capabilities of GPs by using a composite kernel that combines a kernel implicitly defined by a neural network with a second kernel function chosen to model known properties (e.g., seasonality). We implement this idea by combining a deep network and an efficient mapping based on the Nystrom approximation, which we call Implicit Composite Kernel (ICK). We then adopt a sample-then-optimize approach to approximate the full GP posterior distribution. We demonstrate that ICK has superior performance and flexibility on both synthetic and real-world data sets. We believe that ICK framework can be used to include prior information into neural networks in many applications."}}
{"id": "thmtrq5exDC", "cdate": 1672365906254, "mdate": 1672365906254, "content": {"title": "Improving Spatial Variation of Ground-level PM2.5 Prediction with Contrastive Learning from Satellite Imagery", "abstract": "Convolutional Neural Networks (CNNs) are a promising technique to predict highly localized fine particulate\nmatter (i.e., PM2.5 levels) based on high-resolution satellite imagery. Unfortunately, CNNs typically require large\namounts of supervised data to perform well, whereas this application generally has lots of unsupervised data (all\nsatellite imagery) and relatively sparse supervised data (measurements from ground sensors). Previous work used\ntransfer learning from another visual task to initialize the CNN weights; however, we hypothesize that standard\ntransfer learning strategies would bias the CNN to focus on irrelevant details of the image for our applications.\nInstead, we develop a novel framework called Spatiotemporal Contrastive Learning (SCL) to pre-train the CNN.\nWe test both regular contrastive learning and SCL on predicting PM2.5 levels from satellite images in two\ndifferent cities, Delhi and Beijing, and compare to CNNs with parameters initialized randomly and by transfer\nlearning. Our results show that regular contrastive learning and our SCL frameworks both manage to better\ncapture spatial variation of ground-level PM2.5 concentrations compared to traditional initialization schemes,\nand that this performance gap increases as the number of ground sensors decreases, implying that the approach\nwill be even more valuable in cities with fewer ground sensors. Our work demonstrates that contrastive learning\nis a powerful pre-training technique to build better spatial maps of PM2.5, and can be broadly applied in related\nsituations"}}
{"id": "pAq8iDy00Oa", "cdate": 1652737425560, "mdate": null, "content": {"title": "Incorporating Prior Knowledge into Neural Networks through an Implicit Composite Kernel", "abstract": "It is challenging to guide neural network (NN) learning with prior knowledge. In contrast, many known properties, such as spatial smoothness or seasonality, are straightforward to model by choosing an appropriate kernel in a Gaussian process (GP). Many deep learning applications could be enhanced by modeling such known properties. For example, convolutional neural networks (CNNs) are frequently used in remote sensing, which is subject to strong seasonal effects. We propose to blend the strengths of deep learning and the clear modeling capabilities of GPs by using a composite kernel that combines a kernel implicitly defined by a neural network with a second kernel function chosen to model known properties (e.g., seasonality). Then, we approximate the resultant GP by combining a deep network and an efficient mapping based on the Nystrom approximation, which we call Implicit Composite Kernel (ICK). ICK is flexible and can be used to include prior information in neural networks in many applications. We demonstrate the strength of our framework by showing its superior performance and flexibility on both synthetic and real-world data sets. The code is available at: https://anonymous.4open.science/r/ICK_NNGP-17C5/. "}}
{"id": "TxqmmPNh_k", "cdate": 1640995200000, "mdate": 1649212544630, "content": {"title": "Learning to Weight Filter Groups for Robust Classification", "abstract": "In many real-world tasks, a canonical \u201cbig data\u201d problem is created by combining data from several individual groups or domains. Because test data will likely come from a new group of data, we want to utilize the grouped structure of our training data to enforce generalization between groups of data, not just individual samples. This can be viewed as a multiple-domain generalization problem. Specifically, the goal is to encourage generalization between previously seen labeled source data from multiple domains and unlabeled target domain data. To address this challenge, we introduce Domain-Specific Filter Group (DSFG), where each training domain has a unique filter group and each test data point is predicted by a weighted sum over the outputs of different domain filters. A separate neural network learns to estimate the appropriate filter group weights through a meta-learning strategy. Empirically, experiments on three benchmark datasets demonstrate improved performance compared to current state-of-the-art approaches."}}
{"id": "gSIkjYGNuro", "cdate": 1623848389592, "mdate": 1623848389592, "content": {"title": "Geometric deep learning enables 3D kinematic profiling across species and environments", "abstract": "Comprehensive descriptions of animal behavior require precise three-dimensional (3D) measurements of whole-body movements. Although two-dimensional approaches can track visible landmarks in restrictive environments, performance drops in freely moving animals, due to occlusions and appearance changes. Therefore, we designed DANNCE to robustly track anatomical landmarks in 3D across species and behaviors. DANNCE uses projective geometry to construct inputs to a convolutional neural network that leverages learned 3D geometric reasoning. We trained and benchmarked DANNCE using a dataset of nearly seven million frames that relates color videos and rodent 3D poses. In rats and mice, DANNCE robustly tracked dozens of landmarks on the head, trunk, and limbs of freely moving animals in naturalistic settings. We extended DANNCE to datasets from rat pups, marmosets, and chickadees, and demonstrate quantitative profiling of behavioral lineage during development."}}
{"id": "AhlzUugOFIo", "cdate": 1621630026360, "mdate": null, "content": {"title": "Directed Spectrum Measures Improve Latent Network Models Of Neural Populations", "abstract": "Systems neuroscience aims to understand how networks of neurons distributed throughout the brain mediate computational tasks. One popular approach to identify those networks is to first calculate measures of neural activity (e.g. power spectra) from multiple brain regions, and then apply a linear factor model to those measures. Critically, despite the established role of directed communication between brain regions in neural computation, measures of directed communication have been rarely utilized in network estimation because they are incompatible with the implicit assumptions of the linear factor model approach. Here, we develop a novel spectral measure of directed communication called the Directed Spectrum (DS). We prove that it is compatible with the implicit assumptions of linear factor models, and we provide a method to estimate the DS. We demonstrate that latent linear factor models of DS measures better capture underlying brain networks in both simulated and real neural recording data compared to available alternatives. Thus, linear factor models of the Directed Spectrum offer neuroscientists a simple and effective way to explicitly model directed communication in networks of neural populations."}}
{"id": "HMUfUJz31QH", "cdate": 1609459200000, "mdate": 1649212544825, "content": {"title": "Estimating Uncertainty Intervals from Collaborating Networks", "abstract": "Effective decision making requires understanding the uncertainty inherent in a prediction. In regression, this uncertainty can be estimated by a variety of methods; however, many of these methods are laborious to tune, generate overconfident uncertainty intervals, or lack sharpness (give imprecise intervals). We address these challenges by proposing a novel method to capture predictive distributions in regression by defining two neural networks with two distinct loss functions. Specifically, one network approximates the cumulative distribution function, and the second network approximates its inverse. We refer to this method as Collaborating Networks (CN). Theoretical analysis demonstrates that a fixed point of the optimization is at the idealized solution, and that the method is asymptotically consistent to the ground truth distribution. Empirically, learning is straightforward and robust. We benchmark CN against several common approaches on two synthetic and six real-world datasets, including forecasting A1c values in diabetic patients from electronic health records, where uncertainty is critical. In the synthetic data, the proposed approach essentially matches ground truth. In the real-world datasets, CN improves results on many performance metrics, including log-likelihood estimates, mean absolute errors, coverage estimates, and prediction interval widths."}}
{"id": "Dqz3lXEFb8M", "cdate": 1609459200000, "mdate": 1649212544824, "content": {"title": "Estimating Potential Outcome Distributions with Collaborating Causal Networks", "abstract": "Traditional causal inference approaches leverage observational study data to estimate the difference in observed and unobserved outcomes for a potential treatment, known as the Conditional Average Treatment Effect (CATE). However, CATE corresponds to the comparison on the first moment alone, and as such may be insufficient in reflecting the full picture of treatment effects. As an alternative, estimating the full potential outcome distributions could provide greater insights. However, existing methods for estimating treatment effect potential outcome distributions often impose restrictive or simplistic assumptions about these distributions. Here, we propose Collaborating Causal Networks (CCN), a novel methodology which goes beyond the estimation of CATE alone by learning the full potential outcome distributions. Estimation of outcome distributions via the CCN framework does not require restrictive assumptions of the underlying data generating process. Additionally, CCN facilitates estimation of the utility of each possible treatment and permits individual-specific variation through utility functions. CCN not only extends outcome estimation beyond traditional risk difference, but also enables a more comprehensive decision-making process through definition of flexible comparisons. Under assumptions commonly made in the causal literature, we show that CCN learns distributions that asymptotically capture the true potential outcome distributions. Furthermore, we propose an adjustment approach that is empirically effective in alleviating sample imbalance between treatment groups in observational data. Finally, we evaluate the performance of CCN in multiple synthetic and semi-synthetic experiments. We demonstrate that CCN learns improved distribution estimates compared to existing Bayesian and deep generative methods as well as improved decisions with respects to a variety of utility functions."}}
{"id": "9mPRf3vd_ba", "cdate": 1609459200000, "mdate": 1649212544779, "content": {"title": "Local PM2.5 Hotspot Detector at 300 m Resolution: A Random Forest-Convolutional Neural Network Joint Model Jointly Trained on Satellite Images and Meteorology", "abstract": "Satellite-based rapid sweeping screening of localized PM2.5 hotspots at fine-scale local neighborhood levels is highly desirable. This motivated us to develop a random forest\u2013convolutional neural network\u2013local contrast normalization (RF\u2013CNN\u2013LCN) pipeline that detects local PM2.5 hotspots at a 300 m resolution using satellite imagery and meteorological information. The RF\u2013CNN joint model in the pipeline uses three meteorological variables and daily 3 m/pixel resolution PlanetScope satellite imagery to generate daily 300 m ground-level PM2.5 estimates. The downstream LCN processes the estimated PM2.5 maps to reveal local PM2.5 hotspots. The RF\u2013CNN joint model achieved a low normalized root mean square error for PM2.5 of within ~31% and normalized mean absolute error of within ~19% on the holdout samples in both Delhi and Beijing. The RF\u2013CNN\u2013LCN pipeline reasonably predicts urban PM2.5 local hotspots and coolspots by capturing both the main intra-urban spatial trends in PM2.5 and the local variations in PM2.5 with urban landscape, with local hotspots relating to compact urban spatial structures and coolspots being open areas and green spaces. Based on 20 sampled representative neighborhoods in Delhi, our pipeline revealed an annual average 9.2 \u00b1 4.0 \u03bcg m\u22123 difference in PM2.5 between the local hotspots and coolspots within the same community. In some cases, the differences were much larger; for example, at the Indian Gandhi International Airport, the increase was 20.3 \u03bcg m\u22123 from the coolest spot (the residential area immediately outside the airport) to the hottest spot (airport runway). This work provides a possible means of automatically identifying local PM2.5 hotspots at 300 m in heavily polluted megacities and highlights the potential existence of substantial health inequalities in long-term outdoor PM2.5 exposures even within the same local neighborhoods between local hotspots and coolspots."}}
{"id": "653X4ve02h", "cdate": 1609459200000, "mdate": 1649212544865, "content": {"title": "Supervising the Decoder of Variational Autoencoders to Improve Scientific Utility", "abstract": "Probabilistic generative models are attractive for scientific modeling because their inferred parameters can be used to generate hypotheses and design experiments. This requires that the learned model provide an accurate representation of the input data and yield a latent space that effectively predicts outcomes relevant to the scientific question. Supervised Variational Autoencoders (SVAEs) have previously been used for this purpose, where a carefully designed decoder can be used as an interpretable generative model while the supervised objective ensures a predictive latent representation. Unfortunately, the supervised objective forces the encoder to learn a biased approximation to the generative posterior distribution, which renders the generative parameters unreliable when used in scientific models. This issue has remained undetected as reconstruction losses commonly used to evaluate model performance do not detect bias in the encoder. We address this previously-unreported issue by developing a second order supervision framework (SOS-VAE) that influences the decoder to induce a predictive latent representation. This ensures that the associated encoder maintains a reliable generative interpretation. We extend this technique to allow the user to trade-off some bias in the generative parameters for improved predictive performance, acting as an intermediate option between SVAEs and our new SOS-VAE. We also use this methodology to address missing data issues that often arise when combining recordings from multiple scientific experiments. We demonstrate the effectiveness of these developments using synthetic data and electrophysiological recordings with an emphasis on how our learned representations can be used to design scientific experiments."}}
