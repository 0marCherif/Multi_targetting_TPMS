{"id": "GOcdI_nEyj", "cdate": 1698562896669, "mdate": 1698562896669, "content": {"title": "SoccerNet 2023 Challenges Results", "abstract": "The SoccerNet 2023 challenges were the third annual video understanding challenges organized by the SoccerNet team. For this third edition, the challenges were composed of seven vision-based tasks split into three main themes. The first theme, broadcast video understanding, is composed of three high-level tasks related to describing events occurring in the video broadcasts: (1) action spotting, focusing on retrieving all timestamps related to global actions in soccer, (2) ball action spotting, focusing on retrieving all timestamps related to the soccer ball change of state, and (3) dense video captioning, focusing on describing the broadcast with natural language and anchored timestamps. The second theme, field understanding, relates to the single task of (4) camera calibration, focusing on retrieving the intrinsic and extrinsic camera parameters from images. The third and last theme, player understanding, is composed of three low-level tasks related to extracting information about the players: (5) re-identification, focusing on retrieving the same players across multiple views, (6) multiple object tracking, focusing on tracking players and the ball through unedited video streams, and (7) jersey number recognition, focusing on recognizing the jersey number of players from tracklets. Compared to the previous editions of the SoccerNet challenges, tasks (2-3-7) are novel, including new annotations and data, task (4) was enhanced with more data and annotations, and task (6) now focuses on end-to-end approaches. More information on the tasks, challenges, and leaderboards are available on this https URL."}}
{"id": "Wtin1qPoXn", "cdate": 1698562854841, "mdate": 1698562854841, "content": {"title": "Learning Semantic Segmentation with Query Points Supervision on Aerial Images", "abstract": "Semantic segmentation is crucial in remote sensing, where high-resolution satellite images are segmented into meaningful regions. Recent advancements in deep learning have significantly improved satellite image segmentation. However, most of these methods are typically trained in fully supervised settings that require high-quality pixel-level annotations, which are expensive and time-consuming to obtain. In this work, we present a weakly supervised learning algorithm to train semantic segmentation algorithms that only rely on query point annotations instead of full mask labels. Our proposed approach performs accurate semantic segmentation and improves efficiency by significantly reducing the cost and time required for manual annotation. Specifically, we generate superpixels and extend the query point labels into those superpixels that group similar meaningful semantics. Then, we train semantic segmentation models, supervised with images partially labeled with the superpixels pseudo-labels. We benchmark our weakly supervised training approach on an aerial image dataset and different semantic segmentation architectures, showing that we can reach competitive performance compared to fully supervised training while reducing the annotation effort."}}
{"id": "3y8Itwaj1W", "cdate": 1698562783971, "mdate": 1698562783971, "content": {"title": "Mask-Guided Data Augmentation for Multiparametric MRI Generation with a Rare Hepatocellular Carcinoma", "abstract": "Data augmentation is classically used to improve the overall performance of deep learning models. It is, however, challenging in the case of medical applications, and in particular for multiparametric datasets. For example, traditional geometric transformations used in several applications to generate synthetic images can modify in a non-realistic manner the patients\u2019 anatomy. Therefore, dedicated image generation techniques are necessary in the medical field to, for example, mimic a given pathology in a realistic manner. This paper introduces a new data augmentation architecture that generates synthetic multiparametric (T1 arterial, T1 portal, and T2) magnetic resonance images (MRI) of massive macrotrabecular subtype hepatocellular carcinoma with their corresponding tumor masks through a generative deep learning approach. The proposed architecture creates liver tumor masks and abdominal edges used as input in a Pix2Pix network for synthetic data creation. The efficiency of the method is demonstrated by training it on a limited multiparametric dataset of MRI triplets from 89 patients with liver lesions to generate 1000 synthetic triplets and their corresponding liver tumor masks. The resulting Frechet Inception Distance score was 86.55. The proposed approach was among the winners of the 2021 data augmentation challenge organized by the French Society of Radiology."}}
{"id": "KCi8GjUZ-E7", "cdate": 1667477442308, "mdate": 1667477442308, "content": {"title": "Multiple snapshot colored compressive spectral imager", "abstract": "The snapshot colored compressive spectral imager (SCCSI) is a recent compressive spectral imaging (CSI) architecture that senses the spatial and spectral information of a scene in a single snapshot by means of a colored mosaic FPA detector and a dispersive element. Commonly, CSI architectures allow multiple snapshot acquisition, yielding improved reconstructions of spatially detailed and spectrally rich scenes. Each snapshot is captured employing a different coding pattern. In principle, SCCSI does not admit multiple snapshots since the pixelated tiling of optical filters is directly attached to the detector. This paper extends the concept of SCCSI to a system admitting multiple snapshot acquisition by rotating the dispersive element, so the dispersed spatiospectral source is coded and integrated at different detector pixels in each rotation. Thus, a different set of coded projections is captured using the same optical components of the original architecture. The mathematical model of the multishot SCCSI system is presented along with several simulations. Results show that a gain up to 7 dB of peak signal-to-noise ratio is achieved when four SCCSI snapshots are compared to a single snapshot reconstruction. Furthermore, a gain up to 5 dB is obtained with respect to state-of-the-art architecture, the multishot CASSI."}}
{"id": "wW1MHQZJOx", "cdate": 1667477277008, "mdate": 1667477277008, "content": {"title": "CX-DaGAN: Domain Adaptation for Pneumonia Diagnosis on a Small Chest X-Ray Dataset", "abstract": "Recent advances in deep learning led to several algorithms for the accurate diagnosis of pneumonia from chest X-rays. However, these models require large training medical datasets, which are sparse, isolated, and generally private. Furthermore, these models in medical imaging are known to over-fit to a particular data domain source, i.e., these algorithms do not conserve the same accuracy when tested on a dataset from another medical center, mainly due to image distribution discrepancies. In this work, a domain adaptation and classification technique is proposed to overcome the over-fit challenges on a small dataset. This method uses a private-small dataset (target domain), a public-large labeled dataset from another medical center (source domain), and consists of three steps. First, it performs a data selection of the source domain\u2019s most representative images based on similarity constraints through principal component analysis subspaces. Second, the selected samples from the source domain are fit to the target distribution through an image to image translation based on a cycle-generative adversarial network. Finally, the target train dataset and the adapted images from the source dataset are used within a convolutional neural network to explore different settings to adjust the layers and perform the classification of the target test dataset. It is shown that fine-tuning a few specific layers together with the selected-adapted images increases the sorting accuracy while reducing the trainable parameters. The proposed approach achieved a notable increase in the target dataset\u2019s overall classification accuracy, reaching up to 97.78 % compared to 90.03 % by standard transfer learning."}}
{"id": "1A2KyuzF4_", "cdate": 1667477119482, "mdate": 1667477119482, "content": {"title": "OPTICS LENS DESIGN FOR PRIVACY-PRESERVING SCENE CAPTIONING", "abstract": "Image captioning is a challenging task that connects two major artificial intelligence fields: computer vision and natural language processing. Image captioning models use traditional images to generate a natural language description of the scene. However, the scene could contain private information that we want to hide but still generate the captions. Inspired by the trend of jointly designing optics and algorithms, this paper addresses the problem of privacy-preserving scene captioning. Our approach promotes privacy preservation, by hiding the faces in the images, during the acquisition process with a designed refractive camera lens while extracting useful features to perform image captioning. The refractive lens and an image captioning deep network architecture are optimized end-to-end to generate descriptions directly from the blurred images. Simulations show that our privacy-preserving approach degrades private visual attributes (e.g., face detection fails with our distorted images) while achieving comparable captioning performance with traditional non-private methods on the COCO dataset."}}
{"id": "nW15qSLY_Uo", "cdate": 1640995200000, "mdate": 1667386372129, "content": {"title": "PrivHAR: Recognizing Human Actions From Privacy-preserving Lens", "abstract": "The accelerated use of digital cameras prompts an increasing concern about privacy and security, particularly in applications such as action recognition. In this paper, we propose an optimizing framework to provide robust visual privacy protection along the human action recognition pipeline. Our framework parameterizes the camera lens to successfully degrade the quality of the videos to inhibit privacy attributes and protect against adversarial attacks while maintaining relevant features for activity recognition. We validate our approach with extensive simulations and hardware experiments."}}
{"id": "Q35Y0hJhrZg", "cdate": 1609459200000, "mdate": 1667386372130, "content": {"title": "Learning Privacy-preserving Optics for Human Pose Estimation", "abstract": "The widespread use of always-connected digital cameras in our everyday life has led to increasing concerns about the users\u2019 privacy and security. How to develop privacy- preserving computer vision systems? In particular, we want to prevent the camera from obtaining detailed visual data that may contain private information. However, we also want the camera to capture useful information to perform computer vision tasks. Inspired by the trend of jointly designing optics and algorithms, we tackle the problem of privacy-preserving human pose estimation by optimizing an optical encoder (hardware-level protection) with a software decoder (convolutional neural network) in an end-to- end framework. We introduce a visual privacy protection layer in our optical encoder that, parametrized appropriately, enables the optimization of the camera lens\u2019s point spread function (PSF). We validate our approach with extensive simulations and a prototype camera. We show that our privacy-preserving deep optics approach successfully degrades or inhibits private attributes while maintaining important features to perform human pose estimation."}}
{"id": "O2zuxB8w-S", "cdate": 1609459200000, "mdate": 1667386372239, "content": {"title": "A Fast and Accurate Similarity-Constrained Subspace Clustering Algorithm for Hyperspectral Image", "abstract": "Accurate unsupervised classification of hyperspectral images (HSIs) is challenging and has drawn widespread attention in remote sensing due to its inherent complexity. Although significant efforts have been made to develop a variety of methods, most of them rely on supervised strategies. Subspace clustering methods, such as sparse subspace clustering (SSC), have become a popular tool for unsupervised learning due to their high performance. However, the computational complexity of SSC methods prevents their use on full HSIs. Furthermore, since SSC ignores the spatial information in the HSIs, its discrimination capability is limited, hampering the clustering results\u2019 spatial homogeneity. To address these two relevant issues, in this article, we propose a fast algorithm that obtains a sparse representation coefficient matrix by first selecting a small set of pixels that best represent their neighborhood. Then, it performs spatial filtering to enforce the connectivity of neighboring pixels and uses fast spectral clustering to get the final clustering map. Extensive simulations with our proposed method demonstrate its effectiveness in unsupervised HSI classification, obtaining remarkable high clustering performance compared with state-of-the-art SSC-based algorithms and even novel unsupervised-deep-learning-based methods. Besides, the proposed method is up to three orders of magnitude faster than SSC when clustering more than <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><tex-math notation=\"LaTeX\">$\\text{2} \\times \\text{10}^4$</tex-math></inline-formula> spectral pixels."}}
{"id": "KWFER1G49VE", "cdate": 1609459200000, "mdate": 1667386372240, "content": {"title": "Fast Subspace Clustering Algorithm with Efficient Similarity-Constrained Sampling for Hyperspectral Images", "abstract": "Hyperspectral images (HSIs) are high-dimensional and complex images that provide rich spectral information of the scenes. Image processing and remote sensing communities are currently developing unsupervised learning methods for HSI classification due to the lack of labeled data. Subspace clustering (SC) methods based on spectral clustering have achieved high clustering performance in real data experiments. However, the computational complexity of such methods prevents their use on large HSI since they require building a similarity matrix that should account for all the pixels in the image. This work proposes an efficient SC-based method that reduces the temporal and spatial computational complexity by splitting the HSI clustering task using similarity-constrained sampling, which considers the spatial information to boost the clustering performance. Experimental results on two widely used HSI data sets show the proposed method's effectiveness, outperforming the baseline methods in more than 20% of overall accuracy."}}
