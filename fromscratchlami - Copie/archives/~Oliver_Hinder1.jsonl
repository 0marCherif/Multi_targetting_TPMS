{"id": "KmHIKFULoZ", "cdate": 1672531200000, "mdate": 1681490149226, "content": {"title": "DoG is SGD's Best Friend: A Parameter-Free Dynamic Step Size Schedule", "abstract": ""}}
{"id": "A0WsxAzR_yn", "cdate": 1652737545856, "mdate": null, "content": {"title": "A consistently adaptive trust-region method", "abstract": "Adaptive trust-region methods attempt to maintain strong convergence guarantees without depending on conservative estimates of problem properties such as Lipschitz constants. However, on close inspection, one can show existing adaptive trust-region methods have theoretical guarantees with severely suboptimal dependence on problem properties such as the Lipschitz constant of the Hessian. For example, TRACE developed by Curtis et al. obtains a $O(\\Delta_f L^{3/2} \\epsilon^{-3/2}) + \\tilde{O}(1)$ iteration bound where $L$ is the Lipschitz constant of the Hessian. Compared with the optimal $O(\\Delta_f L^{1/2} \\epsilon^{-3/2})$ bound this is suboptimal with respect to $L$. We present the first adaptive trust-region method which circumvents this issue and requires at most $O( \\Delta_f L^{1/2}  \\epsilon^{-3/2}) + \\tilde{O}(1)$ iterations to find an $\\epsilon$-approximate stationary point, matching the optimal iteration bound up to an additive logarithmic term. Our method is a simple variant of a classic trust-region method and in our experiments performs competitively with both ARC and a classical trust-region method."}}
{"id": "IVBycjXgPyx", "cdate": 1640995200000, "mdate": 1681490149055, "content": {"title": "Making SGD Parameter-Free", "abstract": ""}}
{"id": "_eXwwWOyqT_", "cdate": 1621630295163, "mdate": null, "content": {"title": "Practical Large-Scale Linear Programming using Primal-Dual Hybrid Gradient", "abstract": "We present PDLP, a practical first-order method for linear programming (LP) that can solve to the high levels of accuracy that are expected in traditional LP applications. In addition, it can scale to very large problems because its core operation is matrix-vector multiplications. PDLP is derived by applying the primal-dual hybrid gradient (PDHG) method, popularized by Chambolle and Pock (2011), to a saddle-point formulation of LP. PDLP enhances PDHG for LP by combining several new techniques with older tricks from the literature; the enhancements include diagonal preconditioning, presolving, adaptive step sizes, and adaptive restarting. PDLP improves the state of the art for first-order methods applied to LP. We compare PDLP with SCS, an ADMM-based solver, on a set of 383 LP instances derived from MIPLIB 2017. With a target of $10^{-8}$ relative accuracy and 1 hour time limit, PDLP achieves a 6.3x reduction in the geometric mean of solve times and a 4.6x reduction in the number of instances unsolved (from 227 to 49). Furthermore, we highlight standard benchmark instances and a large-scale application (PageRank) where our open-source prototype of PDLP, written in Julia, outperforms a commercial LP solver."}}
{"id": "bVTliJMPzD", "cdate": 1609459200000, "mdate": null, "content": {"title": "Lower bounds for finding stationary points II: first-order methods", "abstract": "We establish lower bounds on the complexity of finding $$\\epsilon $$ \u03f5 -stationary points of smooth, non-convex high-dimensional functions using first-order methods. We prove that deterministic first-order methods, even applied to arbitrarily smooth functions, cannot achieve convergence rates in $$\\epsilon $$ \u03f5 better than $$\\epsilon ^{-8/5}$$ \u03f5 - 8 / 5 , which is within $$\\epsilon ^{-1/15}\\log \\frac{1}{\\epsilon }$$ \u03f5 - 1 / 15 log 1 \u03f5 of the best known rate for such methods. Moreover, for functions with Lipschitz first and second derivatives, we prove that no deterministic first-order method can achieve convergence rates better than $$\\epsilon ^{-12/7}$$ \u03f5 - 12 / 7 , while $$\\epsilon ^{-2}$$ \u03f5 - 2 is a lower bound for functions with only Lipschitz gradient. For convex functions with Lipschitz gradient, accelerated gradient descent achieves a better rate, showing that finding stationary points is easier given convexity."}}
{"id": "ByxLISif9LE", "cdate": 1609459200000, "mdate": 1681490149173, "content": {"title": "On the behavior of Lagrange multipliers in convex and nonconvex infeasible interior point methods", "abstract": ""}}
{"id": "9-v8jz-8Tus", "cdate": 1609459200000, "mdate": 1681490149091, "content": {"title": "Practical Large-Scale Linear Programming using Primal-Dual Hybrid Gradient", "abstract": ""}}
{"id": "wqjDoVKaGXS", "cdate": 1577836800000, "mdate": 1681490149174, "content": {"title": "Conic Descent and its Application to Memory-efficient Optimization over Positive Semidefinite Matrices", "abstract": ""}}
{"id": "mQVaL-ilgUW", "cdate": 1577836800000, "mdate": null, "content": {"title": "An efficient nonconvex reformulation of stagewise convex optimization problems", "abstract": "Convex optimization problems with staged structure appear in several contexts, including optimal control, verification of deep neural networks, and isotonic regression. Off-the-shelf solvers can solve these problems but may scale poorly. We develop a nonconvex reformulation designed to exploit this staged structure. Our reformulation has only simple bound constraints, enabling solution via projected gradient methods and their accelerated variants. The method automatically generates a sequence of primal and dual feasible solutions to the original convex problem, making optimality certification easy. We establish theoretical properties of the nonconvex formulation, showing that it is (almost) free of spurious local minima and has the same global optimum as the convex problem. We modify projected gradient descent to avoid spurious local minimizers so it always converges to the global minimizer. For neural network verification, our approach obtains small duality gaps in only a few gradient steps. Consequently, it can provide tight duality gaps for many large-scale verification problems where both off-the-shelf and specialized solvers struggle."}}
{"id": "hp-FfzW6nX6", "cdate": 1577836800000, "mdate": null, "content": {"title": "Lower bounds for finding stationary points I", "abstract": "We prove lower bounds on the complexity of finding $$\\epsilon $$ \u03f5 -stationary points (points x such that $$\\Vert \\nabla f(x)\\Vert \\le \\epsilon $$ \u2016 \u2207 f ( x ) \u2016 \u2264 \u03f5 ) of smooth, high-dimensional, and potentially non-convex functions f. We consider oracle-based complexity measures, where an algorithm is given access to the value and all derivatives of f at a query point x. We show that for any (potentially randomized) algorithm $$\\mathsf {A}$$ A , there exists a function f with Lipschitz pth order derivatives such that $$\\mathsf {A}$$ A requires at least $$\\epsilon ^{-(p+1)/p}$$ \u03f5 - ( p + 1 ) / p queries to find an $$\\epsilon $$ \u03f5 -stationary point. Our lower bounds are sharp to within constants, and they show that gradient descent, cubic-regularized Newton\u2019s method, and generalized pth order regularization are worst-case optimal within their natural function classes."}}
