{"id": "fYzLpCsGZVf", "cdate": 1663850200057, "mdate": null, "content": {"title": "On Accelerated Perceptrons and Beyond", "abstract": "The classical Perceptron algorithm of Rosenblatt can be used to find a linear threshold function to correctly classify $n$ linearly separable data points, assuming the classes are separated by some margin $\\gamma > 0$. A foundational result is that Perceptron converges after  $\\Omega(1/\\gamma^{2})$ iterations. There have been several recent works that managed to improve this rate by a quadratic factor, to $\\Omega(\\sqrt{\\log n}/\\gamma)$, with more sophisticated algorithms. In this paper, we unify these existing results under one framework by showing that they can all be described through the lens of solving min-max problems using modern acceleration techniques, mainly through \\emph{optimistic} online learning.  We then show that the proposed framework also leads to improved results for a series of problems beyond the standard Perceptron setting. Specifically, a) for the margin maximization problem, we improve the state-of-the-art result from $O(\\log t/t^2)$ to $O(1/t^2)$, where $t$ is the number of iterations; b) we provide the first result on identifying the implicit bias property of the classical Nesterov's accelerated gradient descent (NAG) algorithm, and show NAG can maximize the margin with an $O(1/t^2)$ rate; c) for the classical $p$-norm Perceptron problem, we provide an algorithm with $\\Omega(\\sqrt{(p-1)\\log n}/\\gamma)$ convergence rate, while existing algorithms suffer the $\\Omega({(p-1)}/\\gamma^2)$ convergence rate."}}
{"id": "I4XNmBm2h-E", "cdate": 1652737474328, "mdate": null, "content": {"title": "Adaptive Oracle-Efficient Online Learning", "abstract": "The classical algorithms for online learning and decision-making have the benefit of achieving the optimal performance guarantees, but suffer from computational complexity limitations when implemented at scale. More recent sophisticated techniques, which we refer to as $\\textit{oracle-efficient}$ methods, address this problem by dispatching to an $\\textit{offline optimization oracle}$ that can search through an exponentially-large (or even infinite) space of decisions and select that which performed the best on any dataset. But despite the benefits of computational feasibility, most oracle-efficient algorithms exhibit one major limitation: while performing well in worst-case settings, they do not adapt well to friendly environments. In this paper we consider two such friendly scenarios, (a) \"small-loss\" problems and (b) IID data. We provide a new framework for designing follow-the-perturbed-leader algorithms that are oracle-efficient and adapt well to the small-loss environment, under a particular condition which we call $\\textit{approximability}$ (which is spiritually related to sufficient conditions provided in (Dud\u00edk et al., 2020)). We identify a series of real-world settings, including online auctions and transductive online classification, for which approximability holds. We also extend the algorithm to an IID data setting and establish a \"best-of-both-worlds\" bound in the oracle-efficient setting. "}}
{"id": "nnQpieSBwJ", "cdate": 1621630004887, "mdate": null, "content": {"title": "Dual Adaptivity: A Universal Algorithm for Minimizing the Adaptive Regret of Convex Functions", "abstract": "To deal with changing environments, a new performance measure\u2014adaptive regret, defined as the maximum static regret over any interval, was proposed in online learning. Under the setting of online convex optimization, several algorithms have been successfully developed to minimize the adaptive regret. However, existing algorithms lack universality in the sense that they can only handle one type of convex functions and need apriori knowledge of parameters. By contrast, there exist universal algorithms, such as MetaGrad, that attain optimal static regret for multiple types of convex functions simultaneously. Along this line of research, this paper presents the first universal algorithm for minimizing the adaptive regret of convex functions. Specifically, we borrow the idea of maintaining multiple learning rates in MetaGrad to handle the uncertainty of functions, and utilize the technique of sleeping experts to capture changing environments. In this way, our algorithm automatically adapts to the property of functions (convex, exponentially concave, or strongly convex), as well as the nature of environments (stationary or changing). As a by product, it also allows the type of functions to switch between rounds.\n"}}
{"id": "M3lIEwZLmvI", "cdate": 1621629930439, "mdate": null, "content": {"title": "Online Convex Optimization with Continuous Switching Constraint", "abstract": "In many sequential decision making applications, the change of decision would bring an additional cost, such as the wear-and-tear cost associated with changing server status. To control the switching cost, we introduce the problem of online convex optimization with continuous switching constraint, where the goal is to achieve a small regret given a budget on the \\emph{overall} switching cost. We first investigate the hardness of the problem, and provide a lower bound of order $\\Omega(\\sqrt{T})$ when the switching cost budget $S=\\Omega(\\sqrt{T})$, and $\\Omega(\\min\\{\\frac{T}{S},T\\})$ when $S=O(\\sqrt{T})$, where $T$ is the time horizon. The essential idea is to carefully design an adaptive adversary, who can adjust the loss function according to the cumulative switching cost of the player incurred so far based on the orthogonal technique. We then develop a simple gradient-based algorithm which enjoys the minimax optimal regret bound. Finally, we show that, for strongly convex functions, the regret bound can be improved to $O(\\log T)$ for $S=\\Omega(\\log T)$, and $O(\\min\\{T/\\exp(S)+S,T\\})$ for $S=O(\\log T)$."}}
{"id": "rye5YaEtPr", "cdate": 1569439105721, "mdate": null, "content": {"title": "SAdam: A Variant of Adam for Strongly Convex Functions", "abstract": "The Adam algorithm has become extremely popular for large-scale machine learning. Under convexity condition, it has been proved to enjoy a data-dependent $O(\\sqrt{T})$ regret bound where $T$ is the time horizon. However, whether strong convexity can be utilized to further improve the performance remains an open problem. In this paper, we give an affirmative answer by developing a variant of Adam (referred to as SAdam) which achieves a data-dependent $O(\\log T)$ regret bound for strongly convex functions. The essential idea is to maintain a faster decaying yet under controlled step size for exploiting strong convexity. In addition, under a special configuration of hyperparameters, our SAdam reduces to SC-RMSprop, a recently proposed variant of RMSprop for strongly convex functions, for which we provide the first data-dependent logarithmic regret bound. Empirical results on optimizing strongly convex functions and training deep networks demonstrate the effectiveness of our method."}}
