{"id": "6dzP4CJTRC5", "cdate": 1640995200000, "mdate": 1649949758567, "content": {"title": "Self-supervised driven consistency training for annotation efficient histopathology image analysis", "abstract": "Highlights \u2022 We design a self-supervised pretext task via predicting the resolution sequence ordering in histology WSI. \u2022 We propose a teacher-student consistency paradigm to effectively transfer the pretrained representations to downstream tasks. \u2022 Extensive validation experiments on three histopathology benchmark datasets for classification and regression based tasks. \u2022 Proposed method yields tangible improvements outperforming other state-of-the-art self-supervised and supervised baselines. Abstract Training a neural network with a large labeled dataset is still a dominant paradigm in computational histopathology. However, obtaining such exhaustive manual annotations is often expensive, laborious, and prone to inter and intra-observer variability. While recent self-supervised and semi-supervised methods can alleviate this need by learning unsupervised feature representations, they still struggle to generalize well to downstream tasks when the number of labeled instances is small. In this work, we overcome this challenge by leveraging both task-agnostic and task-specific unlabeled data based on two novel strategies: (i) a self-supervised pretext task that harnesses the underlying multi-resolution contextual cues in histology whole-slide images to learn a powerful supervisory signal for unsupervised representation learning; (ii) a new teacher-student semi-supervised consistency paradigm that learns to effectively transfer the pretrained representations to downstream tasks based on prediction consistency with the task-specific unlabeled data. We carry out extensive validation experiments on three histopathology benchmark datasets across two classification and one regression based tasks, i.e., tumor metastasis detection, tissue type classification, and tumor cellularity quantification. Under limited-label data, the proposed method yields tangible improvements, which is close to or even outperforming other state-of-the-art self-supervised and supervised baselines. Furthermore, we empirically show that the idea of bootstrapping the self-supervised pretrained features is an effective way to improve the task-specific semi-supervised learning on standard benchmarks. Code and pretrained models are made available at: https://github.com/srinidhiPY/SSL_CR_Histo."}}
{"id": "6PmSX4mqM_", "cdate": 1640995200000, "mdate": 1649949758566, "content": {"title": "Consistency driven Sequential Transformers Attention Model for Partially Observable Scenes", "abstract": "Most hard attention models initially observe a complete scene to locate and sense informative glimpses, and predict class-label of a scene based on glimpses. However, in many applications (e.g., aerial imaging), observing an entire scene is not always feasible due to the limited time and resources available for acquisition. In this paper, we develop a Sequential Transformers Attention Model (STAM) that only partially observes a complete image and predicts informative glimpse locations solely based on past glimpses. We design our agent using DeiT-distilled and train it with a one-step actor-critic algorithm. Furthermore, to improve classification performance, we introduce a novel training objective, which enforces consistency between the class distribution predicted by a teacher model from a complete image and the class distribution predicted by our agent using glimpses. When the agent senses only 4% of the total image area, the inclusion of the proposed consistency loss in our training objective yields 3% and 8% higher accuracy on ImageNet and fMoW datasets, respectively. Moreover, our agent outperforms previous state-of-the-art by observing nearly 27% and 42% fewer pixels in glimpses on ImageNet and fMoW."}}
{"id": "jsY4HmGFmUc", "cdate": 1609459200000, "mdate": 1649949758566, "content": {"title": "Improving Self-supervised Learning with Hardness-aware Dynamic Curriculum Learning: An Application to Digital Pathology", "abstract": "Self-supervised learning (SSL) has recently shown tremendous potential to learn generic visual representations useful for many image analysis tasks. Despite their notable success, the existing SSL methods fail to generalize to downstream tasks when the number of labeled training instances is small or if the domain shift between the transfer domains is significant. In this paper, we attempt to improve self-supervised pretrained representations through the lens of curriculum learning by proposing a hardness-aware dynamic curriculum learning (HaDCL) approach. To improve the robustness and generalizability of SSL, we dynamically leverage progressive harder examples via easy-to-hard and hard-to-very-hard samples during mini-batch downstream fine-tuning. We discover that by progressive stage-wise curriculum learning, the pretrained representations are significantly enhanced and adaptable to both in-domain and out-of-domain distribution data.We performed extensive validation on three histology benchmark datasets on both patch-wise and slide-level classification problems. Our curriculum based fine-tuning yields a significant improvement over standard fine-tuning, with a minimum improvement in area-under-the-curve (AUC) score of 1.7% and 2.2% on in-domain and out-of-domain distribution data, respectively. Further, we empirically show that our approach is more generic and adaptable to any SSL methods and does not impose any additional overhead complexity. Besides, we also outline the role of patch-based versus slide-based curriculum learning in histopathology to provide practical insights into the success of curriculum based fine-tuning of SSL methods. <sup xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">1</sup>"}}
{"id": "X-fd6eBM-5a", "cdate": 1609459200000, "mdate": 1631739178537, "content": {"title": "Deep neural network models for computational histopathology: A survey", "abstract": "Highlights \u2022 A comprehensive review of state-of-the-art deep learning (DL) approaches is presented in the context of histopathological image analysis. \u2022 This survey paper focuses on a methodological aspect of different machine learning strategies such as supervised, weakly supervised, unsupervised, transfer learning and various other sub-variants of these methods. \u2022 We also provided an overview of deep learning based survival models that are applicable for diseasespecific prognosis tasks. \u2022 Finally, we summarize several existing open datasets and highlight critical challenges and limitations with current deep learning approaches, along with possible avenues for future research. Abstract Histopathological images contain rich phenotypic information that can be used to monitor underlying mechanisms contributing to disease progression and patient survival outcomes. Recently, deep learning has become the mainstream methodological choice for analyzing and interpreting histology images. In this paper, we present a comprehensive review of state-of-the-art deep learning approaches that have been used in the context of histopathological image analysis. From the survey of over 130 papers, we review the field\u2019s progress based on the methodological aspect of different machine learning strategies such as supervised, weakly supervised, unsupervised, transfer learning and various other sub-variants of these methods. We also provide an overview of deep learning based survival models that are applicable for disease-specific prognosis tasks. Finally, we summarize several existing open datasets and highlight critical challenges and limitations with current deep learning approaches, along with possible avenues for future research."}}
{"id": "zH5stSsCOoa", "cdate": 1546300800000, "mdate": 1631739178536, "content": {"title": "Deep neural network models for computational histopathology: A survey", "abstract": "Histopathological images contain rich phenotypic information that can be used to monitor underlying mechanisms contributing to diseases progression and patient survival outcomes. Recently, deep learning has become the mainstream methodological choice for analyzing and interpreting cancer histology images. In this paper, we present a comprehensive review of state-of-the-art deep learning approaches that have been used in the context of histopathological image analysis. From the survey of over 130 papers, we review the fields progress based on the methodological aspect of different machine learning strategies such as supervised, weakly supervised, unsupervised, transfer learning and various other sub-variants of these methods. We also provide an overview of deep learning based survival models that are applicable for disease-specific prognosis tasks. Finally, we summarize several existing open datasets and highlight critical challenges and limitations with current deep learning approaches, along with possible avenues for future research."}}
{"id": "_irzdiwSr-s", "cdate": 1546300800000, "mdate": 1631739178540, "content": {"title": "Automated Method for Retinal Artery/Vein Separation via Graph Search Metaheuristic Approach", "abstract": "Separation of the vascular tree into arteries and veins is a fundamental prerequisite in the automatic diagnosis of retinal biomarkers associated with systemic and neurodegenerative diseases. In this paper, we present a novel graph search metaheuristic approach for automatic separation of arteries/veins (A/V) from color fundus images. Our method exploits local information to disentangle the complex vascular tree into multiple subtrees, and global information to label these vessel subtrees into arteries and veins. Given a binary vessel map, a graph representation of the vascular network is constructed representing the topological and spatial connectivity of the vascular structures. Based on the anatomical uniqueness at vessel crossing and branching points, the vascular tree is split into multiple subtrees containing arteries and veins. Finally, the identified vessel subtrees are labeled with A/V based on a set of hand-crafted features trained with random forest classifier. The proposed method has been tested on four different publicly available retinal datasets with an average accuracy of 94.7%, 93.2%, 96.8%, and 90.2% across AV-DRIVE, CT-DRIVE, INSPIRE-AVR, and WIDE datasets, respectively. These results demonstrate the superiority of our proposed approach in outperforming the state-of-the-art methods for A/V separation."}}
{"id": "CbC1tCrdoBB", "cdate": 1514764800000, "mdate": 1631739178537, "content": {"title": "A visual attention guided unsupervised feature learning for robust vessel delineation in retinal images", "abstract": "Highlights \u2022 A novel visual attention guided unsupervised feature learning (VA-UFL) approach. \u2022 VA-UFL exploits both visual attention mechanism and multi-scale contextual information. \u2022 Results are superior to state-of-the-art methods on five publicly available datasets. \u2022 Method is robust against central vessel reflex, complex crossovers and pathological lesions. Abstract Background and objective Accurate segmentation of retinal vessels from color fundus images play a significant role in early diagnosis of various ocular, systemic and neuro-degenerative diseases. Segmenting retinal vessels is challenging due to varying nature of vessel caliber, the proximal presence of pathological lesions, strong central vessel reflex and relatively low contrast images. Most existing methods mainly rely on carefully designed hand-crafted features to model the local geometrical appearance of vasculature structures, which often lacks the discriminative capability in segmenting vessels from a noisy and cluttered background. Methods We propose a novel visual attention guided unsupervised feature learning (VA-UFL) approach to automatically learn the most discriminative features for segmenting vessels in retinal images. Our VA-UFL approach captures both the knowledge of visual attention mechanism and multi-scale contextual information to selectively visualize the most relevant part of the structure in a given local patch. This allows us to encode a rich hierarchical information into unsupervised filtering learning to generate a set of most discriminative features that aid in the accurate segmentation of vessels, even in the presence of cluttered background. Results Our proposed method is validated on the five publicly available retinal datasets: DRIVE, STARE, CHASE_DB1, IOSTAR and RC-SLO. The experimental results show that the proposed approach significantly outperformed the state-of-the-art methods in terms of sensitivity, accuracy and area under the receiver operating characteristic curve across all five datasets. Specifically, the method achieved an average sensitivity greater than 0.82, which is 7% higher compared to all existing approaches validated on DRIVE, CHASE_DB1, IOSTAR and RC-SLO datasets, and outperformed even second-human observer. The method is shown to be robust to segmentation of thin vessels, strong central vessel reflex, complex crossover structures and fares well on abnormal cases. Conclusions The discriminative features learned via visual attention mechanism is superior to hand-crafted features, and it is easily adaptable to various kind of datasets where generous training images are often scarce. Hence, our approach can be easily integrated into large-scale retinal screening programs where the expensive labelled annotation is often unavailable."}}
{"id": "ZCO2L_SZah", "cdate": 1483228800000, "mdate": 1631739178535, "content": {"title": "Recent Advancements in Retinal Vessel Segmentation", "abstract": "Retinal vessel segmentation is a key step towards the accurate visualization, diagnosis, early treatment and surgery planning of ocular diseases. For the last two decades, a tremendous amount of research has been dedicated in developing automated methods for segmentation of blood vessels from retinal fundus images. Despite the fact, segmentation of retinal vessels still remains a challenging task due to the presence of abnormalities, varying size and shape of the vessels, non-uniform illumination and anatomical variability between subjects. In this paper, we carry out a systematic review of the most recent advancements in retinal vessel segmentation methods published in last five years. The objectives of this study are as follows: first, we discuss the most crucial preprocessing steps that are involved in accurate segmentation of vessels. Second, we review most recent state-of-the-art retinal vessel segmentation techniques which are classified into different categories based on their main principle. Third, we quantitatively analyse these methods in terms of its sensitivity, specificity, accuracy, area under the curve and discuss newly introduced performance metrics in current literature. Fourth, we discuss the advantages and limitations of the existing segmentation techniques. Finally, we provide an insight into active problems and possible future directions towards building successful computer-aided diagnostic system."}}
{"id": "WvdPe0mRlt7", "cdate": 1483228800000, "mdate": 1631739178538, "content": {"title": "A Vessel Keypoint Detector for junction classification", "abstract": "Retinal vessel keypoint detection and classification is a fundamental step in tracking the physiological changes that occur in the retina which is linked to various retinal and systemic diseases. In this paper, we propose a novel Vessel Keypoint Detector (VKD) which is derived from the projection of log-polar transformed binary patches around vessel points. VKD is used to design a two stage solution for junction detection and classification. In the first stage, the keypoints detected using VKD are refined using curvature orientation information to extract candidate junctions. True junctions from these candidates are identified in a supervised manner using a Random Forest classifier. In the next stage, a novel combination of local orientation and shape based features is extracted from the junction points and classified using a second Random Forest classifier. Evaluation results on five datasets show that the designed system is robust to changes in resolution and other variations across datasets, with average values of accuracy/sensitivity/specificity for junction detection being 0.78/0.79/0.75 and for junction classification being 0.87/0.85/0.88. Our system outperforms the state of the art method [1] by at least 11%, on the DRIVE and IOSTAR datasets. These results demonstrate the effectiveness of VKD for vessel analysis."}}
