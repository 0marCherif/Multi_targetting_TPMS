{"id": "VdgtVc8Wphh", "cdate": 1672531200000, "mdate": 1696187409088, "content": {"title": "Predictive Modeling of Equine Activity Budgets Using a 3D Skeleton Reconstructed from Surveillance Recordings", "abstract": "In this work, we present a pipeline to reconstruct the 3D pose of a horse from 4 simultaneous surveillance camera recordings. Our environment poses interesting challenges to tackle, such as limited field view of the cameras and a relatively closed and small environment. The pipeline consists of training a 2D markerless pose estimation model to work on every viewpoint, then applying it to the videos and performing triangulation. We present numerical evaluation of the results (error analysis), as well as show the utility of the achieved poses in downstream tasks of selected behavioral predictions. Our analysis of the predictive model for equine behavior showed a bias towards pain-induced horses, which aligns with our understanding of how behavior varies across painful and healthy subjects."}}
{"id": "Iii6YbY1bhs", "cdate": 1672531200000, "mdate": 1696187409066, "content": {"title": "Going Deeper than Tracking: A Survey of Computer-Vision Based Recognition of Animal Pain and Emotions", "abstract": "Advances in animal motion tracking and pose recognition have been a game changer in the study of animal behavior. Recently, an increasing number of works go \u2018deeper\u2019 than tracking, and address automated recognition of animals\u2019 internal states such as emotions and pain with the aim of improving animal welfare, making this a timely moment for a systematization of the field. This paper provides a comprehensive survey of computer vision-based research on recognition of pain and emotional states in animals, addressing both facial and bodily behavior analysis. We summarize the efforts that have been presented so far within this topic\u2014classifying them across different dimensions, highlight challenges and research gaps, and provide best practice recommendations for advancing the field, and some future directions for research."}}
{"id": "BdhK-f0u3R", "cdate": 1672531200000, "mdate": 1696187409073, "content": {"title": "Recur, Attend or Convolve? On Whether Temporal Modeling Matters for Cross-Domain Robustness in Action Recognition", "abstract": "Most action recognition models today are highly parameterized, and evaluated on datasets with appearance-wise distinct classes. It has also been shown that 2D Convolutional Neural Networks (CNNs) tend to be biased toward texture rather than shape in still image recognition tasks [19], in contrast to humans. Taken together, this raises suspicion that large video models partly learn spurious spatial texture correlations rather than to track relevant shapes over time to infer generalizable semantics from their movement. A natural way to avoid parameter explosion when learning visual patterns over time is to make use of recurrence. Biological vision consists of abundant recurrent circuitry, and is superior to computer vision in terms of domain shift generalization. In this article, we empirically study whether the choice of low-level temporal modeling has consequences for texture bias and cross-domain robustness. In order to enable a light-weight and systematic assessment of the ability to capture temporal structure, not revealed from single frames, we provide the Temporal Shape (TS) dataset, as well as modified domains of Diving48 allowing for the investigation of spatial texture bias in video models. The combined results of our experiments indicate that sound physical inductive bias such as recurrence in temporal modeling may be advantageous when robustness to domain shift is important for the task."}}
{"id": "x7wyv0tkOWR", "cdate": 1640995200000, "mdate": 1668199045726, "content": {"title": "Equine Pain Behavior Classification via Self-Supervised Disentangled Pose Representation", "abstract": ""}}
{"id": "uo0mHdClCx3", "cdate": 1640995200000, "mdate": 1696187409066, "content": {"title": "Learning Spatiotemporal Features in Low-Data and Fine-Grained Action Recognition with an Application to Equine Pain Behavior", "abstract": "Recognition of pain in animals is important because pain compromises animal welfare and can be a manifestation of disease. This is a difficult task for veterinarians and caretakers, partly because ..."}}
{"id": "oy71n9pVCJz", "cdate": 1609459200000, "mdate": 1631603355212, "content": {"title": "Automated Detection of Equine Facial Action Units", "abstract": "The recently developed Equine Facial Action Coding System (EquiFACS) provides a precise and exhaustive, but laborious, manual labelling method of facial action units of the horse. To automate parts of this process, we propose a Deep Learning-based method to detect EquiFACS units automatically from images. We use a cascade framework; we firstly train several object detectors to detect the predefined Region-of-Interest (ROI), and secondly apply binary classifiers for each action unit in related regions. We experiment with both regular CNNs and a more tailored model transferred from human facial action unit recognition. Promising initial results are presented for nine action units in the eye and lower face regions. Code for the project is publicly available."}}
{"id": "hnraKt4LPFN", "cdate": 1609459200000, "mdate": 1631603355307, "content": {"title": "Sharing Pain: Using Domain Transfer Between Pain Types for Recognition of Sparse Pain Expressions in Horses", "abstract": "Orthopedic disorders are common among horses, often leading to euthanasia, which often could have been avoided with earlier detection. These conditions often create varying degrees of subtle long-term pain. It is challenging to train a visual pain recognition method with video data depicting such pain, since the resulting pain behavior also is subtle, sparsely appearing, and varying, making it challenging for even an expert human labeller to provide accurate ground-truth for the data. We show that a model trained solely on a dataset of horses with acute experimental pain (where labeling is less ambiguous) can aid recognition of the more subtle displays of orthopedic pain. Moreover, we present a human expert baseline for the problem, as well as an extensive empirical study of various domain transfer methods and of what is detected by the pain recognition method trained on clean experimental pain in the orthopedic dataset. Finally, this is accompanied with a discussion around the challenges posed by real-world animal behavior datasets and how best practices can be established for similar fine-grained action recognition tasks. Our code is available at https://github.com/sofiabroome/painface-recognition."}}
{"id": "Vx82pBHPiK2", "cdate": 1609459200000, "mdate": 1668199045765, "content": {"title": "hSMAL: Detailed Horse Shape and Pose Reconstruction for Motion Pattern Recognition", "abstract": "In this paper we present our preliminary work on model-based behavioral analysis of horse motion. Our approach is based on the SMAL model, a 3D articulated statistical model of animal shape. We define a novel SMAL model for horses based on a new template, skeleton and shape space learned from $37$ horse toys. We test the accuracy of our hSMAL model in reconstructing a horse from 3D mocap data and images. We apply the hSMAL model to the problem of lameness detection from video, where we fit the model to images to recover 3D pose and train an ST-GCN network on pose data. A comparison with the same network trained on mocap points illustrates the benefit of our approach."}}
{"id": "VLFcOdxkR4", "cdate": 1577836800000, "mdate": 1696187409075, "content": {"title": "Interpreting Video Features: A Comparison of 3D Convolutional Networks and Convolutional LSTM Networks", "abstract": "A number of techniques for interpretability have been presented for deep learning in computer vision, typically with the goal of understanding what the networks have based their classification on. However, interpretability for deep video architectures is still in its infancy and we do not yet have a clear concept of how to decode spatiotemporal features. In this paper, we present a study comparing how 3D convolutional networks and convolutional LSTM networks learn features across temporally dependent frames. This is the first comparison of two video models that both convolve to learn spatial features but have principally different methods of modeling time. Additionally, we extend the concept of meaningful perturbation introduced by [1] to the temporal dimension, to identify the temporal part of a sequence most meaningful to the network for a classification decision. Our findings indicate that the 3D convolutional model concentrates on shorter events in the input sequence, and places its spatial focus on fewer, contiguous areas."}}
{"id": "HyxQr65z6S", "cdate": 1575296315013, "mdate": null, "content": {"title": "[Re] Unsupervised Scalable Representation Learning for Multivariate Time Series", "abstract": "We have reimplemented the paper Unsupervised Scalable Representation Learning for Multivariate Time Series by Franceschi et al., as part of the Replications track of the NeurIPS Reproducibility Challenge 2019. Among a large number of experiments, we were largely able to replicate the original paper's results. Since our experiments were run with a set of additional assumptions, this speaks in favor of the robustness of the authors' method."}}
