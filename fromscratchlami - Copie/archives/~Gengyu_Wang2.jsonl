{"id": "OfBdquxcIl", "cdate": 1672531200000, "mdate": 1693835092731, "content": {"title": "IdealGPT: Iteratively Decomposing Vision and Language Reasoning via Large Language Models", "abstract": "The field of vision-and-language (VL) understanding has made unprecedented progress with end-to-end large pre-trained VL models (VLMs). However, they still fall short in zero-shot reasoning tasks that require multi-step inferencing. To achieve this goal, previous works resort to a divide-and-conquer pipeline. In this paper, we argue that previous efforts have several inherent shortcomings: 1) They rely on domain-specific sub-question decomposing models. 2) They force models to predict the final answer even if the sub-questions or sub-answers provide insufficient information. We address these limitations via IdealGPT, a framework that iteratively decomposes VL reasoning using large language models (LLMs). Specifically, IdealGPT utilizes an LLM to generate sub-questions, a VLM to provide corresponding sub-answers, and another LLM to reason to achieve the final answer. These three modules perform the divide-and-conquer procedure iteratively until the model is confident about the final answer to the main question. We evaluate IdealGPT on multiple challenging VL reasoning tasks under a zero-shot setting. In particular, our IdealGPT outperforms the best existing GPT-4-like models by an absolute 10% on VCR and 15% on SNLI-VE. Code is available at https://github.com/Hxyou/IdealGPT"}}
{"id": "KWzcxawt6q", "cdate": 1672531200000, "mdate": 1693835092719, "content": {"title": "Check-COVID: Fact-Checking COVID-19 News Claims with Scientific Evidence", "abstract": ""}}
{"id": "Q83SnGsVfo", "cdate": 1640995200000, "mdate": 1693835092744, "content": {"title": "Distinguish Sense from Nonsense: Out-of-Scope Detection for Virtual Assistants", "abstract": ""}}
{"id": "q1Cva6PRyIl", "cdate": 1609459200000, "mdate": 1693835092712, "content": {"title": "Evidence based Automatic Fact-Checking for Climate Change Misinformation", "abstract": ""}}
{"id": "li-vqYXmOO", "cdate": 1609459200000, "mdate": 1632867915148, "content": {"title": "Semantic Categorization of Social Knowledge for Commonsense Question Answering", "abstract": "Large pre-trained language models (PLMs) have led to great success on various commonsense question answering (QA) tasks in an end-to-end fashion. However, little attention has been paid to what commonsense knowledge is needed to deeply characterize these QA tasks. In this work, we proposed to categorize the semantics needed for these tasks using the SocialIQA as an example. Building upon our labeled social knowledge categories dataset on top of SocialIQA, we further train neural QA models to incorporate such social knowledge categories and relation information from a knowledge base. Unlike previous work, we observe our models with semantic categorizations of social knowledge can achieve comparable performance with a relatively simple model and smaller size compared to other complex approaches."}}
{"id": "F-qSkkUQqE", "cdate": 1609459200000, "mdate": 1693835092741, "content": {"title": "Semantic Categorization of Social Knowledge for Commonsense Question Answering", "abstract": ""}}
{"id": "gCQsefIozag", "cdate": 1546300800000, "mdate": 1630561375133, "content": {"title": "Soft Representation Learning for Sparse Transfer", "abstract": "Haeju Park, Jinyoung Yeo, Gengyu Wang, Seung-won Hwang. Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics. 2019."}}
{"id": "lP-1f8CszNK", "cdate": 1514764800000, "mdate": null, "content": {"title": "Visual Choice of Plausible Alternatives: An Evaluation of Image-based Commonsense Causal Reasoning", "abstract": "This paper proposes the task of Visual COPA (VCOPA). Given a premise image and two alternative images, the task is to identify the more plausible alternative with their commonsense causal context. The VCOPA task is designed as its desirable machine system needs a more detailed understanding of the image, commonsense knowledge, and complex causal reasoning than state-of-the-art AI techniques. For that, we generate an evaluation dataset containing 380 VCOPA questions and over 1K images with various topics, which is amenable to automatic evaluation, and present the performance of baseline reasoning approaches as initial benchmarks for future systems."}}
