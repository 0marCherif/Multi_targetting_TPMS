{"id": "rpVxn-rX2Wh", "cdate": 1663850300494, "mdate": null, "content": {"title": "Fine-grained Few-shot Recognition by Deep Object Parsing", "abstract": "We propose a new method for fine-grained few-shot recognition via deep object parsing. In our framework, an object is made up of $K$ distinct parts and for each part, we learn a dictionary of templates, which is shared across all instances and categories. An object is parsed by estimating the locations of these $K$ parts and a set of active templates that can reconstruct the part features.  We recognize test instances by comparing its active templates and the relative geometry of its part locations against those of the presented few-shot instances. Our method is end-to-end trainable to learn part templates on-top of a convolutional backbone. To combat visual distortions such as orientation, pose and size, we learn templates at multiple scales, and at test-time parse and match instances across these scales. We show that our method is competitive with the state-of-the-art, and by virtue of parsing enjoys interpretability as well."}}
{"id": "-uNA_O_RlK", "cdate": 1577836800000, "mdate": null, "content": {"title": "Zero Shot Detection.", "abstract": "As we move toward large-scale object detection, it is unrealistic to expect annotated training data, in the form of bounding box annotations around objects, for all object classes at sufficient scale; therefore, the methods capable of unseen object detection are required. We propose a novel zero-shot method based on training an end-to-end model that fuses semantic attribute prediction with visual features to propose object bounding boxes for seen and unseen classes. While we utilize semantic features during training, our method is agnostic to semantic information for unseen classes at test-time. Our method retains the efficiency and effectiveness of YOLOv2 for objects seen during training, while improving its performance for novel and unseen objects. The ability of the state-of-the-art detection methods to learn discriminative object features to reject background proposals also limits their performance for unseen objects. We posit that, to detect unseen objects, we must incorporate semantic information into the visual domain so that the learned visual features reflect this information and lead to improved recall rates for unseen objects. We test our method on PASCAL VOC and MS COCO dataset and observed significant improvements on the average precision of unseen classes."}}
{"id": "yMhaahZnflY", "cdate": 1546300800000, "mdate": null, "content": {"title": "Cost aware Inference for IoT Devices.", "abstract": "Networked embedded devices (IoTs) of limited CPU, memory and power resources are revolutionizing data gathering, remote monitoring and planning in many consumer and business applications. Neverthel..."}}
{"id": "vClj9H0Z2wx", "cdate": 1546300800000, "mdate": null, "content": {"title": "Learning for New Visual Environments with Limited Labels.", "abstract": "In computer vision applications, such as domain adaptation (DA), few shot learning (FSL) and zero-shot learning (ZSL), we encounter new objects and environments, for which insufficient examples exist to allow for training \"models from scratch,\" and methods that adapt existing models, trained on the presented training environment, to the new scenario are required. We propose a novel visual attribute encoding method that encodes each image as a low-dimensional probability vector composed of prototypical part-type probabilities. The prototypes are learnt to be representative of all training data. At test-time we utilize this encoding as an input to a classifier. At test-time we freeze the encoder and only learn/adapt the classifier component to limited annotated labels in FSL; new semantic attributes in ZSL. We conduct extensive experiments on benchmark datasets. Our method outperforms state-of-art methods trained for the specific contexts (ZSL, FSL, DA)."}}
{"id": "TZXmN8NkeDy", "cdate": 1546300800000, "mdate": null, "content": {"title": "Generalized Zero-Shot Recognition Based on Visually Semantic Embedding.", "abstract": "We propose a novel Generalized Zero-Shot learning (GZSL) method that is agnostic to both unseen images and unseen semantic vectors during training. Prior works in this context propose to map high-dimensional visual features to the semantic domain, which we believe contributes to the semantic gap. To bridge the gap, we propose a novel low-dimensional embedding of visual instances that is \"visually semantic.\" Analogous to semantic data that quantifies the existence of an attribute in the presented instance, components of our visual embedding quantifies existence of a prototypical part-type in the presented instance. In parallel, as a thought experiment, we quantify the impact of noisy semantic data by utilizing a novel visual oracle to visually supervise a learner. These factors, namely semantic noise, visual-semantic gap and label noise lead us to propose a new graphical model for inference with pairwise interactions between label, semantic data, and inputs. We tabulate results on a number of benchmark datasets demonstrating significant improvement in accuracy over state-of-art under both semantic and visual supervision."}}
{"id": "CedbiI0eGhq", "cdate": 1546300800000, "mdate": null, "content": {"title": "Dont Even Look Once: Synthesizing Features for Zero-Shot Detection.", "abstract": "Zero-shot detection, namely, localizing both seen and unseen objects, increasingly gains importance for large-scale applications, with large number of object classes, since, collecting sufficient annotated data with ground truth bounding boxes is simply not scalable. While vanilla deep neural networks deliver high performance for objects available during training, unseen object detection degrades significantly. At a fundamental level, while vanilla detectors are capable of proposing bounding boxes, which include unseen objects, they are often incapable of assigning high-confidence to unseen objects, due to the inherent precision/recall tradeoffs that requires rejecting background objects. We propose a novel detection algorithm Dont Even Look Once (DELO), that synthesizes visual features for unseen objects and augments existing training algorithms to incorporate unseen object detection. Our proposed scheme is evaluated on Pascal VOC and MSCOCO, and we demonstrate significant improvements in test accuracy over vanilla and other state-of-art zero-shot detectors"}}
{"id": "-lyJLDk4Kof", "cdate": 1546300800000, "mdate": null, "content": {"title": "Learning Classifiers for Target Domain with Limited or No Labels.", "abstract": "In computer vision applications, such as domain adaptation (DA), few shot learning (FSL) and zero-shot learning (ZSL), we encounter new objects and environments, for which insufficient examples exi..."}}
{"id": "fY-JVMma15Z", "cdate": 1514764800000, "mdate": null, "content": {"title": "Zero-Shot Detection.", "abstract": "As we move towards large-scale object detection, it is unrealistic to expect annotated training data, in the form of bounding box annotations around objects, for all object classes at sufficient scale, and so methods capable of unseen object detection are required. We propose a novel zero-shot method based on training an end-to-end model that fuses semantic attribute prediction with visual features to propose object bounding boxes for seen and unseen classes. While we utilize semantic features during training, our method is agnostic to semantic information for unseen classes at test-time. Our method retains the efficiency and effectiveness of YOLOv2 for objects seen during training, while improving its performance for novel and unseen objects. The ability of state-of-art detection methods to learn discriminative object features to reject background proposals also limits their performance for unseen objects. We posit that, to detect unseen objects, we must incorporate semantic information into the visual domain so that the learned visual features reflect this information and leads to improved recall rates for unseen objects. We test our method on PASCAL VOC and MS COCO dataset and observed significant improvements on the average precision of unseen classes."}}
{"id": "VJRWIoCS3H", "cdate": 1514764800000, "mdate": null, "content": {"title": "Generalized Zero-Shot Recognition based on Visually Semantic Embedding.", "abstract": "We propose a novel Generalized Zero-Shot learning (GZSL) method that is agnostic to both unseen images and unseen semantic vectors during training. Prior works in this context propose to map high-dimensional visual features to the semantic domain, we believe contributes to the semantic gap. To bridge the gap, we propose a novel low-dimensional embedding of visual instances that is \"visually semantic.\" Analogous to semantic data that quantifies the existence of an attribute in the presented instance, components of our visual embedding quantifies existence of a prototypical part-type in the presented instance. In parallel, as a thought experiment, we quantify the impact of noisy semantic data by utilizing a novel visual oracle to visually supervise a learner. These factors, namely semantic noise, visual-semantic gap and label noise lead us to propose a new graphical model for inference with pairwise interactions between label, semantic data, and inputs. We tabulate results on a number of benchmark datasets demonstrating significant improvement in accuracy over state-of-the-art under both semantic and visual supervision."}}
{"id": "w6C4B4BIRj5", "cdate": 1483228800000, "mdate": null, "content": {"title": "Ship Fuzzy Recognition Based on Superstructure with Maximum Membership Rule.", "abstract": "The Automatic Target Recognition (ATR) of ship targets based on high resolution Inverse Synthetic Aperture Radar (ISAR) images has a good prospect of marine environmental protection, monitoring and traffic management. In this letter, a novel ship classification technique is proposed based on the ship superstructure by using the fuzzy recognition method. An improved segmentation algorithm of the ship silhouette is applied to obtain the segment comparative mean (SCM) feature. The SCM is used to calculate the target\u2019s membership of each class and eventually the maximum membership rule is applied to determine the target\u2019s class. The experimental results of applying the technique on real ISAR data demonstrate the effectiveness of the proposed approach."}}
