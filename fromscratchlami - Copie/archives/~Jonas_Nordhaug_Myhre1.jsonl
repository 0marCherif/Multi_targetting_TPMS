{"id": "THDtEu-v225", "cdate": 1577836800000, "mdate": 1631701068981, "content": {"title": "A generic unfolding algorithm for manifolds estimated by local linear approximations", "abstract": "The individual stages of most popular manifold learning algorithms are complicated by overlapping ideas -- often consisting of a mix of learning how to embed, unfold and reduce the dimension of the manifold at the same time. Furthermore, the effect each step has on the final result is in many cases not clear. Research in both machine learning and mathematical communities has focused on the steps involved in manifold embedding and estimation, and sample sizes and performance bounds related to these operations have been explored. However, the problem of unwrapping or unfolding manifolds has received relatively little attention despite being an integral part of manifold learning in general. In this work, we present a new generic algorithm for unfolding manifolds that have been estimated by local linear approximations. Our algorithm is a combination of ideas from principal curves and density ridge estimation and tools from classical differential geometry. Numerical experiments on both real and synthetic data sets illustrates the merit of our proposed algorithm."}}
{"id": "p49DBo7jGeD", "cdate": 1514764800000, "mdate": 1631701068984, "content": {"title": "Robust clustering using a kNN mode seeking ensemble", "abstract": "Highlights \u2022 A new clustering ensemble based on kNN mode seeking is proposed. \u2022 The algorithm is robust with respect to hyperparameters\u2013no manual tuning needed. \u2022 The algorithm is faster than the state-of-the art and able to handle high-dimensional data sets. Abstract In this paper we present a new algorithm for parameter-free clustering by mode seeking. Mode seeking, especially in the form of the mean shift algorithm, is a widely used strategy for clustering data, but at the same time prone to poor performance if the parameters are not chosen correctly. We propose to form a clustering ensemble consisting of repeated and bootstrapped runs of the recent kNN mode seeking algorithm, an algorithm which is faster than ordinary mean shift and more suited for high dimensional data. This creates a robust mode seeking clustering algorithm with respect to the choice of parameters and high dimensional input spaces, while at the same inheriting all other strengths of mode seeking in general. We demonstrate promising results on a number of synthetic and real data sets."}}
{"id": "Utp97fvz2E8", "cdate": 1514764800000, "mdate": 1631701068983, "content": {"title": "Controlling blood glucose Levels in patients with Type 1 Diabetes using fitted Q-iterations and Functional Features", "abstract": "Type 1 Diabetes is characterized by the lack of insulin-producing beta cells in the pancreas. The artificial pancreas promises to alleviate the burdens of self-management. While the physical components of the system - the continuous glucose monitor and insulin pump - have experienced rapid advances, a technological bottleneck remains in the control algorithm, which is responsible for translating data from the former into instructions for the latter. In this work, we propose to bring machine learning techniques to bear upon the challenges of blood glucose control. Specifically, we employ reinforcement learning to learn an optimal insulin policy. Learning is generalized using nonparametric regression with functional features, exploiting information contained in the shape of the glucose curve. Our algorithm is model-free, data-driven and personalized. In-silico simulations with T1D models demonstrate the potential of the proposed algorithm."}}
{"id": "-K6K_vymmRR", "cdate": 1514764800000, "mdate": 1631701068982, "content": {"title": "Secant manifold constrained random projections -Improved cluster ensembles", "abstract": "In this paper we present two contributions to the framework of ensemble clustering. Our work expands the robust k nearest neighborhood clustering ensemble to include random projections for further increasing the stochastic exploration of the data set to be clustered. In addition we propose to constrain the random projection ensemble to only contain distance-preserving projection directions. The latter is obtained by constraining the projection directions to be orthogonal to the so-called Secant manifold of the input data set. Promising results are shown on a series of benchmark data sets."}}
{"id": "Pq1IJLo2LjX", "cdate": 1483228800000, "mdate": null, "content": {"title": "Density ridge manifold traversal", "abstract": "The density ridge framework for estimating principal curves and surfaces has in a number of recent works been shown to capture manifold structure in data in an intuitive and effective manner. However, to date there exists no efficient way to traverse these manifolds as defined by density ridges. This is unfortunate, as manifold traversal is an important problem for example for shape estimation in medical imaging, or in general for being able to characterize and understand state transitions or local variability over the data manifold. In this paper, we remedy this situation by introducing a novel manifold traversal algorithm based on geodesics within the density ridge approach. The traversal is executed in a subspace capturing the intrinsic dimensionality of the data using dimensionality reduction techniques such as principal component analysis or kernel entropy component analysis. A mapping back to the ambient space is obtained by training a neural network. We compare against maximum mean discrepancy traversal, a recent approach, and obtain promising results."}}
{"id": "gHB8H9Th2Gq", "cdate": 1420070400000, "mdate": 1631701068984, "content": {"title": "Computationally Efficient Exact Calculation of Kernel Density Derivatives", "abstract": "Machine learning research related to the derivatives of the kernel density estimator has received limited attention compared to the density estimator itself. This is despite of the general consensus that most of the important features of a data distribution, such as modes, curvature or even cluster structure, are characterized by its derivatives. In this paper we present a computationally efficient algorithm to calculate kernel density estimates and their derivatives for linearly separable kernels, with significant savings especially for high dimensional data and higher order derivatives. It significantly reduces the number of operations (multiplications and derivative evaluations) to calculate the estimates, while keeping results exact (i.e. no approximations are involved). The main idea is that the calculation of multivariate separable kernels and their derivatives, such as the gradient vector and the Hessian matrix involves significant number of redundant operations that can be eliminated using the chain rule. A tree-based algorithm that calculates exact kernel density estimate and derivatives in the most efficient fashion is presented with the particular focus being on optimizing kernel evaluations for individual data pairs. In contrast, most approaches in the literature resort to approximations of functions or downsampling. Overall computational savings of the presented method could be further increased by incorporating such approximations, which aim to reduce the number of pairs of data considered. The theoretical computational complexity of the tree-based and direct methods that perform all multiplications are compared. In experimental results, calculating separable kernels and their derivatives is considered, as well as a measure that evaluates how close a point is to the principal curve of a density, which employs first and second derivatives. These results indicate considerable improvement in computational complexity, hence time over the direct approach."}}
{"id": "ZNIowt2O86z", "cdate": 1420070400000, "mdate": 1631701069194, "content": {"title": "Consensus Clustering Using kNN Mode Seeking", "abstract": "In this paper we present a novel clustering approach which combines two modern strategies, namely consensus clustering, and two stage clustering as represented by the mean shift spectral clustering algorithm. We introduce the recent kNN mode seeking algorithm in the consensus clustering framework, and the information theoretic kNN Cauchy Schwarz divergence as foundation for spectral clustering. In combining these frameworks, two well known problematic issues are directly bypassed; the kernel bandwidth choice of the kernel density based mean shift and the computational complexity of the mean shift iterations. We demonstrate experiments on both real and synthetic data as a proof of concept for our contributions."}}
{"id": "3GxjnG8wTFf", "cdate": 1388534400000, "mdate": 1631701069148, "content": {"title": "Invertible nonlinear cluster unwrapping", "abstract": "We propose that the orthogonal curvilinear coordinate systems revealed locally by the eigenvector flow derived from the Hessian of data density can be used as a mean to obtain local charts around modes. These charts can be stitched to form an atlas to define a global map of the data space, providing a base for data classification or clustering. A given point is projected to the ridges of the probability density by solving a differential equation which forces the gradient to be in the direction of the eigenvector corresponding to the largest eigenvalue of the Hessian. A curvilinear coordinate is then determined as the curve length along each ridge from the projection point to the mode. Since solving such differential equations numerically could be computationally prohibitive for large number of samples to be projected, we also present a diffeomorphic coordinate transformation model to approximate these Cartesian-to-curvilinear coordinate mappings. The model is primarily conceived as an interpolator, and the landmark training data are transformed exactly. The interpolation model is regularized in the Tikhonov sense using a user-specified differential operator. The proposed interpolation methodology is adapted from landmark-matching-based deformable image registration literature."}}
{"id": "OP_zZXC5JAg", "cdate": 1325376000000, "mdate": 1631701069136, "content": {"title": "Mixture weight influence on kernel entropy component analysis and semi-supervised learning using the Lasso", "abstract": "The aim of this paper is two-fold. First, we show that the newly developed spectral method known as kernel entropy component analysis (kernel ECA) captures cluster structure, which is very important in semi-supervised learning, and we provide an analysis showing how mixture weights influence kernel ECA in a mixture of cluster components setting. Second, we develop a semi-supervised kernel ECA classifier based on the Lasso framework, and report promising results compared to the state-of-the art."}}
{"id": "oVgo1Xo3KTrlgPMRsBVZ", "cdate": null, "mdate": null, "content": {"title": "Manifold traversal using density ridges", "abstract": "In this work we present two examples of how a manifold learning model can represent the complexity of shape variation in images.\nManifold learning techniques for image manifolds can be used to model data in sparse manifold regions. \nAdditionally, they can be used as generative models as they can often better represent or learn structure in the data. \nWe propose a method of estimating the underlying manifold using the ridges of a kernel density estimate as well as tangent space operations that allows interpolation between images along the manifold and offers a novel approach to analyzing the image manifold."}}
