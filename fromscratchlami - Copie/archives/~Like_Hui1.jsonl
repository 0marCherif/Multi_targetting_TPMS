{"id": "hsFN92eQEla", "cdate": 1601308198718, "mdate": null, "content": {"title": "EVALUATION OF NEURAL ARCHITECTURES TRAINED WITH SQUARE LOSS VS CROSS-ENTROPY IN CLASSIFICATION TASKS", "abstract": "Modern neural architectures for classification tasks are trained using the cross-entropy loss, which is widely believed to be empirically superior to the square loss. In this work we provide evidence indicating that this belief may not be well-founded. \nWe explore several major neural architectures and a range of standard benchmark datasets for NLP, automatic speech recognition (ASR) and computer vision tasks to show that these architectures, with the same hyper-parameter settings as reported in the literature, perform comparably or better when trained with the square loss, even after equalizing computational resources.\nIndeed, we observe that the square loss produces better results in the dominant majority of NLP and ASR experiments. Cross-entropy appears to have a slight edge on computer vision tasks.\n\nWe argue that there is little compelling empirical or theoretical evidence indicating a clear-cut advantage to the cross-entropy loss. Indeed, in our experiments, performance on nearly all non-vision tasks  can be improved, sometimes significantly, by switching to the square loss. Furthermore, training with square loss appears to be less sensitive to the randomness in initialization. We posit that\ntraining using the square loss for classification needs to be a part of best practices of modern deep learning on equal footing with cross-entropy. "}}
{"id": "wXekp1pcK71", "cdate": 1546300800000, "mdate": 1639508170689, "content": {"title": "Joint Training of Complex Ratio Mask Based Beamformer and Acoustic Model for Noise Robust Asr", "abstract": "In this paper, we present a joint training framework between the multi-channel beamformer and the acoustic model for noise robust automatic speech recognition (ASR). The complex ratio mask (CRM), demonstrated to be more effective than the ideal ratio mask (IRM), is proposed to estimate the covariance matrix for the beamformer. Minimum Variance Distortionless Response (MVDR) beamformer and Generalized Eigenvalue (GEV) beamformer are both investigated under the CRM-based joint training architecture. We also propose a robust mask pooling strategy among multiple channels. A long short-term memory (LSTM) based language model is utilized to re-score hypotheses which further improves the overall performance. We evaluate the proposed methods on CHiME-4 challenge dataset. The CRM based system achieves a relative 10% reduction on word error rate (WER) compared with the IRM based system. Without sequence discriminative training, our best single system already achieves an average WER 2.72% on the test set which is comparable to the state-of-the-art."}}
{"id": "lJADgokFuO", "cdate": 1546300800000, "mdate": 1648685820039, "content": {"title": "Kernel Machines Beat Deep Neural Networks on Mask-Based Single-Channel Speech Enhancement", "abstract": "We apply a fast kernel method for mask-based single-channel speech enhancement. Specifically, our method solves a kernel regression problem associated to a non-smooth kernel function (exponential power kernel) with a highly efficient iterative method (EigenPro). Due to the simplicity of this method, its hyper-parameters such as kernel bandwidth can be automatically and efficiently selected using line search with subsamples of training data. We observe an empirical correlation between the regression loss (mean square error) and regular metrics for speech enhancement. This observation justifies our training target and motivates us to achieve lower regression loss by training separate kernel models for different frequency subbands. We compare our method with the state-of-the-art deep neural networks on mask-based HINT and TIMIT. Experimental results show that our kernel method consistently outperforms deep neural networks while requiring less training time."}}
{"id": "AMvooVlImg", "cdate": 1451606400000, "mdate": 1681665114483, "content": {"title": "A speech enhancement algorithm using computational auditory scene analysis with spectral subtraction", "abstract": ""}}
{"id": "li5wGkC1Wmx", "cdate": 1420070400000, "mdate": 1681665114504, "content": {"title": "Improved system fusion for keyword search", "abstract": ""}}
{"id": "UKYAyygw3FC", "cdate": 1420070400000, "mdate": 1648685820028, "content": {"title": "Convolutional maxout neural networks for speech separation", "abstract": "Speech separation based on deep neural networks (DNNs) has been widely studied recently, and has achieved considerable success. However, previous studies are mostly based on fully-connected neural networks. In order to capture the local information of speech signals, we propose to use convolutional maxout neural networks (CMNNs) to separate speech and noise by estimating the ideal ratio mask of the time-frequency units. In our work the proposed CMNN is applied in the frequency domain. By using local filtering and max-pooling, convolutional neural networks can model the local structure of speech signals. Instead of sigmoid function, maxout is selected to address the saturation problem. In addition, dropout is integrated into the network to get better generalization ability. The proposed system outperforms a traditional DNN-based system in both objective speech quality and intelligibility."}}
{"id": "0Lht8xnNUgW", "cdate": 1420070400000, "mdate": 1681665114535, "content": {"title": "High-performance Swahili keyword search with very limited language pack: The THUEE system for the OpenKWS15 evaluation", "abstract": ""}}
