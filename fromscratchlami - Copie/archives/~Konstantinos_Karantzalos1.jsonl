{"id": "WCl2B5GZB42", "cdate": 1652697258696, "mdate": 1652697258696, "content": {"title": "CLOUDTRAN: CLOUD REMOVAL FROM MULTITEMPORAL SATELLITE IMAGES USING AXIAL TRANSFORMER NETWORKS", "abstract": "We present a method for cloud-removal from satellite images using axial transformer networks. The method considers a set of multitemporal images in a given region of interest together with the corresponding cloud masks, and delivers a cloud-free image for a specific day of the year. We propose the combination of an encoder-decoder model employing axial attention layers for the estimation of the low-resolution cloud-free image, together with a fully parallel upsampler that reconstructs the image at full resolution. The method is compared with various baselines and state-of-the-art methods on two Sentinel-2 datasets, showing significant improvements across multiple standard metrics used for image quality assessment."}}
{"id": "zb3l4hrMj40", "cdate": 1640995200000, "mdate": 1668510221596, "content": {"title": "Objects Can Move: 3D Change Detection by Geometric Transformation Consistency", "abstract": "AR/VR applications and robots need to know when the scene has changed. An example is when objects are moved, added, or removed from the scene. We propose a 3D object discovery method that is based only on scene changes. Our method does not need to encode any assumptions about what is an object, but rather discovers objects by exploiting their coherent move. Changes are initially detected as differences in the depth maps and segmented as objects if they undergo rigid motions. A graph cut optimization propagates the changing labels to geometrically consistent regions. Experiments show that our method achieves state-of-the-art performance on the 3RScan dataset against competitive baselines. The source code of our method can be found at https://github.com/katadam/ObjectsCanMove ."}}
{"id": "yZ2xaWJc7JF", "cdate": 1640995200000, "mdate": 1668510221594, "content": {"title": "What to Hide from Your Students: Attention-Guided Masked Image Modeling", "abstract": "Transformers and masked language modeling are quickly being adopted and explored in computer vision as vision transformers and masked image modeling (MIM). In this work, we argue that image token masking differs from token masking in text, due to the amount and correlation of tokens in an image. In particular, to generate a challenging pretext task for MIM, we advocate a shift from random masking to informed masking. We develop and exhibit this idea in the context of distillation-based MIM, where a teacher transformer encoder generates an attention map, which we use to guide masking for the student. We thus introduce a novel masking strategy, called attention-guided masking (AttMask), and we demonstrate its effectiveness over random masking for dense distillation-based MIM as well as plain distillation-based self-supervised learning on classification tokens. We confirm that AttMask accelerates the learning process and improves the performance on a variety of downstream tasks. We provide the implementation code at https://github.com/gkakogeorgiou/attmask ."}}
{"id": "t3Kk9RoXa-", "cdate": 1640995200000, "mdate": 1668510221596, "content": {"title": "RAMONES and Environmental Intelligence: Progress Update", "abstract": "RAMONES is an EU H2020 FET Proactive Project which aims to offer a new fleet of instruments to perform continuous and in situ measurements of natural and artificial radioactivity in the marine environment as part of its main objectives. Those instruments will be developed, optimized, validated and deployed in the field, based on implementing specific functional characteristics, optimizing integrated solutions, and fine-tuning their overall architecture. The main effort in RAMONES is to define the new state-of-the-art in radioactivity monitoring in ocean ecosystems investing on innovative stationary and mobile platforms. RAMONES will develop light-weight, high-resolution, power-efficient radiation spectrometers integrated aboard autonomous underwater vehicles. A benthic laboratory will additionally be developed as a multi-instrument platform to offer high-resolution spectroscopy and imaging capabilities equipped with additional sensors. Radioactivity monitoring will offer several opportunities to understand the dose impact on ocean ecosystems in various extreme locations, such as underwater volcanoes, seismic faults or deep-ocean drilling locations. Artificial intelligence and robotics will core factors in achieving the new state-of-the-art in coordinated navigation and decision making, and will provide the tools for risk forecasting and risk mitigation. In this paper, a progress update on RAMONES instruments is reported, jointly with a report on the RAMONES contributions to the Environmental Intelligence initiative."}}
{"id": "hy3CvmDtAa", "cdate": 1640995200000, "mdate": 1668510221597, "content": {"title": "Objects Can Move: 3D Change Detection by Geometric Transformation Constistency", "abstract": "AR/VR applications and robots need to know when the scene has changed. An example is when objects are moved, added, or removed from the scene. We propose a 3D object discovery method that is based only on scene changes. Our method does not need to encode any assumptions about what is an object, but rather discovers objects by exploiting their coherent move. Changes are initially detected as differences in the depth maps and segmented as objects if they undergo rigid motions. A graph cut optimization propagates the changing labels to geometrically consistent regions. Experiments show that our method achieves state-of-the-art performance on the 3RScan dataset against competitive baselines. The source code of our method can be found at https://github.com/katadam/ObjectsCanMove."}}
{"id": "eItP25WPW9T", "cdate": 1640995200000, "mdate": 1668510221749, "content": {"title": "Transformer-based assignment decision network for multiple object tracking", "abstract": "Data association is a crucial component for any multiple object tracking (MOT) method that follows the tracking-by-detection paradigm. To generate complete trajectories such methods employ a data association process to establish assignments between detections and existing targets during each timestep. Recent data association approaches try to solve a multi-dimensional linear assignment task or a network flow minimization problem or either tackle it via multiple hypotheses tracking. However, during inference an optimization step that computes optimal assignments is required for every sequence frame adding significant computational complexity in any given solution. To this end, in the context of this work we introduce Transformer-based Assignment Decision Network (TADN) that tackles data association without the need of any explicit optimization during inference. In particular, TADN can directly infer assignment pairs between detections and active targets in a single forward pass of the network. We have integrated TADN in a rather simple MOT framework, we designed a novel training strategy for efficient end-to-end training and demonstrate the high potential of our approach for online visual tracking-by-detection MOT on two popular benchmarks, i.e. MOT17 and UA-DETRAC. Our proposed approach outperforms the state-of-the-art in most evaluation metrics despite its simple nature as a tracker which lacks significant auxiliary components such as occlusion handling or re-identification. The implementation of our method is publicly available at https://github.com/psaltaath/tadn-mot."}}
{"id": "dLf4QX4XjE", "cdate": 1640995200000, "mdate": 1668510221595, "content": {"title": "Assessment of Different Object Detectors for the Maturity Level Classification of Broccoli Crops Using UAV Imagery", "abstract": "Broccoli is an example of a high-value crop that requires delicate handling throughout the growing season and during its post-harvesting treatment. As broccoli heads can be easily damaged, they are still harvested by hand. Moreover, human scouting is required to initially identify the field segments where several broccoli plants have reached the desired maturity level, such that they can be harvested while they are in the optimal condition. The aim of this study was to automate this process using state-of-the-art Object Detection architectures trained on georeferenced orthomosaic-derived RGB images captured from low-altitude UAV flights, and to assess their capacity to effectively detect and classify broccoli heads based on their maturity level. The results revealed that the object detection approach for automated maturity classification achieved comparable results to physical scouting overall, especially for the two best-performing architectures, namely Faster R-CNN and CenterNet. Their respective performances were consistently over 80% mAP@50 and 70% mAP@75 when using three levels of maturity, and even higher when simplifying the use case into a two-class problem, exceeding 91% and 83%, respectively. At the same time, geometrical transformations for data augmentations reported improvements, while colour distortions were counterproductive. The best-performing architecture and the trained model could be tested as a prototype in real-time UAV detections in order to assist in on-field broccoli maturity detection."}}
{"id": "ZMNsSD08_u", "cdate": 1640995200000, "mdate": 1668510221597, "content": {"title": "Towards a Deep Learning Fractional Woody Vegetation Cover Monitoring Framework", "abstract": ""}}
{"id": "YlukyeLOTo", "cdate": 1640995200000, "mdate": 1668510221595, "content": {"title": "It Takes Two to Tango: Mixup for Deep Metric Learning", "abstract": "Metric learning involves learning a discriminative representation such that embeddings of similar classes are encouraged to be close, while embeddings of dissimilar classes are pushed far apart. State-of-the-art methods focus mostly on sophisticated loss functions or mining strategies. On the one hand, metric learning losses consider two or more examples at a time. On the other hand, modern data augmentation methods for classification consider two or more examples at a time. The combination of the two ideas is under-studied. In this work, we aim to bridge this gap and improve representations using mixup, which is a powerful data augmentation approach interpolating two or more examples and corresponding target labels at a time. This task is challenging because, unlike classification, the loss functions used in metric learning are not additive over examples, so the idea of interpolating target labels is not straightforward. To the best of our knowledge, we are the first to investigate mixing both examples and target labels for deep metric learning. We develop a generalized formulation that encompasses existing metric learning loss functions and modify it to accommodate for mixup, introducing Metric Mix, or Metrix. We also introduce a new metric---utilization---to demonstrate that by mixing examples during training, we are exploring areas of the embedding space beyond the training classes, thereby improving representations. To validate the effect of improved representations, we show that mixing inputs, intermediate representations or embeddings along with target labels significantly outperforms state-of-the-art metric learning methods on four benchmark deep metric learning datasets."}}
{"id": "WzOw1Lcpka-", "cdate": 1640995200000, "mdate": 1668510221597, "content": {"title": "What to Hide from Your Students: Attention-Guided Masked Image Modeling", "abstract": "Transformers and masked language modeling are quickly being adopted and explored in computer vision as vision transformers and masked image modeling (MIM). In this work, we argue that image token masking differs from token masking in text, due to the amount and correlation of tokens in an image. In particular, to generate a challenging pretext task for MIM, we advocate a shift from random masking to informed masking. We develop and exhibit this idea in the context of distillation-based MIM, where a teacher transformer encoder generates an attention map, which we use to guide masking for the student. We thus introduce a novel masking strategy, called attention-guided masking (AttMask), and we demonstrate its effectiveness over random masking for dense distillation-based MIM as well as plain distillation-based self-supervised learning on classification tokens. We confirm that AttMask accelerates the learning process and improves the performance on a variety of downstream tasks. We provide the implementation code at https://github.com/gkakogeorgiou/attmask."}}
