{"id": "L4SHaWw_od_", "cdate": 1672531200000, "mdate": 1681858522453, "content": {"title": "Relax, it doesn't matter how you get there: A new self-supervised approach for multi-timescale behavior analysis", "abstract": "Natural behavior consists of dynamics that are complex and unpredictable, especially when trying to predict many steps into the future. While some success has been found in building representations of behavior under constrained or simplified task-based conditions, many of these models cannot be applied to free and naturalistic settings where behavior becomes increasingly hard to model. In this work, we develop a multi-task representation learning model for behavior that combines two novel components: (i) An action prediction objective that aims to predict the distribution of actions over future timesteps, and (ii) A multi-scale architecture that builds separate latent spaces to accommodate short- and long-term dynamics. After demonstrating the ability of the method to build representations of both local and global dynamics in realistic robots in varying environments and terrains, we apply our method to the MABe 2022 Multi-agent behavior challenge, where our model ranks 1st overall and on all global tasks, and 1st or 2nd on 7 out of 9 frame-level tasks. In all of these cases, we show that our model can build representations that capture the many different factors that drive behavior and solve a wide range of downstream tasks."}}
{"id": "GTBwKOgSEac", "cdate": 1672531200000, "mdate": 1681709520684, "content": {"title": "MTNeuro: A Benchmark for Evaluating Representations of Brain Structure Across Multiple Levels of Abstraction", "abstract": "There are multiple scales of abstraction from which we can describe the same image, depending on whether we are focusing on fine-grained details or a more global attribute of the image. In brain mapping, learning to automatically parse images to build representations of both small-scale features (e.g., the presence of cells or blood vessels) and global properties of an image (e.g., which brain region the image comes from) is a crucial and open challenge. However, most existing datasets and benchmarks for neuroanatomy consider only a single downstream task at a time. To bridge this gap, we introduce a new dataset, annotations, and multiple downstream tasks that provide diverse ways to readout information about brain structure and architecture from the same image. Our multi-task neuroimaging benchmark (MTNeuro) is built on volumetric, micrometer-resolution X-ray microtomography images spanning a large thalamocortical section of mouse brain, encompassing multiple cortical and subcortical regions. We generated a number of different prediction challenges and evaluated several supervised and self-supervised models for brain-region prediction and pixel-level semantic segmentation of microstructures. Our experiments not only highlight the rich heterogeneity of this dataset, but also provide insights into how self-supervised approaches can be used to learn representations that capture multiple attributes of a single image and perform well on a variety of downstream tasks. Datasets, code, and pre-trained baseline models are provided at: https://mtneuro.github.io/ ."}}
{"id": "5xuowSQ17vy", "cdate": 1654544673115, "mdate": null, "content": {"title": "MTNeuro:  A Benchmark for Evaluating Representations of Brain Structure Across Multiple Levels of Abstraction", "abstract": "There are multiple scales of abstraction from which we can describe the same image, depending on whether we are focusing on fine-grained details or a more global attribute of the image. In brain mapping, learning to automatically parse images to build representations of both small-scale features (e.g., the presence of cells or blood vessels) and global properties of an image (e.g., which brain region the image comes from) is a crucial and open challenge. However, most existing datasets and benchmarks for neuroanatomy consider only a single downstream task at a time. To bridge this gap, we introduce a new dataset, annotations, and multiple downstream tasks that provide diverse ways to readout information about brain structure and architecture from the same image. Our multi-task neuroimaging benchmark (MTNeuro) is built on volumetric, micrometer-resolution X-ray microtomography images spanning a large thalamocortical section of mouse brain, encompassing multiple cortical and subcortical regions. We generated a number of different prediction challenges and evaluated several supervised and self-supervised models for brain-region prediction and pixel-level semantic segmentation of microstructures. Our experiments not only highlight the rich heterogeneity of this dataset, but also provide insights into how self-supervised approaches can be used to learn representations that capture multiple attributes of a single image and perform well on a variety of downstream tasks. Datasets, code, and pre-trained baseline models are provided at: https://mtneuro.github.io/."}}
{"id": "oi33uH0VO-r", "cdate": 1640995200000, "mdate": 1683666170481, "content": {"title": "MTNeuro: A Benchmark for Evaluating Representations of Brain Structure Across Multiple Levels of Abstraction", "abstract": "title> <link rel=\"stylesheet\" href=\"/static/papers/css/papers.css\" /> <meta name=\"citation_title\" content=\"MTNeuro: A Benchmark for Evaluating Representations of Brain Structure Across Multiple Levels of Abstraction\" /> <meta name=\"citation_author\" content=\"Quesada, Jorge\" /> <meta name=\"citation_author\" content=\"Sathidevi, Lakshmi\" /> <meta name=\"citation_author\" content=\"Liu, Ran\" /> <meta name=\"citation_author\" content=\"Ahad, Nauman\" /> <meta name=\"citation_author\" content=\"Jackson, Joy\" /> <meta name=\"citation_author\" content=\"Azabou, Mehdi\" /> <meta name=\"citation_author\" content=\"Xiao, Jingyun\" /> <meta name=\"citation_author\" content=\"Liding, Christopher\" /> <meta name=\"citation_author\" content=\"Jin, Matthew\" /> <meta name=\"citation_author\" content=\"Urzay, Carolina\" /> <meta name=\"citation_author\" content=\"Gray-Roncal, William\" /> <meta name=\"citation_author\" content=\"Johnson, Erik\" /> <meta name=\"citation_author\" content=\"Dyer, Eva\" /> <meta name=\"citation_journal_title\" content=\"Advances in Neural Information Processing Systems\" /> <meta name=\"citation_volume\" content=\"35\" /> <meta name=\"citation_firstpage\" content=\"5299\" /> <meta name=\"citation_lastpage\" content=\"5314\" /> <meta name=\"citation_pdf_url\" content=\"https://proceedings.neurips.cc/paper_files/paper/2022/file/22fb65e39d318c4b5b56fbe9cb082e3f-Paper-Datasets_and_Benchmarks.pdf\" /> <meta name=\"citation_publication_date\" content=\"2022-12-06\" /><!-- Bootstrap CSS --> <!-- https://codepen.io/surjithctly/pen/PJqKzQ --> <link rel=\"stylesheet\" href=\"https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css\" integrity=\"sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh\" crossorigin=\"anonymous\" /> <link href=\"/static/menus/css/menus.css\" rel=\"stylesheet\" id=\"bootstrap-css\" /> <link rel=\"stylesheet\" href=\"https://use.fontawesome.com/releases/v5.8.1/css/all.css\" integrity=\"sha384-50oBUHEmvpQ+1lW4y57PTFmhCaXp0ML5d60M1M7uH2+nqUivzIebhndOJK28anvf\" crossorigin=\"anonymous\" /> <script type=\"text/javascript\" async=\"async\" src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-MML-AM_CHTML\"></script> <script type=\"text/x-mathjax-config\"> <![CDATA[ MathJax.Hub.Config({ \"tex2jax\": { \"inlineMath\": [[\"$\",\"$\"], [\"\\\\(\",\"\\\\)\"]], \"displayMath\": [[\"\\\\[\",\"\\\\]\"]], \"processEscapes\": true } } ); ]]> </script> <style> <![CDATA[ @media (prefers-color-scheme: dark) { body { background-color: #333; color: #eee; } } .btn-spacer { margin: 2px; } .footer { position: fixed; left: 0; bottom: 0; width: 100%; background-color: #eee; color: black; } ]]> </style> <nav class=\"navbar navbar-expand-md navbar-light bg-light\"> <button class=\"navbar-toggler\" type=\"button\" data-toggle=\"collapse\" data-target=\"#navbarToggler6\" aria-controls=\"navbarToggler6\" aria-expanded=\"false\" aria-label=\"Toggle navigation\"><span class=\"navbar-toggler-icon\"></span></button> <div class=\"collapse navbar-collapse\" id=\"navbarToggler6\"> <a class=\"navbar-brand\" href=\"/\">NeurIPS Proceedings</a> <ul class=\"navbar-nav mr-auto mt-2 mt-md-0\"> <li class=\"nav-item\"> <a class=\"nav-link\" href=\"/admin/login/?next=/admin/\"><i class=\"fas fa-sign-in-alt\" title=\"Login\"></i></a> <li class=\"nav-item\"> <a class=\"nav-link\" href=\"/admin/logout/?nextp=/admin\"><i class=\"fas fa-sign-out-alt\" title=\"Logout\"></i></a> <form class=\"form-inline my-2 my-lg-0\" method=\"get\" role=\"search\" action=\"/papers/search\"> <input class=\"form-control mr-sm-2\" type=\"text\" name=\"q\" placeholder=\"Search\" aria-label=\"Search\" id=\"navsearch\" /> <button class=\"btn btn-outline-success my-2 my-sm-0\" type=\"submit\">Search</button>"}}
{"id": "E1yAOVUxXnI", "cdate": 1640995200000, "mdate": 1683666170272, "content": {"title": "Learning Sinkhorn divergences for supervised change point detection", "abstract": "Many modern applications require detecting change points in complex sequential data. Most existing methods for change point detection are unsupervised and, as a consequence, lack any information regarding what kind of changes we want to detect or if some kinds of changes are safe to ignore. This often results in poor change detection performance. We present a novel change point detection framework that uses true change point instances as supervision for learning a ground metric such that Sinkhorn divergences can be then used in two-sample tests on sliding windows to detect change points in an online manner. Our method can be used to learn a sparse metric which can be useful for both feature selection and interpretation in high-dimensional change point detection settings. Experiments on simulated as well as real world sequences show that our proposed method can substantially improve change point detection performance over existing unsupervised change point detection methods using only few labeled change point instances."}}
{"id": "7mMvMWoURXY", "cdate": 1640995200000, "mdate": 1668534652083, "content": {"title": "Learning Behavior Representations Through Multi-Timescale Bootstrapping", "abstract": "Natural behavior consists of dynamics that are both unpredictable, can switch suddenly, and unfold over many different timescales. While some success has been found in building representations of behavior under constrained or simplified task-based conditions, many of these models cannot be applied to free and naturalistic settings due to the fact that they assume a single scale of temporal dynamics. In this work, we introduce Bootstrap Across Multiple Scales (BAMS), a multi-scale representation learning model for behavior: we combine a pooling module that aggregates features extracted over encoders with different temporal receptive fields, and design a set of latent objectives to bootstrap the representations in each respective space to encourage disentanglement across different timescales. We first apply our method on a dataset of quadrupeds navigating in different terrain types, and show that our model captures the temporal complexity of behavior. We then apply our method to the MABe 2022 Multi-agent behavior challenge, where our model ranks 3rd overall and 1st on two subtasks, and show the importance of incorporating multi-timescales when analyzing behavior."}}
{"id": "0oLjGokwdjM", "cdate": 1640995200000, "mdate": 1683666170264, "content": {"title": "Delta Distancing: A Lifting Approach to Localizing Items from User Comparisons", "abstract": "A common problem in recommendation systems is to learn a model of user preferences based only on comparisons of the relative attractiveness of different items. We consider this problem in the context of an ideal point model of user preference, where each user can be represented as a point in a low-dimensional space together with a set of items. In this model, the closer an item is to a user\u2019s ideal point, the more that user prefers the item. When an embedding of items is known a priori, the problem of localizing a user\u2019s ideal point from comparisons amongst items is well studied. However, relatively little work exists on learning embeddings for new items based only on such comparisons. In this paper, we consider the problem of embedding a set of items using paired comparisons from a set of known users. Specifically, we present a novel convex lifted method of learning the embedding representation p <inf xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">1</inf> ,\u2026,p <inf xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">n</inf> \u2208 R <sup xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">n</sup> of n items given noisy responses of the form \"user u <inf xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">k</inf> prefers item p <inf xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">i</inf> to item p <inf xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">j</inf> \" for an arbitrary set of users {u <inf xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">k</inf> } in R <sup xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">d</sup> . We provide a range of simulations that validate the efficacy of our approach."}}
{"id": "ZVrFO_Uru36", "cdate": 1621630353918, "mdate": null, "content": {"title": "Deep inference of latent dynamics with spatio-temporal super-resolution using selective backpropagation through time", "abstract": "Modern neural interfaces allow access to the activity of up to a million neurons within brain circuits. However, bandwidth limits often create a trade-off between greater spatial sampling (more channels or pixels) and the temporal frequency of sampling. Here we demonstrate that it is possible to obtain spatio-temporal super-resolution in neuronal time series by exploiting relationships among neurons, embedded in latent low-dimensional population dynamics. Our novel neural network training strategy, selective backpropagation through time (SBTT), enables learning of deep generative models of latent dynamics from data in which the set of observed variables changes at each time step. The resulting models are able to infer activity for missing samples by combining observations with learned latent dynamics. We test SBTT applied to sequential autoencoders and demonstrate more efficient and higher-fidelity characterization of neural population dynamics in electrophysiological and calcium imaging data. In electrophysiology, SBTT enables accurate inference of neuronal population dynamics with lower interface bandwidths, providing an avenue to significant power savings for implanted neuroelectronic interfaces. In applications to two-photon calcium imaging, SBTT accurately uncovers high-frequency temporal structure underlying neural population activity, substantially outperforming the current state-of-the-art. Finally, we demonstrate that performance could be further improved by using limited, high-bandwidth sampling to pretrain dynamics models, and then using SBTT to adapt these models for sparsely-sampled data."}}
{"id": "9pt6F8w1Jgs", "cdate": 1621630353918, "mdate": null, "content": {"title": "Deep inference of latent dynamics with spatio-temporal super-resolution using selective backpropagation through time", "abstract": "Modern neural interfaces allow access to the activity of up to a million neurons within brain circuits. However, bandwidth limits often create a trade-off between greater spatial sampling (more channels or pixels) and the temporal frequency of sampling. Here we demonstrate that it is possible to obtain spatio-temporal super-resolution in neuronal time series by exploiting relationships among neurons, embedded in latent low-dimensional population dynamics. Our novel neural network training strategy, selective backpropagation through time (SBTT), enables learning of deep generative models of latent dynamics from data in which the set of observed variables changes at each time step. The resulting models are able to infer activity for missing samples by combining observations with learned latent dynamics. We test SBTT applied to sequential autoencoders and demonstrate more efficient and higher-fidelity characterization of neural population dynamics in electrophysiological and calcium imaging data. In electrophysiology, SBTT enables accurate inference of neuronal population dynamics with lower interface bandwidths, providing an avenue to significant power savings for implanted neuroelectronic interfaces. In applications to two-photon calcium imaging, SBTT accurately uncovers high-frequency temporal structure underlying neural population activity, substantially outperforming the current state-of-the-art. Finally, we demonstrate that performance could be further improved by using limited, high-bandwidth sampling to pretrain dynamics models, and then using SBTT to adapt these models for sparsely-sampled data."}}
{"id": "sleFdbJ6w5A", "cdate": 1609459200000, "mdate": 1683666170071, "content": {"title": "Deep inference of latent dynamics with spatio-temporal super-resolution using selective backpropagation through time", "abstract": "Modern neural interfaces allow access to the activity of up to a million neurons within brain circuits. However, bandwidth limits often create a trade-off between greater spatial sampling (more channels or pixels) and the temporal frequency of sampling. Here we demonstrate that it is possible to obtain spatio-temporal super-resolution in neuronal time series by exploiting relationships among neurons, embedded in latent low-dimensional population dynamics. Our novel neural network training strategy, selective backpropagation through time (SBTT), enables learning of deep generative models of latent dynamics from data in which the set of observed variables changes at each time step. The resulting models are able to infer activity for missing samples by combining observations with learned latent dynamics. We test SBTT applied to sequential autoencoders and demonstrate more efficient and higher-fidelity characterization of neural population dynamics in electrophysiological and calcium imaging data. In electrophysiology, SBTT enables accurate inference of neuronal population dynamics with lower interface bandwidths, providing an avenue to significant power savings for implanted neuroelectronic interfaces. In applications to two-photon calcium imaging, SBTT accurately uncovers high-frequency temporal structure underlying neural population activity, substantially outperforming the current state-of-the-art. Finally, we demonstrate that performance could be further improved by using limited, high-bandwidth sampling to pretrain dynamics models, and then using SBTT to adapt these models for sparsely-sampled data."}}
