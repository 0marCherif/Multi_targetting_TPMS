{"id": "Vtn19NjtrC", "cdate": 1609459200000, "mdate": 1632879092147, "content": {"title": "Label-Efficient Point Cloud Semantic Segmentation: An Active Learning Approach", "abstract": "Deep learning models are the state-of-the-art methods for semantic point cloud segmentation, the success of which relies on the availability of large-scale annotated datasets. However, it can be extremely time-consuming and prohibitively expensive to compile such datasets. In this work, we propose an active learning approach to maximize model performance given limited annotation budgets. We investigate the appropriate sample granularity for active selection under realistic annotation cost measurement (clicks), and demonstrate that super-point based selection allows for more efficient usage of the limited budget compared to point-level and instance-level selection. We further exploit local consistency constraints to boost the performance of the super-point based approach. We evaluate our methods on two benchmarking datasets (ShapeNet and S3DIS) and the results demonstrate that active learning is an effective strategy to address the high annotation costs in semantic point cloud segmentation."}}
{"id": "O1HQIrGDhBf", "cdate": 1609459200000, "mdate": 1632879091945, "content": {"title": "Revisiting Superpixels for Active Learning in Semantic Segmentation With Realistic Annotation Costs", "abstract": "State-of-the-art methods for semantic segmentation are based on deep neural networks that are known to be data-hungry. Region-based active learning has shown to be a promising method for reducing data annotation costs. A key design choice for region-based AL is whether to use regularly-shaped regions (e.g., rectangles) or irregularly-shaped region (e.g., superpixels). In this work, we address this question under realistic, click-based measurement of annotation costs. In particular, we revisit the use of superpixels and demonstrate that the inappropriate choice of cost measure (e.g., the percentage of labeled pixels), may cause the effectiveness of the superpixel-based approach to be under-estimated. We benchmark the superpixel-based approach against the traditional \"rectangle+polygon\"-based approach with annotation cost measured in clicks, and show that the former outperforms on both Cityscapes and PASCAL VOC. We further propose a class-balanced acquisition function to boost the performance of the superpixel-based approach and demonstrate its effectiveness on the evaluation datasets. Our results strongly argue for the use of superpixel-based AL for semantic segmentation and highlight the importance of using realistic annotation costs in evaluating such methods."}}
{"id": "BO_-fugSo19", "cdate": 1609459200000, "mdate": 1645068393580, "content": {"title": "Exploring Spatial Diversity for Region-Based Active Learning", "abstract": "State-of-the-art methods for semantic segmentation are based on deep neural networks trained on large-scale labeled datasets. Acquiring such datasets would incur large annotation costs, especially for dense pixel-level prediction tasks like semantic segmentation. We consider region-based active learning as a strategy to reduce annotation costs while maintaining high performance. In this setting, batches of informative image regions instead of entire images are selected for labeling. Importantly, we propose that enforcing local spatial diversity is beneficial for active learning in this case, and to incorporate spatial diversity along with the traditional active selection criterion, e.g., data sample uncertainty, in a unified optimization framework for region-based active learning. We apply this framework to the Cityscapes and PASCAL VOC datasets and demonstrate that the inclusion of spatial diversity effectively improves the performance of uncertainty-based and feature diversity-based active learning methods. Our framework achieves 95% performance of fully supervised methods with only 5 \u2013 9% of the labeled pixels, outperforming all state-of-the-art region-based active learning methods for semantic segmentation."}}
{"id": "NuRfJzf1u5O", "cdate": 1546300800000, "mdate": null, "content": {"title": "TEA-DNN: the Quest for Time-Energy-Accuracy Co-optimized Deep Neural Networks", "abstract": "Embedded deep learning platforms have witnessed two simultaneous improvements. First, the accuracy of convolutional neural networks (CNNs) has been significantly improved through the use of automated neural-architecture search (NAS) algorithms to determine CNN structure. Second, there has been increasing interest in developing hardware accelerators for CNNs that provide improved inference performance and energy consumption compared to GPUs. Such embedded deep learning platforms differ in the amount of compute resources and memory-access bandwidth, which would affect performance and energy consumption of CNNs. It is therefore critical to consider the available hardware resources in the network architecture search. To this end, we introduce TEA-DNN, a NAS algorithm targeting multi-objective optimization of execution time, energy consumption, and classification accuracy of CNN workloads on embedded architectures. TEA-DNN leverages energy and execution time measurements on embedded hardware when exploring the Pareto-optimal curves across accuracy, execution time, and energy consumption and does not require additional effort to model the underlying hardware. We apply TEA-DNN for image classification on actual embedded platforms (NVIDIA Jetson TX2 and Intel Movidius Neural Compute Stick). We highlight the Pareto-optimal operating points that emphasize the necessity to explicitly consider hardware characteristics in the search process. To the best of our knowledge, this is the most comprehensive study of Pareto-optimal models across a range of hardware platforms using actual measurements on hardware to obtain objective values."}}
{"id": "HoIw17meuaB", "cdate": 1546300800000, "mdate": null, "content": {"title": "MaxpoolNMS: Getting Rid of NMS Bottlenecks in Two-Stage Object Detectors.", "abstract": "Modern convolutional object detectors have improved the detection accuracy significantly, which in turn inspired the development of dedicated hardware accelerators to achieve real-time performance by exploiting inherent parallelism in the algorithm. Non-maximum suppression (NMS) is an indispensable operation in object detection. In stark contrast to most operations, the commonly-adopted GreedyNMS algorithm does not foster parallelism, which can be a major performance bottleneck. In this paper, we introduce MaxpoolNMS, a parallelizable alternative to the NMS algorithm, which is based on max-pooling classification score maps. By employing a novel multi-scale multi-channel max-pooling strategy, our method is 20x faster than GreedyNMS while simultaneously achieves comparable accuracy, when quantified across various benchmarking datasets, i.e., MS COCO, KITTI and PASCAL VOC. Furthermore, our method is better suited for hardware-based acceleration than GreedyNMS."}}
{"id": "1WXgh1MJTb", "cdate": 1546300800000, "mdate": 1632879091950, "content": {"title": "MaxpoolNMS: Getting Rid of NMS Bottlenecks in Two-Stage Object Detectors", "abstract": "Modern convolutional object detectors have improved the detection accuracy significantly, which in turn inspired the development of dedicated hardware accelerators to achieve real-time performance by exploiting inherent parallelism in the algorithm. Non-maximum suppression (NMS) is an indispensable operation in object detection. In stark contrast to most operations, the commonly-adopted GreedyNMS algorithm does not foster parallelism, which can be a major performance bottleneck. In this paper, we introduce MaxpoolNMS, a parallelizable alternative to the NMS algorithm, which is based on max-pooling classification score maps. By employing a novel multi-scale multi-channel max-pooling strategy, our method is 20x faster than GreedyNMS while simultaneously achieves comparable accuracy, when quantified across various benchmarking datasets, i.e., MS COCO, KITTI and PASCAL VOC. Furthermore, our method is better suited for hardware-based acceleration than GreedyNMS."}}
{"id": "rnUSpj1xv4", "cdate": 1514764800000, "mdate": null, "content": {"title": "TEA-DNN: the Quest for Time-Energy-Accuracy Co-optimized Deep Neural Networks", "abstract": "Embedded deep learning platforms have witnessed two simultaneous improvements. First, the accuracy of convolutional neural networks (CNNs) has been significantly improved through the use of automated neural-architecture search (NAS) algorithms to determine CNN structure. Second, there has been increasing interest in developing hardware accelerators for CNNs that provide improved inference performance and energy consumption compared to GPUs. Such embedded deep learning platforms differ in the amount of compute resources and memory-access bandwidth, which would affect performance and energy consumption of CNNs. It is therefore critical to consider the available hardware resources in the network architecture search. To this end, we introduce TEA-DNN, a NAS algorithm targeting multi-objective optimization of execution time, energy consumption, and classification accuracy of CNN workloads on embedded architectures. TEA-DNN leverages energy and execution time measurements on embedded hardware when exploring the Pareto-optimal curves across accuracy, execution time, and energy consumption and does not require additional effort to model the underlying hardware. We apply TEA-DNN for image classification on actual embedded platforms (NVIDIA Jetson TX2 and Intel Movidius Neural Compute Stick). We highlight the Pareto-optimal operating points that emphasize the necessity to explicitly consider hardware characteristics in the search process. To the best of our knowledge, this is the most comprehensive study of Pareto-optimal models across a range of hardware platforms using actual measurements on hardware to obtain objective values."}}
{"id": "r_OVzOlSi1q", "cdate": 1483228800000, "mdate": 1645068393780, "content": {"title": "Anomaly detection in thermal images using deep neural networks", "abstract": "Infrared thermography has become an effective tool in electrical preventive maintenance program due to its high precision and the capability of performing non-contact diagnostic. Anomalies in a thermal image is typically detected by comparing the temperatures of the equipment with reference temperatures. Manual detection is time-consuming and unreliable, making it unable to meet the excessive demand for condition monitoring in industrial applications. In this paper, we propose an automatic method to detect thermal anomalies based on deep neural networks (DNNs). The DNN model is trained to learn the statistical regularities of normal thermal images, and anomalies are detected based on pixel-wise comparison between the learned reference temperatures and the actual temperatures. We test our method on a variety of electrical equipment and the experimental results demonstrated the effectiveness of the proposed method."}}
{"id": "BCgZ-OlHikc", "cdate": 1483228800000, "mdate": 1645068393379, "content": {"title": "A two-level clustering approach for multidimensional transfer function specification in volume visualization", "abstract": "Multidimensional transfer functions can perform more sophisticated classification of volumetric objects compared to 1-D transfer functions. However, visualizing and manipulating the transfer function space is non-intuitive when its dimension goes beyond 3-D, thus making user interaction difficult. In this paper, we propose to address the multidimensional transfer function design problem by taking a two-level clustering approach, where the first-level clustering by the self-organizing map (SOM) projects high-dimensional feature data to a 2-D topology preserving map, and the second-level clustering on the SOM neurons reduces the design freedom from a large number of SOM neurons to a manageable number of clusters. Based on the two-level clustering results, we propose a novel volume exploration scheme that provides top-down navigation to users exploring the volume. Guided by an informative volume overview, interesting structures in the volume are discovered interactively by the user selecting clusters to visualize and modifying the clustering results when necessary. Our interface keeps track of each interesting structure discovered, which not only enables users to inspect individual structures closely, but also allows them to compose the final visualization by fusing the structures deemed important."}}
{"id": "SrSWGOlBoyc", "cdate": 1420070400000, "mdate": 1645068393579, "content": {"title": "Rule-Enhanced Transfer Function Generation for Medical Volume Visualization", "abstract": "In volume visualization, transfer functions are used to classify the volumetric data and assign optical properties to the voxels. In general, transfer functions are generated in a transfer function s..."}}
