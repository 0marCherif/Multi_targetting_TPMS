{"id": "HfuFAY9e5oS", "cdate": 1683672077696, "mdate": 1683672077696, "content": {"title": "Mask wearing in community settings reduces SARS-CoV-2 transmission", "abstract": "The effectiveness of mask wearing at controlling severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) transmission has been unclear. While masks are known to substantially reduce disease transmission in healthcare settings [D. K. Chu et al., Lancet 395, 1973\u20131987 (2020); J. Howard et al., Proc. Natl. Acad. Sci. U.S.A. 118, e2014564118 (2021); Y. Cheng et al., Science eabg6296 (2021)], studies in community settings report inconsistent results [H. M. Ollila et al., medRxiv (2020); J. Brainard et al., Eurosurveillance 25, 2000725 (2020); T. Jefferson et al., Cochrane Database Syst. Rev. 11, CD006207 (2020)]. Most such studies focus on how masks impact transmission, by analyzing how effective government mask mandates are. However, we find that widespread voluntary mask wearing, and other data limitations, make mandate effectiveness a poor proxy for mask-wearing effectiveness. We directly analyze the effect of mask wearing on SARS-CoV-2 transmission, drawing on several datasets covering 92 regions on six continents, including the largest survey of wearing behavior (\ud835\udc5b=\n 20 million) [F. Kreuter et al., https://gisumd.github.io/COVID-19-API-Documentation (2020)]. Using a Bayesian hierarchical model, we estimate the effect of mask wearing on transmission, by linking reported wearing levels to reported cases in each region, while adjusting for mobility and nonpharmaceutical interventions (NPIs), such as bans on large gatherings. Our estimates imply that the mean observed level of mask wearing corresponds to a 19% decrease in the reproduction number R. We also assess the robustness of our results in 60 tests spanning 20 sensitivity analyses. In light of these results, policy makers can effectively reduce transmission by intervening to increase mask wearing."}}
{"id": "2JTsK7hlu0p", "cdate": 1683671864393, "mdate": 1683671864393, "content": {"title": "Understanding the effectiveness of government interventions against the resurgence of COVID-19 in Europe", "abstract": "European governments use non-pharmaceutical interventions (NPIs) to control resurging waves of COVID-19. However, they only have outdated estimates for how effective individual NPIs were in the first wave. We estimate the effectiveness of 17 NPIs in Europe\u2019s second wave from subnational case and death data by introducing a flexible hierarchical Bayesian transmission model and collecting the largest dataset of NPI implementation dates across Europe. Business closures, educational institution closures, and gathering bans reduced transmission, but reduced it less than they did in the first wave. This difference is likely due to organisational safety measures and individual protective behaviours\u2014such as distancing\u2014which made various areas of public life safer and thereby reduced the effect of closing them. Specifically, we find smaller effects for closing educational institutions, suggesting that stringent safety measures made schools safer compared to the first wave. Second-wave estimates outperform previous estimates at predicting transmission in Europe\u2019s third wave."}}
{"id": "L_MkT-TgTS", "cdate": 1640995200000, "mdate": 1681913045825, "content": {"title": "Prioritized Training on Points that are Learnable, Worth Learning, and not yet Learnt", "abstract": "Training on web-scale data can take months. But much computation and time is wasted on redundant and noisy points that are already learnt or not learnable. To accelerate training, we introduce Redu..."}}
{"id": "Y0cGpgUhSvp", "cdate": 1632875496469, "mdate": null, "content": {"title": "Prioritized training on points that are learnable, worth learning, and not yet learned", "abstract": "We introduce reducible held-out loss selection (RHOLS), a technique for faster model training which selects a sequence of training points that are \u201cjust right\u201d. We propose a tractable information-theoretic acquisition function\u2014the reducible heldout loss\u2014to efficiently choose training points that maximize information about a holdout set. We show that the \u201chard\u201d (e.g. high loss) points usually selected in the optimization literature are typically noisy, leading to deterioration on real-world datasets. At the same time, \u201ceasy\u201d (e.g. low noise) samples, often prioritized for curriculum learning, confer less information. In contrast, RHOLS chooses points that are \u201cjust right\u201d and trains in fewer steps than the above approaches."}}
{"id": "lbX0Id32a-G", "cdate": 1622361726140, "mdate": null, "content": {"title": "Quantifying Ignorance in Individual-Level Causal-Effect Estimates under Hidden Confounding", "abstract": "We study the problem of learning conditional average treatment effects (CATE) from high-dimensional, observational data with unobserved confounders. Unobserved confounders introduce ignorance -- a level of unidentifiability -- about an individual's response to treatment by inducing bias in CATE estimates. We present a new parametric interval estimator suited for high-dimensional data, that estimates a range of possible CATE values when given a predefined bound on the level of hidden confounding. Further, previous interval estimators do not account for ignorance about the CATE stemming from samples that may be underrepresented in the original study, or samples that violate the overlap assumption. Our novel interval estimator also incorporates model uncertainty so that practitioners can be made aware of out-of-distribution data. We prove that our estimator converges to tight bounds on CATE when there may be unobserved confounding, and assess it using semi-synthetic, high-dimensional datasets."}}
{"id": "ZUjQwHTdvJs", "cdate": 1622361539491, "mdate": null, "content": {"title": "Identifying Causal-Effect Inference Failure with Uncertainty-Aware Models", "abstract": "Recommending the best course of action for an individual is a major application of individual-level causal effect estimation. This application is often needed in safety-critical domains such as healthcare, where estimating and communicating uncertainty to decision-makers is crucial. We introduce a practical approach for integrating uncertainty estimation into a class of state-of-the-art neural network methods used for individual-level causal estimates. We show that our methods enable us to deal gracefully with situations of\" no-overlap\", common in high-dimensional data, where standard applications of causal effect approaches fail. Further, our methods allow us to handle covariate shift, where the train and test distributions differ, common when systems are deployed in practice. We show that when such a covariate shift occurs, correctly modeling uncertainty can keep us from giving overconfident and potentially harmful recommendations. We demonstrate our methodology with a range of state-of-the-art models. Under both covariate shift and lack of overlap, our uncertainty-equipped methods can alert decision makers when predictions are not to be trusted while outperforming standard methods that use the propensity score to identify lack of overlap."}}
{"id": "r14dlFWd-S", "cdate": 1514764800000, "mdate": null, "content": {"title": "Occam's razor is insufficient to infer the preferences of irrational agents", "abstract": "Inverse reinforcement learning (IRL) attempts to infer human rewards or preferences from observed behavior. Since human planning systematically deviates from rationality, several approaches have been tried to account for specific human shortcomings. However, the general problem of inferring the reward function of an agent of unknown rationality has received little attention. Unlike the well-known ambiguity problems in IRL, this one is practically relevant but cannot be resolved by observing the agent's policy in enough environments. This paper shows (1) that a No Free Lunch result implies it is impossible to uniquely decompose a policy into a planning algorithm and reward function, and (2) that even with a reasonable simplicity prior/Occam's razor on the set of decompositions, we cannot distinguish between the true decomposition and others that lead to high regret. To address this, we need simple `normative' assumptions, which cannot be deduced exclusively from observations."}}
{"id": "asuM_H-KS5f", "cdate": 1514764800000, "mdate": null, "content": {"title": "Active Inverse Reward Design", "abstract": "Designers of AI agents often iterate on the reward function in a trial-and-error process until they get the desired behavior, but this only guarantees good behavior in the training environment. We propose structuring this process as a series of queries asking the user to compare between different reward functions. Thus we can actively select queries for maximum informativeness about the true reward. In contrast to approaches asking the designer for optimal behavior, this allows us to gather additional information by eliciting preferences between suboptimal behaviors. After each query, we need to update the posterior over the true reward function from observing the proxy reward function chosen by the designer. The recently proposed Inverse Reward Design (IRD) enables this. Our approach substantially outperforms IRD in test environments. In particular, it can query the designer about interpretable, linear reward functions and still infer non-linear ones."}}
{"id": "KbB96KTOgp", "cdate": 1483228800000, "mdate": 1683891148669, "content": {"title": "Impossibility of deducing preferences and rationality from human policy", "abstract": "Inverse reinforcement learning (IRL) attempts to infer human rewards or preferences from observed behavior. Since human planning systematically deviates from rationality, several approaches have been tried to account for specific human shortcomings. However, the general problem of inferring the reward function of an agent of unknown rationality has received little attention. Unlike the well-known ambiguity problems in IRL, this one is practically relevant but cannot be resolved by observing the agent's policy in enough environments. This paper shows (1) that a No Free Lunch result implies it is impossible to uniquely decompose a policy into a planning algorithm and reward function, and (2) that even with a reasonable simplicity prior/Occam's razor on the set of decompositions, we cannot distinguish between the true decomposition and others that lead to high regret. To address this, we need simple `normative' assumptions, which cannot be deduced exclusively from observations."}}
