{"id": "7_QHeKujaj", "cdate": 1669213093358, "mdate": null, "content": {"title": "Spurious Features in Continual Learning", "abstract": "Continual Learning (CL) is the research field addressing training settings where the data distribution is not static. One of the core problems CL addresses is learning without forgetting.\nTo solve problems, continual learning algorithms need to learn robust and stable representations based only on a subset of the data. Those representations are necessarily biased and should be revisited when new data becomes available.\nThis paper studies spurious features' influence on continual learning algorithms.\nWe show that in continual learning, algorithms have to deal with local spurious features that correlate well with labels within a task only but which are not good representations for the concept to learn. \nOne of the big challenges of continual learning algorithms is to discover causal relationships between features and labels under distribution shifts."}}
{"id": "LoOd40EaGA8", "cdate": 1663850523039, "mdate": null, "content": {"title": "Challenging Common Assumptions about Catastrophic Forgetting", "abstract": "Standard gradient descent algorithms applied to sequences of tasks are known to induce catastrophic forgetting in deep neural networks. When trained on a new task, the model's parameters are updated in a way that degrades performance on past tasks. \nThis article explores continual learning (CL) on long sequences of tasks sampled from a finite environment.\n\\textbf{We show that in this setting, learning with stochastic gradient descent (SGD) results in knowledge retention and accumulation without specific memorization mechanisms.} This is in contrast to the current notion of forgetting from the CL literature, which shows that training on new tasks with such an approach results in forgetting previous tasks, especially in class-incremental settings.\nTo study this phenomenon, we propose an experimental framework, \\Scole{} (Scaling Continual Learning), which allows to generate arbitrarily long task sequences. Our experiments show that the previous results obtained on relatively short task sequences may not reveal certain phenomena that emerge in longer ones."}}
{"id": "Jp7NLnL3n_1", "cdate": 1663850354281, "mdate": null, "content": {"title": "Spurious Features in Continual Learning", "abstract": "Continual Learning (CL) is the research field addressing learning without forgetting when the data distribution is not static. \nThis paper studies spurious features' influence on continual learning algorithms.\nWe show that continual learning algorithms solve tasks by selecting features that are not generalizable. \nOur experiments highlight that continual learning algorithms face two related problems: (1) spurious features (SP) and (2) local spurious features (LSP). The first one is due to a covariate shift between training and testing data, while the second is due to the limited access to data at each training step.\nWe study (1) through a consistent set of continual learning experiments varying spurious correlation amount and data distribution support.\nWe show that (2) is a major cause of performance decrease in continual learning along with catastrophic forgetting. \nThis paper presents a different way of understanding performance decrease in continual learning by highlighting the influence of (local) spurious features in algorithms capabilities."}}
{"id": "R2AN-rz4j_X", "cdate": 1632875623131, "mdate": null, "content": {"title": "Continual Learning in Deep Networks: an Analysis of the Last Layer", "abstract": "We study how different output layers in a  deep neural network learn and forget in continual learning settings. The following three  factors  can affect catastrophic forgetting in the output layer: (1) weights modifications, (2) interference, and (3) projection drift. In this paper, our goal is to provide more insights into how changing the output layers may address (1) and (2).  Some potential solutions to those issues are proposed and evaluated here in  several continual learning scenarios. We show that the best-performing type of the output layer  depends on the data distribution drifts and/or the amount of data available. In particular, in some cases where a standard linear layer would fail, it turns out that changing  parameterization is sufficient in order to  achieve a significantly better performance, whithout introducing a continual-learning algorithm and instead using the standard SGD to train a model.  Our analysis and results  shed light on the dynamics of the output layer in continual learning scenarios,  and suggest a way of  selecting the best type of  output layer for a given scenario."}}
{"id": "xWRX16GCugt", "cdate": 1632875549219, "mdate": null, "content": {"title": "Sequoia: A Software Framework to Unify Continual Learning Research", "abstract": "The field of Continual Learning (CL) seeks to develop algorithms that accumulate knowledge and skills over time through interaction with non-stationary environments. In practice, a plethora of evaluation procedures (settings) and algorithmic solutions (methods) exist, each with their own potentially disjoint set of assumptions. This variety makes measuring progress in CL difficult. We propose a taxonomy of settings, where each setting is described as a set of assumptions. A tree-shaped hierarchy emerges from this view, where more general settings become the parents of those with more restrictive assumptions. This makes it possible to use inheritance to share and reuse research, as developing a method for a given setting also makes it directly applicable onto any of its children. We instantiate this idea as a publicly available software framework called Sequoia, which features a wide variety of settings from both the Continual Supervised Learning (CSL) and Continual Reinforcement Learning (CRL) domains. Sequoia also includes a growing suite of methods which are easy to extend and customize, in addition to more specialized methods from external libraries. We hope that this new paradigm and its first implementation can help unify and accelerate research in CL. You can help us grow the tree by visiting (this GitHub URL)."}}
{"id": "CxGPf2BPVA", "cdate": 1601308171205, "mdate": null, "content": {"title": "Regularization Shortcomings for Continual Learning", "abstract": "In most machine learning algorithms, training data is assumed to be independent and identically distributed (iid).  \nWhen it is not the case, the performances of the algorithms are challenged, leading to the famous phenomenon of \\textit{catastrophic forgetting}. Algorithms dealing with it are gathered in the \\textit{Continual Learning} research field. In this paper, we study the \\textit{regularization} based approaches to continual learning and show that those approaches can not learn to discriminate classes from different tasks in an elemental continual benchmark, the class-incremental setting.\nWe make theoretical reasoning to prove this shortcoming and illustrate it with experiments.\nMoreover, we show that it can have some important consequences on multi-tasks reinforcement learning or in pre-trained models used for continual learning.\nWe believe this paper to be the first to propose a theoretical description of regularization shortcomings for continual learning. "}}
{"id": "BklR5pHhjV", "cdate": 1557056918406, "mdate": null, "content": {"title": "Continual Reinforcement Learning deployed in Real-life using Policy Distillation and Sim2Real Transfer", "abstract": "We focus on the problem of teaching a robot to solve tasks presented sequentially, i.e., in a continual learning scenario. The robot should be able to solve all tasks it has encountered, without forgetting past tasks. We provide preliminary work on applying Reinforcement Learning to such setting, on navigation tasks for a 3 wheel omni-directional robot. Our approach takes advantage of state representation learning and policy distillation. Policies are trained using learned features as input, rather than raw observations, allowing for better sample efficiency. Policy distillation is used to combine different policies into a single policy that solves all encountered tasks."}}
{"id": "S1eFtj0cKQ", "cdate": 1538087808716, "mdate": null, "content": {"title": "Generative Models from the perspective of Continual Learning", "abstract": "Which generative model is the most suitable for Continual Learning? This paper aims at evaluating and comparing generative models on disjoint sequential image generation tasks. We investigate how several models learn and forget, considering various strategies: rehearsal, regularization, generative replay and fine-tuning. We used two quantitative metrics to estimate the generation quality and memory ability. We experiment with sequential tasks on three commonly used benchmarks for Continual Learning (MNIST, Fashion MNIST and CIFAR10). We found that among all models, the original GAN performs best and among Continual Learning strategies, generative replay outperforms all other methods. Even if we found satisfactory combinations on MNIST and Fashion MNIST, training generative models sequentially on CIFAR10 is particularly instable, and remains a challenge."}}
{"id": "Hkl-di09FQ", "cdate": 1538087784580, "mdate": null, "content": {"title": "Decoupling feature extraction from policy learning: assessing benefits of state representation learning in goal based robotics", "abstract": "Scaling end-to-end reinforcement learning to control real robots from vision presents a series of challenges, in particular in terms of sample efficiency. Against end-to-end learning, state representation learning can help learn a compact, efficient and relevant representation of states that speeds up policy learning, reducing the number of samples needed, and that is easier to interpret. We evaluate several state representation learning methods on goal based robotics tasks and propose a new unsupervised model that stacks representations and combines strengths of several of these approaches. This method encodes all the relevant features, performs on par or better than end-to-end learning, and is robust to hyper-parameters change."}}
{"id": "HJ1HFlZAb", "cdate": 1518730171421, "mdate": null, "content": {"title": "Evaluation of generative networks through their data augmentation capacity", "abstract": "Generative networks are known to be difficult to assess. Recent works on generative models, especially on generative adversarial networks, produce nice samples of varied categories of images. But the validation of their quality is highly dependent on the method used. A good generator should generate data which contain meaningful and varied information and that fit the distribution of a dataset. This paper presents a new method to assess a generator. Our approach is based on training a classifier with a mixture of real and generated samples. We train a generative model over a labeled training set, then we use this generative model to sample new data points that we mix with the original training data. This mixture of real and generated data is thus used to train a classifier which is afterwards tested on a given labeled test dataset. We compare this result with the score of the same classifier trained on the real training data mixed with noise. By computing the classifier's accuracy with different ratios of samples from both distributions (real and generated) we are able to estimate if the generator successfully fits and is able to generalize the distribution of the dataset. Our experiments compare the result of different generators from the VAE and GAN framework on MNIST and fashion MNIST dataset."}}
