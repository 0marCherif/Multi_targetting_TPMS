{"id": "f2OZCsJM-L", "cdate": 1640995200000, "mdate": 1681762371147, "content": {"title": "ScAN: Suicide Attempt and Ideation Events Dataset", "abstract": "Bhanu Pratap Singh Rawat, Samuel Kovaly, Hong Yu, Wilfred Pigeon. Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. 2022."}}
{"id": "Kw2ZlJDDLrL", "cdate": 1640995200000, "mdate": 1681762371146, "content": {"title": "An Investigation of the Representation of Social Determinants of Health in the UMLS", "abstract": ""}}
{"id": "IixybdTUkU", "cdate": 1640995200000, "mdate": 1681762371148, "content": {"title": "Parameter Efficient Transfer Learning for Suicide Attempt and Ideation Detection", "abstract": ""}}
{"id": "93qcbU9nUi", "cdate": 1640995200000, "mdate": 1681762371147, "content": {"title": "Knowledge Injected Prompt Based Fine-tuning for Multi-label Few-shot ICD Coding", "abstract": ""}}
{"id": "_G9zzcPhLk7", "cdate": 1609459200000, "mdate": 1623593607484, "content": {"title": "Membership Inference Attack Susceptibility of Clinical Language Models", "abstract": "Deep Neural Network (DNN) models have been shown to have high empirical privacy leakages. Clinical language models (CLMs) trained on clinical data have been used to improve performance in biomedical natural language processing tasks. In this work, we investigate the risks of training-data leakage through white-box or black-box access to CLMs. We design and employ membership inference attacks to estimate the empirical privacy leaks for model architectures like BERT and GPT2. We show that membership inference attacks on CLMs lead to non-trivial privacy leakages of up to 7%. Our results show that smaller models have lower empirical privacy leakages than larger ones, and masked LMs have lower leakages than auto-regressive LMs. We further show that differentially private CLMs can have improved model utility on clinical domain while ensuring low empirical privacy leakage. Lastly, we also study the effects of group-level membership inference and disease rarity on CLM privacy leakages."}}
{"id": "wbSxuGWZa3Q", "cdate": 1577836800000, "mdate": null, "content": {"title": "Improved Pretraining for Domain-specific Contextual Embedding Models", "abstract": "Pre-trained language models (LM) such as BERT, DistilBERT, and RoBERTa can be tuned for different domains (domain-tuning) by continuing the pre-training phase on a new target domain corpus. This simple domain tuning (SDT) technique has been widely used to create domain-tuned models such as BioBERT, SciBERT and ClinicalBERT. However, during the pretraining phase on the target domain, the LM models may catastrophically forget the patterns learned from their source domain. In this work, we study the effects of catastrophic forgetting on domain-tuned LM models and investigate methods that mitigate its negative effects. We propose continual learning (CL) based alternatives for SDT, that aim to reduce catastrophic forgetting. We show that these methods may increase the performance of LM models on downstream target domain tasks. Additionally, we also show that constraining the LM model from forgetting the source domain leads to downstream task models that are more robust to domain shifts. We analyze the computational cost of using our proposed CL methods and provide recommendations for computationally lightweight and effective CL domain-tuning procedures."}}
{"id": "k-XTTAPbr2", "cdate": 1577836800000, "mdate": 1676412716248, "content": {"title": "Entity-Enriched Neural Models for Clinical Question Answering", "abstract": "We explore state-of-the-art neural models for question answering on electronic medical records and improve their ability to generalize better on previously unseen (paraphrased) questions at test time. We enable this by learning to predict logical forms as an auxiliary task along with the main task of answer span detection. The predicted logical forms also serve as a rationale for the answer. Further, we also incorporate medical entity information in these models via the ERNIE architecture. We train our models on the large-scale emrQA dataset and observe that our multi-task entity-enriched models generalize to paraphrased questions ~5% better than the baseline BERT model."}}
{"id": "fULL8kCjoK", "cdate": 1577836800000, "mdate": 1623593615464, "content": {"title": "Inferring ADR causality by predicting the Naranjo Score from Clinical Notes", "abstract": ""}}
{"id": "_57iQo5J0jT", "cdate": 1577836800000, "mdate": 1623593607484, "content": {"title": "Conversational Machine Comprehension: a Literature Review", "abstract": "Somil Gupta, Bhanu Pratap Singh Rawat, Hong Yu. Proceedings of the 28th International Conference on Computational Linguistics. 2020."}}
{"id": "EngqGfiGSjO", "cdate": 1577836800000, "mdate": 1623593607478, "content": {"title": "Entity-Enriched Neural Models for Clinical Question Answering", "abstract": "Bhanu Pratap Singh Rawat, Wei-Hung Weng, So Yeon Min, Preethi Raghavan, Peter Szolovits. Proceedings of the 19th SIGBioMed Workshop on Biomedical Language Processing. 2020."}}
