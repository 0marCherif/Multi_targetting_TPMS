{"id": "_Bb-CdkbUM", "cdate": 1672531200000, "mdate": 1693679077882, "content": {"title": "TVSPrune - Pruning Non-discriminative filters via Total Variation separability of intermediate representations without fine tuning", "abstract": ""}}
{"id": "Tr6n9QXmAPR", "cdate": 1672531200000, "mdate": 1693679077882, "content": {"title": "DFPC: Data flow driven pruning of coupled channels without data", "abstract": ""}}
{"id": "mhnHqRqcjYU", "cdate": 1663850588877, "mdate": null, "content": {"title": "DFPC: Data flow driven pruning of coupled channels without data.", "abstract": "Modern, multi-branched neural network architectures often possess complex interconnections between layers, which we call coupled channels (CCs). Structured pruning of CCs in these multi-branch networks is an under-researched problem, as most existing works are typically designed for pruning single-branch models like VGG-nets. While these methods yield accurate subnetworks, the improvements in inference times when applied to multi-branch networks are comparatively modest, as these methods do not prune CCs, which we observe contribute significantly to inference time. For instance, layers with CCs as input or output take more than 66% of the inference time in ResNet-50. Moreover, pruning in the data-free regime, where data is not used for pruning, is gaining traction owing to privacy concerns and computational costs associated with fine-tuning. Motivated by this, we study the problem of pruning CCs in the data-free regime. To facilitate the development of algorithms to prune CCs, we define Data Flow Couplings (DFCs) to enumerate the layers that constitute coupled connections and the associated transformation. Additionally, saliencies for pruning CCs cannot be gauged in isolation, as there may be discrepancies among the layerwise importance of CCs using conventional scoring strategies. This necessitates finding grouped saliencies to gauge the importance of all corresponding coupled elements in a network. We thus propose the Backwards Graph-based Saliency Computation (BGSC) algorithm, a data-free method that computes saliencies by estimating an upper bound to the reconstruction error of intermediate layers; we call this pruning strategy Data Flow driven Pruning of Coupled channels (DFPC). Finally, we show the efficacy of DFPC for models trained on standard datasets. Since we pruned coupled channels, we achieve up to 1.66x improvements in inference time for ResNet-101 trained on CIFAR-10 with a 5% accuracy drop without fine-tuning. With access to the ImageNet training set, we achieve significant improvements over the data-free method and see an improvement of at least 47.1% in speedup for a 2.3% accuracy drop for ResNet-50 against our baselines."}}
{"id": "sZI1Oj9KBKy", "cdate": 1663850588630, "mdate": null, "content": {"title": "TVSPrune - Pruning Non-discriminative filters via Total Variation separability of intermediate representations without fine tuning", "abstract": "Achieving structured, data-free sparsity of deep neural networks (DNNs) remains an open area of research.  In this work, we address the challenge of pruning filters without access to the original training set or loss function. We propose the discriminative filters hypothesis, that well-trained models possess discriminative filters, and any non-discriminative filters can be pruned without impacting the predictive performance of the classifier. Based on this hypothesis, we propose a new paradigm for pruning neural networks: distributional pruning, wherein we only require access to the distributions that generated the original datasets. Our approach to solving the problem of formalising and quantifying the discriminating ability of filters is through the total variation (TV) distance between the class-conditional distributions of the filter outputs. We present empirical results that, using this definition of discriminability, support our hypothesis on a variety of datasets and architectures. Next, we define the LDIFF score, a heuristic to quantify the extent to which a layer possesses a mixture of discriminative and non-discriminative filters. We empirically demonstrate that the LDIFF score is indicative of the performance of random pruning for a given layer, and thereby indicates the extent to which a layer may be pruned. Our main contribution is a novel one-shot pruning algorithm, called TVSPrune, that identifies non-discriminative filters for pruning. We extend this algorithm to IterTVSPrune, wherein we iteratively apply TVSPrune, thereby enabling us to achieve greater sparsity. Last, we demonstrate the efficacy of the TVSPrune on a variety of datasets, and show that in some cases, we can prune up to 60% of parameters with only a 2% loss of accuracy without any fine-tuning of the model, beating the nearest baseline by almost 10%."}}
{"id": "lggq18HNeu", "cdate": 1546300800000, "mdate": null, "content": {"title": "Optimizing DNN Architectures for High Speed Autonomous Navigation in GPS Denied Environments on Edge Devices", "abstract": "We address the challenge of high speed autonomous navigation of micro aerial vehicles (MAVs) using DNNs in GPS-denied environments with limited computational resources; specifically, we use the ODROID XU4 and the Raspberry Pi 3. The high computation costs of using DNNs for inference, particularly in the absence of powerful GPUs, necessitates negotiating a tradeoff between accuracy and inference. We address this tradeoff by employing sparsified neural networks. To obtain such architectures, we propose a novel algorithm to find sparse \u201csub networks\u201d of existing pre trained models. Contrary to existing pruning-only strategies, our proposal includes a novel exploration step that efficiently searches for a different, but identically sparse, architecture with better generalization abilities. We derive learning theoretic bounds that reinforce our empirical findings that the optimized network achieves comparable generalization to the original network. We show that using our algorithm it is possible to discover models which, on average, have upto 19x fewer parameters than those obtained using existing state of the art pruning methods on autonomous navigation datasets, and achieve upto 6x improvements on inference time compared to existing state of the art shallow models on the ODROID XU4 and Raspberry Pi 3. Last, we demonstrate that our sparsified models can complete autonomous navigation missions with speeds upto 4\u00a0m/s using the ODROID XU4, which existing state of the art methods fail to do."}}
{"id": "XqcHxHgfLAu", "cdate": 1388534400000, "mdate": null, "content": {"title": "Constructing piecewise-polynomial lyapunov functions for local stability of nonlinear systems using Handelman's theorem", "abstract": "In this paper, we propose a new convex approach to stability analysis of nonlinear systems with polynomial vector fields. First, we consider an arbitrary convex polytope that contains the equilibrium in its interior. Then, we decompose the polytope into several convex sub-polytopes with a common vertex at the equilibrium. Then, by using Handelman's theorem, we derive a new set of affine feasibility conditions -solvable by linear programming- on each sub-polytope. Any solution to this feasibility problem yields a piecewise polynomial Lyapunov function on the entire polytope. This is the first result which utilizes Handelman's theorem and decomposition to construct piecewise polynomial Lyapunov functions on arbitrary polytopes. In a computational complexity analysis, we show that for large number of states and large degrees of the Lyapunov function, the complexity of the proposed feasibility problem is less than the complexity of certain semi-definite programs associated with alternative methods based on Sum-of-Squares or Polya's theorem. Using different types of convex polytopes, we assess the accuracy of the algorithm in estimating the region of attraction of the equilibrium point of the reverse-time Van Der Pol oscillator."}}
{"id": "OxGvkM2n2VR", "cdate": 1356998400000, "mdate": null, "content": {"title": "A sum-of-squares approach to the analysis of Zeno stability in polynomial hybrid systems", "abstract": "Hybrid dynamical systems can exhibit many unique phenomena, such as Zeno behavior. Zeno behavior is the occurrence of infinite discrete transitions in finite time. Zeno behavior has been likened to a form of finite-time asymptotic stability, and corresponding Lyapunov theorems have been developed. In this paper, we propose a method to construct Lyapunov functions to prove Zeno stability of compact sets in cyclic hybrid systems with parametric uncertainties in the vector fields, domains and guard sets, and reset maps utilizing sum-of-squares programming. This technique can easily be applied to cyclic hybrid systems without parametric uncertainties as well. Examples illustrating the use of the proposed technique are also provided."}}
