{"id": "0somR4DXJ3", "cdate": 1667472115559, "mdate": 1667472115559, "content": {"title": "Few-shot object detection with attention-RPN and multi-relation detector", "abstract": "Conventional methods for object detection typically require a substantial amount of training data and preparing such high-quality training data is very labor-intensive. In this paper, we propose a novel few-shot object detection network that aims at detecting objects of unseen categories with only a few annotated examples. Central to our method are our Attention-RPN, Multi-Relation Detector and Contrastive Training strategy, which exploit the similarity between the few shot support set and query set to detect novel objects while suppressing false detection in the background. To train our network, we contribute a new dataset that contains 1000 categories of various objects with high-quality annotations. To the best of our knowledge, this is one of the first datasets specifically designed for few-shot object detection. Once our few-shot network is trained, it can detect objects of unseen categories without further training or fine-tuning. Our method is general and has a wide range of potential applications. We produce a new state-of-the-art performance on different datasets in the few-shot setting. The dataset link is https://github. com/fanq15/Few-Shot-Object-Detection-Dataset."}}
{"id": "ByZxzgW_bH", "cdate": 1514764800000, "mdate": null, "content": {"title": "3D Box Proposals From a Single Monocular Image of an Indoor Scene", "abstract": "Chinese Scholarship Council; CSIRO-Data61; The Program of Shanghai Subject Chief Scientist (A type) (No.15XD1502900)."}}
{"id": "BkWSDxM_Zr", "cdate": 1483228800000, "mdate": null, "content": {"title": "Indoor Scene Parsing with Instance Segmentation, Semantic Labeling and Support Relationship Inference", "abstract": "Over the years, indoor scene parsing has attracted a growing interest in the computer vision community. Existing methods have typically focused on diverse subtasks of this challenging problem. In particular, while some of them aim at segmenting the image into regions, such as object or surface instances, others aim at inferring the semantic labels of given regions, or their support relationships. These different tasks are typically treated as separate ones. However, they bear strong connections: good regions should respect the semantic labels, support can only be defined for meaningful regions, support relationships strongly depend on semantics. In this paper, we therefore introduce an approach to jointly segment the instances and infer their semantic labels and support relationships from a single input image. By exploiting a hierarchical segmentation, we formulate our problem as that of jointly finding the regions in the hierarchy that correspond to instances and estimating their class labels and pairwise support relationships. We express this via a Markov Random Field, which allows us to further encode links between the different types of variables. Inference in this model can be done exactly via integer linear programming, and we learn its parameters in a structural SVM framework. Our experiments on NYUv2 demonstrate the benefits of reasoning jointly about all these subtasks of indoor scene parsing."}}
{"id": "S1-us1zO-H", "cdate": 1420070400000, "mdate": null, "content": {"title": "Indoor scene structure analysis for single image depth estimation", "abstract": "We tackle the problem of single image depth estimation, which, without additional knowledge, suffers from many ambiguities. Unlike previous approaches that only reason locally, we propose to exploit the global structure of the scene to estimate its depth. To this end, we introduce a hierarchical representation of the scene, which models local depth jointly with mid-level and global scene structures. We formulate single image depth estimation as inference in a graphical model whose edges let us encode the interactions within and across the different layers of our hierarchy. Our method therefore still produces detailed depth estimates, but also leverages higher-level information about the scene. We demonstrate the benefits of our approach over local depth estimation methods on standard indoor datasets."}}
