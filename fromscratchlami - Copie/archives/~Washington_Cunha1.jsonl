{"id": "W5dD8KmbRj", "cdate": 1686328680290, "mdate": 1686328680290, "content": {"title": "An Effective, Efficient, and Scalable Confidence-Based Instance Selection Framework for Transformer-Based Text Classification", "abstract": "Transformer-based deep learning is currently the state-of-the-art in many NLP and IR tasks. However, fine-tuning such Transformers for specific tasks, especially in scenarios of ever-expanding volumes of data with constant re-training requirements and budget constraints, is costly (computationally and financially) and energy-consuming. In this paper, we focus on Instance Selection (IS) \u2013 a set of methods focused on selecting the most representative documents for training,  aimed at maintaining (or improving) classification effectiveness while reducing total time for training (or fine-tuning). We propose E2SC-IS -- Effective, Efficient, and Scalable Confidence-Based IS -- a two-step framework with a particular focus on Transformers and large datasets. E2SC-IS estimates the probability of each instance being removed from the training set based on scalable, fast, and calibrated weak classifiers. E2SC-IS  also exploits iterative heuristics to estimate a near-optimal reduction rate. Our solution can reduce the training sets by 29% on average while maintaining the effectiveness in all datasets, with speedup gains up to 70%,  scaling for very large datasets (something that the baselines cannot do)."}}
{"id": "LIgUsPoK5JM", "cdate": 1609459200000, "mdate": 1634227258162, "content": {"title": "On the cost-effectiveness of neural and non-neural approaches and representations for text classification: A comprehensive comparative study", "abstract": "Highlights \u2022 A critical literature review reveals serious experimental issues in the recent ATC (neural) literature. \u2022 We provide a very comprehensive and scientifically sound comparison of neural and non-neural methods. \u2022 We consider a cost-effectiveness tradeoff analysis based on more than 1500 measurements. \u2022 Simpler and cheaper non-neural solutions beat neural network methods in smaller datasets with a shortage of training. \u2022 Transformer architectures are better in larger datasets but by small margins and at a much higher cost. \u2022 Metafeatures are competitive with neural networks in both scenarios with a potentially better tradeoff. Abstract This article brings two major contributions. First, we present the results of a critical analysis of recent scientific articles about neural and non-neural approaches and representations for automatic text classification (ATC). This analysis is focused on assessing the scientific rigor of such studies. It reveals a profusion of potential issues related to the experimental procedures including: (i) use of inadequate experimental protocols, including no repetitions for the sake of assessing variability and generalization; (ii) lack of statistical treatment of the results; (iii) lack of details on hyperparameter tuning, especially of the baselines; (iv) use of inadequate measures of classification effectiveness (e.g., accuracy with skewed distributions). Second, we provide some organization and ground to the field by performing a comprehensive and scientifically sound comparison of recent neural and non-neural ATC solutions. Our study provides a more complete picture by looking beyond classification effectiveness, taking the trade-off between model costs (i.e., training time) into account. Our evaluation is guided by scientific rigor, which, as our literature review shows, is missing in a large body of work. Our experimental results, based on more than 1500 measurements, reveal that in the smaller datasets, the simplest and cheaper non-neural methods are among the best performers. In the larger datasets, neural Transformers perform better in terms of classification effectiveness. However, when compared to the best (properly tuned) non-neural solutions, the gains in effectiveness are not very expressive, especially considering the much longer training times (up to 23x slower). Our findings call for a self-reflection of best practices in the field, from the way experiments are conducted and analyzed to the choice of proper baselines for each situation and scenario."}}
{"id": "yYsHXYM0yb9", "cdate": 1577836800000, "mdate": 1634227257966, "content": {"title": "CluHTM - Semantic Hierarchical Topic Modeling based on CluWords", "abstract": "Felipe Viegas, Washington Cunha, Christian Gomes, Ant\u00f4nio Pereira, Leonardo Rocha, Marcos Goncalves. Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. 2020."}}
{"id": "RqQCu3qG92Y", "cdate": 1577836800000, "mdate": 1634227257985, "content": {"title": "\"Keep it Simple, Lazy\" - MetaLazy: A New MetaStrategy for Lazy Text Classification", "abstract": "Recent advances in text-related tasks on the Web, such as text (topic) classification and sentiment analysis, have been made possible by exploiting mostly the \"rule of more\": more data (massive amounts) more computing power, more complex solutions. We propose a shift in the paradigm to do \"more with less\" by focusing, at maximum extent, just on the task at hand (e.g., classify a single test instance). Accordingly, we propose MetaLazy, a new supervised lazy text classification meta-strategy that greatly extends the scope of lazy solutions. Lazy classifiers postpone the creation of a classification model until a given test instance for decision making is given. MetaLazy exploits new ideas and solutions, which have in common their lazy nature, producing altogether a solution for text classification, which is simpler, more efficient, and less data demanding than new alternatives. It extends and evolves the lazy creation of the model for the test instance by allowing: (i) to dynamically choose the best classifier for the task; (ii) the exploration of distances in the neighborhood of the test document when learning a classification model, thus diminishing the importance of irrelevant training instances; and (iii) a better representational space for training and test documents by augmenting them, in a lazy fashion, with new co-occurrence based features considering just those observed in the specific test instance. In a sizeable experimental evaluation, considering topics and sentiment analysis datasets and nine baselines, we show that our MetaLazy instantiations are among the top performers in most situations, even when compared to state-of-the-art deep learning classifiers such as Deep Network Transformer Architectures."}}
{"id": "0gXZG_H2c8V", "cdate": 1577836800000, "mdate": 1634227257992, "content": {"title": "Extended pre-processing pipeline for text classification: On the role of meta-feature representations, sparsification and selective sampling", "abstract": "Highlights \u2022 We propose and orchestrate new pre-processing steps for text classification pipelines. \u2022 We explore meta-feature representations, sparsification and selective sampling. \u2022 We provide thorough evaluations of the trade-offs between costs and effectiveness. \u2022 Our final representations are more effective than word embeddings (up to 46%). \u2022 Our processes induce large reductions in computational costs and memory consumption. Abstract Text Classification pipelines are a sequence of tasks needed to be performed to classify documents into a set of predefined categories. The pre-processing phase (before training) of these pipelines involve different ways of transforming and manipulating the documents for the next (learning) phase. In this paper, we introduce three new steps into the pre-processing phase of text classification pipelines to improve effectiveness while reducing the associated costs. The distance-based Meta-Features (MFs) generation step aims at reducing the dimensionality of the original term-document matrix while producing a potentially more informative space that explicitly exploits discriminative labeled information. The second step is a sparsification one aimed at making the MF representation less dense to reduce training costs and noise. The third step is a selective sampling (SS) aimed at removing lines (documents) of the matrix obtained in the previous step, by carefully selecting the \u201cbest\u201d documents for the learning phase. Our experiments show that the proposed extended pre-processing pipeline can achieve significant gains in effectiveness when compared to the original TF-IDF (up to 52%) and embedding-based representations (up to 46%), at a much lower cost (up to 9.7x faster in some datasets). Other main contributions of our work include a thorough and rigorous evaluation of the trade-offs between cost and effectiveness associated with the introduction of these new steps into the pipeline as well as a comprehensive comparative experimental evaluation of many alternatives in terms of representations, approaches, etc."}}
{"id": "OrNGCilrsai", "cdate": 1546300800000, "mdate": 1634227379342, "content": {"title": "CluWords: Exploiting Semantic Word Clustering Representation for Enhanced Topic Modeling", "abstract": "In this paper, we advance the state-of-the-art in topic modeling by means of a new document representation based on pre-trained word embeddings for non-probabilistic matrix factorization. Specifically, our strategy, called CluWords, exploits the nearest words of a given pre-trained word embedding to generate meta-words capable of enhancing the document representation, in terms of both, syntactic and semantic information. The novel contributions of our solution include: (i)the introduction of a novel data representation for topic modeling based on syntactic and semantic relationships derived from distances calculated within a pre-trained word embedding space and (ii)the proposal of a new TF-IDF-based strategy, particularly developed to weight the CluWords. In our extensive experimentation evaluation, covering 12 datasets and 8 state-of-the-art baselines, we exceed (with a few ties) in almost cases, with gains of more than 50% against the best baselines (achieving up to 80% against some runner-ups). Finally, we show that our method is able to improve document representation for the task of automatic text classification."}}
{"id": "xE3kZy50OI1", "cdate": 1514764800000, "mdate": 1634227379355, "content": {"title": "Please please me: does the presence of test cases influence mobile app users' satisfaction?", "abstract": "Mobile application developers have started to realize that quality plays a vital role in increasing the popularity of mobile applications (apps), thereby directly influencing economical profit (in-app purchases revenue) and app-related success factors (i.e., number of downloads). Therefore, developers have become increasingly concerned with taking preemptive actions to ensure the quality of their apps. In general, developers have been relying on testing as their main quality assurance practice. However, little is known about how much mobile app testing contributes to increasing user level satisfaction. In this paper we investigate to what extent testing mobile apps contributes to achieving higher user satisfaction. To this end, we probed into whether there is a relation between having automated tests and overall user satisfaction. We looked into users ratings, which express their level of satisfaction with apps, and users reviews, which often include bug (i.e., fault) reports. By analyzing a quantitative indicator of user satisfaction (i.e., user rating), we found that there is no significant difference between apps with automated tests and apps that have been developed without test suites. We also applied sentiment analysis on user reviews to examine the main differences between apps with and without test suites. The results of our review-based sentiment analysis suggest that most apps with and without test suites score quite high for user satisfaction. In addition, we found that update-related problems are far more common in apps with test suites, while apps without test suites are likely to have battery-drain problems."}}
{"id": "tRPSDHzweFG", "cdate": 1514764800000, "mdate": 1634227379475, "content": {"title": "Semantically-Enhanced Topic Modeling", "abstract": "In this paper, we advance the state-of-the-art in topic modeling by means of the design and development of a novel (semi-formal) general topic modeling framework. The novel contributions of our solution include: (i) the introduction of new semantically-enhanced data representations for topic modeling based on pooling, and (ii) the proposal of a novel topic extraction strategy - ASToC - that solves the difficulty in representing topics in our semantically-enhanced information space. In our extensive experimentation evaluation, covering 12 datasets and 12 state-of-the-art baselines, totalizing 108 tests, we exceed (with a few ties) in almost 100 cases, with gains of more than 50% against the best baselines (achieving up to 80% against some runner-ups). We provide qualitative and quantitative statistical analyses of why our solutions work so well. Finally, we show that our method is able to improve document representation in automatic text classification."}}
