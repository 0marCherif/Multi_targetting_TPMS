{"id": "F3jDT5Ch7s", "cdate": 1667901222592, "mdate": 1667901222592, "content": {"title": "Learning Attribute-driven Disentangled Representations for Interactive Fashion Retrieval", "abstract": "Interactive retrieval for online fashion shopping pro-\nvides the ability to change image retrieval results according\nto the user feedback. One common problem in interactive\nretrieval is that a specific user interaction (e.g., changing\nthe color of a T-shirt) causes other aspects to change inad-\nvertently (e.g., the retrieved item has a sleeve type different\nthan the query). This is a consequence of existing methods\nlearning visual representations that are semantically entan-\ngled in the embedding space, which limits the controllability\nof the retrieved results. We propose to leverage on the se-\nmantics of visual attributes to train convolutional networks\nthat learn attribute-specific subspaces for each attribute to\nobtain disentangled representations. Thus operations, such\nas swapping out a particular attribute value for another,\nimpact the attribute at hand and leave others untouched.\nWe show that our model can be tailored to deal with dif-\nferent retrieval tasks while maintaining its disentanglement\nproperty. We obtain state-of-the-art performance on three\ninteractive fashion retrieval tasks: attribute manipulation\nretrieval, conditional similarity retrieval, and outfit com-\nplementary item retrieval. "}}
{"id": "rkeNqkBFPB", "cdate": 1569439627995, "mdate": null, "content": {"title": "Deep automodulators", "abstract": "We introduce a novel autoencoder model that deviates from traditional autoencoders by using the full latent vector to independently modulate each layer in the decoder. We demonstrate how such an 'automodulator' allows for a principled approach to enforce latent space disentanglement, mixing of latent codes, and a straightforward way to utilize prior information that can be construed as a scale-specific invariance. Unlike GANs, autoencoder models can directly operate on new real input samples. This makes our model directly suitable for applications involving real-world inputs. As the architectural backbone, we extend recent generative autoencoder models that retain input identity and image sharpness at high resolutions better than VAEs. We show that our model achieves state-of-the-art latent space disentanglement and achieves high quality and diversity of output samples, as well as faithfulness of reconstructions."}}
