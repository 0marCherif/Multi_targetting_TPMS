{"id": "jAk7Mg9EvwJ", "cdate": 1683901027420, "mdate": 1683901027420, "content": {"title": "Transductive Matrix Completion with Calibration for Multi-Task Learning", "abstract": "Multi-task learning has attracted much attention due to growing multi-purpose research with multiple related data sources. Moreover, transduction with matrix completion is a useful method in multi-label learning. In this paper, we propose a transductive matrix completion algorithm that incorporates a calibration constraint for the features under the multi-task learning framework. The proposed algorithm recovers the incomplete feature matrix and target matrix simultaneously. Fortunately, the calibration information improves the completion results. In particular, we provide a statistical guarantee for the proposed algorithm, and the theoretical improvement induced by calibration information is also studied. Moreover, the proposed algorithm enjoys a sub-linear convergence rate. Several synthetic data experiments are conducted, which show the proposed algorithm out-performs other methods, especially when the target matrix is associated with the feature matrix in a nonlinear way."}}
{"id": "SVhG78Us5g5", "cdate": 1646077514771, "mdate": null, "content": {"title": "Byzantine-Tolerant Distributed Multiclass Sparse Linear Discriminant Analysis", "abstract": "Communication cost and security issues are both important in large-scale distributed machine learning. In this paper, we investigate a multiclass sparse classification problem under two distributed systems. We propose two distributed multiclass sparse discriminant analysis algorithms based on mean-aggregation and median-aggregation under normal distributed system or Byzantine failure system. Both of them are computation and communication efficient. Several theoretical results, including estimation error bounds, and support recovery, are established. With moderate initial estimators, our iterative estimators achieve a (near-)optimal rate and exact support recovery after a constant number of rounds. Experiments on both synthetic and real datasets are provided to demonstrate the effectiveness of our proposed methods."}}
{"id": "dd9a9kJG5pT", "cdate": 1640995200000, "mdate": 1671866625425, "content": {"title": "DEMO: A Flexible Deartifacting Module for Compressed Sensing MRI", "abstract": "Compressed sensing (CS) has been a novel technique for fast reconstruction of magnetic resonance (MR) images from their partial <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><tex-math notation=\"LaTeX\">$k$</tex-math></inline-formula> -space measurements. However, the quality of the reconstructed images could be severely affected by artifacts from various sources. In this paper, we propose a deartifacting module (DEMO) that can effectively remove the artifacts by eliminating sparse outliers in the <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><tex-math notation=\"LaTeX\">$k$</tex-math></inline-formula> -space. Specifically, DEMO augments the measurements in the original loss function to approximate a new loss that is robust to outliers. Since DEMO is developed independently of any backbone algorithm to perform with, it can be flexibly incorporated into a broad range of CS-MRI methods, including both model-based methods and unrolling deep neural networks. Extensive experiments under various settings demonstrate the effectiveness and robustness of DEMO."}}
{"id": "UN_oH152siU", "cdate": 1640995200000, "mdate": 1648703616068, "content": {"title": "Fast and Robust Sparsity Learning over Networks: A Decentralized Surrogate Median Regression Approach", "abstract": "Decentralized sparsity learning has attracted a significant amount of attention recently due to its rapidly growing applications. To obtain the robust and sparse estimators, a natural idea is to adopt the non-smooth median loss combined with a $\\ell_1$ sparsity regularizer. However, most of the existing methods suffer from slow convergence performance caused by the {\\em double} non-smooth objective. To accelerate the computation, in this paper, we proposed a decentralized surrogate median regression (deSMR) method for efficiently solving the decentralized sparsity learning problem. We show that our proposed algorithm enjoys a linear convergence rate with a simple implementation. We also investigate the statistical guarantee, and it shows that our proposed estimator achieves a near-oracle convergence rate without any restriction on the number of network nodes. Moreover, we establish the theoretical results for sparse support recovery. Thorough numerical experiments and real data study are provided to demonstrate the effectiveness of our method."}}
{"id": "UFrQu3iVpQ", "cdate": 1640995200000, "mdate": 1671866625426, "content": {"title": "Byzantine-tolerant distributed multiclass sparse linear discriminant analysis", "abstract": "Communication cost and security issues are both important in large-scale distributed machine learning. In this paper, we investigate a multiclass sparse classification problem under two distributed..."}}
{"id": "SBBb-K_0k19", "cdate": 1640995200000, "mdate": 1644320888744, "content": {"title": "Nonparametric Feature Selection by Random Forests and Deep Neural Networks", "abstract": "Random forests are a widely used machine learning algorithm, but their computational efficiency is undermined when applied to large-scale datasets with numerous instances and useless features. Herein, we propose a nonparametric feature selection algorithm that incorporates random forests and deep neural networks, and its theoretical properties are also investigated under regularity conditions. Using different synthetic models and a real-world example, we demonstrate the advantage of the proposed algorithm over other alternatives in terms of identifying useful features, avoiding useless ones, and the computation efficiency. Although the algorithm is proposed using standard random forests, it can be widely adapted to other machine learning algorithms, as long as features can be sorted accordingly."}}
{"id": "QU4FenKV2Tk", "cdate": 1640995200000, "mdate": 1671866625154, "content": {"title": "Nonparametric feature selection by random forests and deep neural networks", "abstract": ""}}
{"id": "MM2DIN_8cD", "cdate": 1640995200000, "mdate": 1671866625154, "content": {"title": "Applying Differential Privacy to Tensor Completion", "abstract": "Tensor completion aims at filling the missing or unobserved en-tries based on partially observed tensors. However, utilization of the observed tensors often raises serious privacy concerns in many practical scenarios. To address this issue, we propose a solid and unified framework that contains several approaches for applying differential privacy to the two most widely used tensor decomposition methods: i) CANDECOMP/PARAFAC and ii) Tucker decompositions. For each approach, we establish a rigorous privacy guarantee and meanwhile evaluate the privacy-accuracy trade-off. Experiments on synthetic datasets demonstrate that our proposal achieves high accuracy for tensor completion while ensuring strong privacy protections."}}
{"id": "F-A2BbVdrs", "cdate": 1640995200000, "mdate": 1671866625424, "content": {"title": "Majority Vote for Distributed Differentially Private Sign Selection", "abstract": "Privacy-preserving data analysis has become prevailing in recent years. In this paper, we propose a distributed group differentially private majority vote mechanism for the sign selection problem in a distributed setup. To achieve this, we apply the iterative peeling to the stability function and use the exponential mechanism to recover the signs. As applications, we study the private sign selection for mean estimation and linear regression problems in distributed systems. Our method recovers the support and signs with the optimal signal-to-noise ratio as in the non-private scenario, which is better than contemporary works of private variable selections. Moreover, the sign selection consistency is justified with theoretical guarantees. Simulation studies are conducted to demonstrate the effectiveness of our proposed method."}}
{"id": "DcFQ0D7HF7", "cdate": 1640995200000, "mdate": 1671866625153, "content": {"title": "Compressive Sensing Approaches for Sparse Distribution Estimation Under Local Privacy", "abstract": "Recent years, local differential privacy (LDP) has been adopted by many web service providers like Google [23], Apple [33] and Microsoft [15] to collect and analyse users\u2019 data privately. In this paper, we consider the problem of discrete distribution estimation under local differential privacy constraints. Distribution estimation is one of the most fundamental estimation problems, which is widely studied in both non-private and private settings. In the local model, private mechanisms with provably optimal sample complexity are known. However, they are optimal only in the worst-case sense; their sample complexity is proportional to the size of the entire universe, which could be huge in practice. In this paper, we consider sparse or approximately sparse (e.g. highly skewed) distribution, and show that the number of samples needed could be significantly reduced. This problem has been studied recently [1], but they only consider strict sparse distributions and the high privacy regime. We propose new privatization mechanisms based on compressive sensing. Our methods work for approximately sparse distributions and medium privacy, and have optimal sample and communication complexity."}}
