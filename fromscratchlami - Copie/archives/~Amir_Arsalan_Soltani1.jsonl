{"id": "beeafrOhoDE", "cdate": 1674608490580, "mdate": 1674608490580, "content": {"title": "Seeing Soft Materials Draped Over Objects: A Case Study of Intuitive Physics in Perception, Attention, and Memory", "abstract": "We typically think of intuitive physics in terms of high-level cognition, but might aspects of physics also be extracted during lower-level visual processing? Might we not only think about physics, but also see it? We explored this using multiple tasks in online adult samples with objects covered by soft materials\u2014as when you see a chair with a blanket draped over it\u2014where you must account for the physical interactions between cloth, gravity, and object. In multiple change-detection experiments (n = 200), observers from an online testing marketplace were better at detecting image changes involving underlying object structure versus those involving only the superficial folds of cloths\u2014even when the latter were more extreme along several dimensions. And in probe-comparison experiments (n = 100), performance was worse when both probes (vs. only one) appeared on image regions reflective of underlying object structure (equating visual properties). This work collectively shows how vision uses intuitive physics to recover the deeper underlying structure of scenes."}}
{"id": "-trI7NVvRl", "cdate": 1674608129861, "mdate": null, "content": {"title": "3D Shape Perception Integrates Intuitive Physics and Analysis-by-Synthesis", "abstract": "Many surface cues support three-dimensional shape perception, but people can sometimes still see shape when these features are missing \u2013 in extreme cases, even when an object is completely occluded, as when covered with a draped cloth. We propose a framework for 3D shape perception that explains perception in both typical and atypical cases as analysis-by-synthesis, or inference in a generative model of image formation: the model integrates intuitive physics to explain how shape can be inferred from deformations it causes to other objects, as in cloth- draping. Behavioral and computational studies comparing this account with several alternatives show that it best matches human observers in both accuracy and response times, and is the only model that correlates significantly with human performance on difficult discriminations. Our results suggest that bottom-up deep neural network models are not fully adequate accounts of human shape perception, and point to how machine vision systems might achieve more human-like robustness."}}
{"id": "4hMZEOe_ewh", "cdate": 1632683579591, "mdate": 1632683579591, "content": {"title": "Inverse Rendering Best Explains Face Perception Under Extreme Illuminations", "abstract": "Humans can successfully interpret images even when they have been distorted by significant image transformations. Suchimages could aid in differentiating proposed computational architectures for perception because while all proposals predictsimilar results for typical stimuli (good performance), they differ when confronting atypical stimuli.  Here we study twoclasses of degraded stimuli \u2013 Mooney faces and silhouettes of faces \u2013 as well as typical faces, in humans and severalcomputational models, with the goal of identifying divergent predictions among the models, evaluating against humanjudgments, and ultimately informing models of human perception.  We find that our top-down inverse rendering modelbetter matches human percepts than either an invariance-based account implemented in a deep neural network, or a neuralnetwork trained to perform approximate inverse rendering in a feedforward circuit."}}
{"id": "1tpypOzek9a", "cdate": 1632683116258, "mdate": 1632683116258, "content": {"title": "Draping an Elephant: Uncovering Children\u2019s Reasoning About Cloth-Covered Objects", "abstract": "Humans have an intuitive understanding of physics. They can predict how a physical scene will unfold, and reason about how it came to be. Adults may rely on such a physical representation for visual reasoning and recognition, going beyond visual features and capturing objects in terms of their physical properties. Recently, the use of draped objects in recognition was used to examine adult object representations in the absence of many common visual features. In this paper we examine young children\u2019s reasoning about draped objects in order to examine the develop of physical object representation. In addition, we argue that a better understanding of the development of the concept of cloth as a physical entity is worthwhile in and of itself, as it may form a basic ontological category in intuitive physical reasoning akin to liquids and solids. We use two experiments to investigate young children\u2019s (ages 3\u20135) reasoning about cloth-covered objects, and find that they perform significantly above chance (though far from perfectly) indicating a representation of physical objects that can interact dynamically with the world. Children\u2019s success and failure pattern is similar across the two experiments, and we compare it to adult behavior. We find a small effect, which suggests the specific features that make reasoning about certain objects more difficult may carry into adulthood."}}
{"id": "B1EvSJGd-H", "cdate": 1483228800000, "mdate": null, "content": {"title": "Synthesizing 3D Shapes via Modeling Multi-view Depth Maps and Silhouettes with Deep Generative Networks", "abstract": "We study the problem of learning generative models of 3D shapes. Voxels or 3D parts have been widely used as the underlying representations to build complex 3D shapes, however, voxel-based representations suffer from high memory requirements, and parts-based models require a large collection of cached or richly parametrized parts. We take an alternative approach: learning a generative model over multi-view depth maps or their corresponding silhouettes, and using a deterministic rendering function to produce 3D shapes from these images. A multi-view representation of shapes enables generation of 3D models with fine details, as 2D depth maps and silhouettes can be modeled at a much higher resolution than 3D voxels. Moreover, our approach naturally brings the ability to recover the underlying 3D representation from depth maps of one or a few viewpoints. Experiments show that our framework can generate 3D shapes with variations and details. We also demonstrate that our model has out-of-sample generalization power for real-world tasks with occluded objects."}}
