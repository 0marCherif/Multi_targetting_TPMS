{"id": "4u-r3BKFY6", "cdate": 1672531200000, "mdate": 1682363739292, "content": {"title": "ChiroDiff: Modelling chirographic data with Diffusion Models", "abstract": "Generative modelling over continuous-time geometric constructs, a.k.a such as handwriting, sketches, drawings etc., have been accomplished through autoregressive distributions. Such strictly-ordered discrete factorization however falls short of capturing key properties of chirographic data -- it fails to build holistic understanding of the temporal concept due to one-way visibility (causality). Consequently, temporal data has been modelled as discrete token sequences of fixed sampling rate instead of capturing the true underlying concept. In this paper, we introduce a powerful model-class namely \"Denoising Diffusion Probabilistic Models\" or DDPMs for chirographic data that specifically addresses these flaws. Our model named \"ChiroDiff\", being non-autoregressive, learns to capture holistic concepts and therefore remains resilient to higher temporal sampling rate up to a good extent. Moreover, we show that many important downstream utilities (e.g. conditional sampling, creative mixing) can be flexibly implemented using ChiroDiff. We further show some unique use-cases like stochastic vectorization, de-noising/healing, abstraction are also possible with this model-class. We perform quantitative and qualitative evaluation of our framework on relevant datasets and found it to be better or on par with competing approaches."}}
{"id": "1ROAstc9jv", "cdate": 1663849830314, "mdate": null, "content": {"title": "ChiroDiff: Modelling chirographic data with Diffusion Models", "abstract": "Generative modelling over continuous-time geometric constructs, a.k.a $chirographic\\ data$ such as handwriting, sketches, drawings etc., have been accomplished through autoregressive distributions. Such strictly-ordered discrete factorization however falls short of capturing key properties of chirographic data -- it fails to build holistic understanding of the temporal concept due to one-way visibility (causality). Consequently, temporal data has been modelled as discrete token sequences of fixed sampling rate instead of capturing the true underlying concept. In this paper, we introduce a powerful model-class namely Denoising\\ Diffusion\\ Probabilistic\\ Models or DDPMs for chirographic data that specifically addresses these flaws. Our model named \"ChiroDiff\", being non-autoregressive, learns to capture holistic concepts and therefore remains resilient to higher temporal sampling rate up to a good extent. Moreover, we show that many important downstream utilities (e.g. conditional sampling, creative mixing) can be flexibly implemented using ChiroDiff. We further show some unique use-cases like stochastic vectorization, de-noising/healing, abstraction are also possible with this model-class. We perform quantitative and qualitative evaluation of our framework on relevant datasets and found it to be better or on par with competing approaches."}}
{"id": "rIqIeDNI804", "cdate": 1640995200000, "mdate": 1667401423249, "content": {"title": "SketchODE: Learning neural sketch representation in continuous time", "abstract": "Learning meaningful representations for chirographic drawing data such as sketches, handwriting, and flowcharts is a gateway for understanding and emulating human creative expression. Despite being..."}}
{"id": "c-4HSDAWua5", "cdate": 1632875430052, "mdate": null, "content": {"title": "SketchODE: Learning neural sketch representation in continuous time", "abstract": "Learning meaningful representations for chirographic drawing data such as sketches, handwriting, and flowcharts is a gateway for understanding and emulating human creative expression. Despite being inherently continuous-time data, existing works have treated these as discrete-time sequences, disregarding their true nature. In this work, we model such data as continuous-time functions and learn compact representations by virtue of Neural Ordinary Differential Equations. To this end, we introduce the first continuous-time Seq2Seq model and demonstrate some remarkable properties that set it apart from traditional discrete-time analogues. We also provide solutions for some practical challenges for such models, including introducing a family of parameterized ODE dynamics & continuous-time data augmentation particularly suitable for the task. Our models are validated on several datasets including VectorMNIST, DiDi and Quick, Draw!."}}
{"id": "PNs1Yo-lYm", "cdate": 1609459200000, "mdate": 1667401423208, "content": {"title": "Cloud2Curve: Generation and Vectorization of Parametric Sketches", "abstract": "Analysis of human sketches in deep learning has advanced immensely through the use of waypoint-sequences rather than raster-graphic representations. We further aim to model sketches as a sequence of low-dimensional parametric curves. To this end, we propose an inverse graphics framework capable of approximating a raster or waypoint based stroke encoded as a point-cloud with a variable-degree Bezier curve. Building on this module, we present Cloud2Curve, a generative model for scalable high-resolution vector sketches that can be trained end-to-end using point-cloud data alone. As a consequence, our model is also capable of deterministic vectorization which can map novel raster or waypoint based sketches to their corresponding high-resolution scalable Bezier equivalent. We evaluate the generation and vectorization capabilities of our model on Quick, Draw! and K-MNIST datasets."}}
{"id": "grQ4SFRNsDc", "cdate": 1577836800000, "mdate": 1667401423191, "content": {"title": "Pixelor: a competitive sketching AI agent. so you think you can sketch?", "abstract": ""}}
{"id": "6Sd9FqCSewy5", "cdate": 1577836800000, "mdate": 1668197291787, "content": {"title": "B\u00e9zierSketch: A Generative Model for Scalable Vector Sketches", "abstract": "The study of neural generative models of human sketches is a fascinating contemporary modeling problem due to the links between sketch image generation and the human drawing process. The landmark SketchRNN provided breakthrough by sequentially generating sketches as a sequence of waypoints. However this leads to low-resolution image generation, and failure to model long sketches. In this paper we present B\u00e9zierSketch, a novel generative model for fully vector sketches that are automatically scalable and high-resolution. To this end, we first introduce a novel inverse graphics approach to stroke embedding that trains an encoder to embed each stroke to its best fit B\u00e9zier curve. This enables us to treat sketches as short sequences of paramaterized strokes and thus train a recurrent sketch generator with greater capacity for longer sketches, while producing scalable high-resolution results. We report qualitative and quantitative results on the Quick, Draw! benchmark."}}
