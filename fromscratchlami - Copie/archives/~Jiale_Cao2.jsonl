{"id": "UHbqtAi0QBA", "cdate": 1640995200000, "mdate": 1668144183391, "content": {"title": "PSTR: End-to-End One-Step Person Search With Transformers", "abstract": ""}}
{"id": "9-cCzRrd6o", "cdate": 1640995200000, "mdate": 1668144183427, "content": {"title": "From Handcrafted to Deep Features for Pedestrian Detection: A Survey", "abstract": ""}}
{"id": "H5rdHU_SuC", "cdate": 1609459200000, "mdate": 1668144183426, "content": {"title": "TJU-DHD: A Diverse High-Resolution Dataset for Object Detection", "abstract": ""}}
{"id": "wfFzjBbHdY", "cdate": 1577836800000, "mdate": 1668144183488, "content": {"title": "SipMask: Spatial Information Preservation for Fast Image and Video Instance Segmentation", "abstract": ""}}
{"id": "wNV_hw26a0a", "cdate": 1577836800000, "mdate": 1668144183372, "content": {"title": "D2Det: Towards High Quality Object Detection and Instance Segmentation", "abstract": ""}}
{"id": "rsj-NzXe_TH", "cdate": 1546300800000, "mdate": null, "content": {"title": "Triply Supervised Decoder Networks for Joint Detection and Segmentation.", "abstract": "Joint object detection and semantic segmentation is essential in many fields such as self-driving cars. An initial attempt towards this goal is to simply share a single network for multi-task learning. We argue that it does not make full use of the fact that detection and segmentation are mutually beneficial. In this paper, we propose a framework called TripleNet to deeply boost these two tasks. On the one hand, to deeply join the two tasks at different scales, triple supervisions including detection-oriented supervision and class-aware/agnostic segmentation supervisions are imposed on each layer of the decoder. Class-agnostic segmentation provides an objectness prior to detection and segmentation. On the other hand, to further intercross the two tasks and refine the features in each scale, two light-weight modules (i.e., the inner-connected module and the attention skip-layer fusion) are incorporated. Because segmentation supervision on each decoder layer are not performed at the test stage and two added modules are light-weight, the proposed TripleNet can run at a real-time speed (16 fps). Experiments on the VOC 2007/2012 and COCO datasets show that TripleNet outperforms all the other one-stage methods on both two tasks (e.g., 81.9% mAP and 83.3% mIoU on VOC 2012, and 37.1% mAP and 59.6% mIoU on COCO) by a single network."}}
{"id": "SkW8HlfdZS", "cdate": 1451606400000, "mdate": null, "content": {"title": "Pedestrian Detection Inspired by Appearance Constancy and Shape Symmetry", "abstract": "The discrimination and simplicity of features are very important for effective and efficient pedestrian detection. However, most state-of-the-art methods are unable to achieve good tradeoff between accuracy and efficiency. Inspired by some simple inherent attributes of pedestrians (i.e., appearance constancy and shape symmetry), we propose two new types of non-neighboring features (NNF): side-inner difference features (SIDF) and symmetrical similarity features (SSF). SIDF can characterize the difference between the background and pedestrian and the difference between the pedestrian contour and its inner part. SSF can capture the symmetrical similarity of pedestrian shape. However, it's difficult for neighboring features to have such above characterization abilities. Finally, we propose to combine both non-neighboring and neighboring features for pedestrian detection. It's found that nonneighboring features can further decrease the average miss rate by 4.44%. Experimental results on INRIA and Caltech pedestrian datasets demonstrate the effectiveness and efficiency of the proposed method. Compared to the state-of the-art methods without using CNN, our method achieves the best detection performance on Caltech, outperforming the second best method (i.e., Checkerboards) by 1.63%."}}
