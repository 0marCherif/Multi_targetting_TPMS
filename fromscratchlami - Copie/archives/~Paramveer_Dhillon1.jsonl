{"id": "QEK1Bhvmzz", "cdate": 1640995200000, "mdate": 1682338083900, "content": {"title": "Judging a Book by Its Cover: Predicting the Marginal Impact of Title on Reddit Post Popularity", "abstract": "Several factors influence the popularity of content on social media, including the what, when, and who of a post. Of these factors, the what and when of content are easiest to customize in order to maximize viewership and reach. Further, the title of a post (part of the what) is the easiest to tailor, compared to the post's body, which is often fixed. So, in this paper, we assess the impact of a post's title on its popularity while controlling for the time of posting (the when) by proposing an interpretable attention-based model. Our approach achieves state-of-the-art performance on predicting the popularity of posts on multiple online communities of various sizes, topics, and formats while still being parsimonious. Interpretation of our model's attention weights sheds light on the heterogeneous patterns in how the specific words in a post's title shape its popularity across different communities. Our results highlight the power of sentiment alignment, personal storytelling, and even personality politics in propelling content to virality."}}
{"id": "OZ_WKa3xd_E", "cdate": 1640995200000, "mdate": 1682338083934, "content": {"title": "Detecting Struggling Students from Interactive Ebook Data: A Case Study Using CSAwesome", "abstract": "Ebooks on the Runestone platform contain instructional material (text, images, videos, and a code visualizer/stepper) and a variety of practice problem types (write code problems with unit tests, multiple-choice questions, mixed-up code problems, etc.). User interaction is timestamped and logged. This paper reports on analyses comparing student interaction data to midterm scores for CSAwesome: a College Board endorsed ebook for the Advanced Placement Computer Science A course. We also analyzed mixed-up code (Parsons) problem data in-depth since these are a newer type of practice. Our analysis found that the percent correct on the midterm was most negatively correlated with being in a larger class and most positively correlated with the percent correct on other multiple-choice questions. It was also positively correlated with several other activities including the percent correct on Parsons problems, active code, and the pretest. Interestingly, it was positively correlated with the number of videos viewed, but negatively correlated with the number of videos completed. Next, our analysis of adaptive mixed-up code (Parsons) problems, where the student can ask for help when stuck, found a positive correlation with the number of steps a user completed before asking for help and a negative correlation with the elapsed time before getting help. Looking closely at two Parsons problems, we found that solving each problem more efficiently, i.e., with fewer extra steps, correlated with higher midterm scores. This work could help instructors identify and support struggling students early in a semester and informs the redesign of the instructor dashboard."}}
{"id": "OnvyZ8oZ_hz", "cdate": 1620328074215, "mdate": null, "content": {"title": "Targeting for long-term outcomes", "abstract": "Decision-makers often want to target interventions (e.g., marketing campaigns) so as to maximize an outcome that is observed only in the long-term. This typically requires delaying decisions until the outcome is observed or relying on simple short-term proxies for the long- term outcome. Here we build on the statistical surrogacy and off-policy learning literature to impute the missing long-term outcomes and then approximate the optimal targeting policy on the imputed outcomes via a doubly-robust approach. We apply our approach in large-scale proactive churn management experiments at The Boston Globe by targeting optimal discounts to its digital subscribers to maximize their long-term revenue. We first show that conditions for validity of average treatment effect estimation with imputed outcomes are also sufficient for valid policy evaluation and optimization; furthermore, these conditions can be somewhat relaxed for policy optimization. We then validate this approach empirically by comparing it with a policy learned on the ground truth long-term outcomes and show that they are statisti- cally indistinguishable. Our approach also outperforms a policy learned on short-term proxies for the long-term outcome. In a second field experiment, we implement the optimal targeting policy with additional randomized exploration, which allows us to update the optimal policy for each new cohort of customers to account for potential non-stationarity. Over three years, our approach had a net-positive revenue impact in the range of $4-5 million compared to The Boston Globe\u2019s current policies."}}
{"id": "Y6hWeTKWJLm", "cdate": 1620327932941, "mdate": null, "content": {"title": "Modeling Dynamic User Interests: A Neural Matrix Factorization Approach", "abstract": "In recent years, there has been significant interest in understanding users\u2019 online content consumption patterns. But, the unstructured, high-dimensional, and dy- namic nature of such data makes extracting valuable insights challenging. Here we propose a model that combines the simplicity of matrix factorization with the flex- ibility of neural networks to efficiently extract nonlinear patterns from massive text data collections relevant to consumers\u2019 online consumption patterns. Our model decomposes a user\u2019s content consumption journey into nonlinear user and content factors that are used to model their dynamic interests. This natural decomposition allows us to summarize each user\u2019s content consumption journey with a dynamic probabilistic weighting over a set of underlying content attributes. The model is fast to estimate, easy to interpret and can harness external data sources as an empirical prior. These advantages make our method well suited to the challenges posed by modern datasets. We use our model to understand the dynamic news consumption interests of Boston Globe readers over five years. Thorough qualitative studies, including a crowdsourced evaluation, highlight our model\u2019s ability to accurately identify nuanced and coherent consumption patterns. These results are supported by our model\u2019s superior and robust predictive performance over several competitive baseline methods."}}
{"id": "pmvSFu0qCo", "cdate": 1609459200000, "mdate": 1682338083877, "content": {"title": "Modeling Dynamic User Interests: A Neural Matrix Factorization Approach", "abstract": ""}}
{"id": "HJhkpXJ_ef7", "cdate": 1609459200000, "mdate": 1682338084246, "content": {"title": "Modeling Dynamic User Interests: A Neural Matrix Factorization Approach", "abstract": "In recent years, there has been significant interest in understanding users' online content consumption patterns. But, the unstructured, high-dimensional, and dynamic nature of such data makes extracting valuable insights challenging. Here we propose a model that combines the simplicity of matrix factorization with the flexibility of neural networks to efficiently extract nonlinear patterns from massive text data collections relevant to consumers' online consumption patterns. Our model decomposes a user's content consumption journey into nonlinear user and content factors that are used to model their dynamic interests. This natural decomposition allows us to summarize each user's content consumption journey with a dynamic probabilistic weighting over a set of underlying content attributes. The model is fast to estimate, easy to interpret and can harness external data sources as an empirical prior. These advantages make our method well suited to the challenges posed by modern datasets. We use our model to understand the dynamic news consumption interests of Boston Globe readers over five years. Thorough qualitative studies, including a crowdsourced evaluation, highlight our model's ability to accurately identify nuanced and coherent consumption patterns. These results are supported by our model's superior and robust predictive performance over several competitive baseline methods."}}
{"id": "9fYwHdAuX4z", "cdate": 1609459200000, "mdate": 1682338084244, "content": {"title": "Digital Paywall Design: Implications for Content Demand and Subscriptions", "abstract": "Most online content publishers have moved to subscription-based business models regulated by digital paywalls. But the managerial implications of such freemium content offerings are not well unders..."}}
{"id": "93zVOpRCIl", "cdate": 1609459200000, "mdate": 1682338084120, "content": {"title": "Comparing Ebook Student Interactions With Test Scores: A Case Study Using CSAwesome (Work in Progress)", "abstract": ""}}
{"id": "0cB3iu4wlh", "cdate": 1609459200000, "mdate": 1682338084114, "content": {"title": "Judging a book by its cover: Predicting the marginal impact of title on Reddit post popularity", "abstract": "Several factors influence the popularity of content on social media, including the what, when, and who of a post. Of these factors, the what and when of content are easiest to customize in order to maximize viewership and reach. Further, the title of a post (part of the what) is the easiest to tailor, compared to the post's body, which is often fixed. So, in this paper, we assess the impact of a post's title on its popularity while controlling for the time of posting (the when) by proposing an interpretable attention-based model. Our approach achieves state-of-the-art performance in predicting the popularity of posts on multiple online communities of various sizes, topics, and formats while still being parsimonious. Interpretation of our model's attention weights sheds light on the heterogeneous patterns in how the specific words in a post's title shape its popularity across different communities. Our results highlight the power of sentiment alignment, personal storytelling, and even personality politics in propelling content to virality."}}
{"id": "r1eb_4nLwH", "cdate": 1569272937040, "mdate": null, "content": {"title": "Social Influence Maximization Under Empirical Influence Models", "abstract": ""}}
