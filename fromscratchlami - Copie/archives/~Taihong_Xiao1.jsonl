{"id": "w25Q9Ttjrs", "cdate": 1675715128588, "mdate": null, "content": {"title": "Exploiting Category Names for Few-Shot Classification with Vision-Language Models", "abstract": "Vision-language foundation models pretrained on large-scale data provide a powerful tool for many visual understanding tasks.\nNotably, many vision-language models build two encoders (visual and textual) that can map two modalities into the same embedding space. As a result, the learned representations achieve good zero-shot performance on tasks like image classification. However, when there are only a few examples per category, the potential of large vision-language models is often underperformed, mainly due to the gap between a large number of parameters and a relatively small amount of training data. This paper shows that we can significantly improve the performance of few-shot classification by using the category names to initialize the classification head.  With the proposed category name initialization method, our model obtains the state-of-the-art performance on a number of few-shot image classification benchmarks (e.g., 87.37\\% on ImageNet and 96.08\\% on Stanford Cars, both using five-shot learning). "}}
{"id": "yOKbDa8yp6", "cdate": 1640995200000, "mdate": 1672911599228, "content": {"title": "Adaptive Transformers for Robust Few-shot Cross-domain Face Anti-spoofing", "abstract": ""}}
{"id": "p0xooMGrQWD", "cdate": 1640995200000, "mdate": 1672911599269, "content": {"title": "Exploiting Category Names for Few-Shot Classification with Vision-Language Models", "abstract": ""}}
{"id": "USP9hImgiU", "cdate": 1640995200000, "mdate": 1666367254171, "content": {"title": "Learning Contrastive Representation for Semantic Correspondence", "abstract": "Dense correspondence across semantically related images has been extensively studied, but still faces two challenges: 1) large variations in appearance, scale and pose exist even for objects from the same category, and 2) labeling pixel-level dense correspondences is labor intensive and infeasible to scale. Most existing methods focus on designing various matching modules using fully-supervised ImageNet pretrained networks. On the other hand, while a variety of self-supervised approaches are proposed to explicitly measure image-level similarities, correspondence matching the pixel level remains under-explored. In this work, we propose a multi-level contrastive learning approach for semantic matching, which does not rely on any ImageNet pretrained model. We show that image-level contrastive learning is a key component to encourage the convolutional features to find correspondence between similar objects, while the performance can be further enhanced by regularizing cross-instance cycle-consistency at intermediate feature levels. Experimental results on the PF-PASCAL, PF-WILLOW, and SPair-71k benchmark datasets demonstrate that our method performs favorably against the state-of-the-art approaches."}}
{"id": "KjG-5pYMP6V", "cdate": 1640995200000, "mdate": 1668583001097, "content": {"title": "FlowNAS: Neural Architecture Search for Optical Flow Estimation", "abstract": "Existing optical flow estimators usually employ the network architectures typically designed for image classification as the encoder to extract per-pixel features. However, due to the natural difference between the tasks, the architectures designed for image classification may be sub-optimal for flow estimation. To address this issue, we propose a neural architecture search method named FlowNAS to automatically find the better encoder architecture for flow estimation task. We first design a suitable search space including various convolutional operators and construct a weight-sharing super-network for efficiently evaluating the candidate architectures. Then, for better training the super-network, we propose Feature Alignment Distillation, which utilizes a well-trained flow estimator to guide the training of super-network. Finally, a resource-constrained evolutionary algorithm is exploited to find an optimal architecture (i.e., sub-network). Experimental results show that the discovered architecture with the weights inherited from the super-network achieves 4.67\\% F1-all error on KITTI, an 8.4\\% reduction of RAFT baseline, surpassing state-of-the-art handcrafted models GMA and AGFlow, while reducing the model complexity and latency. The source code and trained models will be released in https://github.com/VDIGPKU/FlowNAS."}}
{"id": "JcJFrqVsIht", "cdate": 1640995200000, "mdate": 1672911599157, "content": {"title": "Correction to: Learning Contrastive Representation for Semantic Correspondence", "abstract": ""}}
{"id": "FIAaYpfeWd", "cdate": 1640995200000, "mdate": 1667466946847, "content": {"title": "Adaptive Transformers for Robust Few-shot Cross-domain Face Anti-spoofing", "abstract": "While recent face anti-spoofing methods perform well under the intra-domain setups, an effective approach needs to account for much larger appearance variations of images acquired in complex scenes with different sensors for robust performance. In this paper, we present adaptive vision transformers (ViT) for robust cross-domain face anti-spoofing. Specifically, we adopt ViT as a backbone to exploit its strength to account for long-range dependencies among pixels. We further introduce the ensemble adapters module and feature-wise transformation layers in the ViT to adapt to different domains for robust performance with a few samples. Experiments on several benchmark datasets show that the proposed models achieve both robust and competitive performance against the state-of-the-art methods."}}
{"id": "vSm1MSQrfyN", "cdate": 1609459200000, "mdate": 1663770109158, "content": {"title": "Structured sparsification with joint optimization of group convolution and channel shuffle", "abstract": "Recent advances in convolutional neural networks (CNNs) usually come with the expense of excessive computational overhead and memory footprint. Network compression aims to alleviate this issue by t..."}}
{"id": "_Fwp_e9cx1MP", "cdate": 1609459200000, "mdate": 1663770109396, "content": {"title": "Semi-Supervised Learning with Meta-Gradient", "abstract": "In this work, we propose a simple yet effective meta-learning algorithm in semi-supervised learning. We notice that most existing consistency-based approaches suffer from overfitting and limited model generalization ability, especially when training with only a small number of labeled data. To alleviate this issue, we propose a learn-to-generalize regularization term by utilizing the label information and optimize the problem in a meta-learning fashion. Specifically, we seek the pseudo labels of the unlabeled data so that the model can generalize well on the labeled data, which is formulated as a nested optimization problem. We address this problem using the meta-gradient that bridges between the pseudo label and the regularization term. In addition, we introduce a simple first-order approximation to avoid computing higher-order derivatives and provide theoretic convergence analysis. Extensive evaluations on the SVHN, CIFAR, and ImageNet datasets demonstrate that the proposed algorithm performs favorably against state-of-the-art methods."}}
{"id": "UPIZkPoW6-", "cdate": 1609459200000, "mdate": 1672911599234, "content": {"title": "Learning Contrastive Representation for Semantic Correspondence", "abstract": ""}}
