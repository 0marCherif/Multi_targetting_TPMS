{"id": "gkQkZy-pRik", "cdate": 1652737278784, "mdate": null, "content": {"title": "MetaMask: Revisiting Dimensional Confounder for Self-Supervised Learning", "abstract": "As a successful approach to self-supervised learning, contrastive learning aims to learn invariant information shared among distortions of the input sample. While contrastive learning has yielded continuous advancements in sampling strategy and architecture design, it still remains two persistent defects: the interference of task-irrelevant information and sample inefficiency, which are related to the recurring existence of trivial constant solutions. From the perspective of dimensional analysis, we find out that the dimensional redundancy and dimensional confounder are the intrinsic issues behind the phenomena, and provide experimental evidence to support our viewpoint. We further propose a simple yet effective approach MetaMask, short for the dimensional Mask learned by Meta-learning, to learn representations against dimensional redundancy and confounder. MetaMask adopts the redundancy-reduction technique to tackle the dimensional redundancy issue and innovatively introduces a dimensional mask to reduce the gradient effects of specific dimensions containing the confounder, which is trained by employing a meta-learning paradigm with the objective of improving the performance of masked representations on a typical self-supervised task. We provide solid theoretical analyses to prove MetaMask can obtain tighter risk bounds for downstream classification compared to typical contrastive methods. Empirically, our method achieves state-of-the-art performance on various benchmarks."}}
{"id": "ltEGQl4BIf_", "cdate": 1640995200000, "mdate": 1648714006200, "content": {"title": "RHMC: Modeling consistent information from deep multiple views via Regularized and Hybrid Multiview Coding", "abstract": "Modeling multiple views by unsupervised representation learning is a challenging problem, since multi-view data features are different from each other, and it is unclear how to perform representation learning to fully explore discriminative information from multiple views. Recent works focus on learning consistent information by contrasting high-dimensional features, but amounts of useful view-consistent information of low-dimensional representation is ignored, and such information can benefit the learned representation on downstream tasks. In this paper, we propose a novel method called Regularized and Hybrid Multiview Coding (RHMC) for comprehensively modeling consistent information between multiple views. We induce the discriminative improvement of features by constraining the learned multi-view representations in the latent space with diversified self-supervised learning tasks. Specifically, RHMC proposes a hybrid MI estimation, which jointly considers the mutual information between the aggregated high-dimensional feature and low-dimensional representation of views. RHMC enables the learned representation to model the consistent information that is hidden in low-dimensional representations under the direction of the aggregated high-dimensional feature. In hidden space, the problem of multi-view domain shift degenerates the performance of mutual information estimation. To tackle the issue, RHMC imposes globally aligned structures of the learned representations in the latent space, that is aligning the probability distribution of different views by utilizing the Wasserstein distance-based view alignment regularization. Empirically, our experimental validation supports the ability of RHMC to outperform the state-of-the-art self-supervised methods by a significant margin, which proves that RHMC can indeed model consistent and discriminative information from multi-view data."}}
{"id": "bBwlOwKplh", "cdate": 1640995200000, "mdate": 1648714006166, "content": {"title": "MetAug: Contrastive Learning via Meta Feature Augmentation", "abstract": "What matters for contrastive learning? We argue that contrastive learning heavily relies on informative features, or \"hard\" (positive or negative) features. Early works include more informative features by applying complex data augmentations and large batch size or memory bank, and recent works design elaborate sampling approaches to explore informative features. The key challenge toward exploring such features is that the source multi-view data is generated by applying random data augmentations, making it infeasible to always add useful information in the augmented data. Consequently, the informativeness of features learned from such augmented data is limited. In response, we propose to directly augment the features in latent space, thereby learning discriminative representations without a large amount of input data. We perform a meta learning technique to build the augmentation generator that updates its network parameters by considering the performance of the encoder. However, insufficient input data may lead the encoder to learn collapsed features and therefore malfunction the augmentation generator. A new margin-injected regularization is further added in the objective function to avoid the encoder learning a degenerate mapping. To contrast all features in one gradient back-propagation step, we adopt the proposed optimization-driven unified contrastive loss instead of the conventional contrastive loss. Empirically, our method achieves state-of-the-art results on several benchmark datasets."}}
{"id": "Ikb5JS80NrV", "cdate": 1640995200000, "mdate": 1648714006198, "content": {"title": "Robust Local Preserving and Global Aligning Network for Adversarial Domain Adaptation", "abstract": "Unsupervised domain adaptation (UDA) requires source domain samples with clean ground truth labels during training. Accurately labeling a large number of source domain samples is time-consuming and laborious. An alternative is to utilize samples with noisy labels for training. However, training with noisy labels can greatly reduce the performance of UDA. In this paper, we address the problem that learning UDA models only with access to noisy labels and propose a novel method called robust local preserving and global aligning network (RLPGA). RLPGA improves the robustness of the label noise from two aspects. One is learning a classifier by a robust informative-theoretic-based loss function. The other is constructing two adjacency weight matrices and two negative weight matrices by the proposed local preserving module to preserve the local topology structures of input data. We conduct theoretical analysis on the robustness of the proposed RLPGA and prove that the robust informative-theoretic-based loss and the local preserving module are beneficial to reduce the empirical risk of the target domain. A series of empirical studies show the effectiveness of our proposed RLPGA."}}
{"id": "FxrmGvVb7U4", "cdate": 1640995200000, "mdate": 1648714006197, "content": {"title": "Bootstrapping Informative Graph Augmentation via A Meta Learning Approach", "abstract": "Recent works explore learning graph representations in a self-supervised manner. In graph contrastive learning, benchmark methods apply various graph augmentation approaches. However, most of the augmentation methods are non-learnable, which causes the issue of generating unbeneficial augmented graphs. Such augmentation may degenerate the representation ability of graph contrastive learning methods. Therefore, we motivate our method to generate augmented graph by a learnable graph augmenter, called MEta Graph Augmentation (MEGA). We then clarify that a \"good\" graph augmentation must have uniformity at the instance-level and informativeness at the feature-level. To this end, we propose a novel approach to learning a graph augmenter that can generate an augmentation with uniformity and informativeness. The objective of the graph augmenter is to promote our feature extraction network to learn a more discriminative feature representation, which motivates us to propose a meta-learning paradigm. Empirically, the experiments across multiple benchmark datasets demonstrate that MEGA outperforms the state-of-the-art methods in graph self-supervised learning tasks. Further experimental studies prove the effectiveness of different terms of MEGA."}}
{"id": "pXNXwaLu5MN", "cdate": 1632875432861, "mdate": null, "content": {"title": "Domain-Invariant Representation Learning with Global and Local Consistency", "abstract": "In this paper, we give an analysis of the existing representation learning framework of unsupervised domain adaptation and show that the learned feature representations of the source domain samples are with discriminability, compressibility, and transferability. However, the learned feature representations of the target domain samples are only with compressibility and transferability. To address this challenge, we propose a novel framework and show from the information theory view that this framework can effectively improve the discriminability of the target domain sample representation. We also propose a method, namely domain-invariant representation learning with global and local consistency (RLGLC), under this framework. In particular, to maintain the global consistency, RLGLC proposes a new metric called asymmetrically-relaxed Wasserstein of Wasserstein distance (AR-WWD), AR-WWD can not only extract the transferability and compressibility of the feature representation of two domains, but also correlates well with human perception. To impose the local consistency structures, we propose a regularized contrastive loss, which can not only keep as much as possible predictive information contained in the feature representation of the target domain, but also alleviates the problem that semantically similar instances are undesirable pushed apart in training processing. Finally, we verify the effectiveness of RLGLC from both theoretical analyses on Bayes error rate and experimental validation on several benchmarks."}}
{"id": "w8EbT3lWXkB", "cdate": 1609459200000, "mdate": 1648714006197, "content": {"title": "Information Theory-Guided Heuristic Progressive Multi-View Coding", "abstract": "Multi-view representation learning captures comprehensive information from multiple views of a shared context. Recent works intuitively apply contrastive learning (CL) to learn representations, regarded as a pairwise manner, which is still scalable: view-specific noise is not filtered in learning view-shared representations; the fake negative pairs, where the negative terms are actually within the same class as the positive, and the real negative pairs are coequally treated; and evenly measuring the similarities between terms might interfere with optimization. Importantly, few works research the theoretical framework of generalized self-supervised multi-view learning, especially for more than two views. To this end, we rethink the existing multi-view learning paradigm from the information theoretical perspective and then propose a novel information theoretical framework for generalized multi-view learning. Guided by it, we build a multi-view coding method with a three-tier progressive architecture, namely Information theory-guided heuristic Progressive Multi-view Coding (IPMC). In the distribution-tier, IPMC aligns the distribution between views to reduce view-specific noise. In the set-tier, IPMC builds self-adjusted pools for contrasting, which utilizes a view filter to adaptively modify the pools. Lastly, in the instance-tier, we adopt a designed unified loss to learn discriminative representations and reduce the gradient interference. Theoretically and empirically, we demonstrate the superiority of IPMC over state-of-the-art methods."}}
{"id": "McXBAh7K033", "cdate": 1609459200000, "mdate": 1648714006198, "content": {"title": "Short Text Clustering with a Deep Multi-embedded Self-supervised Model", "abstract": "Short text clustering is challenging in the field of Natural Language Processing (NLP) since it is hard to learn the discriminative representations with limited information. In this paper, fused multi-embedded features are employed to enhance the representations of short texts. Then, a denoising autoencoder with an attention layer is adopted to extract low-dimensional features from the multi-embeddings against the disturbance of noisy texts. Furthermore, we propose a novel distribution estimation with jointly utilizing soft cluster assignment and the prior target distribution transition to better fine-tune the encoder. Combining the above work, we propose a deep multi-embedded self-supervised model(DMESSM) for short text clustering. We compare our DMESSM with the state-of-the-art methods in head-to-head comparisons on benchmark datasets, which indicates that our method outperforms them."}}
{"id": "5REmdgf1xUK", "cdate": 1609459200000, "mdate": 1648714006196, "content": {"title": "Auxiliary task guided mean and covariance alignment network for adversarial domain adaptation", "abstract": "Adversarial domain adaptation (ADA) learns representations with strong transferability by eliminating the discrepancy between the probability distributions of the source and the target domains. Conventional ADA methods usually employ the Wasserstein distance as a discrepancy measure and train the classifier only from the source domain data. We show that such methods actually only consider first-order statistics in the latent feature space and the discriminability of the learned representations is not fully explored. In this paper, we propose a novel method called auxiliary task guided mean and covariance alignment network (AT-MCAN) for unsupervised domain adaptation. To take the second-order statistics differences into consideration, AT-MCAN introduces a covariance-aware divergence metric to align the distributions of two domains. To enhance the discriminability of the features, AT-MCAN introduces an auxiliary clustering task to the target domain so that the classifier can employ the data from both domains. We provide both theoretical analysis on the generalization bound and empirical evaluations on standard benchmarks to show the effectiveness of our proposed AT-MCAN."}}
