{"id": "FWcHVot_vqC", "cdate": 1701388800000, "mdate": 1707234882135, "content": {"title": "Learning joint surface reconstruction and segmentation, from brain images to cortical surface parcellation", "abstract": ""}}
{"id": "CrnXU0EJHmj", "cdate": 1701388800000, "mdate": 1707234882133, "content": {"title": "Active learning for medical image segmentation with stochastic batches", "abstract": ""}}
{"id": "upQogJXuhQ", "cdate": 1680830860066, "mdate": null, "content": {"title": "Active learning for medical image segmentation with stochastic batches", "abstract": "Active learning (AL) selects informative samples for annotation. This is becoming increasingly crucial to medical image segmentation since image annotation is hardly scalable to full pixel-level labeling of large datasets. However, most research focuses on classification or natural image segmentation. Uncertainty-based AL methods tend to have sub-optimal batch-query strategies, and diversity-based methods are computationally expensive. This work improves uncertainty-based AL for medical image segmentation using stochastic batches during sampling, computing uncertainty at the batch-level. Experiments on MRI prostate imaging show this approach\u2019s effectiveness and robustness under various conditions."}}
{"id": "u4kP4lohYNe", "cdate": 1672531200000, "mdate": 1707234882216, "content": {"title": "From Machine Learning to Deep Learning", "abstract": "This chapter provides a thorough grounding in the fundamental mathematical concepts of deep learning. It is first shown how a simple linear classifier can be defined based on the equation for a straight line. A more general scheme for optimization of the parameters of classifiers is introduced, based on gradient descent and its variants. We then see how the basic classifier model can be extended to produce simple artificial neural networks such as the perceptron and logistic regression. Next, these models are taken further to show how multiclass classification problems and nonlinearly separable data can be handled. Finally, the idea of a convolutional neural network is introduced and we see how this leads to the idea of deep learning. A practical tutorial is provided to give the reader some practical experience of developing classification models using Python."}}
{"id": "lAcxCHaGr30", "cdate": 1672531200000, "mdate": 1707234882182, "content": {"title": "TAAL: Test-time Augmentation for Active Learning in Medical Image Segmentation", "abstract": "Deep learning methods typically depend on the availability of labeled data, which is expensive and time-consuming to obtain. Active learning addresses such effort by prioritizing which samples are best to annotate in order to maximize the performance of the task model. While frameworks for active learning have been widely explored in the context of classification of natural images, they have been only sparsely used in medical image segmentation. The challenge resides in obtaining an uncertainty measure that reveals the best candidate data for annotation. This paper proposes Test-time Augmentation for Active Learning (TAAL), a novel semi-supervised active learning approach for segmentation that exploits the uncertainty information offered by data transformations. Our method applies cross-augmentation consistency during training and inference to both improve model learning in a semi-supervised fashion and identify the most relevant unlabeled samples to annotate next. In addition, our consistency loss uses a modified version of the JSD to further improve model performance. By relying on data transformations rather than on external modules or simple heuristics typically used in uncertainty-based strategies, TAAL emerges as a simple, yet powerful task-agnostic semi-supervised active learning approach applicable to the medical domain. Our results on a publicly-available dataset of cardiac images show that TAAL outperforms existing baseline methods in both fully-supervised and semi-supervised settings. Our implementation is publicly available on https://github.com/melinphd/TAAL."}}
{"id": "hp4zenPjVQa", "cdate": 1672531200000, "mdate": 1707234882132, "content": {"title": "Segmentation with mixed supervision: Confidence maximization helps knowledge distillation", "abstract": ""}}
{"id": "gVADMIkR32m", "cdate": 1672531200000, "mdate": 1707234882215, "content": {"title": "Mixup-Privacy: A simple yet effective approach for privacy-preserving segmentation", "abstract": "Privacy protection in medical data is a legitimate obstacle for centralized machine learning applications. Here, we propose a client-server image segmentation system which allows for the analysis of multi-centric medical images while preserving patient privacy. In this approach, the client protects the to-be-segmented patient image by mixing it to a reference image. As shown in our work, it is challenging to separate the image mixture to exact original content, thus making the data unworkable and unrecognizable for an unauthorized person. This proxy image is sent to a server for processing. The server then returns the mixture of segmentation maps, which the client can revert to a correct target segmentation. Our system has two components: 1) a segmentation network on the server side which processes the image mixture, and 2) a segmentation unmixing network which recovers the correct segmentation map from the segmentation mixture. Furthermore, the whole system is trained end-to-end. The proposed method is validated on the task of MRI brain segmentation using images from two different datasets. Results show that the segmentation accuracy of our method is comparable to a system trained on raw images, and outperforms other privacy-preserving methods with little computational overhead."}}
{"id": "fgmjgs7DeCB", "cdate": 1672531200000, "mdate": 1684269882154, "content": {"title": "Deep Neural Forest for Out-of-Distribution Detection of Skin Lesion Images", "abstract": "Deep learning methods have shown outstanding potential in dermatology for skin lesion detection and identification. However, they usually require annotations beforehand and can only classify lesion classes seen in the training set. Moreover, large-scale, open-sourced medical datasets normally have far fewer annotated classes than in real life, further aggravating the problem. This paper proposes a novel method called DNF-OOD, which applies a non-parametric deep forest-based approach to the problem of out-of-distribution (OOD) detection. By leveraging a maximum probabilistic routing strategy and over-confidence penalty term, the proposed method can achieve better performance on the task of detecting OOD skin lesion images, which is challenging due to the large intra-class variability in such images. We evaluate our OOD detection method on images from two large, publicly-available skin lesion datasets, ISIC2019 and DermNet, and compare it against recently-proposed approaches. Results demonstrate the potential of our DNF-OOD framework for detecting OOD skin images."}}
{"id": "_YGARIr-0b", "cdate": 1672531200000, "mdate": 1699249426107, "content": {"title": "ClusT3: Information Invariant Test-Time Training", "abstract": "Deep Learning models have shown remarkable performance in a broad range of vision tasks. However, they are often vulnerable against domain shifts at test-time. Test-time training (TTT) methods have been developed in an attempt to mitigate these vulnerabilities, where a secondary task is solved at training time simultaneously with the main task, to be later used as an self-supervised proxy task at test-time. In this work, we propose a novel unsupervised TTT technique based on the maximization of Mutual Information between multi-scale feature maps and a discrete latent representation, which can be integrated to the standard training as an auxiliary clustering task. Experimental results demonstrate competitive classification performance on different popular test-time adaptation benchmarks."}}
{"id": "VcNJ7xkrJV", "cdate": 1672531200000, "mdate": 1699249426108, "content": {"title": "TTTFlow: Unsupervised Test-Time Training with Normalizing Flow", "abstract": "A major problem of deep neural networks for image classification is their vulnerability to domain changes at test-time. Recent methods have proposed to address this problem with test-time training (TTT), where a two-branch model is trained to learn a main classification task and also a self-supervised task used to perform test-time adaptation. However, these techniques require defining a proxy task specific to the target application. To tackle this limitation, we propose TTTFlow: a Y-shaped architecture using an unsupervised head based on Normalizing Flows to learn the nor-mal distribution of latent features and detect domain shifts in test examples. At inference, keeping the unsupervised head fixed, we adapt the model to domain-shifted examples by maximizing the log likelihood of the Normalizing Flow. Our results show that our method can significantly improve the accuracy with respect to previous works."}}
