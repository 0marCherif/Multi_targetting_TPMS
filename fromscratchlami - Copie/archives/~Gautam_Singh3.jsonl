{"id": "KmjqFpmHupL", "cdate": 1672531200000, "mdate": 1681636278031, "content": {"title": "Object-Centric Slot Diffusion", "abstract": ""}}
{"id": "ZPHE4fht19t", "cdate": 1663850517858, "mdate": null, "content": {"title": "Neural Systematic Binder", "abstract": "The key to high-level cognition is believed to be the ability to systematically manipulate and compose knowledge pieces. While token-like structured knowledge representations are naturally provided in text, it is elusive how to obtain them for unstructured modalities such as scene images. In this paper, we propose a neural mechanism called Neural Systematic Binder or SysBinder for constructing a novel structured representation called Block-Slot Representation. In Block-Slot Representation, object-centric representations known as slots are constructed by composing a set of independent factor representations called blocks, to facilitate systematic generalization. SysBinder obtains this structure in an unsupervised way by alternatingly applying two different binding principles: spatial binding for spatial modularity across the full scene and factor binding for factor modularity within an object. SysBinder is a simple, deterministic, and general-purpose layer that can be applied as a drop-in module in any arbitrary neural network and on any modality.  In experiments, we find that SysBinder provides significantly better factor disentanglement within the slots than the conventional object-centric methods, including, for the first time, in visually complex scene images such as CLEVR-Tex. Furthermore, we demonstrate factor-level systematicity in controlled scene generation by decoding unseen factor combinations."}}
{"id": "eYfIM88MTUE", "cdate": 1652737770152, "mdate": null, "content": {"title": "Simple Unsupervised Object-Centric Learning for Complex and Naturalistic Videos", "abstract": "Unsupervised object-centric learning aims to represent the modular, compositional, and causal structure of a scene as a set of object representations and thereby promises to resolve many critical limitations of traditional single-vector representations such as poor systematic generalization. Although there have been many remarkable advances in recent years, one of the most critical problems in this direction has been that previous methods work only with simple and synthetic scenes but not with complex and naturalistic images or videos. In this paper, we propose STEVE, an unsupervised model for object-centric learning in videos. Our proposed model makes a significant advancement by demonstrating its effectiveness on various complex and naturalistic videos unprecedented in this line of research. Interestingly, this is achieved by neither adding complexity to the model architecture nor introducing a new objective or weak supervision. Rather, it is achieved by a surprisingly simple architecture that uses a transformer-based image decoder conditioned on slots and the learning objective is simply to reconstruct the observation. Our experiment results on various complex and naturalistic videos show significant improvements compared to the previous state-of-the-art."}}
{"id": "slUsKyzbuY", "cdate": 1640995200000, "mdate": 1681636278326, "content": {"title": "Illiterate DALL-E Learns to Compose", "abstract": ""}}
{"id": "Ozlj0wOioO0", "cdate": 1640995200000, "mdate": 1683897539501, "content": {"title": "Simple Unsupervised Object-Centric Learning for Complex and Naturalistic Videos", "abstract": "Unsupervised object-centric learning aims to represent the modular, compositional, and causal structure of a scene as a set of object representations and thereby promises to resolve many critical limitations of traditional single-vector representations such as poor systematic generalization. Although there have been many remarkable advances in recent years, one of the most critical problems in this direction has been that previous methods work only with simple and synthetic scenes but not with complex and naturalistic images or videos. In this paper, we propose STEVE, an unsupervised model for object-centric learning in videos. Our proposed model makes a significant advancement by demonstrating its effectiveness on various complex and naturalistic videos unprecedented in this line of research. Interestingly, this is achieved by neither adding complexity to the model architecture nor introducing a new objective or weak supervision. Rather, it is achieved by a surprisingly simple architecture that uses a transformer-based image decoder conditioned on slots and the learning objective is simply to reconstruct the observation. Our experiment results on various complex and naturalistic videos show significant improvements compared to the previous state-of-the-art."}}
{"id": "BhZ4NTin_2j", "cdate": 1640995200000, "mdate": 1681636278765, "content": {"title": "Neural Block-Slot Representations", "abstract": ""}}
{"id": "-V0nH1Wwct", "cdate": 1640995200000, "mdate": 1681636277940, "content": {"title": "Simple Unsupervised Object-Centric Learning for Complex and Naturalistic Videos", "abstract": ""}}
{"id": "h0OYV0We3oh", "cdate": 1632875700654, "mdate": null, "content": {"title": "Illiterate DALL-E Learns to Compose", "abstract": "Although DALL-E has shown an impressive ability of composition-based systematic generalization in image generation, it requires the dataset of text-image pairs and the compositionality is provided by the text. In contrast, object-centric representation models like the Slot Attention model learn composable representations without the text prompt. However, unlike DALL-E, its ability to systematically generalize for zero-shot generation is significantly limited. In this paper, we propose a simple but novel slot-based autoencoding architecture, called SLATE, for combining the best of both worlds: learning object-centric representations that allow systematic generalization in zero-shot image generation without text. As such, this model can also be seen as an illiterate DALL-E model. Unlike the pixel-mixture decoders of existing object-centric representation models, we propose to use the Image GPT decoder conditioned on the slots for capturing complex interactions among the slots and pixels. In experiments, we show that this simple and easy-to-implement architecture not requiring a text prompt achieves significant improvement in in-distribution and out-of-distribution (zero-shot) image generation and qualitatively comparable or better slot-attention structure than the models based on mixture decoders."}}
{"id": "lq5txZRuf1M", "cdate": 1623601933977, "mdate": 1623601933977, "content": {"title": "Structured World Belief for Reinforcement Learning in POMDP", "abstract": "Object-centric world models provide structured representation  of  the  scene  and  can  be  an  important backbone in reinforcement learning and planning.  However, existing approaches suffer in partially-observable environments due to the lack of belief states.  In this paper, we propose Structured  World  Belief,  a  model  for  learning and inference of object-centric belief states.  Inferred  by  Sequential  Monte  Carlo  (SMC),  our belief states provide multiple object-centric scene hypotheses.  To synergize the benefits of SMC particles with object representations, we also pro-pose a new object-centric dynamics model that considers the inductive bias of object permanence.This enables tracking of object states even when they are invisible for a long time. To further facilitate object tracking in this regime, we allow our model to attend flexibly to any spatial location in the image which was restricted in previous models. In experiments, we show that object-centric belief provides a more accurate and robust performance for filtering and generation. Furthermore,we show the efficacy of structured world belief in improving the performance of reinforcement learning, planning and supervised reasoning."}}
{"id": "jEtrZVD4yBR", "cdate": 1609459200000, "mdate": 1681636278547, "content": {"title": "Illiterate DALL-E Learns to Compose", "abstract": ""}}
