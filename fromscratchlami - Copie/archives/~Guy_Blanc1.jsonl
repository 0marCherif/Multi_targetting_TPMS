{"id": "AYvLkPnDguL", "cdate": 1663850154630, "mdate": null, "content": {"title": "The power of choices in decision tree learning", "abstract": "We propose a simple and natural generalization of standard and empirically successful decision tree learning algorithms such as ID3, C4.5, and CART.   These classic algorithms, which have been central to machine learning for decades, are greedy in nature: they grow a decision tree by iteratively splitting on the \"best\" attribute.  We augment these algorithms with an additional greediness parameter $k$ and our resulting algorithm, Top-$k$, considers the $k$ best attributes as possible splits instead of just the single best attribute.\n\nWe demonstrate, theoretically and empirically, the power of this  simple generalization.  We first prove a sharp greediness hierarchy theorem showing that for every $k\\in \\mathbb{N}$, Top-$(k+1)$  can be much more powerful than Top-$k$: there are data distributions for which the former achieves accuracy $1-\\epsilon$, whereas the latter only achieves accuracy $\\frac{1}{2}+\\epsilon$.  We then show, through extensive experiments, that Top-$k$ compares favorably with the two main approaches to decision tree learning: classic greedy algorithms and more recent \"optimal decision tree\" algorithms.  On one hand, Top-$k$ consistently enjoys significant accuracy gains over the greedy algorithms across a wide range of benchmarks, at the cost of only a mild training slowdown.  On the other hand, Top-$k$ is markedly more scalable than optimal decision tree algorithms, and is able to handle dataset and feature set sizes that remain beyond the reach of these algorithms.  \n\nTaken together, our results highlight the  potential practical impact of the power of choices in decision tree learning."}}
{"id": "DV06vy74q92", "cdate": 1621630066506, "mdate": null, "content": {"title": "Provably efficient, succinct, and precise explanations", "abstract": "We consider the problem of explaining the predictions of an arbitrary blackbox model $f$: given query access to $f$ and an instance $x$, output a small set of $x$'s features that in conjunction essentially determines $f(x)$. We design an efficient algorithm with provable guarantees on the succinctness and precision of the explanations that it returns. Prior algorithms were either efficient but lacked such guarantees, or achieved such guarantees but were inefficient. \n  \nWe obtain our algorithm via a connection to the problem of {\\sl implicitly} learning decision trees.  The implicit nature of this learning task allows for efficient algorithms even when the complexity of~$f$ necessitates an intractably large surrogate decision tree.  We solve the implicit learning problem by bringing together techniques from learning theory, local computation algorithms, and complexity theory. \n  \nOur approach of \u201cexplaining by implicit learning\u201d shares elements of two previously disparate methods for post-hoc explanations, global and local explanations, and we make the case that it enjoys advantages of both."}}
{"id": "9UjRw5bqURS", "cdate": 1621630066506, "mdate": null, "content": {"title": "Provably efficient, succinct, and precise explanations", "abstract": "We consider the problem of explaining the predictions of an arbitrary blackbox model $f$: given query access to $f$ and an instance $x$, output a small set of $x$'s features that in conjunction essentially determines $f(x)$. We design an efficient algorithm with provable guarantees on the succinctness and precision of the explanations that it returns. Prior algorithms were either efficient but lacked such guarantees, or achieved such guarantees but were inefficient. \n  \nWe obtain our algorithm via a connection to the problem of {\\sl implicitly} learning decision trees.  The implicit nature of this learning task allows for efficient algorithms even when the complexity of~$f$ necessitates an intractably large surrogate decision tree.  We solve the implicit learning problem by bringing together techniques from learning theory, local computation algorithms, and complexity theory. \n  \nOur approach of \u201cexplaining by implicit learning\u201d shares elements of two previously disparate methods for post-hoc explanations, global and local explanations, and we make the case that it enjoys advantages of both."}}
{"id": "ByERUi-uWr", "cdate": 1514764800000, "mdate": null, "content": {"title": "Adaptive Sampled Softmax with Kernel Based Sampling", "abstract": "Softmax is the most commonly used output function for multiclass problems and is widely used in areas such as vision, natural language processing, and recommendation. A softmax model has linear cos..."}}
