{"id": "DQLfcXGryn_", "cdate": 1546300800000, "mdate": null, "content": {"title": "Large-Scale Training Framework for Video Annotation.", "abstract": "Video is one of the richest sources of information available online but extracting deep insights from video content at internet scale is still an open problem, both in terms of depth and breadth of understanding, as well as scale. Over the last few years, the field of video understanding has made great strides due to the availability of large-scale video datasets and core advances in image, audio, and video modeling architectures. However, the state-of-the-art architectures on small scale datasets are frequently impractical to deploy at internet scale, both in terms of the ability to train such deep networks on hundreds of millions of videos, and to deploy them for inference on billions of videos. In this paper, we present a MapReduce-based training framework, which exploits both data parallelism and model parallelism to scale training of complex video models. The proposed framework uses alternating optimization and full-batch fine-tuning, and supports large Mixture-of-Experts classifiers with hundreds of thousands of mixtures, which enables a trade-off between model depth and breadth, and the ability to shift model capacity between shared (generalization) layers and per-class (specialization) layers. We demonstrate that the proposed framework is able to reach state-of-the-art performance on the largest public video datasets, YouTube-8M and Sports-1M, and can scale to 100 times larger datasets."}}
{"id": "S1buoVWdbr", "cdate": 1514764800000, "mdate": null, "content": {"title": "Collaborative Deep Metric Learning for Video Understanding", "abstract": "The goal of video understanding is to develop algorithms that enable machines understand videos at the level of human experts. Researchers have tackled various domains including video classification, search, personalized recommendation, and more. However, there is a research gap in combining these domains in one unified learning framework. Towards that, we propose a deep network that embeds videos using their audio-visual content, onto a metric space which preserves video-to-video relationships. Then, we use the trained embedding network to tackle various domains including video classification and recommendation, showing significant improvements over state-of-the-art baselines. The proposed approach is highly scalable to deploy on large-scale video sharing platforms like YouTube."}}
{"id": "S1NPtngu-S", "cdate": 1388534400000, "mdate": null, "content": {"title": "Exploring the Relative Role of Bottom-up and Top-down Information in Phoneme Learning", "abstract": "We test both bottom-up and top-down approaches in learning the phonemic status of the sounds of English and Japanese. We used large corpora of spontaneous speech to provide the learner with an input that models both the linguistic properties and statistical regularities of each language. We found both approaches to help discriminate between allophonic and phonemic contrasts with a high degree of accuracy, although top-down cues proved to be effective only on an interesting subset of the data."}}
{"id": "MIiQCsr0f1", "cdate": 1356998400000, "mdate": null, "content": {"title": "A summary of the 2012 JHU CLSP workshop on zero resource speech technologies and models of early language acquisition.", "abstract": "We summarize the accomplishments of a multi-disciplinary workshop exploring the computational and scientific issues surrounding zero resource (unsupervised) speech technologies and related models of early language acquisition. Centered around the tasks of phonetic and lexical discovery, we consider unified evaluation metrics, present two new approaches for improving speaker independence in the absence of supervision, and evaluate the application of Bayesian word segmentation algorithms to automatic subword unit tokenizations. Finally, we present two strategies for integrating zero resource techniques into supervised settings, demonstrating the potential of unsupervised methods to improve mainstream technologies."}}
{"id": "m-zyUhTecB-", "cdate": 1293840000000, "mdate": null, "content": {"title": "Learning and inference algorithms for partially observed structured switching vector autoregressive models.", "abstract": "We present learning and inference algorithms for a versatile class of partially observed vector autoregressive (VAR) models for multivariate time-series data. VAR models can capture wide variety of temporal dynamics in a continuous multidimensional signal. Given a sequence of observations to be modeled by a VAR model, it is possible to estimate its parameters in closed form by solving a least squares problem. For high dimensional observations, the state space representation of a linear system is often invoked. One advantage of doing so is that we model the dynamics of a low dimensional hidden state instead of the observations, which results in robust estimation of the dynamical system parameters. The commonly used approach is to project the high dimensional observation to the low dimensional state space using a KL transform. In this article, we propose a novel approach to automatically discover the low dimensional dynamics in a switching VAR model by imposing discriminative structure on the model parameters. We demonstrate its efficacy via significant improvements in gesture recognition accuracy over a standard hidden Markov model, which does not take the state-conditional dynamics of the observations into account, on a bench-top suturing task."}}
{"id": "JdyuWg8U5J", "cdate": 1293840000000, "mdate": null, "content": {"title": "Dirichlet Mixture Models of neural net posteriors for HMM-based speech recognition.", "abstract": "In this paper, we present a novel technique for modeling the posterior probability estimates obtained from a neural net work directly in the HMM framework using the Dirichlet Mixture Models (DMMs). Since posterior probability vectors lie on a probability simplex their distribution can be modeled using DMMs. Being in an exponential family, the parameters of DMMs can be estimated in an efficient manner. Conventional approaches like TANDEM attempt to gaussianize the posteriors by suitable transforms and model them using Gaussian Mixture Models (GMMs). This requires more number of parameters as it does not exploit the fact that the probability vectors lie on a simplex. We demonstrate through TIMIT phoneme recognition experiments that the proposed technique outperforms the conventional TANDEM approach."}}
{"id": "8Feg2fBTAqH", "cdate": 1293840000000, "mdate": null, "content": {"title": "Stepwise Optimal Subspace Pursuit for Improving Sparse Recovery.", "abstract": "We propose a new iterative algorithm to reconstruct an unknown sparse signal x from a set of projected measurements y = \u03a6x . Unlike existing methods, which rely crucially on the near orthogonality of the sampling matrix \u03a6 , our approach makes stepwise optimal updates even when the columns of \u03a6 are not orthogonal. We invoke a block-wise matrix inversion formula to obtain a closed-form expression for the increase (reduction) in the L <sub xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">2</sub> -norm of the residue obtained by removing (adding) a single element from (to) the presumed support of x . We then use this expression to design a computationally tractable algorithm to search for the nonzero components of x . We show that compared to currently popular sparsity seeking matching pursuit algorithms, each step of the proposed algorithm is locally optimal with respect to the actual objective function. We demonstrate experimentally that the algorithm significantly outperforms conventional techniques in recovering sparse signals whose nonzero values have exponentially decaying magnitudes or are distributed N(0,1) ."}}
{"id": "_8kaIDjtPc", "cdate": 1262304000000, "mdate": null, "content": {"title": "Active learning and semi-supervised learning for speech recognition: A unified framework using the global entropy reduction maximization criterion.", "abstract": "We propose a unified global entropy reduction maximization (GERM) framework for active learning and semi-supervised learning for speech recognition. Active learning aims to select a limited subset of utterances for transcribing from a large amount of un-transcribed utterances, while semi-supervised learning addresses the problem of selecting right transcriptions for un-transcribed utterances, so that the accuracy of the automatic speech recognition system can be maximized. We show that both the traditional confidence-based active learning and semi-supervised learning approaches can be improved by maximizing the lattice entropy reduction over the whole dataset. We introduce our criterion and framework, show how the criterion can be simplified and approximated, and describe how these approaches can be combined. We demonstrate the effectiveness of our new framework and algorithm with directory assistance data collected under the real usage scenarios and show that our GERM based active learning and semi-supervised learning algorithms consistently outperform the confidence-based counterparts by a significant margin. Using our new active learning algorithm cuts the number of utterances needed for transcribing by 50% to achieve the same recognition accuracy obtained using the confidence-based active learning approach, and by 60% compared to the random sampling approach. Using our new semi-supervised algorithm we can determine the cutoff point in determining which utterance-transcription pair to use in a principled way by demonstrating that the point it finds is very close to the achievable peak point. Previous article in issue Next article in issue"}}
{"id": "VzDQcEQhWYm", "cdate": 1230768000000, "mdate": null, "content": {"title": "$$-extension Hidden Markov Models and Weighted Transducers for Machine Transliteration.", "abstract": "Balakrishnan Varadarajan, Delip Rao. Proceedings of the 2009 Named Entities Workshop: Shared Task on Transliteration (NEWS 2009). 2009."}}
{"id": "TFRoLoIxlSi", "cdate": 1230768000000, "mdate": null, "content": {"title": "Using collective information in semi-supervised learning for speech recognition.", "abstract": "Training accurate acoustic models typically requires a large amount of transcribed data, which can be expensive to obtain. In this paper, we describe a novel semi-supervised learning algorithm for automatic speech recognition. The algorithm determines whether a hypothesized transcription should be used in the training by taking into consideration collective information from all utterances available instead of solely based on the confidence from that utterance itself. It estimates the expected entropy reduction each utterance and transcription pair may cause to the whole unlabeled dataset and choose the ones with the positive gains. We compare our algorithm with existing confidence-based semi-supervised learning algorithm and show that the former can consistently outperform the latter when the same amount of utterances is selected into the training set. We also indicate that our algorithm may determine the cutoff-point in a principled way by demonstrating that the point it finds is very close to the achievable peak point."}}
