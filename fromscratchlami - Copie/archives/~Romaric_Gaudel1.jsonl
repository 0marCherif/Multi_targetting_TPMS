{"id": "k90jj1q0kv", "cdate": 1640995200000, "mdate": 1681652651322, "content": {"title": "Unimodal Mono-Partite Matching in a Bandit Setting", "abstract": ""}}
{"id": "IWgaPH2JgUu", "cdate": 1640995200000, "mdate": 1672669594673, "content": {"title": "UniRank: Unimodal Bandit Algorithms for Online Ranking", "abstract": ""}}
{"id": "3-ZV6L6FUsi", "cdate": 1640995200000, "mdate": 1650272231917, "content": {"title": "s-LIME: Reconciling Locality and Fidelity in Linear Explanations", "abstract": "The benefit of locality is one of the major premises of LIME, one of the most prominent methods to explain black-box machine learning models. This emphasis relies on the postulate that the more locally we look at the vicinity of an instance, the simpler the black-box model becomes, and the more accurately we can mimic it with a linear surrogate. As logical as this seems, our findings suggest that, with the current design of LIME, the surrogate model may degenerate when the explanation is too local, namely, when the bandwidth parameter                                                               $$\\sigma $$                             tends to zero. Based on this observation, the contribution of this paper is twofold. Firstly, we study the impact of both the bandwidth and the training vicinity on the fidelity and semantics of LIME explanations. Secondly, and based on our findings, we propose s-LIME, an extension of LIME that reconciles fidelity and locality."}}
{"id": "pW8RH_SQgqG", "cdate": 1609459200000, "mdate": null, "content": {"title": "Bandit Algorithm for both Unknown Best Position and Best Item Display on Web Pages", "abstract": "Multiple-play bandits aim at displaying relevant items at relevant positions on a web page. We introduce a new bandit-based algorithm, PB-MHB, for online recommender systems which uses the Thompson sampling framework with Metropolis-Hastings approximation. This algorithm handles a display setting governed by the position-based model. Our sampling method does not require as input the probability of a user to look at a given position in the web page which is difficult to obtain in some applications. Experiments on simulated and real datasets show that our method, with fewer prior information, delivers better recommendations than state-of-the-art algorithms."}}
{"id": "54167X_BaoU", "cdate": 1609459200000, "mdate": 1650272231881, "content": {"title": "Parametric Graph for Unimodal Ranking Bandit", "abstract": "We tackle the online ranking problem of assigning $L$ items to $K$ positions on a web page in order to maximize the number of user clicks. We propose an original algorithm, easy to implement and wi..."}}
{"id": "SHNcrThtRUm", "cdate": 1483228800000, "mdate": 1650272231814, "content": {"title": "Kernalized Collaborative Contextual Bandits", "abstract": ""}}
{"id": "x_yO-miDW6", "cdate": 1451606400000, "mdate": 1650272231863, "content": {"title": "Hybrid Recommender System based on Autoencoders", "abstract": "A standard model for Recommender Systems is the Matrix Completion setting: given partially known matrix of ratings given by users (rows) to items (columns), infer the unknown ratings. In the last decades, few attempts where done to handle that objective with Neural Networks, but recently an architecture based on Autoencoders proved to be a promising approach. In current paper, we enhanced that architecture (i) by using a loss function adapted to input data with missing values, and (ii) by incorporating side information. The experiments demonstrate that while side information only slightly improve the test error averaged on all users/items, it has more impact on cold users/items."}}
{"id": "jXDWLicHHDn", "cdate": 1451606400000, "mdate": null, "content": {"title": "Sequential Collaborative Ranking Using (No-)Click Implicit Feedback", "abstract": "We study Recommender Systems in the context where they suggest a list of items to users. Several crucial issues are raised in such a setting: first, identify the relevant items to recommend; second, account for the feedback given by the user after he clicked and rated an item; third, since new feedback arrive into the system at any moment, incorporate such information to improve future recommendations. In this paper, we take these three aspects into consideration and present an approach handling click/no-click feedback information. Experiments on real-world datasets show that our approach outperforms state of the art algorithms."}}
{"id": "V29qlrH1E7J", "cdate": 1451606400000, "mdate": 1650272231825, "content": {"title": "Scalable Explore-Exploit Collaborative filtering", "abstract": "Recommender Systems (RS) aim at suggesting to users one or several items in which they might have interest. These systems have to update themselves as users provide new ratings, but also as new users/items enter the system. While this adaptation makes recommendation an intrinsically sequential task, most researches about RS based on Collaborative Filtering are omitting this fact, as well as the ensuing exploration/exploitation dilemma: should the system recommend items which bring more information about the users (explore), or should it try to get an immediate feedback as high as possible (exploit)? Recently, a few approaches were proposed to solve that dilemma, but they do not meet requirements to scale up to real life applications which is a crucial point as the number of items available on RS and the number of users in these systems explode. In this paper, we present an explore-exploit Collaborative Filtering RS which is both efficient and scales well. Extensive experiments on some of the largest available real-world datasets show that the proposed approach performs accurate personalized recommendations in less than a millisecond per recommendation, which makes it a good candidate for true applications."}}
{"id": "DcM9sWvOxZm", "cdate": 1451606400000, "mdate": 1650272231850, "content": {"title": "Large-Scale Bandit Recommender System", "abstract": "The main target of Recommender Systems (RS) is to propose to users one or several items in which they might be interested. However, as users provide more feedback, the recommendation process has to take these new data into consideration. The necessity of this update phase makes recommendation an intrinsically sequential task. A few approaches were recently proposed to address this issue, but they do not meet the need to scale up\u00a0to real life applications. In this paper, we present a Collaborative Filtering RS method based on Matrix Factorization and Multi-Armed Bandits. This approach aims at good recommendations with a narrow computation time. Several experiments on large datasets show that the proposed approach performs personalized recommendations in less than a millisecond per recommendation."}}
