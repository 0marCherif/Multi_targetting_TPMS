{"id": "PMxFPDdxavB", "cdate": 1640995200000, "mdate": 1673148164932, "content": {"title": "PanoSynthVR: Toward Light-weight 360-Degree View Synthesis from a Single Panoramic Input", "abstract": ""}}
{"id": "jSQ8oOLnd8e", "cdate": 1609459200000, "mdate": 1631055047988, "content": {"title": "Evaluation of MRI Denoising Methods Using Unsupervised Learning", "abstract": "In this paper we evaluate two unsupervised approaches to denoise Magnetic Resonance Images (MRI) in the complex image space using the raw information that k-space holds. The first method is based on Stein\u2019s Unbiased Risk Estimator, while the second approach is based on a blindspot network, which limits the network\u2019s receptive field. Both methods are tested on two different datasets, one containing real knee MRI and the other consists of synthetic brain MRI. These datasets contain information about the complex image space which will be used for denoising purposes. Both networks are compared against a state-of-the-art algorithm, Non-Local Means (NLM) using quantitative and qualitative measures. For most given metrics and qualitative measures, both networks outperformed NLM, and they prove to be reliable denoising methods."}}
{"id": "XGy8Kfu_1DH", "cdate": 1609459200000, "mdate": 1631055048056, "content": {"title": "View Synthesis In Casually Captured Scenes Using a Cylindrical Neural Radiance Field With Exposure Compensation", "abstract": "We extend Neural Radiance Fields (NeRF) with a cylindrical parameterization that enables rendering photorealistic novel views of 360\u00b0 outward facing scenes. We further introduce a learned exposure compensation parameter to account for the varying exposure in training images that may occur from casually capturing a scene. We evaluate our method on a variety of 360\u00b0 casually captured scenes."}}
{"id": "U8o6uqCfsFt", "cdate": 1609459200000, "mdate": 1631055048057, "content": {"title": "PanoSynthVR: View Synthesis From A Single Input Panorama with Multi-Cylinder Images", "abstract": "We introduce a method to automatically convert a single panoramic input into a multi-cylinder image representation that supports real-time, free-viewpoint view synthesis for virtual reality. We apply an existing convolutional neural network trained on pinhole images to a cylindrical panorama with wrap padding to ensure agreement between the left and right edges. The network outputs a stack of semi-transparent panoramas at varying depths which can be easily rendered and composited with over blending. Initial experiments show that the method produces convincing parallax and cleaner object boundaries than a textured mesh representation."}}
{"id": "5Yq3N4UZG4", "cdate": 1609459200000, "mdate": 1631055048044, "content": {"title": "Self-Supervised Poisson-Gaussian Denoising", "abstract": "We extend the blindspot model for self-supervised de-noising to handle Poisson-Gaussian noise and introduce an improved training scheme that avoids hyperparameters and adapts the denoiser to the test data. Self-supervised models for denoising learn to denoise from only noisy data and do not require corresponding clean images, which are difficult or impossible to acquire in some application areas of interest such as low-light microscopy. We introduce a new training strategy to handle Poisson-Gaussian noise which is the standard noise model for microscope images. Our new strategy eliminates hyperparameters from the loss function, which is important in a self-supervised regime where no ground truth data is available to guide hyperparameter tuning. We show how our denoiser can be adapted to the test data to improve performance. Our evaluations on microscope image denoising benchmarks validate our approach."}}
{"id": "xoE3egySxf", "cdate": 1577836800000, "mdate": 1631055048043, "content": {"title": "P1AC: Revisiting Absolute Pose From a Single Affine Correspondence", "abstract": "We introduce a novel solution to the problem of estimating the pose of a calibrated camera given a single observation of an oriented point and an affine correspondence to a reference image. Affine correspondences have traditionally been used to improve feature matching over wide baselines; however, little previous work has considered the use of such correspondences for absolute camera pose computation. The advantage of our approach (P1AC) is that it requires only a single correspondence in the minimal case in comparison to the traditional point-based approach (P3P) which requires at least three points. Our method removes the limiting assumptions made in previous work and provides a general solution that is applicable to large-scale image-based localization. Our evaluation on synthetic data shows that our approach is numerically stable and more robust to point observation noise than P3P. We also evaluate the application of our approach for large-scale image-based localization and demonstrate a practical reduction in the number of iterations and computation time required to robustly localize an image."}}
{"id": "un4z32Dug7", "cdate": 1577836800000, "mdate": 1631055047990, "content": {"title": "The Overlooked Elephant of Object Detection: Open Set", "abstract": "Even though object detection is a popular area of research that has found considerable applications in the real world, it has some fundamental aspects that have never been formally discussed and experimented. One of the core aspects of evaluating object detectors has been the ability to avoid false detections. While major datasets like PASCAL VOC or MSCOCO extensively test the detectors on their ability to avoid false positives, they do not differentiate between their closed-set and open-set performance. Despite systems being trained to reject everything other than the classes of interest, unknown objects from the open world end up being incorrectly detected as known objects, often with very high confidence. This paper is the first to formalize the problem of open-set object detection and propose the first open-set object detection protocol. Moreover, the paper provides a new evaluation metric to analyze the performance of some state-of-the-art detectors and discusses their performance differences."}}
{"id": "iBGSLjuYXu5", "cdate": 1577836800000, "mdate": 1631055047990, "content": {"title": "Multi-camera Motion Estimation with Affine Correspondences", "abstract": "We present a study of minimal-case motion estimation with affine correspondences and introduce a new solution for multi-camera motion estimation with affine correspondences. Ego-motion estimation using one or more cameras is a well-studied topic with applications in 3D reconstruction and mobile robotics. Most feature-based motion estimation techniques use point correspondences. Recently, several researchers have developed novel epipolar constraints using affine correspondences. In this paper, we extend the epipolar constraint on affine correspondences to the multi-camera setting and develop and evaluate a novel minimal solver using this new constraint. Our solver uses six affine correspondences in the minimal case, which is a significant improvement over the point-based version that requires seventeen point correspondences. Experiments on synthetic and real data show that, in comparison to the point-based solver, our affine solver effectively reduces the number of RANSAC iterations needed for motion estimation while maintaining comparable accuracy."}}
{"id": "dFzHM50l9-T", "cdate": 1577836800000, "mdate": 1631055048064, "content": {"title": "CasualVRVideos: VR videos from casual stationary videos", "abstract": "Thanks to the ubiquity of devices capable of recording and playing back video, the amount of video files is growing at a rapid rate. Most of us have now video recordings of major events in our lives. However, until today, these videos are captured mainly in 2D and are mostly used for screen-based video replay. Currently there is no way for watching them in more immersive environments such as on a VR headset. They are simply not optimized for playback in stereoscopic displays or even tracked Virtual Reality devices.\n                                                    \n                                                    \n                                                        In this work, we present CasualVRVideos, a first approach that works towards solving these issues by extracting spatial information from video footage recorded in 2D, so that it can later be played back in VR displays to increase the immersion. We focus in particular on the challenging scenario when the camera itself is not moving."}}
{"id": "QETizYLRZMb", "cdate": 1577836800000, "mdate": 1631055048057, "content": {"title": "Unsupervised Learning of Depth and Ego-Motion from Cylindrical Panoramic Video with Applications for Virtual Reality", "abstract": "We introduce a convolutional neural network model for unsupervised learning of depth and ego-motion from cylindrical panoramic video. Panoramic depth estimation is an important technology for applications such as virtual reality, 3D modeling, and autonomous robotic navigation. In contrast to previous approaches for applying convolutional neural networks to panoramic imagery, we use the cylindrical panoramic projection which allows for the use of the traditional CNN layers such as convolutional filters and max pooling without modification. Our evaluation of synthetic and real data shows that unsupervised learning of depth and ego-motion on cylindrical panoramic images can produce high-quality depth maps and that an increased field-of-view improves ego-motion estimation accuracy. We create two new datasets to evaluate our approach: a synthetic dataset created using the CARLA simulator, and Headcam, a novel dataset of panoramic video collected from a helmet-mounted camera while biking in an urban setting. We also apply our network to the problem of converting monocular panoramas to stereo panoramas."}}
