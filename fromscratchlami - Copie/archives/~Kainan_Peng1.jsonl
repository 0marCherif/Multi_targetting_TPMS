{"id": "ma7-vky9MN9", "cdate": 1621560721936, "mdate": null, "content": {"title": "ClariNet: Parallel Wave Generation in End-to-End Text-to-Speech", "abstract": "In this work, we propose a new solution for parallel wave generation by WaveNet. In contrast to parallel WaveNet, we distill a Gaussian inverse autoregressive flow from the autoregressive WaveNet by minimizing a regularized KL divergence between their highly-peaked output distributions. Our method computes the KL divergence in closed-form, which simplifies the training algorithm and provides very efficient distillation. In addition, we introduce the first text-to-wave neural architecture for speech synthesis, which is fully convolutional and enables fast end-to-end training from scratch. It significantly outperforms the previous pipeline that connects a text-to-spectrogram model to a separately trained WaveNet. We also successfully distill a parallel waveform synthesizer conditioned on the hidden representation in this end-to-end model."}}
{"id": "HFhlEpLAGlL", "cdate": 1577836800000, "mdate": null, "content": {"title": "WaveFlow: A Compact Flow-based Model for Raw Audio", "abstract": "In this work, we propose WaveFlow, a small-footprint generative flow for raw audio, which is directly trained with maximum likelihood. It handles the long-range structure of 1-D waveform with a dil..."}}
{"id": "83TqgtmvjlI", "cdate": 1577836800000, "mdate": null, "content": {"title": "Non-Autoregressive Neural Text-to-Speech", "abstract": "In this work, we propose ParaNet, a non-autoregressive seq2seq model that converts text to spectrogram. It is fully convolutional and brings 46.7 times speed-up over the lightweight Deep Voice 3 at..."}}
{"id": "2N08P4lKo7oL", "cdate": 1577836800000, "mdate": 1661382801618, "content": {"title": "Incremental Text-to-Speech Synthesis with Prefix-to-Prefix Framework", "abstract": ""}}
{"id": "BJeFQ0NtPS", "cdate": 1569439264737, "mdate": null, "content": {"title": "Parallel Neural Text-to-Speech", "abstract": "In this work, we first propose ParaNet, a non-autoregressive seq2seq model that converts text to spectrogram. It is fully convolutional and obtains 46.7 times speed-up over Deep Voice 3 at synthesis while maintaining comparable speech quality using a WaveNet vocoder. ParaNet also produces stable alignment between text and speech on the challenging test sentences by iteratively improving the attention in a layer-by-layer manner. Based on ParaNet, we build the first fully parallel neural text-to-speech system using parallel neural vocoders, which can synthesize speech from text through a single feed-forward pass.  We investigate several parallel vocoders within the TTS system, including variants of IAF vocoders and bipartite flow vocoder."}}
{"id": "lfZqgkvQ4T3", "cdate": 1546300800000, "mdate": null, "content": {"title": "WaveFlow: A Compact Flow-based Model for Raw Audio", "abstract": "In this work, we propose WaveFlow, a small-footprint generative flow for raw audio, which is directly trained with maximum likelihood. It handles the long-range structure of 1-D waveform with a dilated 2-D convolutional architecture, while modeling the local variations using expressive autoregressive functions. WaveFlow provides a unified view of likelihood-based models for 1-D data, including WaveNet and WaveGlow as special cases. It generates high-fidelity speech as WaveNet, while synthesizing several orders of magnitude faster as it only requires a few sequential steps to generate very long waveforms with hundreds of thousands of time-steps. Furthermore, it can significantly reduce the likelihood gap that has existed between autoregressive models and flow-based models for efficient synthesis. Finally, our small-footprint WaveFlow has only 5.91M parameters, which is 15$\\times$ smaller than WaveGlow. It can generate 22.05 kHz high-fidelity audio 42.6$\\times$ faster than real-time (at a rate of 939.3 kHz) on a V100 GPU without engineered inference kernels."}}
{"id": "keXPW6HYiN", "cdate": 1546300800000, "mdate": null, "content": {"title": "Multi-Speaker End-to-End Speech Synthesis", "abstract": "In this work, we extend ClariNet (Ping et al., 2019), a fully end-to-end speech synthesis model (i.e., text-to-wave), to generate high-fidelity speech from multiple speakers. To model the unique characteristic of different voices, low dimensional trainable speaker embeddings are shared across each component of ClariNet and trained together with the rest of the model. We demonstrate that the multi-speaker ClariNet outperforms state-of-the-art systems in terms of naturalness, because the whole model is jointly optimized in an end-to-end manner."}}
{"id": "k17YeYuESM", "cdate": 1546300800000, "mdate": 1681669558249, "content": {"title": "ClariNet: Parallel Wave Generation in End-to-End Text-to-Speech", "abstract": "In this work, we propose a new solution for parallel wave generation by WaveNet. In contrast to parallel WaveNet (van Oord et al., 2018), we distill a Gaussian inverse autoregressive flow from the autoregressive WaveNet by minimizing a regularized KL divergence between their highly-peaked output distributions. Our method computes the KL divergence in closed-form, which simplifies the training algorithm and provides very efficient distillation. In addition, we introduce the first text-to-wave neural architecture for speech synthesis, which is fully convolutional and enables fast end-to-end training from scratch. It significantly outperforms the previous pipeline that connects a text-to-spectrogram model to a separately trained WaveNet (Ping et al., 2018). We also successfully distill a parallel waveform synthesizer conditioned on the hidden representation in this end-to-end model."}}
{"id": "h7Ns4AJIsSp", "cdate": 1546300800000, "mdate": 1681669558181, "content": {"title": "Parallel Neural Text-to-Speech", "abstract": "In this work, we propose ParaNet, a non-autoregressive seq2seq model that converts text to spectrogram. It is fully convolutional and brings 46.7 times speed-up over the lightweight Deep Voice 3 at synthesis, while obtaining reasonably good speech quality. ParaNet also produces stable alignment between text and speech on the challenging test sentences by iteratively improving the attention in a layer-by-layer manner. Furthermore, we build the parallel text-to-speech system and test various parallel neural vocoders, which can synthesize speech from text through a single feed-forward pass. We also explore a novel VAE-based approach to train the inverse autoregressive flow (IAF) based parallel vocoder from scratch, which avoids the need for distillation from a separately trained WaveNet as previous work."}}
{"id": "JsxfzPIvrhi", "cdate": 1546300800000, "mdate": null, "content": {"title": "Incremental Text-to-Speech Synthesis with Prefix-to-Prefix Framework", "abstract": "Text-to-speech synthesis (TTS) has witnessed rapid progress in recent years, where neural methods became capable of producing audios with high naturalness. However, these efforts still suffer from two types of latencies: (a) the {\\em computational latency} (synthesizing time), which grows linearly with the sentence length even with parallel approaches, and (b) the {\\em input latency} in scenarios where the input text is incrementally generated (such as in simultaneous translation, dialog generation, and assistive technologies). To reduce these latencies, we devise the first neural incremental TTS approach based on the recently proposed prefix-to-prefix framework. We synthesize speech in an online fashion, playing a segment of audio while generating the next, resulting in an $O(1)$ rather than $O(n)$ latency."}}
