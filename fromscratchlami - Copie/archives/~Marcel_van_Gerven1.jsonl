{"id": "v865WmUzAbe", "cdate": 1667337756697, "mdate": 1667337756697, "content": {"title": "Explainable deep learning: A field guide for the uninitiated", "abstract": "Deep neural networks (DNNs) are an indispensable machine learning tool despite the difficulty of diagnosing what aspects of a model\u2019s input drive its decisions. In countless real-world domains, from legislation and law enforcement to healthcare, such diagnosis is essential to ensure that DNN decisions are driven by aspects appropriate in the context of its use. The development of methods and studies enabling the explanation of a DNN\u2019s decisions has thus blossomed into an active and broad area of research. The field\u2019s complexity is exacerbated by competing definitions of what it means \u201cto explain\u201d the actions of a DNN and to evaluate an approach\u2019s \u201cability to explain\u201d. This article offers a field guide to explore the space of explainable deep learning for those in the AI/ML field who are uninitiated.The field guide: i) Introduces three simple dimensions defining the space of foundational methods that contribute to explainable deep learning, ii) discusses the evaluations for model explanations, iii) places explainability in the context of other related deep learning research areas, and iv) discusses user-oriented explanation design and future directions. We hope the guide is seen as a starting point for those embarking on this research field."}}
{"id": "hT1S68yza7", "cdate": 1663850330450, "mdate": null, "content": {"title": "Brain2GAN; Reconstructing perceived faces from the primate brain via StyleGAN3", "abstract": "Neural coding characterizes the relationship between stimuli and their corresponding neural responses. The usage of synthesized yet photorealistic reality by generative adversarial networks (GANs) allows for superior control over these data: the underlying feature representations that account for the semantics in synthesized data are known a priori and their relationship is perfect rather than approximated post-hoc by feature extraction models. We exploit this property in neural decoding of multi-unit activity responses that we recorded from the primate brain upon presentation with synthesized face images in a passive fixation experiment. The face reconstructions we acquired from brain activity were astonishingly similar to the originally perceived face stimuli. This provides strong evidence that the neural face manifold and the disentangled w-latent space conditioned on StyleGAN3 (rather than the z-latent space of arbitrary GANs or other feature representations we encountered so far) share how they represent the high-level semantics of the high-dimensional space of faces."}}
{"id": "zz_qjE6N1OF", "cdate": 1632875665094, "mdate": null, "content": {"title": "P4O: Efficient Deep Reinforcement Learning with Predictive Processing Proximal Policy Optimization", "abstract": "Advances in reinforcement learning (RL) often rely on massive compute resources and remain notoriously sample inefficient. In contrast, the human brain is able to efficiently learn effective control strategies using limited resources. This raises the question whether insights from neuroscience can be used to improve current RL methods. Predictive processing is a popular theoretical framework which maintains that the human brain is actively seeking to minimize surprise. We show that recurrent neural networks which predict their own sensory states can be leveraged to minimise surprise, yielding substantial gains in cumulative reward. Specifically, we present the Predictive Processing Proximal Policy Optimization (P4O) agent; an actor-critic reinforcement learning agent that applies predictive processing to a recurrent variant of the PPO algorithm by integrating a world model in its hidden state. P4O significantly outperforms a baseline recurrent variant of the PPO algorithm on multiple Atari games using a single GPU. It also outperforms other state-of-the-art agents given the same wall-clock time and exceeds human gamer performance on Seaquest, which is a particularly challenging environment in the Atari domain. Altogether, our work underscores how insights from the field of neuroscience may support the development of more capable and efficient artificial agents."}}
{"id": "vQ58AMOw4Il", "cdate": 1632875539046, "mdate": null, "content": {"title": "Hermitry Ratio: Evaluating the validity of perturbation methods for explainable deep learning", "abstract": "Perturbation methods are model-agnostic methods used to generate heatmaps to explain black-box algorithms such as deep neural networks. Perturbation methods work by perturbing the input image. However, by perturbing parts of the input image we are changing the underlying structure of the image, potentially generating out-of-distribution (OOD) data. This would violate one of the core assumptions in supervised learning, namely that the train and test data come from the same distribution. \nIn this study, we coin the term hermitry ratio to quantify the utility of perturbation methods by looking at the amount of OOD samples they produce. Using this metric, we observe the utility of XAI methods (Occlusion analysis, LIME, Anchor LIME, Kernel SHAP) for image classification models ResNet50, DensNet121 and MnasNet1.0 on three classes of the ImageNet dataset. Our results show that, to some extent, \\emph{all} four perturbation methods generate OOD data regardless of architecture or image class. Occlusion analysis primarily produces in-distribution perturbations while LIME produces mostly OOD perturbations. "}}
{"id": "G0RZ7_UzChu", "cdate": 1630721407150, "mdate": 1630721407150, "content": {"title": "A large single-participant fMRI dataset for probing brain responses to naturalistic stimuli in space and time", "abstract": "Visual and auditory representations in the human brain have been studied with encoding, decoding and reconstruction models. Representations from convolutional neural networks have been used as explanatory models for these stimulus-induced hierarchical brain activations. However, none of the fMRI datasets currently available has adequate amounts of data for sufficiently sampling their representations. We recorded a densely sampled large fMRI dataset (TR=700 ms) in a single individual exposed to spatiotemporal visual and auditory naturalistic stimuli (30 episodes of BBC\u2019s Doctor Who). The data consists of 120.830 whole-brain volumes (approx. 23 h) of single-presentation data (full episodes, training set) and 1.178 volumes (11 min) of repeated narrative short episodes (test set, 22 repetitions), recorded with fixation over a period of six months. This rich dataset can be used widely to study the way the brain represents audiovisual input across its sensory hierarchies."}}
{"id": "XSvq_sDDZh-", "cdate": 1630721245848, "mdate": 1630721245848, "content": {"title": "End-to-end neural system identification with neural information flow", "abstract": "Neural information flow (NIF) provides a novel approach for system identification in neuroscience. It models the neural computations in multiple brain regions and can be trained end-to-end via stochastic gradient descent from noninvasive data. NIF models represent neural information processing via a network of coupled tensors, each encoding the representation of the sensory input contained in a brain region. The elements of these tensors can be interpreted as cortical columns whose activity encodes the presence of a specific feature in a spatiotemporal location. Each tensor is coupled to the measured data specific to a brain region via low-rank observation models that can be decomposed into the spatial, temporal and feature receptive fields of a localized neuronal population. Both these observation models and the convolutional weights defining the information processing within regions are learned end-to-end by predicting the neural signal during sensory stimulation. We trained a NIF model on the activity of early visual areas using a large-scale fMRI dataset recorded in a single participant. We show that we can recover plausible visual representations and population receptive fields that are consistent with empirical findings."}}
{"id": "8TSLv9L2l0", "cdate": 1623413376660, "mdate": null, "content": {"title": "Automatic variational inference with cascading flows", "abstract": "The automation of probabilistic reasoning is one\nof the primary aims of machine learning. Recently, the confluence of variational inference and\ndeep learning has led to powerful and flexible automatic inference methods that can be trained by\nstochastic gradient descent. In particular, normalizing flows are highly parameterized deep models\nthat can fit arbitrarily complex posterior densities.\nHowever, normalizing flows struggle in highly\nstructured probabilistic programs as they need\nto relearn the forward-pass of the program. Automatic structured variational inference (ASVI)\nremedies this problem by constructing variational\nprograms that embed the forward-pass. Here, we\ncombine the flexibility of normalizing flows and\nthe prior-embedding property of ASVI in a new\nfamily of variational programs, which we named\ncascading flows. A cascading flows program interposes a newly designed highway flow architecture in between the conditional distributions\nof the prior program such as to steer it toward\nthe observed data. These programs can be constructed automatically from an input probabilistic program and can also be amortized automatically. We evaluate the performance of the new\nvariational programs in a series of structured inference problems. We find that cascading flows\nhave much higher performance than both normalizing flows and ASVI in a large set of structured\ninference problems."}}
{"id": "l_LGi6xeNT9", "cdate": 1601308350405, "mdate": null, "content": {"title": "The 3TConv: An Intrinsic Approach to Explainable 3D CNNs", "abstract": "Current deep learning architectures that make use of the 3D convolution (3DConv) achieve state-of-the-art results on action recognition benchmarks. However, the 3DConv does not easily lend itself to explainable model decisions. To this end we introduce a novel and intrinsic approach, whereby all the aspects of the 3DConv are rendered explainable. Our approach proposes the temporally factorized 3D convolution (3TConv) as an interpretable alternative to the regular 3DConv. In a 3TConv the 3D convolutional filter is obtained by learning a 2D filter and a set of temporal transformation parameters, resulting in a sparse filter requiring less parameters. We demonstrate that 3TConv learns temporal transformations that afford a direct interpretation by analyzing the transformation parameter statistics on a model level. Our experiments show that in the low-data regime the 3TConv outperforms 3DConv and R(2+1)D while containing up to 77\\% less parameters."}}
{"id": "qU-eouoIyAy", "cdate": 1601308101269, "mdate": null, "content": {"title": "Hyperrealistic neural decoding: Reconstruction of face stimuli from fMRI measurements via the GAN latent space", "abstract": "We introduce a new framework for hyperrealistic reconstruction of perceived naturalistic stimuli from brain recordings. To this end, we embrace the use of generative adversarial networks (GANs) at the earliest step of our neural decoding pipeline by acquiring functional magnetic resonance imaging data as subjects perceived face images created by the generator network of a GAN. Subsequently, we used a decoding approach to predict the latent state of the GAN from brain data. Hence, latent representations for stimulus (re-)generation are obtained, leading to state-of-the-art image reconstructions. Altogether, we have developed a highly promising approach for decoding sensory perception from brain activity and systematically analyzing neural information processing in the human brain."}}
