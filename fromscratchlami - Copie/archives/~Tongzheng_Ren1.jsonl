{"id": "Z1BobPmCTy", "cdate": 1676827084220, "mdate": null, "content": {"title": "Energy-based Predictive Representations for Partially Observed Reinforcement Learning", "abstract": "In real-world applications, handling partial observability is a common requirement for reinforcement learning algorithms, which is not captured by a Markov decision process (MDP). Although partially observable Markov decision processes (POMDPs) have been specifically designed to address this requirement, they present significant computational and statistical challenges in learning and planning. In this work, we introduce the \\emph{Energy-based Predictive Representation (EPR)} to provide a unified approach for designing practical reinforcement learning algorithms in both the MDP and POMDP settings. This framework enables coherent handling of \\emph{learning, exploration, and planning} tasks. The proposed framework leverages a powerful neural energy-based model to extract an adequate representation, allowing for efficient approximation of Q-functions. This representation facilitates the efficient computation of confidence, enabling the implementation of optimism or pessimism in planning when faced with uncertainty. Consequently, it effectively manages the trade-off between exploration and exploitation. Experimental investigations demonstrate that the proposed algorithm achieves state-of-the-art performance in both MDP and POMDP settings."}}
{"id": "_7zs6VepQ9", "cdate": 1672531200000, "mdate": 1681490066622, "content": {"title": "Markovian Sliced Wasserstein Distances: Beyond Independent Projections", "abstract": ""}}
{"id": "2Fb-h04mt5I", "cdate": 1663850242645, "mdate": null, "content": {"title": "Robustify Transformers with Robust Kernel Density Estimation", "abstract": "Recent advances in Transformer architecture have empowered its empirical success in various tasks across different domains. However, existing works mainly focus on improving the standard accuracy and computational cost, without considering the robustness of contaminated samples. Existing work (Nguyen et al, 2022, FourierFormer) has shown that the self-attention mechanism, which is the center of the Transformer architecture, can be viewed as a non-parametric estimator based on the well-known kernel density estimation (KDE). This motivates us to leverage the robust kernel density estimation (RKDE) in the self-attention mechanism, to alleviate the issue of the contamination of data by down-weighting the weight of bad samples in the estimation process. The modified self-attention mechanism can be incorporated into different Transformer variants. Empirical results on language modeling and image classification tasks demonstrate the effectiveness of this approach."}}
{"id": "aCCRmE3Pglv", "cdate": 1663850204832, "mdate": null, "content": {"title": "Energy-based Predictive Representation for Reinforcement Learning", "abstract": "In real world applications, it is usually necessary for a reinforcement learning algorithm to handle the partial observability beyond Markov decision processes (MDPs). Although the partially observable Markov decision process (POMDP) has been precisely motivated for this requirement, such a formulation raises significant computational and statistical hardness challenges in learning and planning. In this work, we introduce the Energy-based Predictive Representation (EPR), which leads to a unified framework for practical reinforcement learning algorithm design in both MDPs and POMDPs settings, to handle the learning, exploration, and planning in a coherent way. The proposed approach relies on the powerful neural energy-based model to extract sufficient representation, from which Q-functions can be efficiently approximated. With such a representation, we develop an efficient approach for computing confidence, which allows optimism/pessimism in the face of uncertainty to be efficiently implemented in planning, hence managing the exploration versus exploitation tradeoff. An experimental investigation shows that the proposed algorithm can surpass state-of-the-art performance in both MDP and POMDP settings in comparison to existing baselines."}}
{"id": "mQpmZVzXK1h", "cdate": 1663850202943, "mdate": null, "content": {"title": "Latent Variable Representation for Reinforcement Learning", "abstract": "Deep latent variable models have achieved significant empirical successes in model-based reinforcement learning (RL) due to their expressiveness in modeling complex transition dynamics. On the other hand, it remains unclear theoretically and empirically how latent variable models may facilitate learning, planning, and exploration to improve the sample efficiency of RL. In this paper, we provide a representation view of the latent variable models for state-action value functions, which allows both tractable variational learning algorithm and effective implementation of the optimism/pessimism principle in the face of uncertainty for exploration. In particular, we propose a computationally efficient planning algorithm with UCB exploration by incorporating kernel embeddings of latent variable models. Theoretically, we establish the sample complexity of the proposed approach in the online and offline settings. Empirically, we demonstrate superior performance over current state-of-the-art algorithms across various benchmarks."}}
{"id": "FBMLeaXpZN", "cdate": 1663850200172, "mdate": null, "content": {"title": "Spectral Decomposition Representation for Reinforcement Learning", "abstract": "Representation learning often plays a critical role in avoiding the curse of dimensionality in reinforcement learning. A representative class of algorithms exploits spectral decomposition of the stochastic transition dynamics to construct representations that enjoy strong theoretical properties in idealized settings. However, current spectral methods suffer from limited applicability because they are constructed for\nstate-only aggregation and are derived from a policy-dependent transition kernel, without considering the issue of exploration. To address these issues, we propose an alternative spectral method, Spectral Decomposition Representation (SPEDER), that extracts a state-action abstraction from the dynamics without inducing spurious dependence on the data collection policy, while also balancing the exploration-versus-exploitation trade-off during learning. A theoretical analysis establishes the sample efficiency of the proposed algorithm in both the online and offline settings. In addition, an experimental investigation demonstrates superior performance over current state-of-the-art algorithms across several RL benchmarks."}}
{"id": "CUOaVn6mYEj", "cdate": 1663850055953, "mdate": null, "content": {"title": "Hierarchical Sliced Wasserstein Distance", "abstract": "Sliced Wasserstein (SW) distance has been widely used in different application scenarios since it can be scaled to a large number of supports without suffering from the curse of dimensionality. The value of sliced Wasserstein distance is the average of transportation cost between one-dimensional representations (projections) of original measures that are obtained by Radon Transform (RT). Despite its efficiency in the number of supports, estimating the sliced Wasserstein requires a relatively large number of projections in high-dimensional settings. Therefore, for applications where the number of supports is relatively small compared with the dimension, e.g., several deep learning applications where the mini-batch approaches are utilized, the complexities from matrix multiplication of Radon Transform become the main computational bottleneck. To address this issue, we propose to derive projections by linearly and randomly combining a smaller number of projections which are named bottleneck projections. We explain the usage of these projections by introducing Hierarchical Radon Transform (HRT) which is constructed by applying  Radon Transform variants recursively. We then formulate the approach into a new metric between measures, named Hierarchical Sliced Wasserstein (HSW) distance. By proving the injectivity of HRT, we derive the metricity of HSW. Moreover, we investigate the theoretical properties of HSW including its connection to SW variants and its computational and sample complexities. Finally, we compare the computational cost and generative quality of HSW with the conventional SW on the task of deep generative modeling using various benchmark datasets including CIFAR10, CelebA, and Tiny ImageNet."}}
{"id": "SHg8gwUsqxc", "cdate": 1646077528446, "mdate": null, "content": {"title": "A Free Lunch from the Noise: Provable and Practical Exploration for Representation Learning", "abstract": "Representation learning lies at the heart of the em- pirical success of deep learning for dealing with the curse of dimensionality. However, the power of representation learning has not been fully exploited yet in reinforcement learning (RL), due to i), the trade-off between expressiveness and tractability; and ii), the coupling between exploration and rep- resentation learning. In this paper, we first reveal the fact that under some noise assumption in the stochastic control model, we can obtain the lin- ear spectral feature of its corresponding Markov transition operator in closed-form for free. Based on this observation, we propose Spectral Dynam- ics Embedding (SPEDE), which breaks the trade- off and completes optimistic exploration for rep- resentation learning by exploiting the structure of the noise. We provide rigorous theoretical analysis of SPEDE, and demonstrate the practical superior performance over the existing state-of-the-art em- pirical algorithms on several benchmarks.\n"}}
{"id": "vJb7e874Qm", "cdate": 1640995200000, "mdate": 1681490066369, "content": {"title": "Linear Bandit Algorithms with Sublinear Time Complexity", "abstract": ""}}
{"id": "rfUxUes7yRS", "cdate": 1640995200000, "mdate": 1681490066477, "content": {"title": "A free lunch from the noise: Provable and practical exploration for representation learning", "abstract": ""}}
