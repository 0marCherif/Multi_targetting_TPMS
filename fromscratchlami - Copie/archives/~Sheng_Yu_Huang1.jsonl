{"id": "JVoKzM_-lhz", "cdate": 1652737303162, "mdate": null, "content": {"title": "SPoVT: Semantic-Prototype Variational Transformer for Dense Point Cloud Semantic Completion", "abstract": "Point cloud completion is an active research topic for 3D vision and has been widely\nstudied in recent years. Instead of directly predicting missing point cloud from\nthe partial input, we introduce a Semantic-Prototype Variational Transformer\n(SPoVT) in this work, which takes both partial point cloud and their semantic\nlabels as the inputs for semantic point cloud object completion. By observing\nand attending at geometry and semantic information as input features, our SPoVT\nwould derive point cloud features and their semantic prototypes for completion\npurposes. As a result, our SPoVT not only performs point cloud completion with\nvarying resolution, it also allows manipulation of different semantic parts of an\nobject. Experiments on benchmark datasets would quantitatively and qualitatively\nverify the effectiveness and practicality of our proposed model.\n"}}
{"id": "xtokGUKShR", "cdate": 1640995200000, "mdate": 1683880225379, "content": {"title": "SPoVT: Semantic-Prototype Variational Transformer for Dense Point Cloud Semantic Completion", "abstract": "Point cloud completion is an active research topic for 3D vision and has been widelystudied in recent years. Instead of directly predicting missing point cloud fromthe partial input, we introduce a Semantic-Prototype Variational Transformer(SPoVT) in this work, which takes both partial point cloud and their semanticlabels as the inputs for semantic point cloud object completion. By observingand attending at geometry and semantic information as input features, our SPoVTwould derive point cloud features and their semantic prototypes for completionpurposes. As a result, our SPoVT not only performs point cloud completion withvarying resolution, it also allows manipulation of different semantic parts of anobject. Experiments on benchmark datasets would quantitatively and qualitativelyverify the effectiveness and practicality of our proposed model."}}
{"id": "6ipgXgVA04", "cdate": 1640995200000, "mdate": 1668640405218, "content": {"title": "Learning of 3D Graph Convolution Networks for Point Cloud Analysis", "abstract": "Point clouds are among the popular geometry representations in 3D vision. However, unlike 2D images with pixel-wise layouts, such representations containing unordered data points which make the processing and understanding the associated semantic information quite challenging. Although a number of previous works attempt to analyze point clouds and achieve promising performances, their performances would degrade significantly when data variations like shift and scale changes are presented. In this paper, we propose <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">3D graph convolution networks (3D-GCN)</i> , which uniquely learns 3D kernels with graph max-pooling mechanisms for extracting geometric features from point cloud data across different scales. We show that, with the proposed 3D-GCN, satisfactory shift and scale invariance can be jointly achieved. We show that 3D-GCN can be applied to point cloud classification and segmentation tasks, with ablation studies and visualizations verifying the design of 3D-GCN."}}
{"id": "4748uBrEfLp", "cdate": 1640995200000, "mdate": 1677642192476, "content": {"title": "3D-Selfcutmix: Self-Supervised Learning for 3D Point Cloud Analysis", "abstract": ""}}
{"id": "9vYRjdGf_T", "cdate": 1577836800000, "mdate": 1668640405219, "content": {"title": "Convolution in the Cloud: Learning Deformable Kernels in 3D Graph Convolution Networks for Point Cloud Analysis", "abstract": "Point clouds are among the popular geometry representations for 3D vision applications. However, without regular structures like 2D images, processing and summarizing information over these unordered data points are very challenging. Although a number of previous works attempt to analyze point clouds and achieve promising performances, their performances would degrade significantly when data variations like shift and scale changes are presented. In this paper, we propose 3D Graph Convolution Networks (3D-GCN), which is designed to extract local 3D features from point clouds across scales, while shift and scale-invariance properties are introduced. The novelty of our 3D-GCN lies in the definition of learnable kernels with a graph max-pooling mechanism. We show that 3D-GCN can be applied to 3D classification and segmentation tasks, with ablation studies and visualizations verifying the design of 3D-GCN."}}
