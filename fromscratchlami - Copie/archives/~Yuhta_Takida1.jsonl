{"id": "WqW7tC32v8N", "cdate": 1664310938091, "mdate": null, "content": {"title": "Regularizing Score-based Models with Score Fokker-Planck Equations", "abstract": "Score-based generative models learn a family of noise-conditional score functions corresponding to the data density perturbed with increasingly large amounts of noise. These pertubed data densities are tied together by the Fokker-Planck equation (FPE), a PDE governing the spatial-temporal evolution of a density undergoing a diffusion process. In this work, we derive a corresponding equation characterizing the noise-conditional scores of the perturbed data densities (i.e., their gradients), termed the score FPE. Surprisingly, despite impressive empirical performance, we observe that scores learned via denoising score matching (DSM) do not satisfy the underlying score FPE. We mathematically analyze two implications of satisfying the score FPE and a potential explanation for why the score FPE is not satisfied in practice. At last, we propose to regularize  the DSM objective to enforce satisfaction of the score FPE, and show its effectiveness on synthetic data and MNIST. "}}
{"id": "ecVbozYsBmw", "cdate": 1663849987554, "mdate": null, "content": {"title": "Towards Learning Imperceptible Adversarial Distribution for Black-Box Attacks", "abstract": "An effective black-box threat model should find a sweet spot that balances well across success rate, perceptual quality, and query efficiency. In this paper, we propose PadvFlow, a black-box attack method that achieves the desirable property. Instead of searching for examples in a conventional $\\ell_p$ space, PadvFlow leverages the use of normalizing flows (NFs) to model the density distribution of natural and indistinguishable adversarial examples in a perceptual space. The expressive NFs can reduce the perceptible noises. Meanwhile, searching for adversarial samples via the perceptual space improves details of generation. Thus, PadvFlow can generate perceptually-natural adversarial examples. Our comprehensive experiments show that PadvFlow not only successfully attacks 6 undefended and 4 defended image classifiers on CIFAR-10 and SVHN, but also can be scaled up to attack ImageNet of pixel size $299\\times299$. The effectiveness of PadvFlow is also validated for a different modality by attacking an automatic speech recognition system."}}
{"id": "dInTmpKDWr", "cdate": 1640995200000, "mdate": 1674347230661, "content": {"title": "Preventing oversmoothing in VAE via generalized variance parameterization", "abstract": ""}}
{"id": "Qk5tFh56iEf", "cdate": 1640995200000, "mdate": 1667462859508, "content": {"title": "SQ-VAE: Variational Bayes on Discrete Representation with Self-annealed Stochastic Quantization", "abstract": "One noted issue of vector-quantized variational autoencoder (VQ-VAE) is that the learned discrete representation uses only a fraction of the full capacity of the codebook, also known as codebook co..."}}
{"id": "P1qDT-yk-PZ", "cdate": 1640995200000, "mdate": 1663201641533, "content": {"title": "SQ-VAE: Variational Bayes on Discrete Representation with Self-annealed Stochastic Quantization", "abstract": "One noted issue of vector-quantized variational autoencoder (VQ-VAE) is that the learned discrete representation uses only a fraction of the full capacity of the codebook, also known as codebook collapse. We hypothesize that the training scheme of VQ-VAE, which involves some carefully designed heuristics, underlies this issue. In this paper, we propose a new training scheme that extends the standard VAE via novel stochastic dequantization and quantization, called stochastically quantized variational autoencoder (SQ-VAE). In SQ-VAE, we observe a trend that the quantization is stochastic at the initial stage of the training but gradually converges toward a deterministic quantization, which we call self-annealing. Our experiments show that SQ-VAE improves codebook utilization without using common heuristics. Furthermore, we empirically show that SQ-VAE is superior to VAE and VQ-VAE in vision- and speech-related tasks."}}
{"id": "7ZJPhriEdRQ", "cdate": 1601308296141, "mdate": null, "content": {"title": "AR-ELBO: Preventing Posterior Collapse Induced by Oversmoothing in Gaussian VAE", "abstract": "Variational autoencoders (VAEs) often suffer from posterior collapse, which is a phenomenon that the learned latent space becomes uninformative. This is related to local optima introduced by a fixed hyperparameter resembling the data variance in the objective function. We suggest that this variance parameter regularizes the VAE and affects its smoothness, which is the magnitude of its gradient. An inappropriate choice of this parameter causes oversmoothness and leads to posterior collapse. This is shown theoretically by analysis on the linear approximated objective function and empirically in general cases. We propose AR-ELBO, which stands for adaptively regularized ELBO~(Evidence Lower BOund). It controls the strength of regularization by adapting the variance parameter, and thus avoids oversmoothing the model. Generation models trained by proposed objectives show improved Fr\u00e9chet inception distance~(FID) of images generated from the MNIST and CelebA datasets."}}
