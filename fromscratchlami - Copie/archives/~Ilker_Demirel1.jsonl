{"id": "CkUF91ckbri", "cdate": 1672531200000, "mdate": 1681675398455, "content": {"title": "Falsification of Internal and External Validity in Observational Studies via Conditional Moment Restrictions", "abstract": "Randomized Controlled Trials (RCT)s are relied upon to assess new treatments, but suffer from limited power to guide personalized treatment decisions. On the other hand, observational (i.e., non-experimental) studies have large and diverse populations, but are prone to various biases (e.g. residual confounding). To safely leverage the strengths of observational studies, we focus on the problem of falsification, whereby RCTs are used to validate causal effect estimates learned from observational data. In particular, we show that, given data from both an RCT and an observational study, assumptions on internal and external validity have an observable, testable implication in the form of a set of Conditional Moment Restrictions (CMRs). Further, we show that expressing these CMRs with respect to the causal effect, or \"causal contrast\", as opposed to individual counterfactual means, provides a more reliable falsification test. In addition to giving guarantees on the asymptotic properties of our test, we demonstrate superior power and type I error of our approach on semi-synthetic and real world datasets. Our approach is interpretable, allowing a practitioner to visualize which subgroups in the population lead to falsification of an observational study."}}
{"id": "OHYikHrlVHp", "cdate": 1652856195422, "mdate": 1652856195422, "content": {"title": "Combinatorial Gaussian Process Bandits with Probabilistically Triggered Arms", "abstract": "Combinatorial bandit models and algorithms are used in many sequential decision-making tasks ranging from item list recommendation to influence maximization. Typical algorithms proposed for combinatorial bandits, including combinatorial UCB (CUCB) and combinatorial Thompson sampling (CTS) do not exploit correlations between base arms during the learning process. Moreover, their regret is usually analyzed under independent base arm outcomes. In this paper, we use Gaussian Processes (GPs) to model correlations between base arms. In particular, we consider a combinatorial bandit model with probabilistically triggered arms, and assume that the expected base arm outcome function is a sample from a GP. We assume that the learner has access to an exact computation oracle, which returns an optimal solution given expected base arm outcomes, and analyze the regret of Combinatorial Gaussian Process Upper Confidence Bound (ComGP-UCB) algorithm for this setting. Under (triggering probability modulated) Lipschitz continuity assumption on the expected reward function, we derive ($O( \\sqrt{m T \\log T \\gamma_{T, \\boldsymbol{\\mu}}^{PTA}})$) $O(m \\sqrt{\\frac{T \\log T}{p^*}})$ upper bounds for the regret of ComGP-UCB that hold with high probability, where $m$ denotes the number of base arms, $p^*$ denotes the minimum non-zero triggering probability, and $\\gamma_{T, \\boldsymbol{\\mu}}^{PTA}$ denotes the pseudo-information gain. Finally, we show via simulations that when the correlations between base arm outcomes are strong, ComGP-UCB significantly outperforms CUCB and CTS. "}}
{"id": "JokpPqA294", "cdate": 1652737737804, "mdate": null, "content": {"title": "ESCADA: Efficient Safety and Context Aware Dose Allocation for Precision Medicine", "abstract": "Finding an optimal individualized treatment regimen is considered one of the most challenging precision medicine problems. Various patient characteristics influence the response to the treatment, and hence, there is no one-size-fits-all regimen. Moreover, the administration of an unsafe dose during the treatment can have adverse effects on health. Therefore, a treatment model must ensure patient \\emph{safety} while \\emph{efficiently} optimizing the course of therapy. We study a prevalent medical problem where the treatment aims to keep a physiological variable in a safe range and preferably close to a target level, which we refer to as \\emph{leveling}. Such a task may be relevant in numerous other domains as well. We propose ESCADA, a novel and generic multi-armed bandit (MAB) algorithm tailored for the leveling task, to make safe, personalized, and context-aware dose recommendations. We derive high probability upper bounds on its cumulative regret and safety guarantees. Following ESCADA's design, we also describe its Thompson sampling-based counterpart. We discuss why the straightforward adaptations of the classical MAB algorithms such as GP-UCB may not be a good fit for the leveling task. Finally, we make \\emph{in silico} experiments on the bolus-insulin dose allocation problem in type-1 diabetes mellitus disease and compare our algorithms against the famous GP-UCB algorithm, the rule-based dose calculators, and a clinician."}}
{"id": "yUz4XopJg2", "cdate": 1640995200000, "mdate": 1682436792644, "content": {"title": "Distance and position estimation in visible light systems with RGB LEDs", "abstract": ""}}
{"id": "muxdvW4OK2v", "cdate": 1640995200000, "mdate": 1682018847494, "content": {"title": "Federated Multi-Armed Bandits Under Byzantine Attacks", "abstract": "Multi-armed bandits (MAB) is a simple reinforcement learning model where the learner controls the trade-off between exploration versus exploitation to maximize its cumulative reward. Federated multi-armed bandits (FMAB) is a recently emerging framework where a cohort of learners with heterogeneous local models play a MAB game and communicate their aggregated feedback to a parameter server to learn the global feedback model. Federated learning models are vulnerable to adversarial attacks such as model-update attacks or data poisoning. In this work, we study an FMAB problem in the presence of Byzantine clients who can send false model updates that pose a threat to the learning process. We borrow tools from robust statistics and propose a median-of-means-based estimator: Fed-MoM-UCB, to cope with the Byzantine clients. We show that if the Byzantine clients constitute at most half the cohort, it is possible to incur a cumulative regret on the order of ${\\cal O} (\\log T)$ with respect to an unavoidable error margin, including the communication cost between the clients and the parameter server. We analyze the interplay between the algorithm parameters, unavoidable error margin, regret, communication cost, and the arms' suboptimality gaps. We demonstrate Fed-MoM-UCB's effectiveness against the baselines in the presence of Byzantine attacks via experiments."}}
{"id": "vcF2iWcUWlt", "cdate": 1609459200000, "mdate": 1682018847516, "content": {"title": "Combinatorial Gaussian Process Bandits with Probabilistically Triggered Arms", "abstract": "Combinatorial bandit models and algorithms are used in many sequential decision-making tasks ranging from item list recommendation to influence maximization. Typical algorithms proposed for combinatorial bandits, including combinatorial UCB (CUCB) and combinatorial Thompson sampling (CTS) do not exploit correlations between base arms during the learning process. Moreover, their regret is usually analyzed under independent base arm outcomes. In this paper, we use Gaussian Processes (GPs) to model correlations between base arms. In particular, we consider a combinatorial bandit model with probabilistically triggered arms, and assume that the expected base arm outcome function is a sample from a GP. We assume that the learner has access to an exact computation oracle, which returns an optimal solution given expected base arm outcomes, and analyze the regret of Combinatorial Gaussian Process Upper Confidence Bound (ComGP-UCB) algorithm for this setting. Under (triggering probability modulated) Lipschitz continuity assumption on the expected reward function, we derive ($O( \\sqrt{m T \\log T \\gamma_{T, \\boldsymbol{\\mu}}^{PTA}})$) $O(m \\sqrt{\\frac{T \\log T}{p^*}})$ upper bounds for the regret of ComGP-UCB that hold with high probability, where $m$ denotes the number of base arms, $p^*$ denotes the minimum non-zero triggering probability, and $\\gamma_{T, \\boldsymbol{\\mu}}^{PTA}$ denotes the pseudo-information gain. Finally, we show via simulations that when the correlations between base arm outcomes are strong, ComGP-UCB significantly outperforms CUCB and CTS."}}
{"id": "u8yY8a9ody", "cdate": 1609459200000, "mdate": 1682436792696, "content": {"title": "Distance and Position Estimation in Visible Light Systems with RGB LEDs", "abstract": "In this manuscript, distance and position estimation problems are investigated for visible light positioning (VLP) systems with red-green-blue (RGB) light emitting diodes (LEDs). The accuracy limits on distance and position estimation are calculated in terms of the Cramer-Rao lower bound (CRLB) for three different scenarios. Scenario~1 and Scenario~2 correspond to synchronous and asynchronous systems, respectively, with known channel attenuation formulas at the receiver. In Scenario~3, a synchronous system is considered but channel attenuation formulas are not known at the receiver. The derived CRLB expressions reveal the relations among distance/position estimation accuracies in the considered scenarios and lead to intuitive explanations for the benefits of using RGB LEDs. In addition, maximum likelihood (ML) estimators are derived in all scenarios, and it is shown that they can achieve close performance to the CRLBs in some cases for sufficiently high source optical powers."}}
{"id": "ouggMl-Ks7U", "cdate": 1609459200000, "mdate": 1682018847669, "content": {"title": "Safe Linear Leveling Bandits", "abstract": "Multi-armed bandits (MAB) are extensively studied in various settings where the objective is to \\textit{maximize} the actions' outcomes (i.e., rewards) over time. Since safety is crucial in many real-world problems, safe versions of MAB algorithms have also garnered considerable interest. In this work, we tackle a different critical task through the lens of \\textit{linear stochastic bandits}, where the aim is to keep the actions' outcomes close to a target level while respecting a \\textit{two-sided} safety constraint, which we call \\textit{leveling}. Such a task is prevalent in numerous domains. Many healthcare problems, for instance, require keeping a physiological variable in a range and preferably close to a target level. The radical change in our objective necessitates a new acquisition strategy, which is at the heart of a MAB algorithm. We propose SALE-LTS: Safe Leveling via Linear Thompson Sampling algorithm, with a novel acquisition strategy to accommodate our task and show that it achieves sublinear regret with the same time and dimension dependence as previous works on the classical reward maximization problem absent any safety constraint. We demonstrate and discuss our algorithm's empirical performance in detail via thorough experiments."}}
{"id": "_TPC-XB3tRM", "cdate": 1609459200000, "mdate": 1682018847653, "content": {"title": "ESCADA: Efficient Safety and Context Aware Dose Allocation for Precision Medicine", "abstract": "Finding an optimal individualized treatment regimen is considered one of the most challenging precision medicine problems. Various patient characteristics influence the response to the treatment, and hence, there is no one-size-fits-all regimen. Moreover, the administration of an unsafe dose during the treatment can have adverse effects on health. Therefore, a treatment model must ensure patient \\emph{safety} while \\emph{efficiently} optimizing the course of therapy. We study a prevalent medical problem where the treatment aims to keep a physiological variable in a safe range and preferably close to a target level, which we refer to as \\emph{leveling}. Such a task may be relevant in numerous other domains as well. We propose ESCADA, a novel and generic multi-armed bandit (MAB) algorithm tailored for the leveling task, to make safe, personalized, and context-aware dose recommendations. We derive high probability upper bounds on its cumulative regret and safety guarantees. Following ESCADA's design, we also describe its Thompson sampling-based counterpart. We discuss why the straightforward adaptations of the classical MAB algorithms such as GP-UCB may not be a good fit for the leveling task. Finally, we make \\emph{in silico} experiments on the bolus-insulin dose allocation problem in type-1 diabetes mellitus disease and compare our algorithms against the famous GP-UCB algorithm, the rule-based dose calculators, and a clinician."}}
{"id": "dLxOiqeBOx", "cdate": 1546300800000, "mdate": 1682436792692, "content": {"title": "Accuracy Limits of Distance Estimation in Visible Light Systems with RGB LEDs", "abstract": "The distance estimation problem is investigated for visible light positioning (VLP) systems with red-green-blue (RGB) light emitting diodes (LEDs). The accuracy limits on distance estimation are calculated in terms of the Cram\u00e9r-Rao lower bounds (CRLBs) for three different scenarios. Scenario 1 and Scenario 2 correspond to synchronous and asynchronous systems, respectively, with known channel attenuation formulas at the receiver. In Scenario 3, a synchronous systems is considered but channel attenuation formulas are not known at the receiver. The derived CRLB expressions reveal the relations among the distance estimation accuracies in the considered scenarios and provide intuitive explanations for the benefits of using RGB LEDs."}}
