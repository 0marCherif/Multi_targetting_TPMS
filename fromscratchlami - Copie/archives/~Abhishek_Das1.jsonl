{"id": "9m3GFgAT9C2", "cdate": 1676591079127, "mdate": null, "content": {"title": "PIRLNav: Pretraining with Imitation and RL Finetuning for ObjectNav", "abstract": "We study ObjectGoal Navigation - where a virtual robot situated in a new environment is asked to navigate to an object. Prior work has shown that imitation learning (IL) on a dataset of human demonstrations achieves promising results. However, this has limitations \u2212 1) IL policies generalize poorly to new states, since the training mimics actions not their consequences, and 2) collecting demonstrations is expensive. On the other hand, reinforcement learning (RL) is trivially scalable, but requires careful reward engineering to achieve desirable behavior. We present a two-stage learning scheme for IL pretraining on human demonstrations followed by RL-finetuning. This leads to a PIRLNav policy that advances the state-of-the-art on ObjectNav from 60.0% success rate to 65.0% (+5.0% absolute). Using this IL\u2192RL training recipe, we present a rigorous empirical analysis of design choices. First, we investigate whether human demonstrations can be replaced with `free' (automatically generated) sources of demonstrations, e.g. shortest paths (SP) or task-agnostic frontier exploration (FE) trajectories. We find that IL\u2192RL on human demonstrations outperforms IL\u2192RL on SP and FE trajectories, even when controlled for the same IL-pretraining success on TRAIN, and even on a subset of VAL episodes where IL-pretraining success favors the SP or FE policies. Next, we study how RL-finetuning performance scales with the size of the IL pretraining dataset. We find that as we increase the size of the IL-pretraining dataset and get to high IL accuracies, the improvements from RL-finetuning are smaller, and that 90% of the performance of our best IL\u2192RL policy can be achieved with less than half the number of IL demonstrations. Finally, we analyze failure modes of our ObjectNav policies, and present guidelines for further improving them."}}
{"id": "5Z3GURcqwT", "cdate": 1652737845900, "mdate": null, "content": {"title": "Spherical Channels for Modeling Atomic Interactions", "abstract": "Modeling the energy and forces of atomic systems is a fundamental problem in computational chemistry with the potential to help address many of the world\u2019s most pressing problems, including those related to energy scarcity and climate change. These calculations are traditionally performed using Density Functional Theory, which is computationally very expensive. Machine learning has the potential to dramatically improve the efficiency of these calculations from days or hours to seconds.\n\nWe propose the Spherical Channel Network (SCN) to model atomic energies and forces. The SCN is a graph neural network where nodes represent atoms and edges their neighboring atoms. The atom embeddings are a set of spherical functions, called spherical channels, represented using spherical harmonics. We demonstrate, that by rotating the embeddings based on the 3D edge orientation, more information may be utilized while maintaining the rotational equivariance of the messages. While equivariance is a desirable property, we find that by relaxing this constraint in both message passing and aggregation, improved accuracy may be achieved. We demonstrate state-of-the-art results on the large-scale Open Catalyst 2020 dataset in both energy and force prediction for numerous tasks and metrics."}}
{"id": "0jP2n0YFmKG", "cdate": 1632875750942, "mdate": null, "content": {"title": "Towards Training Billion Parameter Graph Neural Networks for Atomic Simulations", "abstract": "Recent progress in Graph Neural Networks (GNNs) for modeling atomic simulations has the potential to revolutionize catalyst discovery, which is a key step in making progress towards the energy breakthroughs needed to combat climate change. However, the GNNs that have proven most effective for this task are memory intensive as they model higher-order interactions in the graphs such as those between triplets or quadruplets of atoms, making it challenging to scale these models. In this paper, we introduce Graph Parallelism, a method to distribute input graphs across multiple GPUs, enabling us to train very large GNNs with hundreds of millions or billions of parameters. We empirically evaluate our method by scaling up the recently proposed DimeNet++ and GemNet models by over an order of magnitude in the number of parameters. On the large-scale Open Catalyst 2020 (OC20) dataset, these graph-parallelized models lead to relative improvements of 1) 15% on the force MAE metric on the S2EF task and 2) 21% on the AFbT metric on the IS2RS task, establishing new state-of-the-art results."}}
{"id": "wt_JnQnRmU3", "cdate": 1601908329200, "mdate": null, "content": {"title": "Evaluating visual conversational agents via cooperative human-ai games", "abstract": "As AI continues to advance, human-AI teams are inevitable.\nHowever, progress in AI is routinely measured in isolation,\nwithout a human in the loop. It is crucial to benchmark\nprogress in AI, not just in isolation, but also in terms of how\nit translates to helping humans perform certain tasks, i.e., the\nperformance of human-AI teams.\nIn this work, we design a cooperative game \u2013 GuessWhich \u2013\nto measure human-AI team performance in the specific context of the AI being a visual conversational agent. GuessWhich involves live interaction between the human and the\nAI. The AI, which we call ALICE, is provided an image which\nis unseen by the human. Following a brief description of the\nimage, the human questions ALICE about this secret image to\nidentify it from a fixed pool of images.\nWe measure performance of the human-ALICE team by the\nnumber of guesses it takes the human to correctly identify the\nsecret image after a fixed number of dialog rounds with ALICE. We compare performance of the human-ALICE teams for\ntwo versions of ALICE. Our human studies suggest a counterintuitive trend \u2013 that while AI literature shows that one version outperforms the other when paired with an AI questioner\nbot, we find that this improvement in AI-AI performance does\nnot translate to improved human-AI performance. This suggests a mismatch between benchmarking of AI in isolation\nand in the context of human-AI teams."}}
{"id": "K3qa-sMHpQX", "cdate": 1601308113041, "mdate": null, "content": {"title": "ForceNet: A Graph Neural Network for Large-Scale Quantum Chemistry Simulation", "abstract": "Machine Learning (ML) has a potential to dramatically accelerate large-scale physics-based simulations. However, practical models for real large-scale and complex problems remain out of reach. Here we present ForceNet, a model for accurate and fast quantum chemistry simulations to accelerate catalyst discovery for renewable energy applications. ForceNet is a graph neural network that uses surrounding 3D molecular structure to estimate per-atom forces---a central capability for performing atomic simulations. The key challenge is to accurately capture highly complex and non-linear quantum interactions of atoms in 3D space, on which forces are dependent. To this end, ForceNet adopts (1) expressive message passing architecture, (2) appropriate choice of basis and non-linear activation functions, and (3) model scaling in terms of network depth and width. We show ForceNet reduces the estimation error of atomic forces by 30% compared to existing ML models, and generalizes well to out-of-distribution structures. Finally,  we apply ForceNet to the large-scale catalyst dataset, OC20. We use ForceNet to perform quantum chemistry simulations, where ForceNet is able to achieve 4x higher success rate than existing ML models. Overall, we demonstrate the potential for ML-based simulations to achieve practical usefulness while being orders of magnitude faster than physics-based simulations."}}
{"id": "Bylh2krYPr", "cdate": 1569439667763, "mdate": null, "content": {"title": "Probing Emergent Semantics in Predictive Agents via Question Answering", "abstract": "Recent work has demonstrated how predictive modeling can endow agents with rich knowledge of their surroundings, improving their ability to act in complex environments. We propose question-answering as a general paradigm to decode and understand the representations that such agents develop, applying our method to two recent approaches to predictive modeling \u2013 action-conditional CPC (Guo et al., 2018) and SimCore (Gregor et al., 2019). After training agents with these predictive objectives in a visually-rich, 3D environment with an assortment of objects, colors, shapes, and spatial configurations, we probe their internal state representations with a host of synthetic (English) questions, without backpropagating gradients from the question-answering decoder into the agent. The performance of different agents when probed in this way reveals that they learn to encode detailed, and seemingly compositional, information about objects, properties and spatial relations from their physical environment. Our approach is intuitive, i.e. humans can easily interpret the responses of the model as opposed to inspecting continuous vectors, and model-agnostic, i.e. applicable to any modeling approach. By revealing the implicit knowledge of objects, quantities, properties and relations acquired by agents as they learn, question-conditional agent probing can stimulate the design and development of stronger predictive learning objectives."}}
{"id": "SJeQGJrKwH", "cdate": 1569439499144, "mdate": null, "content": {"title": "DS-VIC: Unsupervised Discovery of Decision States for Transfer in RL", "abstract": "We learn to identify decision states, namely the parsimonious set of states where decisions meaningfully affect the future states an agent can reach in an environment. We utilize the VIC framework, which maximizes an agent\u2019s `empowerment\u2019, ie the ability to reliably reach a diverse set of states -- and formulate a sandwich bound on the empowerment objective that allows identification of decision states. Unlike previous work, our decision states are discovered without extrinsic rewards -- simply by interacting with the world. Our results show that our decision states are: 1) often interpretable, and 2) lead to better exploration on downstream goal-driven tasks in partially observable environments."}}
{"id": "SJeAbAVODH", "cdate": 1569373702069, "mdate": null, "content": {"title": "Unsupervised Discovery of Decision States for Transfer in Reinforcement Learning", "abstract": "We present a hierarchical reinforcement learning (HRL) or options framework for identifying \u2018decision states\u2019. Informally speaking, these are states considered \u2018important\u2019 by the agent\u2019s policy \u2013 e.g., for navigation, decision states would be crossroads or doors where an agent needs to make strategic decisions. While previous work (most notably Goyal et al., 2019) discovers decision states in a task/goal specific (or \u2018supervised\u2019) manner, we do so in a goal-independent (or \u2018unsupervised\u2019) manner, i.e. entirely without any goal or extrinsic rewards. Our approach combines two hitherto disparate ideas \u2013 1) intrinsic control (Gregor et al., 2016, Eysenbach et al., 2018): learning a set of options that allow an agent to reliably reach a diverse set of states, and 2) information bottleneck (Tishby et al., 2000): penalizing mutual information between the option \u2126 and the states st visited in the trajectory. The former encourages an agent to reliably explore the environment; the latter allows identification of decision states as the ones with high mutual information I(\u2126; at|st) despite the bottleneck. Our results demonstrate that 1) our model learns interpretable decision states in an unsupervised manner, and 2) these learned decision states transfer to goal-driven tasks in new environments, effectively guide exploration, and improve performance."}}
{"id": "r1eojaEuwB", "cdate": 1569373603457, "mdate": null, "content": {"title": "Improving Generative Visual Dialog by Answering Diverse Questions", "abstract": "Prior work on training generative Visual Dialog models with reinforcement learning (Das et al., 2017b) has explored a Q-BOT-ABOT image-guessing game and shown that this \u2018self-talk\u2019 approach can lead to improved performance at the downstream dialogconditioned image-guessing task. However, this improvement saturates and starts degrading after a few rounds of interaction, and does not lead to a better Visual Dialog model. We find that this is due in part to repeated interactions between Q-BOT and A-BOT during selftalk, which are not informative with respect to the image. To improve this, we devise a simple auxiliary objective that incentivizes Q-BOT to ask diverse questions, thus reducing repetitions and in turn enabling A-BOT to explore a larger state space during RL i.e. be exposed to more visual concepts to talk about, and varied questions to answer. We evaluate our approach via a host of automatic metrics and human studies, and demonstrate that it leads to better dialog, i.e. dialog that is more diverse (i.e. less repetitive), consistent (i.e. has fewer conflicting exchanges), fluent (i.e. more humanlike), and detailed, while still being comparably image-relevant as prior work and ablations."}}
{"id": "S7FNoXQx_aH", "cdate": 1546300800000, "mdate": null, "content": {"title": "Embodied Question Answering in Photorealistic Environments With Point Cloud Perception.", "abstract": "To help bridge the gap between internet vision-style problems and the goal of vision for embodied perception we instantiate a large-scale navigation task -- Embodied Question Answering [1] in photo-realistic environments (Matterport 3D). We thoroughly study navigation policies that utilize 3D point clouds, RGB images, or their combination. Our analysis of these models reveals several key findings. We find that two seemingly naive navigation baselines, forward-only and random, are strong navigators and challenging to outperform, due to the specific choice of the evaluation setting presented by [1]. We find a novel loss-weighting scheme we call Inflection Weighting to be important when training recurrent models for navigation with behavior cloning and are able to out perform the baselines with this technique. We find that point clouds provide a richer signal than RGB images for learning obstacle avoidance, motivating the use (and continued study) of 3D deep learning models for embodied navigation."}}
