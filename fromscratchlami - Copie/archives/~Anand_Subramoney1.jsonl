{"id": "v-vGvnsKTT", "cdate": 1680013366470, "mdate": 1680013366470, "content": {"title": "Efficient Real Time Recurrent Learning through combined activity and parameter sparsity", "abstract": "Backpropagation through time (BPTT) is the standard algorithm for training recurrent neural networks (RNNs), which requires separate simulation phases for the forward and backward passes for inference and learning, respectively. Moreover, BPTT requires storing the complete history of network states between phases, with memory consumption growing proportional to the input sequence length. This makes BPTT unsuited for online learning and presents a challenge for implementation on low-resource real-time systems. Real-Time Recurrent Learning (RTRL) allows online learning, and the growth of required memory is independent of sequence length. However, RTRL suffers from exceptionally high computational costs that grow proportional to the fourth power of the state size, making RTRL computationally intractable for all but the smallest of networks. In this work, we show that recurrent networks exhibiting high activity sparsity can reduce the computational cost of RTRL. Moreover, combining activity and parameter sparsity can lead to significant enough savings in computational and memory costs to make RTRL practical. Unlike previous work, this improvement in the efficiency of RTRL can be achieved without using any approximations for the learning process. "}}
{"id": "X5gN2L4GbC", "cdate": 1672531200000, "mdate": 1696501882017, "content": {"title": "Beyond Weights: Deep learning in Spiking Neural Networks with pure synaptic-delay training", "abstract": "Biological evidence suggests that adaptation of synaptic delays on short to medium timescales plays an important role in learning in the brain. Inspired by biology, we explore the feasibility and power of using synaptic delays to solve challenging tasks even when the synaptic weights are not trained but kept at randomly chosen fixed values. We show that training ONLY the delays in feed-forward spiking networks using backpropagation can achieve performance comparable to the more conventional weight training. Moreover, further constraining the weights to ternary values does not significantly affect the networks' ability to solve the tasks using only the synaptic delays. We demonstrate the task performance of delay-only training on MNIST and Fashion-MNIST datasets in preliminary experiments. This demonstrates a new paradigm for training spiking neural networks and sets the stage for models that can be more efficient than the ones that use weights for computation."}}
{"id": "I0LA3yoeECY", "cdate": 1672531200000, "mdate": 1696501882009, "content": {"title": "Block-local learning with probabilistic latent representations", "abstract": "The ubiquitous backpropagation algorithm requires sequential updates across blocks of a network, introducing a locking problem. Moreover, backpropagation relies on the transpose of weight matrices to calculate updates, introducing a weight transport problem across blocks. Both these issues prevent efficient parallelisation and horizontal scaling of models across devices. We propose a new method that introduces a twin network that propagates information backwards from the targets to the input to provide auxiliary local losses. Forward and backward propagation can work in parallel and with different sets of weights, addressing the problems of weight transport and locking. Our approach derives from a statistical interpretation of end-to-end training which treats activations of network layers as parameters of probability distributions. The resulting learning framework uses these parameters locally to assess the matching between forward and backward information. Error backpropagation is then performed locally within each block, leading to `block-local' learning. Several previously proposed alternatives to error backpropagation emerge as special cases of our model. We present results on various tasks and architectures, including transformers, demonstrating state-of-the-art performance using block-local learning. These results provide a new principled framework to train very large networks in a distributed setting and can also be applied in neuromorphic systems."}}
{"id": "lJdOlWg8td", "cdate": 1663850262289, "mdate": null, "content": {"title": "Efficient recurrent architectures through activity sparsity and sparse back-propagation through time", "abstract": "Recurrent neural networks (RNNs) are well suited for solving sequence tasks in resource-constrained systems due to their expressivity and  low computational requirements. However, there is still a need to bridge the gap between what RNNs are capable of in terms of efficiency and performance and real-world application requirements. The memory and computational requirements arising from propagating the activations of all the neurons at every time step to every connected neuron, together with the sequential dependence of activations, contribute to the inefficiency of training and using RNNs. We propose a solution inspired by biological neuron dynamics that makes the communication between RNN units sparse and discrete. This makes the backward pass with backpropagation through time (BPTT) computationally sparse and efficient as well. We base our model on the gated recurrent unit (GRU), extending it with units that emit discrete events for communication triggered by a threshold so that no information is communicated to other units in the absence of events.  We show theoretically that the communication between units, and hence the computation required for both the forward and backward passes, scales with the number of events in the network. Our model achieves efficiency without compromising task performance, demonstrating competitive performance compared to state-of-the-art recurrent network models in real-world tasks, including language modeling. The dynamic activity sparsity mechanism also makes our model well suited for novel energy-efficient neuromorphic hardware. Code is available at https://github.com/KhaleelKhan/EvNN/."}}
{"id": "vaxPmiHE3S", "cdate": 1652737438869, "mdate": null, "content": {"title": "EGRU: Event-based GRU for activity-sparse inference and learning", "abstract": "The scalability of recurrent neural networks (RNNs) is hindered by the sequential dependence of each time step's computation on the previous time step's output. Therefore, one way to speed up and scale RNNs is to reduce the computation required at each time step independent of model size and task. In this paper, we propose a model that reformulates Gated Recurrent Units (GRU) as an event-based activity-sparse model that we call the Event-based GRU (EGRU), where units compute updates only on receipt of input events (event-based) from other units. When combined with having only a small fraction of the units active at a time (activity-sparse), this model has the potential to be vastly more compute efficient than current RNNs. Notably, activity-sparsity in our model also translates into sparse parameter updates during gradient descent, extending this compute efficiency to the training phase. We show that the EGRU demonstrates competitive performance compared to state-of-the-art recurrent network models in real-world tasks, including language modeling while maintaining high activity sparsity naturally during inference and training. This sets the stage for the next generation of recurrent networks that are scalable and more suitable for novel neuromorphic hardware."}}
{"id": "4Sh7-92GCrT", "cdate": 1623671945109, "mdate": 1623671945109, "content": {"title": "Slow processes of neurons enable a biologically plausible approximation to policy gradient", "abstract": "Recurrent neural networks underlie the astounding information processing capabilities of the brain, and play a key role in many state-of-the-art algorithms in deep reinforcement learning.  But it has remained an open question how such networks could learn from rewards in a biologically plausible manner, with synaptic plasticity that is both local and online.  We describe such an algorithm that approximates actor-critic policy gradient in recurrent neural networks. Building on an approximation of backpropagation through time (BPTT):e-prop, and using the equivalence between forward and backward view in reinforcement learning (RL), we formulate a novel learning rule for RL that is both online and local, called reward-based e-prop. This learning rule uses neuroscience inspired slow processes and top-down signals, while still being rigorously derived as an approximation to actor-critic policy gradient.  To empirically evaluate this algorithm, we consider a delayed reaching task, where an arm is controlled using a recurrent network of spiking neurons. In this task, we show that reward-based e-prop performs as well as an agent trained with actor-critic policy gradient with biologically implausible BPTT"}}
{"id": "JFQjzB1Y3J", "cdate": 1623671560460, "mdate": 1623671560460, "content": {"title": "Spike frequency adaptation supports network computations on temporally dispersed information", "abstract": "For solving tasks such as recognizing a song, answering a question, or inverting a sequence of symbols, cortical microcircuits need to integrate and manipulate information that was dispersed over time during the preceding seconds. Creating biologically realistic models for the underlying computations, especially with spiking neurons and for behaviorally relevant integration time spans, is notoriously difficult. We examine the role of spike frequency adaptation in such computations and find that it has a surprisingly large impact. The inclusion of this well known property of a substantial fraction of neurons in the neocortex \u2014 especially in higher areas of the human neocortex \u2014 moves the performance of spiking neural network models for computations on network inputs that are temporally dispersed from a fairly low level up to the performance level of the human brain."}}
{"id": "eF6JUvOkbd", "cdate": 1623671396535, "mdate": 1623671396535, "content": {"title": "Revisiting the role of synaptic plasticity and network dynamics for fast learning in spiking neural networks", "abstract": "Spike-based neural network models have so far not been able to reproduce the capability of the brain to learn from very few, often even from just a single example. We show that this deficiency of models disappears if one allows synaptic weights to store priors and other information that optimize the learning process, while using the network state to quickly absorb information from new examples. For that, it suffices to include biologically realistic neurons with spike frequency adaptation in the neural network model, and to optimize the learning process through meta-learning. We demonstrate this on a variety of tasks, including fast learning and deletion of attractors, adaptation of motor control to changes in the body, and solving the Morris water maze task \u2013 a paradigm for fast learning of navigation to a new goal."}}
{"id": "hJVZL5v9pEN", "cdate": 1620892090663, "mdate": null, "content": {"title": "A solution to the learning dilemma for recurrent networks of spiking neurons", "abstract": "Recurrently connected networks of spiking neurons underlie the astounding information\nprocessing capabilities of the brain. Yet in spite of extensive research, how they can learn\nthrough synaptic plasticity to carry out complex network computations remains unclear. We\nargue that two pieces of this puzzle were provided by experimental data from neuroscience.\nA mathematical result tells us how these pieces need to be combined to enable biologically\nplausible online network learning through gradient descent, in particular deep reinforcement\nlearning. This learning method\u2013called e-prop\u2013approaches the performance of backpropagation\nthrough time (BPTT), the best-known method for training recurrent neural\nnetworks in machine learning. In addition, it suggests a method for powerful on-chip learning\nin energy-efficient spike-based hardware for artificial intelligence."}}
{"id": "dsn8OyYhfmZ", "cdate": 1609459200000, "mdate": 1696501882010, "content": {"title": "Reservoirs Learn to Learn", "abstract": "The common procedure in reservoir computing is to take a \u201cfound\u201d reservoir, such as a recurrent neural network with randomly chosen synaptic weights or a complex physical device, and to adapt the weights of linear readouts from this reservoir for a particular computing task. We address the question of whether the performance of reservoir computing can be significantly enhanced if one instead optimizes some (hyper)parameters of the reservoir, not for a single task but for the range of all possible tasks in which one is potentially interested, before the weights of linear readouts are optimized for a particular computing task. After all, networks of neurons in the brain are also known to be not randomly connected. Rather, their structure and parameters emerge from complex evolutionary and developmental processes, arguably in a way that enhances the speed and accuracy of subsequent learning of any concrete task that is likely to be essential for the survival of the organism. We apply the Learning-to-Learn (L2L) paradigm to mimic this two-tier process, where a set of (hyper)parameters of the reservoir are optimized for a whole family of learning tasks. We found that this substantially enhances the performance of reservoir computing for the families of tasks that we considered. Furthermore, L2L enables a new form of reservoir learning that tends to enable even faster learning, where not even the weights of readouts need to be adjusted for learning a concrete task. We present demos and performance results of these new forms of reservoir computing for reservoirs that consist of networks of spiking neurons and are hence of particular interest from the perspective of neuroscience and implementations in spike-based neuromorphic hardware. We leave it as an open question of what performance advantage the new methods that we propose provide for other types of reservoirs."}}
