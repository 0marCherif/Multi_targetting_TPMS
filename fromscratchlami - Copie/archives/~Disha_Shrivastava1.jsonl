{"id": "MtGmCCPJD-", "cdate": 1663850343694, "mdate": null, "content": {"title": "Repository-Level Prompt Generation for Large Language Models of Code", "abstract": "With the success of large language models (LLMs) of code and their use as code assistants (e.g.\\ Codex used in GitHub Copilot, techniques for introducing domain-specific knowledge in the prompt design process become important. In this work, we propose a framework called Repo-Level Prompt Generator that learns to generate example-specific prompts using prompt proposals. The prompt proposals take context from the entire repository, thereby incorporating both the structure of the repository and the context from other relevant files (e.g.\\ imports, parent class files). Our technique doesn't require any access to the weights of the LLM, making it applicable in cases where we only have black-box access to the LLM. We conduct experiments on the task of single-line code-autocompletion using code repositories taken from Google Code archives. We demonstrate that an oracle constructed from our prompt proposals gives a remarkably high relative improvement of 36\\% over Codex, showing the quality of these proposals. Further, we show that when we train a model to select the best prompt proposal, we can achieve significant performance gains over Codex and other baselines."}}
{"id": "bUDmRzeh3PT", "cdate": 1654124927347, "mdate": null, "content": {"title": "Repository-Level Prompt Generation for Large Language Models of Code", "abstract": "With the success of large language models (LLMs) of code and their use as code assistants (e.g. Codex (Chen et al., 2021) used in GitHub Copilot), development of techniques where we can have the capability to introduce domain-specific knowledge in the prompt design process becomes important. In this work, we propose a framework called Repo-Level Prompt Generator that learns to generate example-specific prompts using a set of rules. These rules allow us to take context from the entire repository, thereby incorporating both the structure of the repository and the context from other relevant files (e.g. imports, parent class files). Our technique doesn\u2019t require any access to the weights of the LLM, making it applicable in cases where we only have a black- box access to the LLM. We conduct experiments on the task of single line code-autocompletion using code repositories taken from Google Code archives. We demonstrate that an oracle constructed from our proposed rules gives up to 36% relative improvement over Codex, showing the quality of our proposed rules. Further, we show that when we train a model to select the best rule, we can achieve significant performance gains over Codex."}}
{"id": "4PK-St2iVZn", "cdate": 1621629930828, "mdate": null, "content": {"title": "Learning to Combine Per-Example Solutions for Neural Program Synthesis", "abstract": "The goal of program synthesis from examples is to find a computer program that is consistent with a given set of input-output examples. Most learning-based approaches try to find a program that satisfies all examples at once. Our work, by contrast, considers an approach that breaks the problem into two stages: (a) find programs that satisfy only one example, and (b) leverage these per-example solutions to yield a program that satisfies all examples. We introduce the Cross Aggregator neural network module based on a multi-head attention mechanism that learns to combine the cues present in these per-example solutions to synthesize a global solution. Evaluation across programs of different lengths and under two different experimental settings reveal that when given the same time budget, our technique significantly improves the success rate over PCCoder [Zohar et. al 2018] and other ablation baselines."}}
{"id": "FeVaSthrFst", "cdate": 1602617098449, "mdate": null, "content": {"title": "On-the-Fly Adaptation of Source Code Models", "abstract": "The ability to adapt to unseen, local contexts is an important challenge that successful models of source code must overcome. One of the most popular approaches for the adaptation of such models is dynamic evaluation. With dynamic evaluation, when running a model on an unseen file, the model is updated immediately after having observed each token in that file. In this work, we propose instead to approach this problem in two steps: (a) We select targeted information (\\textit{support tokens}) from the given context; (b) We use these support tokens to learn adapted parameters which are then used to predict the target hole. We refer to our proposed framework as Targeted Support Set Adaptation (TSSA).  We consider an evaluation setting that we call \\textit{line-level maintenance}, designed to reflect the downstream task of code auto-completion in an IDE. We demonstrate improved performance in experiments on a large scale Java GitHub corpus, compared to other adaptation baselines including dynamic evaluation. Moreover, our analysis shows that, compared to a non-adaptive baseline, our approach improves performance on identifiers and literals by 44% and 19%, respectively."}}
{"id": "RaiW81AYIwv", "cdate": 1577836800000, "mdate": null, "content": {"title": "On-the-Fly Adaptation of Source Code Models using Meta-Learning", "abstract": "The ability to adapt to unseen, local contexts is an important challenge that successful models of source code must overcome. One of the most popular approaches for the adaptation of such models is dynamic evaluation. With dynamic evaluation, when running a model on an unseen file, the model is updated immediately after having observed each token in that file. In this work, we propose instead to frame the problem of context adaptation as a meta-learning problem. We aim to train a base source code model that is best able to learn from information in a file to deliver improved predictions of missing tokens. Unlike dynamic evaluation, this formulation allows us to select more targeted information (support tokens) for adaptation, that is both before and after a target hole in a file. We consider an evaluation setting that we call line-level maintenance, designed to reflect the downstream task of code auto-completion in an IDE. Leveraging recent developments in meta-learning such as first-order MAML and Reptile, we demonstrate improved performance in experiments on a large scale Java GitHub corpus, compared to other adaptation baselines including dynamic evaluation. Moreover, our analysis shows that, compared to a non-adaptive baseline, our approach improves performance on identifiers and literals by 44\\% and 15\\%, respectively."}}
{"id": "K50W_g7Vxz", "cdate": 1546300800000, "mdate": null, "content": {"title": "Transfer Learning by Modeling a Distribution over Policies", "abstract": "Exploration and adaptation to new tasks in a transfer learning setup is a central challenge in reinforcement learning. In this work, we build on the idea of modeling a distribution over policies in a Bayesian deep reinforcement learning setup to propose a transfer strategy. Recent works have shown to induce diversity in the learned policies by maximizing the entropy of a distribution of policies (Bachman et al., 2018; Garnelo et al., 2018) and thus, we postulate that our proposed approach leads to faster exploration resulting in improved transfer learning. We support our hypothesis by demonstrating favorable experimental results on a variety of settings on fully-observable GridWorld and partially observable MiniGrid (Chevalier-Boisvert et al., 2018) environments."}}
{"id": "GZ-KVuVaVhq", "cdate": 1546300800000, "mdate": null, "content": {"title": "What is deemed computationally creative?", "abstract": "In this new era of computational creativity, where artificial intelligence (AI) systems are attempting to achieve human-level creativity, a set of golden questions needs to be answered, such as \u201cWhat kind of systems are creative systems?\u201d and \u201cWhen does a system qualify as truly creative?\u201d The existing generation of AI-driven cognitive systems is based on the goal of achieving human-level intelligence, not human-level creativity. Creativity is considered subjective with respect to both the application domains and the perceiving end-user. In this paper, we postulate the dimensions and factors that distinguish creativity and intelligence, such as novelty, value, surprise, influence, coherence, correctness, and comprehensibility. We group the application domains into time-dependent and time-independent ones and define a framework to describe these dimensions in each application. In addition to defining the factors that determine creativity, we also suggest ideas on how to evaluate these factors. We strongly believe that the proposed framework would act as the basis for building and evaluating creative systems and also provide us with the ultimate goal for achieving human-level creativity."}}
{"id": "nZz95J0Dn6X", "cdate": 1514764800000, "mdate": null, "content": {"title": "Modeling Topical Coherence in Discourse without Supervision", "abstract": "Coherence of text is an important attribute to be measured for both manually and automatically generated discourse; but well-defined quantitative metrics for it are still elusive. In this paper, we present a metric for scoring topical coherence of an input paragraph on a real-valued scale by analyzing its underlying topical structure. We first extract all possible topics that the sentences of a paragraph of text are related to. Coherence of this text is then measured by computing: (a) the degree of uncertainty of the topics with respect to the paragraph, and (b) the relatedness between these topics. All components of our modular framework rely only on unlabeled data and WordNet, thus making it completely unsupervised, which is an important feature for general-purpose usage of any metric. Experiments are conducted on two datasets - a publicly available dataset for essay grading (representing human discourse), and a synthetic dataset constructed by mixing content from multiple paragraphs covering diverse topics. Our evaluation shows that the measured coherence scores are positively correlated with the ground truth for both the datasets. Further validation to our coherence scores is provided by conducting human evaluation on the synthetic data, showing a significant agreement of 79.3%"}}
{"id": "AKJuIaO92fV", "cdate": 1514764800000, "mdate": null, "content": {"title": "Hypernyms Through Intra-Article Organization in Wikipedia", "abstract": "We introduce a new measure for unsupervised hypernym detection and directionality. The motivation is to keep the measure computationally light and portatable across languages. We show that the relative physical location of words in explanatory articles captures the directionality property. Further, the phrases in section titles of articles about the word, capture the semantic similarity needed for hypernym detection task. We experimentally show that the combination of features coming from these two simple measures suffices to produce results comparable with the best unsupervised measures in terms of the average precision."}}
{"id": "dX_-IMNo5u", "cdate": 1483228800000, "mdate": null, "content": {"title": "A Data and Model-Parallel, Distributed and Scalable Framework for Training of Deep Networks in Apache Spark", "abstract": "Training deep networks is expensive and time-consuming with the training period increasing with data size and growth in model parameters. In this paper, we provide a framework for distributed training of deep networks over a cluster of CPUs in Apache Spark. The framework implements both Data Parallelism and Model Parallelism making it suitable to use for deep networks which require huge training data and model parameters which are too big to fit into the memory of a single machine. It can be scaled easily over a cluster of cheap commodity hardware to attain significant speedup and obtain better results making it quite economical as compared to farm of GPUs and supercomputers. We have proposed a new algorithm for training of deep networks for the case when the network is partitioned across the machines (Model Parallelism) along with detailed cost analysis and proof of convergence of the same. We have developed implementations for Fully-Connected Feedforward Networks, Convolutional Neural Networks, Recurrent Neural Networks and Long Short-Term Memory architectures. We present the results of extensive simulations demonstrating the speedup and accuracy obtained by our framework for different sizes of the data and model parameters with variation in the number of worker cores/partitions; thereby showing that our proposed framework can achieve significant speedup (upto 11X for CNN) and is also quite scalable."}}
