{"id": "rk-WnoWO-S", "cdate": 1546300800000, "mdate": null, "content": {"title": "Imputing Missing Events in Continuous-Time Event Streams", "abstract": "Events in the world may be caused by other, unobserved events. We consider sequences of events in continuous time. Given a probability model of complete sequences, we propose particle smoothing\u2014a f..."}}
{"id": "HJehSnCcFX", "cdate": 1538088004477, "mdate": null, "content": {"title": "Inference of unobserved event streams with neural Hawkes particle smoothing", "abstract": "Events that we observe in the world may be caused by other, unobserved events. We consider sequences of discrete events in continuous time. When only some of the events are observed, we propose particle smoothing to infer the missing events. Particle smoothing is an extension of particle filtering in which proposed events are conditioned on the future as well as the past. For our setting, we develop a novel proposal distribution that is a type of continuous-time bidirectional LSTM. We use the sampled particles in an approximate minimum Bayes risk decoder that outputs a single low-risk prediction of the missing events. We experiment in multiple synthetic and real domains, modeling the complete sequences in each domain with a neural Hawkes process (Mei & Eisner, 2017). On held-out incomplete sequences, our method is effective at inferring the ground-truth unobserved events. In particular, particle smoothing consistently improves upon particle filtering, showing the benefit of training a bidirectional proposal distribution."}}
{"id": "HyV7IMfOWH", "cdate": 1514764800000, "mdate": null, "content": {"title": "Learning Latent Semantic Annotations for Grounding Natural Language to Structured Data", "abstract": ""}}
{"id": "Bk-eWfMdbB", "cdate": 1514764800000, "mdate": null, "content": {"title": "Data2Text Studio: Automated Text Generation from Structured Data", "abstract": ""}}
