{"id": "r3MeIGuqsxq", "cdate": 1646139406199, "mdate": 1646139406199, "content": {"title": "Calibrated Learning to Defer with One-vs-All Classifiers", "abstract": "The learning to defer (L2D) framework has the potential to make AI systems safer. For a given input, the system can defer the decision to a human if the human is more likely than the model to take the correct action. We study the calibration of L2D systems, investigating if the probabilities they output are sound. We find that Mozannar & Sontag's (2020) multiclass framework is not calibrated with respect to expert correctness. Moreover, it is not even guaranteed to produce valid probabilities due to its parameterization being degenerate for this purpose. We propose an L2D system based on one-vs-all classifiers that is able to produce calibrated probabilities of expert correctness. Furthermore, our loss function is also a consistent surrogate for multiclass L2D, like Mozannar & Sontag's (2020). Our experiments verify that not only is our system calibrated, but this benefit comes at no cost to accuracy. Our model's accuracy is always comparable (and often superior) to Mozannar & Sontag's (2020) model's in tasks ranging from hate speech detection to galaxy classification to diagnosis of skin lesions."}}
{"id": "rA8MXPZPXj", "cdate": 1640995200000, "mdate": 1672919527261, "content": {"title": "Learning to Defer to Multiple Experts: Consistent Surrogate Losses, Confidence Calibration, and Conformal Ensembles", "abstract": ""}}
{"id": "cqAHExg2f", "cdate": 1612102779061, "mdate": null, "content": {"title": "Explaining Low Dimensional Representation, a reproduction", "abstract": "This report covers our reproduction of the paper 'Explaining Low dimensional Representation' \\cite{plumb2020explaining} by Plumb et al. In this paper a method (Transitive Global Translations, TGT) is proposed for explaining different clusters in low dimensional representations of high dimensional data. They show their method outperforms the difference between the means (DBM) method, is consistent in explaining differences with few features, and matches real patterns in data. We verify these claims by reproducing their experiments and testing their method on new data. We also investigate the use of more complex transformations to explain differences between clusters.\n\nWe reproduce the original experiments using their source code. We also replicate the findings by re-implementing the authors' method in PyTorch and evaluating on two of the dataset used in the paper and two new ones. Furthermore, we compare TGT with our own extension of TGT, which uses a larger class of transformations.\n\nWe were able to reproduce their results using their code, yielding mostly similar results. TGT generally outperforms DBM, especially when explanations use few features. TGT is consistent in terms of the features to which it attributes cluster differences across different sparsity levels. TGT matches real patterns in data. When extending the types of functions used for explanations, performance did not improve significantly, suggesting translations make for adequate explanations. However, the scaling extension shows promising performance on the modified synthetic data to recover the original signal.\n\nThe easiest part was running the existing code with the pre-trained model files. The original authors had set up their codebase in an organized manner with clear instructions.\n\nThe first difficulty that we encounter was finding the right environment. The source code depends on deprecated functionality. The clustering method they used, had to be re-implemented for us to use it in our replication. Another difficulty was the selection of clusters. The authors did not prove a consistent method for selecting clusters in a latent space representation. When retraining the provided models, we get a latent space representation different from the original experiments. The clusters have to be manually selected. The metrics that they used to evaluate their explanations are also depending on the clustering. This means that there is some variability in the exact verification of reproducibility.\n\nWe asked the original authors for clarification on how to choose the $\\epsilon$ hyper-parameter. However, it became apparent that we had misread, and the procedure is indeed adequately reported in the paper.\n\n\n\n\n\n\n"}}
