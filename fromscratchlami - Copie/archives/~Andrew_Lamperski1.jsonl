{"id": "KxVSnZVuZZ", "cdate": 1652737390762, "mdate": null, "content": {"title": "Constrained Langevin Algorithms with L-mixing External Random Variables", "abstract": "Langevin algorithms are gradient descent methods augmented with additive noise, and are widely used in Markov Chain Monte Carlo (MCMC) sampling, optimization, and machine learning. In recent years, the non-asymptotic analysis of Langevin algorithms for non-convex learning has been extensively explored. For constrained problems with non-convex losses over a compact convex domain with IID data variables, the projected Langevin algorithm achieves a deviation of $O(T^{-1/4} (\\log T)^{1/2})$ from its target distribution \\cite{lamperski2021projected} in $1$-Wasserstein distance. In this paper, we obtain a deviation of $O(T^{-1/2} \\log T)$ in $1$-Wasserstein distance for non-convex losses with $L$-mixing data variables and polyhedral constraints (which are not necessarily bounded). This improves on the previous bound for constrained problems and matches the best-known bound for unconstrained problems.\n"}}
{"id": "BnM5Aaac6iZ", "cdate": 1596126271623, "mdate": null, "content": {"title": "A Random Algorithm for Semidefinite Programming Problems", "abstract": "We introduce a first-order method for solving semidefinite programming problems. This method has low computational complexity per iteration and is easy to implement. In each iteration, it alternates in two steps: gradient-descent to optimize the objective function, and random projection to reduce the infeasibility of the constraints. Due to its low computational complexity per iteration, it can be scaled to\nlarge problems. We also prove the algorithm\u2019s convergence and demonstrate its performance in numerical examples."}}
{"id": "rm07K2m5DXr", "cdate": 1596126193608, "mdate": null, "content": {"title": "Online Control Basis Selection by a Regularized Actor Critic Algorithm", "abstract": "Policy gradient algorithms are useful reinforcement learning methods which optimize a control policy by performing stochastic gradient descent with respect to controller parameters. In this paper, we extend actor-critic algorithms by adding an $\\ell_1$ norm regularization on the actor part, which makes our algorithm automatically select and optimize the useful controller basis functions. Our method is closely related to existing approaches to sparse controller design and actuator selection, but in contrast to these, our approach runs online\nand does not require a plant model. In order to utilize $\\ell_1$ regularization online, the actor updates are extended to include an\niterative soft-thresholding step. Convergence of the algorithm is proved using methods from stochastic approximation. The\neffectiveness of our algorithm for control basis and actuator selection is demonstrated on numerical examples."}}
{"id": "_ScVFRQvq5s", "cdate": 1596125884288, "mdate": null, "content": {"title": "Trading-Off Static and Dynamic Regret in Online Least-Squares and Beyond", "abstract": "Recursive least-squares algorithms often use forgetting factors as a heuristic to adapt to nonstationary data streams. The first contribution of this paper rigorously characterizes the effect of forgetting factors for a class of online Newton algorithms. For exp-concave and strongly convex objectives, the algorithms achieve the dynamic regret of $\\max\\{O(\\log T), O(\\sqrt{T V})\\}$, where V is a\nbound on the path length of the comparison sequence. In particular, we show how classic recursive\nleast-squares with a forgetting factor achieves this dynamic regret bound. By varying V, we obtain a trade-off between static and dynamic regret. In order to obtain more computationally efficient algorithms, our second contribution is a novel gradient descent step size rule for strongly convex functions. Our gradient descent rule recovers the order optimal dynamic regret bounds described above. For smooth problems, we can also obtain static regret of $O(T^{1\u2212\\beta})$ and dynamic regret of $O(T^{\\beta}V^*)$, where $\\beta \\in (0, 1)$ and $V^*$ is the path length of the sequence of minimizers. By varying $\\beta$, we obtain a trade-off between static and dynamic regret."}}
{"id": "YYW9PRhl16", "cdate": 1577836800000, "mdate": null, "content": {"title": "First-Order Algorithms for Constrained Nonlinear Dynamic Games.", "abstract": "This paper presents algorithms for non-zero sum nonlinear constrained dynamic games with full information. Such problems emerge when multiple players with action constraints and differing objectives interact with the same dynamic system. They model a wide range of applications including economics, defense, and energy systems. We show how to exploit the temporal structure in projected gradient and Douglas-Rachford (DR) splitting methods. The resulting algorithms converge locally to open-loop Nash equilibria (OLNE) at linear rates. Furthermore, we extend stagewise Newton method to find a local feedback policy around an OLNE. In the of linear dynamics and polyhedral constraints, we show that this local feedback controller is an approximated feedback Nash equilibrium (FNE). Numerical examples are provided."}}
{"id": "JR7MfCp-8a", "cdate": 1577836800000, "mdate": null, "content": {"title": "Moment analysis of stochastic hybrid systems using semidefinite programming.", "abstract": "This paper proposes a method based on semidefinite programming for estimating moments of stochastic hybrid systems (SHSs). The class of SHSs considered herein consists of a finite number of discrete states and a continuous state whose dynamics as well as the reset maps and transition intensities are polynomial in the continuous state. For these SHSs, the dynamics of moments evolve according to a system of linear ordinary differential equations. However, it is generally not possible to exactly solve the system since time evolution of a specific moment may depend upon moments of order higher than it. Our methodology recasts an SHS with multiple discrete modes to a single-mode SHS with algebraic constraints. We then find lower and upper bounds on a moment of interest via a semidefinite program that includes linear constraints obtained from moment dynamics and those arising from the recasting process, along with semidefinite constraints coming from the non-negativity of moment matrices. We illustrate the methodology via an example of SHS. Previous article in issue Next article in issue"}}
{"id": "sKu_AvPSQev", "cdate": 1546300800000, "mdate": null, "content": {"title": "Corruption Detection in Networks of Bi-directional Dynamical Systems.", "abstract": "Modeling complex networked systems as graphs is prevalent, with nodes representing the agents and the links describing a notion of dynamic coupling between them. Passive methods to identify such influence pathways from data are central to many applications. However, dynamically related data-streams originating at different sources are prone to corruption caused by asynchronous time-stamps of different streams, packet drops and noise. Earlier results have shown that spurious links are inferred in the graph structure identified using corrupt data-streams. In this article, we provide a novel approach to detect the location of corrupt agents in the network solely by observing the inferred directed graph. Here, the generative system that yields the data admits bidirectionally coupled nonlinear dynamic influences between agents. A simple, but novel and effective approach, using graph theory tools is presented to arrive at the results."}}
{"id": "ra0K-8SwTRR", "cdate": 1546300800000, "mdate": null, "content": {"title": "Newton's Method and Differential Dynamic Programming for Unconstrained Nonlinear Dynamic Games.", "abstract": "Dynamic games arise when multiple agents with differing objectives choose control inputs to a dynamic system. However, compared to single-agent control problems, the computational methods for dynamic games are relatively limited. Only very specialized dynamic games can be solved exactly, so approximation algorithms are required. In this paper, we show how to extend a recursive Newton algorithm and differential dynamic programming (DDP) to the case of full-information non-zero sum dynamic games. We show that the iterates of Newton's method and DDP are sufficiently close for DDP to inherit the quadratic convergence rate of Newton's method."}}
{"id": "iSFgmgEDR7c", "cdate": 1546300800000, "mdate": null, "content": {"title": "Analysis and Control of Stochastic Systems Using Semidefinite Programming Over Moments.", "abstract": "This technical note develops a unified methodology for probabilistic analysis and optimal control design for jump diffusion processes defined by polynomials. The statistical moments of these systems can be described by a system of linear ordinary differential equations. Typically, however, the low-order moments depend on higher order moments, thus requiring an infinite system of equations to compute any moment exactly. Here, we develop a methodology for bounding statistical moments by using the higher order moments as inputs to an auxiliary convex optimal control problem with semidefinite constraints. For steady-state problems, the auxiliary optimal control problem reduces to a static semidefinite program. The method applies to both controlled and uncontrolled stochastic processes. For stochastic optimal control problems, the method gives bounds on achievable performance and can be used to compute approximately optimal solutions. For uncontrolled problems, both upper and lower bounds on desired moments can be computed. While the accuracy of most moment approximations cannot be quantitatively characterized, our method guarantees that the moment of interest is between the computed bounds."}}
{"id": "fb2eXXjX9cx", "cdate": 1546300800000, "mdate": null, "content": {"title": "Trading-Off Static and Dynamic Regret in Online Least-Squares and Beyond.", "abstract": "Recursive least-squares algorithms often use forgetting factors as a heuristic to adapt to non-stationary data streams. The first contribution of this paper rigorously characterizes the effect of forgetting factors for a class of online Newton algorithms. For exp-concave and strongly convex objectives, the algorithms achieve the dynamic regret of $\\max\\{O(\\log T),O(\\sqrt{TV})\\}$, where $V$ is a bound on the path length of the comparison sequence. In particular, we show how classic recursive least-squares with a forgetting factor achieves this dynamic regret bound. By varying $V$, we obtain a trade-off between static and dynamic regret. In order to obtain more computationally efficient algorithms, our second contribution is a novel gradient descent step size rule for strongly convex functions. Our gradient descent rule recovers the order optimal dynamic regret bounds described above. For smooth problems, we can also obtain static regret of $O(T^{1-\\beta})$ and dynamic regret of $O(T^\\beta V^*)$, where $\\beta \\in (0,1)$ and $V^*$ is the path length of the sequence of minimizers. By varying $\\beta$, we obtain a trade-off between static and dynamic regret."}}
