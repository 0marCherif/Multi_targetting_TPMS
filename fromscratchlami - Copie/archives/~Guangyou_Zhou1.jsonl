{"id": "nHmTM08LDZ", "cdate": 1693526400000, "mdate": 1696301011922, "content": {"title": "Query Path Generation via Bidirectional Reasoning for Multihop Question Answering From Knowledge Bases", "abstract": "Multihop question answering from knowledge bases (KBQA) is a hot research topic in natural language processing. Recently, the graph neural network-based (GNN-based) methods have achieved promising results as the KB can be organized as a knowledge graph (KG). However, they often suffered from the sparsity of the KG which was detrimental to the structure encoding and reasoning capabilities of GNN. Specifically, a KG is a sparse graph linked by directed relations and previous studies have paid scant attention to the directional characteristic of relations in the KG, limiting the patterns of relation path that GNN-based approaches could resolve. This study proposes a bidirectional recurrent GNN (BRGNN) to tackle these difficulties. To model the bidirectional information of relations, all adjacent relations of an entity are grouped by their directions, and they are separately aggregated into the entity representation in outward and inward directions. For the reasoning process, BRGNN simultaneously considers the neighbor relations in both directions to cover more patterns of relation paths and improve the recall of answers. Extensive experiments on three benchmarks: WebQuestionsSP, ComplexWebQuestions, and MetaQA, verify that BRGNN can answer more questions by taking into account the directional information, and it is competitive to all state-of-the-art approaches."}}
{"id": "xEjqQaxBJu", "cdate": 1672531200000, "mdate": 1682991741825, "content": {"title": "A question-guided multi-hop reasoning graph network for visual question answering", "abstract": ""}}
{"id": "phmXVVdVCRp", "cdate": 1672531200000, "mdate": 1696301011910, "content": {"title": "TARGAT: A Time-Aware Relational Graph Attention Model for Temporal Knowledge Graph Embedding", "abstract": "Temporal knowledge graph embedding (TKGE) aims to learn the embedding of entities and relations in a temporal knowledge graph (TKG). Although the previous graph neural networks (GNN) based models have achieved promising results, they cannot directly capture the interactions of multi-facts at different timestamps. To address the above limitation, we propose a time-aware relational graph attention model (TARGAT), which takes the multi-facts at different timestamps as a unified graph. First, we develop a relational generator to dynamically generate a series of time-aware relational message transformation matrices, which jointly models the relations and the timestamp information into a unified way. Then, we apply the generated message transformation matrices to project the neighborhood features into different time-aware spaces and aggregate these neighborhood features to explicitly capture the interactions of multi-facts. Finally, a temporal transformer classifier is applied to learn the representation of the query quadruples and predict the missing entities. The experimental results show that our TARGAT model beats the GNN-based models by a large margin and achieves new state-of-the-art results on four popular benchmark datasets."}}
{"id": "Ao72WxXC1Ik", "cdate": 1672531200000, "mdate": 1696301011907, "content": {"title": "Learning Query Adaptive Anchor Representation for Inductive Relation Prediction", "abstract": ""}}
{"id": "sWazxpEbNX3", "cdate": 1640995200000, "mdate": 1682991741711, "content": {"title": "Generating Factoid Questions with Question Type Enhanced Representation and Attention-based Copy Mechanism", "abstract": "Question generation over knowledge bases is an important research topic. How to deal with rare and low-frequency words in traditional generation models is a key challenge for question generation. Although the copy mechanism provides significant performance improvements, the original copy mechanism weakens the focus on aspect generation in the overall representations. In this article, we present a novel method to improve question generation with a question type enhanced representation and attention-based copy mechanism. The proposed method exploits the advantages of the generate mode in the copy mechanism and replaces objects in the factual triples with question types, which attempts to improve the output quality in the generate mode and effectively generate questions with proper interrogative words. We evaluate the proposed method on two standard benchmark datasets. The experimental results demonstrate that our proposed method can produce higher-quality questions than these of the Encoder-Decoder-based and CopyNet-based methods."}}
{"id": "rpPNaSdRm92", "cdate": 1640995200000, "mdate": 1682991741680, "content": {"title": "A3MR: Attentive Auto-encoder for Acoustic-assisted Music Recommendation", "abstract": "In the era of big data, users often seem to be unable to make choices in the face of such a huge range of options. This is especially the case with music; consequently, personalized music recommendation has attracted much interest. Many effective strategies have been offered by researchers, nevertheless, they still face two challenging problems: (1) how to model the complex usermusic relationships from sparse implicit feedback data, and (2) how to introduce auxiliary information to improve the recom-mendation effect. To copy with these challenges, we propose an Attentive Auto-encoder for Acoustic-assisted Music Recommen-dation (A <sup xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">3</sup> MR), which takes user historical behaviors, music acoustic features, and similar music to the objective music into account. Especially, we design a multi-attention layer to learn complex user-music relationships in order to gain the hidden representation of the objective music based on uses' behaviors. Besides, we use an embedding layer to generate music repre-sentation based on acoustic features, and cluster the similar music to objective music in order to predict users' preference. We conduct a series of experiments on the real-world dataset to evaluate the proposed model, and the results indicate that it is effective."}}
{"id": "pJ-TR6cq34", "cdate": 1640995200000, "mdate": 1696301011903, "content": {"title": "How Severe is Your COVID-19? Predicting SARS-CoV-2 Infection with Graph Attention Capsule Networks", "abstract": "Recent studies in machine learning have demonstrated the effectiveness of applying graph neural networks (GNNs) to single-cell RNA sequencing (scRNA-seq) data to predict COVID-19 disease states. In this study, we propose a graph attention capsule network (GACapNet) which extracts and fuses Severe Acute Respiratory Syndrome Coronavirus 2 (SARS-CoV-2) transcriptomic patterns to improve node classification performance on cells and genes. Significantly different from the existing GNN approaches, we innovatively incorporate a capsule layer with dynamic routing into our model architecture to combine and fuse gene features effectively and to allow those more prominent gene features present in the output. We evaluate our GACapNet model on two scRNA-seq datasets, and the experimental results show that our GACapNet model significantly outperforms state-of-the-art baseline models. Therefore, our study demonstrates the capability of advanced machine learning models to generate predictive features and evolutionary patterns of the SARS-CoV-2 pathogen, and the applicability of closing knowledge gaps in the pathogenesis and recovery of COVID-19."}}
{"id": "nMfsdBVFxA", "cdate": 1640995200000, "mdate": 1682991741665, "content": {"title": "ARL: An adaptive reinforcement learning framework for complex question answering over knowledge base", "abstract": ""}}
{"id": "hlcTPZO2ve", "cdate": 1640995200000, "mdate": 1682991742372, "content": {"title": "Dual Gated Graph Attention Networks with Dynamic Iterative Training for Cross-Lingual Entity Alignment", "abstract": "Cross-lingual entity alignment has attracted considerable attention in recent years. Past studies using conventional approaches to match entities share the common problem of missing important structural information beyond entities in the modeling process. This allows graph neural network models to step in. Most existing graph neural network approaches model individual knowledge graphs (KGs) separately with a small amount of pre-aligned entities served as anchors to connect different KG embedding spaces. However, this characteristic can cause several major problems, including performance restraint due to the insufficiency of available seed alignments and ignorance of pre-aligned links that are useful in contextual information in-between nodes. In this article, we propose DuGa-DIT, a dual gated graph attention network with dynamic iterative training, to address these problems in a unified model. The DuGa-DIT model captures neighborhood and cross-KG alignment features by using intra-KG attention and cross-KG attention layers. With the dynamic iterative process, we can dynamically update the cross-KG attention score matrices, which enables our model to capture more cross-KG information. We conduct extensive experiments on two benchmark datasets and a case study in cross-lingual personalized search. Our experimental results demonstrate that DuGa-DIT outperforms state-of-the-art methods."}}
{"id": "hQCxy_OmCP", "cdate": 1640995200000, "mdate": 1682991741659, "content": {"title": "Modeling Temporal-Sensitive Information for Complex Question Answering over Knowledge Graphs", "abstract": "Question answering over temporal knowledge graphs (TKGQA) has attracted great attentions in natural language processing community. One of the key challenges is how to effectively model the representations of questions and the candidate answers associated with timestamp constraints. Many existing methods attempt to learn temporal knowledge graph embedding for entities, relations and timestamps. However, these existing methods cannot effectively exploiting temporal knowledge graph embeddings to capture time intervals (e.g., \u201cWWII\u201d refers to 1939\u20131945) as well as temporal relation words (e.g., \u201cfirst\u201d and \u201clast\u201d) appeared in complex questions, resulting in the sub-optimal results. In this paper, we propose a temporal-sensitive information for complex question answering (TSIQA) framework to tackle these problems. We employ two alternative approaches to augment questions embeddings with question-specific time interval information, which consists of specific start and end timestamps. We also present auxiliary contrastive learning to contrast the answer prediction and prior knowledge regarding time approximation for questions that only differ by the temporal relation words. To evaluate the effectiveness of our proposed method, we conduct the experiments on $$\\textbf{C}$$ RON $$\\textbf{Q}$$ UESTION. The results show that our proposed model achieves better improvements over the state-of-the-art models that require multiple steps of reasoning."}}
