{"id": "Y4RpOD5vPk-", "cdate": 1686250300478, "mdate": null, "content": {"title": "Delayed Bandits: When Do Intermediate Observations Help?", "abstract": "We study a $K$-armed bandit with delayed feedback and intermediate observations. We consider a model where intermediate observations have a form of a finite state, which is observed immediately after taking an action, whereas the loss is observed after an adversarially chosen delay. We show that the regime of the mapping of states to losses determines the complexity of the problem, irrespective of whether the mapping of actions to states is stochastic or adversarial. If the mapping of states to losses is adversarial, then the regret rate is of order $\\sqrt{(K+d)T}$ (within log factors), where $T$ is the time horizon and $d$ is a fixed delay. This matches the regret rate of a $K$-armed bandit with delayed feedback and without intermediate observations, implying that intermediate observations are not helpful. However, if the mapping of states to losses is stochastic, we show that the regret grows at a rate of $\\sqrt{\\bigl(K+\\min\\{|\\mathcal{S}|,d\\}\\bigr)T}$ (within log factors), implying that if the number $|\\mathcal{S}|$ of states is smaller than the delay, then intermediate observations help. We also provide refined high-probability regret upper bounds for non-uniform delays, together with experimental validation of our algorithms."}}
{"id": "5XtsqM57-Zb", "cdate": 1652737719556, "mdate": null, "content": {"title": "Learning on the Edge: Online Learning with Stochastic Feedback Graphs", "abstract": "The framework of feedback graphs is a generalization of sequential decision-making with bandit or full information feedback. In this work, we study an extension where the directed feedback graph is stochastic, following a distribution similar to the classical Erd\u0151s-R\u00e9nyi model. Specifically, in each round every edge in the graph is either realized or not with a distinct probability for each edge. We prove nearly optimal regret bounds of order $\\min\\bigl\\{\\min_{\\varepsilon} \\sqrt{(\\alpha_\\varepsilon/\\varepsilon) T},\\, \\min_{\\varepsilon} (\\delta_\\varepsilon/\\varepsilon)^{1/3} T^{2/3}\\bigr\\}$ (ignoring logarithmic factors), where $\\alpha_{\\varepsilon}$ and $\\delta_{\\varepsilon}$ are graph-theoretic quantities measured on the support of the stochastic feedback graph $\\mathcal{G}$ with edge probabilities thresholded at $\\varepsilon$. Our result, which holds without any preliminary knowledge about $\\mathcal{G}$, requires the learner to observe only the realized out-neighborhood of the chosen action. When the learner is allowed to observe the realization of the entire graph (but only the losses in the out-neighborhood of the chosen action), we derive a more efficient algorithm featuring a dependence on weighted versions of the independence and weak domination numbers that exhibits improved bounds for some special cases."}}
{"id": "XtxG6dBOpAQ", "cdate": 1652737702680, "mdate": null, "content": {"title": "A Regret-Variance Trade-Off in Online Learning", "abstract": "We consider prediction with expert advice for strongly convex and bounded losses, and investigate trade-offs between regret and ``variance'' (i.e., squared difference of learner's predictions and best expert predictions).\nWith $K$ experts, the Exponentially Weighted Average (EWA) algorithm is known to achieve $O(\\log K)$ regret.\nWe prove that a variant of EWA either achieves a \\textsl{negative} regret (i.e., the algorithm outperforms the best expert), or guarantees a $O(\\log K)$ bound on \\textsl{both} variance and regret.\nBuilding on this result, we show several examples of how variance of predictions can be exploited in learning.\nIn the online to batch analysis, we show that a large empirical variance allows to stop the online to batch conversion early and outperform the risk of the best predictor in the class. We also recover the optimal rate of model selection aggregation when we do not consider early stopping.\nIn online prediction with corrupted losses, we show that the effect of corruption on the regret can be compensated by a large variance.\nIn online selective sampling, we design an algorithm that samples less when the variance is large, while guaranteeing the optimal regret bound in expectation.\nIn online learning with abstention, we use a similar term as the variance to derive the first high-probability $O(\\log K)$ regret bound in this setting.\nFinally, we extend our results to the setting of online linear regression."}}
{"id": "pbILUUf_hBN", "cdate": 1652737418452, "mdate": null, "content": {"title": "A Near-Optimal Best-of-Both-Worlds Algorithm for Online Learning with Feedback Graphs", "abstract": "We consider online learning with feedback graphs, a sequential decision-making framework where the learner's feedback is determined by a directed graph over the action set. We present a computationally-efficient algorithm for learning in this framework that simultaneously achieves near-optimal regret bounds in both stochastic and adversarial environments. The bound against oblivious adversaries is $\\tilde{O} (\\sqrt{\\alpha T})$, where $T$ is the time horizon and $\\alpha$ is the independence number of the feedback graph. The bound against stochastic environments is $O\\big((\\ln T)^2 \\max_{S\\in \\mathcal I(G)} \\sum_{i \\in S} \\Delta_i^{-1}\\big)$ where $\\mathcal I(G)$ is the family of all independent sets in a suitably defined undirected version of the graph and $\\Delta_i$ are the suboptimality gaps.\nThe algorithm combines ideas from the EXP3++ algorithm for stochastic and adversarial bandits and the EXP3.G algorithm for feedback graphs with a novel exploration scheme. The scheme, which exploits the structure of the graph to reduce exploration, is key to obtain best-of-both-worlds guarantees with feedback graphs. \nWe also extend our algorithm and results to a setting where the feedback graphs are allowed to change over time."}}
{"id": "07v1SfTxkQ0", "cdate": 1640995200000, "mdate": 1651239770656, "content": {"title": "Distributed Online Learning for Joint Regret with Communication Constraints", "abstract": "We consider distributed online learning for joint regret with communication constraints. In this setting, there are multiple agents that are connected in a graph. Each round, an adversary first act..."}}
{"id": "cZpUtLSOJnu", "cdate": 1621629764658, "mdate": null, "content": {"title": "Beyond Bandit Feedback in Online Multiclass Classification", "abstract": "We study the problem of online multiclass classification in a setting where the learner's feedback is determined by an arbitrary directed graph. While including bandit feedback as a special case, feedback graphs allow a much richer set of applications, including filtering and label efficient classification.\nWe introduce \\textproc{Gappletron}, the first online multiclass algorithm that works with arbitrary feedback graphs. For this new algorithm,\nwe prove surrogate regret bounds that hold, both in expectation and with high probability, for a large class of surrogate losses. Our bounds are of order $B\\sqrt{\\rho KT}$, where $B$ is the diameter of the prediction space, $K$ is the number of classes, $T$ is the time horizon, and $\\rho$ is the domination number (a graph-theoretic parameter affecting the amount of exploration). In the full information case, we show that \\textproc{Gappletron} achieves a constant surrogate regret of order $B^2K$. We also prove a general lower bound of order $\\max\\big\\{B^2K,\\sqrt{T}\\big\\}$ showing that our upper bounds are not significantly improvable. Experiments on synthetic data show that for various feedback graphs our algorithm is competitive against known baselines."}}
{"id": "AVvcLO2UYGA", "cdate": 1621629764658, "mdate": null, "content": {"title": "Beyond Bandit Feedback in Online Multiclass Classification", "abstract": "We study the problem of online multiclass classification in a setting where the learner's feedback is determined by an arbitrary directed graph. While including bandit feedback as a special case, feedback graphs allow a much richer set of applications, including filtering and label efficient classification.\nWe introduce \\textproc{Gappletron}, the first online multiclass algorithm that works with arbitrary feedback graphs. For this new algorithm,\nwe prove surrogate regret bounds that hold, both in expectation and with high probability, for a large class of surrogate losses. Our bounds are of order $B\\sqrt{\\rho KT}$, where $B$ is the diameter of the prediction space, $K$ is the number of classes, $T$ is the time horizon, and $\\rho$ is the domination number (a graph-theoretic parameter affecting the amount of exploration). In the full information case, we show that \\textproc{Gappletron} achieves a constant surrogate regret of order $B^2K$. We also prove a general lower bound of order $\\max\\big\\{B^2K,\\sqrt{T}\\big\\}$ showing that our upper bounds are not significantly improvable. Experiments on synthetic data show that for various feedback graphs our algorithm is competitive against known baselines."}}
{"id": "tyncfV0iIYY", "cdate": 1609459200000, "mdate": 1651239770656, "content": {"title": "MetaGrad: Adaptation using Multiple Learning Rates in Online Learning", "abstract": "We provide a new adaptive method for online convex optimization, MetaGrad, that is robust to general convex losses but achieves faster rates for a broad class of special functions, including exp-concave and strongly convex functions, but also various types of stochastic and non-stochastic functions without any curvature. We prove this by drawing a connection to the Bernstein condition, which is known to imply fast rates in offline statistical learning. MetaGrad further adapts automatically to the size of the gradients. Its main feature is that it simultaneously considers multiple learning rates, which are weighted directly proportional to their empirical performance on the data using a new meta-algorithm. We provide three versions of MetaGrad. The full matrix version maintains a full covariance matrix and is applicable to learning tasks for which we can afford update time quadratic in the dimension. The other two versions provide speed-ups for high-dimensional learning tasks with an update time that is linear in the dimension: one is based on sketching, the other on running a separate copy of the basic algorithm per coordinate. We evaluate all versions of MetaGrad on benchmark online classification and regression tasks, on which they consistently outperform both online gradient descent and AdaGrad."}}
{"id": "i-Y8ot-s1V", "cdate": 1609459200000, "mdate": 1651239770657, "content": {"title": "Nonstochastic Bandits and Experts with Arm-Dependent Delays", "abstract": "We study nonstochastic bandits and experts in a delayed setting where delays depend on both time and arms. While the setting in which delays only depend on time has been extensively studied, the arm-dependent delay setting better captures real-world applications at the cost of introducing new technical challenges. In the full information (experts) setting, we design an algorithm with a first-order regret bound that reveals an interesting trade-off between delays and losses. We prove a similar first-order regret bound also for the bandit setting, when the learner is allowed to observe how many losses are missing. These are the first bounds in the delayed setting that depend on the losses and delays of the best arm only. When in the bandit setting no information other than the losses is observed, we still manage to prove a regret bound through a modification to the algorithm of Zimmert and Seldin (2020). Our analyses hinge on a novel bound on the drift, measuring how much better an algorithm can perform when given a look-ahead of one round."}}
{"id": "XSSiyqP7WiK", "cdate": 1609459200000, "mdate": 1651239770656, "content": {"title": "Beyond Bandit Feedback in Online Multiclass Classification", "abstract": "We study the problem of online multiclass classification in a setting where the learner's feedback is determined by an arbitrary directed graph. While including bandit feedback as a special case, feedback graphs allow a much richer set of applications, including filtering and label efficient classification. We introduce Gappletron, the first online multiclass algorithm that works with arbitrary feedback graphs. For this new algorithm, we prove surrogate regret bounds that hold, both in expectation and with high probability, for a large class of surrogate losses. Our bounds are of order $B\\sqrt{\\rho KT}$, where $B$ is the diameter of the prediction space, $K$ is the number of classes, $T$ is the time horizon, and $\\rho$ is the domination number (a graph-theoretic parameter affecting the amount of exploration). In the full information case, we show that Gappletron achieves a constant surrogate regret of order $B^2K$. We also prove a general lower bound of order $\\max\\big\\{B^2K,\\sqrt{T}\\big\\}$ showing that our upper bounds are not significantly improvable. Experiments on synthetic data show that for various feedback graphs, our algorithm is competitive against known baselines."}}
