{"id": "XfpvWyH2kgV", "cdate": 1672531200000, "mdate": 1681737776113, "content": {"title": "Learning from Multiple Independent Advisors in Multi-agent Reinforcement Learning", "abstract": "Multi-agent reinforcement learning typically suffers from the problem of sample inefficiency, where learning suitable policies involves the use of many data samples. Learning from external demonstrators is a possible solution that mitigates this problem. However, most prior approaches in this area assume the presence of a single demonstrator. Leveraging multiple knowledge sources (i.e., advisors) with expertise in distinct aspects of the environment could substantially speed up learning in complex environments. This paper considers the problem of simultaneously learning from multiple independent advisors in multi-agent reinforcement learning. The approach leverages a two-level Q-learning architecture, and extends this framework from single-agent to multi-agent settings. We provide principled algorithms that incorporate a set of advisors by both evaluating the advisors at each state and subsequently using the advisors to guide action selection. We also provide theoretical convergence and sample complexity guarantees. Experimentally, we validate our approach in three different test-beds and show that our algorithms give better performances than baselines, can effectively integrate the combined expertise of different advisors, and learn to ignore bad advice."}}
{"id": "MLC1TLxOWwY", "cdate": 1672531200000, "mdate": 1681559408528, "content": {"title": "Combining Tree-Search, Generative Models, and Nash Bargaining Concepts in Game-Theoretic Reinforcement Learning", "abstract": ""}}
{"id": "CAQZNiNQ9G", "cdate": 1672531200000, "mdate": 1681737775978, "content": {"title": "Revealed Multi-Objective Utility Aggregation in Human Driving", "abstract": "A central design problem in game theoretic analysis is the estimation of the players' utilities. In many real-world interactive situations of human decision making, including human driving, the utilities are multi-objective in nature; therefore, estimating the parameters of aggregation, i.e., mapping of multi-objective utilities to a scalar value, becomes an essential part of game construction. However, estimating this parameter from observational data introduces several challenges due to a host of unobservable factors, including the underlying modality of aggregation and the possibly boundedly rational behaviour model that generated the observation. Based on the concept of rationalisability, we develop algorithms for estimating multi-objective aggregation parameters for two common aggregation methods, weighted and satisficing aggregation, and for both strategic and non-strategic reasoning models. Based on three different datasets, we provide insights into how human drivers aggregate the utilities of safety and progress, as well as the situational dependence of the aggregation process. Additionally, we show that irrespective of the specific solution concept used for solving the games, a data-driven estimation of utility aggregation significantly improves the predictive accuracy of behaviour models with respect to observed human behaviour."}}
{"id": "qfl79P5Qpa", "cdate": 1640995200000, "mdate": 1672765495295, "content": {"title": "Multi-Agent Advisor Q-Learning", "abstract": ""}}
{"id": "hxwJ3RSG2nb", "cdate": 1640995200000, "mdate": 1672765495292, "content": {"title": "The Importance of Credo in Multiagent Learning", "abstract": ""}}
{"id": "hmBdZvuDQw", "cdate": 1640995200000, "mdate": 1672765495306, "content": {"title": "Exploring the Benefits of Teams in Multiagent Learning", "abstract": ""}}
{"id": "btbL0aFqdV", "cdate": 1640995200000, "mdate": 1672765495286, "content": {"title": "Developing, evaluating and scaling learning agents in multi-agent environments", "abstract": ""}}
{"id": "WfYmWJ-Wri", "cdate": 1640995200000, "mdate": 1672765495339, "content": {"title": "Developing, Evaluating and Scaling Learning Agents in Multi-Agent Environments", "abstract": ""}}
{"id": "RoSVid5hwKE", "cdate": 1640995200000, "mdate": 1672332689457, "content": {"title": "How Should We Vote? A Comparison of Voting Systems within Social Networks", "abstract": ""}}
{"id": "Qbg0oW3tuy", "cdate": 1640995200000, "mdate": 1672765495302, "content": {"title": "Exploring the Benefits of Teams in Multiagent Learning", "abstract": ""}}
