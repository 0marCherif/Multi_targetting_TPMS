{"id": "rye4lT4tvB", "cdate": 1569438955749, "mdate": null, "content": {"title": "PAD-Nets: Learning Dynamic Receptive Fields via Pixel-Wise Adaptive Dilation", "abstract": "Dilated convolution kernels are constrained by their shared dilation, keeping them from being aware of diverse spatial contents at different locations. We address such limitations by formulating the dilation as trainable weights respect to individual positions. We introduce Pixel-wise Adaptive Dilation (PAD), a light-weighted extension that allows convolution kernels to flexibly adjust receptive fields based on different contents at pixel level. By inferring dilation via modeling inter-layer patterns, PAD-Nets also provide a possible way to partially understand the hierarchical representations of CNNs. Our evaluation results indicate PAD-Nets can consistently outperform their conventional counterparts on various visual tasks."}}
{"id": "rQ0V2kMgd6r", "cdate": 1546300800000, "mdate": null, "content": {"title": "Learning to Adaptively Scale Recurrent Neural Networks.", "abstract": "Recent advancements in recurrent neural network (RNN) research have demonstrated the superiority of utilizing multiscale structures in learning temporal representations of time series. Currently, most of multiscale RNNs use fixed scales, which do not comply with the nature of dynamical temporal patterns among sequences. In this paper, we propose Adaptively Scaled Recurrent Neural Networks (ASRNN), a simple but efficient way to handle this problem. Instead of using predefined scales, ASRNNs are able to learn and adjust scales based on different temporal contexts, making them more flexible in modeling multiscale patterns. Compared with other multiscale RNNs, ASRNNs are bestowed upon dynamical scaling capabilities with much simpler structures, and are easy to be integrated with various RNN cells. The experiments on multiple sequence modeling tasks indicate ASRNNs can efficiently adapt scales based on different sequence contexts and yield better performances than baselines without dynamical scaling abilities."}}
{"id": "SyEr0A-OWS", "cdate": 1514764800000, "mdate": null, "content": {"title": "Global Versus Localized Generative Adversarial Nets", "abstract": "In this paper, we present a novel localized Generative Adversarial Net (GAN) to learn on the manifold of real data. Compared with the classic GAN that {em globally} parameterizes a manifold, the Localized GAN (LGAN) uses local coordinate charts to parameterize distinct local geometry of how data points can transform at different locations on the manifold. Specifically, around each point there exists a {em local} generator that can produce data following diverse patterns of transformations on the manifold. The locality nature of LGAN enables local generators to adapt to and directly access the local geometry without need to invert the generator in a global GAN. Furthermore, it can prevent the manifold from being locally collapsed to a dimensionally deficient tangent subspace by imposing an orthonormality prior between tangents. This provides a geometric approach to alleviating mode collapse at least locally on the manifold by imposing independence between data transformations in different tangent directions. We will also demonstrate the LGAN can be applied to train a robust classifier that prefers locally consistent classification decisions on the manifold, and the resultant regularizer is closely related with the Laplace-Beltrami operator. Our experiments show that the proposed LGANs can not only produce diverse image transformations, but also deliver superior classification performances."}}
{"id": "rk-rxAW_bH", "cdate": 1483228800000, "mdate": null, "content": {"title": "Temporal Domain Neural Encoder for Video Representation Learning", "abstract": "We address the challenge of learning good video representations by explicitly modeling the relationship between visual concepts in time space. We propose a novel Temporal Preserving Recurrent Neural Network (TPRNN) that extracts and encodes visual dynamics with frame-level features as input. The proposed network architecture captures temporal dynamics by keeping track of the ordinal relationship of co-occurring visual concepts, and constructs video representations with their temporal order patterns. The resultant video representations effectively encode temporal information of dynamic patterns, which makes them more discriminative to human actions performed with different sequences of action patterns. We evaluate the proposed model on several real video datasets, and the results show that it successfully outperforms the baseline models. In particular, we observe significant improvement on action classes that can only be distinguished by capturing the temporal orders of action patterns."}}
{"id": "rJbImnb_br", "cdate": 1483228800000, "mdate": null, "content": {"title": "State-Frequency Memory Recurrent Neural Networks", "abstract": "Modeling temporal sequences plays a fundamental role in various modern applications and has drawn more and more attentions in the machine learning community. Among those efforts on improving the ca..."}}
{"id": "B1bQ-BbubS", "cdate": 1451606400000, "mdate": null, "content": {"title": "Temporal Order-based First-Take-All Hashing for Fast Attention-Deficit-Hyperactive-Disorder Detection", "abstract": "Attention Deficit Hyperactive Disorder (ADHD) is one of the most common childhood disorders and can continue through adolescence and adulthood. Although the root cause of the problem still remains unknown, recent advancements in brain imaging technology reveal there exists differences between neural activities of Typically Developing Children (TDC) and ADHD subjects. Inspired by this, we propose a novel First-Take-All (FTA) hashing framework to investigate the problem of fast ADHD subjects detection through the fMRI time-series of neuron activities. By hashing time courses from regions of interests (ROIs) in the brain into fixed-size hash codes, FTA can compactly encode the temporal order differences between the neural activity patterns that are key to distinguish TDC and ADHD subjects. Such patterns can be directly learned via minimizing the training loss incurred by the generated FTA codes. By conducting similarity search on the resultant FTA codes, data-driven ADHD detection can be achieved in an efficient fashion. The experiments' results on real-world ADHD detection benchmarks demonstrate the FTA can outperform the state-of-the-art baselines using only neural activity time series without any phenotypic information."}}
{"id": "rkbbXVWubS", "cdate": 1325376000000, "mdate": null, "content": {"title": "Rank-directed layout of UML class diagrams", "abstract": "UML class diagram layout is an important task in software visualization to enhance people's comprehension about the systems. In this paper, we describe a novel UML class diagram layout algorithm, called rank-directed method, which captures the difference in relationships among classes and stresses significant classes. As a layout algorithm, rank-directed method supports the clustering of classes according to the inherent characteristics of classes. To recognize the significance of classes, we applied PageRank algorithms through abstracting relationships among different classes as the link among web pages. We assume that important classes have more relationships with other classes. To emphasize the important classes, rank-directed method adopts a sub graph layout method based on clustering of classes. We have developed a UML class diagram layout platform to evaluate our method. Our evaluation shows that rank-directed method could effectively recognize the important classes and layout the class diagram with higher readability than traditional layout methods do."}}
