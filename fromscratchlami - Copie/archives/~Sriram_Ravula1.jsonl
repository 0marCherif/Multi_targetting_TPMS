{"id": "UJadediTusC", "cdate": 1640995200000, "mdate": 1684298441016, "content": {"title": "One-dimensional Deep Image Prior for Time Series Inverse Problems", "abstract": "We extend the Deep Image Prior (DIP) framework to one-dimensional time series signals. DIP is using a randomly initialized convolutional neural network (CNN) to solve linear inverse problems by optimizing over the weights of the network to fit the observed measurements. Our main finding is that properly tuned one-dimensional convolutional architectures provide an excellent Deep Prior for various types of temporal signals including audio, biological signals, and sensor measurements. We show that our network can be used for a wide range of inverse tasks including missing value imputation, forecasting, and blind denoising. Our method outperforms baselines even with a fraction of the observed measurements in a variety of recovery tasks."}}
{"id": "HCOdL3dWab", "cdate": 1621630322484, "mdate": null, "content": {"title": "Inverse Problems Leveraging Pre-trained Contrastive Representations", "abstract": "We study a new family of inverse problems for recovering representations of corrupted data. We assume access to a pre-trained representation learning network R(x) that operates on clean images, like CLIP. The problem is to recover the representation of an image R(x), if we are only given a corrupted version A(x), for some known forward operator A. We propose a supervised inversion method that uses a contrastive objective to obtain excellent representations for highly corrupted images. Using a linear probe on our robust representations, we achieve a higher accuracy than end-to-end supervised baselines when classifying images with various types of distortions, including blurring, additive noise, and random pixel masking. We evaluate on a subset of ImageNet and observe that our method is robust to varying levels of distortion. Our method outperforms end-to-end baselines even with a fraction of the labeled data in a wide range of forward operators. "}}
{"id": "Sv1y2lajOF", "cdate": 1609459200000, "mdate": 1684298441016, "content": {"title": "A Comparison of Classical and Deep Learning-based Techniques for Compressing Signals in a Union of Subspaces", "abstract": "Many natural signals lie in a union of subspaces, which we can exploit when compressing these signals to maintain a high level of fidelity while significantly reducing the storage size. Standard compression techniques for natural signals such as images follow a general pipeline which uses predetermined transformations to encode and decode data. Recent advances in deep learning-based techniques for compressing image data have shown results which compete with existing compression standards. Inspired by the success of these deep learning methods, we evaluate various classical and deep learning-based methods for encoding and decoding signals which follow a union-of-subspaces structure. On the classical side, we evaluate compressed sensing with a learned dictionary, whereas for deep learning-based techniques, we consider an autoencoder and a deep generative model-based variant of compressed sensing. Our results suggest that while classical compressed sensing-based methods work well, deep learning-based techniques perform better as the union-of-subspaces signal structure becomes more complex."}}
{"id": "HRAgx3Yg7s1", "cdate": 1609459200000, "mdate": 1652642619909, "content": {"title": "Inverse Problems Leveraging Pre-trained Contrastive Representations", "abstract": "We study a new family of inverse problems for recovering representations of corrupted data. We assume access to a pre-trained representation learning network R(x) that operates on clean images, like CLIP. The problem is to recover the representation of an image R(x), if we are only given a corrupted version A(x), for some known forward operator A. We propose a supervised inversion method that uses a contrastive objective to obtain excellent representations for highly corrupted images. Using a linear probe on our robust representations, we achieve a higher accuracy than end-to-end supervised baselines when classifying images with various types of distortions, including blurring, additive noise, and random pixel masking. We evaluate on a subset of ImageNet and observe that our method is robust to varying levels of distortion. Our method outperforms end-to-end baselines even with a fraction of the labeled data in a wide range of forward operators."}}
{"id": "8UzjXlc1rK", "cdate": 1609459200000, "mdate": 1684298441016, "content": {"title": "Inverse Problems Leveraging Pre-trained Contrastive Representations", "abstract": "We study a new family of inverse problems for recovering representations of corrupted data. We assume access to a pre-trained representation learning network R(x) that operates on clean images, like CLIP. The problem is to recover the representation of an image R(x), if we are only given a corrupted version A(x), for some known forward operator A. We propose a supervised inversion method that uses a contrastive objective to obtain excellent representations for highly corrupted images. Using a linear probe on our robust representations, we achieve a higher accuracy than end-to-end supervised baselines when classifying images with various types of distortions, including blurring, additive noise, and random pixel masking. We evaluate on a subset of ImageNet and observe that our method is robust to varying levels of distortion. Our method outperforms end-to-end baselines even with a fraction of the labeled data in a wide range of forward operators."}}
{"id": "77dVa3mNNhc", "cdate": 1609459200000, "mdate": 1684298441016, "content": {"title": "Deep Autoencoder-based Massive MIMO CSI Feedback with Quantization and Entropy Coding", "abstract": "Techniques which leverage channel state information (CSI) at a transmitter to adapt wireless signals to changing propagation conditions have been shown to improve the reliability of modern multiple input multiple output (MIMO) communication systems. To reduce overhead, previous works have proposed to compress CSI matrices using a trained deep autoencoder (AE) at the receiver before feeding it back to the transmitter, and recent work has proposed to quantize and perform entropy coding on the compressed CSI to further reduce communication complexity. While these methods are effective, they either do not incorporate quantization and lossless coding into their end-to-end optimization, or do not achieve performance comparable to methods that do not use quantization and entropy coding. In this work, we propose a new AE-based feedback method which uses an entropy bottleneck layer to both quantize and losslessly code the compressed CSI. This bottleneck layer allows us to jointly optimize bit-rate and distortion to achieve a highly-compressed CSI representation which preserves important channel information. Our method achieves better reconstruction quality than existing autoencoder-based CSI feedback methods for a wide range of bit-rates on simulated data, in both indoor and outdoor wireless settings."}}
{"id": "MkeZVQil-d", "cdate": 1546300800000, "mdate": 1684298441015, "content": {"title": "One-dimensional Deep Image Prior for Time Series Inverse Problems", "abstract": "We extend the Deep Image Prior (DIP) framework to one-dimensional signals. DIP is using a randomly initialized convolutional neural network (CNN) to solve linear inverse problems by optimizing over weights to fit the observed measurements. Our main finding is that properly tuned one-dimensional convolutional architectures provide an excellent Deep Image Prior for various types of temporal signals including audio, biological signals, and sensor measurements. We show that our network can be used in a variety of recovery tasks including missing value imputation, blind denoising, and compressed sensing from random Gaussian projections. The key challenge is how to avoid overfitting by carefully tuning early stopping, total variation, and weight decay regularization. Our method requires up to 4 times fewer measurements than Lasso and outperforms NLM-VAMP for random Gaussian measurements on audio signals, has similar imputation performance to a Kalman state-space model on a variety of data, and outperforms wavelet filtering in removing additive noise from air-quality sensor readings."}}
