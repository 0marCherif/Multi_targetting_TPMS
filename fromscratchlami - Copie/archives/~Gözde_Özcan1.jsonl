{"id": "qgoPBoBEe9", "cdate": 1672531200000, "mdate": 1684163171570, "content": {"title": "Stochastic Submodular Maximization via Polynomial Estimators", "abstract": "In this paper, we study stochastic submodular maximization problems with general matroid constraints, that naturally arise in online learning, team formation, facility location, influence maximization, active learning and sensing objective functions. In other words, we focus on maximizing submodular functions that are defined as expectations over a class of submodular functions with an unknown distribution. We show that for monotone functions of this form, the stochastic continuous greedy algorithm attains an approximation ratio (in expectation) arbitrarily close to $(1-1/e) \\approx 63\\%$ using a polynomial estimation of the gradient. We argue that using this polynomial estimator instead of the prior art that uses sampling eliminates a source of randomness and experimentally reduces execution time."}}
{"id": "FKd6eLQxc9E", "cdate": 1672531200000, "mdate": 1696356375936, "content": {"title": "Online Submodular Maximization via Online Convex Optimization", "abstract": "We study monotone submodular maximization under general matroid constraints in the online setting. We prove that online optimization of a large class of submodular functions, namely, weighted threshold potential functions, reduces to online convex optimization (OCO). This is precisely because functions in this class admit a concave relaxation; as a result, OCO policies, coupled with an appropriate rounding scheme, can be used to achieve sublinear regret in the combinatorial setting. We show that our reduction extends to many different versions of the online learning problem, including the dynamic regret, bandit, and optimistic-learning settings."}}
{"id": "BUIrM0-R2W", "cdate": 1672531200000, "mdate": 1692022382974, "content": {"title": "Stochastic Submodular Maximization via Polynomial Estimators", "abstract": "In this paper, we study stochastic submodular maximization problems with general matroid constraints, which naturally arise in online learning, team formation, facility location, influence maximization, active learning and sensing objective functions. In other words, we focus on maximizing submodular functions that are defined as expectations over a class of submodular functions with an unknown distribution. We show that for monotone functions of this form, the stochastic continuous greedy algorithm [19] attains an approximation ratio (in expectation) arbitrarily close to $$(1-1/e) \\approx 63\\%$$ using a polynomial estimation of the gradient. We argue that using this polynomial estimator instead of the prior art that uses sampling eliminates a source of randomness and experimentally reduces execution time."}}
{"id": "TB4PSE14FD", "cdate": 1609459200000, "mdate": 1683002953045, "content": {"title": "Submodular Maximization via Taylor Series Approximation", "abstract": ""}}
{"id": "IebhBK-dNH8", "cdate": 1609459200000, "mdate": 1624735515929, "content": {"title": "Submodular Maximization via Taylor Series Approximation", "abstract": "We study submodular maximization problems with matroid constraints, in particular, problems where the objective can be expressed via compositions of analytic and multilinear functions. We show that for functions of this form, the so-called continuous greedy algorithm attains a ratio arbitrarily close to $(1-1/e) \\approx 0.63$ using a deterministic estimation via Taylor series approximation. This drastically reduces execution time over prior art that uses sampling."}}
