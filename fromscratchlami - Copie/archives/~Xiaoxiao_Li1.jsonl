{"id": "47wEQdvV8L", "cdate": 1684258200298, "mdate": 1684258200298, "content": {"title": "Efficient Medical Image Assessment via Self-supervised Learning", "abstract": "High-performance deep learning methods typically rely on\nlarge annotated training datasets, which are difficult to obtain in many\nclinical applications due to the high cost of medical image labeling. Existing\ndata assessment methods commonly require knowing the labels in\nadvance, which are not feasible to achieve our goal of \u2018knowing which\ndata to label.\u2019 To this end, we formulate and propose a novel and efficient\ndata assessment strategy, EXponentiAl Marginal sINgular valuE\n(EXAMINE) score, to rank the quality of unlabeled medical image data\nbased on their useful latent representations extracted via Self-supervised\nLearning (SSL) networks. Motivated by theoretical implication of SSL\nembedding space, we leverage a Masked Autoencoder [8] for feature extraction.\nFurthermore, we evaluate data quality based on the marginal\nchange of the largest singular value after excluding the data point in the\ndataset. We conduct extensive experiments on a pathology dataset. Our\nresults indicate the effectiveness and efficiency of our proposed methods\nfor selecting the most valuable data to label."}}
{"id": "21qf2LbB8e", "cdate": 1684258090431, "mdate": 1684258090431, "content": {"title": "A Dataset Auditing Method for Collaboratively Trained Machine Learning Models", "abstract": "Dataset auditing for machine learning (ML)\nmodels is a method to evaluate if a given dataset is used\nin training a model. In a Federated Learning setting where\nmultiple institutions collaboratively train a model with their\ndecentralized private datasets, dataset auditing can facilitate\nthe enforcement of regulations, which provide rules for\npreserving privacy, but also allow users to revoke authorizations\nand remove their data from collaboratively trained\nmodels. This paper first proposes a set of requirements for a\npractical dataset auditing method, and then present a novel\ndataset auditing method called Ensembled Membership Auditing\n(EMA). Its key idea is to leverage previously proposed\nMembership Inference Attack methods and to aggregate\ndata-wise membership scores using statistic testing to audit\na dataset for a ML model. We have experimentally evaluated\nthe proposed approach with benchmark datasets,\nas well as 4 X-ray datasets (CBIS-DDSM, COVIDx, Child-\nXRay, and CXR-NIH) and 3 dermatology datasets (DERM7pt,\nHAM10000, and PAD-UFES-20). Our results show that EMA\nmeet the requirements substantially better than the previous\nstate-of-the-art method."}}
{"id": "L2oWJf3tU-", "cdate": 1684257954027, "mdate": null, "content": {"title": "DeMed: A Novel and Efficient Decentralized Learning Framework for Medical Images Classification on Blockchain", "abstract": "Training predictive models with decentralized medical data\ncan boost the healthcare research and is important for healthcare applications.\nAlthough the federated learning (FL) was proposed to build\nthe predictive models, how to improve the security and robustness of a\nlearning system to resist the accidental or malicious modification of data\nrecords are still the open questions. In this paper, we describe DeMed, a\nprivacy-preserving decentralized medical image analysis framework empowered\nby blockchain technology. While blockchain is limited in serial\ncomputing, the decentralized data interaction in blockchain is very\ndesired to preserve the data privacy when training models. To adapt\nblockchain in medical image analysis, our framework consists of the self-supervised\nlearning part running on users\u2019 local devices and the smart\ncontract part running on blockchain. The prior is to obtain the provable\nlinearly separable low-dimensional representations of local medical images\nand the latter is to obtain the classifier by synthetically absorbing\nusers\u2019 self-supervised learning results. The proposed DeMed is validated\non two independent medical image classification tasks on pathological\ndata and chest X-ray. Our work provides an open platform and arena for\nFL, where everyone can deploy a smart contract to attract contributors\nfor medical image classification in a secure and decentralized manner\nwhile preserving the privacy in medical images."}}
{"id": "Rq2vt3tnAK9", "cdate": 1665069647104, "mdate": null, "content": {"title": "Improving Fairness in Image Classification via Sketching", "abstract": "Fairness is a fundamental requirement for trustworthy and human-centered Artificial Intelligence (AI) system. However, deep neural networks (DNNs) tend to make unfair predictions when the training data are collected from different sub-populations with different attributes (i.e. color, sex, age), leading to biased DNN predictions. We notice that such a troubling phenomenon is often caused by data itself, which means that bias information is encoded to the DNN along with the useful information (i.e. class information, semantic information). Therefore, we propose to use sketching to handle this phenomenon. Without losing the utility of data, we explore the image-to-sketching methods that can maintain useful semantic information for the target classification while filtering out the useless bias information. In addition, we design a fair loss to further improve the model fairness. We evaluate our method through extensive experiments on both general scene dataset and medical scene dataset. Our results show that the desired image-to-sketching method improves model fairness and achieves satisfactory results among state-of-the-art."}}
{"id": "UqVDq19iVx", "cdate": 1663850293196, "mdate": null, "content": {"title": "Biological Factor Regulatory Neural Network", "abstract": "Genes are fundamental for analyzing biological systems and many recent works proposed to utilize gene expression for various biological tasks by deep learning models. Despite their promising performance, it is hard for deep neural networks to provide biological insights for humans due to their black-box nature. Recently, some works integrated biological knowledge with neural networks to improve the transparency and performance of their models. However, these methods can only incorporate partial biological knowledge, leading to suboptimal performance. In this paper, we propose the Biological Factor Regulatory Neural Network (BFReg-NN), a generic framework to model relations among biological factors in cell systems. BFReg-NN starts from gene expression data and is capable of merging most existing biological knowledge into the model, including the regulatory relations among genes or proteins (e.g., gene regulatory networks (GRN), protein-protein interaction networks (PPI)) and the hierarchical relations among genes, proteins and pathways (e.g., several genes/proteins are contained in a pathway). Moreover, BFReg-NN also has the ability to provide new biologically meaningful insights because of its white-box characteristics. Experimental results on different gene expression-based tasks verify the superiority of BFReg-NN compared with baselines. Our case studies also show that the key insights found by BFReg-NN are consistent with the biological literature."}}
{"id": "lCzuxqRbThP", "cdate": 1663850215488, "mdate": null, "content": {"title": "FedMT: Federated Learning with Mixed-type Labels", "abstract": "In federated learning (FL), classifiers (e.g., deep networks) are trained on datasets from multiple centers without exchanging data across them, and thus improves sample efficiency. In the classical setting of FL, the same labeling criterion is usually employed across all centers being involved in training. This constraint greatly limits the applicability of FL. For example, standards used for disease diagnosis are more likely to be different across clinical centers, which mismatches the classical FL setting. In this paper, we consider an important yet under-explored setting of FL, namely FL with mixed-type labels where different labeling criteria can be employed by various centers, leading to inter-center label space differences and challenging existing FL methods designed for the classical setting. To effectively and efficiently train models with mixed-type labels, we propose a theory-guided and model-agnostic approach that can make use of the underlying correspondence between those label spaces and can be easily combined with various FL methods such as FedAvg. We present convergence analysis based on over-parameterized ReLU networks. We show that the proposed method can achieve linear convergence in label projection, and demonstrate the impact of the parameters of our new setting on the convergence rate. The proposed method is evaluated and the theoretical findings are validated on benchmark and medical datasets."}}
{"id": "hxEIgUXLFF", "cdate": 1663850176350, "mdate": null, "content": {"title": "PerFedMask: Personalized Federated Learning with Optimized Masking Vectors", "abstract": "Recently, various personalized federated learning (FL) algorithms have been proposed to tackle data heterogeneity. To mitigate device heterogeneity, a common approach is to use masking.  In this paper, we first show that using random masking can lead to a bias in the obtained solution of the learning model. To this end, we propose a personalized FL algorithm with optimized masking vectors called PerFedMask. In particular, PerFedMask facilitates each device to obtain its optimized masking vector based on its computational capability before training.  Fine-tuning is performed after training. PerFedMask is a generalization of a recently proposed personalized FL algorithm, FedBABU (Oh et al., 2022). PerFedMask can be combined with other FL algorithms including HeteroFL (Diao et al., 2021) and Split-Mix FL (Hong et al., 2022). Results based on CIFAR-10 and CIFAR-100 datasets show that the proposed PerFedMask algorithm provides a higher test accuracy after fine-tuning and lower average number of trainable parameters when compared with six existing state-of-the-art FL algorithms in the literature. The codes are available at https://github.com/MehdiSet/PerFedMask."}}
{"id": "RAoBtzlwtCC", "cdate": 1632875606681, "mdate": null, "content": {"title": "Provable Federated Adversarial Learning via Min-max Optimization", "abstract": "Federated learning (FL) is a trending training paradigm to utilize decentralized training data. FL allows clients to update model parameters locally for several epochs, then share them to a global model for aggregation. This training paradigm with multi-local step updating before aggregation exposes unique vulnerabilities to adversarial attacks. Adversarial training is a trending method to improve the robustness of neural networks against adversarial perturbations. First, we formulate a \\textit{general} form of federated adversarial learning (FAL) that is adapted from adversarial learning in the centralized setting. On the client side of FL training, FAL has an inner loop to optimize an adversarial to generate adversarial samples for adversarial training and an outer loop to update local model parameters. On the server side, FAL aggregates local model updates and broadcast the aggregated model. We design a global training loss to formulate FAL training as a min-max optimization problem. Unlike the convergence analysis in centralized training that relies on the gradient direction, it is significantly harder to analyze the convergence in FAL for two reasons: 1) the complexity of min-max optimization, and 2) model not updating in the gradient direction due to the multi-local updates on the client-side before aggregation. Further, we address the challenges using appropriate gradient approximation and coupling techniques and present the convergence analysis in the over-parameterized regime. Our main result theoretically shows that the minimal value of loss function under this algorithm can converge to $\\epsilon$ small with chosen learning rate and communication rounds. It is noteworthy that our analysis is feasible for non-IID clients."}}
{"id": "WHA8009laxu", "cdate": 1632875542135, "mdate": null, "content": {"title": "Federated Learning from Only Unlabeled Data with Class-conditional-sharing Clients", "abstract": "Supervised federated learning (FL) enables multiple clients to share the trained model without sharing their labeled data. However, potential clients might even be reluctant to label their own data, which could limit the applicability of FL in practice. In this paper, we show the possibility of unsupervised FL whose model is still a classifier for predicting class labels, if the class-prior probabilities are shifted while the class-conditional distributions are shared among the unlabeled data owned by the clients. We propose federation of unsupervised learning (FedUL), where the unlabeled data are transformed into surrogate labeled data for each of the clients, a modified model is trained by supervised FL, and the wanted model is recovered from the modified model. FedUL is a very general solution to unsupervised FL: it is compatible with many supervised FL methods, and the recovery of the wanted model can be theoretically guaranteed as if the data have been labeled. Experiments on benchmark and real-world datasets demonstrate the effectiveness of FedUL. Code is available at https://github.com/lunanbit/FedUL."}}
{"id": "nZon4NT0WSw", "cdate": 1632875489529, "mdate": null, "content": {"title": "TsmoBN: Interventional Generalization for Unseen Clients in Federated Learning", "abstract": "Generalizing federated learning (FL) models to unseen clients with non-iid data is a crucial topic, yet unsolved so far. In this work, we propose to tackle this problem from a novel causal perspective. Specifically, we form a training structural causal model (SCM) to explain the challenges of model generalization in a distributed learning paradigm. Based on this, we present a simple yet effective method using test-specific and momentum tracked batch normalization (TsmoBN) to generalize FL models to testing clients. We give a causal analysis by formulating another testing SCM and demonstrate that the key factor in TsmoBN is the test-specific statistics (i.e., mean and variance) of features. Such statistics can be seen as a surrogate variable for causal intervention. In addition, by considering generalization bounds in FL, we show that our TsmoBN method can reduce divergence between training and testing feature distributions, which achieves a lower generalization gap than standard model testing. Our extensive experimental evaluations demonstrate significant improvements for unseen client generalization on three datasets with various types of distribution shifts and numbers of clients. It is worth noting that our proposed approach can be flexibly applied to different state-of-the-art federated learning algorithms and is orthogonal to existing domain generalization methods. "}}
