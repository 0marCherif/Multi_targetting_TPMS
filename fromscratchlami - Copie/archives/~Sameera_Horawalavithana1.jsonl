{"id": "iUUvNqUzJX2", "cdate": 1664725484778, "mdate": null, "content": {"title": "Lessons from Developing Multimodal Models with Code and Developer Interactions", "abstract": "Recent advances in natural language processing has seen the rise of language models trained on code. Of great interest is the ability of these models to find and classify defects in existing code bases. These models have been applied to defect detection but improvements between these models has been minor. Literature from cyber security highlights how developer behaviors are often the cause of these defects. In this work we propose to approach the defect detection problem in a multimodal manner using weakly-aligned code and the developer workflow data. \nWe find that models trained on code and developer interactions tend to overfit and do not generalize because of weak-alignment between the code and developer workflow data."}}
{"id": "7UudBVsIrr", "cdate": 1663850399351, "mdate": null, "content": {"title": "MolJET: Multimodal Joint Embedding Transformer for Conditional de novo Molecular Design and Multi-Property Optimization", "abstract": "Multi-property constrained optimization of molecules using generative de novo design models is vital for the successful application of Artificial Intelligence (AI) towards materials and drug discovery. Yet there remains a gap between the reported performance of such models in the literature and their practical utility in real world design scenarios. Furthermore, existing models are largely inaccessible to chemists without an extensive background in computer science. To address these challenges, we propose a generative foundation model, the Multimodal Joint Embedding Transformer (MolJET), which performs conditional generation of desired molecular distributions based on human-interpretable chemistry prompts in a zero-shot manner. We assess MolJET on the standard benchmarks available in the GuacaMol and MIMOSA evaluation frameworks. These include structure-based sampling tasks as well as a range of multi-property optimization tasks that probe a models ability to design drug-like molecules given realistic property constraints. We demonstrate that with self-supervised pretraining, MolJET outperforms 80% of task-optimized models while using zero-shot inferences and beats all baselines after minimal supervision. Moreover, the performance of MolJET on text-only conditioning tasks improves with the inclusion of property modalities during training, highlighting the importance of a multimodal approach to molecular design. MolJET is the first example of text-based de novo molecular design using large-scale multimodal foundation models and should serve as a building block towards further improvements to accessible AI for chemists."}}
{"id": "SLX-I2MHUZ9", "cdate": 1646838446035, "mdate": null, "content": {"title": "Foundation Models of Scientific Knowledge for Chemistry: Opportunities, Challenges and Lessons Learned", "abstract": "Foundation models pre-trained on large corpora demonstrate significant gains across many natural language processing tasks and domains e.g., law, healthcare, education, etc. However, only limited efforts have investigated the opportunities and limitations of applying these powerful models to science and security applications. In this work, we develop foundation models of scientific knowledge for chemistry to augment scientists with the advanced ability to perceive and reason at scale previously unimagined. Specifically, we build large-scale (1.47B parameter) general-purpose models for chemistry that can be effectively used to perform a wide range of in-domain and out-of-domain tasks. Evaluating these models in a zero-shot setting, we analyze the effect of model and data scaling, knowledge depth, and temporality on model performance in context of model training efficiency. \nOur novel findings demonstrate that (1) model size significantly contributes to the task performance when evaluated in a zero-shot setting; (2) data quality (aka diversity) affects model performance more than data quantity; (3) similarly, unlike previous work, temporal order of the documents in the corpus boosts model performance only for specific tasks, e.g., SciQ; and (4)  models pre-trained from scratch perform better on in-domain tasks than those tuned from general-purpose models like Open AI's GPT-2."}}
{"id": "RlEb2DVGptW", "cdate": 1640995200000, "mdate": 1682366744054, "content": {"title": "Online discussion threads as conversation pools: predicting the growth of discussion threads on reddit", "abstract": "This paper proposes a data-driven method that forecasts groups of topic-related, overlapping, online conversation trees. Our method is generative: given a group of original posts, it generates the resulting conversation threads with timing and authorship information. We demonstrate using two large datasets from Reddit that the microscopic properties of such groups of conversations can be accurately predicted when starting from the original posts, without knowledge of the intermediate reactions to such posts. We show that our solution significantly outperforms competitive baselines in terms of predicting the conversation structure and user engagement over time. Potential benefits of this solution include the evaluation of intervention strategies to limit disinformation."}}
{"id": "R-JaLQdvVzv", "cdate": 1640995200000, "mdate": 1682366744067, "content": {"title": "EXPERT: Public Benchmarks for Dynamic Heterogeneous Academic Graphs", "abstract": "Machine learning models that learn from dynamic graphs face nontrivial challenges in learning and inference as both nodes and edges change over time. The existing large-scale graph benchmark datasets that are widely used by the community primarily focus on homogeneous node and edge attributes and are static. In this work, we present a variety of large scale, dynamic heterogeneous academic graphs to test the effectiveness of models developed for multi-step graph forecasting tasks. Our novel datasets cover both context and content information extracted from scientific publications across two communities: Artificial Intelligence (AI) and Nuclear Nonproliferation (NN). In addition, we propose a systematic approach to improve the existing evaluation procedures used in the graph forecasting models."}}
{"id": "-7VAyT8Z-W", "cdate": 1640995200000, "mdate": 1682366744057, "content": {"title": "Social media activity forecasting with exogenous and endogenous signals", "abstract": "Modeling social media activity has numerous practical implications such as in helping analyze strategic information operations, designing intervention techniques to mitigate disinformation, or delivering critical information during disaster relief operations. In this paper, we propose a modeling technique that forecasts topic-specific daily volume of social media activities by multiplexing different exogenous signals, such as news reports and armed conflicts records, and endogenous data from the social media platform we model. For this, we trained a collection of LSTM models, each leveraging a different exogenous source, and dynamically select one model for each topic. Empirical evaluations with real datasets from two social media platforms and two different contexts each composed of multiple interrelated topics demonstrate the effectiveness of our solution."}}
{"id": "y39loBwUVT8", "cdate": 1609459200000, "mdate": 1682366744382, "content": {"title": "Drivers of Polarized Discussions on Twitter during Venezuela Political Crisis", "abstract": "Social media activity is driven by real-world events (natural disasters, political unrest, etc.) and by processes within the platform itself (viral content, posts by influentials, etc). Understanding how these different factors affect social media conversations in polarized communities has practical implications, from identifying polarizing users to designing content promotion algorithms that alleviate polarization. Based on two datasets that record real-world events (ACLED and GDELT), we investigate how internal and external factors drive related Twitter activity in the highly polarizing context of the Venezuela\u2019s political crisis from early 2019. Our findings show that antagonistic communities react differently to different exogenous sources depending on the language they tweet. The engagement of influential users within particular topics seem to match the different levels of polarization observed in the networks."}}
{"id": "mtnm49KCIq_", "cdate": 1609459200000, "mdate": 1682366744428, "content": {"title": "Social-Media Activity Forecasting with Exogenous Information Signals", "abstract": "Due to their widespread adoption, social media platforms present an ideal environment for studying and understanding social behavior, especially on information spread. Modeling social media activity has numerous practical implications such as supporting efforts to analyze strategic information operations, designing intervention techniques to mitigate disinformation, or delivering critical information during disaster relief operations. In this paper we propose a modeling technique that forecasts topic-specific daily volume of social media activities by using both exogenous signals, such as news or armed conflicts records, and endogenous data from the social media platform we model. Empirical evaluations with real datasets from two different platforms and two different contexts each composed of multiple interrelated topics demonstrate the effectiveness of our solution."}}
{"id": "m4KzWkaHY5", "cdate": 1609459200000, "mdate": 1682366744029, "content": {"title": "Forecasting topic activity with exogenous and endogenous information signals in Twitter", "abstract": ""}}
{"id": "jZG1C3bpb4", "cdate": 1609459200000, "mdate": 1682366744383, "content": {"title": "Malicious and Low Credibility URLs on Twitter during COVID-19", "abstract": "We investigate the link sharing behavior of Twitter users following the temporary halt of AstraZeneca COVID-19 vaccine development in September 2020. During this period, we show the presence of malicious and low credibility information sources shared on Twitter messages in multiple languages. The malicious URLs, often in shortened forms, are increasingly hosted in content delivery networks and shared cloud hosting infrastructures not only to improve reach but also to avoid being detected and blocked. There are potential signs of coordination to promote both malicious and low credibility URLs on Twitter. Our findings suggest the need to develop a system that monitors the low-quality URLs shared in times of crisis."}}
