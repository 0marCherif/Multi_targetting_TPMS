{"id": "ZbwqqxW2f-G", "cdate": 1663850131415, "mdate": null, "content": {"title": "RangeAugment:  Efficient Online Augmentation with Range Learning", "abstract": "State-of-the-art automatic augmentation methods (e.g., AutoAugment and RandAugment) for visual recognition tasks diversify training data using a large set of augmentation operations. The range of magnitudes of many augmentation operations (e.g., brightness and contrast) is continuous. Therefore, to make search computationally tractable, these methods use fixed and manually-defined magnitude ranges for each operation, which may lead to sub-optimal policies. To answer the open question on the importance of magnitude ranges for each augmentation operation,  we introduce RangeAugment that allows us to efficiently learn the range of magnitudes for individual as well as composite augmentation operations. RangeAugment uses an auxiliary loss based on image similarity as a measure to control the range of magnitudes of augmentation operations. As a result, RangeAugment has a single scalar parameter for search, image similarity, which we simply optimize via linear search. RangeAugment integrates seamlessly with any model and learns model- and task-specific augmentation policies. With extensive experiments on the ImageNet dataset across different networks, we show that RangeAugment achieves competitive performance to state-of-the-art automatic augmentation methods with 4-5 times fewer augmentation operations. Experimental results on semantic segmentation and contrastive learning further shows RangeAugment's effectiveness."}}
{"id": "0RTJcuvHtIu", "cdate": 1652737679203, "mdate": null, "content": {"title": "Flexible Diffusion Modeling of Long Videos", "abstract": "We present a framework for video modeling based on denoising diffusion probabilistic models that produces long-duration video completions in a variety of realistic environments. We introduce a generative model that can at test-time sample any arbitrary subset of video frames conditioned on any other subset and present an architecture adapted for this purpose. Doing so allows us to efficiently compare and optimize a variety of schedules for the order in which frames in a long video are sampled and use selective sparse and long-range conditioning on previously sampled frames.  We demonstrate improved video modeling over prior work on a number of datasets and sample temporally coherent videos over 25 minutes in length.  We additionally release a new video modeling dataset and semantically meaningful metrics based on videos generated in the CARLA autonomous driving simulator."}}
{"id": "fgA2mdGwP5l", "cdate": 1640995200000, "mdate": 1683879080300, "content": {"title": "RangeAugment: Efficient Online Augmentation with Range Learning", "abstract": "State-of-the-art automatic augmentation methods (e.g., AutoAugment and RandAugment) for visual recognition tasks diversify training data using a large set of augmentation operations. The range of magnitudes of many augmentation operations (e.g., brightness and contrast) is continuous. Therefore, to make search computationally tractable, these methods use fixed and manually-defined magnitude ranges for each operation, which may lead to sub-optimal policies. To answer the open question on the importance of magnitude ranges for each augmentation operation, we introduce RangeAugment that allows us to efficiently learn the range of magnitudes for individual as well as composite augmentation operations. RangeAugment uses an auxiliary loss based on image similarity as a measure to control the range of magnitudes of augmentation operations. As a result, RangeAugment has a single scalar parameter for search, image similarity, which we simply optimize via linear search. RangeAugment integrates seamlessly with any model and learns model- and task-specific augmentation policies. With extensive experiments on the ImageNet dataset across different networks, we show that RangeAugment achieves competitive performance to state-of-the-art automatic augmentation methods with 4-5 times fewer augmentation operations. Experimental results on semantic segmentation, object detection, foundation models, and knowledge distillation further shows RangeAugment's effectiveness."}}
{"id": "Z7ImF39vhqT", "cdate": 1640995200000, "mdate": 1681494432331, "content": {"title": "Conditional Image Generation by Conditioning Variational Auto-Encoders", "abstract": ""}}
{"id": "M5oTlSbMe0d", "cdate": 1640995200000, "mdate": 1681494432333, "content": {"title": "Amortized Rejection Sampling in Universal Probabilistic Programming", "abstract": ""}}
{"id": "7MV6uLzOChW", "cdate": 1632875546706, "mdate": null, "content": {"title": "Conditional Image Generation by Conditioning Variational Auto-Encoders", "abstract": "We present a conditional variational auto-encoder (VAE) which, to avoid the substantial cost of training from scratch, uses an architecture and training objective capable of leveraging a foundation model in the form of a pretrained unconditional VAE. To train the conditional VAE, we only need to train an artifact to perform amortized inference over the unconditional VAE's latent variables given a conditioning input. We demonstrate our approach on tasks including image inpainting, for which it outperforms state-of-the-art GAN-based approaches at faithfully representing the inherent uncertainty. We conclude by describing a possible application of our inpainting model, in which it is used to perform Bayesian experimental design for the purpose of guiding a sensor."}}
{"id": "cT0jK5VvFuS", "cdate": 1601308298470, "mdate": null, "content": {"title": "Uncertainty in Neural Processes", "abstract": "We explore the effects of architecture and training objective choice on amortized posterior predictive inference in probabilistic conditional generative models.  We aim this work to be a counterpoint to a recent trend in the literature that stresses achieving good samples when the amount of conditioning data is large.  We instead focus our attention on the case where the amount of conditioning data is small.  We highlight specific architecture and objective choices that we find lead to qualitative and quantitative improvement to posterior inference in this low data regime.  Specifically we explore the effects of choices of pooling operator and variational family on posterior quality in neural processes.  Superior posterior predictive samples drawn from our novel neural process architectures are demonstrated via image completion/in-painting experiments."}}
{"id": "rOWZVzJ5Sec", "cdate": 1577836800000, "mdate": 1645743883896, "content": {"title": "Coping With Simulators That Don't Always Return", "abstract": "Deterministic models are approximations of reality that are easy to interpret and often easier to build than stochastic alternatives. Unfortunately, as nature is capricious, observational data can ..."}}
{"id": "o8mYwPT_Dc", "cdate": 1577836800000, "mdate": 1681494432488, "content": {"title": "Uncertainty in Neural Processes", "abstract": ""}}
{"id": "F3PR3xNYuKI", "cdate": 1577836800000, "mdate": null, "content": {"title": "Planning as Inference in Epidemiological Models", "abstract": "In this work we demonstrate how to automate parts of the infectious disease-control policy-making process via performing inference in existing epidemiological models. The kind of inference tasks undertaken include computing the posterior distribution over controllable, via direct policy-making choices, simulation model parameters that give rise to acceptable disease progression outcomes. Among other things, we illustrate the use of a probabilistic programming language that automates inference in existing simulators. Neither the full capabilities of this tool for automating inference nor its utility for planning is widely disseminated at the current time. Timely gains in understanding about how such simulation-based models and inference automation tools applied in support of policymaking could lead to less economically damaging policy prescriptions, particularly during the current COVID-19 pandemic."}}
