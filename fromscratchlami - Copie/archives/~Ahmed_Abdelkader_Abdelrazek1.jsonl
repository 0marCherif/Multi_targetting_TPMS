{"id": "XJk19XzGq2J", "cdate": 1601308313526, "mdate": null, "content": {"title": "The Intrinsic Dimension of Images and Its Impact on Learning", "abstract": "It is widely believed that natural image data exhibits low-dimensional structure despite the high dimensionality of conventional pixel representations.  This idea underlies a common intuition for the remarkable success of deep learning in computer vision. In this work, we apply dimension estimation tools to popular datasets and investigate the role of low-dimensional structure in deep learning.  We find that common natural image datasets indeed have very low intrinsic dimension relative to the high number of pixels in the images.  Additionally, we find that low dimensional datasets are easier for neural networks to learn, and models solving these tasks generalize better from training to test data.   Along the way,  we develop a technique for validating our dimension estimation tools on synthetic data generated by GANs allowing us to actively manipulate the intrinsic dimension by controlling the image generation process. Code for our experiments may be found  \\href{https://github.com/ppope/dimensions}{here}."}}
{"id": "SfbEMJpoeq", "cdate": 1577836800000, "mdate": 1646149387527, "content": {"title": "Headless Horseman: Adversarial Attacks on Transfer Learning Models", "abstract": "Transfer learning facilitates the training of task-specific classifiers using pre-trained models as feature extractors. We present a family of transferable adversarial attacks against such classifiers, generated without access to the classification head; we call these headless attacks. We first demonstrate successful transfer attacks against a victim network using only its feature extractor. This motivates the introduction of a label-blind adversarial attack. This transfer attack method does not require any information about the class-label space of the victim. Our attack lowers the accuracy of a ResNet18 trained on CIFAR10 by over 40%."}}
{"id": "KnyH0oj9_i0", "cdate": 1577836800000, "mdate": 1668439877247, "content": {"title": "Certified Defenses for Adversarial Patches", "abstract": "Adversarial patch attacks are among one of the most practical threat models against real-world computer vision systems. This paper studies certified and empirical defenses against patch attacks. We..."}}
{"id": "A5pskvRxk4", "cdate": 1577836800000, "mdate": 1668439877579, "content": {"title": "Detection as Regression: Certified Object Detection with Median Smoothing", "abstract": "Despite the vulnerability of object detectors to adversarial attacks, very few defenses are known to date. While adversarial training can improve the empirical robustness of image classifiers, a direct extension to object detection is very expensive. This work is motivated by recent progress on certified classification by randomized smoothing. We start by presenting a reduction from object detection to a regression problem. Then, to enable certified regression, where standard mean smoothing fails, we propose median smoothing, which is of independent interest. We obtain the first model-agnostic, training-free, and certified defense for object detection against $\\ell_2$-bounded attacks."}}
{"id": "8ojwJznNkY", "cdate": 1577836800000, "mdate": 1679953706686, "content": {"title": "VoroCrust: Voronoi Meshing Without Clipping", "abstract": ""}}
{"id": "HyeaSkrYPH", "cdate": 1569439557505, "mdate": null, "content": {"title": "Certified Defenses for Adversarial Patches", "abstract": "Adversarial patch attacks are among one of the most practical threat models against real-world computer vision systems. This paper studies certified and empirical defenses against patch attacks. We begin with a set of experiments showing that most existing defenses, which work by pre-processing input images to mitigate adversarial patches, are easily broken by simple white-box adversaries. Motivated by this finding, we propose the first certified defense against patch attacks, and propose faster methods for its training. Furthermore, we experiment with different patch shapes for testing, obtaining surprisingly good robustness transfer across shapes, and present preliminary results on certified defense against sparse attacks. Our complete implementation can be found on: https://github.com/Ping-C/certifiedpatchdefense."}}
{"id": "akAxkILbKt", "cdate": 1546300800000, "mdate": 1679953706696, "content": {"title": "On Realistic Target Coverage by Autonomous Drones", "abstract": ""}}
{"id": "4Rma4pfraeb", "cdate": 1546300800000, "mdate": 1679953706694, "content": {"title": "Approximate Nearest Neighbor Searching with Non-Euclidean and Weighted Distances", "abstract": ""}}
{"id": "oh8S4Puata", "cdate": 1514764800000, "mdate": 1679953706703, "content": {"title": "Sampling Conditions for Conforming Voronoi Meshing by the VoroCrust Algorithm", "abstract": ""}}
{"id": "aS1t1XmkKUs", "cdate": 1514764800000, "mdate": 1679953706704, "content": {"title": "Sampling Conditions for Conforming Voronoi Meshing by the VoroCrust Algorithm", "abstract": ""}}
