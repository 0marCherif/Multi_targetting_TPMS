{"id": "PUVizwFOOzS", "cdate": 1672531200000, "mdate": 1681657094212, "content": {"title": "Towards Zero-Shot Sign Language Recognition", "abstract": "This paper tackles the problem of zero-shot sign language recognition (ZSSLR), where the goal is to leverage models learned over the seen sign classes to recognize the instances of unseen sign classes. In this context, readily available textual sign descriptions and attributes collected from sign language dictionaries are utilized as semantic class representations for knowledge transfer. For this novel problem setup, we introduce three benchmark datasets with their accompanying textual and attribute descriptions to analyze the problem in detail. Our proposed approach builds spatiotemporal models of body and hand regions. By leveraging the descriptive text and attribute embeddings along with these visual representations within a zero-shot learning framework, we show that textual and attribute based class definitions can provide effective knowledge for the recognition of previously unseen sign classes. We additionally introduce techniques to analyze the influence of binary attributes in correct and incorrect zero-shot predictions. We anticipate that the introduced approaches and the accompanying datasets will provide a basis for further exploration of zero-shot learning in sign language recognition."}}
{"id": "ACahUm41Pe", "cdate": 1667399211206, "mdate": 1667399211206, "content": {"title": "A Deep Dive into Adversarial Robustness in Zero-Shot Learning", "abstract": "Machine learning (ML) systems have introduced significant advances in various fields, due to the introduction of highly complex models. Despite their success, it has been shown multiple times that machine learning models are prone to imperceptible perturbations that can severely degrade their accuracy. So far, existing studies have primarily focused on models where supervision across all classes were available. In contrast, Zero-shot Learning (ZSL) and Generalized Zero-shot Learning (GZSL) tasks inherently lack supervision across all classes. In this paper, we present a study aimed on evaluating the adversarial robustness of ZSL and GZSL models. We leverage the well-established label embedding model and subject it to a set of established adversarial attacks and defenses across multiple datasets. In addition to creating possibly the first benchmark on adversarial robustness of ZSL models, we also present analyses on important points that require attention for better interpretation of ZSL robustness results. We hope these points, along with the benchmark, will help researchers establish a better understanding what challenges lie ahead and help guide their work."}}
{"id": "xrPZUFzM3LL", "cdate": 1667399151651, "mdate": null, "content": {"title": "Red Carpet to Fight Club: Partially-supervised Domain Transfer for Face Recognition in Violent Videos", "abstract": "In many real-world problems, there is typically a large discrepancy between the characteristics of data used in training versus deployment. A prime example is the analysis of aggression videos: in a criminal incidence, typically suspects need to be identified based on their clean portrait-like photos, instead of their prior video recordings. This results in three major challenges; large domain discrepancy between violence videos and ID-photos, the lack of video examples for most individuals and limited training data availability. To mimic such scenarios, we formulate a realistic domain-transfer problem, where the goal is to transfer the recognition model trained on clean posed images to the target domain of violent videos, where training videos are available only for a subset of subjects. To this end, we introduce the \"WildestFaces\" dataset, tailored to study cross-domain recognition under a variety of adverse conditions. We divide the task of transferring a recognition model from the domain of clean images to the violent videos into two sub-problems and tackle them using (i) stacked affine-transforms for classifier-transfer, (ii) attention-driven pooling for temporal-adaptation. We additionally formulate a self attention based model for domain-transfer. We establish a rigorous evaluation protocol for this \"clean-to-violent\" recognition task, and present a detailed analysis of the proposed dataset and the methods. Our experiments highlight the unique challenges introduced by the Wildest-Faces dataset and the advantages of the proposed approach"}}
{"id": "DmHurvMCqxa", "cdate": 1667398928304, "mdate": 1667398928304, "content": {"title": "How robust are discriminatively trained zero-shot learning models?", "abstract": "Data shift robustness has been primarily investigated from a fully supervised perspective, and robustness of zero-shot learning (ZSL) models have been largely neglected. In\nthis paper, we present novel analyses on the robustness of discriminative ZSL to image\ncorruptions. We subject several ZSL models to a large set of common corruptions and\ndefenses. In order to realize the corruption analysis, we curate and release the first ZSL\ncorruption robustness datasets SUN-C, CUB-C and AWA2-C. We analyse our results by\ntaking into account the dataset characteristics, class imbalance, class transitions between\nseen and unseen classes and the discrepancies between ZSL and GZSL performances. Our\nresults show that discriminative ZSL suffers from corruptions and this trend is further\nexacerbated by the severe class imbalance and model weakness inherent in ZSL methods. We then combine our findings with those based on adversarial attacks in ZSL,\nand highlight the different effects of corruptions and adversarial examples, such as the\npseudo-robustness effect present under adversarial attacks. We also obtain new strong\nbaselines for both models with the defense methods. Finally, our experiments show that\nalthough existing methods to improve robustness somewhat work for ZSL models, they\ndo not produce a tangible effect."}}
{"id": "wgJrjvTp8R", "cdate": 1640995200000, "mdate": 1681657093986, "content": {"title": "Semantics-driven attentive few-shot learning over clean and noisy samples", "abstract": ""}}
{"id": "uFkwFAS9mmk", "cdate": 1640995200000, "mdate": 1668599783301, "content": {"title": "Streaming Multiscale Deep Equilibrium Models", "abstract": "We present StreamDEQ, a method that infers frame-wise representations on videos with minimal per-frame computation. In contrast to conventional methods where compute time grows at least linearly with the network depth, we aim to update the representations in a continuous manner. For this purpose, we leverage the recently emerging implicit layer models, which infer the representation of an image by solving a fixed-point problem. Our main insight is to leverage the slowly changing nature of videos and use the previous frame representation as an initial condition on each frame. This scheme effectively recycles the recent inference computations and greatly reduces the needed processing time. Through extensive experimental analysis, we show that StreamDEQ is able to recover near-optimal representations in a few frames time, and maintain an up-to-date representation throughout the video duration. Our experiments on video semantic segmentation and video object detection show that StreamDEQ achieves on par accuracy with the baseline (standard MDEQ) while being more than $3\\times$ faster. Code and additional results are available at https://ufukertenli.github.io/streamdeq/."}}
{"id": "tAsyeaCbPM", "cdate": 1640995200000, "mdate": 1681657093639, "content": {"title": "Caption generation on scenes with seen and unseen object categories", "abstract": ""}}
{"id": "mi5KicDrppd", "cdate": 1640995200000, "mdate": 1681657093820, "content": {"title": "Closed-form Sample Probing for Learning Generative Models in Zero-shot Learning", "abstract": "Generative model based approaches have led to significant advances in zero-shot learning (ZSL) over the past few years. These approaches typically aim to learn a conditional generator that synthesizes training samples of classes conditioned on class definitions. The final zero-shot learning model is then obtained by training a supervised classification model over the real and/or synthesized training samples of seen and unseen classes, combined. Therefore, naturally, the generative model needs to produce not only relevant samples, but also those that are sufficiently rich for classifier training purposes, which is handled by various heuristics in existing works. In this paper, we introduce a principled approach for training generative models {\\em directly} for training data generation purposes. Our main observation is that the use of closed-form models opens doors to end-to-end training thanks to the differentiability of the solvers. In our approach, at each generative model update step, we fit a task-specific closed-form ZSL model from generated samples, and measure its loss on novel samples all within the compute graph, a procedure that we refer to as {\\em sample probing}. In this manner, the generator receives feedback directly based on the value of its samples for model training purposes. Our experimental results show that the proposed sample probing approach improves the ZSL results even when integrated into state-of-the-art generative models."}}
{"id": "cjP2g0sPw6", "cdate": 1640995200000, "mdate": 1668520228323, "content": {"title": "How robust are discriminatively trained zero-shot learning models?", "abstract": ""}}
{"id": "YrGmgvzIgj", "cdate": 1640995200000, "mdate": 1668520228128, "content": {"title": "How Robust are Discriminatively Trained Zero-Shot Learning Models?", "abstract": "Data shift robustness has been primarily investigated from a fully supervised perspective, and robustness of zero-shot learning (ZSL) models have been largely neglected. In this paper, we present novel analyses on the robustness of discriminative ZSL to image corruptions. We subject several ZSL models to a large set of common corruptions and defenses. In order to realize the corruption analysis, we curate and release the first ZSL corruption robustness datasets SUN-C, CUB-C and AWA2-C. We analyse our results by taking into account the dataset characteristics, class imbalance, class transitions between seen and unseen classes and the discrepancies between ZSL and GZSL performances. Our results show that discriminative ZSL suffers from corruptions and this trend is further exacerbated by the severe class imbalance and model weakness inherent in ZSL methods. We then combine our findings with those based on adversarial attacks in ZSL, and highlight the different effects of corruptions and adversarial examples, such as the pseudo-robustness effect present under adversarial attacks. We also obtain new strong baselines for both models with the defense methods. Finally, our experiments show that although existing methods to improve robustness somewhat work for ZSL models, they do not produce a tangible effect."}}
