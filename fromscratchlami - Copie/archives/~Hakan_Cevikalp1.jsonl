{"id": "AraljTbmDP", "cdate": 1685577600000, "mdate": 1682319604066, "content": {"title": "From anomaly detection to open set recognition: Bridging the gap", "abstract": ""}}
{"id": "jFfdFL7Jy0", "cdate": 1682899200000, "mdate": 1682319604078, "content": {"title": "Deep Discriminative Feature Models (DDFMs) for Set Based Face Recognition and Distance Metric Learning", "abstract": "This article introduces two methods that find compact deep feature models for approximating images in set based face recognition problems. The proposed method treats each image set as a nonlinear face manifold that is composed of linear components. To find linear components of the face manifold, we first split image sets into subsets containing face images which share similar appearances. Then, our first proposed method approximates each subset by using the center of the deep feature representations of images in those subsets. Centers modeling the subsets are learned by using distance metric learning. The second proposed method uses discriminative common vectors to represent image features in the subsets, and entire subset is approximated with an affine hull in this approach. Discriminative common vectors are subset centers that are projected onto a new feature space where the combined within-class variances coming from all subsets are removed. Our proposed methods can also be considered as distance metric learning methods using triplet loss function where the learned subcluster centers are the selected anchors. This procedure yields to applying distance metric learning to quantized data and brings many advantages over using classical distance metric learning methods. We tested proposed methods on various face recognition problems using image sets and some visual object classification problems. Experimental results show that the proposed methods achieve the state-of-the-art accuracies on the most of the tested image datasets."}}
{"id": "A0hS562Bvxx", "cdate": 1677628800000, "mdate": 1682319604231, "content": {"title": "Visual object tracking by using ranking loss and spatial-temporal features", "abstract": "This paper introduces a novel two-stream deep neural network tracker for robust object tracking. In the proposed network, we use both spatial and temporal features and employ a novel loss function called ranking loss. The class confidence scores coming from the two-stream (spatial and temporal) networks are fused at the end for final decision. Using ranking loss in the proposed tracker enforces the networks to learn giving higher scores to the candidate regions that frame the target object better. As a result, the tracker returns more precise bounding boxes framing the target object, and the risk of tracking error accumulation and drifts are largely mitigated when the proposed network architecture is used with a simple yet effective model update rule. We conducted extensive experiments on six different benchmarks, including OTB-2015, VOT-2017, TC-128, DTB70, NfS and UAV123. Our proposed tracker achieves the state-of-the-art results on the most of the tested challenging tracking datasets. Especially, our results on the OTB-2015, DTB70, NfS and TC-128 datasets are very promising. The source code and trained models are available at https://github.com/Hasan4825/RankingT ."}}
{"id": "wcBXsXIf-n9", "cdate": 1652737382886, "mdate": null, "content": {"title": "Reaching Nirvana: Maximizing the Margin in Both Euclidean and Angular Spaces for Deep Neural Network Classification", "abstract": "The classification loss functions used in deep neural network classifiers can be grouped into two categories based on maximizing the margin in either Euclidean or angular spaces. Euclidean distances between sample vectors are used during classification for the methods maximizing the margin in Euclidean spaces whereas the Cosine similarity distance is used during the testing stage for the methods maximizing margin in the angular spaces. This paper introduces a novel classification loss that maximizes the margin in both the Euclidean and angular spaces at the same time. This way, the Euclidean and Cosine distances will produce similar and consistent results and complement each other, which will in turn improve the accuracies. The proposed loss function enforces the samples of classes to cluster around the centers that represent them. The centers approximating classes are chosen from the boundary of a hypersphere, and the pairwise distances between class centers are always equivalent. This restriction corresponds to choosing centers from the vertices of a regular simplex. There is not any hyperparameter that must be set by the user in the proposed loss function, therefore the use of the proposed method is extremely easy for classical classification problems. Moreover, since the class samples are compactly clustered around their corresponding means, the proposed classifier is also very suitable for open set recognition problems where test samples can come from the unknown classes that are not seen in the training phase. Experimental studies show that the proposed method achieves the state-of-the-art accuracies on open set recognition despite its simplicity."}}
{"id": "f29O-OY0WH1", "cdate": 1640995200000, "mdate": 1682319604101, "content": {"title": "Transductive polyhedral conic classifiers for machine learning applications", "abstract": ""}}
{"id": "cztBTYbFYEF", "cdate": 1640995200000, "mdate": 1667412783135, "content": {"title": "Dissected 3D CNNs: Temporal skip connections for efficient online video processing", "abstract": ""}}
{"id": "5Y0rV4sN5", "cdate": 1640995200000, "mdate": 1682319604053, "content": {"title": "TRAT: Tracking by attention using spatio-temporal features", "abstract": ""}}
{"id": "iCiA9H2BKY", "cdate": 1609459200000, "mdate": 1682319604063, "content": {"title": "Polyhedral Conic Classifiers for Computer Vision Applications and Open Set Recognition", "abstract": "This paper introduces a family of quasi-linear discriminants that outperform current large-margin methods in sliding window visual object detection and open set recognition tasks. In these applications, the classification problems are both numerically imbalanced - positive (object class) training and test windows are much rarer than negative (non-class) ones - and geometrically asymmetric - the positive samples typically form compact, visually-coherent groups while negatives are much more diverse, including anything at all that is not a well-centered sample from the target class. For such tasks, there is a need for discriminants whose decision regions focus on tightly circumscribing the positive class, while still taking account of negatives in zones where the two classes overlap. To this end, we propose a family of quasi-linear \u201cpolyhedral conic\u201d discriminants whose positive regions are distorted L <sub xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">1</sub> or L <sub xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">2</sub> balls. In addition, we also integrated the proposed classification loss into deep neural networks so that both the features and classifier can be learned simultaneously end-to-end fashion to improve the classification accuracies. The methods have properties and run-time complexities comparable to linear Support Vector Machines (SVMs), and they can be trained from either binary or positive-only samples using constrained quadratic programs related to SVMs. Our experiments show that they significantly outperform linear SVMs, deep neural networks using softmax loss function and existing one-class discriminants on a wide range of object detection, face verification, open set recognition and conventional closed-set classification tasks."}}
{"id": "SisWpGQldTr", "cdate": 1546300800000, "mdate": null, "content": {"title": "A Hybrid Method for Tracking of Objects by UAVs.", "abstract": "Object tracking remains one of the fundamental problems of computer vision since it becomes difficult under some realistic conditions such as fast camera movement, occlusion and similar of objects to the tracked targets. As a real-world application, tracking objects using cameras mounted on unmanned aerial vehicles (UAVs) has become very popular. With the increasing availability of small single board computers with high parallel processing power capabilities, tracking of objects by using onboard computers within UAVs in real-time has become feasible. Although these onboard computers allow a wide variety of computer vision methods to be executed on a UAV, there is still a need to optimize these methods for running time and power consumption. In this paper, we propose a hybrid method for a UAV to detect and track other UAVs efficiently. To detect the target UAV at the beginning of the video and in the case where the tracked UAV has been lost, we use the deep learning-based YOLOv3 and YOLOv3-Tiny models, which provide one of the best trade-offs between speed and accuracy in the literature. To track the detected UAVs in real-time, a kernelized correlation filter is used. Combining these two methods provides high accuracy and speed even on onboard computers. To train the neural nets and test our method, we have collected a new dataset composed of videos of various UAVs in flight, captured from another UAV. The performance of the proposed method has been compared with other state-of-the-art methods in the literature on this dataset. Additionally, we also tested the proposed trackers on aerial videos captured from UAVs. Experimental results show that the proposed hybrid trackers achieve the state-of-the-art performance on all tested datasets. The code is available at https://github.com/bdrhn9/hybrid-tracker."}}
{"id": "Bm-mN7guTH", "cdate": 1546300800000, "mdate": null, "content": {"title": "Semi-Supervised Robust Deep Neural Networks for Multi-Label Classification.", "abstract": "In this paper, we propose a robust method for semi-supervised training of deep neural networks for multi-label image classification. To this end, we use ramp loss, which is more robust against noisy and incomplete image labels compared to the classical hinge loss. The proposed method allows for learning from both labeled and unlabeled data in a semi-supervised learning setting. This is achieved by propagating labels from the labeled images to their unlabeled neighbors. Using a robust loss function be- comes crucial here, as the initial label propagations may include many errors, which degrades the performance of non-robust loss functions. In contrast, the proposed robust ramp loss restricts extreme penalties for the samples with incorrect labels, and the label assignment improves in each iteration and contributes to the learning process. The proposed method achieves state-of-the-art results in semi-supervised learning experiments on the CIFAR-10 and STL-10 datasets, and comparable results to the state-of the-art in supervised learning experiments on the NUS-WIDE and MS-COCO datasets."}}
