{"id": "sYb_bfWX-y", "cdate": 1664833376914, "mdate": null, "content": {"title": "Conditional COT-GAN for Video Prediction with Kernel Smoothing", "abstract": "Causal Optimal Transport (COT) results from imposing a temporal causality constraint on classic optimal transport problems.\nRelying on recent work of COT-GAN optimized for sequential learning, the contribution of the present paper is twofold. First, we develop a conditional version of COT-GAN suitable for sequence prediction. This means that the dataset is now used in order to learn how a sequence will evolve given the observation of its past evolution. Second, we improve on the convergence results by working with modifications of the empirical measures via kernel smoothing.  The resulting kernel conditional COT-GAN (KCCOT-GAN) algorithm is illustrated with an application for video prediction."}}
{"id": "4Jq0XWCZQel", "cdate": 1663850273122, "mdate": null, "content": {"title": "Neural Image Compression with a Diffusion-based Decoder", "abstract": "Diffusion probabilistic models have recently achieved remarkable success in generating high quality image and video data. In this work, we build on this class of generative models and introduce a method for lossy compression of high resolution images. The resulting codec, which we call \\emph{DIffuson-based Residual Augmentation Codec (DIRAC)}, is the first neural codec to allow smooth traversal of the rate-distortion-perception tradeoff at test time, while obtaining competitive performance with GAN-based methods in perceptual quality. Furthermore, while sampling from diffusion probabilistic models is notoriously expensive, we show that in the compression setting the number of steps can be drastically reduced."}}
{"id": "jQ0XleVhYuT", "cdate": 1601308105598, "mdate": null, "content": {"title": "Double Generative Adversarial Networks for Conditional Independence Testing", "abstract": "In this article, we consider the problem of high-dimensional conditional independence testing, which is a key building block in statistics and machine learning. We propose a double generative adversarial networks (GAN)-based inference procedure. We first introduce a double GANs framework to learn two generators, and integrate the two generators to construct a doubly-robust test statistic. We next consider multiple generalized covariance measures, and take their maximum as our test statistic. Finally, we obtain the empirical distribution of our test statistic through multiplier bootstrap. We show that our test controls type-I error, while the\npower approaches one asymptotically. More importantly, these theoretical guarantees are obtained under much weaker and practically more feasible conditions compared to existing tests. We demonstrate the efficacy of our test through both synthetic and real datasets."}}
