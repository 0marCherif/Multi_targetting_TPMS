{"id": "MIjCHkJgKtw", "cdate": 1698809104688, "mdate": 1698809104688, "content": {"title": "Category Query Learning for Human-Object Interaction Classification", "abstract": "Unlike most previous HOI methods that focus on learning better human-object features, we propose a novel and complementary approach called category query learning. Such queries are explicitly associated to interaction categories, converted to image specific category representation via a transformer decoder, and learnt via an auxiliary image-level classification task. This idea is motivated by an earlier multi-label image classification method, but is for the first time applied for the challenging human-object interaction classification task. Our method is simple, general and effective. It is validated on three representative HOI baselines and achieves new state-of-the art results on two benchmarks."}}
{"id": "kNGoSDdDmg", "cdate": 1672531200000, "mdate": 1683783682520, "content": {"title": "Category Query Learning for Human-Object Interaction Classification", "abstract": "Unlike most previous HOI methods that focus on learning better human-object features, we propose a novel and complementary approach called category query learning. Such queries are explicitly associated to interaction categories, converted to image specific category representation via a transformer decoder, and learnt via an auxiliary image-level classification task. This idea is motivated by an earlier multi-label image classification method, but is for the first time applied for the challenging human-object interaction classification task. Our method is simple, general and effective. It is validated on three representative HOI baselines and achieves new state-of-the-art results on two benchmarks."}}
{"id": "h_06P7v6xb", "cdate": 1672531200000, "mdate": 1684144037066, "content": {"title": "BENet: Boundary Enhance Network for Salient Object Detection", "abstract": "Although deep convolutional networks have achieved good results in the field of salient object detection, most of these methods can not work well near the boundary. This results in poor boundary quality of network predictions, accompanied by a large number of blurred contours and hollow objects. To solve this problem, this paper proposes a Boundary Enhance Network (BENet) for salient object detection, which makes the network pay more attention to salient edge features by fusing auxiliary boundary information of objects. We adopt the Progressive Feature Extraction Module (PFEM) to obtain multi-scale edge and object features of salient objects. In response to the semantic gap problem in feature fusion, we propose an Adaptive Edge Fusion Module (AEFM) to allow the network to adaptively and complementarily fuse edge features and salient object features. The Self Refinement (SR) module further repairs and enhances edge features. Moreover, in order to make the network pay more attention to the boundary, we design an edge enhance loss function, which uses the additional boundary maps to guide the network to learn rich boundary features at the pixel level. Experimental results show that our proposed method outperforms state-of-the-art methods on five benchmark datasets."}}
{"id": "lhwXsGJiGzi", "cdate": 1640995200000, "mdate": 1683783682495, "content": {"title": "Joint relation based human pose estimation", "abstract": "With the increasing application of computer vision technology in real life, human pose estimation task becomes more and more important. However, inferencing accurate coordinates of limb joints or invisible joints is still difficult for even state-of-the-art approaches. The positions of limb joints are diversified, and a percentage of the joints are occluded. In this paper, we aim to solve such problem by proposing joint relation based human pose estimation framework. Joint relation is the spatial relation between selected neighbor joints which can imitate human body structure and localize a complex joint with the help of its neighbor joint. We evaluate the joint relation module on challenging dataset and demonstrate its effectiveness by accuracy and visualization results. The proposed joint relation based human pose estimation method achieves state-of-the-art performance."}}
{"id": "Rvf6Bkaoyk", "cdate": 1640995200000, "mdate": 1684144036931, "content": {"title": "Pose-Enhanced Relation Feature for Action Recognition in Still Images", "abstract": "Due to the lack of motion information, action recognition in still images is considered a challenging task. Previous works focused on contextual information in the image, including human pose, surrounding objects, etc. But they rarely consider the relation between the local pose and the entire human body, so that poses related to the action are not fully utilized. In this paper, we propose a solution for action recognition in still images, which makes complete and effective use of pose information. The multi-key points calculation method is carefully designed for generating pose regions that explicitly includes possible actions. The extensible Pose-Enhanced Relation Module extracts the implicit relation between pose and human body, and outputs the Pose-Enhanced Relation Feature which owns powerful representation capabilities. Surrounding objects information is also applied to strengthen the solution. Through experiments, it can be found that the proposed solution exceed the state-of-the-art performance on two commonly used datasets, PASCAL VOC 2012 Action and Stanford 40 Actions. Visualization shows that the proposed solution enables the network to pay more attention to the pose regions related to the action."}}
{"id": "J88dC-VyAO", "cdate": 1640995200000, "mdate": 1684144037066, "content": {"title": "Structural Attention for Channel-Wise Adaptive Graph Convolution in Skeleton-Based Action Recognition", "abstract": "In skeleton-based action recognition, graph convolutions to model human action dynamics have been widely implemented and achieved remarkable results. Among these convolutions, channel-wise adaptive graph convolution shows outstanding performance. However, this method focuses too much on capturing correlation between joints within each channel and lacks the capability of learning structural features, which are generally hidden in geometric property of the skeleton on spatial domain. Our proposed method (SA-GCN) introduces symmetry trajectory attention module to measure the relation between left and right part of body and part relation attention module for exploration of the attention on general relation of each part. Both modules are intended to make full use of structural features in skeleton, further strengthening advantages of graph convolution. Experiments on three datasets (NW-UCLA, NTU-RGB+D and NTU-RGB+D 120) demonstrate state-of-the-art performance of our model, especially on joint modality."}}
{"id": "vq3RHLG7mXd", "cdate": 1609459200000, "mdate": 1683783682528, "content": {"title": "Recurrent Graph Convolutional Autoencoder for Unsupervised Skeleton-Based Action Recognition", "abstract": "Skeleton-based action recognition is a significant task in computer vision due to its robustness and wide application. Most unsupervised methods do not employ topological information of skeleton graphs, which actually ignore the spatial dependencies of action sequences. In this paper, we introduce a Recurrent Graph Convolutional Autoencoder (RGCA) for unsupervised action recognition from skeleton data. Our method explicitly exploits the spatial relationships among every frame\u2019s joints while preserving the long-term temporal dynamics in whole sequences. Moreover, a Spatial Joints Attention Module is employed to measure the importance of joints in the input sequence automatically. We conduct experiments on three datasets (NTU RGB+D 60, NW-UCLA, and UWA3D) and exceed the state-of-the-art performance."}}
{"id": "v5dmSTCkc7", "cdate": 1609459200000, "mdate": 1684144037066, "content": {"title": "Uncertainty Learning for Noise Resistant Sketch-Based 3D Shape Retrieval", "abstract": "Recently, sketch-based 3D shape retrieval has received growing attention in the community of computer graphics and computer vision. Most previous works focus on the problem of <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">how to reduce the large cross-modality difference between 2D sketch and 3D shape data</i> and make significant progress. Nevertheless, little attention has been paid to another important problem of <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">how to deal with noise in the sketch data</i> . For the first time, this work investigates the problem of noisy sketch data. It firstly provides qualitative and insightful analysis on the impact of noise, revealing that the noisy data are a key factor for unsatisfactory retrieval performance, as they cause severe over fitting and impair feature learning. Thus, the issue is worthy of serious treatment. Then, we propose to estimate sketch noise as data uncertainty, motivated by existing ideas that model data uncertainty with a distributional representation. We present methods with simple network structure and loss functions. They achieve strong results and establish new state-of-the-art on two benchmarks. Comprehensive experiment results, ablation studies, and insightful analysis validate the effectiveness of our methods, revealing that sketch feature learning with uncertainty is crucial for noise resistant sketch based 3D shape retrieval."}}
{"id": "TcBzin6izsA", "cdate": 1609459200000, "mdate": 1684144037004, "content": {"title": "Automatic Pose Quality Assessment for Adaptive Human Pose Refinement", "abstract": "Multi-person pose estimation from a 2D image is an essential technique for many computer vision tasks. Although the development of deep convolutional neural networks has brought large improvement to human pose estimation, some complex cases are still challenging to even state-of-the-art approaches. The forms of people in the images are diverse. The quality of estimated poses is difficult to guarantee. Estimated poses usually cannot be directly used in practical application scenarios. In this paper, we propose a pose quality assessment model and an adaptive human pose refinement method. The pose quality assessment model can measure per-joint pose quality with a quality score and select qualified estimated poses. The adaptive pose refinement method can handle each estimated pose respectively, until reaching a certain standard. Our experiments show the effectiveness of the pose quality assessment model and confirm that adaptive pose refinement method performs better than generally refining all poses once. Our adaptive pose refinement method reaches state-of-the-art performance."}}
{"id": "vhrGtpvc8c", "cdate": 1577836800000, "mdate": 1684144037073, "content": {"title": "Human-Object Relation Network For Action Recognition In Still Images", "abstract": "Surrounding object information has been widely used for action recognition. However, the relation between human and object, as an important cue, is usually ignored in the still image action recognition field. In this paper, we propose a novel approach for action recognition. The key to ours is a human-object relation module. By using the appearance as well as the spatial location of human and object, the module can compute (b) the pair-wise relation information between human and object to enhance features for action classification and can be trained jointly with our action recognition network. Experimental results on two popular datasets demonstrate the effectiveness of the proposed approach. Moreover, our method yields the new state-of-the-art results of 92.8% and 94.6% mAP on the PASCAL VOC 2012 Action and Stanford 40 Actions datasets respectively. Ablation study and visualization confirm the proposed method can model and utilize the human-object relation for action recognition."}}
