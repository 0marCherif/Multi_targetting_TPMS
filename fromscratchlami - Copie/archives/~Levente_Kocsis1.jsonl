{"id": "dCFqMtPGAOc", "cdate": 1546300800000, "mdate": null, "content": {"title": "Online ranking combination", "abstract": "As a task of high importance for recommender systems, we consider the problem of learning the convex combination of ranking algorithms by online machine learning. In the case of two base rankers, we show that the exponentially weighted combination achieves near optimal performance. However, the number of required points to be evaluated may be prohibitive with more base models in a real application. We propose a gradient based stochastic optimization algorithm that uses finite differences. Our new algorithm achieves similar empirical performance for two base rankers, while scaling well with an increased number of models. In our experiments with five real-world recommendation data sets, we show that the combination offers significant improvement over previously known stochastic optimization techniques. Our algorithm is the first effective stochastic optimization method for combining ranked recommendation lists by online machine learning."}}
{"id": "SGWhGUGUeq", "cdate": 1546300800000, "mdate": 1645778451799, "content": {"title": "Recommender Systems Over Data Streams", "abstract": "Recommender systems predict preferences of users to offer them relevant items in case the selection is too large. Recommender systems have to serve in online environments that can be highly nonstationary. Traditional recommender algorithms may periodically rebuild their models, but they cannot adjust to quick changes in trends caused, for example, by timely information. In this article, we investigate online learning based recommender algorithms that can efficiently handle nonstationary datasets. We show that online learning for recommendation is rather the usual than the exceptional task: For example, if no user history is available, we have to build a user model on the fly, based on the interactions in the live user session. To the best of our knowledge, this is the first survey with a comprehensive overview of the ideas for recommendation over streaming data and their implementation in various distributed data stream processing systems."}}
{"id": "HCG-3G8M8eq", "cdate": 1546300800000, "mdate": 1645778451776, "content": {"title": "Online Machine Learning in Big Data Streams: Overview", "abstract": "The area of online machine learning in big data streams covers algorithms that are distributed and work from data streams with only a limited possibility to store past data. The first requirement mostly concerns software architectures and efficient algorithms. The second one also imposes nontrivial theoretical restrictions on the modeling methods: In the data stream model, older data is no longer available to revise earlier suboptimal modeling decisions as the fresh data arrives. In this article, we provide an overview of the general requirements for online machine learning. We enumerate the distributed software architectures and libraries for online learning and show how various machine learning models are implemented in them. Some algorithms are described in more details in three more chapters of this handbook, including \u201cOnline Machine Learning Algorithms Over Data Streams\u201d; \u201cReinforcement Learning, Unsupervised Methods, and Concept Drift in Stream Learning\u201d; and \u201cRecommender Systems Over Data Streams.\u201d This article is a reference material and not a survey, with pointers to the most important resources and other surveys in the field."}}
{"id": "H4lZ2zLfIe5", "cdate": 1546300800000, "mdate": 1645778451804, "content": {"title": "Reinforcement Learning, Unsupervised Methods, and Concept Drift in Stream Learning", "abstract": "In this chapter, we give a brief overview of a few special topics in online machine learning, all of which are extensively covered in recent surveys. In Section \u201cReinforcement Learning,\u201d we survey reinforcement learning. In Section \u201cUnsupervised Data Mining,\u201d we describe unsupervised data mining methods, including clustering, frequent itemset mining, dimensionality reduction, and topic modeling. In Section \u201cConcept Drift and Adaptive Learning,\u201d we describe the notion of the dataset drift or, in other terms, concept drift and list the most important drift adapting methods. We only discuss representative results in these areas. This chapter is an extension of the other chapters in this handbook, \u201cOverview of Online Machine Learning in Big Data Streams,\u201d \u201cOnline Machine Learning Algorithms Over Data Streams,\u201d and \u201cRecommender Systems Over Data Streams.\u201d"}}
{"id": "BLQW3fUfIgq", "cdate": 1546300800000, "mdate": 1645778451759, "content": {"title": "Online Machine Learning Algorithms over Data Streams", "abstract": "The area of online machine learning in big data streams covers algorithms that (1) use only a limited possibility to store past data, (2) adapt their models to concept drift on the fly, and (3) work in a distributed computational environment. In this chapter, we overview the main online learning methods for classification and regression, the most important machine learning tasks. We highlight the most important ideas, including linear models, gradient descent, and tree-based methods. In these algorithms, older data is no longer available to revise earlier suboptimal modeling decisions as the fresh data arrives. Furthermore, due to the infinite nature of the data stream, online classifiers and regressors are best evaluated by the prequential method, which we also describe in this chapter. This entry is a reference material and not a survey. We attempt neither depth nor width in coverage, rather to give the most important pointers and references. This entry can be read independently but based on the concepts introduced in the \u201c Overview of Online Machine Learning in Big Data Streams \u201d chapter of this Handbook. Additional topics are covered in the chapters \u201c Reinforcement Learning, Unsupervised Methods, and Concept Drift in Stream Learning \u201d and \u201c Recommender Systems over Data Streams .\u201d"}}
{"id": "SU5-3GLM8gc", "cdate": 1514764800000, "mdate": 1645778451755, "content": {"title": "Online Machine Learning in Big Data Streams", "abstract": "The area of online machine learning in big data streams covers algorithms that are (1) distributed and (2) work from data streams with only a limited possibility to store past data. The first requirement mostly concerns software architectures and efficient algorithms. The second one also imposes nontrivial theoretical restrictions on the modeling methods: In the data stream model, older data is no longer available to revise earlier suboptimal modeling decisions as the fresh data arrives. In this article, we provide an overview of distributed software architectures and libraries as well as machine learning models for online learning. We highlight the most important ideas for classification, regression, recommendation, and unsupervised modeling from streaming data, and we show how they are implemented in various distributed data stream processing systems. This article is a reference material and not a survey. We do not attempt to be comprehensive in describing all existing methods and solutions; rather, we give pointers to the most important resources in the field. All related sub-fields, online algorithms, online learning, and distributed data processing are hugely dominant in current research and development with conceptually new research results and software components emerging at the time of writing. In this article, we refer to several survey results, both for distributed data processing and for online machine learning. Compared to past surveys, our article is different because we discuss recommender systems in extended detail."}}
{"id": "r-VhfLfLgc", "cdate": 1483228800000, "mdate": 1645778451780, "content": {"title": "Alpenglow: Open Source Recommender Framework with Time-aware Learning and Evaluation", "abstract": ""}}
{"id": "HGfZnfUzIlc", "cdate": 1483228800000, "mdate": 1645778451772, "content": {"title": "Location-aware online learning for top-k recommendation", "abstract": "We address the problem of recommending highly volatile items for users, both with potentially ambiguous location that may change in time. The three main ingredients of our method include (1) using online machine learning for the highly volatile items; (2) learning the personalized importance of hierarchical geolocation (for example, town, region, country, continent); finally (3) modeling temporal relevance by counting recent items with an exponential decay in recency. For (1), we consider a time-aware setting, where evaluation is cumbersome by traditional measures since we have different top recommendations at different times. We describe a time-aware framework based on individual item discounted gain. For (2), we observe that trends and geolocation turns out to be more important than personalized user preferences: user\u2013item and content-item matrix factorization improves in combination with our geo-trend learning methods, but in itself, they are greatly inferior to our location based models. In fact, since our best performing methods are based on spatiotemporal data, they are applicable in the user cold start setting as well and perform even better than content based cold start methods. Finally for (3), we estimate the probability that the item will be viewed by its previous views to obtain a powerful model that combines item popularity and recency. To generate realistic data for measuring our new methods, we rely on Twitter messages with known GPS location and consider hashtags as items that we recommend the users to be included in their next message."}}
{"id": "BuONnzLfUg5", "cdate": 1483228800000, "mdate": 1645778451772, "content": {"title": "Online Ranking Prediction in Non-stationary Environments", "abstract": ""}}
{"id": "PTEMB_-ahTh", "cdate": 1451606400000, "mdate": null, "content": {"title": "Robust Decentralized Low-Rank Matrix Decomposition", "abstract": "Low-rank matrix approximation is an important tool in data mining with a wide range of applications, including recommender systems, clustering, and identifying topics in documents. When the matrix to be approximated originates from a large distributed system, such as a network of mobile phones or smart meters, a challenging problem arises due to the strongly conflicting yet essential requirements of efficiency, robustness, and privacy preservation. We argue that although collecting sensitive data in a centralized fashion may be efficient, it is not an option when considering privacy and efficiency at the same time. Thus, we do not allow any sensitive data to leave the nodes of the network. The local information at each node (personal attributes, documents, media ratings, etc.) defines one row in the matrix. This means that all computations have to be performed at the edge of the network. Known parallel methods that respect the locality constraint, such as synchronized parallel gradient search or distributed iterative methods, require synchronized rounds or have inherent issues with load balancing, and thus they are not robust to failure. Our distributed stochastic gradient descent algorithm overcomes these limitations. During the execution, any sensitive information remains local, whereas the global features (e.g., the factor model of movies) converge to the correct value at all nodes. We present a theoretical derivation and a thorough experimental evaluation of our algorithm. We demonstrate that the convergence speed of our method is competitive while not relying on synchronization and being robust to extreme and realistic failure scenarios. To demonstrate the feasibility of our approach, we present trace-based simulations, real smartphone user behavior analysis, and tests over real movie recommender system data."}}
