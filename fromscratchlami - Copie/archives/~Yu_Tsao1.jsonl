{"id": "YtntjusJV6", "cdate": 1663850436128, "mdate": null, "content": {"title": "Interpretations of Domain Adaptations via Layer Variational Analysis", "abstract": "Transfer learning is known to perform efficiently in many applications empirically, yet limited literature reports the mechanism behind the scene. This study establishes both formal derivations and heuristic analysis to formulate the theory of transfer learning in deep learning. Our framework utilizing layer variational analysis proves that the success of transfer learning can be guaranteed with corresponding data conditions. Moreover, our theoretical calculation yields intuitive interpretations towards the knowledge transfer process. Subsequently, an alternative method for network-based transfer learning is derived. The method shows an increase in efficiency and accuracy for domain adaptation. It is particularly advantageous when new domain data is sufficiently sparse during adaptation. Numerical experiments over diverse tasks validated our theory and verified that our analytic expression achieved better performance in domain adaptation than the gradient descent method."}}
{"id": "5fvXH49wk2", "cdate": 1663849988795, "mdate": null, "content": {"title": "D4AM: A General Denoising Framework for Downstream Acoustic Models", "abstract": "The performance of acoustic models degrades notably in noisy environments. Speech enhancement (SE) can be used as a front-end strategy to aid automatic speech recognition (ASR) systems. However, existing training objectives of SE methods are not fully effective at integrating speech-text and noise-clean paired data for training toward unseen ASR systems. In this study, we propose a general denoising framework, D4AM, for various downstream acoustic models. Our framework fine-tunes the SE model with the backward gradient according to a specific acoustic model and the corresponding classification objective. In addition, our method aims to consider the regression objective as an auxiliary loss to make the SE model generalize to other unseen acoustic models. To jointly train an SE unit with regression and classification objectives, D4AM uses an adjustment scheme to directly estimate suitable weighting coefficients rather than undergoing a grid search process with additional training costs. The adjustment scheme consists of two parts: gradient calibration and regression objective weighting. The experimental results show that D4AM can consistently and effectively provide improvements to various unseen acoustic models and outperforms other combination setups. Specifically, when evaluated on the Google ASR API with real noisy data completely unseen during SE training, D4AM achieves a relative WER reduction of 24.65% compared with the direct feeding of noisy input. To our knowledge, this is the first work that deploys an effective combination scheme of regression (denoising) and classification (ASR) objectives to derive a general pre-processor applicable to various unseen ASR systems. Our code is available at https://github.com/ChangLee0903/D4AM."}}
{"id": "_j4ZUpoNO1e", "cdate": 1663849950191, "mdate": null, "content": {"title": "NEW TRAINING FRAMEWORK FOR SPEECH ENHANCEMENT USING REAL NOISY SPEECH", "abstract": "Recently, deep learning-based speech enhancement (SE) models have gained\nsignificant improvements. However, the success is mainly based on using synthetic\ntraining data created by adding clean speech with noise. On the other hand, in spite\nof its large amount, real noisy speech is hard to be applied for SE model training\nbecause of lack of its clean reference. In this paper, we propose a novel method\nto utilize real noisy speech for SE model training based on a non-intrusive speech\nquality prediction model. The SE model is trained through the guide of the quality\nprediction model. We also find that a speech quality predictor with better accuracy\nmay not necessarily be an appropriate teacher to guide the SE model. In addition,\nwe show that if the quality prediction model is adversarially robust, then the\nprediction model itself can also be served as a SE model by modifying the input\nnoisy speech through gradient backpropagation. Objective experiment results show\nthat, under the same SE model structure, the proposed new training method trained\non a large amount of real noisy speech can outperform the conventional supervised\nmodel trained on synthetic noisy speech. Lastly, the two training methods can be\ncombined to utilize both benefits of synthetic noisy speech (easy to learn) and real\nnoisy speech (large amount) to form semi-supervised learning which can further\nboost the performance both objectively and subjectively. The code will be released\nafter publication."}}
{"id": "LtXNu_mJdJI", "cdate": 1632875536585, "mdate": null, "content": {"title": "Mutual Information Continuity-constrained Estimator", "abstract": "The estimation of mutual information (MI) is vital to a variety of applications in machine learning. Recent developments in neural approaches have shown encouraging potential in estimating the MI between high-dimensional variables based on their latent representations. However, these estimators are prone to high variances owing to the inevitable outlier events. Recent approaches mitigate the outlier issue by smoothing the partition function using clipping or averaging strategies; however, these estimators either break the lower bound condition or sacrifice the level of accuracy. Accordingly, we propose Mutual Information Continuity-constrained Estimator (MICE). MICE alternatively smooths the partition function by constraining the Lipschitz constant of the log-density ratio estimator, thus alleviating the induced variances without clipping or averaging. Our proposed estimator outperforms most of the existing estimators in terms of bias and variance in the standard benchmark. In addition, we propose an experiment extension based on the standard benchmark, where variables are drawn from a multivariate normal distribution with correlations between each sample in a batch. The experimental results imply that when the i.i.d. assumption is unfulfilled, our proposed estimator can be more accurate than the existing approaches in which the MI tends to be underestimated. Finally, we demonstrate that MICE mitigates mode collapse in the kernel density estimation task."}}
{"id": "R6U4-Qkcg21", "cdate": 1621630263098, "mdate": null, "content": {"title": "Unsupervised Noise Adaptive Speech Enhancement by Discriminator-Constrained Optimal Transport", "abstract": "This paper presents a novel discriminator-constrained optimal transport network (DOTN) that performs unsupervised domain adaptation for speech enhancement (SE), which is an essential regression task in speech processing. The DOTN aims to estimate clean references of noisy speech in a target domain, by exploiting the knowledge available from the source domain. The domain shift between training and testing data has been reported to be an obstacle to learning problems in diverse fields. Although rich literature exists on unsupervised domain adaptation for classification, the methods proposed, especially in regressions, remain scarce and often depend on additional information regarding the input data. The proposed DOTN approach tactically fuses the optimal transport (OT) theory from mathematical analysis with generative adversarial frameworks, to help evaluate continuous labels in the target domain. The experimental results on two SE tasks demonstrate that by extending the classical OT formulation, our proposed DOTN outperforms previous adversarial domain adaptation frameworks in a purely unsupervised manner."}}
{"id": "SJ-KAq-_br", "cdate": 1546300800000, "mdate": null, "content": {"title": "MetricGAN: Generative Adversarial Networks based Black-box Metric Scores Optimization for Speech Enhancement", "abstract": "Adversarial loss in a conditional generative adversarial network (GAN) is not designed to directly optimize evaluation metrics of a target task, and thus, may not always guide the generator in a GA..."}}
{"id": "BybJo1fObr", "cdate": 1483228800000, "mdate": null, "content": {"title": "Track-Clustering Error Evaluation for Track-Based Multi-camera Tracking System Employing Human Re-identification", "abstract": "In this study, we present a set of new evaluation measures for the track-based multi-camera tracking (T-MCT) task leveraging the clustering measurements. We demonstrate that the proposed evaluation measures provide notable advantages over previous ones. Moreover, a distributed and online T-MCT framework is proposed, where re-identification (Re-id) is embedded in T-MCT, to confirm the validity of the proposed evaluation measures. Experimental results reveal that with the proposed evaluation measures, the performance of T-MCT can be accurately measured, which is highly correlated to the performance of Re-id. Furthermore, it is also noted that our T-MCT framework achieves competitive score on the DukeMTMC dataset when compared to the previous work that used global optimization algorithms. Both the evaluation measures and the inter-camera tracking framework are proven to be the stepping stone for multi-camera tracking."}}
