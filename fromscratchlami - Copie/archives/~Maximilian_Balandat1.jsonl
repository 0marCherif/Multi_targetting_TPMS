{"id": "uKuZrFD2OV", "cdate": 1684350534549, "mdate": 1684350534549, "content": {"title": "Bayesian Optimization over High-Dimensional Combinatorial Spaces via Dictionary-based Embeddings", "abstract": "We consider the problem of optimizing expensive black-box functions over high-dimensional\ncombinatorial spaces which arises in many science, engineering, and ML applications. We use\nBayesian Optimization (BO) and propose a novel\nsurrogate modeling approach for efficiently handling a large number of binary and categorical\nparameters. The key idea is to select a number of discrete structures from the input space\n(the dictionary) and use them to define an ordinal embedding for high-dimensional combinatorial structures. This allows us to use existing Gaussian process models for continuous\nspaces. We develop a principled approach based\non binary wavelets to construct dictionaries for\nbinary spaces, and propose a randomized construction method that generalizes to categorical\nspaces. We provide theoretical justification to\nsupport the effectiveness of the dictionary-based\nembeddings. Our experiments on diverse realworld benchmarks demonstrate the effectiveness\nof our proposed surrogate modeling approach\nover state-of-the-art BO methods"}}
{"id": "WwVR_YUH1-", "cdate": 1672531200000, "mdate": 1681658302411, "content": {"title": "Bayesian Optimization over High-Dimensional Combinatorial Spaces via Dictionary-based Embeddings", "abstract": "We consider the problem of optimizing expensive black-box functions over high-dimensional combinatorial spaces which arises in many science, engineering, and ML applications. We use Bayesian Optimization (BO) and propose a novel surrogate modeling approach for efficiently handling a large number of binary and categorical parameters. The key idea is to select a number of discrete structures from the input space (the dictionary) and use them to define an ordinal embedding for high-dimensional combinatorial structures. This allows us to use existing Gaussian process models for continuous spaces. We develop a principled approach based on binary wavelets to construct dictionaries for binary spaces, and propose a randomized construction method that generalizes to categorical spaces. We provide theoretical justification to support the effectiveness of the dictionary-based embeddings. Our experiments on diverse real-world benchmarks demonstrate the effectiveness of our proposed surrogate modeling approach over state-of-the-art BO methods."}}
{"id": "QHG2g7DNvFE", "cdate": 1672531200000, "mdate": 1682340555140, "content": {"title": "HHVM Performance Optimization for Large Scale Web Services", "abstract": ""}}
{"id": "WV1ZXTH0OIn", "cdate": 1652737389503, "mdate": null, "content": {"title": "Bayesian Optimization over Discrete and Mixed Spaces via Probabilistic Reparameterization", "abstract": "Optimizing expensive-to-evaluate black-box functions of discrete (and potentially continuous) design parameters is a ubiquitous problem in scientific and engineering applications. Bayesian optimization (BO) is a popular, sample-efficient method that leverages a probabilistic surrogate model and  an acquisition function (AF) to select promising designs to evaluate. However, maximizing the AF over mixed or high-cardinality discrete search spaces is challenging standard gradient-based methods cannot be used directly or evaluating the AF at every point in the search space would be computationally prohibitive. To address this issue, we propose using probabilistic reparameterization (PR). Instead of directly optimizing the AF over the search space containing discrete parameters, we instead maximize the expectation of the AF over a probability distribution defined by continuous parameters. We prove that under suitable reparameterizations, the BO policy that maximizes the probabilistic objective is the same as that which maximizes the AF, and therefore, PR enjoys the same regret bounds as the original BO policy using the underlying AF. Moreover, our approach provably converges to a stationary point of the probabilistic objective under gradient ascent using scalable, unbiased estimators of both the probabilistic objective and its gradient. Therefore, as the number of starting points and gradient steps increase, our approach will recover of a maximizer of the AF (an often-neglected requisite for commonly used BO regret bounds). We validate our approach empirically and demonstrate state-of-the-art optimization performance on a wide range of real-world applications. PR is complementary to (and benefits) recent work and naturally generalizes to settings with multiple objectives and black-box constraints."}}
{"id": "1WstkEYVcDz", "cdate": 1652125452491, "mdate": 1652125452491, "content": {"title": "Multi-objective bayesian optimization over high-dimensional search spaces", "abstract": "The ability to optimize multiple competing objective functions with high sample efficiency is imperative in many applied problems across science and industry. Multi-objective Bayesian optimization (BO) achieves strong empirical performance on such problems, but even with recent methodological advances, it has been restricted to simple, low-dimensional domains. Most existing BO methods exhibit poor performance on search spaces with more than a few dozen parameters. In this work we propose MORBO, a method for multi-objective Bayesian optimization over high-dimensional search spaces. MORBO performs local Bayesian optimization within multiple trust regions simultaneously, allowing it to explore and identify diverse solutions even when the objective functions are difficult to model globally. We show that MORBO significantly advances the state-of-the-art in sample-efficiency for several high-dimensional synthetic and real-world multi-objective problems, including a vehicle design problem with 222 parameters, demonstrating that MORBO is a practical approach for challenging and important problems that were previously out of reach for BO methods."}}
{"id": "r5IEvvIs9xq", "cdate": 1646077534827, "mdate": null, "content": {"title": "Multi-Objective Bayesian Optimization over High-Dimensional Search Spaces", "abstract": "Many real-world scientific and industrial applications require optimizing multiple competing black-box objectives. When the objectives are expensive-to-evaluate, multi-objective Bayesian optimization (BO) is a popular approach because of its high simple efficiency. However, even with recent methodological advances, most existing multi-objective BO methods perform poorly on search spaces with more than a few dozen parameters and rely on global surrogate models that scale cubically with the number of observations. In this work we propose MORBO, a scalable method for multi-objective BO over high-dimensional search spaces. MORBO identifies diverse globally optimal solutions by performing BO in multiple local regions of the design space in parallel using a coordinated strategy. We show that MORBO significantly advances the state-of-the-art in sample efficiency for several high-dimensional synthetic problems and real world applications, including an optical display design problem and a vehicle design problem with 146 and 222 parameters, respectively. On these problems, where existing BO algorithms fail to scale and perform well, MORBO provides practitioners with order-of-magnitude improvements in sample-efficiency over the current approach. "}}
{"id": "dsS7QAdFh8", "cdate": 1640995200000, "mdate": 1681658302539, "content": {"title": "Multi-objective Bayesian optimization over high-dimensional search spaces", "abstract": "Many real world scientific and industrial applications require optimizing multiple competing black-box objectives. When the objectives are expensive-to-evaluate, multi-objective Bayesian optimizati..."}}
{"id": "_NRnpOUkn6e", "cdate": 1640995200000, "mdate": 1681658301882, "content": {"title": "Sustainable AI: Environmental Implications, Challenges and Opportunities", "abstract": ""}}
{"id": "OJV-Vl40XXJ", "cdate": 1640995200000, "mdate": 1681658302188, "content": {"title": "Robust Multi-Objective Bayesian Optimization Under Input Noise", "abstract": "Bayesian optimization (BO) is a sample-efficient approach for tuning design parameters to optimize expensive-to-evaluate, black-box performance metrics. In many manufacturing processes, the design parameters are subject to random input noise, resulting in a product that is often less performant than expected. Although BO methods have been proposed for optimizing a single objective under input noise, no existing method addresses the practical scenario where there are multiple objectives that are sensitive to input perturbations. In this work, we propose the first multi-objective BO method that is robust to input noise. We formalize our goal as optimizing the multivariate value-at-risk (MVaR), a risk measure of the uncertain objectives. Since directly optimizing MVaR is computationally infeasible in many settings, we propose a scalable, theoretically-grounded approach for optimizing MVaR using random scalarizations. Empirically, we find that our approach significantly outperforms alternative methods and efficiently identifies optimal robust designs that will satisfy specifications across multiple metrics with high probability."}}
{"id": "BQyHXUuFcDq", "cdate": 1640995200000, "mdate": 1681658302405, "content": {"title": "Robust Multi-Objective Bayesian Optimization Under Input Noise", "abstract": "Bayesian optimization (BO) is a sample-efficient approach for tuning design parameters to optimize expensive-to-evaluate, black-box performance metrics. In many manufacturing processes, the design ..."}}
