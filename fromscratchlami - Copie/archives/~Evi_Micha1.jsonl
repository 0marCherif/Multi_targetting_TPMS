{"id": "l7aekTjF6CO", "cdate": 1652737639814, "mdate": null, "content": {"title": "Is Sortition Both Representative and Fair?", "abstract": "Sortition is a form of democracy built on random selection of representatives. Two of the key arguments in favor of sortition are that it provides representation (a random panel reflects the composition of the population) and fairness (everyone has a chance to participate). Uniformly random selection is perfectly fair, but is it representative? Towards answering this question, we introduce the notion of a representation metric on the space of individuals, and assume that the cost of an individual for a panel is determined by the $q$-th closest representative; the representation of a (random) panel is measured by the ratio between the (expected) sum of costs of the optimal panel for the individuals and that of the given panel. For $k/2 < q \\le k-\\Omega(k)$, where $k$ is the panel size, we show that uniform random selection is indeed representative by establishing a constant lower bound on this ratio. By contrast, for $q \\leq k/2$, no random selection algorithm that is almost fair can give such a guarantee. We therefore consider relaxed fairness guarantees and develop a new random selection algorithm that sheds light on the tradeoff between representation and fairness. \n"}}
{"id": "qKgG5yOetq", "cdate": 1640995200000, "mdate": 1682644625916, "content": {"title": "Proportionally Fair Online Allocation of Public Goods with Predictions", "abstract": "We design online algorithms for the fair allocation of public goods to a set of $N$ agents over a sequence of $T$ rounds and focus on improving their performance using predictions. In the basic model, a public good arrives in each round, the algorithm learns every agent's value for the good, and must irrevocably decide the amount of investment in the good without exceeding a total budget of $B$ across all rounds. The algorithm can utilize (potentially inaccurate) predictions of each agent's total value for all the goods to arrive. We measure the performance of the algorithm using a proportional fairness objective, which informally demands that every group of agents be rewarded in proportion to its size and the cohesiveness of its preferences. In the special case of binary agent preferences and a unit budget, we show that $O(\\log N)$ proportional fairness can be achieved without using any predictions, and that this is optimal even if perfectly accurate predictions were available. However, for general preferences and budget no algorithm can achieve better than $\\Theta(T/B)$ proportional fairness without predictions. We show that algorithms with (reasonably accurate) predictions can do much better, achieving $\\Theta(\\log (T/B))$ proportional fairness. We also extend this result to a general model in which a batch of $L$ public goods arrive in each round and achieve $O(\\log (\\min(N,L) \\cdot T/B))$ proportional fairness. Our exact bounds are parametrized as a function of the error in the predictions and the performance degrades gracefully with increasing errors."}}
{"id": "oUIrjl8tuV", "cdate": 1640995200000, "mdate": 1682644625912, "content": {"title": "Welfare-Maximizing Pooled Testing", "abstract": "In an epidemic, how should an organization with limited testing resources safely return to in-person activities after a period of lockdown? We study this question in a setting where the population at hand is heterogeneous in both utility for in-person activities and probability of infection. In such a period of re-integration, tests can be used as a certificate of non-infection, whereby those in negative tests are permitted to return to in-person activities for a designated amount of time. Under the assumption that samples can be pooled, the question of how to allocate a limited testing budget in the population to maximize the aggregate utility (i.e. welfare) of negatively-tested individuals who return to in-person activities is non-trivial, with a large space of potential testing allocations. We show that non-overlapping testing allocations, which are both conceptually and (crucially) logistically more simple to implement, are approximately optimal, and we design an efficient greedy algorithm for finding non-overlapping testing allocations with approximately optimal welfare. In computational experiments, we highlight the efficacy and viability of our greedy algorithm in practice. To the best of our knowledge, we are also first to implement and provide causal evidence on the benefits of utility-weighted pooled testing in a real-world setting. Surprisingly, our pilot study at a higher education research institute in Mexico finds no evidence that performance and mental health outcomes of participants in our testing regime are worse than under the first-best counterfactual of full reopening without testing."}}
{"id": "_OBvcUnLvH", "cdate": 1640995200000, "mdate": 1682644625913, "content": {"title": "A Little Charity Guarantees Fair Connected Graph Partitioning", "abstract": "Motivated by fair division applications, we study a fair connected graph partitioning problem, in which an undirected graph with m nodes must be divided between n agents such that each agent receives a connected subgraph and the partition is fair. We study approximate versions of two fairness criteria: \\alpha-proportionality requires that each agent receive a subgraph with at least (1/\\alpha)*m/n nodes, and \\alpha-balancedness requires that the ratio between the sizes of the largest and smallest subgraphs be at most \\alpha. Unfortunately, there exist simple examples in which no partition is reasonably proportional or balanced. To circumvent this, we introduce the idea of charity. We show that by \"donating\" just n-1 nodes, we can guarantee the existence of 2-proportional and almost 2-balanced partitions (and find them in polynomial time), and that this result is almost tight. More generally, we chart the tradeoff between the size of charity and the approximation of proportionality or balancedness we can guarantee."}}
{"id": "BZictJ-kJi", "cdate": 1640995200000, "mdate": 1682644625913, "content": {"title": "Individual Representation in Approval-Based Committee Voting", "abstract": "When selecting multiple candidates based on approval preferences of agents, the proportional representation of agents' opinions is an important and well-studied desideratum. Existing criteria for evaluating the representativeness of outcomes focus on groups of agents and demand that sufficiently large and cohesive groups are \"represented\" in the sense that candidates approved by some group members are selected. Crucially, these criteria say nothing about the representation of individual agents, even if these agents are members of groups that deserve representation. In this paper, we formalize the concept of individual representation (IR) and explore to which extent, and under which circumstances, it can be achieved. We show that checking whether an IR outcome exists is computationally intractable, and we verify that all common approval-based voting rules may fail to provide IR even in cases where this is possible. We then focus on domain restrictions and establish an interesting contrast between \"voter interval\" and \"candidate interval\" preferences. This contrast can also be observed in our experimental results, where we analyze the attainability of IR for realistic preference profiles."}}
{"id": "AlD5WD2ANIQ", "cdate": 1621629940114, "mdate": null, "content": {"title": "Fair Algorithms for Multi-Agent Multi-Armed Bandits", "abstract": "We propose a multi-agent variant of the classical multi-armed bandit problem, in which there are $N$ agents and $K$ arms, and pulling an arm generates a (possibly different) stochastic reward for each agent. Unlike the classical multi-armed bandit problem, the goal is not to learn the \"best arm\"; indeed, each agent may perceive a different arm to be the best for her personally. Instead, we seek to learn a fair distribution over the arms. Drawing on a long line of research in economics and computer science, we use the Nash social welfare as our notion of fairness. We design multi-agent variants of three classic multi-armed bandit algorithms and show that they achieve sublinear regret, which is now measured in terms of the lost Nash social welfare. We also extend a classical lower bound, establishing the optimality of one of our algorithms."}}
{"id": "qra3BuUugft", "cdate": 1609459200000, "mdate": 1682644625915, "content": {"title": "Individual Representation in Approval-Based Committee Voting", "abstract": "When selecting multiple candidates based on approval preferences of agents, the proportional representation of agents' opinions is an important and well-studied desideratum. Existing criteria for evaluating the representativeness of outcomes focus on groups of agents and demand that sufficiently large and cohesive groups are ''represented'' in the sense that candidates approved by some group members are selected. Crucially, these criteria say nothing about the representation of individual agents, even if these agents are members of groups that deserve representation. In this paper, we formalize the concept of individual representation (IR) and explore to which extent, and under which circumstances, it can be achieved. We show that checking whether an IR outcome exists is computationally intractable, and we verify that all common approval-based voting rules may fail to provide IR even in cases where this is possible. We then focus on domain restrictions and establish an interesting contrast between ''voter interval'' and ''candidate interval'' preferences. This contrast can also be observed in our experimental results, where we analyze the attainability of IR for realistic preference profiles."}}
{"id": "_QlfUAODs1", "cdate": 1609459200000, "mdate": 1682644625915, "content": {"title": "Two-Sided Matching Meets Fair Division", "abstract": "We introduce a new model for two-sided matching which allows us to borrow popular fairness notions from the fair division literature such as envy-freeness up to one good and maximin share guarantee. In our model, each agent is matched to multiple agents on the other side over whom she has additive preferences. We demand fairness for each side separately, giving rise to notions such as double envy-freeness up to one match (DEF1) and double maximin share guarantee (DMMS). We show that (a slight strengthening of) DEF1 cannot always be achieved, but in the special case where both sides have identical preferences, the round-robin algorithm with a carefully designed agent ordering achieves it. In contrast, DMMS cannot be achieved even when both sides have identical preferences."}}
{"id": "VOYdqMFm3Bx", "cdate": 1609459200000, "mdate": 1682644625914, "content": {"title": "Fair Algorithms for Multi-Agent Multi-Armed Bandits", "abstract": "We propose a multi-agent variant of the classical multi-armed bandit problem, in which there are $N$ agents and $K$ arms, and pulling an arm generates a (possibly different) stochastic reward for each agent. Unlike the classical multi-armed bandit problem, the goal is not to learn the \"best arm\"; indeed, each agent may perceive a different arm to be the best for her personally. Instead, we seek to learn a fair distribution over the arms. Drawing on a long line of research in economics and computer science, we use the Nash social welfare as our notion of fairness. We design multi-agent variants of three classic multi-armed bandit algorithms and show that they achieve sublinear regret, which is now measured in terms of the lost Nash social welfare. We also extend a classical lower bound, establishing the optimality of one of our algorithms."}}
{"id": "2CwxVnwUrP", "cdate": 1609459200000, "mdate": 1682644625910, "content": {"title": "Two-Sided Matching Meets Fair Division", "abstract": "We introduce a new model for two-sided matching which allows us to borrow popular fairness notions from the fair division literature such as envy-freeness up to one good and maximin share guarantee. In our model, each agent is matched to multiple agents on the other side over whom she has additive preferences. We demand fairness for each side separately, giving rise to notions such as double envy-freeness up to one match (DEF1) and double maximin share guarantee (DMMS). We show that (a slight strengthening of) DEF1 cannot always be achieved, but in the special case where both sides have identical preferences, the round-robin algorithm with a carefully designed agent ordering achieves it. In contrast, DMMS cannot be achieved even when both sides have identical preferences."}}
