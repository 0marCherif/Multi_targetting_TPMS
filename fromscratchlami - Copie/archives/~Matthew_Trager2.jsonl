{"id": "ma0lliBlUrt", "cdate": 1694172027479, "mdate": 1694172027479, "content": {"title": "Linear spaces of meanings: the compositional language of vlms", "abstract": "We investigate compositional structures in vector data embeddings from pre-trained vision-language models (VLMs). Traditionally, compositionality has been associated with algebraic operations on embeddings of words from a pre-existing vocabulary. In contrast, we seek to approximate label representations from a text encoder as combinations of a smaller set of vectors in the embedding space. These vectors can be seen as \"ideal words\" which can be used to generate new concepts in an efficient way. We present a theoretical framework for understanding linear compositionality, drawing connections with mathematical representation theory and previous definitions of disentanglement. We provide theoretical and empirical evidence that ideal words provide good compositional approximations of composite concepts and can be more effective than token-based decompositions of the same concepts."}}
{"id": "EcO1FSGUTm", "cdate": 1694171816915, "mdate": 1694171816915, "content": {"title": "a-la-carte prompt tuning (apt): Combining distinct data via composable prompting", "abstract": "We introduce A-la-carte Prompt Tuning (APT), a transformer-based scheme to tune prompts on distinct data so that they can be arbitrarily composed at inference time. The individual prompts can be trained in isolation, possibly on different devices, at different times, and on different distributions or domains. Furthermore each prompt only contains information about the subset of data it was exposed to during training. During inference, models can be assembled based on arbitrary selections of data sources, which we call a-la-carte learning. A-la-carte learning enables constructing bespoke models specific to each user's individual access rights and preferences. We can add or remove information from the model by simply adding or removing the corresponding prompts without retraining from scratch. We demonstrate that a-la-carte built models achieve accuracy within 5% of models trained on the union of the respective sources, with comparable cost in terms of training and inference time. For the continual learning benchmarks Split CIFAR-100 and CORe50, we achieve state-of-the-art performance."}}
{"id": "bR7rnrEIu4S", "cdate": 1694171694585, "mdate": 1694171694585, "content": {"title": "Train/test-time adaptation with retrieval", "abstract": "We introduce Train/Test-Time Adaptation with Retrieval (T3AR), a method to adapt models both at train and test time by means of a retrieval module and a searchable pool of external samples. Before inference, T3AR adapts a given model to the downstream task using refined pseudo-labels and a self-supervised contrastive objective function whose noise distribution leverages retrieved real samples to improve feature adaptation on the target data manifold. The retrieval of real images is key to T3AR since it does not rely solely on synthetic data augmentations to compensate for the lack of adaptation data, as typically done by other adaptation algorithms. Furthermore, thanks to the retrieval module, our method gives the user or service provider the possibility to improve model adaptation on the downstream task by incorporating further relevant data or to fully remove samples that may no longer be available due to changes in user preference after deployment. First, we show that T3AR can be used at training time to improve downstream fine-grained classification over standard fine-tuning baselines, and the fewer the adaptation data the higher the relative improvement (up to 13%). Second, we apply T3AR for test-time adaptation and show that exploiting a pool of external images at test-time leads to more robust representations over existing methods on DomainNet-126 and VISDA-C, especially when few adaptation data are available (up to 8%)."}}
{"id": "rkgOlCVYvB", "cdate": 1569439216437, "mdate": null, "content": {"title": "Pure and Spurious Critical Points: a Geometric Study of Linear Networks", "abstract": "The critical locus of the loss function of a neural network is determined by the geometry of the functional space and by the parameterization of this space by the network's weights. We introduce a natural distinction between pure critical points, which only depend on the functional space, and spurious critical points, which arise from the parameterization. We apply this perspective to revisit and extend the literature on the loss function of linear neural networks. For this type of network, the functional space is either the set of all linear maps from input to output space, or a determinantal variety, i.e., a set of linear maps with bounded rank. We use geometric properties of determinantal varieties to derive new results on the landscape of linear networks with different loss functions and different parameterizations. Our analysis clearly illustrates that the absence of \"bad\" local minima in the loss landscape of linear networks is due to two distinct phenomena that apply in different settings: it is true for arbitrary smooth convex losses in the case of architectures that can express all linear maps (\"filling architectures\") but it holds only for the quadratic loss when the functional space is a determinantal variety (\"non-filling architectures\"). Without any assumption on the architecture, smooth convex losses may lead to landscapes with many bad minima."}}
{"id": "Bye6JSHxLr", "cdate": 1567802596592, "mdate": null, "content": {"title": "On the Expressive Power of Deep Polynomial Neural Networks", "abstract": "We study deep neural networks with polynomial activations, particularly their expressive power.  For a fixed architecture and activation degree, a polynomial neural network defines an algebraic map from weights to polynomials.  The image of this map is the functional space associated to the network, and it is an irreducible algebraic variety upon taking closure.  This paper proposes the dimension of this variety as a precise measure of the expressive power of polynomial neural networks.  We obtain several theoretical results regarding this dimension as a function of architecture, including an exact formula for high activation degrees, as well as upper and lower bounds on layer widths in order for deep polynomials networks to fill the ambient functional space. We also present computational evidence that it is profitable in terms of expressiveness for layer widths to increase monotonically and then decrease monotonically.  Finally, we link our study to favorable optimization properties when training weights, and we draw  intriguing connections with tensor and polynomial decompositions.  "}}
{"id": "SmR4sAzeOaS", "cdate": 1546300800000, "mdate": null, "content": {"title": "Coordinate-Free Carlsson-Weinshall Duality and Relative Multi-View Geometry.", "abstract": "We present a coordinate-free description of Carlsson-Weinshall duality between scene points and camera pinholes and use it to derive a new characterization of primal/dual multi-view geometry. In the case of three views, a particular set of reduced trilinearities provide a novel parameterization of camera geometry that, unlike existing ones, is subject only to very simple internal constraints. These trilinearities lead to new \"quasi-linear\" algorithms for primal and dual structure from motion. We include some preliminary experiments with real and synthetic data."}}
{"id": "SkZqH5-ubH", "cdate": 1514764800000, "mdate": null, "content": {"title": "On the Solvability of Viewing Graphs", "abstract": "A set of fundamental matrices relating pairs of cameras in some configuration can be represented as edges of a \u201cviewing graph\u201d. Whether or not these fundamental matrices are generically sufficient to recover the global camera configuration depends on the structure of this graph. We study characterizations of \u201csolvable\u201d viewing graphs, and present several new results that can be applied to determine which pairs of views may be used to recover all camera parameters. We also discuss strategies for verifying the solvability of a graph computationally."}}
{"id": "ByW8ypZO-B", "cdate": 1483228800000, "mdate": null, "content": {"title": "General Models for Rational Cameras and the Case of Two-Slit Projections", "abstract": "The rational camera model recently introduced in [18] provides a general methodology for studying abstract nonlinear imaging systems and their multi-view geometry. This paper builds on this framework to study physical realizations of rational cameras. More precisely, we give an explicit account of the mapping between between physical visual rays and image points (missing in the original description), which allows us to give simple analytical expressions for direct and inverse projections. We also consider primitive camera models, that are orbits under the action of various projective transformations, and lead to a general notion of intrinsic parameters. The methodology is general, but it is illustrated concretely by an in-depth study of two-slit cameras, that we model using pairs of linear projections. This simple analytical form allows us to describe models for the corresponding primitive cameras, to introduce intrinsic parameters with a clear geometric meaning, and to define an epipolar tensor characterizing two-view correspondences. In turn, this leads to new algorithms for structure from motion and self-calibration."}}
{"id": "rXNgR8guTS", "cdate": 1451606400000, "mdate": null, "content": {"title": "Trinocular Geometry Revisited.", "abstract": "When do the visual rays associated with triplets of point correspondences converge, that is, intersect in a common point? Classical models of trinocular geometry based on the fundamental matrices and trifocal tensor associated with the corresponding cameras only provide partial answers to this fundamental question, in large part because of underlying, but seldom explicit, general configuration assumptions. This paper uses elementary tools from projective line geometry to provide necessary and sufficient geometric and analytical conditions for convergence in terms of transversals to triplets of visual rays, without any such assumptions. In turn, this yields a novel and simple minimal parameterization of trinocular geometry for cameras with non-collinear or collinear pinholes, which can be used to construct a practical and efficient method for trinocular geometry parameter estimation. We present numerical experiments using synthetic and real data."}}
{"id": "B14h22-ObB", "cdate": 1451606400000, "mdate": null, "content": {"title": "Consistency of Silhouettes and Their Duals", "abstract": "Silhouettes provide rich information on three-dimensional shape, since the intersection of the associated visual cones generates the \"visual hull\", which encloses and approximates the original shape. However, not all silhouettes can actually be projections of the same object in space: this simple observation has implications in object recognition and multi-view segmentation, and has been (often implicitly) used as a basis for camera calibration. In this paper, we investigate the conditions for multiple silhouettes, or more generally arbitrary closed image sets, to be geometrically \"consistent\". We present this notion as a natural generalization of traditional multi-view geometry, which deals with consistency for points. After discussing some general results, we present a \"dual\" formulation for consistency, that gives conditions for a family of planar sets to be sections of the same object. Finally, we introduce a more general notion of silhouette \"compatibility\" under partial knowledge of the camera projections, and point out some possible directions for future research."}}
