{"id": "XKlUkeOVNi", "cdate": 1705927797067, "mdate": 1705927797067, "content": {"title": "Enhancing code-switching for cross-lingual slu: A unified view of semantic and grammatical coherence", "abstract": "Despite the success of spoken language understanding (SLU) in high-resource languages, achieving similar performance in low-resource settings, such as zero-shot scenarios, remains challenging due to limited labeled training data. To improve zero-shot cross-lingual SLU, recent studies have explored code-switched sentences containing tokens from multiple languages. However, vanilla code-switched sentences often lack semantic and grammatical coherence. We ascribe this lack to two issues:(1) randomly replacing code-switched tokens with equal probability and (2) disregarding token-level dependency within each language. To tackle these issues, in this paper, we propose a novel method termed SoGo, for zero-shot cross-lingual SLU. First, we use a saliency-based substitution approach to extract keywords as substitution options. Then, we introduce a novel token-level alignment strategy that considers the similarity between the context and the code-switched tokens, ensuring grammatical coherence in code-switched sentences. Extensive experiments and analyses demonstrate the superior performance of SoGo across nine languages on MultiATIS++."}}
{"id": "gUrliAYkTsO", "cdate": 1705926724079, "mdate": 1705926724079, "content": {"title": "Towards unified spoken language understanding decoding via label-aware compact linguistics representations", "abstract": "Joint intent detection and slot filling models have shown promising success in recent years due to the high correlations between the two tasks. However, previous works independently decode the two tasks, which could result in misaligned predictions for both tasks. To address this shortcoming, we propose a novel method named Label-aware Compact Linguistics Representation (LCLR), which leverages label embeddings to jointly guide the decoding process. Concretely, LCLR projects both task-specific hidden states into a joint label latent space, where both task-specific hidden states could be concisely represented as linear combinations of label embeddings. Such feature decomposition of task-specific hidden states increases the representing power for the linguistics of utterance. Extensive experiments on two single-and multi-intent SLU benchmarks prove that LCLR can learn more discriminative label information than previous separate decoders, and consistently outperform previous state-of-the-art methods across all metrics. More encouragingly, LCLR can be applied to boost the performance of existing approaches, making it easy to be incorporated into any existing SLU models."}}
{"id": "QP8tIoFVJ-", "cdate": 1702815359744, "mdate": 1702815359744, "content": {"title": "MCLF: A multi-grained contrastive learning framework for asr-robust spoken language understanding", "abstract": "Enhancing the robustness towards Automatic Speech Recognition (ASR) errors is of great importance for Spoken Language Understanding (SLU). Trending ASR-robust SLU systems have witnessed impressive improvements through global contrastive learning. However, although most ASR errors occur only at local positions of utterances, they can easily lead to severe semantic changes, and utterance-level classification or comparison is difficult to distinguish such differences. To address the problem, we propose a two-stage multi-grained contrastive learning framework dubbed MCLF. Technically, we first adapt the pre-trained language models to downstream SLU datasets via the proposed multi-grained contrastive learning objective and then fine-tune it on the corresponding dataset. Besides, to facilitate contrastive learning in the pre-training stage, we explore several data augmentation methods to expand the training data. Experimental results and detailed analyses on four datasets and four BERT-like backbone models demonstrate the effectiveness of our approach."}}
{"id": "CMQf2NchXj", "cdate": 1702815179274, "mdate": 1702815179274, "content": {"title": "Syntax Matters: Towards Spoken Language Understanding via Syntax-Aware Attention", "abstract": "Spoken Language Understanding (SLU), a crucial component of task-oriented dialogue systems, has consistently garnered attention from both academic and industrial communities. Although incorporating syntactic information into models has the potential to enhance the comprehension of user utterances and yield impressive results, its application in SLU systems remains largely unexplored. In this paper, we propose a carefully designed model termed Syntax-aware attention (SAT) to enhance SLU, where attention scopes are constrained based on relationships within the syntactic structure. Experimental results on three datasets show that our model achieves substantial improvements and excellent performance. Moreover, SAT can be integrated into other BERT-based language models to further boost their performance."}}
{"id": "Qk2LcXDDUt", "cdate": 1702814749083, "mdate": 1702814749083, "content": {"title": "Mix before Align: Towards Zero-shot Cross-lingual Sentiment Analysis via Soft-Mix and Multi-View Learning", "abstract": "Due to the insufficient sentiment corpus in many languages, recent studies have proposed cross-lingual sentiment analysis to adapt sentiment analysis models from rich-resource languages to low-resource ones. However, existing models heavily rely on code-switched sentences to reduce the alignment discrepancy of cross-lingual embeddings, which could be limited by their inherent constraints. In this paper, we propose a novel method SOUL (short for Soft-mix and Multi-view learning) to enhance zero-shot cross-lingual sentiment analysis. Instead of using the embeddings of code-switched sentences directly, SOUL first mixes them softly with the embeddings of original sentences. Furthermore, SOUL utilizes multi-view learning to encourage contextualized embeddings to align into a refined language-invariant space. Experimental results on four cross-lingual benchmarks across five languages clearly verify the effectiveness of our proposed SOUL."}}
{"id": "tFck64Hbwj", "cdate": 1702814544658, "mdate": 1702814544658, "content": {"title": "Enhancing Code-Switching for Cross-lingual SLU: A Unified View of Semantic and Grammatical Coherence", "abstract": "Despite the success of spoken language understanding (SLU) in high-resource languages, achieving similar performance in low-resource settings, such as zero-shot scenarios, remains challenging due to limited labeled training data. To improve zero-shot cross-lingual SLU, recent studies have explored code-switched sentences containing tokens from multiple languages. However, vanilla code-switched sentences often lack semantic and grammatical coherence. We ascribe this lack to two issues:(1) randomly replacing code-switched tokens with equal probability and (2) disregarding token-level dependency within each language. To tackle these issues, in this paper, we propose a novel method termed SoGo, for zero-shot cross-lingual SLU. First, we use a saliency-based substitution approach to extract keywords as substitution options. Then, we introduce a novel token-level alignment strategy that considers the similarity between the context and the code-switched tokens, ensuring grammatical coherence in code-switched sentences. Extensive experiments and analyses demonstrate the superior performance of SoGo across nine languages on MultiATIS++."}}
{"id": "_uk3kzZJ8ls", "cdate": 1640995200000, "mdate": 1667354125591, "content": {"title": "MTL-SLT: Multi-Task Learning for Spoken Language Tasks", "abstract": ""}}
{"id": "UQqaqGUaCI", "cdate": 1640995200000, "mdate": 1667354125601, "content": {"title": "Towards Joint Intent Detection and Slot Filling via Higher-order Attention", "abstract": "Recently, attention-based models for joint intent detection and slot filling have achieved state-of-the-art performance. However, we think the conventional attention can only capture the first-order feature interaction between two tasks and is insufficient. To address this issue, we propose a unified BiLinear attention block, which leverages bilinear pooling to synchronously explore both the contextual and channel-wise bilinear attention distributions to capture the second-order interactions between the input intent and slot features. Higher-order interactions are constructed by combining many such blocks and exploiting Exponential Linear activations. Furthermore, we present a Higher-order Attention Network (HAN) to jointly model them. The experimental results show that our approach outperforms the state-of-the-art results. We also conduct experiments on the new SLURP dataset, and give a discussion on HAN\u2019s properties, i.e., robustness and generalization."}}
{"id": "PjZu_y5pTWE", "cdate": 1640995200000, "mdate": 1667354125597, "content": {"title": "Leveraging Bilinear Attention to Improve Spoken Language Understanding", "abstract": "Spoken language understanding system (SLU) typically includes two tasks: Intent detection (ID) and Slot filling (SF). Optimizing these two tasks in an interactive way with attention mechanism has been shown effective. However, previous attention-based works leveraged only the first order attention design, which is lacking in efficacy. To trigger more adequate information interaction between the input intent or slot features, we propose a novel framework with Bilinear attention, which can build the second order feature interactions. By stacking numerous Bilinear attention modules and equipping the Exponential Linear Unit activation, it can build higher and infinity order feature interactions. To demonstrate the effectiveness of the proposed framework, we conduct some experiments on two benchmark datasets, i.e., SNIPS and ATIS. And the experimental results show that our framework is more competitive than multiple baselines as well as the first order attention model."}}
{"id": "fCxWGrUzna", "cdate": 1609459200000, "mdate": 1667354125606, "content": {"title": "Sentiment Injected Iteratively Co-Interactive Network for Spoken Language Understanding", "abstract": "Spoken Language Understanding (SLU) is an essential part of the spoken dialogue system, which typically consists of intent detection (ID) and slot filling (SF) tasks. During the conversation, most utterances of people contain rich sentimental information, which is helpful for performing the ID and SF tasks but ignored to be explored by existing works. In this paper, we argue that implicitly introducing sentimental features can promote SLU performance. Specifically, we present a Multitask Learning (MTL) framework to implicitly extract and utilize the aspect-based sentimental text features. Besides, we introduce an Iteratively Co-Interactive Network (ICN) for the SLU task to fully utilize the comprehensive text features. Experimental results show that with the external BERT representation, our framework achieves new state-of-the-art on two benchmark datasets, i.e., SNIPS and ATIS."}}
