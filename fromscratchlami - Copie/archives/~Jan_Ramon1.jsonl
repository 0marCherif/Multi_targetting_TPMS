{"id": "dKJBCMamTbj", "cdate": 1680307200000, "mdate": 1693157110295, "content": {"title": "Private Sampling with Identifiable Cheaters", "abstract": ""}}
{"id": "nxtm4joi3T5", "cdate": 1672531200000, "mdate": 1708517176416, "content": {"title": "Introducing the TRUMPET project: TRUstworthy Multi-site Privacy Enhancing Technologies", "abstract": "This paper is an overview of the EU-funded project TRUMPET (https://trumpetproject.eu/), and gives an outline of its scope and main technical aspects and objectives. In recent years, Federated Learning has emerged as a revolutionary privacy-enhancing technology. However, further research has cast a shadow of doubt on its strength for privacy protection. The goal of TRUMPET is to research and develop novel privacy enhancement methods for Federated Learning, and to deliver a highly scalable Federated AI service platform for researchers, that will enable AI-powered studies of siloed, multi-site, cross-domain, cross-border European datasets with privacy guarantees that follow the requirements of GDPR. The generic TRUMPET platform will be piloted, demonstrated and validated in the specific use case of European cancer hospitals, allowing researchers and policymakers to extract AI-driven insights from previously inaccessible cross-border, cross-organization cancer data, while ensuring the patients' privacy."}}
{"id": "dDvkaI5MJi", "cdate": 1672531200000, "mdate": 1708517176259, "content": {"title": "Limits of multi-relational graphs", "abstract": "Graphons are limits of large graphs. Motivated by a theoretical problem from statistical relational learning, we develop a generalization of basic results from graphon theory into the \u201cmulti-relational\u201d setting. We show that their multi-relational counterparts, which we call multi-relational graphons, are analogically limits of large multi-relational graphs. We extend the cut-distance topology for graphons to multi-relational graphons and prove its compactness and the density of multi-relational graphs in this topology. In turn, compactness enables to prove the large deviation principle for Multi-Relational Graphs (LDP) which enables to prove the most typical random graphs constrained by marginal statistics converge asymptotically to constrained multi-relational graphons with maximum entropy. We show the equivalence between a restricted version of Markov Logic Network and Multi-Relational Graphons with maximum entropy."}}
{"id": "2Goml54fLh", "cdate": 1672531200000, "mdate": 1708517176411, "content": {"title": "DP-SGD with weight clipping", "abstract": "Recently, due to the popularity of deep neural networks and other methods whose training typically relies on the optimization of an objective function, and due to concerns for data privacy, there is a lot of interest in differentially private gradient descent methods. To achieve differential privacy guarantees with a minimum amount of noise, it is important to be able to bound precisely the sensitivity of the information which the participants will observe. In this study, we present a novel approach that mitigates the bias arising from traditional gradient clipping. By leveraging a public upper bound of the Lipschitz value of the current model and its current location within the search domain, we can achieve refined noise level adjustments. We present a new algorithm with improved differential privacy guarantees and a systematic empirical evaluation, showing that our new approach outperforms existing approaches also in practice."}}
{"id": "y-Hnf1ae9XQ", "cdate": 1640995200000, "mdate": 1681484529586, "content": {"title": "An accurate, scalable and verifiable protocol for federated differentially private averaging", "abstract": ""}}
{"id": "tONXVnQQ9jL", "cdate": 1640995200000, "mdate": 1708517176423, "content": {"title": "Linear Programs with Conjunctive Queries", "abstract": "In this paper, we study the problem of optimizing a linear program whose variables are the answers to a conjunctive query. For this we propose the language LP(CQ) for specifying linear programs whose constraints and objective functions depend on the answer sets of conjunctive queries. We contribute an efficient algorithm for solving programs in a fragment of LP(CQ). The naive approach constructs a linear program having as many variables as there are elements in the answer set of the queries. Our approach constructs a linear program having the same optimal value but fewer variables. This is done by exploiting the structure of the conjunctive queries using generalized hypertree decompositions of small width to factorize elements of the answer set together. We illustrate the various applications of LP(CQ) programs on three examples: optimizing deliveries of resources, minimizing noise for differential privacy, and computing the s-measure of patterns in graphs as needed for data mining."}}
{"id": "gZ8SUPZhSF", "cdate": 1640995200000, "mdate": 1708517176414, "content": {"title": "Linear Programs with Conjunctive Database Queries", "abstract": "In this paper, we study the problem of optimizing a linear program whose variables are the answers to a conjunctive query. For this we propose the language LP(CQ) for specifying linear programs whose constraints and objective functions depend on the answer sets of conjunctive queries. We contribute an efficient algorithm for solving programs in a fragment of LP(CQ). The natural approach constructs a linear program having as many variables as there are elements in the answer set of the queries. Our approach constructs a linear program having the same optimal value but fewer variables. This is done by exploiting the structure of the conjunctive queries using generalized hypertree decompositions of small width to factorize elements of the answer set together. We illustrate the various applications of LP(CQ) programs on three examples: optimizing deliveries of resources, minimizing noise for differential privacy, and computing the s-measure of patterns in graphs as needed for data mining."}}
{"id": "YS47RZFtKm", "cdate": 1631722296596, "mdate": null, "content": {"title": "Zero Knowledge Arguments for Verifiable Sampling", "abstract": "In privacy-preserving machine learning, it is less obvious to verify correct behavior of participants because they are not supposed to reveal their inputs in cleartext to other participants. It is hence important to make federated machine learning robust against data poisoning and related attacks.  While input data can be related to a distributed ledger (blockchain), a less studied input is formed by the random sampling parties perform. In this paper, we describe strategies based on zero knowledge proofs to allow parties to prove they perform sampling (and other computations) correctly.  We sketch a number of alternative ways to implement our idea and provide some preliminary experimental results."}}
{"id": "UErJ348uyNp_", "cdate": 1577836800000, "mdate": null, "content": {"title": "Distributed Differentially Private Averaging with Improved Utility and Robustness to Malicious Parties", "abstract": "Learning from data owned by several parties, as in federated learning, raises challenges regarding the privacy guarantees provided to participants and the correctness of the computation in the presence of malicious parties. We tackle these challenges in the context of distributed averaging, an essential building block of federated learning algorithms. Our first contribution is a scalable protocol in which participants exchange correlated Gaussian noise along the edges of a network graph, complemented by independent noise added by each party. We analyze the differential privacy guarantees of our protocol and the impact of the graph topology under colluding malicious parties, showing that we can nearly match the utility of the trusted curator model even when each honest party communicates with only a logarithmic number of other parties chosen at random. This is in contrast with protocols in the local model of privacy (with lower utility) or based on secure aggregation (where all pairs of users need to exchange messages). Our second contribution enables users to prove the correctness of their computations without compromising the efficiency and privacy guarantees of the protocol. Our verification protocol relies on standard cryptographic primitives like commitment schemes and zero knowledge proofs."}}
{"id": "2r2ljTYF-u", "cdate": 1577836800000, "mdate": 1708517176423, "content": {"title": "Interpretable Privacy with Optimizable Utility", "abstract": "In this position paper, we discuss the problem of specifying privacy requirements for machine learning based systems, in an interpretable yet operational way. Explaining privacy-improving technology is a challenging problem, especially when the goal is to construct a system which at the same time is interpretable and has a high performance. In order to address this challenge, we propose to specify privacy requirements as constraints, leaving several options for the concrete implementation of the system open, followed by a constraint optimization approach to achieve an efficient implementation also, next to the interpretable privacy guarantees."}}
