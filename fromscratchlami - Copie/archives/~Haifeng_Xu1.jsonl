{"id": "KTOcrOR5mQ9", "cdate": 1652737777558, "mdate": null, "content": {"title": "CS-Shapley: Class-wise Shapley Values for Data Valuation in Classification", "abstract": "Data valuation, or the valuation of individual datum contributions, has seen growing interest in machine learning due to its demonstrable efficacy for tasks such as noisy label detection. In particular, due to the desirable axiomatic properties, several Shapley value approximations have been proposed. In these methods, the value function is usually defined as the predictive accuracy over the entire development set. However, this limits the ability to differentiate between training instances that are helpful or harmful to their own classes. Intuitively, instances that harm their own classes may be noisy or mislabeled and should receive a lower valuation than helpful instances. In this work, we propose CS-Shapley, a Shapley value with a new value function that discriminates between training instances\u2019 in-class and out-of-class contributions. Our theoretical analysis shows the proposed value function is (essentially) the unique function that satisfies two desirable properties for evaluating data values in classification. Further, our experiments on two benchmark evaluation tasks (data removal and noisy label detection) and four classifiers demonstrate the effectiveness of CS-Shapley over existing methods. Lastly, we evaluate the \u201ctransferability\u201d of data values estimated from one classifier to others, and our results suggest Shapley-based data valuation is transferable for application across different models."}}
{"id": "Haj8_Rwqq_H", "cdate": 1652737637661, "mdate": null, "content": {"title": "Incrementality Bidding via Reinforcement Learning under Mixed and Delayed Rewards", "abstract": "Incrementality, which  measures the causal effect of showing an ad to a potential customer (e.g. a user in an internet platform) versus not, is a central object for advertisers in online advertising platforms. This paper  investigates the problem of how an advertiser can learn to optimize the bidding sequence in an online manner \\emph{without} knowing the incrementality parameters in advance. We formulate the offline version of this problem as a specially structured episodic Markov Decision Process (MDP) and then, for its online learning counterpart,  propose a novel reinforcement learning (RL) algorithm with regret at most $\\widetilde{O}(H^2\\sqrt{T})$, which depends on the number of rounds $H$ and number of episodes $T$, but does not depend on the number of actions (i.e., possible bids). A fundamental difference between our learning problem from standard RL problems is that the realized reward feedback from conversion incrementality is \\emph{mixed} and \\emph{delayed}. To handle this difficulty we propose and analyze a novel pairwise moment-matching algorithm to learn the conversion incrementality, which we believe is of independent  interest."}}
{"id": "ymAsTHhrnGm", "cdate": 1652737306391, "mdate": null, "content": {"title": "Inverse Game Theory for Stackelberg Games: the Blessing of Bounded Rationality", "abstract": "Optimizing strategic decisions (a.k.a. computing equilibrium) is key to the success of many non-cooperative multi-agent applications. However, in many real-world situations, we may face the exact opposite of this game-theoretic problem --- instead of prescribing equilibrium of a given game, we may directly observe the agents' equilibrium behaviors but want to infer the underlying parameters of an unknown game. This research question, also known as inverse game theory, has been studied in multiple recent works in the context of Stackelberg games. Unfortunately, existing works exhibit quite negative results, showing statistical hardness and computational hardness, assuming follower's perfectly rational behaviors. Our work relaxes the perfect rationality agent assumption to the classic quantal response model, a more realistic behavior model of bounded rationality. Interestingly, we show that the smooth property brought by such bounded rationality model actually leads to provably more efficient learning of the follower utility parameters in general Stackelberg games. Systematic empirical experiments on synthesized games confirm our theoretical results and further suggest its robustness beyond the strict quantal response model."}}
{"id": "S98f_IIsceq", "cdate": 1646077519753, "mdate": null, "content": {"title": "Information Design for Multiple Independent and Self-Interested Defenders: Work Less, Pay Off More", "abstract": "This paper studies the problem of information design in a general security game setting in which multiple independent self-interested defenders attempt to provide protection simultaneously on the same set of important targets against an unknown attacker. A principal, who can be one of the defenders, has access to certain private information (i.e., attacker type) whereas other defenders do not. We investigate the  question of how that principal, with additional private information, can influence the decisions of the defenders by partially and strategically revealing her information. We focus on the algorithmic study of information design for private signaling in this game setting. In particular, we develop a polynomial-time ellipsoid algorithm to compute an optimal private signaling scheme. Our key finding is that the separation oracle in the ellipsoid approach can be carefully reduced to bipartite matching. Furthermore, we introduce a compact representation of any ex-ante persuasive signaling schemes by exploiting intrinsic security resource allocation structures, enabling us to compute an optimal scheme significantly faster. Our experiment results show that by strategically revealing private information, the principal can significantly enhance the protection effectiveness on the targets.  "}}
{"id": "2lBhfVPYOM", "cdate": 1621630105644, "mdate": null, "content": {"title": "(Almost) Free Incentivized Exploration from Decentralized Learning Agents", "abstract": "Incentivized exploration in multi-armed bandits (MAB) has witnessed increasing interests and many progresses in recent years, where a principal offers bonuses to agents to do explorations on her behalf. However, almost all existing studies are confined to temporary myopic agents. In this work, we break this barrier and study incentivized exploration with multiple and long-term strategic agents, who have more complicated behaviors that often appear in real-world applications. An important observation of this work is that strategic agents' intrinsic needs of learning benefit (instead of harming) the principal's explorations by providing \"free pulls\". Moreover, it turns out that increasing the population of agents significantly lowers the principal's burden of incentivizing. The key and somewhat surprising insight revealed from our results is that when there are sufficiently many learning agents involved, the exploration process of the principal can be (almost) free. Our main results are built upon three novel components which may be of independent interest: (1) a simple yet provably effective incentive-provision strategy; (2) a carefully crafted best arm identification algorithm for rewards aggregated under unequal confidences; (3) a high-probability finite-time lower bound of UCB algorithms. Experimental results are provided to complement the theoretical analysis."}}
{"id": "TqvwWkdlLIk", "cdate": 1621629862133, "mdate": null, "content": {"title": "The Limits of Optimal Pricing in the Dark", "abstract": "A ubiquitous learning problem in today\u2019s digital market is, during repeated interactions between a seller and a buyer, how a seller can gradually learn optimal pricing decisions based on the buyer\u2019s past purchase responses. A fundamental challenge of learning in such a strategic setup is that the buyer will naturally have incentives to manipulate his responses in order to induce more favorable learning outcomes for him. To understand the limits of the seller\u2019s learning when facing such a strategic and possibly manipulative buyer, we study a natural yet powerful buyer manipulation strategy. That is, before the pricing game starts, the buyer simply commits to \u201cimitate\u201d a different value function by pretending to always react optimally according to this imitative value function. \n\nWe fully characterize the optimal imitative value function that the buyer should imitate as well as the resultant seller revenue and buyer surplus under this optimal buyer manipulation. Our characterizations reveal many useful insights about what happens at equilibrium. For example, a seller with concave production cost will obtain essentially 0 revenue at equilibrium whereas the revenue for a seller with convex production cost is the Bregman divergence of her cost function between no production and certain production. Finally, and importantly, we show that a more powerful class of pricing schemes does not necessarily increase, in fact, may be harmful to, the seller\u2019s revenue. Our results not only lead to an effective prescriptive way for buyers to manipulate learning algorithms but also shed lights on the limits of what a seller can really achieve when pricing in the dark."}}
{"id": "rTxCRLXRtk9", "cdate": 1621629811032, "mdate": null, "content": {"title": "Least Square Calibration for Peer Reviews", "abstract": "Peer review systems such as conference paper review often suffer from the issue of miscalibration. Previous works on peer review calibration usually only use the ordinal information or assume simplistic reviewer scoring functions such as linear functions. In practice, applications like academic conferences often rely on manual methods, such as open discussions, to mitigate miscalibration. It remains an important question to develop algorithms that can   handle different types of miscalibrations based on available prior knowledge. In this paper, we propose a flexible framework, namely \\emph{least square calibration} (LSC), for selecting top candidates from peer ratings. Our framework provably performs perfect calibration from noiseless linear scoring functions under mild assumptions, yet also provides competitive calibration results when the scoring function is from broader classes beyond linear functions and with arbitrary noise. On our synthetic dataset, we empirically demonstrate that our algorithm consistently outperforms the baseline which select top papers based on the highest average ratings.\n"}}
{"id": "Y6V1sVsaFUD", "cdate": 1620666648737, "mdate": null, "content": {"title": "Selling Information Through Consulting", "abstract": "We consider a monopoly information holder selling information to a budget-constrained decision\nmaker, who may benefit from the seller\u2019s information. The decision maker has a utility function that\ndepends on his action and an uncertain state of the world. The seller and the buyer each observe a private\nsignal regarding the state of the world, which may be correlated with each other. The seller\u2019s goal is to\nsell her private information to the buyer and extract maximum possible revenue, subject to the buyer\u2019s\nbudget constraints. We consider three different settings with increasing generality, i.e., the seller\u2019s signal\nand the buyer\u2019s signal can be independent, correlated, or follow a general distribution accessed through\na black-box sampling oracle. For each setting, we design information selling mechanisms which are both\noptimal and simple in the sense that they can be naturally interpreted, have succinct representations,\nand can be efficiently computed. Notably, though the optimal mechanism exhibits slightly increasing\ncomplexity as the setting becomes more general, all our mechanisms share the same format of acting\nas a consultant who recommends the best action to the buyer but uses different and carefully designed\npayment rules for different settings. Each of our optimal mechanisms can be easily computed by solving\na single polynomial-size linear program. This significantly simplifies exponential-size LPs solved by the\nEllipsoid method in the previous work, which computes the optimal mechanisms in the same setting\nbut without budget limit. Such simplification is enabled by our new characterizations of the optimal\nmechanism in the (more realistic) budget-constrained setting."}}
{"id": "HJx2G1iNKv", "cdate": 1620613884947, "mdate": null, "content": {"title": "Collapsing Bandits and Their Applications to Public Health Interventions", "abstract": "We propose and study Collpasing Bandits, a new restless multi-armed bandit (RMAB) setting in which each arm follows a binary-state Markovian process with a special structure: when an arm is played, the state is fully observed, thus \"collapsing\" any uncertainty, but when an arm is passive, no observation is made, thus allowing uncertainty to evolve. The goal is to keep as many arms in the \"good\" state as possible by planning a limited budget of actions per round. Such Collapsing Bandits are natural models for many healthcare domains in which workers must simultaneously monitor patients and deliver interventions in a way that maximizes the health of their patient cohort. Our main contributions are as follows: (i) Building on the Whittle index technique for RMABs, we derive conditions under which the Collapsing Bandits problem is indexable. Our derivation hinges on novel conditions that characterize when the optimal policies may take the form of either \"forward\" or \"reverse\" threshold policies. (ii) We exploit the optimality of threshold policies to build fast algorithms for computing the Whittle index, including a closed-form. (iii) We evaluate our algorithm on several data distributions including data from a real-world healthcare task in which a worker must monitor and deliver interventions to maximize their patients' adherence to tuberculosis medication. Our algorithm achieves a 3-order-of-magnitude speedup compared to state-of-the-art RMAB techniques while achieving similar performance."}}
{"id": "SyM9Zlbu-H", "cdate": 1514764800000, "mdate": null, "content": {"title": "Strategic Coordination of Human Patrollers and Mobile Sensors With Signaling for Security Games", "abstract": "Traditional security games concern the optimal randomized allocation of human patrollers, who can directly catch attackers or interdict attacks. Motivated by the emerging application of utilizing mobile sensors (e.g., UAVs) for patrolling, in this paper we propose the novel Sensor-Empowered security Game (SEG) model which captures the joint allocation of human patrollers and mobile sensors. Sensors differ from patrollers in that they cannot directly interdict attacks, but they can notify nearby patrollers (if any). Moreover, SEGs incorporate mobile sensors' natural functionality of strategic signaling. On the technical side, we first prove that solving SEGs is NP-hard even in zero-sum cases. We then develop a scalable algorithm SEGer based on the branch-and-price framework with two key novelties: (1) a novel MILP formulation for the slave; (2) an efficient relaxation of the problem for pruning. To further accelerate SEGer, we design a faster combinatorial algorithm for the slave problem, which is provably a constant-approximation to the slave problem in zero-sum cases and serves as a useful heuristic for general-sum SEGs. Our experiments demonstrate the significant benefit of utilizing mobile sensors."}}
