{"id": "wQuCGgWIzBS", "cdate": 1698796800000, "mdate": 1699146906963, "content": {"title": "Cervical cancerous cell classification: opposition-based harmony search for deep feature selection", "abstract": "Over 500 K (per year) cervical cancer cases are reported with a high mortality rate (6\u20139%). Automatically detecting cervical cancer using the Computer-Aided Diagnosis (CAD) tool at an early stage is important since it leads to successful treatment as pathologists. In this paper, we propose a tool that classifies cervical cancer cases from Pap smear cytology images using deep features. The proposed tool constitutes a Convolutional Neural Network (CNN) and a metaheuristic evolutionary algorithm called Opposition-based Harmony Search Algorithm (O-bHSA) for deep feature section. These features are classified using standard classifiers: SVM, MLP, and KNN. On two different publicly available datasets: Pap smear and liquid-based cytology, the proposed tool outperforms not only seven well-known optimization algorithms but also state-of-the-art methods. Codes are publicly available on GitHub ."}}
{"id": "97e92FXnesm", "cdate": 1696118400000, "mdate": 1699146906944, "content": {"title": "Texture and semantic convolutional auto-encoder for anomaly detection and segmentation", "abstract": "TSCAE uses a pre-trained network to extract image features and aggregate shallow and deep features into texture and semantic modules, respectively, which detect anomalies for these two features. Furt..."}}
{"id": "H9PVrKgVz4q", "cdate": 1690848000000, "mdate": 1699146906908, "content": {"title": "Adversarial Learning of Object-Aware Activation Map for Weakly-Supervised Semantic Segmentation", "abstract": "Recent years have witnessed impressive advances in the area of weakly-supervised semantic segmentation (WSSS). However, most of existing approaches are based on class activation maps (CAMs), which suffer from the under-segmentation problem (i.e., objects of interest are segmented partially). Although a number of literature works have been proposed to tackle this under-segmentation problem, we argue that these solutions built on CAMs may not be optimal for the WSSS task. Instead, in this paper we propose a network based on the object-aware activation map (OAM). The proposed network, termed OAM-Net, consists of four loss functions (foreground loss, background loss, average pixel and consistency loss) which ensure exactness, completeness, compactness and consistency of segmented objects via adversarial training. Compared to conventional CAM-based methods, our OAM-Net overcomes the under-segmentation drawback and significantly improves segmentation accuracy with negligible computational cost. A thorough comparison between OAM-Net and CAM-based approaches is carried out on the PASCAL VOC2012 dataset, and experimental results show that our network outperforms state-of-the-art approaches by a large margin. The code will be available soon."}}
{"id": "xaCVwjsFjC2", "cdate": 1688169600000, "mdate": 1699146906851, "content": {"title": "Adaptive weighted rain streaks model-driven deep network for single image deraining", "abstract": ""}}
{"id": "Eyuvj16cuP", "cdate": 1688169600000, "mdate": 1699146906869, "content": {"title": "Deep generative image priors for semantic face manipulation", "abstract": ""}}
{"id": "rCQhfMkxxqD", "cdate": 1683881155787, "mdate": null, "content": {"title": "Robust Twin Bounded Support Vector Classifier With Manifold Regularization", "abstract": "Support vector machine (SVM), as a supervised learning method, has different kinds of varieties with significant performance. In recent years, more research focused on nonparallel SVM, where twin SVM (TWSVM) is the typical one. In order to reduce the influence of outliers, more robust distance measurements are considered in these methods, but the discriminability of the models is neglected. In this article, we propose robust manifold twin bounded SVM (RMTBSVM), which considers both robustness and discriminability. Specifically, a novel norm, that is, capped L\u2081-norm, is used as the distance metric for robustness, and a robust manifold regularization is added to further improve the robustness and classification performance. In addition, we also use the kernel method to extend the proposed RMTBSVM for nonlinear classification. We introduce the optimization problems of the proposed model. Subsequently, effective algorithms for both linear and nonlinear cases are proposed and proved to be convergent. Moreover, the experiments are conducted to verify the effectiveness of our model. Compared with other methods under the SVM framework, the proposed RMTBSVM shows better classification accuracy and robustness."}}
{"id": "OyuoK5QwOT", "cdate": 1682899200000, "mdate": 1699146906869, "content": {"title": "Learning from pseudo-lesion: a self-supervised framework for COVID-19 diagnosis", "abstract": "The Coronavirus disease 2019 (COVID-19) has rapidly spread all over the world since its first report in December 2019, and thoracic computed tomography (CT) has become one of the main tools for its diagnosis. In recent years, deep learning-based approaches have shown impressive performance in myriad image recognition tasks. However, they usually require a large number of annotated data for training. Inspired by ground glass opacity, a common finding in COIVD-19 patient\u2019s CT scans, we proposed in this paper a novel self-supervised pretraining method based on pseudo-lesion generation and restoration for COVID-19 diagnosis. We used Perlin noise, a gradient noise based mathematical model, to generate lesion-like patterns, which were then randomly pasted to the lung regions of normal CT images to generate pseudo-COVID-19 images. The pairs of normal and pseudo-COVID-19 images were then used to train an encoder\u2013decoder architecture-based U-Net for image restoration, which does not require any labeled data. The pretrained encoder was then fine-tuned using labeled data for COVID-19 diagnosis task. Two public COVID-19 diagnosis datasets made up of CT images were employed for evaluation. Comprehensive experimental results demonstrated that the proposed self-supervised learning approach could extract better feature representation for COVID-19 diagnosis, and the accuracy of the proposed method outperformed the supervised model pretrained on large-scale images by 6.57% and 3.03% on SARS-CoV-2 dataset and Jinan COVID-19 dataset, respectively."}}
{"id": "llHS4E9DTP", "cdate": 1680307200000, "mdate": 1681695249081, "content": {"title": "Tongue size and shape classification fusing segmentation features for traditional Chinese medicine diagnosis", "abstract": "The size and shape of the tongue can reflect different pathological changes of the human body in Traditional Chinese Medicine (TCM). Recently, convolutional neural networks (CNNs) have been widely used for the classification of the color, thickness and teeth marks of the tongue. However, only a few works have been devoted to tongue size and shape classification, which is also key evidence for tongue diagnosis. In this work, we proposed an efficient deep network, TSC-WNet, for tongue size and shape classification. The proposed TSC-WNet consists of two subnetworks, i.e. TSC-Net and TSC-UNet. While TSC-Net is a straightforward and effective classification backbone, TSC-UNet is built for tongue segmentation and offers complementary beneficial features to enhance the classification performance of the networks. Our classification backbone requires fewer parameters than classic CNNs like AlexNet, VGG16 and ResNet18, and achieves better classification performance. Employing TSC-Net as the encoder, the TSC-UNet was used to provide the segmentation information for helping better tongue size and shape classification. Two different datasets, i.e. FJTCM/SZU and BioHit, were employed for performance evaluation. The experimental results show that TSC-Net achieves at least 2% higher accuracy and $$F_{1}$$ F 1 score than the baseline networks. Ablation studies show that the fusion of TSC-Net and TSC-UNet at both input and feature levels can further improve the accuracy and $$F_{1}$$ F 1 score by about 2%. The code is available at: https://github.com/Yating-Huang/TSC-WNet ."}}
{"id": "I3N7tga8t0", "cdate": 1680307200000, "mdate": 1699146906903, "content": {"title": "Enhanced robust spatial feature selection and correlation filter learning for UAV tracking", "abstract": ""}}
{"id": "bYilsWQjlj", "cdate": 1677628800000, "mdate": 1681695249135, "content": {"title": "Weakly Supervised Pedestrian Segmentation for Person Re-Identification", "abstract": "Person re-identification (RelD) is an important problem in intelligent surveillance and public security. Among all the solutions to this problem, existing mask-based methods first use a well-pretrained segmentation model to generate a foreground mask, in order to exclude the background from ReID. Then they perform the RelD task directly on the segmented pedestrian image. However, such a process requires extra datasets with pixel-level semantic labels. In this paper, we propose a Weakly Supervised Pedestrian Segmentation (WSPS) framework to produce the foreground mask directly from the RelD datasets. In contrast, our WSPS only requires image-level subject ID labels. To better utilize the pedestrian mask, we also propose the Image Synthesis Augmentation (ISA) technique to further augment the dataset. Experiments show that the features learned from our proposed framework are robust and discriminative. Compared with the baseline, the mAP of our framework is about 4.4%, 11.7%, and 4.0% higher on three widely used datasets including Market-1501, CUHK03, and MSMT17. The code will be available soon."}}
