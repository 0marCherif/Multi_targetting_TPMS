{"id": "xhsn2WhtBFG", "cdate": 1609459200000, "mdate": null, "content": {"title": "Active Exploration for Unsupervised Object Categorization Based on Multimodal Hierarchical Dirichlet Process", "abstract": "This paper describes an effective active exploration method for multimodal object categorization using a multimodal hierarchical Dirichlet process (MHDP). MHDP is a type of multimodal latent variable models, e.g., multimodal latent Dirichlet allocation and multimodal variational autoencoder, that enables a robot to perform unsupervised multimodal object categorization on the basis of different types of sensor information. The goal of the active exploration is to reduce the number of actions executed to collect multimodal sensor information from a variety of objects to acquire knowledge on object categories. The active exploration method employing the information gain (IG) criterion for MHDP is described by extending the IG-based active perception method. Exploiting the submodular property of IG in MHDP, greedy and lazy greedy algorithms with a certain theoretical guarantee of performance are proposed. The effectiveness of the proposed method is evaluated in a robot experiment. Results show that the proposed active exploration method with the greedy algorithm works well, and it significantly reduces the step for exploration. Further, the performance of the lazy greedy algorithm is found to deteriorate at times, due to the estimation error in the IG, differently from that of active perception."}}
{"id": "mn4nS9JFebW", "cdate": 1609459200000, "mdate": null, "content": {"title": "Whole brain Probabilistic Generative Model toward Realizing Cognitive Architecture for Developmental Robots", "abstract": "Building a humanlike integrative artificial cognitive system, that is, an artificial general intelligence (AGI), is the holy grail of the artificial intelligence (AI) field. Furthermore, a computational model that enables an artificial system to achieve cognitive development will be an excellent reference for brain and cognitive science. This paper describes an approach to develop a cognitive architecture by integrating elemental cognitive modules to enable the training of the modules as a whole. This approach is based on two ideas: (1) brain-inspired AI, learning human brain architecture to build human-level intelligence, and (2) a probabilistic generative model(PGM)-based cognitive system to develop a cognitive system for developmental robots by integrating PGMs. The development framework is called a whole brain PGM (WB-PGM), which differs fundamentally from existing cognitive architectures in that it can learn continuously through a system based on sensory-motor information. In this study, we describe the rationale of WB-PGM, the current status of PGM-based elemental cognitive modules, their relationship with the human brain, the approach to the integration of the cognitive modules, and future challenges. Our findings can serve as a reference for brain studies. As PGMs describe explicit informational relationships between variables, this description provides interpretable guidance from computational sciences to brain science. By providing such information, researchers in neuroscience can provide feedback to researchers in AI and robotics on what the current models lack with reference to the brain. Further, it can facilitate collaboration among researchers in neuro-cognitive sciences as well as AI and robotics."}}
{"id": "dVo3qyM2Z_V", "cdate": 1609459200000, "mdate": null, "content": {"title": "Double Articulation Analyzer with Prosody for Unsupervised Word and Phoneme Discovery", "abstract": "Infants acquire words and phonemes from unsegmented speech signals using segmentation cues, such as distributional, prosodic, and co-occurrence cues. Many pre-existing computational models that represent the process tend to focus on distributional or prosodic cues. This paper proposes a nonparametric Bayesian probabilistic generative model called the prosodic hierarchical Dirichlet process-hidden language model (Prosodic HDP-HLM). Prosodic HDP-HLM, an extension of HDP-HLM, considers both prosodic and distributional cues within a single integrative generative model. We conducted three experiments on different types of datasets, and demonstrate the validity of the proposed method. The results show that the Prosodic DAA successfully uses prosodic cues and outperforms a method that solely uses distributional cues. The main contributions of this study are as follows: 1) We develop a probabilistic generative model for time series data including prosody that potentially has a double articulation structure; 2) We propose the Prosodic DAA by deriving the inference procedure for Prosodic HDP-HLM and show that Prosodic DAA can discover words directly from continuous human speech signals using statistical information and prosodic information in an unsupervised manner; 3) We show that prosodic cues contribute to word segmentation more in naturally distributed case words, i.e., they follow Zipf's law."}}
{"id": "OWPnYLBYmeo", "cdate": 1609459200000, "mdate": null, "content": {"title": "Map completion from partial observation using the global structure of multiple environmental maps", "abstract": "Using the spatial structure of various indoor environments as prior knowledge, the robot would construct the map more efficiently. Autonomous mobile robots generally apply simultaneous localization and mapping (SLAM) methods to understand the reachable area in newly visited environments. However, conventional mapping approaches are limited by only considering sensor observation and control signals to estimate the current environment map. This paper proposes a novel SLAM method, map completion network-based SLAM (MCN-SLAM), based on a probabilistic generative model incorporating deep neural networks for map completion. These map completion networks are primarily trained in the framework of generative adversarial networks (GANs) to extract the global structure of large amounts of existing map data. We show in experiments that the proposed method can estimate the environment map 1.3 times better than the previous SLAM methods in the situation of partial observation."}}
{"id": "Nvc2UYQ4W16", "cdate": 1609459200000, "mdate": null, "content": {"title": "Autonomous planning based on spatial concepts to tidy up home environments with service robots", "abstract": "Tidy-up tasks by service robots in home environments are challenging in robotics applications because they involve various interactions with the environment. In particular, robots are required not ..."}}
{"id": "NPs0ylP3XwP", "cdate": 1609459200000, "mdate": null, "content": {"title": "Hierarchical Bayesian Model for the Transfer of Knowledge on Spatial Concepts based on Multimodal Information", "abstract": "This paper proposes a hierarchical Bayesian model based on spatial concepts that enables a robot to transfer the knowledge of places from experienced environments to a new environment. The transfer of knowledge based on spatial concepts is modeled as the calculation process of the posterior distribution based on the observations obtained in each environment with the parameters of spatial concepts generalized to environments as prior knowledge. We conducted experiments to evaluate the generalization performance of spatial knowledge for general places such as kitchens and the adaptive performance of spatial knowledge for unique places such as `Emma's room' in a new environment. In the experiments, the accuracies of the proposed method and conventional methods were compared in the prediction task of location names from an image and a position, and the prediction task of positions from a location name. The experimental results demonstrated that the proposed method has a higher prediction accuracy of location names and positions than the conventional method owing to the transfer of knowledge."}}
{"id": "G5zV8Nm878f", "cdate": 1609459200000, "mdate": null, "content": {"title": "StarGAN-based Emotional Voice Conversion for Japanese Phrases", "abstract": "This paper shows that StarGAN-VC, a spectral envelope transformation method for non-parallel many-to-many voice conversion (VC), is capable of emotional VC (EVC). Although StarGAN-VC has been shown to enable speaker identity conversion, its capability for EVC for Japanese phrases has not been clarified. In this paper, we describe the direct application of StarGAN-VC to an EVC task with minimal fundamental frequency and aperiodicity processing. Through subjective evaluation experiments, we evaluated the performance of our StarGAN-EVC system in terms of its ability to achieve EVC for Japanese phrases. The subjective evaluation is conducted in terms of subjective classification and mean opinion score of neutrality and similarity. In addition, the interdependence between the source and target emotional domains was investigated from the perspective of the quality of EVC."}}
{"id": "E5rM2rhJPdy", "cdate": 1609459200000, "mdate": null, "content": {"title": "Teaching System for Multimodal Object Categorization by Human-Robot Interaction in Mixed Reality", "abstract": "As service robots are becoming essential to support aging societies, teaching them how to perform general service tasks is still a major challenge preventing their deployment in daily-life environments. In addition, developing an artificial intelligence for general service tasks requires bottom-up, unsupervised approaches to let the robots learn from their own observations and interactions with the users. However, compared to the top-down, supervised approaches such as deep learning where the extent of the learning is directly related to the amount and variety of the pre-existing data provided to the robots, and thus relatively easy to understand from a human perspective, the learning status in bottom-up approaches is by their nature much harder to appreciate and visualize. To address these issues, we propose a teaching system for multimodal object categorization by human-robot interaction through Mixed Reality (MR) visualization. In particular, our proposed system enables a user to monitor and intervene in the robot\u2019s object categorization process based on Multimodal Latent Dirichlet Allocation (MLDA) to solve unexpected results and accelerate the learning. Our contribution is twofold by 1) describing the integration of a service robot, MR interactions, and MLDA object categorization in a unified system, and 2) proposing an MR user interface to teach robots through intuitive visualization and interactions."}}
{"id": "DIHoqnoBxJ", "cdate": 1609459200000, "mdate": null, "content": {"title": "Bidirectional Generation of Object Images and Positions using Deep Generative Models for Service Robotics Applications", "abstract": "The introduction of systems and robots for automated services is important for reducing running costs and improving operational efficiency in the retail industry. To this aim, we develop a system that enables robot agents to display products in stores. The main problem in automating product display using common supervised methods with robot agents is the huge amount of data required to recognize product categories and arrangements in a variety of different store layouts. To solve this problem, we propose a crossmodal inference system based on joint multimodal variational autoencoder (JMVAE) that learns the relationship between object image information and location information observed on site by robot agents. In our experiments, we created a simulation environment replicating a convenience store that allows a robot agent to observe an object image and its 3D coordinate information, and confirmed whether JMVAE can learn and generate a shared representation of an object image and 3D coordinates in a bidirectional manner."}}
{"id": "5FwW6dL9qk4", "cdate": 1609459200000, "mdate": null, "content": {"title": "Editorial: Language and Robotics", "abstract": "Language in the real-world environment involves a wide range of challenges in robotics and artificial intelligence (AI). Service robots are required to communicate and collaborate with people using language in the real-world environment. When a robot receives a spoken command from a user in a domestic environment, the robot must understand its meaning in the context of the specific environment. For example, to understand the meaning of \"please bring me a pen in Takato's room\" the robot needs to know where to find a pen and where Takato's room is. Futhermore, words or expressions (i.e. sounds processed as symbols) can be invented naturally in our daily environment and their meaning can change [1] over time (i.e. depending on the culture or age of the speaker). Robots thus need to adapt like humans to these versatile aspects of language and demonstrate the ability to learn any language [2]. In robotics, language understanding inevitably involves multimodal learning, semantic mapping, and behavior learning. To enable a robot to interact orally with people in a long-term manner, we need to develop an AI that makes a robot learn and adapt to language in the real-world environment and in an on-line manner. This topic thus raises several challenges to bridge the gap from low-level sensorimotor interaction [3] to high-level compositional symbolic communication. Taking inspiration of how children acquire language can help to design the simplest mechanisms to deal with these challen..."}}
