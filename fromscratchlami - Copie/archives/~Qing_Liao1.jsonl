{"id": "q78_qyyMW8", "cdate": 1677628800000, "mdate": 1679904515658, "content": {"title": "E$^{3}$3Outlier: a Self-Supervised Framework for Unsupervised Deep Outlier Detection", "abstract": ""}}
{"id": "9GApYctqwb", "cdate": 1677628800000, "mdate": 1679904515642, "content": {"title": "Design of a Quantization-Based DNN Delta Compression Framework for Model Snapshots and Federated Learning", "abstract": ""}}
{"id": "iAiYL0t_NOp", "cdate": 1672531200000, "mdate": 1679904515656, "content": {"title": "Vulnerability Detection with Graph Simplification and Enhanced Graph Representation Learning", "abstract": ""}}
{"id": "ygjmnHQS8pH", "cdate": 1640995200000, "mdate": 1679904516002, "content": {"title": "Improving Multi-task Stance Detection with Multi-task Interaction Network", "abstract": ""}}
{"id": "xesdRN4_bl", "cdate": 1640995200000, "mdate": 1667354454538, "content": {"title": "Coarse-to-fine pseudo supervision guided meta-task optimization for few-shot object classification", "abstract": ""}}
{"id": "wHinmhK_YZg", "cdate": 1640995200000, "mdate": 1667375775615, "content": {"title": "On the Equity of Nuclear Norm Maximization in Unsupervised Domain Adaptation", "abstract": "Nuclear norm maximization has shown the power to enhance the transferability of unsupervised domain adaptation model (UDA) in an empirical scheme. In this paper, we identify a new property termed equity, which indicates the balance degree of predicted classes, to demystify the efficacy of nuclear norm maximization for UDA theoretically. With this in mind, we offer a new discriminability-and-equity maximization paradigm built on squares loss, such that predictions are equalized explicitly. To verify its feasibility and flexibility, two new losses termed Class Weighted Squares Maximization (CWSM) and Normalized Squares Maximization (NSM), are proposed to maximize both predictive discriminability and equity, from the class level and the sample level, respectively. Importantly, we theoretically relate these two novel losses (i.e., CWSM and NSM) to the equity maximization under mild conditions, and empirically suggest the importance of the predictive equity in UDA. Moreover, it is very efficient to realize the equity constraints in both losses. Experiments of cross-domain image classification on three popular benchmark datasets show that both CWSM and NSM contribute to outperforming the corresponding counterparts."}}
{"id": "sWk7NzO4TGf", "cdate": 1640995200000, "mdate": 1679904516080, "content": {"title": "Affective Knowledge Enhanced Multiple-Graph Fusion Networks for Aspect-based Sentiment Analysis", "abstract": ""}}
{"id": "lvFiu9PoY2", "cdate": 1640995200000, "mdate": 1679904515648, "content": {"title": "A Novel Deep Learning Framework for Automatic Recognition of Thyroid Gland and Tissues of Neck in Ultrasound Image", "abstract": ""}}
{"id": "kZiwjFZPYe3", "cdate": 1640995200000, "mdate": 1674562752072, "content": {"title": "Knowledge-aware Neural Networks with Personalized Feature Referencing for Cold-start Recommendation", "abstract": "Incorporating knowledge graphs (KGs) as side information in recommendation has recently attracted considerable attention. Despite the success in general recommendation scenarios, prior methods may fall short of performance satisfaction for the cold-start problem in which users are associated with very limited interactive information. Since the conventional methods rely on exploring the interaction topology, they may however fail to capture sufficient information in cold-start scenarios. To mitigate the problem, we propose a novel Knowledge-aware Neural Networks with Personalized Feature Referencing Mechanism, namely KPER. Different from most prior methods which simply enrich the targets' semantics from KGs, e.g., product attributes, KPER utilizes the KGs as a \"semantic bridge\" to extract feature references for cold-start users or items. Specifically, given cold-start targets, KPER first probes semantically relevant but not necessarily structurally close users or items as adaptive seeds for referencing features. Then a Gated Information Aggregation module is introduced to learn the combinatorial latent features for cold-start users and items. Our extensive experiments over four real-world datasets show that, KPER consistently outperforms all competing methods in cold-start scenarios, whilst maintaining superiority in general scenarios without compromising overall performance, e.g., by achieving 0.81%-16.08% and 1.01%-14.49% performance improvement across all datasets in Top-10 recommendation."}}
{"id": "j60PKP-ScF", "cdate": 1640995200000, "mdate": 1679904516035, "content": {"title": "Listening to Users' Voice: Automatic Summarization of Helpful App Reviews", "abstract": ""}}
