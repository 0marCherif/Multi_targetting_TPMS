{"id": "ff3zEyIuV1", "cdate": 1672531200000, "mdate": 1681652129562, "content": {"title": "Graph Neural Networks with Interlayer Feature Representation for Image Super-Resolution", "abstract": ""}}
{"id": "xrhSsjhIul8", "cdate": 1640995200000, "mdate": 1648686961416, "content": {"title": "Graph convolutional autoencoders with co-learning of graph structure and node attributes", "abstract": "Highlights \u2022 We propose a novel end-to-end graph autoencoders model for the attributed graph. \u2022 The proposed model can reconstruct both the graph structure and node attributes. \u2022 The graph encoder is a completely low-pass filter. \u2022 The graph decoder is a completely high-pass filter. \u2022 Show the effectiveness of the proposed model. Abstract Recently, graph representation learning based on autoencoders has received much attention. However, these methods suffer from two limitations. First, most graph autoencoders ignore the reconstruction of either the graph structure or the node attributes, which often leads to a poor latent representation of the graph-structured data. Second, for existing graph autoencoders models, the encoder and decoder are mainly composed of an initial graph convolutional network (GCN) or its variants. These traditional GCN-based graph autoencoders more or less encounter the problem of incomplete filtering, which causes these models to be unstable in practical applications. To address the above issues, this paper proposes the Graph convolutional Autoencoders with co-learning of graph Structure and Node attributes (GASN) based on variational autoencoders. Specifically, the proposed GASN encodes and decodes the node attributes and graph structure comprehensively in the graph-structured data. Furthermore, we design a completely low-pass graph encoder and a high-pass graph decoder. The experimental results on real-world datasets demonstrate that the proposed GASN achieves state-of-the-art performance on node clustering, link prediction, and visualization tasks."}}
{"id": "kVFgb6CnS2P", "cdate": 1640995200000, "mdate": 1653663756313, "content": {"title": "Multi-view graph convolutional networks with attention mechanism", "abstract": ""}}
{"id": "hbJo-iWnSz", "cdate": 1640995200000, "mdate": 1681652130159, "content": {"title": "Graph convolutional autoencoders with co-learning of graph structure and node attributes", "abstract": ""}}
{"id": "eWzbNpYf0o", "cdate": 1640995200000, "mdate": 1648686961416, "content": {"title": "Multi-Scale Variational Graph AutoEncoder for Link Prediction", "abstract": "Link prediction has become a significant research problem in deep learning, and the graph-based autoencoder model is one of the most important methods to solve it. The existing graph-based autoencoder models only learn a single set of distributions, which cannot accurately represent the mixed distribution in real graph data. Meanwhile, existing learning models have been greatly restricted when the graph data has insufficient attribute information and inaccurate topology information. In this paper, we propose a novel graph embedding framework, termed multi-scale variational graph autoencoder (MSVGAE), which learns multiple sets of low-dimensional vectors of different dimensions through the graph encoder to represent the mixed probability distribution of the original graph data, and performs multiple sampling in each dimension. Furthermore, a self-supervised learning strategy (i.e., graph feature reconstruction auxiliary learning) is introduced to fully use the graph attribute information to help the graph structure learning. Experiment studies on real-world graphs demonstrate that the proposed model achieves state-of-the-art performance compared with other baseline methods in link prediction tasks. Besides, the robustness analysis shows that the proposed MSVGAE method has obvious advantages in the processes of graph data with insufficient attribute information and inaccurate topology information."}}
{"id": "Z4cUg9hkbb", "cdate": 1640995200000, "mdate": 1681652129721, "content": {"title": "Multi-Scale Variational Graph AutoEncoder for Link Prediction", "abstract": ""}}
{"id": "IpfkH5Vgopq", "cdate": 1640995200000, "mdate": 1681652129494, "content": {"title": "Multi-view graph convolutional networks with attention mechanism", "abstract": ""}}
{"id": "eNCUAoWFR8C", "cdate": 1609459200000, "mdate": 1648686961415, "content": {"title": "Deep neural network compression through interpretability-based filter pruning", "abstract": "Highlights \u2022 Filters are visualized by the activation maximization to explain functions of filters. \u2022 DNNs are compressed based on the visualization results. \u2022 The redundant filters are measured based on the color and texture similarities. \u2022 The repetitive and invalid filters can be pruned by optimization. Abstract This paper proposes a method to compress deep neural networks (DNNs) based on interpretability. For a trained DNN model, the activation maximization technique is first used to visualize every filter of the DNN model. Then, a single-layer filter pruning approach is introduced from what is learned by visualization. The entire DNN model is compressed layer by layer by using the single-layer filter pruning method in which the compression of the current layer is based on the compression of the preceding layers. Importantly, in addition to effective compression, the proposed method renders a better interpretation of the deep learning process. With a 60 % compression rate of the VGG-16, our method achieves 0.8429 Top-1 accuracy under CIFAR-10, with a slight accuracy drop of only 0.0322, and the storage space of the model can be compressed to 9.42 Mb. For a modern DNN model such as ResNet50, our visualization-based filter pruning method is significantly better than other pruning strategies in different convolutional layers under different compression rates and the larger ImageNet dataset. After pruning, the computation cost and storage requirement of the DNN can be significantly reduced, which means that complex DNN models can be easily implemented in small mobile devices, thus enabling the efficient use of DNNs in the Internet of Things technologies."}}
{"id": "JvC2FmlZgxK", "cdate": 1609459200000, "mdate": 1681652129720, "content": {"title": "Deep neural network compression through interpretability-based filter pruning", "abstract": ""}}
{"id": "CcI0icrBpqx", "cdate": 1577836800000, "mdate": 1648686961418, "content": {"title": "Deconvolutional neural network for image super-resolution", "abstract": "This study builds a fully deconvolutional neural network (FDNN) and addresses the problem of single image super-resolution (SISR) by using the FDNN. Although SISR using deep neural networks has been a major research focus, the problem of reconstructing a high resolution (HR) image with an FDNN has received little attention. A few recent approaches toward SISR are to embed deconvolution operations into multilayer feedforward neural networks. This paper constructs a deep FDNN for SISR that possesses two remarkable advantages compared to existing SISR approaches. The first improves the network performance without increasing the depth of the network or embedding complex structures. The second replaces all convolution operations with deconvolution operations to implement an effective reconstruction. That is, the proposed FDNN only contains deconvolution layers and learns an end-to-end mapping from low resolution (LR) to HR images. Furthermore, to avoid the oversmoothness of the mean squared error loss, the trained image is treated as a probability distribution, and the Kullback\u2013Leibler divergence is introduced into the final loss function to achieve enhanced recovery. Although the proposed FDNN only has 10 layers, it is successfully evaluated through extensive experiments. Compared with other state-of-the-art methods and deep convolution neural networks with 20 or 30 layers, the proposed FDNN achieves better performance for SISR."}}
