{"id": "Z1iuYTd68R9", "cdate": 1704067200000, "mdate": 1707891503574, "content": {"title": "A Survey on Hypergraph Mining: Patterns, Tools, and Generators", "abstract": "Hypergraphs are a natural and powerful choice for modeling group interactions in the real world, which are often referred to as higher-order networks. For example, when modeling collaboration networks, where collaborations can involve not just two but three or more people, employing hypergraphs allows us to explore beyond pairwise (dyadic) patterns and capture groupwise (polyadic) patterns. The mathematical complexity of hypergraphs offers both opportunities and challenges for learning and mining on hypergraphs, and hypergraph mining, which seeks to enhance our understanding of underlying systems through hypergraph modeling, gained increasing attention in research. Researchers have discovered various structural patterns in real-world hypergraphs, leading to the development of mining tools. Moreover, they have designed generators with the aim of reproducing and thereby shedding light on these patterns. In this survey, we provide a comprehensive overview of the current landscape of hypergraph mining, covering patterns, tools, and generators. We provide comprehensive taxonomies for them, and we also provide in-depth discussions to provide insights into future research on hypergraph mining."}}
{"id": "y-ydCJVbif", "cdate": 1698796800000, "mdate": 1698993343438, "content": {"title": "Reciprocity in directed hypergraphs: measures, findings, and generators", "abstract": "Group interactions are prevalent in a variety of areas. Many of them, including email exchanges, chemical reactions, and bitcoin transactions, are directional, and thus they are naturally modeled as directed hypergraphs, where each hyperarc consists of the set of source nodes and the set of destination nodes. For directed graphs, which are a special case of directed hypergraphs, reciprocity has played a key role as a fundamental graph statistic in revealing organizing principles of graphs and in solving graph learning tasks. For general directed hypergraphs, however, even no systematic measure of reciprocity has been developed. In this work, we investigate the reciprocity of 11 real-world hypergraphs. To this end, we first introduce eight axioms that any reasonable measure of reciprocity should satisfy. Second, we propose HyperRec, a family of principled measures of hypergraph reciprocity that satisfy all the axioms. Third, we develop FastHyperRec, a fast and exact algorithm for computing the measures. Fourth, using them, we examine 11 real-world hypergraphs and discover patterns that distinguish them from random hypergraphs. Lastly, we propose ReDi, an intuitive generative model for directed hypergraphs exhibiting the patterns."}}
{"id": "qEMm_c65f7", "cdate": 1698796800000, "mdate": 1707783384590, "content": {"title": "Interplay between topology and edge weights in real-world graphs: concepts, patterns, and an algorithm", "abstract": "What are the relations between the edge weights and the topology in real-world graphs? Given only the topology of a graph, how can we assign realistic weights to its edges based on the relations? Several trials have been done for edge-weight prediction where some unknown edge weights are predicted with most edge weights known. There are also existing works on generating both topology and edge weights of weighted graphs. Differently, we are interested in generating edge weights that are realistic in a macroscopic scope, merely from the topology, which is unexplored and challenging. To this end, we explore and exploit the patterns involving edge weights and topology in real-world graphs. Specifically, we divide each graph into layers where each layer consists of the edges with weights at least a threshold. We observe consistent and surprising patterns appearing in multiple layers: the similarity between being adjacent and having high weights, and the nearly-linear growth of the fraction of edges having high weights with the number of common neighbors. We also observe a power-law pattern that connects the layers. Based on the observations, we propose PEAR, an algorithm assigning realistic edge weights to a given topology. The algorithm relies on only two parameters, preserves all the observed patterns, and produces more realistic weights than the baseline methods with more parameters."}}
{"id": "m_dl1kOHKk", "cdate": 1698796800000, "mdate": 1699242341197, "content": {"title": "Datasets, tasks, and training methods for large-scale hypergraph learning", "abstract": "Relations among multiple entities are prevalent in many fields, and hypergraphs are widely used to represent such group relations. Hence, machine learning on hypergraphs has received considerable attention, and especially much effort has been made in neural network architectures for hypergraphs (a.k.a., hypergraph neural networks). However, existing studies mostly focused on small datasets for a few single-entity-level downstream tasks and overlooked scalability issues, although most real-world group relations are large-scale. In this work, we propose new tasks, datasets, and scalable training methods for addressing these limitations. First, we introduce two pair-level hypergraph-learning tasks to formulate a wide range of real-world problems. Then, we build and publicly release two large-scale hypergraph datasets with tens of millions of nodes, rich features, and labels. After that, we propose PCL, a scalable learning method for hypergraph neural networks. To tackle scalability issues, PCL splits a given hypergraph into partitions and trains a neural network via contrastive learning. Our extensive experiments demonstrate that hypergraph neural networks can be trained for large-scale hypergraphs by PCL while outperforming 16 baseline models. Specifically, the performance is comparable, or surprisingly even better than that achieved by training hypergraph neural networks on the entire hypergraphs without partitioning."}}
{"id": "6toM23K5kVc", "cdate": 1698796800000, "mdate": 1707783384554, "content": {"title": "Hypercore decomposition for non-fragile hyperedges: concepts, algorithms, observations, and applications", "abstract": ""}}
{"id": "3vlKe61fbb", "cdate": 1698796800000, "mdate": 1707891503590, "content": {"title": "Improving the core resilience of real-world hypergraphs", "abstract": "Interactions that involve a group of people or objects are omnipresent in practice. Some examples include the list of recipients of an email, the group of co-authors of a publication, and the users participating in online discussion threads. These interactions are modeled as hypergraphs in which each hyperedge is a set of nodes constituting an interaction. In a hypergraph, the k-core is the sub-hypergraph within which the degree of each node is at least k. Investigating the k-core structures is valuable in revealing some properties of the hypergraph, one of which is the network behavior when facing attacks. Networks in practice are often prone to attacks by which the attacker removes a portion of the nodes or hyperedges to weaken some properties of the networks. The resilience of the k-cores is an indicator of the robustness of the network against such attacks. In this work, we investigate the core resilience of real-world hypergraphs against deletion attacks. How robust are the core structures of real-world hypergraphs in these attack scenarios? Given the complexity of a real-world hypergraph, how should we supplement the hypergraph with augmented hyperedges to enhance its core resilience? In light of several empirical observations regarding core resilience, we present a two-step method that preserves and strengthens the core structures of the hypergraphs."}}
{"id": "m426fVFUY4a", "cdate": 1685577600000, "mdate": 1707891503579, "content": {"title": "Two-Stage Training of Graph Neural Networks for Graph Classification", "abstract": "Graph neural networks (GNNs) have received massive attention in the field of machine learning on graphs. Inspired by the success of neural networks, a line of research has been conducted to train GNNs to deal with various tasks, such as node classification, graph classification, and link prediction. In this work, our task of interest is graph classification. Several GNN models have been proposed and shown great accuracy in this task. However, the question is whether usual training methods fully realize the capacity of the GNN models. In this work, we propose a two-stage training framework based on triplet loss. In the first stage, GNN is trained to map each graph to a Euclidean-space vector so that graphs of the same class are close while those of different classes are mapped far apart. Once graphs are well-separated based on labels, a classifier is trained to distinguish between different classes. This method is generic in the sense that it is compatible with any GNN model. By adapting five GNN models to our method, we demonstrate the consistent improvement in accuracy and utilization of each GNN\u2019s allocated capacity over the original training method of each model up to $$5.4\\%$$ 5.4 % points in 12 datasets."}}
{"id": "wkBCt07yiM", "cdate": 1684043740847, "mdate": 1684043740847, "content": {"title": "Robust and Efficient Alignment of Calcium Imaging Data through Simultaneous Low Rank and Sparse Decomposition", "abstract": "Accurate alignment of calcium imaging data, which is critical for the extraction of neuronal activity signals, is often hindered by the image noise and the neuronal activity itself. To address the problem, we propose an algorithm named REALS for robust and efficient batch image alignment through simultaneous transformation and low rank and sparse decomposition. REALS is constructed upon our finding that the low rank subspace can be recovered via linear projection, which allows us to perform simultaneous image alignment and decomposition with gradient-based updates.REALS achieves orders-of-magnitude improvement in terms of accuracy and speed compared to the state-of-the-art robust image alignment algorithms. "}}
{"id": "BJUc7bAXe_Y", "cdate": 1680307200000, "mdate": 1683893633551, "content": {"title": "Temporal hypergraph motifs", "abstract": "Group interactions arise in our daily lives (email communications, on-demand ride sharing, and comment interactions on online communities, to name a few), and they together form hypergraphs that evolve over time. Given such temporal hypergraphs, how can we describe their underlying design principles? If their sizes and time spans are considerably different, how can we compare their structural and temporal characteristics? In this work, we define 96 temporal hypergraph motifs (TH-motifs) and propose the relative occurrences of their instances as an answer to the above questions. TH-motifs categorize the relational and temporal dynamics among three connected hyperedges that appear within a short time. For scalable analysis, we develop THyMe $$^{+}$$ + , a fast and exact algorithm for counting the instances of TH-motifs in massive hypergraphs, and we show that THyMe $$^{+}$$ + is up to 2,163 $$\\times $$ \u00d7 faster while requiring less space than baseline approaches. In addition to exact counting algorithms, we design three versions of sampling algorithms for approximate counting. We theoretically analyze the accuracy of the proposed methods, and we empirically show that the most advanced algorithm, , is up to $$11.1\\times $$ 11.1 \u00d7 more accurate than baseline approaches. Using the algorithms, we investigate 11 real-world temporal hypergraphs from various domains. We demonstrate that TH-motifs provide important information useful for downstream tasks and reveal interesting patterns, including the striking similarity between temporal hypergraphs from the same domain."}}
{"id": "zfxjRespX8U", "cdate": 1672531200000, "mdate": 1707891503988, "content": {"title": "Robust Graph Clustering via Meta Weighting for Noisy Graphs", "abstract": "How can we find meaningful clusters in a graph robustly against noise edges? Graph clustering (i.e., dividing nodes into groups of similar ones) is a fundamental problem in graph analysis with applications in various fields. Recent studies have demonstrated that graph neural network (GNN) based approaches yield promising results for graph clustering. However, we observe that their performance degenerates significantly on graphs with noise edges, which are prevalent in practice. In this work, we propose MetaGC for robust GNN-based graph clustering. MetaGC employs a decomposable clustering loss function, which can be rephrased as a sum of losses over node pairs. We add a learnable weight to each node pair, and MetaGC adaptively adjusts the weights of node pairs using meta-weighting so that the weights of meaningful node pairs increase and the weights of less-meaningful ones (e.g., noise edges) decrease. We show empirically that MetaGC learns weights as intended and consequently outperforms the state-of-the-art GNN-based competitors, even when they are equipped with separate denoising schemes, on five real-world graphs under varying levels of noise. Our code and datasets are available at https://github.com/HyeonsooJo/MetaGC."}}
