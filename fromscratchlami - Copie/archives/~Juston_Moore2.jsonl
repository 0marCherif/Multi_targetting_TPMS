{"id": "ukocFhBHNrB", "cdate": 1674501429140, "mdate": 1674501429140, "content": {"title": "Deepfaking it: experiments in generative, adversarial multispectral remote sensing", "abstract": "In this work we utilize generative adversarial networks (GANs) to synthesize realistic transformations for remote sensing imagery in the multispectral domain. Despite the apparent perceptual realism of the transformed images at a first glance, we show that a deep learning classifier can very easily be trained to differentiate between real and GAN-generated images, likely due to subtle but pervasive artifacts introduced by the GAN during the synthesis process. We also show that a very low-amplitude adversarial attack can easily fool the aforementioned deep learning classifier, although these types of attacks can be partially mitigated via adversarial training. Finally, we explore the features utilized by the classifier to differentiate real images from GAN-generated ones, and how adversarial training causes the classifier to focus on different, lower-frequency features."}}
{"id": "3nQtMhLCBWd", "cdate": 1674501273999, "mdate": 1674501273999, "content": {"title": "General-Purpose Unsupervised Cyber Anomaly Detection via Non-Negative Tensor Factorization", "abstract": "Distinguishing malicious anomalous activities from unusual but benign activities is a fundamental challenge for cyber\ndefenders. Prior studies have shown that statistical user behavior analysis yields accurate detections by learning behavior\nproiles from observed user activity. These unsupervised models are able to generalize to unseen types of attacks by detecting\ndeviations from normal behavior, without knowledge of speciic attack signatures. However, approaches proposed to date\nbased on probabilistic matrix factorization are limited by the information conveyed in a two-dimensional space. Non-negative\ntensor factorization, on the other hand, is a powerful unsupervised machine learning method that naturally models multi-\ndimensional data, capturing complex and multi-faceted details of behavior proiles. Our new unsupervised statistical anomaly\ndetection methodology matches or surpasses state-of-the-art supervised learning baselines across several challenging and\ndiverse cyber application areas, including detection of compromised user credentials, botnets, spam e-mails, and fraudulent\ncredit card transactions."}}
{"id": "f9owlVR29s", "cdate": 1672531200000, "mdate": 1682317531071, "content": {"title": "Laplacian Segmentation Networks: Improved Epistemic Uncertainty from Spatial Aleatoric Uncertainty", "abstract": "Out of distribution (OOD) medical images are frequently encountered, e.g. because of site- or scanner differences, or image corruption. OOD images come with a risk of incorrect image segmentation, potentially negatively affecting downstream diagnoses or treatment. To ensure robustness to such incorrect segmentations, we propose Laplacian Segmentation Networks (LSN) that jointly model epistemic (model) and aleatoric (data) uncertainty in image segmentation. We capture data uncertainty with a spatially correlated logit distribution. For model uncertainty, we propose the first Laplace approximation of the weight posterior that scales to large neural networks with skip connections that have high-dimensional outputs. Empirically, we demonstrate that modelling spatial pixel correlation allows the Laplacian Segmentation Network to successfully assign high epistemic uncertainty to out-of-distribution objects appearing within images."}}
{"id": "nZRTRevUO-", "cdate": 1652737540394, "mdate": null, "content": {"title": "Local Latent Space Bayesian Optimization over Structured Inputs", "abstract": "Bayesian optimization over the latent spaces of deep autoencoder models (DAEs) has recently emerged as a promising new approach for optimizing challenging black-box functions over structured, discrete, hard-to-enumerate search spaces (e.g., molecules). Here the DAE dramatically simplifies the search space by mapping inputs into a continuous latent space where familiar Bayesian optimization tools can be more readily applied. Despite this simplification, the latent space typically remains high-dimensional. Thus, even with a well-suited latent space, these approaches do not necessarily provide a complete solution, but may rather shift the structured optimization problem to a high-dimensional one. In this paper, we propose LOL-BO, which adapts the notion of trust regions explored in recent work on high-dimensional Bayesian optimization to the structured setting. By reformulating the encoder to function as both an encoder for the DAE globally and as a deep kernel for the surrogate model within a trust region, we better align the notion of local optimization in the latent space with local optimization in the input space. LOL-BO achieves as much as 20 times improvement over state-of-the-art latent space Bayesian optimization methods across six real-world benchmarks, demonstrating that improvement in optimization strategies is as important as developing better DAE models."}}
{"id": "BGfLS_8j5eq", "cdate": 1646077549342, "mdate": null, "content": {"title": "If You've Trained One You\u2019ve Trained Them All: Inter-Architecture Similarity Increases With Robustness", "abstract": "Previous work has shown that commonly-used metrics for comparing representations between neural networks overestimate similarity due to correlations between data points. We show that intra-example feature correlations also causes significant overestimation of network similarity and propose an image inversion technique to analyze only the features used by a network. With this technique, we find that similarity across architectures is significantly lower than commonly understood, but we surprisingly find that similarity between models with different architectures increases as the adversarial robustness of the models increase. Our findings indicate that robust networks tend towards a universal set of representations, regardless of architecture, and that the robust training criterion is a strong prior constraint on the functions that can be learned by diverse modern architectures. We also find that the representations learned by a robust network of any architecture have an asymmetric overlap with non-robust networks of many architectures, indicating that the representations used by robust neural networks are highly entangled with the representations used by non-robust networks."}}
{"id": "oepuoi68Bsd", "cdate": 1640995200000, "mdate": 1674500523172, "content": {"title": "If you've trained one you've trained them all: inter-architecture similarity increases with robustness", "abstract": "Previous work has shown that commonly-used metrics for comparing representations between neural networks overestimate similarity due to correlations between data points. We show that intra-example ..."}}
{"id": "X4DAinxUqt", "cdate": 1640995200000, "mdate": 1674500327107, "content": {"title": "LCANets: Lateral Competition Improves Robustness Against Corruption and Attack", "abstract": "Although Convolutional Neural Networks (CNNs) achieve high accuracy on image recognition tasks, they lack robustness against realistic corruptions and fail catastrophically when deliberately attack..."}}
{"id": "HgWDVkHSeq", "cdate": 1640995200000, "mdate": 1645723438771, "content": {"title": "Local Latent Space Bayesian Optimization over Structured Inputs", "abstract": "Bayesian optimization over the latent spaces of deep autoencoder models (DAEs) has recently emerged as a promising new approach for optimizing challenging black-box functions over structured, discrete, hard-to-enumerate search spaces (e.g., molecules). Here the DAE dramatically simplifies the search space by mapping inputs into a continuous latent space where familiar Bayesian optimization tools can be more readily applied. Despite this simplification, the latent space typically remains high-dimensional. Thus, even with a well-suited latent space, these approaches do not necessarily provide a complete solution, but may rather shift the structured optimization problem to a high-dimensional one. In this paper, we propose LOL-BO, which adapts the notion of trust regions explored in recent work on high-dimensional Bayesian optimization to the structured setting. By reformulating the encoder to function as both an encoder for the DAE globally and as a deep kernel for the surrogate model within a trust region, we better align the notion of local optimization in the latent space with local optimization in the input space. LOL-BO achieves as much as 20 times improvement over state-of-the-art latent space Bayesian optimization methods across six real-world benchmarks, demonstrating that improvement in optimization strategies is as important as developing better DAE models."}}
{"id": "Ws7NeFj3s9i", "cdate": 1603119170531, "mdate": null, "content": {"title": "Is the Discrete VAE\u2019s Power Stuck in its Prior?", "abstract": "We investigate why probabilistic neural models with discrete latent variables are effective at generating high-quality images. We hypothesize that fitting a more flexible variational posterior distribution and performing joint training of the encoder, decoder, and prior distribution should improve model fit. However, we find that modifying the training procedure for the well-known vector quantized variational autoencoder (VQ-VAE) leads to models with lower marginal likelihood for held-out data and degraded sample quality. These results indicate that current discrete VAEs use their encoder and decoder as a deterministic compression bottleneck. The distribution-matching power of these models lies solely in the prior distribution, which is typically trained after clamping the encoder and decoder."}}
{"id": "e_Iucd89I3", "cdate": 1577836800000, "mdate": 1674500523116, "content": {"title": "Multi-Dimensional Anomalous Entity Detection via Poisson Tensor Factorization", "abstract": "As the attack surfaces of large enterprise networks grow, anomaly detection systems based on statistical user behavior analysis play a crucial role in identifying malicious activities. Previous work has shown that link prediction algorithms based on non-negative matrix factorization learn highly accurate predictive models of user actions. However, most statistical link prediction models have been constructed on bipartite graphs, and fail to capture the nuanced, multi-faceted details of a user's activity profile. This paper establishes a new benchmark for red team event detection on the Los Alamos National Laboratory Unified Host and Network Dataset by applying a tensor factorization model that exploits the multi-dimensional and sparse structure of user authentication logs. We show that learning patterns of normal activity across multiple dimensions in one unified statistical framework yields improved detection of penetration testing events. We further show operational value by developing fusion methods that can identify anomalous users, source devices, and destination devices in the network."}}
