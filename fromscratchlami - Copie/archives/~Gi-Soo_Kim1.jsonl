{"id": "5KJiMUX1BSL", "cdate": 1676827112112, "mdate": null, "content": {"title": "Heavy-tailed Linear Bandit with Huber Regression", "abstract": "Linear bandit algorithms have been extensively studied and have shown successful in sequential decision tasks despite their simplicity. Many algorithms however work under the assumption that the reward is the sum of linear function of observed contexts and a sub-Gaussian error. In practical applications, errors can be heavy-tailed, especially in financial data. In such reward environments, algorithms designed for sub-Gaussian error may underexplore, resulting in suboptimal regret. In this paper, we relax the reward assumption and propose a novel linear bandit algorithm which works well under heavy-tailed errors as well. The proposed algorithm utilizes Huber regression. When contexts are stochastic with positive definite covariance matrix and the $(1+\\delta)$-th moment of the error is bounded by a constant, we show that the high-probability upper bound of the regret is $O(\\sqrt{d}T^{\\frac{1}{1+\\delta}}(\\log dT)^{\\frac{\\delta}{1+\\delta}})$, where $d$ is the dimension of context variables, $T$ is the time horizon, and $\\delta\\in (0,1]$. This bound improves on the state-of-the-art regret bound of the Median of Means and Truncation algorithm by a factor of $\\sqrt{\\log T}$ and $\\sqrt{d}$ for the case where the time horizon $T$ is unknown. We also remark that when $\\delta=1$, the order is the same as the regret bound of linear bandit algorithms designed for sub-Gaussian errors. We support our theoretical findings with synthetic experiments."}}
{"id": "WBVbl8POq8v", "cdate": 1621629963718, "mdate": null, "content": {"title": "Doubly Robust Thompson Sampling with Linear Payoffs", "abstract": "A challenging aspect of the bandit problem is that a stochastic reward is observed only for the chosen arm and the rewards of other arms remain missing.    \nThe dependence of the arm choice on the past context and reward pairs compounds the complexity of regret analysis.\nWe propose a novel multi-armed contextual bandit algorithm called Doubly Robust Thompson Sampling (DRTS) employing the doubly-robust estimator used in missing data literature to Thompson Sampling with contexts (\\texttt{LinTS}).\nDifferent from previous works relying on missing data techniques (Dimakopoulou et al. [2019], Kim and Paik [2019]), the proposed algorithm is designed to allow a novel additive regret decomposition leading to an improved regret bound with the order of $\\tilde{O}(\\phi^{-2}\\sqrt{T})$, where $\\phi^2$ is the minimum eigenvalue of the covariance matrix of contexts.\nThis is the first regret bound of \\texttt{LinTS} using $\\phi^2$ without $d$,  where $d$ is the dimension of the context.\nApplying the relationship between $\\phi^2$ and $d$, the regret bound of the proposed algorithm is $\\tilde{O}(d\\sqrt{T})$ in many practical scenarios, improving the bound of \\texttt{LinTS} by a factor of $\\sqrt{d}$.\nA benefit of the proposed method is that it uses all the context data, chosen or not chosen, thus allowing to circumvent the technical definition of unsaturated arms used in theoretical analysis of \\texttt{LinTS}.\nEmpirical studies show the advantage of the proposed algorithm over \\texttt{LinTS}."}}
{"id": "POJdCvdCR0Y", "cdate": 1546300800000, "mdate": null, "content": {"title": "Doubly-Robust Lasso Bandit", "abstract": "Contextual multi-armed bandit algorithms are widely used in sequential decision tasks such as news article recommendation systems, web page ad placement algorithms, and mobile health. Most of the existing algorithms have regret proportional to a polynomial function of the context dimension, $d$. In many applications however, it is often the case that contexts are high-dimensional with only a sparse subset of size $s_0 (\\ll d)$ being correlated with the reward. We consider the stochastic linear contextual bandit problem and propose a novel algorithm, namely the Doubly-Robust Lasso Bandit algorithm, which exploits the sparse structure of the regression parameter as in Lasso, while blending the doubly-robust technique used in missing data literature. The high-probability upper bound of the regret incurred by the proposed algorithm does not depend on the number of arms and scales with $\\mathrm{log}(d)$ instead of a polynomial function of $d$. The proposed algorithm shows good performance when contexts of different arms are correlated and requires less tuning parameters than existing methods."}}
{"id": "Bk-rOn-dZB", "cdate": 1546300800000, "mdate": null, "content": {"title": "Contextual Multi-armed Bandit Algorithm for Semiparametric Reward Model", "abstract": "Contextual multi-armed bandit (MAB) algorithms have been shown promising for maximizing cumulative rewards in sequential decision tasks such as news article recommendation systems, web page ad plac..."}}
{"id": "22uEa534Kq7v", "cdate": 1546300800000, "mdate": null, "content": {"title": "Doubly-Robust Lasso Bandit", "abstract": "Contextual multi-armed bandit algorithms are widely used in sequential decision tasks such as news article recommendation systems, web page ad placement algorithms, and mobile health. Most of the existing algorithms have regret proportional to a polynomial function of the context dimension, $d$. In many applications however, it is often the case that contexts are high-dimensional with only a sparse subset of size $s_0 (\\ll d)$ being correlated with the reward. We consider the stochastic linear contextual bandit problem and propose a novel algorithm, namely the Doubly-Robust Lasso Bandit algorithm, which exploits the sparse structure of the regression parameter as in Lasso, while blending the doubly-robust technique used in missing data literature. The high-probability upper bound of the regret incurred by the proposed algorithm does not depend on the number of arms and scales with $\\mathrm{log}(d)$ instead of a polynomial function of $d$. The proposed algorithm shows good performance when contexts of different arms are correlated and requires less tuning parameters than existing methods."}}
{"id": "oCPfLztig7D", "cdate": 1483228800000, "mdate": null, "content": {"title": "Causal inference with observational data under cluster-specific non-ignorable assignment mechanism", "abstract": "An estimator of the population average causal treatment effect is proposed for multi-level clustered data from observational studies when the treatment assignment mechanism is cluster-specific non-ignorable. This is motivated from a health policy study to evaluate the cost associated with rehospitalization due to premature discharge. The proposed estimator utilizes cluster-level calibration condition and is shown to be consistent and asymptotically normal. The proposed method is evaluated along with existing methods through simulations and is applied to the health care cost study using California inpatient dataset."}}
