{"id": "aeeHjpao_dF", "cdate": 1640995200000, "mdate": 1665087167102, "content": {"title": "Color Overmodification Emerges from Data-Driven Learning and Pragmatic Reasoning", "abstract": "Speakers' referential expressions often depart from communicative ideals in ways that help illuminate the nature of pragmatic language use. Patterns of overmodification, in which a speaker uses a modifier that is redundant given their communicative goal, have proven especially informative in this regard. It seems likely that these patterns are shaped by the environment a speaker is exposed to in complex ways. Unfortunately, systematically manipulating these factors during human language acquisition is impossible. In this paper, we propose to address this limitation by adopting neural networks (NN) as learning agents. By systematically varying the environments in which these agents are trained, while keeping the NN architecture constant, we show that overmodification is more likely with environmental features that are infrequent or salient. We show that these findings emerge naturally in the context of a probabilistic model of pragmatic communication."}}
{"id": "NqATsqYysj", "cdate": 1640995200000, "mdate": 1665087167102, "content": {"title": "Context Matters for Image Descriptions for Accessibility: Challenges for Referenceless Evaluation Metrics", "abstract": "Few images on the Web receive alt-text descriptions that would make them accessible to blind and low vision (BLV) users. Image-based NLG systems have progressed to the point where they can begin to address this persistent societal problem, but these systems will not be fully successful unless we evaluate them on metrics that guide their development correctly. Here, we argue against current referenceless metrics -- those that don't rely on human-generated ground-truth descriptions -- on the grounds that they do not align with the needs of BLV users. The fundamental shortcoming of these metrics is that they cannot take context into account, whereas contextual information is highly valued by BLV users. To substantiate these claims, we present a study with BLV participants who rated descriptions along a variety of dimensions. An in-depth analysis reveals that the lack of context-awareness makes current referenceless metrics inadequate for advancing image accessibility, requiring a rethinking of referenceless evaluation metrics for image-based NLG systems."}}
{"id": "Rtquf4Jk0jN", "cdate": 1622965078874, "mdate": null, "content": {"title": "ReaSCAN: Compositional Reasoning in Language Grounding", "abstract": "The ability to compositionally map language to referents, relations, and actions is an essential component of language understanding. The recent gSCAN dataset (Ruis et al. 2020, NeurIPS) is an inspiring attempt to assess the capacity of models to learn this kind of grounding in scenarios involving navigational instructions. However, we show that gSCAN's highly constrained design means that it does not require compositional interpretation and that many details of its instructions and scenarios are not required for task success. To address these limitations, we propose ReaSCAN, a benchmark dataset that builds off gSCAN but requires compositional language interpretation and reasoning about entities and relations. We assess two models on ReaSCAN: a multi-modal baseline and a state-of-the-art graph convolutional neural model. These experiments show that ReaSCAN is substantially harder than gSCAN for both neural architectures. This suggests that ReaSCAN can serve as a valuable benchmark for advancing our understanding of models' compositional generalization and reasoning capabilities."}}
{"id": "a1lvE6hD7aw", "cdate": 1609459200000, "mdate": 1665087167102, "content": {"title": "ReaSCAN: Compositional Reasoning in Language Grounding", "abstract": "The ability to compositionally map language to referents, relations, and actions is an essential component of language understanding. The recent gSCAN dataset (Ruis et al. 2020, NeurIPS) is an inspiring attempt to assess the capacity of models to learn this kind of grounding in scenarios involving navigational instructions. However, we show that gSCAN's highly constrained design means that it does not require compositional interpretation and that many details of its instructions and scenarios are not required for task success. To address these limitations, we propose ReaSCAN, a benchmark dataset that builds off gSCAN but requires compositional language interpretation and reasoning about entities and relations. We assess two models on ReaSCAN: a multi-modal baseline and a state-of-the-art graph convolutional neural model. These experiments show that ReaSCAN is substantially harder than gSCAN for both neural architectures. This suggests that ReaSCAN can serve as a valuable benchmark for advancing our understanding of models' compositional generalization and reasoning capabilities."}}
{"id": "EVLrm9Y18vc", "cdate": 1609459200000, "mdate": 1640171440264, "content": {"title": "Concadia: Tackling image accessibility with context", "abstract": "Images have become an integral part of online media. This has enhanced the dissemination of knowledge, but it poses serious accessibility challenges. The HTML \"alt\" field is hidden by default and designated for supplying a description that could replace the image, but it is rarely used. By contrast, image captions appear alongside the image and are more abundant, but they are written to supply additional information and generally lack the details required for accessibility. These terms are often treated as synonyms, but we argue that a distinction is essential. To address this, we introduce the publicly available Wikipedia-based corpus Concadia, which consists of 96,918 images with corresponding English-language descriptions, captions, and surrounding context. We use Concadia to characterize the commonalities and differences between descriptions and captions. This leads us to the hypothesis that captions, while not substitutes for descriptions, can provide a useful signal for creating effective descriptions. We substantiate this hypothesis by showing that image description systems trained on Concadia benefit from having caption embeddings as part of their inputs. Finally, we provide evidence from a human-subjects experiment that human-created captions and descriptions have distinct communicative purposes, and that our generated texts follow this same pattern. These experiments begin to show how Concadia can be a powerful tool in addressing the underlying accessibility issues posed by image data."}}
{"id": "3ZNQAjXOham", "cdate": 1599285818324, "mdate": null, "content": {"title": "Modeling Subjective Assessments of Guilt in Newspaper Crime Narratives", "abstract": "Crime reporting is a prevalent form of journalism with the power to shape public perceptions and social policies. How does the language of these reports act on readers? We seek to address this question with the SuspectGuilt Corpus of annotated crime stories from English language newspapers in the U.S. For SuspectGuilt, annotators read short crime articles and provided text-level ratings concerning the guilt of the main suspect as well as span-level annotations indicating which parts of the story they felt most influenced their ratings. SuspectGuilt thus provides a rich picture of how linguistic choices affect subjective guilt judgments. In addition, we use SuspectGuilt to train and assess predictive models, and show that these models benefit from genre pretraining and joint supervision from the text-level ratings and span-level annotations. Such models might be used as tools for understanding\nthe societal effects of crime reporting."}}
{"id": "nxbQKGX79k", "cdate": 1577836800000, "mdate": 1640171440261, "content": {"title": "Production expectations modulate contrastive inference", "abstract": "Contrastive inferences, whereby a listener pragmatically infers a speaker's referential intention of a partial referring expression like \"the yellow\" by reasoning about other objects in the context, are notoriously unstable. We report a production-centric model of interpretation couched within the Rational Speech Act framework. Adjective production probabilities a listener expects for objects in a context drive the size of contrastive inferences: the greater the asymmetry in expectation for a speaker to use a pre-nominal adjective for the target rather than for competitors, the greater the listener's resulting target preference. Modifier production probabilities were collected (Exp. 1) and used to make predictions about comprehension in an incremental decision task (Exp. 2). The model's interpretation predictions are supported by the data. This account has the potential to explain the fluctuating appearance of contrastive inferences and shifts the explanatory focus away from contrastive inference towards online interpretation of referring expressions more broadly."}}
{"id": "aYTyhecb75B", "cdate": 1546300800000, "mdate": 1637139298947, "content": {"title": "When redundancy is rational: A Bayesian approach to 'overinformative' referring expressions", "abstract": "Referring is one of the most basic and prevalent uses of language. How do speakers choose from the wealth of referring expressions at their disposal? Rational theories of language use have come under attack for decades for not being able to account for the seemingly irrational overinformativeness ubiquitous in referring expressions. Here we present a novel production model of referring expressions within the Rational Speech Act framework that treats speakers as agents that rationally trade off cost and informativeness of utterances. Crucially, we relax the assumption that informativeness is computed with respect to a deterministic Boolean semantics, in favor of a non-deterministic continuous semantics. This innovation allows us to capture a large number of seemingly disparate phenomena within one unified framework: the basic asymmetry in speakers' propensity to overmodify with color rather than size; the increase in overmodification in complex scenes; the increase in overmodification with atypical features; and the increase in specificity in nominal reference as a function of typicality. These findings cast a new light on the production of referring expressions: rather than being wastefully overinformative, reference is usefully redundant."}}
{"id": "HoxCke1Xq5d", "cdate": 1546300800000, "mdate": 1640171440280, "content": {"title": "Uncertain evidence statements and guilt perception in iterative reproductions of crime stories", "abstract": "Transmission of information by means of language is a potentially lossy process. Especially adjunct information, such as the graded degree of evidence, is a piece of information that seems prima facie likely to be distorted by reproduction noise. To investigate this issue, we present the results of a two-step iterated narration study: first, we collected a corpus of 250 crime story reproductions that were produced in parallel reproduction chains of 5 generations in depth, for 5 different seed stories; a second separate large-scale experiment then targeted readers' interpretation of these reproductions. Crucially, strength of evidence for the guilt of each story's suspect(s) was manipulated in the initial seed stories. Across generations, readers' guilt perceptions decreased when the evidence was originally strong, but remained stable when evidence was originally weak. Analysis of linguistic measures revealed that dissimilarity between a seed story and its reproduction, story length, and amount of hedging language affected the readers' own guilt perception and the readers' attribution of guilt perception to the author differently. The results provide evidence that evidential information indeed influences guilt perception in complex ways."}}
