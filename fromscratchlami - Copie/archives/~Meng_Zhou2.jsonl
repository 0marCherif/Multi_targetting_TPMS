{"id": "ugeVCsvUnN", "cdate": 1672531200000, "mdate": 1695949090598, "content": {"title": "Enhancing Cross-lingual Prompting with Dual Prompt Augmentation", "abstract": ""}}
{"id": "gSQiE_rtjk", "cdate": 1640995200000, "mdate": 1674007536448, "content": {"title": "From Clozing to Comprehending: Retrofitting Pre-trained Language Model to Pre-trained Machine Reader", "abstract": ""}}
{"id": "7kwcsCMXK6R", "cdate": 1640995200000, "mdate": 1668427906549, "content": {"title": "Towards Theoretical Analysis of Transformation Complexity of ReLU DNNs", "abstract": "This paper aims to theoretically analyze the complexity of feature transformations encoded in piecewise linear DNNs with ReLU layers. We propose metrics to measure three types of complexities of tr..."}}
{"id": "fMaIxda5Y6K", "cdate": 1621629779540, "mdate": null, "content": {"title": "Towards a Unified Game-Theoretic View of Adversarial Perturbations and Robustness", "abstract": "This paper provides a unified view to explain different adversarial attacks and defense methods, i.e. the view of multi-order interactions between input variables of DNNs. Based on the multi-order interaction, we discover that adversarial attacks mainly affect high-order interactions to fool the DNN. Furthermore, we find that the robustness of adversarially trained DNNs comes from category-specific low-order interactions. Our findings provide a potential method to unify adversarial perturbations and robustness, which can explain the existing robustness-boosting methods in a principle way. Besides, our findings also make a revision of previous inaccurate understanding of the shape bias of adversarially learned features. Our code is available online at https://github.com/Jie-Ren/A-Unified-Game-Theoretic-Interpretation-of-Adversarial-Robustness."}}
{"id": "yzjNLufwZfL", "cdate": 1609459200000, "mdate": 1636426690433, "content": {"title": "Self-supervised Regularization for Text Classification", "abstract": "Text classification is a widely studied problem and has broad applications. In many real-world problems, the number of texts for training classification models is limited, which renders these models prone to overfitting. To address this problem, we propose SSL-Reg, a data-dependent regularization approach based on self-supervised learning (SSL). SSL is an unsupervised learning approach which defines auxiliary tasks on input data without using any human-provided labels and learns data representations by solving these auxiliary tasks. In SSL-Reg, a supervised classification task and an unsupervised SSL task are performed simultaneously. The SSL task is unsupervised, which is defined purely on input texts without using any human-provided labels. Training a model using an SSL task can prevent the model from being overfitted to a limited number of class labels in the classification task. Experiments on 17 text classification datasets demonstrate the effectiveness of our proposed method."}}
{"id": "svgcHDYK4Wu", "cdate": 1609459200000, "mdate": 1636426690429, "content": {"title": "Self-supervised Regularization for Text Classification", "abstract": "Text classification is a widely studied problem and has broad applications. In many real-world problems, the number of texts for training classification models is limited, which renders these models prone to overfitting. To address this problem, we propose SSL-Reg, a data-dependent regularization approach based on self-supervised learning (SSL). SSL is an unsupervised learning approach which defines auxiliary tasks on input data without using any human-provided labels and learns data representations by solving these auxiliary tasks. In SSL-Reg,\u00a0 a supervised classification task and an unsupervised SSL task are performed simultaneously. The SSL task is unsupervised, which is defined purely on input texts without using any human-provided labels. Training\u00a0 a model using an SSL task can prevent the model from being overfitted to a limited number of class labels in the classification task. \u00a0Experiments on 17 text classification datasets demonstrate the effectiveness of our proposed method. Code is available at https://github.com/UCSD-AI4H/SSReg"}}
{"id": "ltQclSyq7_p", "cdate": 1609459200000, "mdate": 1636426690431, "content": {"title": "On the Generation of Medical Dialogs for COVID-19", "abstract": "Meng Zhou, Zechen Li, Bowen Tan, Guangtao Zeng, Wenmian Yang, Xuehai He, Zeqian Ju, Subrato Chakravorty, Shu Chen, Xingyi Yang, Yichen Zhang, Qingyang Wu, Zhou Yu, Kun Xu, Eric Xing, Pengtao Xie. Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers). 2021."}}
{"id": "IeXzzshsqys", "cdate": 1609459200000, "mdate": 1650848445818, "content": {"title": "A Unified Game-Theoretic Interpretation of Adversarial Robustness", "abstract": "This paper provides a unified view to explain different adversarial attacks and defense methods, \\emph{i.e.} the view of multi-order interactions between input variables of DNNs. Based on the multi-order interaction, we discover that adversarial attacks mainly affect high-order interactions to fool the DNN. Furthermore, we find that the robustness of adversarially trained DNNs comes from category-specific low-order interactions. Our findings provide a potential method to unify adversarial perturbations and robustness, which can explain the existing defense methods in a principle way. Besides, our findings also make a revision of previous inaccurate understanding of the shape bias of adversarially learned features."}}
{"id": "9LogXjJ3Yy6", "cdate": 1609459200000, "mdate": 1668760147823, "content": {"title": "Towards a Unified Game-Theoretic View of Adversarial Perturbations and Robustness", "abstract": "This paper provides a unified view to explain different adversarial attacks and defense methods, i.e. the view of multi-order interactions between input variables of DNNs. Based on the multi-order interaction, we discover that adversarial attacks mainly affect high-order interactions to fool the DNN. Furthermore, we find that the robustness of adversarially trained DNNs comes from category-specific low-order interactions. Our findings provide a potential method to unify adversarial perturbations and robustness, which can explain the existing robustness-boosting methods in a principle way. Besides, our findings also make a revision of previous inaccurate understanding of the shape bias of adversarially learned features. Our code is available online at https://github.com/Jie-Ren/A-Unified-Game-Theoretic-Interpretation-of-Adversarial-Robustness."}}
{"id": "l47UCAewjy", "cdate": 1601308172777, "mdate": null, "content": {"title": "Understanding, Analyzing, and Optimizing the Complexity of Deep Models", "abstract": "This paper aims to evaluate and analyze the complexity of feature transformations encoded in DNNs. We propose metrics to measure three types of complexity of transformations based on the information theory. We further discover and prove the negative correlation between the complexity and the disentanglement of transformations. Based on the proposed metrics, we analyze two typical phenomena of the change of the transformation complexity during the training process, and explore the ceiling of a DNN\u2019s complexity. The proposed metrics can also be used as a loss to learn a DNN with the minimum complexity, which also controls the significance of over-fitting of the DNN. Comprehensive comparative studies have provided new perspectives to understand the DNN. We will release the code when the paper is accepted."}}
