{"id": "1FPu3fvznaw", "cdate": 1673059300789, "mdate": 1673059300789, "content": {"title": "Complex Activity Recognition Via Attribute Dynamics", "abstract": "The problem of modeling the dynamic structure of human activities is considered. Video is mapped\nto a semantic feature space, which encodes activity attribute probabilities over time. The binary dynamic\nsystem (BDS) model is proposed to jointly learn the\ndistribution and dynamics of activities in this space.\nThis is a non-linear dynamic system that combines binary observation variables and a hidden Gauss-Markov\nstate process, extending both binary principal component analysis (PCA) and the classical linear dynamic\nsystems (LDS). A BDS learning algorithm, inspired by\nthe popular dynamic texture, and a dissimilarity measure between BDSs, which generalizes the Binet-Cauchy\nkernel, are introduced. To enable the recognition of\nhighly non-stationary activities, the BDS is embedded\nin a bag of words. An algorithm is introduced for learning a BDS codebook, enabling the use of the BDS as a\nvisual word for attribute dynamics (WAD). Short-term\nvideo segments are then quantized with a WAD codebook, allowing the representation of video as a bagof-words for attribute dynamics (BoWAD). Video sequences are finally encoded as vectors of locally aggregated descriptors (VLAD), which summarize the firstmoments of video snippets on the BDS manifold. Experiments show that this representation achieves stateof-the-art performance on the tasks of complex activity\nrecognition and event identification."}}
{"id": "E08kaoSiQl0", "cdate": 1663849811830, "mdate": null, "content": {"title": "Transcendental Idealism of Planner: Evaluating Perception from Planning Perspective for Autonomous Driving", "abstract": "Evaluating the performance of perception module in autonomous driving is one of the most critical tasks in developing these complex intelligent systems. While module-level unit test methodologies adopted from traditional computer vision tasks are viable to a certain extent, it still remains far less explored to evaluate how changes in a perception module can impact the planning of an autonomous vehicle in a consistent and holistic manner. In this work, we propose a principled framework that provides a coherent and systematic understanding of how perception modules affect the planning of an autonomous vehicle that actually controls the vehicle. Specifically, planning of an autonomous vehicle is formulated as an expected utility maximisation problem, where all input signals from upstream modules jointly provide a world state description, and the planner aims to find the optimal action to execute by finding the solution to maximise the expected utility determined by both the world state and the action. We show that, under some mild conditions, the objective function can be represented as an inner product between the world state description and the utility function in a Hilbert space. This geometric interpretation enables a novel way to formulate, analyse and evaluate the impact of noise in world state estimation on the solution to the problem, and leads to a universal quantitative metric for such purpose. The whole framework resembles the idea of transcendental idealism in the classical philosophy literature, which gives the name to our approach."}}
{"id": "B1xaZnn8wS", "cdate": 1569274885111, "mdate": null, "content": {"title": "Anomaly Detection and Localization in Crowded Scenes", "abstract": ""}}
{"id": "rJ-67eMd-S", "cdate": 1451606400000, "mdate": null, "content": {"title": "VLAD3: Encoding Dynamics of Deep Features for Action Recognition", "abstract": "Previous approaches to action recognition with deep features tend to process video frames only within a small temporal region, and do not model long-range dynamic information explicitly. However, such information is important for the accurate recognition of actions, especially for the discrimination of complex activities that share sub-actions, and when dealing with untrimmed videos. Here, we propose a representation, VLAD for Deep Dynamics (VLAD <sup xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">3</sup> ), that accounts for different levels of video dynamics. It captures short-term dynamics with deep convolutional neural network features, relying on linear dynamic systems (LDS) to model medium-range dynamics. To account for long-range inhomogeneous dynamics, a VLAD descriptor is derived for the LDS and pooled over the whole video, to arrive at the final VLAD <sup xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">3</sup> representation. An extensive evaluation was performed on Olympic Sports, UCF101 and THUMOS15, where the use of the VLAD <sup xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">3</sup> representation leads to state-of-the-art results."}}
{"id": "rk-nG6Z_bS", "cdate": 1420070400000, "mdate": null, "content": {"title": "Multiple instance learning for soft bags via top instances", "abstract": "A generalized formulation of the multiple instance learning problem is considered. Under this formulation, both positive and negative bags are soft, in the sense that negative bags can also contain positive instances. This reflects a problem setting commonly found in practical applications, where labeling noise appears on both positive and negative training samples. A novel bag-level representation is introduced, using instances that are most likely to be positive (denoted top instances), and its ability to separate soft bags, depending on their relative composition in terms of positive and negative instances, is studied. This study inspires a new large-margin algorithm for soft-bag classification, based on a latent support vector machine that efficiently explores the combinatorial space of bag compositions. Empirical evaluation on three datasets is shown to confirm the main findings of the theoretical analysis and the effectiveness of the proposed soft-bag classifier."}}
{"id": "rkNNpAWubH", "cdate": 1356998400000, "mdate": null, "content": {"title": "Recognizing Activities via Bag of Words for Attribute Dynamics", "abstract": "In this work, we propose a novel video representation for activity recognition that models video dynamics with attributes of activities. A video sequence is decomposed into short-term segments, which are characterized by the dynamics of their attributes. These segments are modeled by a dictionary of attribute dynamics templates, which are implemented by a recently introduced generative model, the binary dynamic system~(BDS). We propose methods for learning a dictionary of BDSs from a training corpus, and for quantizing attribute sequences extracted from videos into these BDS code words. This procedure produces a representation of the video as a histogram of BDS code words, which is denoted the bag-of-words for attribute dynamics (BoWAD). An extensive experimental evaluation reveals that this representation outperforms other state-of-the-art approaches in temporal structure modeling for complex activity recognition."}}
{"id": "BJEFolGuZS", "cdate": 1356998400000, "mdate": null, "content": {"title": "Dynamic Pooling for Complex Event Recognition", "abstract": "The problem of adaptively selecting pooling regions for the classification of complex video events is considered. Complex events are defined as events composed of several characteristic behaviors, whose temporal configuration can change from sequence to sequence. A dynamic pooling operator is defined so as to enable a unified solution to the problems of event specific video segmentation, temporal structure modeling, and event detection. Video is decomposed into segments, and the segments most informative for detecting a given event are identified, so as to dynamically determine the pooling operator most suited for each sequence. This dynamic pooling is implemented by treating the locations of characteristic segments as hidden information, which is inferred, on a sequence-by-sequence basis, via a large-margin classification rule with latent variables. Although the feasible set of segment selections is combinatorial, it is shown that a globally optimal solution to the inference problem can be obtained efficiently, through the solution of a series of linear programs. Besides the coarse-level location of segments, a finer model of video structure is implemented by jointly pooling features of segment-tuples. Experimental evaluation demonstrates that the resulting event detector has state-of-the-art performance on challenging video datasets."}}
{"id": "HyWinI-ubB", "cdate": 1325376000000, "mdate": null, "content": {"title": "Recognizing Activities by Attribute Dynamics", "abstract": "In this work, we consider the problem of modeling the dynamic structure of human activities in the attributes space. A video sequence is first represented in a semantic feature space, where each feature encodes the probability of occurrence of an activity attribute at a given time. A generative model, denoted the binary dynamic system (BDS), is proposed to learn both the distribution and dynamics of different activities in this space. The BDS is a non-linear dynamic system, which extends both the binary principal component analysis (PCA) and classical linear dynamic systems (LDS), by combining binary observation variables with a hidden Gauss-Markov state process. In this way, it integrates the representation power of semantic modeling with the ability of dynamic systems to capture the temporal structure of time-varying processes. An algorithm for learning BDS parameters, inspired by a popular LDS learning method from dynamic textures, is proposed. A similarity measure between BDSs, which generalizes the Binet-Cauchy kernel for LDS, is then introduced and used to design activity classifiers. The proposed method is shown to outperform similar classifiers derived from the kernel dynamic system (KDS) and state-of-the-art approaches for dynamics-based or attribute-based action recognition."}}
{"id": "H1W-p0b_bH", "cdate": 1262304000000, "mdate": null, "content": {"title": "Anomaly detection in crowded scenes", "abstract": "A novel framework for anomaly detection in crowded scenes is presented. Three properties are identified as important for the design of a localized video representation suitable for anomaly detection in such scenes: (1) joint modeling of appearance and dynamics of the scene, and the abilities to detect (2) temporal, and (3) spatial abnormalities. The model for normal crowd behavior is based on mixtures of dynamic textures and outliers under this model are labeled as anomalies. Temporal anomalies are equated to events of low-probability, while spatial anomalies are handled using discriminant saliency. An experimental evaluation is conducted with a new dataset of crowded scenes, composed of 100 video sequences and five well defined abnormality categories. The proposed representation is shown to outperform various state of the art anomaly detection techniques."}}
