{"id": "08Yk-n5l2Al", "cdate": 1652737360841, "mdate": null, "content": {"title": "Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding", "abstract": "We present Imagen, a text-to-image diffusion model with an unprecedented degree of photorealism and a deep level of language understanding. Imagen builds on the power of large transformer language models in understanding text and hinges on the strength of diffusion models in high-fidelity image generation. Our key discovery is that generic large language models (e.g., T5), pretrained on text-only corpora, are surprisingly effective at encoding text for image synthesis: increasing the size of the language model in Imagen boosts both sample fidelity and image-text alignment much more than increasing the size of the image diffusion model. Imagen achieves a new state-of-the-art FID score of 7.27 on the COCO dataset, without ever training on COCO, and human raters find Imagen samples to be on par with the COCO data itself in image-text alignment. To assess text-to-image models in greater depth, we introduce DrawBench, a comprehensive and challenging benchmark for text-to-image models. With DrawBench, we compare Imagen with recent methods including VQ-GAN+CLIP, Latent Diffusion Models, and DALL-E 2, and find that human raters prefer Imagen over other models in side-by-side comparisons, both in terms of sample quality and image-text alignment."}}
{"id": "dCiGVxd4P29", "cdate": 1640995200000, "mdate": 1668635520068, "content": {"title": "Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding", "abstract": "We present Imagen, a text-to-image diffusion model with an unprecedented degree of photorealism and a deep level of language understanding. Imagen builds on the power of large transformer language models in understanding text and hinges on the strength of diffusion models in high-fidelity image generation. Our key discovery is that generic large language models (e.g. T5), pretrained on text-only corpora, are surprisingly effective at encoding text for image synthesis: increasing the size of the language model in Imagen boosts both sample fidelity and image-text alignment much more than increasing the size of the image diffusion model. Imagen achieves a new state-of-the-art FID score of 7.27 on the COCO dataset, without ever training on COCO, and human raters find Imagen samples to be on par with the COCO data itself in image-text alignment. To assess text-to-image models in greater depth, we introduce DrawBench, a comprehensive and challenging benchmark for text-to-image models. With DrawBench, we compare Imagen with recent methods including VQ-GAN+CLIP, Latent Diffusion Models, and DALL-E 2, and find that human raters prefer Imagen over other models in side-by-side comparisons, both in terms of sample quality and image-text alignment. See https://imagen.research.google/ for an overview of the results."}}
{"id": "ajW13IJb0H", "cdate": 1640995200000, "mdate": 1668635519957, "content": {"title": "Deblurring via Stochastic Refinement", "abstract": "Image deblurring is an ill-posed problem with multiple plausible solutions for a given input image. However, most existing methods produce a deterministic estimate of the clean image and are trained to minimize pixel-level distortion. These metrics are known to be poorly correlated with human perception, and often lead to unrealistic reconstructions. We present an alternative framework for blind deblurring based on conditional diffusion models. Unlike existing techniques, we train a stochastic sampler that refines the output of a deterministic predictor and is capable of producing a diverse set of plausible reconstructions for a given input. This leads to a significant improvement in perceptual quality over existing state-of-the-art methods across multiple standard benchmarks. Our predict-and-refine approach also enables much more efficient sampling compared to typical diffusion models. Combined with a carefully tuned network architecture and inference procedure, our method is competitive in terms of distortion metrics such as PSNR. These results show clear benefits of our diffusion-based method for deblurring and challenge the widely used strategy of producing a single, deterministic reconstruction."}}
{"id": "KHRgLp2jp4", "cdate": 1640995200000, "mdate": 1668635520118, "content": {"title": "Imagen Video: High Definition Video Generation with Diffusion Models", "abstract": "We present Imagen Video, a text-conditional video generation system based on a cascade of video diffusion models. Given a text prompt, Imagen Video generates high definition videos using a base video generation model and a sequence of interleaved spatial and temporal video super-resolution models. We describe how we scale up the system as a high definition text-to-video model including design decisions such as the choice of fully-convolutional temporal and spatial super-resolution models at certain resolutions, and the choice of the v-parameterization of diffusion models. In addition, we confirm and transfer findings from previous work on diffusion-based image generation to the video generation setting. Finally, we apply progressive distillation to our video models with classifier-free guidance for fast, high quality sampling. We find Imagen Video not only capable of generating videos of high fidelity, but also having a high degree of controllability and world knowledge, including the ability to generate diverse videos and text animations in various artistic styles and with 3D object understanding. See https://imagen.research.google/video/ for samples."}}
{"id": "DhZmQMY7Em-", "cdate": 1640995200000, "mdate": 1668635520041, "content": {"title": "Deblurring via Stochastic Refinement", "abstract": "Image deblurring is an ill-posed problem with multiple plausible solutions for a given input image. However, most existing methods produce a deterministic estimate of the clean image and are trained to minimize pixel-level distortion. These metrics are known to be poorly correlated with human perception, and often lead to unrealistic reconstructions. We present an alternative framework for blind deblurring based on conditional diffusion models. Unlike existing techniques, we train a stochastic sampler that refines the output of a deterministic predictor and is capable of producing a diverse set of plausible reconstructions for a given input. This leads to a significant improvement in perceptual quality over existing state-of-the-art methods across multiple standard benchmarks. Our predict-and-refine approach also enables much more efficient sampling compared to typical diffusion models. Combined with a carefully tuned network architecture and inference procedure, our method is competitive in terms of distortion metrics such as PSNR. These results show clear benefits of our diffusion-based method for deblurring and challenge the widely used strategy of producing a single, deterministic reconstruction."}}
{"id": "vZGPHN0Q_f", "cdate": 1623413377034, "mdate": null, "content": {"title": "Composing Normalizing Flows for Inverse Problems", "abstract": "Given an inverse problem with a normalizing flow prior, we wish to estimate the distribution of the underlying signal conditioned on the observations.  We approach this problem as a task of conditional inference on the pre-trained unconditional flow model.  We first establish that this is computationally hard for a large class of flow models.  Motivated by this, we propose a framework for approximate inference that estimates the target conditional as a composition of two flow models.  This formulation leads to a stable variational inference training procedure that avoids adversarial training.  Our method is evaluated on a variety of inverse problems and is shown to produce high quality samples with uncertainty quantification.  We further demonstrate that our approach can be amortized for zero-shot inference."}}
{"id": "dHVZQl7fPX5", "cdate": 1609459200000, "mdate": 1668635520174, "content": {"title": "Neural Distributed Source Coding", "abstract": "Distributed source coding (DSC) is the task of encoding an input in the absence of correlated side information that is only available to the decoder. Remarkably, Slepian and Wolf showed in 1973 that an encoder without access to the side information can asymptotically achieve the same compression rate as when the side information is available to it. While there is vast prior work on this topic, practical DSC has been limited to synthetic datasets and specific correlation structures. Here we present a framework for lossy DSC that is agnostic to the correlation structure and can scale to high dimensions. Rather than relying on hand-crafted source modeling, our method utilizes a conditional Vector-Quantized Variational Autoencoder (VQ-VAE) to learn the distributed encoder and decoder. We evaluate our method on multiple datasets and show that our method can handle complex correlations and achieves state-of-the-art PSNR."}}
{"id": "VpnXzGi1NI", "cdate": 1609459200000, "mdate": 1668635520170, "content": {"title": "Composing Normalizing Flows for Inverse Problems", "abstract": "Given an inverse problem with a normalizing flow prior, we wish to estimate the distribution of the underlying signal conditioned on the observations. We approach this problem as a task of conditio..."}}
{"id": "KmzrQ22-jD", "cdate": 1609459200000, "mdate": 1668635520119, "content": {"title": "Solving Inverse Problems with a Flow-based Noise Model", "abstract": "We study image inverse problems with a normalizing flow prior. Our formulation views the solution as the maximum a posteriori estimate of the image conditioned on the measurements. This formulation..."}}
{"id": "qMIW5nuCjwL", "cdate": 1603473990146, "mdate": null, "content": {"title": "Approximate Probabilistic Inference with Composed Flows", "abstract": "We study the problem of probabilistic inference on the joint distribution defined by a normalizing flow model. Given a pre-trained flow model $p(\\boldsymbol{x})$, we wish to estimate $p(\\boldsymbol{x}_2 \\mid \\boldsymbol{x}_1)$ for some partitioning of the variables $\\boldsymbol{x} = (\\boldsymbol{x}_1, \\boldsymbol{x}_2)$. We first show that this task is computationally hard for a large class of flow models.  Motivated by this, we propose a framework for \\textit{approximate} probabilistic inference. Specifically, our method trains a new flow model with the property that its composition with the given model approximates the target conditional distribution.  We describe how we can train this new model using variational inference and handle conditioning under arbitrary differentiable transformations.  Experimentally, our approach outperforms Langevin Dynamics in terms of sample quality, while requiring much fewer parameters and training time compared to regular variational inference. We further validate the flexibility of our method on a variety of inference tasks with applications to inverse problems."}}
