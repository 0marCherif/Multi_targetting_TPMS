{"id": "t4bcTWX6UD", "cdate": 1675209600000, "mdate": 1681699580672, "content": {"title": "Weakly Supervised Deep Nuclei Segmentation With Sparsely Annotated Bounding Boxes for DNA Image Cytometry", "abstract": "Nuclei segmentation is an essential step in DNA ploidy analysis by image-based cytometry (DNA-ICM) which is widely used in cytopathology and allows an objective measurement of DNA content (ploidy). The routine fully supervised learning-based method requires often tedious and expensive pixel-wise labels. In this paper, we propose a novel weakly supervised nuclei segmentation framework which exploits only sparsely annotated bounding boxes, without any segmentation labels. The key is to integrate the traditional image segmentation and self-training into fully supervised instance segmentation. We first leverage the traditional segmentation to generate coarse masks for each box-annotated nucleus to supervise the training of a teacher model, which is then responsible for both the refinement of these coarse masks and pseudo labels generation of unlabeled nuclei. These pseudo labels and refined masks along with the original manually annotated bounding boxes jointly supervise the training of student model. Both teacher and student share the same architecture and especially the student is initialized by the teacher. We have extensively evaluated our method with both our DNA-ICM dataset and public cytopathological dataset. Without bells and whistles, our method outperforms all existing weakly supervised entries on both datasets. Code and our DNA-ICM dataset are publicly available at <uri xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">https://github.com/CVIU-CSU/Weakly-Supervised-Nuclei-Segmentation</uri> ."}}
{"id": "AlgbeSuE1lx", "cdate": 1652737267691, "mdate": null, "content": {"title": "Coded Residual Transform for Generalizable Deep Metric Learning", "abstract": "A fundamental challenge in deep metric learning is the generalization capability of the  feature embedding network model since the embedding network learned on training classes need to be evaluated on new test classes. To address this challenge, in this paper, we introduce a new method called coded residual transform (CRT) for deep metric learning to significantly improve its generalization capability. Specifically, we learn a set of diversified prototype features, project the feature map onto each prototype, and then encode its features using their projection residuals weighted by their correlation coefficients with each prototype. The proposed CRT method has the following two unique characteristics. First, it represents and encodes the feature map from a set of complimentary perspectives based on projections onto diversified prototypes. Second, unlike existing transformer-based feature representation approaches which encode the original values of features based on global correlation analysis, the proposed coded residual transform encodes the relative differences between the original features and their projected prototypes. Embedding space density and spectral decay analysis show that this multi perspective projection onto diversified prototypes and coded residual representation  are able to achieve significantly improved generalization capability in metric learning. Finally, to further enhance the generalization performance, we propose to enforce the consistency on their feature similarity matrices between  coded residual transforms with different sizes of projection prototypes and embedding dimensions. Our extensive experimental results and ablation studies demonstrate that the proposed CRT method outperform the state-of-the-art deep metric learning methods by large margins and improving upon the current best method by up to 4.28% on the CUB dataset."}}
{"id": "ulD8huuXS6X", "cdate": 1640995200000, "mdate": 1681699580713, "content": {"title": "Dual-Branch Network With Dual-Sampling Modulated Dice Loss for Hard Exudate Segmentation in Color Fundus Images", "abstract": "Automated segmentation of hard exudates in colour fundus images is a challenge task due to issues of extreme class imbalance and enormous size variation. This paper aims to tackle these issues and proposes a dual-branch network with dual-sampling modulated Dice loss. It consists of two branches: large hard exudate biased segmentation branch and small hard exudate biased segmentation branch. Both of them are responsible for their own duties separately. Furthermore, we propose a dual-sampling modulated Dice loss for the training such that our proposed dual-branch network is able to segment hard exudates in different sizes. In detail, for the first branch, we use a uniform sampler to sample pixels from predicted segmentation mask for Dice loss calculation, which leads to this branch naturally be biased in favour of large hard exudates as Dice loss generates larger cost on misidentification of large hard exudates than small hard exudates. For the second branch, we use a re-balanced sampler to oversample hard exudate pixels and undersample background pixels for loss calculation. In this way, cost on misidentification of small hard exudates is enlarged, which enforces the parameters in the second branch fit small hard exudates well. Considering that large hard exudates are much easier to be correctly identified than small hard exudates, we propose an easy-to-difficult learning strategy by adaptively modulating the losses of two branches. We evaluate our proposed method on two public datasets and the results demonstrate that ours achieves state-of-the-art performance."}}
{"id": "pHResYPqLh", "cdate": 1640995200000, "mdate": 1681699580740, "content": {"title": "MEJIGCLU: More Effective Jigsaw Clustering For Unsupervised Visual Representation Learning", "abstract": "Unsupervised visual representation learning aims to learn general features from unlabelled data. Early methods design intra-image pretext tasks as learning targets and can be achieved with low computational overhead but unsatisfactory performance. Recent methods introduce contrastive learning and achieve surprising performance, but multiple views of training data are required in one batch, resulting in high computational overhead. To achieve competitive results to contrastive learning with low computational overhead, we propose a new unsupervised representation learning method with jigsaw clustering and classification as pretext tasks motivate the network to learn discriminative feature. To increase the data diversity, we propose to partition each training image into patches with random overlap, then randomly permute and stitch them into new training batch. Comparing with SOTAs, our method achieves state-of-the-art performance on both image classification/semi-classification on ImageNet and object detection on COCO."}}
{"id": "dfrUb3PEi9g", "cdate": 1640995200000, "mdate": 1681699580768, "content": {"title": "Learning Deep Pathological Features for WSI-Level Cervical Cancer Grading", "abstract": "Fully automated cervical cancer grading on the level of Whole Slide Images (WSI) is a challenge task. As WSIs are in gigapixel resolution, it is impossible to train a deep classification neural network with the entire WSIs as inputs. To bypass this problem, we propose a two-stage learning framework. In detail, we propose to first learn patch-level deep pathological features for smear patches via a patch-level feature learning module, which is trained via leveraging the cell instance detection task. Then, we propose to learn WSI-level pathological features from patch-level features for cervical cancer grading. We conduct extensive experiments on our private dataset and make comparisons with rule-based cervical cancer grading methods. Experimental results demonstrate that our proposed deep feature-based WSI-level cervical cancer grading method achieves state-of-the-art performance."}}
{"id": "-4QlpO6juLa", "cdate": 1640995200000, "mdate": 1681699580811, "content": {"title": "Information-Driven Fast Marching Autonomous Exploration With Aerial Robots", "abstract": "Autonomous exploration in unknown environments is a fundamental task of Unmanned Aerial Vehicles (UAVs). To choose exploration goals wisely, we propose an information-driven exploration strategy by applying the fast marching method to exploration of UAVs. A frontier point detection algorithm is designed to obtain Candidate Goals (CGs) by utilizing the structural characteristics of the octree-based map. With the sum of the information gain during the exploration journey as an evaluation indicator, we present a novel utility function to evaluate CGs by considering the trade-off between information gain and travel consumption. Given the effect of the environment on UAVs, UAVs are required to march aggressively in the Euclidean Symbol Distance Field (ESDF) to calculate the flight time, which is defined as the travel consumption. The uncertainty of the environment is minimized gradually by maximizing the utility function during each exploration journey. To take full advantage of the mobility of UAVs, we perform B-spline trajectory optimization and yaw angle planning based on the fast marching paths. We conduct sufficient comparison and evaluation experiments in simulation environments. Experimental results show the superiority of the proposed exploration strategy. The code related to the experiments will be published at <uri xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">https://github.com/BoLeiChen/fastmarching-exploration</uri> ."}}
{"id": "zjaO2e0kPI9", "cdate": 1609459200000, "mdate": 1681699580778, "content": {"title": "Comparison detector for cervical cell/clumps detection in the limited data scenario", "abstract": ""}}
{"id": "xeXozUMn7sq", "cdate": 1609459200000, "mdate": 1681699580800, "content": {"title": "Global context-aware cervical cell detection with soft scale anchor matching", "abstract": ""}}
{"id": "0wiDxJkklR6", "cdate": 1609459200000, "mdate": 1666755129362, "content": {"title": "BEA-SegNet: Body and Edge Aware Network for Medical Image Segmentation", "abstract": "Medical image segmentation is a fundamental step for diagnosis and prognosis. This study proposes a new body and edge aware network for automated 2D medical image segmentation (called BEA-SegNet). The proposed BEA-SegNet consists of a shared encoder, a body and edge decouple (BEdecouple) module, two parallel decoders for body and edge segmentation. In the encoder and decoders, short-term multi-scale concatenation (STMSC) modules are utilized to implement multi-scale representation. We design a BEdecouple module to decouple the convolutional features into the body and edge features, making the proposed method be body and edge aware. The body and edge decoders utilize Bedecouple modules in each level to learn more effective features for the body and edge segmentation respectively, and their outputs are fused to generate the final segmentation. Besides, the body and edge supervision are applied to improve the final segmentation. The proposed BEA-SegNet is trained and evaluated on the International Skin Imaging Collaboration challenge 2018 dataset (ISIC2018). Experimental results show that the proposed BEA-SegNet achieves an average Dice similarity coefficient of 90.3% and an average Hausdorff distance of 15.9 for the skin lesion segmentation task and outperforms five benchmarks for skin lesion segmentation."}}
{"id": "ubjSMB3tpJ", "cdate": 1577836800000, "mdate": 1681699580750, "content": {"title": "Dual-Branch Network with Dual-Sampling Modulated Dice Loss for Hard Exudate Segmentation from Colour Fundus Images", "abstract": "Automated segmentation of hard exudates in colour fundus images is a challenge task due to issues of extreme class imbalance and enormous size variation. This paper aims to tackle these issues and proposes a dual-branch network with dual-sampling modulated Dice loss. It consists of two branches: large hard exudate biased learning branch and small hard exudate biased learning branch. Both of them are responsible for their own duty separately. Furthermore, we propose a dual-sampling modulated Dice loss for the training such that our proposed dual-branch network is able to segment hard exudates in different sizes. In detail, for the first branch, we use a uniform sampler to sample pixels from predicted segmentation mask for Dice loss calculation, which leads to this branch naturally be biased in favour of large hard exudates as Dice loss generates larger cost on misidentification of large hard exudates than small hard exudates. For the second branch, we use a re-balanced sampler to oversample hard exudate pixels and undersample background pixels for loss calculation. In this way, cost on misidentification of small hard exudates is enlarged, which enforces the parameters in the second branch fit small hard exudates well. Considering that large hard exudates are much easier to be correctly identified than small hard exudates, we propose an easy-to-difficult learning strategy by adaptively modulating the losses of two branches. We evaluate our proposed method on two public datasets and results demonstrate that ours achieves state-of-the-art performances."}}
