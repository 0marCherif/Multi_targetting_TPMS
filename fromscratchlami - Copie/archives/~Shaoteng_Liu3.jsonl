{"id": "vxaliy7cUbV", "cdate": 1640995200000, "mdate": 1682389792103, "content": {"title": "Blind Robust Video Watermarking Based on Adaptive Region Selection and Channel Reference", "abstract": "Digital watermarking technology has a wide range of applications in video distribution and copyright protection due to its excellent invisibility and convenient traceability. This paper proposes a robust blind watermarking algorithm using adaptive region selection and channel reference. By designing a combinatorial selection algorithm using texture information and feature points, the method realizes automatically selecting stable blocks which can avoid being destroyed during video encoding and complex attacks. In addition, considering human's insensitivity to some specific color components, a channel-referenced watermark embedding method is designed for less impact on video quality. Moreover, compared with other methods' embedding watermark only at low frequencies, our method tends to modify low-frequency coefficients close to mid frequencies, further ensuring stable retention of the watermark information in the video encoding process. Experimental results show that the proposed method achieves excellent video quality and high robustness against geometric attacks, compression, transcoding and camcorder recordings attacks."}}
{"id": "rbo4GlW0iL-", "cdate": 1640995200000, "mdate": 1684122884322, "content": {"title": "Generative Model Watermarking Based on Human Visual System", "abstract": "Intellectual property protection of deep neural networks is receiving attention from more and more researchers, and the latest research applies model watermarking to generative models for image processing. However, the existing watermarking methods designed for generative models do not take into account the effects of different channels of sample images on watermarking. As a result, the watermarking performance is still limited. To tackle this problem, in this paper, we first analyze the effects of embedding watermark information on different channels. Then, based on the characteristics of human visual system (HVS), we introduce two HVS-based generative model watermarking methods, which are realized in RGB color space and YUV color space respectively. In RGB color space, the watermark is embedded into the R and B channels based on the fact that HVS is more sensitive to G channel. In YUV color space, the watermark is embedded into the DCT domain of U and V channels based on the fact that HVS is more sensitive to brightness changes. Experimental results demonstrate the effectiveness of the proposed work, which improves the fidelity of the model to be protected and has good universality compared with previous methods."}}
{"id": "24caZ_i-X-", "cdate": 1640995200000, "mdate": 1682389792103, "content": {"title": "Blind Robust VideoWatermarking Based on Adaptive Region Selection and Channel Reference", "abstract": "Digital watermarking technology has a wide range of applications in video distribution and copyright protection due to its excellent invisibility and convenient traceability. This paper proposes a robust blind watermarking algorithm using adaptive region selection and channel reference. By designing a combinatorial selection algorithm using texture information and feature points, the method realizes automatically selecting stable blocks which can avoid being destroyed during video encoding and complex attacks. In addition, considering human's insensitivity to some specific color components, a channel-referenced watermark embedding method is designed for less impact on video quality. Moreover, compared with other methods' embedding watermark only at low frequencies, our method tends to modify low-frequency coefficients close to mid frequencies, further ensuring stable retention of the watermark information in the video encoding process. Experimental results show that the proposed method achieves excellent video quality and high robustness against geometric attacks, compression, transcoding and camcorder recordings attacks."}}
{"id": "ZtLoo9MXDc", "cdate": 1609459200000, "mdate": 1683950906396, "content": {"title": "Multiple Auxiliary Networks for Single Blind Image Deblurring", "abstract": "Single blind image deblurring caused by a combination of multiple factors has been one of the most challenging visual tasks. Recently, many essential methods of this task are based on deep learning networks and have achieved high performance. However, most of them only apply norm pixel-wise L1-loss function as the guide of training, which is not suitable or effective enough. In this paper, we propose Multiple Auxiliary Networks (MANet) for single blind image deblurring to assist norm L1-loss function and enhance the quality of the deblurring image. The main branch of our MANet is an encoder-decoder structure made up of residual blocks, and the three auxiliary branches are the edge prediction branch, the multi-scale refinement branch, and the perceptual loss branch. The experimental results demonstrate that the proposed MANet can obtain better deblurring performance with more details than state-of-the-art methods. The code is released at github.com/ZERO2ER0/MANet."}}
{"id": "hzQvP9m3F8b", "cdate": 1577836800000, "mdate": 1668512353704, "content": {"title": "GREEN: a Graph REsidual rE-ranking Network for Grading Diabetic Retinopathy", "abstract": "The automatic grading of diabetic retinopathy (DR) facilitates medical diagnosis for both patients and physicians. Existing researches formulate DR grading as an image classification problem. As the stages/categories of DR correlate with each other, the relationship between different classes cannot be explicitly described via a one-hot label because it is empirically estimated by different physicians with different outcomes. This class correlation limits existing networks to achieve effective classification. In this paper, we propose a Graph REsidual rE-ranking Network (GREEN) to introduce a class dependency prior into the original image classification network. The class dependency prior is represented by a graph convolutional network with an adjacency matrix. This prior augments image classification pipeline by re-ranking classification results in a residual aggregation manner. Experiments on the standard benchmarks have shown that GREEN performs favorably against state-of-the-art approaches."}}
{"id": "bI3FK2DJfbrE", "cdate": 1577836800000, "mdate": 1668512353536, "content": {"title": "GREEN: a Graph REsidual rE-ranking Network for Grading Diabetic Retinopathy", "abstract": "The automatic grading of diabetic retinopathy (DR) facilitates medical diagnosis for both patients and physicians. Existing researches formulate DR grading as an image classification problem. As the stages/categories of DR correlate with each other, the relationship between different classes cannot be explicitly described via a one-hot label because it is empirically estimated by different physicians with different outcomes. This class correlation limits existing networks to achieve effective classification. In this paper, we propose a Graph REsidual rE-ranking Network (GREEN) to introduce a class dependency prior into the original image classification network. The class dependency prior is represented by a graph convolutional network with an adjacency matrix. This prior augments image classification pipeline by re-ranking classification results in a residual aggregation manner. Experiments on the standard benchmarks have shown that GREEN performs favorably against state-of-the-art approaches."}}
{"id": "aRAMgP2Aj8", "cdate": 1546300800000, "mdate": 1683951307021, "content": {"title": "Scene Classification With Recurrent Attention of VHR Remote Sensing Images", "abstract": "Scene classification of remote sensing images has drawn great attention because of its wide applications. In this paper, with the guidance of the human visual system (HVS), we explore the attention mechanism and propose a novel end-to-end attention recurrent convolutional network (ARCNet) for scene classification. It can learn to focus selectively on some key regions or locations and just process them at high-level features, thereby discarding the noncritical information and promoting the classification performance. The contributions of this paper are threefold. First, we design a novel recurrent attention structure to squeeze high-level semantic and spatial features into several simplex vectors for the reduction of learning parameters. Second, an end-to-end network named ARCNet is proposed to adaptively select a series of attention regions and then to generate powerful predictions by learning to process them sequentially. Third, we construct a new data set named OPTIMAL-31, which contains more categories than popular data sets and gives researchers an extra platform to validate their algorithms. The experimental results demonstrate that our model makes great promotion in comparison with the state-of-the-art approaches."}}
{"id": "-X18IUHvrA", "cdate": 1514764800000, "mdate": 1683951306669, "content": {"title": "Attention Based Network for Remote Sensing Scene Classification", "abstract": "Scene classification of very high resolution remote sensing images is becoming more and more important because of its wide range of applications. However, previous works are mainly based on handcrafted features which do not have enough adaptability and expression ability. In this paper, inspired by the attention mechanism of human visual system, we propose a novel attention based network (AttNet) for scene classification. It can focus selectively on some key areas of images so that it can abandon redundant information. Essentially, AttNet gives a way to readjust the signal of supervision, and it is one of the first successful attempts on visual attention for remote sensing scene classification. Our method is evaluated on the UC Merced Land-Use Dataset, in comparison with some state-of-the-art methods. The experimental result shows that the proposed method makes a great improvement on both convergence speed and classification accuracy, and it also shows the effectiveness of visual attention for this task."}}
