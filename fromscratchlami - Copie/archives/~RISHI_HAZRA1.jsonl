{"id": "ZvXz67SIjz", "cdate": 1672531200000, "mdate": 1681652229407, "content": {"title": "EgoTV: Egocentric Task Verification from Natural Language Task Descriptions", "abstract": ""}}
{"id": "IGGo4oHNXm", "cdate": 1672531200000, "mdate": 1693496869203, "content": {"title": "SayCanPay: Heuristic Planning with Large Language Models using Learnable Domain Knowledge", "abstract": "Large Language Models (LLMs) have demonstrated impressive planning abilities due to their vast \"world knowledge\". Yet, obtaining plans that are both feasible (grounded in affordances) and cost-effective (in plan length), remains a challenge, despite recent progress. This contrasts with heuristic planning methods that employ domain knowledge (formalized in action models such as PDDL) and heuristic search to generate feasible, optimal plans. Inspired by this, we propose to combine the power of LLMs and heuristic planning by leveraging the world knowledge of LLMs and the principles of heuristic search. Our approach, SayCanPay, employs LLMs to generate actions (Say) guided by learnable domain knowledge, that evaluates actions' feasibility (Can) and long-term reward/payoff (Pay), and heuristic search to select the best sequence of actions. Our contributions are (1) a novel framing of the LLM planning problem in the context of heuristic planning, (2) integrating grounding and cost-effective elements into the generated plans, and (3) using heuristic search over actions. Our extensive evaluations show that our model surpasses other LLM planning approaches."}}
{"id": "1sQf7w7uJ_o", "cdate": 1672531200000, "mdate": 1682239629862, "content": {"title": "Deep Explainable Relational Reinforcement Learning: A Neuro-Symbolic Approach", "abstract": "Despite numerous successes in Deep Reinforcement Learning (DRL), the learned policies are not interpretable. Moreover, since DRL does not exploit symbolic relational representations, it has difficulties in coping with structural changes in its environment (such as increasing the number of objects). Relational Reinforcement Learning, on the other hand, inherits the relational representations from symbolic planning to learn reusable policies. However, it has so far been unable to scale up and exploit the power of deep neural networks. We propose Deep Explainable Relational Reinforcement Learning (DERRL), a framework that exploits the best of both -- neural and symbolic worlds. By resorting to a neuro-symbolic approach, DERRL combines relational representations and constraints from symbolic planning with deep learning to extract interpretable policies. These policies are in the form of logical rules that explain how each decision (or action) is arrived at. Through several experiments, in setups like the Countdown Game, Blocks World, Gridworld, and Traffic, we show that the policies learned by DERRL can be applied to different configurations and contexts, hence generalizing to environmental modifications."}}
{"id": "kOFk9SEUKc", "cdate": 1609459200000, "mdate": 1681652229443, "content": {"title": "Active\u00b2 Learning: Actively reducing redundancies in Active Learning methods for Sequence Tagging and Machine Translation", "abstract": ""}}
{"id": "f2mYc-yoXT", "cdate": 1609459200000, "mdate": 1681652229476, "content": {"title": "Zero-Shot Generalization using Intrinsically Motivated Compositional Emergent Protocols", "abstract": ""}}
{"id": "bpm_iqnl2n", "cdate": 1609459200000, "mdate": 1681652229400, "content": {"title": "gComm: An environment for investigating generalization in Grounded Language Acquisition", "abstract": ""}}
{"id": "G2-WoV_zbQX", "cdate": 1577836800000, "mdate": 1681652229431, "content": {"title": "Networked Multi-Agent Reinforcement Learning with Emergent Communication", "abstract": ""}}
{"id": "H1lUp1BYDH", "cdate": 1569439678483, "mdate": null, "content": {"title": "Emergent Communication in Networked Multi-Agent Reinforcement Learning", "abstract": "With the ever increasing demand and the resultant reduced quality of services, the focus has shifted towards easing network congestion to enable more efficient flow in systems like traffic, supply chains and electrical grids. A step in this direction is to re-imagine the traditional heuristics based training of systems as this approach is incapable of modelling the involved dynamics. While one can apply Multi-Agent Reinforcement Learning (MARL) to such problems by considering each vertex in the network as an agent, most MARL-based models assume the agents to be independent. In many real-world tasks, agents need to behave as a group, rather than as a collection of individuals. In this paper, we propose a framework that induces cooperation and coordination amongst agents, connected via an underlying network, using emergent communication in a MARL-based setup. We formulate the problem in a general network setting and demonstrate the utility of communication in networks with the help of a case study on traffic systems. Furthermore, we study the emergent communication protocol and show the formation of distinct communities with grounded vocabulary. To the best of our knowledge, this is the only work that studies emergent language in a networked MARL setting."}}
