{"id": "Xx7eJDXG3Xl", "cdate": 1671748395742, "mdate": 1671748395742, "content": {"title": "Subset Node Anomaly Tracking over Large Dynamic Graphs", "abstract": "Tracking a targeted subset of nodes in an evolving graph is important for many real-world applications. Existing methods typically focus on identifying anomalous edges or finding anomaly graph snapshots in a stream way. However, edge-oriented methods cannot quantify how individual nodes change over time while others need to maintain representations of the whole graph all time, thus computationally inefficient. \nThis paper proposes \\textsc{DynAnom}, an efficient framework to quantify the changes and localize per-node anomalies over large dynamic weighted-graphs. Thanks to recent advances in dynamic representation learning based on Personalized PageRank, \\textsc{DynAnom} is 1) \\textit{efficient}: the time complexity is linear to the number of edge events and independent on node size of the input graph; 2) \\textit{effective}: \\textsc{DynAnom} can successfully track topological changes reflecting real-world anomaly; 3) \\textit{flexible}: different type of anomaly score functions can be defined for various applications. Experiments demonstrate these properties on both benchmark graph datasets and a new large real-world dynamic graph. Specifically, an instantiation method based on \\textsc{DynAnom} achieves the accuracy of 0.5425 compared with 0.2790, the best baseline, on the task of node-level anomaly localization while running 2.3 times faster than the baseline. We present a real-world case study and further demonstrate the usability of \\textsc{DynAnom} for anomaly discovery over large-scale graphs.\n"}}
{"id": "OGFXoZHgsnc", "cdate": 1671748153623, "mdate": 1671748153623, "content": {"title": "Subset Node Representation Learning over Large Dynamic Graphs", "abstract": "Dynamic graph representation learning is a task to learn node embeddings over dynamic networks, and has many important applications, including knowledge graphs, citation networks to social networks. Graphs of this type are usually large-scale but only a small subset of vertices are related in downstream tasks. Current methods are too expensive to this setting as the complexity is at best linear-dependent on both the number of nodes and edges.\nIn this paper, we propose a new method, namely Dynamic Personalized PageRank Embedding (DynamicPPE) for learning a target subset of node representations over large-scale dynamic networks. Based on recent advances in local node embedding and a novel computation of dynamic personalized PageRank vector (PPV), DynamicPPE has two key ingredients: 1) the per-PPV complexity is O (m d / \u03b5) where m, d, and \u03b5 are the number of edges received, average degree, global precision error respectively. Thus, the per-edge event update of a single node is only dependent on d in average; and 2) by using these high quality PPVs and hash kernels, the learned embeddings have properties of both locality and global consistency. These two make it possible to capture the evolution of graph structure effectively.\nExperimental results demonstrate both the effectiveness and efficiency of the proposed method over large-scale dynamic networks. We apply DynamicPPE to capture the embedding change of Chinese cities in the Wikipedia graph during this ongoing COVID-19 pandemic. https://en.wikipedia.org/wiki/COVID-19_pandemic. Our results show that these representations successfully encode the dynamics of the Wikipedia graph."}}
{"id": "j30wC0JM39Q", "cdate": 1632875541406, "mdate": null, "content": {"title": "Why do embedding spaces look as they do?", "abstract": "The power of embedding representations is a curious phenomenon.   For embeddings to work effectively as feature representations, there must exist substantial latent structure inherent in the domain to be encoded.  Language vocabularies and Wikipedia topics are human-generated structures that reflect how people organize their world, and what they find important. The structure of the resulting embedding spaces reflects the human evolution of language formation and the cultural processes shaping our world.\n\nThis paper studies what the observed structure of embeddings can tell us about the natural processes that generate new knowledge or concepts.   We demonstrate that word and graph embeddings trained on standard datasets using several popular algorithms consistently share two distinct properties: (1) a decreasing neighbor frequency concentration with rank, and (2) specific clustering velocities and power-law based community structures.\nWe then assess a variety of generative models of embedding spaces by these criteria, and conclude that incremental insertion processes based on the Barab\u00e1si-Albert network generation process best model the observed phenomenon on language and network data.\n"}}
{"id": "DZKw_snKTXmA", "cdate": 1601054039605, "mdate": null, "content": {"title": "Dual Averaging Method for Online Graph-structured Sparsity", "abstract": "Online learning algorithms update models via one sample per iteration, thus efficient to process large-scale datasets and useful to detect malicious events for social benefits, such as disease outbreak and traffic congestion on the fly. However, existing algorithms for graph-structured models focused on the offline setting and the least square loss, incapable for online setting, while methods designed for online setting cannot be directly applied to the problem of complex (usually non-convex) graph-structured sparsity model. To address these limitations, in this paper we propose a new algorithm for graph-structured sparsity constraint problems under online setting, which we call \\textsc{GraphDA}. The key part in \\textsc{GraphDA} is to project both averaging gradient (in dual space) and primal variables (in primal space) onto lower dimensional subspaces, thus capturing the graph-structured sparsity effectively. Furthermore, the objective functions assumed here are generally convex so as to handle different losses for online learning settings. To the best of our knowledge, \\textsc{GraphDA} is the first online learning algorithm for graph-structure constrained optimization problems. To validate our method, we conduct extensive experiments on both benchmark graph and real-world graph datasets. Our experiment results show that, compared to other baseline methods, \\textsc{GraphDA} not only improves classification performance, but also successfully captures graph-structured features more effectively, hence stronger interpretability."}}
{"id": "rJEO5ob_ZB", "cdate": 1546300800000, "mdate": null, "content": {"title": "Stochastic Iterative Hard Thresholding for Graph-structured Sparsity Optimization", "abstract": "Stochastic optimization algorithms update models with cheap per-iteration costs sequentially, which makes them amenable for large-scale data analysis. Such algorithms have been widely studied for s..."}}
{"id": "ryEmTCxuWB", "cdate": 1451606400000, "mdate": null, "content": {"title": "Efficient Nonparametric Subgraph Detection Using Tree Shaped Priors", "abstract": "Non-parametric graph scan (NPGS) statistics are used to detect anomalous connected subgraphs on graphs, and have a wide variety of applications, such as disease outbreak detection, road traffic congestion detection, and event detection in social media. In contrast to traditional parametric scan statistics (e.g., the Kulldorff statistic), NPGS statistics are free of distributional assumptions and can be applied to heterogeneous graph data. In this paper, we make a number of contributions to the computational study of NPGS statistics. First, we present a novel reformulation of the problem as a sequence of Budget Price-Collecting Steiner Tree (BPCST) sub-problems. Second, we show that this reformulated problem is NP-hard for a large class of non-parametric statistic functions. Third, we further develop efficient exact and approximate algorithms for a special category of graphs in which the anomalous subgraphs can be reformulated in a fixed tree topology. Finally, using extensive experiments we demonstrate the performance of our proposed algorithms in two real-world application domains (water pollution detection in water sensor networks and spatial event detection in social media networks) and contrast against state-of-the-art connected subgraph detection methods."}}
{"id": "H149n7z_bB", "cdate": 1451606400000, "mdate": null, "content": {"title": "A Generalized Matching Pursuit Approach for Graph-Structured Sparsity", "abstract": "Sparsity-constrained optimization is an important and challenging problem that has wide applicability in data mining, machine learning, and statistics. In this paper, we focus on sparsity-constrained optimization in cases where the cost function is a general nonlinear function and, in particular, the sparsity constraint is defined by a graph-structured sparsity model. Existing methods explore this problem in the context of sparse estimation in linear models. To the best of our knowledge, this is the first work to present an efficient approximation algorithm, namely, GRAPH-structured Matching Pursuit (GRAPH-MP), to optimize a general nonlinear function subject to graph-structured constraints. We prove that our algorithm enjoys the strong guarantees analogous to those designed for linear models in terms of convergence rate and approximation accuracy. As a case study, we specialize GRAPHMP to optimize a number of well-known graph scan statistic models for the connected subgraph detection task, and empirical evidence demonstrates that our general algorithm performs superior over state-of-the-art methods that are designed specifically for the task of connected subgraph detection."}}
