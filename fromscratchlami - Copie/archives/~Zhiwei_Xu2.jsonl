{"id": "yZJNKZhJQM", "cdate": 1640995200000, "mdate": 1667343966494, "content": {"title": "Adaptive Test-Time Defense with the Manifold Hypothesis", "abstract": "In this work, we formulate a novel framework of adversarial robustness using the manifold hypothesis. Our framework provides sufficient conditions for defending against adversarial examples. We develop a test-time defense method with our formulation and variational inference. The developed approach combines manifold learning with the Bayesian framework to provide adversarial robustness without the need for adversarial training. We show that our proposed approach can provide adversarial robustness even if attackers are aware of existence of test-time defense. In additions, our approach can also serve as a test-time defense mechanism for variational autoencoders."}}
{"id": "b-IfcH5y-Vg", "cdate": 1640995200000, "mdate": 1667343966639, "content": {"title": "Exploiting Problem Structure in Deep Declarative Networks: Two Case Studies", "abstract": "Deep declarative networks and other recent related works have shown how to differentiate the solution map of a (continuous) parametrized optimization problem, opening up the possibility of embedding mathematical optimization problems into end-to-end learnable models. These differentiability results can lead to significant memory savings by providing an expression for computing the derivative without needing to unroll the steps of the forward-pass optimization procedure during the backward pass. However, the results typically require inverting a large Hessian matrix, which is computationally expensive when implemented naively. In this work we study two applications of deep declarative networks -- robust vector pooling and optimal transport -- and show how problem structure can be exploited to obtain very efficient backward pass computations in terms of both time and memory. Our ideas can be used as a guide for improving the computational performance of other novel deep declarative nodes."}}
{"id": "kRYOK8Bbql", "cdate": 1577836800000, "mdate": 1667343966550, "content": {"title": "Deep Learning Superpixel Semantic Segmentation with Transparent Initialization and Sparse Encoder", "abstract": "Although deep learning greatly improves the performance of semantic segmentation, its success mainly lies in object central areas without accurate edges. As superpixels are a popular and effective auxiliary to preserve object edges, in this paper, we jointly learn semantic segmentation with trainable superpixels. We achieve it with fully-connected layers with Transparent Initialization (TI) and efficient logit consistency using a sparse encoder. The proposed TI preserves the effects of learned parameters of pretrained networks. This avoids a significant increase of the loss of pretrained networks, which otherwise may be caused by inappropriate parameter initialization of the additional layers. Meanwhile, consistent pixel labels in each superpixel are guaranteed by logit consistency. The sparse encoder with sparse matrix operations substantially reduces both the memory requirement and the computational complexity. We demonstrated the superiority of TI over other parameter initialization methods and tested its numerical stability. The effectiveness of our proposal was validated on PASCAL VOC 2012, ADE20K, and PASCAL Context showing enhanced semantic segmentation edges. With quantitative evaluations on segmentation edges using performance ratio and F-measure, our method outperforms the state-of-the-art."}}
{"id": "M1wxqqPXOB", "cdate": 1577836800000, "mdate": 1667343966571, "content": {"title": "RANP: Resource Aware Neuron Pruning at Initialization for 3D CNNs", "abstract": "Although 3D Convolutional Neural Networks (CNNs) are essential for most learning based applications involving dense 3D data, their applicability is limited due to excessive memory and computational requirements. Compressing such networks by pruning therefore becomes highly desirable. However, pruning 3D CNNs is largely unexplored possibly because of the complex nature of typical pruning algorithms that embeds pruning into an iterative optimization paradigm. In this work, we introduce a Resource Aware Neuron Pruning (RANP) algorithm that prunes 3D CNNs at initialization to high sparsity levels. Specifically, the core idea is to obtain an importance score for each neuron based on their sensitivity to the loss function. This neuron importance is then reweighted according to the neuron resource consumption related to FLOPs or memory. We demonstrate the effectiveness of our pruning method on 3D semantic segmentation with widely used 3D-UNets on ShapeNet and BraTS'18 as well as on video classification with MobileNetV2 and I3D on UCF101 dataset. In these experiments, our RANP leads to roughly 50%-95% reduction in FLOPs and 35%-80% reduction in memory with negligible loss in accuracy compared to the unpruned networks. This significantly reduces the computational resources required to train 3D CNNs. The pruned network obtained by our algorithm can also be easily scaled up and transferred to another dataset for training."}}
{"id": "5kwcIKPOWrR", "cdate": 1577836800000, "mdate": 1667343966501, "content": {"title": "Fast and Differentiable Message Passing on Pairwise Markov Random Fields", "abstract": "Despite the availability of many Markov Random Field (MRF) optimization algorithms, their widespread usage is currently limited due to imperfect MRF modelling arising from hand-crafted model parameters and the selection of inferior inference algorithm. In addition to differentiability, the two main aspects that enable learning these model parameters are the forward and backward propagation time of the MRF optimization algorithm and its inference capabilities. In this work, we introduce two fast and differentiable message passing algorithms, namely, Iterative Semi-Global Matching Revised (ISGMR) and Parallel Tree-Reweighted Message Passing (TRWP) which are greatly sped up on a GPU by exploiting massive parallelism. Specifically, ISGMR is an iterative and revised version of the standard SGM for general pairwise MRFs with improved optimization effectiveness, and TRWP is a highly parallel version of Sequential TRW (TRWS) for faster optimization. Our experiments on the standard stereo and denoising benchmarks demonstrated that ISGMR and TRWP achieve much lower energies than SGM and Mean-Field (MF), and TRWP is two orders of magnitude faster than TRWS without losing effectiveness in optimization. We further demonstrated the effectiveness of our algorithms on end-to-end learning for semantic segmentation. Notably, our CUDA implementations are at least 7 and 700 times faster than PyTorch GPU implementations for forward and backward propagation respectively, enabling efficient end-to-end learning with message passing."}}
{"id": "PIriID2Rsne", "cdate": 1420070400000, "mdate": 1667343966648, "content": {"title": "Interesting components detection for space satellites from inverse synthetic aperture radar image via feature probabilistic estimation", "abstract": ""}}
{"id": "Ef_3FgU9TF", "cdate": 1388534400000, "mdate": 1667343966640, "content": {"title": "A Fast BP Algorithm With Wavenumber Spectrum Fusion for High-Resolution Spotlight SAR Imaging", "abstract": "This letter presents the accelerated fast backprojection (AFBP) algorithm for high-resolution spotlight synthetic aperture radar (SAR) imaging. In conventional fast backprojection (FBP) algorithms, image-domain interpolation is employed in the subaperture (SA) fusion. However, in AFBP, by using a unified polar coordinate (UPC) system, the interpolation-based fusion is substituted by fusing the SA spectra in the wavenumber (WN) spectrum domain. The WN-domain SA fusion is efficiently implemented by fast Fourier transform and circular shifting. In this letter, an accurate impulse response function and the WN spectrum expression of the backprojected image in the UPC are explicitly derived, and furthermore, the implementations of AFBP are investigated in detail. Compared with conventional FBP algorithms, the AFBP can precisely focus on high-resolution SAR data with dramatically improved efficiency. Both simulation and real-measured data experiments validate the superiorities of AFBP by comparing it with the fast factorization backprojection (FFBP) algorithm."}}
{"id": "2fwzPuGMiDf", "cdate": 1388534400000, "mdate": 1667343966514, "content": {"title": "Precise Cross-Range Scaling for ISAR Images Using Feature Registration", "abstract": "This letter proposes a precise cross-range scaling algorithm for inverse synthetic aperture radar (ISAR) images by estimating the effective rotation angle through coordinate locations of feature points extracted from two sequenced subaperture ISAR images. In the approach, we first extract adequate feature points and feature descriptor vectors from these two images by scale-invariant feature transform and speeded-up robust features. Then, a two-stage registering scheme is employed to match these feature points to link the two images. Consequently, the effective rotation angle is efficiently and robustly estimated by evaluating a cost function based on the coordinate locations of the matched feature points. Experiments of simulated and real signals validate this proposal."}}
