{"id": "uUifvJSeIZ", "cdate": 1672531200000, "mdate": 1703655023737, "content": {"title": "Question Generation Using Sequence-to-Sequence Model with Semantic Role Labels", "abstract": ""}}
{"id": "pKm1reCP8V", "cdate": 1672531200000, "mdate": 1703655023766, "content": {"title": "Contrastive Fine-tuning on Few Shot Intent Detection with Topological Intent Tree", "abstract": "We present a few-shot intent detection model for an enterprise\u2019s conversational dialogue system. The model uses an intent topological tree to guide the search for the user intent using large language models (LLMs). The intents are resolved based on semantic similarities between user utterances and the text descriptions of the internal nodes of the intent tree or the intent examples in the leaf nodes of the tree. Our results show that an off-the-shelf language model can work reasonably well in a large enterprise deployment without fine-tuning, and its performance can be further improved with fine-tuning as more domain-specific data becomes available. We also show that the fine-tuned language model meets and outperforms the state-of-the-art (SOTA) results in resolving conversation intents without training classifiers. With the use of a topological intent tree, our model provides more interpretability to cultivate people\u2019s trust in their decisions."}}
{"id": "G57ul7xtKzV", "cdate": 1672531200000, "mdate": 1703655023724, "content": {"title": "Empowering Conversational Agents using Semantic In-Context Learning", "abstract": ""}}
{"id": "-pG0l0S3ev", "cdate": 1672531200000, "mdate": 1703655023712, "content": {"title": "Learning to Generate Popular Headlines", "abstract": "Headlines are not only essential for summarizing news articles but also for grabbing users\u2019 attention. Headline generation is a type of text summarization that can employ either an extractive or abstractive approach, with the latter being more prevalent through deep learning models. However, creating a popular headline that can capture readers\u2019 attention is challenging. To address this issue, we propose a hybrid headline generation approach that utilizes state-of-the-art transformer models to generate several headline variations for an article. Additionally, we use a model for predicting headline popularity that can choose the most popular headline from the generated ones. We also create a new dataset for predicting headline popularity by scraping Twitter accounts of news media. Our evaluation shows that fine-tuning summarization models for the headline generation task can significantly improve their performance. We also demonstrate that our proposed method can generate more popular headlines compared to the baseline methods that do not incorporate popularity prediction. For such an evaluation purpose, we create a popularity benchmark to automatically assess the effectiveness of our proposed headline generation approach in generating popular headlines."}}
{"id": "YBbpH24h2c", "cdate": 1640995200000, "mdate": 1703655023818, "content": {"title": "Temporal Graph Representation Learning via Maximal Cliques", "abstract": "Graph Neural Networks (GNNs) have been proposed to learn graph representations for various graph mining tasks such as link prediction and node classification. These methods aggregate information from neighbors of a node to generate the node representation vector. Temporal GNN models consider the temporal and neighborhood information of nodes. However, few temporal GNN methods consider network substructures such as triads and cliques. In this paper, we present a temporal GNN-based method that generates node embeddings by aggregating neighbors of a node that exist in the maximal cliques of the graph containing the node. The reason for considering neighbors that form a maximal clique with the target node is that nodes in a maximal clique are highly connected to each other and most likely share similar characteristics. In addition, we consider the time dependency of nodes by generating temporal walks on the cliques such that in these walks the time order of the nodes is respected. The node embedding is based on the aggregation of the node\u2019s temporal walks. Our experiments on seven datasets show the effectiveness of our method in both link prediction and node classification tasks. Furthermore, our method is faster than other baselines we evaluate."}}
{"id": "CwbsdBdG0s", "cdate": 1640995200000, "mdate": 1703655023722, "content": {"title": "Data Capsule: A Self-Contained Data Model as an Access Policy Enforcement Strategy", "abstract": "In this paper, we introduce a data capsule model, a self-contained and self-enforcing data container based on emerging self-sovereign identity standards, blockchain, and attribute-based encryption. A data capsule allows for a transparent, privacy-respecting, and secure exchange of personal data, enabling a progressive trust scheme in a semi-trusted environment. Each data capsule is bundled with its own access policy structure and verifiable data, drastically reducing the number of interactions needed among the user, the service providers, and data custodians. Moreover, by relying on the decentralized nature of blockchain and attribute-based encryption our proposed model ensures the access policies published by service providers are public, transparent, and strictly followed."}}
{"id": "6Jy5WgkCIR", "cdate": 1640995200000, "mdate": 1703655023730, "content": {"title": "A Survey on Graph Representation Learning Methods", "abstract": "Graphs representation learning has been a very active research area in recent years. The goal of graph representation learning is to generate graph representation vectors that capture the structure and features of large graphs accurately. This is especially important because the quality of the graph representation vectors will affect the performance of these vectors in downstream tasks such as node classification, link prediction and anomaly detection. Many techniques are proposed for generating effective graph representation vectors. Two of the most prevalent categories of graph representation learning are graph embedding methods without using graph neural nets (GNN), which we denote as non-GNN based graph embedding methods, and graph neural nets (GNN) based methods. Non-GNN graph embedding methods are based on techniques such as random walks, temporal point processes and neural network learning methods. GNN-based methods, on the other hand, are the application of deep learning on graph data. In this survey, we provide an overview of these two categories and cover the current state-of-the-art methods for both static and dynamic graphs. Finally, we explore some open and ongoing research directions for future work."}}
{"id": "nt2DvtNLHW", "cdate": 1609459200000, "mdate": 1674366220508, "content": {"title": "ZipLine: An Optimized Algorithm for the Elastic Bulk Synchronous Parallel Model", "abstract": "The bulk synchronous parallel (BSP) is a celebrated synchronization model for distributed training of deep learning models. A shortcoming of the BSP is that it requires workers to wait for the straggler at every iteration. Therefore, employing BSP increases the waiting time of the faster workers of a cluster and results in an overall prolonged training time. To ameliorate this shortcoming of BSP, we proposed ElasticBSP [1], a model that aims to relax its strict synchronization requirement with an elastic synchronization by allowing delayed synchronization to minimize the waiting time. ELASTICBSP is realized by the algorithm named ZipLine. In this work, we show the theoretical proof of ZipLine and further propose algorithmic and implementation optimizations of ZipLine, namely ZipLineOpt and Ziplineoptbs, which reduce the time complexity of ZipLine to linearithmic time. The experiments show that ZipLineOpt and ZipLineOptBs enable the scalability of ElasticBSP. Further experimental evaluation on large deep neural networks on large ImageNet dataset demonstrate that our proposed Elas-ticbspmodel, materialized by the proposed optimized ZipLine variants, converges faster and to a higher accuracy than the predominant BSP."}}
{"id": "RiZEgDpBwj", "cdate": 1609459200000, "mdate": 1703655023722, "content": {"title": "Centrality-based Interpretability Measures for Graph Embeddings", "abstract": "Many real-world data are considered as graphs, such as computer networks, social networks and protein-protein interaction networks. Graph embedding methods are powerful tools for representing large graphs in various domains. A graph embedding method projects the components of a graph, such as its nodes or edges, into a vector space with a lower dimensionality than the adjacency matrix of the graph, and aims to preserve the characteristics of the graph. The generated embedding vectors have been utilized in various graph mining applications such as node classification, link prediction and anomaly detection. Despite the wide success of the graph embedding methods, little study has been done to facilitate a better understanding of the graph embeddings. In this paper, inspired by advancements in interpreting word embeddings, we propose two interpretability measures to quantify the interpretability of graph embeddings by leveraging useful network centrality properties and perform comparisons of different graph embedding methods. Using these scores, we can provide insights into the representational power of graph embedding methods."}}
{"id": "O4EnO7FZIS", "cdate": 1609459200000, "mdate": 1676497787650, "content": {"title": "Extending Isolation Forest for Anomaly Detection in Big Data via K-Means", "abstract": "Industrial Information Technology infrastructures are often vulnerable to cyberattacks. To ensure security to the computer systems in an industrial environment, it is required to build effective intrusion detection systems to monitor the cyber-physical systems (e.g., computer networks) in the industry for malicious activities. This article aims to build such intrusion detection systems to protect the computer networks from cyberattacks. More specifically, we propose a novel unsupervised machine learning approach that combines the K-Means algorithm with the Isolation Forest for anomaly detection in industrial big data scenarios. Since our objective is to build the intrusion detection system for the big data scenario in the industrial domain, we utilize the Apache Spark framework to implement our proposed model that was trained in large network traffic data (about 123 million instances of network traffic) stored in Elasticsearch. Moreover, we evaluate our proposed model on the live streaming data and find that our proposed system can be used for real-time anomaly detection in the industrial setup. In addition, we address different challenges that we face while training our model on large datasets and explicitly describe how these issues were resolved. Based on our empirical evaluation in different use cases for anomaly detection in real-world network traffic data, we observe that our proposed system is effective to detect anomalies in big data scenarios. Finally, we evaluate our proposed model on several academic datasets to compare with other models and find that it provides comparable performance with other state-of-the-art approaches."}}
