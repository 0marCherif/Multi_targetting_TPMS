{"id": "nSqct2hTwIH", "cdate": 1546300800000, "mdate": 1682935651216, "content": {"title": "Comparing the Effects of Annotation Type on Machine Learning Detection Performance", "abstract": "The most prominent machine learning (ML) methods in use today are supervised, meaning they require groundtruth labeling of the data on which they are trained. Annotating data is arduous and expensive. Additionally, data sets for image object detection may be annotated by drawing polygons, drawing bounding boxes, or providing single points on targets. Selection of annotation technique is a tradeoff between time to annotate and accuracy of the annotation. When annotating a dataset for machine object recognition algorithms, researchers may not know the most advantageous method of annotation for their experiments. This paper evaluates the performance tradeoffs of three alternative methods of annotating imagery for use in ML. A neural network was trained using the different types of annotations and compares the detection accuracy of and differences between the resultant models. In addition to the accuracy, cost is analyzed for each of the models and respective datasets."}}
{"id": "WdAM2s2Sg4Y", "cdate": 1546300800000, "mdate": 1682935651144, "content": {"title": "High-Performance Deep Learning Classification for Radio Signals", "abstract": "The ability to classify different types of signal modulations in radio transmissions is an important task with applications in defense, networking, and communications. This process has traditionally been done manually by human analysts. Recent advances have shown that applying deep learning methods to this task is feasible. But existing recognition networks are complex, with heavy computational requirements, and poor accuracy on some modulation types and in noisy environmentsWe have built a robust radio frequency signal classifier with a hybrid approach that uses images derived from signal constellation and spectrogram data, combined with an efficient convolutional neural network. Compared to the state-of-the-art deep learning classifier, our system obtains better accuracy, with lower computational requirements."}}
{"id": "Hoxg4_Rfg_TH", "cdate": 1546300800000, "mdate": null, "content": {"title": "Comparing the Effects of Annotation Type on Machine Learning Detection Performance.", "abstract": "The most prominent machine learning (ML) methods in use today are supervised, meaning they require groundtruth labeling of the data on which they are trained. Annotating data is arduous and expensive. Additionally, data sets for image object detection may be annotated by drawing polygons, drawing bounding boxes, or providing single points on targets. Selection of annotation technique is a tradeoff between time to annotate and accuracy of the annotation. When annotating a dataset for machine object recognition algorithms, researchers may not know the most advantageous method of annotation for their experiments. This paper evaluates the performance tradeoffs of three alternative methods of annotating imagery for use in ML. A neural network was trained using the different types of annotations and compares the detection accuracy of and differences between the resultant models. In addition to the accuracy, cost is analyzed for each of the models and respective datasets."}}
{"id": "-oCXtrUvJ6G", "cdate": 1483228800000, "mdate": null, "content": {"title": "Generative Adversarial Networks for Classification", "abstract": "Our team is reviewing tools and techniques that enable rapid prototyping. Generative Adversarial Networks (GANs) have been shown to reduce training requirements for detection problems. GANs compete generative and discriminative classifiers to improve detection performance. This paper expands the use of GANs from detection (k=2) to classification (k>2) problems. Several GAN network structures and training set sizes were compared to the baseline discriminative network and Bayes' classifiers. The results show no significant performance differences among any of the network configurations or training set size trials. However, the GANs trained with fewer network nodes and iterations than needed by the discriminator classifiers alone."}}
{"id": "etFRjFL7cdD", "cdate": 1262304000000, "mdate": null, "content": {"title": "Training and feature-reduction techniques for human identification using anthropometry", "abstract": "We investigate the utility of ID anthropometric measurements as a biometric for human identification when the subject pose differs in probe and gallery data. Whereas previous studies simulated probe data by adding noise to 3D gallery data, prior to extracting 1D measurements, we use a large 3D full-body data set having multiple poses per subject. Our analysis of 27 measurements from 2,144 subjects reveals differences due to pose, sensor, and other sources-all of which degrade recognition accuracy if uncompensated. We develop new training methods that use small sets of training data to measure and compensate for these differences. The new methods enable rank-1 identification >95% using 27 features and as few as 20 training subjects. To characterize the relative utility of the features and to simplify the biometric system, we develop techniques to identify feature subsets that together achieve good recognition performance. The reduction techniques demonstrate rank-1 identification of 83% and 94% using just ten and fifteen features. Together, these results will guide the development of more effective, accurate, and efficient anthropometry-based recognition systems."}}
{"id": "e6m9nHgKaf3", "cdate": 1230768000000, "mdate": null, "content": {"title": "Overhead imagery research data set - an annotated data library & tools to aid in the development of computer vision algorithms", "abstract": "When failures occur in machine object recognition algorithms, researchers may have limited information on the root causes of the failure. For example, did the algorithm fail to detect a target due to occlusion, shadow, contrast, or some other known computer vision shortcoming? The Overhead Imagery Research Data Set (OIRDS) project will help advance the state of the art in image processing and computer vision by providing an open-access, annotated overhead imagery library that will allow researchers to break down algorithm performance by image and target attributes. The OIRDS project has produced a data set with almost 1,000 labeled images suitable for developing automated vehicle detection algorithms. These images contain approximately 1,800 labeled targets. For each target, the OIRDS provides over 30 annotations and over 60 statistics that describe the target within the context of the image."}}
{"id": "naHdTgJYeuV", "cdate": 1199145600000, "mdate": null, "content": {"title": "Overhead image statistics", "abstract": "Statistical properties of high-resolution overhead images representing different land use categories are analyzed using various local and global statistical image properties based on the shape of the power spectrum, image gradient distributions, edge co-occurrence, and inter-scale wavelet coefficient distributions. The analysis was performed on a database of high-resolution (1 meter) overhead images representing a multitude of different downtown, suburban, commercial, agricultural and wooded exemplars. Various statistical properties relating to these image categories and their relationship are discussed. The categorical variations in power spectrum contour shapes, the unique gradient distribution characteristics of wooded categories, the similarity in edge co-occurrence statistics for overhead and natural images, and the unique edge co-occurrence statistics of downtown categories are presented in this work. Though previous work on natural image statistics has showed some of the unique characteristics for different categories, the relationships for overhead images are not well understood. The statistical properties of natural images were used in previous studies to develop prior image models, to predict and index objects in a scene and to improve computer vision models. The results from our research findings can be used to augment and adapt computer vision algorithms that rely on prior image statistics to process overhead images, calibrate the performance of overhead image analysis algorithms, and derive features for better discrimination of overhead image categories."}}
{"id": "ICf_y2BH1eZ", "cdate": 1199145600000, "mdate": null, "content": {"title": "Current challenges in automating visual perception", "abstract": "After nearly half a century of computer vision research, application-specific systems are common but the goal of developing a robust, general-purpose computer vision system remains out of reach. Rather than focus on the strengths and weaknesses of current computer vision approaches, this paper will enumerate and investigate the challenges that must be overcome before this goal can be achieved. Key challenges include handling variations in environment or acquisition parameters such as lighting, view angle, distance, and image quality; recognizing naturally occurring as well as intentionally deceptive variations in object appearance; providing robust general-purpose image segmentation and co-registration; generating 3D representations from 2D images; developing useful object representations; providing required knowledge that is not represented in the image itself; and managing computational complexity. Each of these challenges, along with their relevance to solving the vision problem, will be discussed. Understanding these challenges as a whole may provide insight into underlying mechanisms that will provide the backbone of a robust general-purpose computer vision system."}}
{"id": "0Q1z8uR53gy", "cdate": 1104537600000, "mdate": null, "content": {"title": "Model-Based Methods For Steganography And Steganalysis", "abstract": "This paper presents methods for performing steganography and steganalysis using a statistical model of the cover medium. The methodology is general, and can be applied to virtually any type of medi..."}}
{"id": "xNLO_JW42yff", "cdate": 1041379200000, "mdate": null, "content": {"title": "Image denoising using learned overcomplete representations", "abstract": "We describe a method for learning sparse multiscale image representations using a sparse prior distribution over the basis function coefficients. The prior consists of a mixture of a Gaussian and a Dirac delta function, and thus encourages coefficients to have exact zero values. Coefficients for an image are computed by sampling from the resulting posterior distribution with a Gibbs sampler. Denoising using the learned image model is demonstrated for some standard test images, with results that compare favorably with other denoising methods."}}
