{"id": "nZQQTa5yJyk", "cdate": 1672531200000, "mdate": 1707782599049, "content": {"title": "Interpretable Survival Analysis for Heart Failure Risk Prediction", "abstract": "Survival analysis, or time-to-event analysis, is an important and widespread problem in healthcare research. Medical research has traditionally relied on Cox models for survival analysis, due to their simplicity and interpretability. Cox models assume a log-linear hazard function as well as proportional hazards over time, and can perform poorly when these assumptions fail. Newer survival models based on machine learning avoid these assumptions and offer improved accuracy, yet sometimes at the expense of model interpretability, which is vital for clinical use. We propose a novel survival analysis pipeline that is both interpretable and competitive with state-of-the-art survival models. Specifically, we use an improved version of survival stacking to transform a survival analysis problem to a classification problem, ControlBurn to perform feature selection, and Explainable Boosting Machines to generate interpretable predictions. To evaluate our pipeline, we predict risk of heart failure using a large-scale EHR database. Our pipeline achieves state-of-the-art performance and provides interesting and novel insights about risk factors for heart failure."}}
{"id": "lGLGouYiZR", "cdate": 1672531200000, "mdate": 1707782599049, "content": {"title": "The Missing Indicator Method: From Low to High Dimensions", "abstract": "Missing data is common in applied data science, particularly for tabular data sets found in healthcare, social sciences, and natural sciences. Most supervised learning methods only work on complete data, thus requiring preprocessing such as missing value imputation to work on incomplete data sets. However, imputation alone does not encode useful information about the missing values themselves. For data sets with informative missing patterns, the Missing Indicator Method (MIM), which adds indicator variables to indicate the missing pattern, can be used in conjunction with imputation to improve model performance. While commonly used in data science, MIM is surprisingly understudied from an empirical and especially theoretical perspective. In this paper, we show empirically and theoretically that MIM improves performance for informative missing values, and we prove that MIM does not hurt linear models asymptotically for uninformative missing values. Additionally, we find that for high-dimensional data sets with many uninformative indicators, MIM can induce model overfitting and thus test performance. To address this issue, we introduce Selective MIM (SMIM), a novel MIM extension that adds missing indicators only for features that have informative missing patterns. We show empirically that SMIM performs at least as well as MIM in general, and improves MIM for high-dimensional data. Lastly, to demonstrate the utility of MIM on real-world data science tasks, we demonstrate the effectiveness of MIM and SMIM on clinical tasks generated from the MIMIC-III database of electronic health records."}}
{"id": "NPx4mPC6YS", "cdate": 1672531200000, "mdate": 1681699644536, "content": {"title": "Cross-Frequency Time Series Meta-Forecasting", "abstract": "Meta-forecasting is a newly emerging field which combines meta-learning and time series forecasting. The goal of meta-forecasting is to train over a collection of source time series and generalize to new time series one-at-a-time. Previous approaches in meta-forecasting achieve competitive performance, but with the restriction of training a separate model for each sampling frequency. In this work, we investigate meta-forecasting over different sampling frequencies, and introduce a new model, the Continuous Frequency Adapter (CFA), specifically designed to learn frequency-invariant representations. We find that CFA greatly improves performance when generalizing to unseen frequencies, providing a first step towards forecasting over larger multi-frequency datasets."}}
{"id": "ux6_Nstizv", "cdate": 1632328762121, "mdate": null, "content": {"title": "CDF Normalization for Controlling the Distribution of Hidden Layer Activations", "abstract": "Batch Normalizaiton (BN) is a normalization method for deep neural networks that has been shown to accelerate training.  While the effectiveness of BN is undisputed, the explanation of its effectiveness is still being studied.  The original BN paper attributes the success of BN to reducing internal covariate shift, so we take this a step further and explicitly enforce a Gaussian distribution on hidden layer activations.  This approach proves to be ineffective, demonstrating further that reducing internal covariate shift is not important for successful layer normalization."}}
{"id": "c4CX1JCQTy", "cdate": 1609459200000, "mdate": 1682120037340, "content": {"title": "CDF Normalization for Controlling the Distribution of Hidden Nodes", "abstract": "Batch Normalizaiton (BN) is a normalization method for deep neural networks that has been shown to accelerate training. While the effectiveness of BN is undisputed, the explanation of its effective..."}}
