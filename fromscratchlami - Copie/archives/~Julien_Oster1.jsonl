{"id": "Q3JrvSACbO", "cdate": 1675849634560, "mdate": null, "content": {"title": "SILICONet : A Siamese Lead Invariant Convolutional Network for Ventricular Heartbeat Detection in Electrocardiograms (ECG)", "abstract": "Pretraining deep learning models on a large corpus of unlabelled data using self supervised learning approaches can be an efficient mitigation strategy to deal with the lack of annotated data. We proposed to use a siamese framework for the pretraining of a convolutional neural network on the Computing in Cardiology 2021 dataset therefore making it invariant to ECG lead configuration changes. \nThe obtained representation was then trained and tested on a heartbeat classification task on the MIT BIH Arrhythmia database, and on an external independent set, namely the INCART database. \nThe proposed model reached a median F1 score of 0.89 on the MIT BIH Arrhythmia database comparable to the 0.90 F1 score obtained without pretraining. However, the pretrained model obtained a median F1 score of 0.74 on average over the different leads, compared to 0.53 the model without pretraining.  \nThe proposed pretraining approach, leveraging the availability of relatively large database of un-(or weakly)annotated ECG data, allows for the training of more generalisable, lead-agnostic, heartbeat classification models. Such an approach would ensure avoiding overfitting complex deep learning models on the small MIT-BIH arrhythmia database.\n"}}
{"id": "jQIlKcuKB-L", "cdate": 1675849634490, "mdate": null, "content": {"title": "Post-Hoc Uncertainty Quantification for QT Interval Measurements with Ensembles of Electrocardiographic Leads and Deep Models", "abstract": "Standard electrocardiography (ECG) allows to record the electrical activity of the heart from different angles called leads. The QT interval, which corresponds to the time elapsed between the onset of ventricular contraction and the end of ventricular relaxation, is an ECG biomarker of drug cardiotoxicity. Deep neural networks (DNNs) have achieved state-of-the-art performance in QT interval measurement but are missing uncertainty quantification, which is necessary for safer decision making. Uncertainty is usually encoded in DNNs through probability distributions over model weights. In this paper, we combine this approach with notions of multisensory integration whereby neural systems account for uncertainty by optimally integrating all available sensory inputs. We thus approximate the posterior predictive distribution of the QT interval given a multi-lead ECG as a weighted average across leads (lead integration) and models (deep ensembling) and derive 100(1 \u2212 \u03b1)% Bayesian prediction intervals (PIs). We apply this method to QT-based cardiac drug safety monitoring and compare it to an adapted version of conformal prediction. The Bayesian and conformal approaches yield comparable empirical coverage (77%-82% for mean PI widths of \u223c28 milliseconds, \u03b1 = 0.1). The former is more straightforward and shows better error-based calibration. Data and code implementation are available at https://github.com/mouslyddiaw/qt-uncertainty."}}
{"id": "pkcN_HOFWRI", "cdate": 1546300800000, "mdate": null, "content": {"title": "Evaluation of Algorithms for Multi-Modality Whole Heart Segmentation: An Open-Access Grand Challenge", "abstract": "Knowledge of whole heart anatomy is a prerequisite for many clinical applications. Whole heart segmentation (WHS), which delineates substructures of the heart, can be very valuable for modeling and analysis of the anatomy and functions of the heart. However, automating this segmentation can be arduous due to the large variation of the heart shape, and different image qualities of the clinical data. To achieve this goal, a set of training data is generally needed for constructing priors or for training. In addition, it is difficult to perform comparisons between different methods, largely due to differences in the datasets and evaluation metrics used. This manuscript presents the methodologies and evaluation results for the WHS algorithms selected from the submissions to the Multi-Modality Whole Heart Segmentation (MM-WHS) challenge, in conjunction with MICCAI 2017. The challenge provides 120 three-dimensional cardiac images covering the whole heart, including 60 CT and 60 MRI volumes, all acquired in clinical environments with manual delineation. Ten algorithms for CT data and eleven algorithms for MRI data, submitted from twelve groups, have been evaluated. The results show that many of the deep learning (DL) based methods achieved high accuracy, even though the number of training datasets was limited. A number of them also reported poor results in the blinded evaluation, probably due to overfitting in their training. The conventional algorithms, mainly based on multi-atlas segmentation, demonstrated robust and stable performance, even though the accuracy is not as good as the best DL method in CT segmentation. The challenge, including the provision of the annotated training data and the blinded evaluation for submitted algorithms on the test data, continues as an ongoing benchmarking resource via its homepage (\\url{www.sdspeople.fudan.edu.cn/zhuangxiahai/0/mmwhs/})."}}
{"id": "3747a32wc9", "cdate": 1546300800000, "mdate": null, "content": {"title": "Evaluation of algorithms for Multi-Modality Whole Heart Segmentation: An open-access grand challenge", "abstract": "Highlights \u2022 This work presents the methodologies and evaluation results for the WHS algorithms selected from the submissions to the Multi-Modality Whole Heart Segmentation (MM-WHS) challenge, in conjunction with MICCAI 2017. \u2022 This work introduces the related information to the challenge, discusses the results from the conventional methods and deep learning-based algorithms, and provides insights to the future research. \u2022 The challenge provides a fair and intuitive comparison framework for methods developed and being developed for WHS. \u2022 The challenge provides the training datasets with manually delineated ground truths and evaluation for an ongoing development of MM-WHS algorithms. Abstract Knowledge of whole heart anatomy is a prerequisite for many clinical applications. Whole heart segmentation (WHS), which delineates substructures of the heart, can be very valuable for modeling and analysis of the anatomy and functions of the heart. However, automating this segmentation can be challenging due to the large variation of the heart shape, and different image qualities of the clinical data. To achieve this goal, an initial set of training data is generally needed for constructing priors or for training. Furthermore, it is difficult to perform comparisons between different methods, largely due to differences in the datasets and evaluation metrics used. This manuscript presents the methodologies and evaluation results for the WHS algorithms selected from the submissions to the Multi-Modality Whole Heart Segmentation (MM-WHS) challenge, in conjunction with MICCAI 2017. The challenge provided 120 three-dimensional cardiac images covering the whole heart, including 60 CT and 60 MRI volumes, all acquired in clinical environments with manual delineation. Ten algorithms for CT data and eleven algorithms for MRI data, submitted from twelve groups, have been evaluated. The results showed that the performance of CT WHS was generally better than that of MRI WHS. The segmentation of the substructures for different categories of patients could present different levels of challenge due to the difference in imaging and variations of heart shapes. The deep learning (DL)-based methods demonstrated great potential, though several of them reported poor results in the blinded evaluation. Their performance could vary greatly across different network structures and training strategies. The conventional algorithms, mainly based on multi-atlas segmentation, demonstrated good performance, though the accuracy and computational efficiency could be limited. The challenge, including provision of the annotated training data and the blinded evaluation for submitted algorithms on the test data, continues as an ongoing benchmarking resource via its homepage ( www.sdspeople.fudan.edu.cn/zhuangxiahai/0/mmwhs/ ). Graphical abstract Download : Download high-res image (311KB) Download : Download full-size image This manuscript presents the methodologies and evaluation results for the WHS algorithms selected from the submissions to the Multi-Modality Whole Heart Segmentation (MMWHS) challenge, in conjunction with MICCAI-STACOM 2017. The challenge provides 120 three-dimensional cardiac images covering the whole heart, including 60 CT and 60 MRI volumes, all acquired in clinical environments with manual delineation. Ten algorithms for CT data and eleven algorithms for MRI data, submitted from twelve groups, have been evaluated. The results show that many of the deep learning (DL) based methods achieved high accuracy, even though the number of training datasets were limited. Several of them also reported poor results in the blinded evaluation, probably due to over fitting in their training. The conventional algorithms, mainly based on multi-atlas segmentation, demonstrated robust and stable performance, even though the accuracy is not as good as the best DL method in CT segmentation. The challenge, including provision of the annotated training data and the blinded evaluation for submitted algorithms on the test data, continues as an ongoing benchmarking resource. Previous article in issue Next article in issue"}}
{"id": "E5k70igun_M", "cdate": 1514764800000, "mdate": null, "content": {"title": "Uncalibrated Real-Time Stroke Volume Estimation in MRI Using the Magnetohydrodynamic Effect ?", "abstract": ""}}
{"id": "U8EhkrvAtJ5", "cdate": 1483228800000, "mdate": null, "content": {"title": "Rhythm and Quality Classification from Short ECGs Recorded using a Mobile Device", "abstract": ""}}
{"id": "TqGOzkE_azX", "cdate": 1483228800000, "mdate": null, "content": {"title": "MRI Whole Heart Segmentation Using Discrete Nonlinear Registration and Fast Non-local Fusion", "abstract": "We present a robust and accurate method for multi-atlas segmentation of whole heart MRI scans. After preprocessing, which includes resampling to isotropic voxel sizes and cropping or padding to same dimensions, all training scans are registered linearly and nonlinearly to an unseen set of test scans. We employ the efficient discrete registration framework called deeds that captures large shape variations across scans, performed best in a recent registration comparison on abdominal scans and requires less than 2\u00a0min of computation time per scan. Subsequently, we perform multi-atlas label fusion using a non-local means approach with a normalised SSD metric and a fast implementation using boxfilters. Subsequently, a multi-label random walk is performed on the obtained probability maps for an edge-preserving smoothing. Without performing any domain-specific parameter tuning, we obtained a Dice accuracy of 86.0% (averaged across 7 labels) and 87.0% for the whole heart on the MRI test dataset, which is the first rank of the MICCAI 2017 challenge. The segmentations are also visually very smooth using this fully automatic method."}}
{"id": "MfxzuYZzhpS", "cdate": 1451606400000, "mdate": null, "content": {"title": "Automated ECG Ventricular Beat Detection with Switching Kalman Filters", "abstract": ""}}
{"id": "jBhbe2kh7bQ", "cdate": 1420070400000, "mdate": null, "content": {"title": "Semisupervised ECG Ventricular Beat Classification With Novelty Detection Based on Switching Kalman Filters", "abstract": "Automatic processing and accurate diagnosis of pathological electrocardiogram (ECG) signals remains a challenge. As long-term ECG recordings continue to increase in prevalence, driven partly by the ease of remote monitoring technology usage, the need to automate ECG analysis continues to grow. In previous studies, a model-based ECG filtering approach to ECG data from healthy subjects has been applied to facilitate accurate online filtering and analysis of physiological signals. We propose an extension of this approach, which models not only normal and ventricular heartbeats, but also morphologies not previously encountered. A switching Kalman filter approach is introduced to enable the automatic selection of the most likely mode (beat type), while simultaneously filtering the signal using appropriate prior knowledge. Novelty detection is also made possible by incorporating a third mode for the detection of unknown (not previously observed) morphologies, and denoted as X-factor. This new approach is compared to state-of-the-art techniques for the ventricular heartbeat classification in the MIT-BIH arrhythmia and Incart databases. F <sub xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">1</sub> scores of 98.3% and 99.5% were found on each database, respectively, which are superior to other published algorithms' results reported on the same databases. Only 3% of all the beats were discarded as X-factor, and the majority of these beats contained high levels of noise. The proposed technique demonstrates accurate beat classification in the presence of previously unseen (and unlearned) morphologies and noise, and provides an automated method for morphological analysis of arbitrary (unknown) ECG leads."}}
{"id": "oQVYM8LEh31", "cdate": 1388534400000, "mdate": null, "content": {"title": "Optimized Modelling of Maternal ECG Beats using the Stationary Wavelet Transform", "abstract": ""}}
