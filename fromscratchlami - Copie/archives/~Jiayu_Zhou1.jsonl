{"id": "jg3XzuNbS-0", "cdate": 1685624090059, "mdate": null, "content": {"title": "A Privacy-Preserving Hybrid Federated Learning Framework for Financial Crime Detection", "abstract": "The recent decade witnessed a surge of increase in financial crimes across the public and private sectors, with an average cost of scams of \\$102m to financial institutions in 2022. Developing a mechanism for battling financial crimes is an impending task that requires in-depth collaboration from multiple institutions, and yet such collaboration imposed significant technical challenges due to the privacy and security requirements of distributed financial data. For example, consider the modern payment network systems, which can generate millions of transactions per day across a large number of global institutions. Training a detection model of fraudulent transactions requires not only secured transactions but also the private account activities of those involved in each transaction from corresponding bank systems. The distributed nature of both samples and features prevents most existing learning systems from being directly adopted to handle the data mining task. In this paper, we collectively address these challenges by proposing a hybrid federated learning system that offers secure and privacy-aware learning and inference for financial crime detection. We conduct extensive empirical studies to evaluate the proposed framework's feasibility and scalability. The codes will be released in the future.\n"}}
{"id": "2c0hdQDvf5g", "cdate": 1685624089827, "mdate": null, "content": {"title": "Federated Blood Supply Chain Demand Forecasting: A Case Study", "abstract": "Blood transfusion is a commonly used, life-saving medical therapeutics worldwide. A significant challenge is the high variability of supply and demand in blood products, making it difficult to maintain a balance between preventing shortages of blood products and preventing wastage. Recent studies used data-driven methods on demand forecasting for blood products from regional and centralized databases due to regulatory restrictions, which lack the panorama view of the national blood supply and demand picture. Motivated by achieving better policy-making through national blood supply chain demand forecasting, in this paper, we propose to use federated learning (FL) to forecast the demand for platelets through a case study with simulated scenarios considering a national demand and supply network. Our solution facilitates FL with a Long-Short-Term Memory (LSTM) model to make collaborative predictions for future decision-making processes from distributed and regional time-series data. Empirical studies show that FL brings additional performance improvement in various settings, especially for regions with scarcer and shorter data histories. We release the source code for our study at https://github.com/denoslab/fl-blood-supply-chain."}}
{"id": "ePdgQEb-L5b", "cdate": 1674117634115, "mdate": 1674117634115, "content": {"title": "Patient Risk Prediction Model via Top-k Stability Selection", "abstract": "The patient risk prediction model aims at assessing therisk of a patient in developing a target disease basedon his/her health pro le. As electronic health records(EHRs) become more prevalent, a large number of fea-tures can be constructed in order to characterize pa-tient pro les.  This wealth of data provides unprece-dented opportunities for data mining researchers to ad-dress important biomedical questions.  Practical datamining challenges include: How to correctly select andrank those features based on their prediction power?What predictive model performs the best in predictinga target disease using those features?In this paper, we propose top-kstability selection,which generalizes a powerful sparse learning method forfeature selection by overcoming its limitation on pa-rameter selection.  In particular, our proposed top-kstability selection includes the original stability selec-tion method as a special case givenk= 1. Moreover,we show that the top-kstability selection is more ro-bust by utilizing more information from selection prob-abilities than the original stability selection, and pro-vides stronger theoretical properties. In a large set ofreal clinical prediction datasets, the top-kstability se-lection methods outperform many existing feature se-lection methods including the original stability selec-tion. We also compare three competitive classi cationmethods (SVM, logistic regression and random forest)to demonstrate the e ectiveness of selected features byour proposed method in the context of clinical predic-tion applications. Finally, through several clinical ap-plications on predicting heart failure related symptoms,we show that top-kstability selection can successfullyidentify important features that are clinically meaningful."}}
{"id": "osIppnySBTV", "cdate": 1663850526949, "mdate": null, "content": {"title": "DEFENDING BACKDOOR ATTACKS VIA ROBUSTNESS AGAINST NOISY LABEL", "abstract": "Many deep neural networks are vulnerable to backdoor poisoning attacks, in which an adversary strategically injects a backdoor trigger into a small fraction of the training data. The trigger can later be applied during inference to manipulate prediction labels. While the data label could be changed to arbitrary values by an adversary, the extent of corruption injected into the feature values is strictly limited to keep the backdoor attack in disguise, which leads to a resemblance between the backdoor attack and a milder attack that involves only noisy labels.\nThis paper investigates an intriguing question: \\textit{Can we leverage algorithms that defend against noisy label corruptions to defend against general backdoor attacks?} We first discuss the limitations of directly using current noisy-label defense algorithms to defend against backdoor attacks. We then propose a meta-algorithm for both supervised and semi-supervised settings that transforms an existing noisy label defense algorithm into one that protects against backdoor attacks. Extensive experiments on different settings show that, by introducing a lightweight alteration for minimax optimization to the existing noisy-label defense algorithms, the robustness against backdoor attacks can be substantially improved, while the initial form of those algorithms would fail in the presence of a backdoor attack."}}
{"id": "faPdyjayCRi", "cdate": 1663850455647, "mdate": null, "content": {"title": "Efficient Stochastic Optimization for Attacking Randomness Involved Inference", "abstract": "Recent years witnessed a surging interest in test-time defense against adversarial attacks by introducing randomness during model inference. Notable examples include randomized smoothing equipped with probabilistic certified robustness and adversarial purification that leverages score-based generalization models. Specifically, the adversarial purification achieves state-of-the-art adversarial robustness under the strongest existing attack. Perhaps the most important component to developing and validating adversarial robustness is efficient attacks. Stochastic Projected Gradient Descent (S-PGD), which combines Expectation over Transformation (EOT) and PGD attacks, has become a common strategy to attack inference randomness and validate defense strategies. However, it often has severe efficiency issues that make it prohibitive for complete verification. For example, one step of S-PGD requires multiple runs of score-based purification models for each data point. This work revisits the techniques attacking randomness-involved inference and subsumes them into a unified stochastic optimization framework, which enables us to use acceleration and variance reduction techniques to largely improve the convergence and thus reduce the cost of attack. In other words, the proposed work can significantly improve attack performance, given a fixed budget for attacking. "}}
{"id": "l2FXO1RJ5Hs", "cdate": 1663850224460, "mdate": null, "content": {"title": "Precautionary Unfairness in Self-Supervised Contrastive Pre-training", "abstract": "Recently, self-supervised contrastive pre-training has become the de facto regime, that allows for efficient downstream fine-tuning. Meanwhile, its fairness issues are barely studied, though they have drawn great attention from the machine learning community,\nwhere structured biases in data can lead to biased predictions against under-presented groups. Most existing fairness metrics and algorithms focus on supervised settings, e.g., based on disparities in prediction performance, and they become inapplicable in the absence of supervision. We are thus interested in the challenging question: how does the pre-training representation (un)fairness transfer to the downstream task (un)fairness, and can we define and pursue fairness in unsupervised pre-training? Firstly, we empirically show that imbalanced groups in the pre-training data indeed lead to unfairness in the pre-trained representations, and that cannot be easily fixed by fairness-aware fine-tuning without sacrificing efficiency. Secondly, motivated by the observation that the majority group of the pre-training data dominates the learned representations, we design the first unfairness metric that can be applicable to self-supervised learning, and leverage that to guide the contrastive pre-training for fairness-aware representations. Our experiments demonstrate that the underestimated representation disparities strike over 10% surges on the proposed metric and our algorithm improves 10 out of 13 tasks on the 1%-labeled CelebA dataset. Codes will be released upon acceptance. \n"}}
{"id": "mMNimwRb7Gr", "cdate": 1663850131651, "mdate": null, "content": {"title": "Turning the Curse of Heterogeneity in Federated Learning into a Blessing for Out-of-Distribution Detection", "abstract": "Deep neural networks have witnessed huge successes in many challenging prediction tasks and yet they often suffer from out-of-distribution (OoD) samples, misclassifying them with high confidence. Recent advances show promising OoD detection performance for centralized training, and however, OoD detection in federated learning (FL) is largely overlooked, even though many security sensitive applications such as autonomous driving and voice recognition authorization are commonly trained using FL for data privacy concerns. The main challenge that prevents previous state-of-the-art OoD detection methods from being incorporated to FL is that they require large amount of real OoD samples. However, in real-world scenarios, such large-scale OoD training data can be costly or even infeasible to obtain, especially for resource-limited local devices. On the other hand, a notorious challenge in FL is data heterogeneity where each client collects non-identically and independently distributed (non-iid) data. We propose to take advantage of such heterogeneity and turn the curse into a blessing that facilitates OoD detection in FL. The key is that for each client, non-iid data from other clients (unseen external classes) can serve as an alternative to real OoD samples. Specifically, we propose a novel Federated Out-of-Distribution Synthesizer (FOSTER), which learns a class-conditional generator to synthesize virtual external-class OoD samples, and maintains data confidentiality and communication efficiency required by FL. Experimental results show that our method outperforms the state-of-the-art by 2.49%, 2.88%, 1.42% AUROC, and 0.01%, 0.89%, 1.74% ID accuracy, on CIFAR-10, CIFAR-100, and STL10, respectively."}}
{"id": "N92hjSf5NNh", "cdate": 1663849860445, "mdate": null, "content": {"title": "MECTA: Memory-Economic Continual Test-Time Model Adaptation", "abstract": "Continual Test-time Adaptation (CTA) is a promising art to secure accuracy gains in continually-changing environments. The state-of-the-art adaptations improve out-of-distribution model accuracy via computation-efficient online test-time gradient descents but meanwhile cost about times of memory versus the inference, even if only a small portion of parameters are updated. Such high memory consumption of CTA substantially impedes wide applications of advanced CTA on memory-constrained devices. In this paper, we provide a novel solution, dubbed MECTA, to drastically improve the memory efficiency of gradient-based CTA. Our profiling shows that the major memory overhead comes from the intermediate cache for back-propagation, which scales by the batch size, channel, and layer number. Therefore, we propose to reduce batch sizes, adopt an adaptive normalization layer to maintain stable and accurate predictions, and stop the back-propagation caching heuristically. On the other hand, we prune the networks to reduce the computation and memory overheads in optimization and recover the parameters afterward to avoid forgetting. The proposed MECTA is efficient and can be seamlessly plugged into state-of-the-art CTA algorithms at negligible overhead on computation and memory. On three datasets, CIFAR10, CIFAR100, and ImageNet, MECTA improves the accuracy by at least 6% with constrained memory and significantly reduces the memory costs of ResNet50 on ImageNet by at least 70% with comparable accuracy. Our codes can be accessed at https://github.com/SonyAI/MECTA."}}
{"id": "C6Iin6nXJy", "cdate": 1652737448516, "mdate": null, "content": {"title": "Outsourcing Training without Uploading Data via Efficient Collaborative Open-Source Sampling", "abstract": "As deep learning blooms with growing demand for computation and data resources, outsourcing model training to a powerful cloud server becomes an attractive alternative to training at a low-power and cost-effective end device. Traditional outsourcing requires uploading device data to the cloud server, which can be infeasible in many real-world applications due to the often sensitive nature of the collected data and the limited communication bandwidth. To tackle these challenges, we propose to leverage widely available open-source data, which is a massive dataset collected from public and heterogeneous sources (e.g., Internet images). We develop a novel strategy called Efficient Collaborative Open-source Sampling (ECOS) to construct a proximal proxy dataset from open-source data for cloud training, in lieu of client data. ECOS probes open-source data on the cloud server to sense the distribution of client data via a communication- and computation-efficient sampling process, which only communicates a few compressed public features and client scalar responses. Extensive empirical studies show that the proposed ECOS improves the quality of automated client labeling, model compression, and label outsourcing when applied in various learning scenarios. Source codes will be released."}}
{"id": "h10xdBrOxNI", "cdate": 1652737281297, "mdate": null, "content": {"title": "Trap and Replace: Defending Backdoor Attacks by Trapping Them into an Easy-to-Replace Subnetwork", "abstract": "Deep neural networks (DNNs) are vulnerable to backdoor attacks. Previous works have shown it extremely challenging to unlearn the undesired backdoor behavior from the network, since the entire network can be affected by the backdoor samples. In this paper, we propose a brand-new backdoor defense strategy, which makes it much easier to remove the harmful influence of backdoor samples from the model. Our defense strategy, \\emph{Trap and Replace}, consists of two stages. In the first stage, we bait and trap the backdoors in a small and easy-to-replace subnetwork. Specifically, we add an auxiliary image reconstruction head on top of the stem network shared with a light-weighted classification head. The intuition is that the auxiliary image reconstruction task encourages the stem network to keep sufficient low-level visual features that are hard to learn but semantically correct, instead of overfitting to the easy-to-learn but semantically incorrect backdoor correlations.  As a result, when trained on backdoored datasets, the backdoors are easily baited towards the unprotected classification head, since it is much more vulnerable than the shared stem, leaving the stem network hardly poisoned. In the second stage, we replace the poisoned light-weighted classification head with an untainted one, by re-training it from scratch only on a small holdout dataset with clean samples, while fixing the stem network. As a result, both the stem and the classification head in the final network are hardly affected by backdoor training samples. We evaluate our method against ten different backdoor attacks. Our method outperforms previous state-of-the-art methods by up to $20.57\\%$, $9.80\\%$, and $13.72\\%$ attack success rate and on-average $3.14\\%$, $1.80\\%$, and $1.21\\%$ clean classification accuracy on CIFAR10, GTSRB, and ImageNet-12, respectively. Code is available at https://github.com/VITA-Group/Trap-and-Replace-Backdoor-Defense."}}
