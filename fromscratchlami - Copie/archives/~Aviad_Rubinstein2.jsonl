{"id": "dZQ38SrZEM", "cdate": 1640995200000, "mdate": 1655210970926, "content": {"title": "Maximizing Non-Monotone Submodular Functions over Small Subsets: Beyond 1/2-Approximation", "abstract": "In this work we give two new algorithms that use similar techniques for (non-monotone) submodular function maximization subject to a cardinality constraint. The first is an offline fixed parameter tractable algorithm that guarantees a $0.539$-approximation for all non-negative submodular functions. The second algorithm works in the random-order streaming model. It guarantees a $(1/2+c)$-approximation for symmetric functions, and we complement it by showing that no space-efficient algorithm can beat $1/2$ for asymmetric functions. To the best of our knowledge this is the first provable separation between symmetric and asymmetric submodular function maximization."}}
{"id": "OprO2tHrW4_", "cdate": 1640995200000, "mdate": 1655210971002, "content": {"title": "Budget-Smoothed Analysis for Submodular Maximization", "abstract": "The greedy algorithm for monotone submodular function maximization subject to cardinality constraint is guaranteed to approximate the optimal solution to within a 1-1/e factor. Although it is well known that this guarantee is essentially tight in the worst case - for greedy and in fact any efficient algorithm, experiments show that greedy performs better in practice. We observe that for many applications in practice, the empirical distribution of the budgets (i.e., cardinality constraints) is supported on a wide range, and moreover, all the existing hardness results in theory break under a large perturbation of the budget. To understand the effect of the budget from both algorithmic and hardness perspectives, we introduce a new notion of budget-smoothed analysis. We prove that greedy is optimal for every budget distribution, and we give a characterization for the worst-case submodular functions. Based on these results, we show that on the algorithmic side, under realistic budget distributions, greedy and related algorithms enjoy provably better approximation guarantees, that hold even for worst-case functions, and on the hardness side, there exist hard functions that are fairly robust to all the budget distributions."}}
{"id": "7_t4Gvubkeo", "cdate": 1621629771089, "mdate": null, "content": {"title": "Cardinality constrained submodular maximization for random streams", "abstract": "We consider the problem of maximizing submodular functions in single-pass streaming and secretaries-with-shortlists models, both with random arrival order.\nFor cardinality constrained monotone functions, Agrawal, Shadravan, and Stein~\\cite{SMC19} gave a single-pass $(1-1/e-\\varepsilon)$-approximation algorithm using only linear memory, but their exponential dependence on $\\varepsilon$ makes it impractical even for $\\varepsilon=0.1$.\nWe simplify both the algorithm and the analysis, obtaining an exponential improvement in the $\\varepsilon$-dependence (in particular, $O(k/\\varepsilon)$ memory).\nExtending these techniques, we also give a simple $(1/e-\\varepsilon)$-approximation for non-monotone functions in $O(k/\\varepsilon)$ memory. For the monotone case, we also give a corresponding unconditional hardness barrier of $1-1/e+\\varepsilon$ for single-pass algorithms in randomly ordered streams, even assuming unlimited computation. \n\nFinally, we show that the algorithms are simple to implement and work well on real world datasets."}}
{"id": "zp0C3LGrk4C", "cdate": 1609459200000, "mdate": 1655210971037, "content": {"title": "The Randomized Communication Complexity of Randomized Auctions", "abstract": "We study the communication complexity of incentive compatible auction-protocols between a monopolist seller and a single buyer with a combinatorial valuation function over $n$ items. Motivated by the fact that revenue-optimal auctions are randomized [Tha04,MV10,BCKW10,Pav11,HR15] (as well as by an open problem of Babaioff, Gonczarowski, and Nisan [BGN17]),we focus on the randomized communication complexity of this problem (in contrast to most prior work on deterministic communication). We design simple, incentive compatible, and revenue-optimal auction-protocols whose expected communication complexity is much (in fact infinitely) more efficient than their deterministic counterparts. We also give nearly matching lower bounds on the expected communication complexity of approximately-revenue-optimal auctions. These results follow from a simple characterization of incentive compatible auction-protocols that allows us to prove lower bounds against randomized auction-protocols. In particular, our lower bounds give the first approximation-resistant, exponential separation between communication complexity of incentivizing vs implementing a Bayesian incentive compatible social choice rule, settling an open question of Fadel and Segal [FS09]."}}
{"id": "uxA9kOV2eSi", "cdate": 1609459200000, "mdate": 1655210970947, "content": {"title": "The Strongish Planted Clique Hypothesis and Its Consequences", "abstract": "We formulate a new hardness assumption, the Strongish Planted Clique Hypothesis (SPCH), which postulates that any algorithm for planted clique must run in time n^\u03a9(log n) (so that the state-of-the-art running time of n^O(log n) is optimal up to a constant in the exponent). We provide two sets of applications of the new hypothesis. First, we show that SPCH implies (nearly) tight inapproximability results for the following well-studied problems in terms of the parameter k: Densest k-Subgraph, Smallest k-Edge Subgraph, Densest k-Subhypergraph, Steiner k-Forest, and Directed Steiner Network with k terminal pairs. For example, we show, under SPCH, that no polynomial time algorithm achieves o(k)-approximation for Densest k-Subgraph. This inapproximability ratio improves upon the previous best k^o(1) factor from (Chalermsook et al., FOCS 2017). Furthermore, our lower bounds hold even against fixed-parameter tractable algorithms with parameter k. Our second application focuses on the complexity of graph pattern detection. For both induced and non-induced graph pattern detection, we prove hardness results under SPCH, improving the running time lower bounds obtained by (Dalirrooyfard et al., STOC 2019) under the Exponential Time Hypothesis."}}
{"id": "rvjVkQJwOv", "cdate": 1609459200000, "mdate": 1655210970982, "content": {"title": "Cardinality constrained submodular maximization for random streams", "abstract": "We consider the problem of maximizing submodular functions in single-pass streaming and secretaries-with-shortlists models, both with random arrival order. For cardinality constrained monotone functions, Agrawal, Shadravan, and Stein gave a single-pass $(1-1/e-\\varepsilon)$-approximation algorithm using only linear memory, but their exponential dependence on $\\varepsilon$ makes it impractical even for $\\varepsilon=0.1$. We simplify both the algorithm and the analysis, obtaining an exponential improvement in the $\\varepsilon$-dependence (in particular, $O(k/\\varepsilon)$ memory). Extending these techniques, we also give a simple $(1/e-\\varepsilon)$-approximation for non-monotone functions in $O(k/\\varepsilon)$ memory. For the monotone case, we also give a corresponding unconditional hardness barrier of $1-1/e+\\varepsilon$ for single-pass algorithms in randomly ordered streams, even assuming unlimited computation. Finally, we show that the algorithms are simple to implement and work well on real world datasets."}}
{"id": "qPUL61aW0WI", "cdate": 1609459200000, "mdate": 1655210971033, "content": {"title": "Budget-Smoothed Analysis for Submodular Maximization", "abstract": "The greedy algorithm for monotone submodular function maximization subject to cardinality constraint is guaranteed to approximate the optimal solution to within a $1-1/e$ factor. Although it is well known that this guarantee is essentially tight in the worst case -- for greedy and in fact any efficient algorithm, experiments show that greedy performs better in practice. We observe that for many applications in practice, the empirical distribution of the budgets (i.e., cardinality constraints) is supported on a wide range, and moreover, all the existing hardness results in theory break under a large perturbation of the budget. To understand the effect of the budget from both algorithmic and hardness perspectives, we introduce a new notion of budget smoothed analysis. We prove that greedy is optimal for every budget distribution, and we give a characterization for the worst-case submodular functions. Based on these results, we show that on the algorithmic side, under realistic budget distributions, greedy and related algorithms enjoy provably better approximation guarantees, that hold even for worst-case functions, and on the hardness side, there exist hard functions that are fairly robust to all the budget distributions."}}
{"id": "ntLVR__qryA", "cdate": 1609459200000, "mdate": 1655210971063, "content": {"title": "Cardinality constrained submodular maximization for random streams", "abstract": "We consider the problem of maximizing submodular functions in single-pass streaming and secretaries-with-shortlists models, both with random arrival order.For cardinality constrained monotone functions, Agrawal, Shadravan, and Stein~\\cite{SMC19} gave a single-pass $(1-1/e-\\varepsilon)$-approximation algorithm using only linear memory, but their exponential dependence on $\\varepsilon$ makes it impractical even for $\\varepsilon=0.1$.We simplify both the algorithm and the analysis, obtaining an exponential improvement in the $\\varepsilon$-dependence (in particular, $O(k/\\varepsilon)$ memory).Extending these techniques, we also give a simple $(1/e-\\varepsilon)$-approximation for non-monotone functions in $O(k/\\varepsilon)$ memory. For the monotone case, we also give a corresponding unconditional hardness barrier of $1-1/e+\\varepsilon$ for single-pass algorithms in randomly ordered streams, even assuming unlimited computation. Finally, we show that the algorithms are simple to implement and work well on real world datasets."}}
{"id": "brxj2XnLxm2", "cdate": 1609459200000, "mdate": 1655210970910, "content": {"title": "The randomized communication complexity of revenue maximization", "abstract": "We study the communication complexity of incentive compatible auction-protocols between a monopolist seller and a single buyer with a combinatorial valuation function over n items [Rubinstein and Zhao 2021]. Motivated by the fact that revenue-optimal auctions are randomized [Thanassoulis 2004; Manelli and Vincent 2010; Briest et al. 2010; Pavlov 2011; Hart and Reny 2015] (as well as by an open problem of Babaioff, Gonczarowski, and Nisan [Babaioff et al. 2017]), we focus on the randomized communication complexity of this problem (in contrast to most prior work on deterministic communication). We design simple, incentive compatible, and revenue-optimal auction-protocols whose expected communication complexity is much (in fact infinitely) more efficient than their deterministic counterparts. We also give nearly matching lower bounds on the expected communication complexity of approximately-revenue-optimal auctions. These results follow from a simple characterization of incentive compatible auction-protocols that allows us to prove lower bounds against randomized auction-protocols. In particular, our lower bounds give the first approximation-resistant, exponential separation between communication complexity of incentivizing vs implementing a Bayesian incentive compatible social choice rule, settling an open question of Fadel and Segal [Fadel and Segal 2009]."}}
{"id": "_T5E2v-XhJu", "cdate": 1609459200000, "mdate": 1655210971148, "content": {"title": "The randomized communication complexity of randomized auctions", "abstract": "We study the communication complexity of incentive compatible auction-protocols between a monopolist seller and a single buyer with a combinatorial valuation function over n items. Motivated by the fact that revenue-optimal auctions are randomized (as well as by an open problem of Babaioff, Gonczarowski, and Nisan), we focus on the randomized communication complexity of this problem (in contrast to most prior work on deterministic communication). We design simple, incentive compatible, and revenue-optimal auction-protocols whose expected communication complexity is much (in fact infinitely) more efficient than their deterministic counterparts. We also give nearly matching lower bounds on the expected communication complexity of approximately-revenue-optimal auctions. These results follow from a simple characterization of incentive compatible auction-protocols that allows us to prove lower bounds against randomized auction-protocols. In particular, our lower bounds give the first approximation-resistant, exponential separation between communication complexity of incentivizing vs implementing a Bayesian incentive compatible social choice rule, settling an open question of Fadel and Segal."}}
