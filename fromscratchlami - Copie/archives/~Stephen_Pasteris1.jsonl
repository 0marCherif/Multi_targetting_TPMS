{"id": "S9NmGEMkn29", "cdate": 1621629922339, "mdate": null, "content": {"title": "A Gang of Adversarial Bandits", "abstract": "We consider running multiple instances of multi-armed bandit (MAB) problems in parallel. \nA main motivation for this study are online recommendation systems, in which each of $N$ users is associated with a MAB problem and the goal is to exploit users' similarity in order to learn users' preferences to $K$ items more efficiently. We consider the adversarial MAB setting, whereby an adversary is free to choose which user and which loss to present to the learner during the learning process. Users are in a social network and the learner is aided by a-priori knowledge of the strengths of the social links between all pairs of users. It is assumed that if the social link between two users is strong then they tend to share the same action. The regret is measured relative to an arbitrary function which maps users to actions. The smoothness of the function is captured by a resistance-based dispersion measure $\\Psi$. We present two learning algorithms, GABA-I and GABA-II, which exploit the network structure to bias towards functions of low $\\Psi$  values. We show that GABA-I has an expected regret bound of $\\mathcal{O}(\\sqrt{\\ln(NK/\\Psi)\\Psi KT})$ and per-trial time complexity of $\\mathcal{O}(K\\ln(N))$, whilst GABA-II has a weaker $\\mathcal{O}(\\sqrt{\\ln(N/\\Psi)\\ln(NK/\\Psi)\\Psi KT})$ regret, but a better $\\mathcal{O}(\\ln(K)\\ln(N))$ per-trial time complexity. We highlight improvements of both algorithms over running independent standard MABs across users."}}
{"id": "IEniJ8TiV1", "cdate": 1621629819668, "mdate": null, "content": {"title": "Cooperative Stochastic Bandits with Asynchronous Agents and Constrained Feedback", "abstract": "This paper studies a cooperative multi-armed bandit problem with $M$ agents cooperating together to solve the same instance of a $K$-armed stochastic bandit problem with the goal of maximizing the cumulative reward of agents. The agents are heterogeneous in (i) their limited access to a local subset of arms; and (ii) their decision-making rounds, i.e., agents are asynchronous with different decision-making gaps. \nThe goal is to find the global optimal arm and agents are able to pull any arm, however, they observe the reward only when the selected arm is local.\nThe challenge is a tradeoff for agents between pulling a local arm with the possibility of observing the feedback, or relying on the observations of other agents that might occur at different rates. Naive extensions of traditional algorithms lead to an arbitrarily poor regret as a function of aggregate action frequency of any $\\textit{suboptimal}$ arm located in slow agents. We resolve this issue by proposing a novel two-stage learning algorithm, called $\\texttt{CO-LCB}$ algorithm, whose regret is a function of aggregate action frequency of agents containing the $\\textit{optimal}$ arm. We also show that the regret of $\\texttt{CO-LCB}$ matches the regret lower bound up to a small factor."}}
{"id": "Sk-6fuZuWH", "cdate": 1451606400000, "mdate": null, "content": {"title": "Mistake Bounds for Binary Matrix Completion", "abstract": "We study the problem of completing a binary matrix in an online learning setting. On each trial we predict a matrix entry and then receive the true entry. We propose a Matrix Exponentiated Gradient algorithm [1] to solve this problem. We provide a mistake bound for the algorithm, which scales with the margin complexity [2, 3] of the underlying matrix. The bound suggests an interpretation where each row of the matrix is a prediction task over a finite set of objects, the columns. Using this we show that the algorithm makes a number of mistakes which is comparable up to a logarithmic factor to the number of mistakes made by the Kernel Perceptron with an optimal kernel in hindsight. We discuss applications of the algorithm to predicting as well as the best biclustering and to the problem of predicting the labeling of a graph without knowing the graph in advance."}}
{"id": "S1ZEavZuWS", "cdate": 1420070400000, "mdate": null, "content": {"title": "Online Prediction at the Limit of Zero Temperature", "abstract": "We design an online algorithm to classify the vertices of a graph. Underpinning the algorithm is the probability distribution of an Ising model isomorphic to the graph. Each classification is based on predicting the label with maximum marginal probability in the limit of zero-temperature with respect to the labels and vertices seen so far. Computing these classifications is unfortunately based on a $\\#P$-complete problem. This motivates us to develop an algorithm for which we give a sequential guarantee in the online mistake bound framework. Our algorithm is optimal when the graph is a tree matching the prior results in [1].For a general graph, the algorithm exploits the additional connectivity over a tree to provide a per-cluster bound. The algorithm is efficient as the cumulative time to sequentially predict all of the vertices of the graph is quadratic in the size of the graph."}}
{"id": "HyZUHDZuWB", "cdate": 1325376000000, "mdate": null, "content": {"title": "Online Sum-Product Computation Over Trees", "abstract": "We consider the problem of performing efficient sum-product computations in an online setting over a tree. A natural application of our methods is to compute the marginal distribution at a vertex in a tree-structured Markov random field. Belief propagation can be used to solve this problem, but requires time linear in the size of the tree, and is therefore too slow in an online setting where we are continuously receiving new data and computing individual marginals. With our method we aim to update the data and compute marginals in time that is no more than logarithmic in the size of the tree, and is often significantly less. We accomplish this via a hierarchical covering structure that caches previous local sum-product computations. Our contribution is three-fold: we i) give a linear time algorithm to find an optimal hierarchical cover of a tree; ii) give a sum-productlike algorithm to efficiently compute marginals with respect to this cover; and iii) apply \"i\" and \"ii\" to find an efficient algorithm with a regret bound for the online allocation problem in a multi-task setting."}}
