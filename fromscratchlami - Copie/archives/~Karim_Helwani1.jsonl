{"id": "aBV8Glc4nl", "cdate": 1674802332309, "mdate": 1674802332309, "content": {"title": "The synthesis of sound figures", "abstract": "In this paper we discuss a novel technique to control the spatial distribution of sound level within a synthesized sound field. The problem is formulated by separating the sound field into regions with high acoustic level, so-called bright regions, and zones with low acoustic level (zones of quiet) by time independent virtual boundaries. This way, the propagating sound field obtains a static spatial shape, which we call sound figure. This problem is treated with a generic approach for creating sound figures. We give an analytic solution to the problem and highlight, how our findings can be applied using established sound field synthesis techniques. We furthermore show the limitations of our approach, provide simulation results to prove the concept and discuss some application areas."}}
{"id": "NL0xwGKD7Zo", "cdate": 1640995200000, "mdate": 1648927322082, "content": {"title": "Robust Audio Anomaly Detection", "abstract": "We propose an outlier robust multivariate time series model which can be used for detecting previously unseen anomalous sounds based on noisy training data. The presented approach doesn't assume the presence of labeled anomalies in the training dataset and uses a novel deep neural network architecture to learn the temporal dynamics of the multivariate time series at multiple resolutions while being robust to contaminations in the training dataset. The temporal dynamics are modeled using recurrent layers augmented with attention mechanism. These recurrent layers are built on top of convolutional layers allowing the network to extract features at multiple resolutions. The output of the network is an outlier robust probability density function modeling the conditional probability of future samples given the time series history. State-of-the-art approaches using other multiresolution architectures are contrasted with our proposed approach. We validate our solution using publicly available machine sound datasets. We demonstrate the effectiveness of our approach in anomaly detection by comparing against several state-of-the-art models."}}
{"id": "JlIMIkJI8hj", "cdate": 1609459200000, "mdate": 1648927322200, "content": {"title": "Enhancing Audio Augmentation Methods with Consistency Learning", "abstract": "Data augmentation is an inexpensive way to increase training data diversity, and is commonly achieved via transformations of existing data. For tasks such as classification, there is a good case for learning representations of the data that are invariant to such transformations, yet this is not explicitly enforced by classification losses such as the cross-entropy loss. This paper investigates the use of training objectives that explicitly impose this consistency constraint, and how it can impact downstream audio classification tasks. In the context of deep convolutional neural networks in the supervised setting, we show empirically that certain measures of consistency are not implicitly captured by the cross-entropy loss, and that incorporating such measures into the loss function can improve the performance of tasks such as audio tagging. Put another way, we demonstrate how existing augmentation methods can further improve learning by enforcing consistency."}}
{"id": "JRfa_22OPR0", "cdate": 1609459200000, "mdate": 1648927322096, "content": {"title": "Low-Complexity, Real-Time Joint Neural Echo Control and Speech Enhancement Based On Percepnet", "abstract": "Speech enhancement algorithms based on deep learning have greatly surpassed their traditional counterparts and are now being considered for the task of removing acoustic echo from hands-free communication systems. This is a challenging problem due to both real-world constraints like loudspeaker non-linearities, and to limited compute capabilities in some communication systems. In this work, we propose a system combining a traditional acoustic echo canceller, and a low-complexity joint residual echo and noise suppressor based on a hybrid signal processing/deep neural network (DSP/DNN) approach. We show that the proposed system outperforms both traditional and other neural approaches, while requiring only 5.5% CPU for real-time operation. We further show that the system can scale to even lower complexity levels."}}
{"id": "9q2ddTxqww-", "cdate": 1609459200000, "mdate": 1648927322186, "content": {"title": "Enhancing Audio Augmentation Methods with Consistency Learning", "abstract": "Data augmentation is an inexpensive way to increase training data diversity and is commonly achieved via transformations of existing data. For tasks such as classification, there is a good case for learning representations of the data that are invariant to such transformations, yet this is not explicitly enforced by classification losses such as the cross-entropy loss. This paper investigates the use of training objectives that explicitly impose this consistency constraint and how it can impact downstream audio classification tasks. In the context of deep convolutional neural networks in the supervised setting, we show empirically that certain measures of consistency are not implicitly captured by the cross-entropy loss and that incorporating such measures into the loss function can improve the performance of audio classification systems. Put another way, we demonstrate how existing augmentation methods can further improve learning by enforcing consistency."}}
{"id": "vxKf3MOO6vC", "cdate": 1577836800000, "mdate": 1648927322093, "content": {"title": "PoCoNet: Better Speech Enhancement with Frequency-Positional Embeddings, Semi-Supervised Conversational Data, and Biased Loss", "abstract": "Neural network applications generally benefit from larger-sized models, but for current speech enhancement models, larger scale networks often suffer from decreased robustness to the variety of real-world use cases beyond what is encountered in training data. We introduce several innovations that lead to better large neural networks for speech enhancement. The novel PoCoNet architecture is a convolutional neural network that, with the use of frequency-positional embeddings, is able to more efficiently build frequency-dependent features in the early layers. A semi-supervised method helps increase the amount of conversational training data by pre-enhancing noisy datasets, improving performance on real recordings. A new loss function biased towards preserving speech quality helps the optimization better match human perceptual opinions on speech quality. Ablation experiments and objective and human opinion metrics show the benefits of the proposed improvements."}}
{"id": "ltQsh53hjQg", "cdate": 1577836800000, "mdate": 1648927322198, "content": {"title": "Group Masked Autoencoder Based Density Estimator for Audio Anomaly Detection", "abstract": ""}}
{"id": "iKe67aDw-4H", "cdate": 1577836800000, "mdate": 1648927322099, "content": {"title": "A Perceptually-Motivated Approach for Low-Complexity, Real-Time Enhancement of Fullband Speech", "abstract": "Over the past few years, speech enhancement methods based on deep learning have greatly surpassed traditional methods based on spectral subtraction and spectral estimation. Many of these new techniques operate directly in the the short-time Fourier transform (STFT) domain, resulting in a high computational complexity. In this work, we propose PercepNet, an efficient approach that relies on human perception of speech by focusing on the spectral envelope and on the periodicity of the speech. We demonstrate high-quality, real-time enhancement of fullband (48 kHz) speech with less than 5% of a CPU core."}}
{"id": "aiPVJlKiBC", "cdate": 1577836800000, "mdate": 1648927322082, "content": {"title": "PoCoNet: Better Speech Enhancement with Frequency-Positional Embeddings, Semi-Supervised Conversational Data, and Biased Loss", "abstract": "Neural network applications generally benefit from larger-sized models, but for current speech enhancement models, larger scale networks often suffer from decreased robustness to the variety of real-world use cases beyond what is encountered in training data. We introduce several innovations that lead to better large neural networks for speech enhancement. The novel PoCoNet architecture is a convolutional neural network that, with the use of frequency-positional embeddings, is able to more efficiently build frequency-dependent features in the early layers. A semi-supervised method helps increase the amount of conversational training data by pre-enhancing noisy datasets, improving performance on real recordings. A new loss function biased towards preserving speech quality helps the optimization better match human perceptual opinions on speech quality. Ablation experiments and objective and human opinion metrics show the benefits of the proposed improvements."}}
{"id": "RjXk3yst6IK", "cdate": 1577836800000, "mdate": 1648927322186, "content": {"title": "Self-Supervised Classification for Detecting Anomalous Sounds", "abstract": ""}}
