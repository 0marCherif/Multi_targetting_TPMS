{"id": "QmrHMnzJG0-", "cdate": 1675560548390, "mdate": null, "content": {"title": "Backdoor Attacks Against Transformers with Attention Enhancement", "abstract": "With the popularity of transformers in natural language processing (NLP) applications, there are growing concerns about their security. Most existing NLP attack methods focus on injecting stealthy trigger words/phrases. In this paper, we focus on the interior structure of neural networks and the Trojan mechanism. Focusing on the prominent NLP transformer models, we propose a novel Trojan Attention Loss (TAL), which enhances the Trojan behavior by directly manipulating the attention pattern. TAL significantly improves the attack efficacy; it achieves better successful rates and uses a much smaller poisoning rate (i.e., a smaller proportion of poisoned samples). It boosts attack efficacy for not only traditional dirty-label attacks, but also the more challenging clean-label attacks. TAL is compatible with existing attack methods and can be easily adapted to different backbone transformer models."}}
{"id": "kwICnhvbyG", "cdate": 1675560548327, "mdate": null, "content": {"title": "On the Existence of a Trojaned Twin Model", "abstract": "We study the Trojan Attack problem, where malicious attackers sabotage deep neural network models with poisoned training data. In most existing works, the effectiveness of the attack is largely overlooked; many attacks can be ineffective or inefficient for certain training schemes, e.g., adversarial training.\nIn this paper, we adopt a novel perspective by looking into the quantitative relationship between a clean model and its Trojaned counterpart. We formulate a successful attack using classic machine learning language, namely a universal Trojan trigger intrinsic to the data distribution. Theoretically, we prove that, under mild assumptions, there exists a Trojaned model, {named Trojaned Twin}, that is very close to the clean model in the output space. Practically, we show that these results have powerful implications since the Trojaned twin model has enhanced attack efficacy and strong resiliency against detection. Empirically, we illustrate the consistent attack efficacy of the proposed method across different training schemes, including the challenging adversarial training scheme. Furthermore, we show that this Trojaned twin model is robust against SoTA detection methods.\n"}}
{"id": "byum5T0ffW", "cdate": 1674237519589, "mdate": 1674237519589, "content": {"title": "A Study of the Attention Abnormality in Trojaned BERTs", "abstract": "Trojan attacks raise serious security concerns. In this paper, we investigate the underlying mechanism of Trojaned BERT models. We observe the attention focus drifting behavior of Trojaned models, i.e., when encountering an poisoned input, the trigger token hijacks the attention focus regardless of the context. We provide a thorough qualitative and quantitative analysis of this phenomenon, revealing insights into the Trojan mechanism. Based on the observation, we propose an attention-based Trojan detector to distinguish Trojaned models from clean ones. To the best of our knowledge, we are the first to analyze the Trojan mechanism and develop a Trojan detector based on the transformer\u2019s attention."}}
{"id": "vff8MeyexQ", "cdate": 1672531200000, "mdate": 1683907278743, "content": {"title": "An integrated LSTM-HeteroRGNN model for interpretable opioid overdose risk prediction", "abstract": ""}}
{"id": "w48XN5HwpV8", "cdate": 1663850539788, "mdate": null, "content": {"title": "On the Existence of a Trojaned Twin Model", "abstract": "We study the Trojan Attack problem, where malicious attackers sabotage deep\nneural network models with poisoned training data. In most existing works, the\neffectiveness of the attack is largely overlooked; many attacks can be ineffective\nor inefficient for certain training schemes, e.g., adversarial training. In this paper,\nwe adopt a novel perspective and look into the quantitative relationship between a\nclean model and its Trojaned counterpart. We formulate a successful attack using\nclassic machine learning language. Under mild assumptions, we show theoretically\nthat there exists a Trojaned model, named Trojaned Twin, that is very close to the\nclean model. This attack can be achieved by simply using a universal Trojan trigger\nintrinsic to the data distribution. This has powerful implications in practice; the\nTrojaned twin model has enhanced attack efficacy and strong resiliency against\ndetection. Empirically, we show that our method achieves consistent attack efficacy\nacross different training schemes, including the challenging adversarial training\nscheme. Furthermore, this Trojaned twin model is robust against SoTA\ndetection methods"}}
{"id": "pNZkow3k3BH", "cdate": 1663850198992, "mdate": null, "content": {"title": "Attention-Guided Backdoor Attacks against Transformers", "abstract": "With the popularity of transformers in natural language processing (NLP) applications, there are growing concerns about their security. Most existing NLP attack methods focus on injecting stealthy trigger words/phrases. In this paper, we focus on the interior structure of neural networks and the Trojan mechanism. Focusing on the prominent NLP transformer models, we propose a novel Trojan Attention Loss (TAL), which enhances the Trojan behavior by directly manipulating the attention pattern. Our loss significantly improves the attack efficacy; it achieves better successful rates and with a much smaller poisoning rate (i.e., a smaller proportion of poisoned samples). It boosts attack efficacy for not only traditional dirty-label attacks, but also the more challenging clean-label attacks. TAL is also highly compatible with most existing attack methods and its flexibility enables this loss easily adapted to other backbone transformer models. "}}
{"id": "km2Pr952kYS", "cdate": 1640995200000, "mdate": 1683897342243, "content": {"title": "A Multimodal Transformer: Fusing Clinical Notes with Structured EHR Data for Interpretable In-Hospital Mortality Prediction", "abstract": ""}}
{"id": "Ya_ECN81s7", "cdate": 1640995200000, "mdate": 1681680355271, "content": {"title": "A Study of the Attention Abnormality in Trojaned BERTs", "abstract": ""}}
{"id": "Wyu5dtQKdlN", "cdate": 1640995200000, "mdate": 1683907278724, "content": {"title": "A Multimodal Transformer: Fusing Clinical Notes with Structured EHR Data for Interpretable In-Hospital Mortality Prediction", "abstract": "Deep-learning-based clinical decision support using structured electronic health records (EHR) has been an active research area for predicting risks of mortality and diseases. Meanwhile, large amounts of narrative clinical notes provide complementary information, but are often not integrated into predictive models. In this paper, we provide a novel multimodal transformer to fuse clinical notes and structured EHR data for better prediction of in-hospital mortality. To improve interpretability, we propose an integrated gradients (IG) method to select important words in clinical notes and discover the critical structured EHR features with Shapley values. These important words and clinical features are visualized to assist with interpretation of the prediction outcomes. We also investigate the significance of domain adaptive pretraining and task adaptive fine-tuning on the Clinical BERT, which is used to learn the representations of clinical notes. Experiments demonstrated that our model outperforms other methods (AUCPR: 0.538, AUCROC: 0.877, F1:0.490)."}}
{"id": "nIciAXPV8dy", "cdate": 1546300800000, "mdate": 1639570360905, "content": {"title": "CUNY-PKU Parser at SemEval-2019 Task 1: Cross-Lingual Semantic Parsing with UCCA", "abstract": "Weimin Lyu, Sheng Huang, Abdul Rafae Khan, Shengqiang Zhang, Weiwei Sun, Jia Xu. Proceedings of the 13th International Workshop on Semantic Evaluation. 2019."}}
