{"id": "dqnezjwpZj", "cdate": 1683905755443, "mdate": null, "content": {"title": "An Improved Lightweight YOLOv5 Model Based on Attention Mechanism for Face Mask Detection", "abstract": "Coronavirus 2019 has brought severe challenges to social stability and public health worldwide. One effective way of curbing the epidemic is to require people to wear masks in public places and monitor their mask-wearing states by suitable automatic detectors. However, existing models struggle to simultaneously achieve the requirements of both high precision and real-time performance. To solve this problem, we propose an improved lightweight face mask detector based on YOLOv5, which can achieve an excellent balance of precision and speed. Firstly, a novel backbone ShuffleCANet that combines ShuffleNetV2 network with Coordinate Attention mechanism is proposed as the backbone. Afterward, an efficient path aggression network BiFPN is applied as the feature fusion neck. Furthermore, the localization loss is replaced with $\\alpha$-CIoU in model training phase to obtain higher-quality anchors. Some valuable strategies such as data augmentation, adaptive image scaling, and anchor cluster operation are also utilized. Experimental results on AIZOO face mask dataset show the superiority of the proposed model. Compared with the original YOLOv5, the proposed model increases the inference speed by 28.3% while still improving the precision by 0.58%. It achieves the best mean average precision of 95.2% compared with other seven existing models, which is 4.4% higher than the baseline."}}
{"id": "IkWPJdo_ier", "cdate": 1640995200000, "mdate": 1668046915888, "content": {"title": "Boosting Semi-Supervised Face Recognition With Noise Robustness", "abstract": ""}}
{"id": "iEBBrNrdCAl", "cdate": 1609459200000, "mdate": 1668046915914, "content": {"title": "Synthetic Data Are as Good as the Real for Association Knowledge Learning in Multi-object Tracking", "abstract": "Association, aiming to link bounding boxes of the same identity in a video sequence, is a central component in multi-object tracking (MOT). To train association modules, e.g., parametric networks, real video data are usually used. However, annotating person tracks in consecutive video frames is expensive, and such real data, due to its inflexibility, offer us limited opportunities to evaluate the system performance w.r.t changing tracking scenarios. In this paper, we study whether 3D synthetic data can replace real-world videos for association training. Specifically, we introduce a large-scale synthetic data engine named MOTX, where the motion characteristics of cameras and objects are manually configured to be similar to those in real-world datasets. We show that compared with real data, association knowledge obtained from synthetic data can achieve very similar performance on real-world test sets without domain adaption techniques. Our intriguing observation is credited to two factors. First and foremost, 3D engines can well simulate motion factors such as camera movement, camera view and object movement, so that the simulated videos can provide association modules with effective motion features. Second, experimental results show that the appearance domain gap hardly harms the learning of association knowledge. In addition, the strong customization ability of MOTX allows us to quantitatively assess the impact of motion factors on MOT, which brings new insights to the community."}}
{"id": "8NQb85QhT9w", "cdate": 1609459200000, "mdate": 1668046915900, "content": {"title": "Action Units That Constitute Trainable Micro-expressions (and A Large-scale Synthetic Dataset)", "abstract": "This paper does not contain technical novelty but introduces our key discoveries in a data generation protocol, a database and insights. We aim to address the lack of large-scale datasets in micro-expression (MiE) recognition due to the prohibitive cost of data collection, which renders large-scale training less feasible. To this end, we develop a protocol to automatically synthesize large scale MiE training data that allow us to train improved recognition models for real-world test data. Specifically, we discover three types of Action Units (AUs) that can constitute trainable MiEs. These AUs come from real-world MiEs, early frames of macro-expression videos, and the relationship between AUs and expression categories defined by human expert knowledge. With these AUs, our protocol then employs large numbers of face images of various identities and an off-the-shelf face generator for MiE synthesis, yielding the MiE-X dataset. MiE recognition models are trained or pre-trained on MiE-X and evaluated on real-world test sets, where very competitive accuracy is obtained. Experimental results not only validate the effectiveness of the discovered AUs and MiE-X dataset but also reveal some interesting properties of MiEs: they generalize across faces, are close to early-stage macro-expressions, and can be manually defined."}}
{"id": "kQe1gtcL0P", "cdate": 1546300800000, "mdate": 1668046915895, "content": {"title": "A Neural Micro-Expression Recognizer", "abstract": ""}}
{"id": "eZSpJ67E48-", "cdate": 1546300800000, "mdate": 1668046915889, "content": {"title": "Improved Techniques for Building EEG Feature Filters", "abstract": ""}}
{"id": "AgCe45KPz-", "cdate": 1546300800000, "mdate": 1668046915895, "content": {"title": "Generalized Alignment for Multimodal Physiological Signal Learning", "abstract": ""}}
