{"id": "_zKlO6euc18", "cdate": 1657357915850, "mdate": null, "content": {"title": "With a Little Help from Gzip: Text Classification with No Training", "abstract": "In text classification, neural network methods often turn out to be an overkill. Compressor-based methods are simpler, but previous works in this area fail to achieve a result comparable with neural network methods. In this paper, we combine a simple compressor like gzip with a k-nearest-neighbor classifier for text classification. Without any training, pre-training or fine-tuning, our method achieves results that are competitive with deep learning methods on seven datasets, and it even outperforms BERT and sentence-BERT on one dataset. In addition, we demonstrate the robustness of our method in the few-shot setting."}}
{"id": "24fiAU_9vT", "cdate": 1652737598131, "mdate": null, "content": {"title": "Few-Shot Non-Parametric Learning with Deep Latent Variable Model", "abstract": "Most real-world problems that machine learning algorithms are expected to solve face the situation with (1) unknown data distribution; (2) little domain-specific knowledge; and (3) datasets with limited annotation. We propose Non-Parametric learning by Compression with Latent Variables (NPC-LV), a learning framework for any dataset with abundant unlabeled data but very few labeled ones. By only training a generative model in an unsupervised way, the framework utilizes the data distribution to build a compressor. Using a compressor-based distance metric derived from Kolmogorov complexity, together with few labeled data, NPC-LV classifies without further training. We show that NPC-LV outperforms supervised methods on all three datasets on image classification in the low data regime and even outperforms semi-supervised learning methods on CIFAR-10. We demonstrate how and when negative evidence lowerbound (nELBO) can be used as an approximate compressed length for classification. By revealing the correlation between compression rate and classification accuracy, we illustrate that under NPC-LV how the improvement of generative models can enhance downstream classification accuracy."}}
