{"id": "4E6Tfv2s0ai", "cdate": 1682691751615, "mdate": 1682691751615, "content": {"title": "Leveraging Pretrained Models for Automatic Summarization of Doctor-Patient Conversations", "abstract": "Fine-tuning pretrained models for automatically summarizing doctor-patient conversation\ntranscripts presents many challenges: limited\ntraining data, significant domain shift, long\nand noisy transcripts, and high target summary variability. In this paper, we explore\nthe feasibility of using pretrained transformer\nmodels for automatically summarizing doctorpatient conversations directly from transcripts.\nWe show that fluent and adequate summaries\ncan be generated with limited training data by\nfine-tuning BART on a specially constructed\ndataset. The resulting models greatly surpass\nthe performance of an average human annotator and the quality of previous published work\nfor the task. We evaluate multiple methods for\nhandling long conversations, comparing them\nto the obvious baseline of truncating the conversation to fit the pretrained model length\nlimit. We introduce a multistage approach\nthat tackles the task by learning two finetuned models: one for summarizing conversation chunks into partial summaries, followed\nby one for rewriting the collection of partial\nsummaries into a complete summary1\n. Using a carefully chosen fine-tuning dataset, this\nmethod is shown to be effective at handling\nlonger conversations, improving the quality\nof generated summaries. We conduct both\nan automatic evaluation (through ROUGE and\ntwo concept-based metrics focusing on medical findings) and a human evaluation (through\nqualitative examples from literature, assessing\nhallucination, generalization, fluency, and general quality of the generated summaries)."}}
{"id": "kUOm0Fdtvh", "cdate": 1652737607899, "mdate": null, "content": {"title": "AdaFocal: Calibration-aware Adaptive Focal Loss", "abstract": "Much recent work has been devoted to the problem of ensuring that a neural network's confidence scores match the true probability of being correct, i.e. the calibration problem. Of note, it was found that training with focal loss leads to better calibration than cross-entropy while achieving similar level of accuracy \\cite{mukhoti2020}. This success stems from focal loss regularizing the entropy of the model's prediction (controlled by the parameter $\\gamma$), thereby reining in the model's overconfidence. Further improvement is expected if $\\gamma$ is selected independently for each training sample (Sample-Dependent Focal Loss (FLSD-53) \\cite{mukhoti2020}). However, FLSD-53 is based on heuristics and does not generalize well. In this paper, we propose a calibration-aware adaptive focal loss called AdaFocal that utilizes the calibration properties of focal (and inverse-focal) loss and adaptively modifies $\\gamma_t$ for different groups of samples based on $\\gamma_{t-1}$ from the previous step and the knowledge of model's under/over-confidence on the validation set. We evaluate AdaFocal on various image recognition and one NLP task, covering a wide variety of network architectures, to confirm the improvement in calibration while achieving similar levels of accuracy. Additionally, we show that models trained with AdaFocal achieve a significant boost in out-of-distribution detection."}}
{"id": "rQCGVktb1a", "cdate": 1640995200000, "mdate": 1682434516306, "content": {"title": "He Said, She Said: Style Transfer for Shifting the Perspective of Dialogues", "abstract": "In this work, we define a new style transfer task: perspective shift, which reframes a dialogue from informal first person to a formal third person rephrasing of the text. This task requires challenging coreference resolution, emotion attribution, and interpretation of informal text. We explore several baseline approaches and discuss further directions on this task when applied to short dialogues. As a sample application, we demonstrate that applying perspective shifting to a dialogue summarization dataset (SAMSum) substantially improves the zero-shot performance of extractive news summarization models on this data. Additionally, supervised extractive models perform better when trained on perspective shifted data than on the original dialogues. We release our code publicly."}}
{"id": "n3GJSjPDDT", "cdate": 1640995200000, "mdate": 1682434516110, "content": {"title": "He Said, She Said: Style Transfer for Shifting the Perspective of Dialogues", "abstract": ""}}
{"id": "kf5FYS7S4s", "cdate": 1640995200000, "mdate": 1682434516008, "content": {"title": "Revisiting text decomposition methods for NLI-based factuality scoring of summaries", "abstract": "Scoring the factuality of a generated summary involves measuring the degree to which a target text contains factual information using the input document as support. Given the similarities in the problem formulation, previous work has shown that Natural Language Inference models can be effectively repurposed to perform this task. As these models are trained to score entailment at a sentence level, several recent studies have shown that decomposing either the input document or the summary into sentences helps with factuality scoring. But is fine-grained decomposition always a winning strategy? In this paper we systematically compare different granularities of decomposition -- from document to sub-sentence level, and we show that the answer is no. Our results show that incorporating additional context can yield improvement, but that this does not necessarily apply to all datasets. We also show that small changes to previously proposed entailment-based scoring methods can result in better performance, highlighting the need for caution in model and methodology selection for downstream tasks."}}
{"id": "YnRtXomNbh", "cdate": 1640995200000, "mdate": 1682434515687, "content": {"title": "On Efficiently Acquiring Annotations for Multilingual Models", "abstract": ""}}
{"id": "YgQLqJMP3A", "cdate": 1640995200000, "mdate": 1682434505886, "content": {"title": "He Said, She Said: Style Transfer for Shifting the Perspective of Dialogues", "abstract": "In this work, we define a new style transfer task: perspective shift, which reframes a dialogue from informal first person to a formal third person rephrasing of the text. This task requires challenging coreference resolution, emotion attribution, and interpretation of informal text. We explore several baseline approaches and discuss further directions on this task when applied to short dialogues. As a sample application, we demonstrate that applying perspective shifting to a dialogue summarization dataset (SAMSum) substantially improves the zero-shot performance of extractive news summarization models on this data. Additionally, supervised extractive models perform better when trained on perspective shifted data than on the original dialogues. We release our code publicly."}}
{"id": "XijGkKL_re", "cdate": 1640995200000, "mdate": 1682434505893, "content": {"title": "He Said, She Said: Style Transfer for Shifting the Perspective of Dialogues", "abstract": ""}}
{"id": "SWNZDd8cA9", "cdate": 1640995200000, "mdate": 1682434505890, "content": {"title": "On Efficiently Acquiring Annotations for Multilingual Models", "abstract": ""}}
{"id": "NXl1tCByjK", "cdate": 1640995200000, "mdate": 1682434515836, "content": {"title": "On Efficiently Acquiring Annotations for Multilingual Models", "abstract": "When tasked with supporting multiple languages for a given problem, two approaches have arisen: training a model for each language with the annotation budget divided equally among them, and training on a high-resource language followed by zero-shot transfer to the remaining languages. In this work, we show that the strategy of joint learning across multiple languages using a single model performs substantially better than the aforementioned alternatives. We also demonstrate that active learning provides additional, complementary benefits. We show that this simple approach enables the model to be data efficient by allowing it to arbitrate its annotation budget to query languages it is less certain on. We illustrate the effectiveness of our proposed method on a diverse set of tasks: a classification task with 4 languages, a sequence tagging task with 4 languages and a dependency parsing task with 5 languages. Our proposed method, whilst simple, substantially outperforms the other viable alternatives for building a model in a multilingual setting under constrained budgets."}}
