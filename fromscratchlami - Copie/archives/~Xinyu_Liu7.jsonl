{"id": "9FP4l_PHaeG", "cdate": 1667362087675, "mdate": 1667362087675, "content": {"title": "Towards Robust Adaptive Object Detection under Noisy Annotations", "abstract": "Domain Adaptive Object Detection (DAOD) models a joint distribution of images and labels from an annotated source domain and learns a domain-invariant transformation to estimate the target labels with the given target domain images. Existing methods assume that the source domain labels are completely clean, yet large-scale datasets often contain error-prone annotations due to instance ambiguity, which may lead to a biased source distribution and severely degrade the performance of the domain adaptive detector de facto. In this paper, we represent the first effort to formulate noisy DAOD and propose a Noise Latent Transferability Exploration (NLTE) framework to address this issue. It is featured with 1) Potential Instance Mining (PIM), which leverages eligible proposals to recapture the miss-annotated instances from the background; 2) Morphable Graph Relation Module (MGRM), which models the adaptation feasibility and transition probability of noisy samples with relation matrices; 3) Entropy-Aware Gradient Reconcilement (EAGR), which incorporates the semantic information into the discrimination process and enforces the gradients provided by noisy and clean samples to be consistent towards learning domain-invariant representations. A thorough evaluation on benchmark DAOD datasets with noisy source annotations validates the effectiveness of NLTE. In particular, NLTE improves the mAP by 8.4% under 60% corrupted annotations and even approaches the ideal upper bound of training on a clean source dataset."}}
{"id": "OtDBcpgsbC", "cdate": 1667361496205, "mdate": null, "content": {"title": "Semi-supervised Medical Image Classification with Temporal Knowledge-Aware Regularization", "abstract": "Semi-supervised learning (SSL) for medical image classification has achieved exceptional success on efficiently exploiting knowledge from unlabeled data with limited labeled data. Nevertheless, recent SSL methods suffer from misleading hard-form pseudo labeling, exacerbating the confirmation bias issue due to rough training process. Moreover, the training schemes excessively depend on the quality of generated pseudo labels, which is vulnerable against the inferior ones. In this paper, we propose TEmporal knowledge-Aware Regularization (TEAR) for semi-supervised medical image classification. Instead of using hard pseudo labels to train models roughly, we design Adaptive Pseudo Labeling (AdaPL), a mild learning strategy that relaxes hard pseudo labels to soft-form ones and provides a cautious training. AdaPL is built on a novel theoretically derived loss estimator, which approximates the loss of unlabeled samples according to the temporal information across training iterations, to adaptively relax pseudo labels. To release the excessive dependency of biased pseudo labels, we take advantage of the temporal knowledge and propose Iterative Prototype Harmonizing (IPH) to encourage the model to learn discriminative representations in an unsupervised manner. The core principle of IPH is to maintain the harmonization of clustered prototypes across different iterations. Both AdaPL and IPH can be easily incorporated into prior pseudo labeling-based models to extract features from unlabeled medical data for accurate classification. Extensive experiments on three semi-supervised medical image datasets demonstrate that our method outperforms state-of-the-art approaches. The code is available at https://github.com/CityU-AIM-Group/TEAR."}}
{"id": "qs9mVvPXgn", "cdate": 1640995200000, "mdate": 1667481634829, "content": {"title": "Global Context Parallel Attention for Anchor-Free Instance Segmentation in Remote Sensing Images", "abstract": "Segmenting objects in optical remote sensing images has always been a hot topic for remote sensing image researchers. However, many previous works used segmentation algorithms designed for common objects without modification, leading to slow and poor results. In this work, we exploit self-attention mechanism into anchor-free segmentation architectures to improve the segmentation accuracy for objects in high-resolution remote sensing images. The proposed module integrates the self-attention mechanism, namely the global context parallel attention module (GC-PAM). It is composed of a parallel global context channel self-attention block and a spatial self-attention block. By implementing our GC-PAM in an anchor-free network, the channel-wise and spatial-wise weights are both reassigned, which can improve the segmentation accuracy significantly."}}
{"id": "cYIhVl5rRSn", "cdate": 1640995200000, "mdate": 1667481634829, "content": {"title": "Semi-supervised Medical Image Classification with Temporal Knowledge-Aware Regularization", "abstract": "Semi-supervised learning (SSL) for medical image classification has achieved exceptional success on efficiently exploiting knowledge from unlabeled data with limited labeled data. Nevertheless, recent SSL methods suffer from misleading hard-form pseudo labeling, exacerbating the confirmation bias issue due to rough training process. Moreover, the training schemes excessively depend on the quality of generated pseudo labels, which is vulnerable against the inferior ones. In this paper, we propose TEmporal knowledge-Aware Regularization (TEAR) for semi-supervised medical image classification. Instead of using hard pseudo labels to train models roughly, we design Adaptive Pseudo Labeling (AdaPL), a mild learning strategy that relaxes hard pseudo labels to soft-form ones and provides a cautious training. AdaPL is built on a novel theoretically derived loss estimator, which approximates the loss of unlabeled samples according to the temporal information across training iterations, to adaptively relax pseudo labels. To release the excessive dependency of biased pseudo labels, we take advantage of the temporal knowledge and propose Iterative Prototype Harmonizing (IPH) to encourage the model to learn discriminative representations in an unsupervised manner. The core principle of IPH is to maintain the harmonization of clustered prototypes across different iterations. Both AdaPL and IPH can be easily incorporated into prior pseudo labeling-based models to extract features from unlabeled medical data for accurate classification. Extensive experiments on three semi-supervised medical image datasets demonstrate that our method outperforms state-of-the-art approaches. The code is available at https://github.com/CityU-AIM-Group/TEAR ."}}
{"id": "Z1o9DNv2Sl", "cdate": 1640995200000, "mdate": 1667481634841, "content": {"title": "SCAN: Cross Domain Object Detection with Semantic Conditioned Adaptation", "abstract": "The domain gap severely limits the transferability and scalability of object detectors trained in a specific domain when applied to a novel one. Most existing works bridge the domain gap by minimizing the domain discrepancy in the category space and aligning category-agnostic global features. Though great success, these methods model domain discrepancy with prototypes within a batch, yielding a biased estimation of domain-level distribution. Besides, the category-agnostic alignment leads to the disagreement of class-specific distributions in the two domains, further causing inevitable classification errors. To overcome these two challenges, we propose a novel Semantic Conditioned AdaptatioN (SCAN) framework such that well-modeled unbiased semantics can support semantic conditioned adaptation for precise domain adaptive object detection. Specifically, class-specific semantics crossing different images in the source domain are graphically aggregated as the input to learn an unbiased semantic paradigm incrementally. The paradigm is then sent to a lightweight manifestation module to obtain conditional kernels to serve as the role of extracting semantics from the target domain for better adaptation. Subsequently, conditional kernels are integrated into global alignment to support the class-specific adaptation in a well-designed Conditional Kernel guided Alignment (CKA) module. Meanwhile, rich knowledge of the unbiased paradigm is transferred to the target domain with a novel Graph-based Semantic Transfer (GST) mechanism, yielding the adaptation in the category-based feature space. Comprehensive experiments conducted on three adaptation benchmarks demonstrate that SCAN outperforms existing works by a large margin."}}
{"id": "W6RmRhmBLJ7", "cdate": 1640995200000, "mdate": 1667481634830, "content": {"title": "SIGMA: Semantic-complete Graph Matching for Domain Adaptive Object Detection", "abstract": "Domain Adaptive Object Detection (DAOD) leverages a labeled domain to learn an object detector generalizing to a novel domain free of annotations. Recent advances align class-conditional distributions by narrowing down cross-domain prototypes (class centers). Though great success,they ignore the significant within-class variance and the domain-mismatched semantics within the training batch, leading to a sub-optimal adaptation. To overcome these challenges, we propose a novel SemantIc-complete Graph MAtching (SIGMA) framework for DAOD, which completes mismatched semantics and reformulates the adaptation with graph matching. Specifically, we design a Graph-embedded Semantic Completion module (GSC) that completes mismatched semantics through generating hallucination graph nodes in missing categories. Then, we establish cross-image graphs to model class-conditional distributions and learn a graph-guided memory bank for better semantic completion in turn. After representing the source and target data as graphs, we reformulate the adaptation as a graph matching problem, i.e., finding well-matched node pairs across graphs to reduce the domain gap, which is solved with a novel Bipartite Graph Matching adaptor (BGM). In a nutshell, we utilize graph nodes to establish semantic-aware node affinity and leverage graph edges as quadratic constraints in a structure-aware matching loss, achieving fine-grained adaptation with a node-to-node graph matching. Extensive experiments verify that SIGMA outperforms existing works significantly. Our code is available at https://github.com/CityU-AIM-Group/SIGMA."}}
{"id": "PTeJCxYp8Wq", "cdate": 1640995200000, "mdate": 1667481634815, "content": {"title": "A Source-Free Domain Adaptive Polyp Detection Framework With Style Diversification Flow", "abstract": "The automatic detection of polyps across colonoscopy and Wireless Capsule Endoscopy (WCE) datasets is crucial for early diagnosis and curation of colorectal cancer. Existing deep learning approaches either require mass training data collected from multiple sites or use unsupervised domain adaptation (UDA) technique with labeled source data. However, these methods are not applicable when the data is not accessible due to privacy concerns or data storage limitations. Aiming to achieve source-free domain adaptive polyp detection, we propose a consistency based model that utilizes Source Model as Proxy Teacher (SMPT) with only a transferable pretrained model and unlabeled target data. SMPT first transfers the stored domain-invariant knowledge in the pretrained source model to the target model via Source Knowledge Distillation (SKD), then uses Proxy Teacher Rectification (PTR) to rectify the source model with temporal ensemble of the target model. Moreover, to alleviate the biased knowledge caused by domain gaps, we propose Uncertainty-Guided Online Bootstrapping (UGOB) to adaptively assign weights for each target image regarding their uncertainty. In addition, we design Source Style Diversification Flow (SSDF) that gradually generates diverse style images and relaxes style-sensitive channels based on source and target information to enhance the robustness of the model towards style variation. The capacities of SMPT and SSDF are further boosted with iterative optimization, constructing a stronger framework SMPT++ for cross-domain polyp detection. Extensive experiments are conducted on five distinct polyp datasets under two types of cross-domain settings. Our proposed method shows the state-of-the-art performance and even outperforms previous UDA approaches that require the source data by a large margin. The source code is available at github.com/CityU-AIM-Group/SFPolypDA."}}
{"id": "JJCDX1tGH0", "cdate": 1640995200000, "mdate": 1667481634816, "content": {"title": "SIGMA: Semantic-complete Graph Matching for Domain Adaptive Object Detection", "abstract": "Domain Adaptive Object Detection (DAOD) leverages a labeled domain to learn an object detector generalizing to a novel domain free of annotations. Recent advances align class-conditional distributions by narrowing down cross-domain prototypes (class centers). Though great success, they ignore the significant within-class variance and the domain-mismatched semantics within the training batch, leading to a sub-optimal adaptation. To overcome these challenges, we propose a novel SemantIc-complete Graph MAtching (SIGMA) framework for DAOD, which completes mismatched semantics and reformulates the adaptation with graph matching. Specifically, we design a Graph-embedded Semantic Completion module (GSC) that completes mis-matched semantics through generating hallucination graph nodes in missing categories. Then, we establish cross-image graphs to model class-conditional distributions and learn a graph-guided memory bank for better semantic completion in turn. After representing the source and target data as graphs, we reformulate the adaptation as a graph matching problem, i.e., finding well-matched node pairs across graphs to reduce the domain gap, which is solved with a novel Bipartite Graph Matching adaptor (BGM). In a nutshell, we utilize graph nodes to establish semantic-aware node affinity and leverage graph edges as quadratic constraints in a structure-aware matching loss, achieving fine-grained adaptation with a node-to-node graph matching. Extensive experiments verify that SIGMA outperforms existing works significantly. Our code is available at https://github.com/CityU-AIM-Group/SIGMA."}}
{"id": "Fw4qCDMu8k", "cdate": 1640995200000, "mdate": 1667481634829, "content": {"title": "Towards Robust Adaptive Object Detection under Noisy Annotations", "abstract": "Domain Adaptive Object Detection (DAOD) models a joint distribution of images and labels from an annotated source domain and learns a domain-invariant transformation to estimate the target labels with the given target domain images. Existing methods assume that the source domain labels are completely clean, yet large-scale datasets often contain error-prone annotations due to instance ambiguity, which may lead to a biased source distribution and severely degrade the performance of the domain adaptive detector de facto. In this paper, we represent the first effort to formulate noisy DAOD and propose a Noise Latent Transferability Exploration (NLTE) framework to address this issue. It is featured with 1) Potential Instance Mining (PIM), which leverages eligible proposals to recapture the miss-annotated instances from the background; 2) Morphable Graph Relation Module (MGRM), which models the adaptation feasibility and transition probability of noisy samples with relation matrices; 3) Entropy-Aware Gradient Reconcilement (EAGR), which incorporates the semantic information into the discrimination process and enforces the gradients provided by noisy and clean samples to be consistent towards learning domain-invariant representations. A thorough evaluation on benchmark DAOD datasets with noisy source annotations validates the effectiveness of NLTE. In particular, NLTE improves the mAP by 8.4% under 60% corrupted annotations and even approaches the ideal upper bound of training on a clean source dataset. <sup xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">1</sup> <sup xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">1</sup> Code is available at https://github.com/CityU-AIM-Group/NLTE."}}
{"id": "6QTv0GqZsR", "cdate": 1640995200000, "mdate": 1667481634830, "content": {"title": "Intervention & Interaction Federated Abnormality Detection with Noisy Clients", "abstract": "Federated learning (FL), which trains a shared global model by collaboration between distributed clients (e.g. medical institutions) and preserves the privacy of local data, has been widely deployed in the medical field to benefit abnormality diagnosis. However, it is inevitable that local data contains noise across clients, resulting in notably performance deterioration in the global model. To this end, a practical yet challenging FL problem is studied in this paper, namely Federated abnormality detection with noisy clients (FADN). We represent the first effort to reason the FADN task as a structural causal model, and identify the main issue that leads to the performance deterioration, namely recognition bias. To tackle the problem, an Intervention & Interaction FL framework (FedInI) is proposed, comprising two key strategies: (1) Intervention: considering the data distribution heterogeneity caused by different noisy levels within each client, we use the global model to intervene the training of local models, by shuffling and mixing features extracted from different models and suppress the noise gradually; (2) Interaction: we devise an adaptive sample-wise weighting strategy that jointly considers the local training statuses and global noisy levels with a shared interactive layer. Extensive experiments on class-conditional noise and instance-dependant noise settings are conducted, FedInI outperforms state-of-the-arts by a remarkable margin. Code is available at github.com/CityU-AIM-Group/FedInI ."}}
