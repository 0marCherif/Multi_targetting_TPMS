{"id": "qm62NWMxHV", "cdate": 1681506300258, "mdate": null, "content": {"title": "CLIPGraphs: Multimodal Graph Networks  to Infer Object-Room Affinities", "abstract": "This work focuses on improving upon pre-trained feature representations for learning functional and semantic priors for embodied AI tasks. Specifically, we propose a GCN-based training pipeline that fine-tunes the CLIP embeddings to effectively estimate object-room affinities. Our approach, CLIPGraphs, efficiently combines human commonsense domain knowledge, multimodal information from language and vision inputs(leveraging the strengths of CLIP); and a Graph Network to encode these functional/semantic priors. We experimentally demonstrate the effectiveness of our approach on a benchmark dataset of object categories, showing a significant improvement over state-of-the-art baselines. The learned embeddings from our approach can be used as priors in downstream embodied AI tasks such as object navigation and scene rearrangement, demonstrating the broad applicability of our method.\n"}}
{"id": "sU95_0l5jhC", "cdate": 1640995200000, "mdate": 1681734759853, "content": {"title": "Object Goal Navigation using Data Regularized Q-Learning", "abstract": "Object Goal Navigation requires a robot to find and navigate to an instance of a target object class in a previously unseen environment. Our framework incrementally builds a semantic map of the environment over time, and then repeatedly selects a long-term goal (\u2019where to go\u2019) based on the semantic map to locate the target object instance. Long-term goal selection is formulated as a vision-based deep reinforcement learning problem. Specifically, an Encoder Network is trained to extract high-level features from a semantic map and select a long-term goal. In addition, we incorporate data augmentation and Q-function regularization to make the long-term goal selection more effective. We report experimental results using the photo-realistic Gibson benchmark dataset in the AI Habitat 3D simulation environment to demonstrate substantial performance improvement on standard measures in comparison with a state of the art data-driven baseline."}}
{"id": "e5j2qpoXwAQ", "cdate": 1640995200000, "mdate": 1681734759575, "content": {"title": "ProxiTrak: Intelligent Enablement of Social Distancing & Contact Tracing for a Safer Workplace in the New Normal", "abstract": "This paper describes an innovative solution that enables the enterprises to bring their associates (or employees) back to physical workspaces for critical operations in a safe manner in the wake of current COVID-19 pandemic."}}
{"id": "coV9EJxbeR", "cdate": 1640995200000, "mdate": 1681734759853, "content": {"title": "Spatial Relation Graph and Graph Convolutional Network for Object Goal Navigation", "abstract": "This paper describes a framework for the object-goal navigation task, which requires a robot to find and move to the closest instance of a target object class from a random starting position. The framework uses a history of robot trajectories to learn a Spatial Relational Graph (SRG) and Graph Convolutional Network (GCN)-based embeddings for the likelihood of proximity of different semantically-labeled regions and the occurrence of different object classes in these regions. To locate a target object instance during evaluation, the robot uses Bayesian inference and the SRG to estimate the visible regions, and uses the learned GCN embeddings to rank visible regions and select the region to explore next."}}
{"id": "_DMWOeNxfM", "cdate": 1640995200000, "mdate": 1681734759574, "content": {"title": "Talk-to-Resolve: Combining scene understanding and spatial dialogue to resolve granular task ambiguity for a collocated robot", "abstract": ""}}
{"id": "X-e5mt03ilw", "cdate": 1640995200000, "mdate": 1681734759572, "content": {"title": "Object Goal Navigation Based on Semantics and RGB Ego View", "abstract": "This paper presents an architecture and methodology to empower a service robot to navigate an indoor environment with semantic decision making, given RGB ego view. This method leverages the knowledge of robot's actuation capability and that of scenes, objects and their relations -- represented in a semantic form. The robot navigates based on GeoSem map - a relational combination of geometric and semantic map. The goal given to the robot is to find an object in a unknown environment with no navigational map and only egocentric RGB camera perception. The approach is tested both on a simulation environment and real life indoor settings. The presented approach was found to outperform human users in gamified evaluations with respect to average completion time."}}
{"id": "Q-6jJZp7au", "cdate": 1640995200000, "mdate": 1681734759853, "content": {"title": "Teledrive: An Intelligent Telepresence Solution for \"Collaborative Multi-presence\" through a Telerobot", "abstract": "This paper presents an Edge-centric architecture along with a novel communication topology for a practical robotic telepresence solution. The system has been experimented in real-life. The subjective user experience is quantified through a simple yet effective technique. The efficacy of the protocol is also proven through experiments in practical deployment."}}
{"id": "Ji74LZpd7QB", "cdate": 1640995200000, "mdate": 1681734759853, "content": {"title": "Object Goal Navigation using Data Regularized Q-Learning", "abstract": "Object Goal Navigation requires a robot to find and navigate to an instance of a target object class in a previously unseen environment. Our framework incrementally builds a semantic map of the environment over time, and then repeatedly selects a long-term goal ('where to go') based on the semantic map to locate the target object instance. Long-term goal selection is formulated as a vision-based deep reinforcement learning problem. Specifically, an Encoder Network is trained to extract high-level features from a semantic map and select a long-term goal. In addition, we incorporate data augmentation and Q-function regularization to make the long-term goal selection more effective. We report experimental results using the photo-realistic Gibson benchmark dataset in the AI Habitat 3D simulation environment to demonstrate substantial performance improvement on standard measures in comparison with a state of the art data-driven baseline."}}
{"id": "1CDSbdasgK", "cdate": 1640995200000, "mdate": 1681734759573, "content": {"title": "Spatial Relation Graph and Graph Convolutional Network for Object Goal Navigation", "abstract": "This paper describes a framework for the object-goal navigation (ObjectNav) task, which requires a robot to find and move to an instance of a target object class from a random starting position. The framework uses a history of robot trajectories to learn a Spatial Relational Graph (SRG) and Graph Convolutional Network (GCN)-based embeddings for the likelihood of proximity of different semantically-labeled regions and the occurrence of different object classes in these regions. To locate a target object instance during evaluation, the robot uses Bayesian inference and the SRG to estimate the visible regions, and uses the learned GCN embeddings to rank visible regions and select the region to explore next. This approach is tested using the Matterport3D (MP3D) benchmark dataset of indoor scenes in AI Habitat, a visually realistic simulation environment, to report substantial performance improvement in comparison with state of the art baselines."}}
{"id": "9AhPFBIWnI6", "cdate": 1618376864236, "mdate": null, "content": {"title": "Towards Safe and Reliable Robot Task Planning", "abstract": "A long-standing goal of AI is to enable robots to\nplan in dynamic and uncertain environments by\nmanaging task failure intelligently. Reliability of a\nrobot task planner has become essential to ensure\noperational safety. Reliability is generally determined by the probability of a task to circumvent\nfailures, while safety is related to the consequences\nof the failures. In this paper, methods and an architecture for handling reliability and safety in robotic\ntask planning is presented. The paper takes help of\na telepresence navigation scenario to describe some\ncandidate solutions such as Task Reliability Graph\nand weighted reliability goals."}}
