{"id": "ePMzDSyXnRb", "cdate": 1690840872009, "mdate": null, "content": {"title": "AlpaGasus: Training A Better Alpaca with Fewer Data", "abstract": "Large language models (LLMs) obtain instruction-following capability through instruction-finetuning (IFT) on supervised instruction/response data. However, widely used IFT datasets (e.g., ALPACA\u2019s 52k data) surprisingly contain many\nlow-quality instances with incorrect or irrelevant responses, which are misleading and detrimental to IFT. In this paper, we propose a simple and effective data selection strategy that automatically identifies and removes low-quality data using a strong LLM (e.g., ChatGPT). To this end, we introduce ALPAGASUS, which is finetuned on only 9k high-quality data filtered from the 52k ALPACA data.\nALPAGASUS significantly outperforms the original ALPACA as evaluated by GPT4 on multiple test sets and its 13B variant matches > 90% performance of its teacher LLM (i.e., Text-Davinci-003) on test tasks. It also provides 5.7x faster training, reducing the training time for a 7B variant from 80 minutes (for ALPACA) to 14 minutes. Overall, ALPAGASUS demonstrates a novel data-centric IFT paradigm that can be generally applied to instruction-tuning data, leading to faster training and better instruction-following models."}}
{"id": "_mnjzaiFDH", "cdate": 1681275607576, "mdate": 1681275607576, "content": {"title": "When do you need Chain-of-Thought Prompting for ChatGPT?", "abstract": "Chain-of-Thought (CoT) prompting can effectively elicit complex multi-step reasoning from Large Language Models~(LLMs). For example, by simply adding CoT instruction ``Let's think step-by-step'' to each input query of MultiArith dataset, GPT-3's accuracy can be improved from 17.7\\% to 78.7\\%. However, it is not clear whether CoT is still effective on more recent instruction finetuned (IFT) LLMs such as ChatGPT. Surprisingly, on ChatGPT, CoT is no longer effective for certain tasks such as arithmetic reasoning while still keeping effective on other reasoning tasks. Moreover, on the former tasks, ChatGPT usually achieves the best performance and can generate CoT even without being instructed to do so. Hence, it is plausible that ChatGPT has already been trained on these tasks with CoT and thus memorized the instruction so it implicitly follows such an instruction when applied to the same queries, even without CoT. Our analysis reflects a potential risk of overfitting/bias toward instructions introduced in IFT, which becomes more common in training LLMs. In addition, it indicates possible leakage of the pretraining recipe, e.g., one can verify whether a dataset and instruction were used in training ChatGPT. Our experiments report new baseline results of ChatGPT on a variety of reasoning tasks and shed novel insights into LLM's profiling, instruction memorization, and pretraining dataset leakage.\n"}}
{"id": "2LXf6l0nWSM", "cdate": 1679903973237, "mdate": 1679903973237, "content": {"title": "An Accelerated Doubly Stochastic Gradient Method with Faster Explicit Model Identification", "abstract": "Sparsity regularized loss minimization problems play an important role in various fields including machine learning, data mining, and\nmodern statistics. Proximal gradient descent method and coordinate descent method are the most popular approaches to solving the\nminimization problem. Although existing methods can achieve implicit model identification, aka support set identification, in a finite\nnumber of iterations, these methods still suffer from huge computational costs and memory burdens in high-dimensional scenarios.\nThe reason is that the support set identification in these methods is implicit and thus cannot explicitly identify the low-complexity\nstructure in practice, namely, they cannot discard useless coefficients of the associated features to achieve algorithmic acceleration\nvia dimension reduction. To address this challenge, we propose a novel accelerated doubly stochastic gradient descent (ADSGD)\nmethod for sparsity regularized loss minimization problems, which can reduce the number of block iterations by eliminating inactive\ncoefficients during the optimization process and eventually achieve faster explicit model identification and improve the algorithm efficiency. Theoretically, we first prove that ADSGD can achieve a linear convergence rate and lower overall computational complexity. More importantly, we prove that ADSGD can achieve a linear rate of explicit model identification. Numerically, experimental results on benchmark datasets confirm the efficiency of our proposed method.\n"}}
{"id": "zfYbx1u02V", "cdate": 1679903853565, "mdate": 1679903853565, "content": {"title": "Toward Unified Data and Algorithm Fairness via Adversarial Data Augmentation and Adaptive Model Fine-tuning", "abstract": "There is some recent research interest in algorithmic fairness for biased data. There are a variety of pre-, in-, and postprocessing methods designed for this problem. However, these methods are exclusively targeting data unfairness and algorithmic unfairness. In this paper, we propose a novel intra-processing method to broaden the application scenario of fairness methods, which can simultaneously address the two bias sources. Since training modern deep models from scratch is expensive due to the enormous training data and the complicated structures, we propose an augmentation and fne-tuning framework. First, we design an adversarial attack to generate weighted samples\ndisentangled with the protected attribute. Next, we identify the fair sub-structure in the biased model and fne-tune the model via weight reactivation. At last, we provide an optional joint training scheme for the augmentation and the fne-tuning. Our method can be combined with a variety of fairness measures. We benchmark our method and some related baselines to show the advantage and the scalability. Experimental results on several standard datasets demonstrate that our approach can effectively learn fair augmentation and achieve superior results to the stateof-the-art baselines. Our method also generalizes well to different types of data."}}
{"id": "RgzRdzFdAN", "cdate": 1665069640477, "mdate": null, "content": {"title": "Cooperation or Competition: Avoiding Player Domination for Multi-target Robustness by Adaptive Budgets", "abstract": "Despite incredible advances, deep learning has been shown to be susceptible to adversarial attacks. Numerous approaches were proposed to train robust networks both empirically and certifiably. However, most of them defend against only a single type of attack, while recent work steps forward at defending against multiple attacks. In this paper, to understand multi-target robustness, we view this problem as a bargaining game in which different players (adversaries) negotiate to reach an agreement on a joint direction of parameter updating. We identify a phenomenon named \\emph{player domination} in the bargaining game, and show that with this phenomenon, some of the existing max-based approaches such as MAX and MSD do not converge. Based on our theoretical results, we design a novel framework that adjusts the budgets of different adversaries to avoid player domination. Experiments on two benchmarks show that employing the proposed framework to the existing approaches significantly advances multi-target robustness."}}
{"id": "rQal9t5Eab5", "cdate": 1663939407127, "mdate": null, "content": {"title": "FedGRec: Federated Graph Recommender System with Lazy Update of Latent Embeddings", "abstract": "Recommender systems are widely used in industry to improve user experience. Despite great success, they have recently been criticized for collecting private user data. Federated Learning (FL) is a new paradigm for learning on distributed data without direct data sharing. Therefore, Federated Recommender (FedRec) systems are proposed to mitigate privacy concerns to non-distributed recommender systems. However, FedRec systems have a performance gap to its non-distributed counterpart. The main reason is that local clients have an incomplete user-item interaction graph, thus FedRec systems cannot utilize indirect user-item interactions well. In this paper, we propose the Federated Graph Recommender System (FedGRec) to mitigate this gap. Our FedGRec system can effectively exploit the indirect user-item interactions. More precisely, in our system, users and the server explicitly store latent embeddings for users and items, where the latent embeddings summarize different orders of indirect user-item interactions and are used as a proxy of missing interaction graph during local training. We perform extensive empirical evaluations to verify the efficacy of using latent embeddings as a proxy of missing interaction graph; the experimental results show superior performance of our system compared to various baselines. "}}
{"id": "WVYJ0BaytpF", "cdate": 1663850513382, "mdate": null, "content": {"title": "On the Convergence of Federated Deep AUC Maximization", "abstract": "In many real-world applications, the distribution of data is skewed. The standard models, which are designed to optimize the accuracy, have poor prediction performance when they are applied to imbalanced data tasks because the model could be dramatically biased toward its major class. Therefore, areas under ROC curves (AUROC) was proposed as a useful metric to assess how well prediction models performed on unbalanced data sets. On the other hand, federated learning (FL) has attracted increasing attention with the emergence of distributed data due to its communication efficiency. To address the challenge of distributed imbalanced data, research on Federated Deep AUC Maximization (FDAM) is necessary. However, the FDAM problem currently is understudied and is more complex than traditional federated learning (FL) techniques since its minimization objective is non-decomposable over individual examples. In this study, we solve FDAM algorithms for heterogeneous data by reformulating it as the popular non-convex strongly-concave min-max formulation and propose the federated stochastic recursive momentum gradient ascent (FMGDA) algorithm , which can also be applied to general federated non-convex-strongly-concave minimax problems. Importantly, our method does not rely on strict assumptions, such as the PL condition and we proved that it can achieve the $O(\\epsilon^{-3})$ sample complexity, which reaches the best-known sample complexity of centralized methods. It also achieves the $O(\\epsilon^{-2})$ communication complexity and a linear speedup in terms of the number of clients. Additionally, extensive experimental results show that our algorithm (i.e. FMGDA) performs empirically superior to other algorithms, supporting its effectiveness."}}
{"id": "Lmff9URfo5", "cdate": 1663850434198, "mdate": null, "content": {"title": "Cooperation or Competition: Avoiding Player Domination for Multi-target Robustness by Adaptive Budgets", "abstract": "Despite incredible advances, deep learning has been shown to be susceptible to adversarial attacks. Numerous approaches were proposed to train robust networks both empirically and certifiably. However, most of them defend against only a single type of attack, while recent work steps forward at defending against multiple attacks. In this paper, to understand multi-target robustness, we view this problem as a bargaining game in which different players (adversaries) negotiate to reach an agreement on a joint direction of parameter updating. We identify a phenomenon named \\emph{player domination} in the bargaining game, and show that with this phenomenon, some of the existing max-based approaches such as MAX and MSD do not converge. Based on our theoretical results, we design a novel framework that adjusts the budgets of different adversaries to avoid player domination. Experiments on two benchmarks show that employing the proposed framework to the existing approaches significantly advances multi-target robustness."}}
{"id": "OA4o8yKW3q", "cdate": 1663850228552, "mdate": null, "content": {"title": "Towards Robust Dataset Learning", "abstract": "We study the problem of learning a robust dataset such that any classifier naturally trained on the dataset is adversarially robust. Such a dataset benefits the downstream tasks as natural training is much faster than adversarial training, and demonstrates that the desired property of robustness is transferable between models and data. In this work, we propose a principled, tri-level optimization to formulate the robust dataset learning problem. We show that, under an abstraction model that characterizes robust vs. non-robust features, the proposed method provably learns a robust dataset. Extensive experiments on MNIST, CIFAR10, and TinyImageNet demostrate the effectiveness of our algorithm with different network initializations and architectures."}}
{"id": "7KdrFjpmJf7", "cdate": 1663850112076, "mdate": null, "content": {"title": "Learning Sampling Policy to Achieve Fewer  Queries for  Zeroth-Order Optimization", "abstract": "Zeroth-order (ZO) methods, which use the finite difference of two function evaluations (also called ZO gradient) to approximate first-order gradient, have attracted much attention recently in machine learning because of its broad applications.\nThe accurateness of ZO gradient highly depends on how many finite differences are averaged, which are intrinsically determined by the number of  perturbations randomly drawn from a distribution. \nExisting ZO methods try to learn a data-driven distribution for sampling the perturbations to improve the efficiency of ZO optimization (ZOO) algorithms. \nIn this paper, we explore  a  new and parallel direction, i.e. , learn an optimal sampling policy  instead of using totally random strategy  to generate perturbations based on the techniques of reinforcement\nlearning (RL), which makes it possible to  approximate the gradient  with only two function evaluations.  Specifically, we first formulate the problem of learning a sampling policy as a Markov decision process. Then, we propose our ZO-RL algorithm,  \\textit{i.e.}, using deep deterministic policy gradient, an actor-critic RL algorithm to  learn a  sampling policy which can guide the generation of perturbed vectors in getting ZO gradients as accurate as possible. Importantly, the existing ZOO algorithms of learning a distribution can be plugged in  to improve the exploration of  ZO-RL.\nExperimental results  with different ZO estimators show that our ZO-RL algorithm can effectively reduce the query complexity of ZOO algorithms  and converge faster than existing ZOO algorithms especially in the later stage of the  optimization process."}}
