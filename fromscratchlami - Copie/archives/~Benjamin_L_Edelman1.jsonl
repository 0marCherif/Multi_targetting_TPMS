{"id": "8XWP2ewX-im", "cdate": 1652737567070, "mdate": null, "content": {"title": "Hidden Progress in Deep Learning: SGD Learns Parities Near the Computational Limit", "abstract": "There is mounting evidence of emergent phenomena in the capabilities of deep learning methods as we scale up datasets, model sizes, and training times. While there are some accounts of how these resources modulate statistical capacity, far less is known about their effect on the computational problem of model training. This work conducts such an exploration through the lens of learning a $k$-sparse parity of $n$ bits, a canonical discrete search problem which is statistically easy but computationally hard. Empirically, we find that a variety of neural networks successfully learn sparse parities, with discontinuous phase transitions in the training curves. On small instances, learning abruptly occurs at approximately $n^{O(k)}$ iterations; this nearly matches SQ lower bounds, despite the apparent lack of a sparse prior. Our theoretical analysis shows that these observations are not explained by a Langevin-like mechanism, whereby SGD \"stumbles in the dark\" until it finds the hidden set of features (a natural algorithm which also runs in $n^{O(k)}$ time). Instead, we show that SGD gradually amplifies the sparse solution via a Fourier gap in the population gradient, making continual progress that is invisible to loss and error metrics."}}
{"id": "UjynxfqnGWG", "cdate": 1632875727099, "mdate": null, "content": {"title": "Inductive Biases and Variable Creation in Self-Attention Mechanisms", "abstract": "Self-attention, an architectural motif designed to model long-range interactions in sequential data, has driven numerous recent breakthroughs in natural language processing and beyond. This work provides a theoretical analysis of the inductive biases of self-attention modules, where our focus is to rigorously establish which functions and long-range dependencies self-attention blocks prefer to represent. We show that bounded-norm Transformer layers create sparse variables: they can represent sparse Lipschitz functions of the input sequence, with sample complexity scaling only logarithmically with the context length. We propose new experimental protocols to support the analysis and guide the practice of training Transformers, built around the rich theory of learning sparse Boolean functions."}}
{"id": "zeczLU1aa9", "cdate": 1577836800000, "mdate": null, "content": {"title": "Causal Strategic Linear Regression", "abstract": "In many predictive decision-making scenarios, such as credit scoring and academic testing, a decision-maker must construct a model that accounts for agents\u2019 propensity to \u201cgame\u201d the decision rule b..."}}
{"id": "-HKpoxaKCZY", "cdate": 1577836800000, "mdate": null, "content": {"title": "The Multiplayer Colonel Blotto Game", "abstract": "We initiate the study of the natural multiplayer generalization of the classic continuous Colonel Blotto game.The two-player Blotto game, introduced by Borel as a model of resource competition across nsimultaneous fronts, has been studied extensively for a century and seen numerous applications throughout the social sciences. Our work defines the multiplayer Colonel Blotto gameand derives Nash equilibria for various settings of k(number of players) and n(number of battlefields)---in particular, we mostly solve the symmetric three-player case. We also introduce a \"Boolean\" version of multiplayer Blotto. The main technical difficulty of our work, as in the two-player theoretical literature, is the challenge of coupling various marginal distributions into a joint distribution satisfying a strict sum constraint. In contrast to previous works in the continuous setting, we derive our couplings algorithmically in the form of efficient sampling algorithms. The full paper can be found at https://arxiv.org/abs/2002.05240."}}
{"id": "qDi19nVj1hT", "cdate": 1546300800000, "mdate": null, "content": {"title": "Matrix Rigidity and the Croot-Lev-Pach Lemma", "abstract": ""}}
{"id": "HHzeNG_4bEL", "cdate": 1546300800000, "mdate": null, "content": {"title": "SGD on Neural Networks Learns Functions of Increasing Complexity.", "abstract": "We perform an experimental study of the dynamics of Stochastic Gradient Descent (SGD) in learning deep neural networks for several real and synthetic classification tasks. We show that in the initial epochs, almost all of the performance improvement of the classifier obtained by SGD can be explained by a linear classifier. More generally, we give evidence for the hypothesis that, as iterations progress, SGD learns functions of increasing complexity. This hypothesis can be helpful in explaining why SGD-learned classifiers tend to generalize well even in the over-parameterized regime. We also show that the linear classifier learned in the initial stages is ``retained'' throughout the execution even if training is continued to the point of zero training error, and complement this with a theoretical result in a simplified model. Key to our work is a new measure of how well one classifier explains the performance of another, based on conditional mutual information."}}
