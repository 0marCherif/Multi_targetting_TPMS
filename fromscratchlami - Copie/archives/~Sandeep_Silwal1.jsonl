{"id": "I29Kt0RwChs", "cdate": 1663850503018, "mdate": null, "content": {"title": "Robust Algorithms on Adaptive Inputs from Bounded Adversaries", "abstract": "We study dynamic algorithms robust to adaptive input generated from sources with bounded capabilities, such as sparsity or limited interaction. For example, we consider robust linear algebraic algorithms when the updates to the input are sparse but given by an adversary with access to a query oracle. We also study robust algorithms in the standard centralized setting, where an adversary queries an algorithm in an adaptive manner, but the number of interactions between the adversary and the algorithm is bounded. We first recall a unified framework of (Hassidim et al., 2020; Beimel et al., 2022; Attias et al., 2023) for answering $Q$ adaptive queries that incurs $\\widetilde{\\mathcal{O}}(\\sqrt{Q})$ overhead in space, which is roughly a quadratic improvement over the na\\\"{i}ve implementation, and only incurs a logarithmic overhead in query time. Although the general framework has diverse applications in machine learning and data science, such as adaptive distance estimation, kernel density estimation, linear regression, range queries, point queries,  and serves as a preliminary benchmark, we demonstrate even better algorithmic improvements for (1) reducing the pre-processing time for adaptive distance estimation and (2) permitting an unlimited number of adaptive queries for kernel density estimation. Finally, we complement our theoretical results with additional empirical evaluations. "}}
{"id": "p0JSSa1AuV", "cdate": 1663850413848, "mdate": null, "content": {"title": "KwikBucks: Correlation Clustering with Cheap-Weak and Expensive-Strong Signals", "abstract": "The unprecedented rate at which the sizes of machine learning (ML) models are growing necessitates novel approaches to enable efficient and scalable solutions. We contribute to this line of work by studying a novel version of the Budgeted Correlation Clustering problem (\\bcc) where along with a limited number of queries to an expensive oracle for node similarities (e.g. a large ML model), we have unlimited access to a cheaper but less accurate second oracle. Our formulation is inspired by many practical scenarios where coarse approximations of the expensive similarity metric can be efficiently obtained via weaker models. We develop a theoretically motivated algorithm in this setting that leverages the cheap oracle to judiciously query the strong oracle while maintaining high clustering quality. We empirically demonstrate gains in query minimization and clustering metrics on a variety of datasets with diverse strong and cheap oracles. Most notably, we demonstrate a practical application in text clustering based on expensive cross-attention language models by showing that cheaper (but weaker) embedding-based models can be leveraged to substantially reduce the number of inference calls to the former."}}
{"id": "74A-FDAyiL", "cdate": 1663850327953, "mdate": null, "content": {"title": "Subquadratic Algorithms for Kernel Matrices via Kernel Density Estimation", "abstract": "Kernel matrices, as well as weighted graphs represented by them, are ubiquitous objects in machine learning, statistics and other related fields. The main drawback of using kernel methods (learning and inference using kernel matrices) is efficiency -- given $n$ input points, most kernel-based algorithms need to materialize the full $n \\times n$ kernel matrix before performing any subsequent computation, thus incurring $\\Omega(n^2)$ runtime. Breaking this quadratic barrier for various problems has therefore, been a subject of extensive research efforts. \n\nWe break the quadratic barrier and obtain \\emph{subquadratic} time  algorithms for several fundamental linear-algebraic and graph processing primitives, including approximating the top eigenvalue and eigenvector, spectral sparsification, solving linear systems, local clustering, low-rank approximation, arboricity estimation and counting weighted triangles. We build on the recently developed Kernel Density Estimation framework, which (after preprocessing in time subquadratic in $n$) can return estimates of row/column sums of the kernel matrix. In particular, we develop efficient reductions from \\emph{weighted vertex} and \\emph{weighted edge sampling} on kernel graphs, \\emph{simulating random walks} on kernel graphs, and \\emph{importance sampling} on matrices to Kernel Density Estimation and show that we can generate samples from these distributions in \\emph{sublinear} (in the support of the distribution) time. Our reductions are the central ingredient in each of our applications and we believe they may be of independent interest. We empirically demonstrate the efficacy of our algorithms on low-rank approximation (LRA) and spectral sparsification, where we observe a $\\textbf{9x}$ decrease in the number of kernel evaluations over baselines for LRA and a $\\textbf{41x}$ reduction in the graph size for spectral sparsification."}}
{"id": "y--ZUTfbNB", "cdate": 1652737789029, "mdate": null, "content": {"title": "Faster Linear Algebra for Distance Matrices", "abstract": "The distance matrix of a dataset $X$ of $n$ points with respect to a distance function $f$ represents all pairwise distances between points in $X$ induced by $f$. Due to their wide applicability, distance matrices and related families of matrices have been the focus of many recent algorithmic works. We continue this line of research and take a broad view of algorithm design for distance matrices with the goal of designing fast algorithms, which are specifically tailored for distance matrices, for fundamental linear algebraic primitives. Our results include efficient algorithms for computing matrix-vector products for a wide class of distance matrices, such as the $\\ell_1$ metric for which we get a linear runtime, as well as an $\\Omega(n^2)$ lower bound for any algorithm which computes a matrix-vector product for the $\\ell_{\\infty}$ case, showing a separation between the $\\ell_1$ and the $\\ell_{\\infty}$ metrics. Our upper bound results in conjunction with recent works on the matrix-vector query model have many further downstream applications, including the fastest algorithm for computing a relative error low-rank approximation for the distance matrix induced by $\\ell_1$ and $\\ell_2^2$ functions and the fastest algorithm for computing an additive error low-rank approximation for the $\\ell_2$ metric, in addition to applications for fast matrix multiplication among others. We also give algorithms for constructing distance matrices and show that one can construct an approximate $\\ell_2$ distance matrix in time faster than the bound implied by the Johnson-Lindenstrauss lemma."}}
{"id": "KzC7Pejhp3z", "cdate": 1652737766496, "mdate": null, "content": {"title": "Learning-Augmented Algorithms for Online Linear and Semidefinite Programming", "abstract": "Semidefinite programming (SDP) is a unifying framework that generalizes both linear programming and quadratically-constrained  quadratic programming, while also yielding efficient solvers, both in theory and in practice. However, there exist known impossibility results for approximating the optimal solution when constraints for covering SDPs arrive in an online fashion. In this paper, we study online covering linear and semidefinite programs in which the algorithm is augmented with advice from a possibly erroneous predictor. We show that if the predictor is accurate, we can efficiently bypass these impossibility results and achieve a constant-factor approximation to the optimal solution, i.e., consistency. On the other hand, if the predictor is inaccurate, under some technical conditions, we achieve results that match both the classical optimal upper bounds and the tight lower bounds up to constant factors, i.e., robustness. \n\nMore broadly, we introduce a framework that extends both (1) the online set cover problem augmented with machine-learning predictors, studied by Bamas, Maggiori, and Svensson (NeurIPS 2020), and (2) the online covering SDP problem, initiated by Elad, Kale, and Naor (ICALP 2016).  Specifically, we obtain general online learning-augmented algorithms for covering linear programs with fractional advice and constraints, and initiate the study of learning-augmented algorithms for covering SDP problems. \n\nOur techniques are based on the primal-dual framework of Buchbinder and Naor (Mathematics of Operations Research, 34, 2009) and can be further adjusted to handle constraints where the variables lie in a bounded region, i.e., box constraints. "}}
{"id": "AyGJDpN2eR6", "cdate": 1652737741823, "mdate": null, "content": {"title": "Exponentially Improving the Complexity of Simulating the Weisfeiler-Lehman Test with Graph Neural Networks", "abstract": "Recent work shows that the expressive power of Graph Neural Networks (GNNs) in distinguishing non-isomorphic graphs is exactly the same as that of the Weisfeiler-Lehman (WL) graph test. In particular, they show that the WL test can be simulated by GNNs. However, those simulations involve neural networks for the \u201ccombine\u201d function of size polynomial or even exponential in the number of graph nodes $n$, as well as feature vectors of length linear in $n$. \n\nWe present an improved simulation of the WL test on GNNs with {\\em exponentially} lower complexity. In particular,  the neural network implementing the  combine function  in each node has only $\\mathrm{polylog}(n)$ parameters, and the feature vectors exchanged by the nodes of GNN consists of only $O(\\log n)$ bits. We also give logarithmic lower bounds for the feature vector length and the size of the neural networks, showing the (near)-optimality of our construction. "}}
{"id": "hjPAurYQzjF", "cdate": 1652714383581, "mdate": 1652714383581, "content": {"title": "Learning-based Support Estimation in Sublinear Time", "abstract": "We consider the problem of estimating the number of distinct elements in a large data set (or, equivalently, the support size of the distribution induced by the data set) from a random sample of its elements. The problem occurs in many applications, including biology, genomics, computer systems and linguistics. A line of research spanning the last decade resulted in algorithms that estimate the support up to $\\pm \\epsilon n$ from a sample of size $O(\\log^2(1/\\epsilon) \\cdot n/ \\log n)$, where n is the data set size. Unfortunately, this bound is known to be tight, limiting further improvements to the complexity of this problem. In this paper we consider estimation algorithms augmented with a machine-learning-based predictor that, given any element, returns an estimation of its frequency. We show that if the predictor is correct up to a constant approximation factor, then the sample complexity can be reduced significantly, to $ \\log(1/\\epsilon) \\cdot n^{1-\\Theta(1/\\log(1/\\epsilon))} $.\nWe evaluate the proposed algorithms on a collection of data sets, using the neural-network based estimators from {Hsu et al, ICLR'19} as predictors. Our experiments demonstrate substantial (up to 3x) improvements in the estimation accuracy compared to the state of the art algorithm. "}}
{"id": "9Q0B0TcUrr", "cdate": 1652714218575, "mdate": 1652714218575, "content": {"title": "Faster Fundamental Graph Algorithms via Learned Predictions", "abstract": "We consider the question of speeding up classic graph algorithms with machine-learned predictions. In this model, algorithms are furnished with extra advice learned from past or similar instances. Given the additional information, we aim to improve upon the traditional worst-case run-time guarantees. Our contributions are the following:\n(i) We give a faster algorithm for minimum-weight bipartite matching via learned duals, improving the recent result by Dinitz, Im, Lavastida, Moseley and Vassilvitskii (NeurIPS, 2021);\n(ii) We extend the learned dual approach to the single-source shortest path problem (with negative edge lengths), achieving an almost linear runtime given sufficiently accurate predictions which improves upon the classic fastest algorithm due to Goldberg (SIAM J. Comput., 1995);\n(iii) We provide a general reduction-based framework for learning-based graph algorithms, leading to new algorithms for degree-constrained subgraph and minimum-cost 0-1 flow, based on reductions to bipartite matching and the shortest path problem.\nFinally, we give a set of general learnability theorems, showing that the predictions required by our algorithms can be efficiently learned in a PAC fashion. "}}
{"id": "ZV4pNmATNpa", "cdate": 1652714149114, "mdate": 1652714149114, "content": {"title": "Randomized Dimensionality Reduction for Facility Location and Single-Linkage Clustering", "abstract": "Random dimensionality reduction is a versatile tool for speeding up algorithms for high-dimensional problems. We study its application to two clustering problems: the facility location problem, and the single-linkage hierarchical clustering problem, which is equivalent to computing the minimum spanning tree. We show that if we project the input pointset X onto a random $d=O(d_X)$-dimensional subspace (where $d_X$ is the doubling dimension of X), then the optimum facility location cost in the projected space approximates the original cost up to a constant factor. We show an analogous statement for minimum spanning tree, but with the dimension d having an extra $\\log\\log n$ term and the approximation factor being arbitrarily close to 1. Furthermore, we extend these results to approximating solutions instead of just their costs. Lastly, we provide experimental results to validate the quality of solutions and the speedup due to the dimensionality reduction. Unlike several previous papers studying this approach in the context of k-means and k-medians, our dimension bound does not depend on the number of clusters but only on the intrinsic dimensionality of X."}}
{"id": "yRb-AiWXBFz", "cdate": 1652714035423, "mdate": 1652714035423, "content": {"title": "Dimensionality Reduction for Wasserstein Barycenter ", "abstract": "The Wasserstein barycenter is a geometric construct which captures the notion of centrality among probability distributions, and which has found many applications in machine learning. However, most algorithms for finding even an approximate barycenter suffer an exponential dependence on the dimension d of the underlying space of the distributions. In order to cope with this \"curse of dimensionality,\" we study dimensionality reduction techniques for the Wasserstein barycenter problem. When the barycenter is restricted to support of size n, we show that randomized dimensionality reduction can be used to map the problem to a space of dimension $O(\\log n)$ independent of both d and k, and that \\emph{any} solution found in the reduced dimension will have its cost preserved up to arbitrary small error in the original space. We provide matching upper and lower bounds on the size of the reduced dimension, showing that our methods are optimal up to constant factors. We also provide a coreset construction for the Wasserstein barycenter problem that significantly decreases the number of input distributions. The coresets can be used in conjunction with random projections and thus further improve computation time. Lastly, our experimental results validate the speedup provided by dimensionality reduction while maintaining solution quality. "}}
