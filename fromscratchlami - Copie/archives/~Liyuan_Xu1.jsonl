{"id": "CKY1WbDh0B", "cdate": 1683229214228, "mdate": 1683229214228, "content": {"title": "Kernel Methods for Multistage Causal Inference: Mediation Analysis and Dynamic Treatment Effects", "abstract": "We propose simple estimators for mediation analysis and dynamic treatment effects over short horizons based on kernel ridge regression. We study both nonparametric response curves and semiparametric treatment effects, allowing treatments, mediators, and covariates to be continuous or discrete in general spaces. Our key innovation is a new RKHS technique called sequential mean embedding, which facilitates the construction of simple estimators for complex causal estimands, including new estimands without existing alternatives. In particular, we propose machine learning estimators of dynamic dose response curves and dynamic counterfactual distributions without restrictive linearity, Markov, or no-effect-modification assumptions. Our simple estimators preserve the generality of classic identification while also achieving nonasymptotic uniform rates for causal functions and semiparametric efficiency for causal scalars. In nonlinear simulations with many covariates, we demonstrate state-of-the-art performance. We estimate mediated and dynamic response curves of the US Job Corps program for disadvantaged youth, and share a data set that may serve as a benchmark in future work."}}
{"id": "BJCTRhmnMrg", "cdate": 1683229053266, "mdate": 1683229053266, "content": {"title": "Kernel Methods for Causal Functions: Dose, Heterogeneous, and Incremental Response Curves", "abstract": "We propose estimators based on kernel ridge regression for nonparametric causal functions such as dose, heterogeneous, and incremental response curves. Treatment and covariates may be discrete or continuous in general spaces. Due to a decomposition property specific to the RKHS, our estimators have simple closed form solutions. We prove uniform consistency with improved finite sample rates, via original analysis of generalized kernel ridge regression. We extend our main results to counterfactual distributions and to causal functions identified by front and back door criteria. In nonlinear simulations with many covariates, we achieve state-of-the-art performance."}}
{"id": "rLguqxYvYHB", "cdate": 1663850121757, "mdate": null, "content": {"title": "A Neural Mean Embedding Approach for Back-door and Front-door Adjustment", "abstract": "We consider the estimation of average and counterfactual treatment effects, under two settings:  back-door adjustment and front-door adjustment. The goal in both cases is to recover the treatment effect without having an access to a hidden confounder. This objective is attained by first estimating the conditional mean of the desired outcome variable given relevant covariates (the ``first stage\" regression), and then taking the (conditional) expectation of this function as a ``second stage\" procedure.  \nWe propose to compute these conditional expectations directly using a regression function to the learned input features of the first stage, thus avoiding the need for sampling or density estimation. All functions and features (and in particular, the output features in the second stage) are neural networks learned adaptively from data, with the sole requirement that the final layer of the first stage should be linear. The proposed method is shown to converge to the true causal parameter, and outperforms the recent state-of-the-art methods on challenging causal benchmarks, including settings involving high-dimensional image data. "}}
{"id": "0FDxsIEv9G", "cdate": 1621630214475, "mdate": null, "content": {"title": "Deep Proxy Causal Learning and its Application to Confounded Bandit Policy Evaluation", "abstract": "Proxy causal learning (PCL) is a method for estimating the causal effect of treatments on outcomes in the presence of unobserved confounding, using proxies (structured side information) for the confounder. This is achieved via two-stage regression: in the first stage, we model relations among the treatment and proxies; in the second stage, we use this model to learn the effect of treatment on the outcome, given the context provided by the proxies. PCL  guarantees recovery of the true causal effect, subject to identifiability conditions. We propose a novel method for PCL, the deep feature proxy variable method (DFPV), to address the case where the proxies, treatments, and outcomes are high-dimensional and have nonlinear complex relationships, as represented by deep neural network features. We show that DFPV outperforms recent state-of-the-art PCL methods on challenging synthetic benchmarks, including settings involving high dimensional image data. Furthermore, we show that PCL can be applied to off-policy evaluation for the confounded bandit problem, in which DFPV also exhibits competitive performance.\n"}}
{"id": "sy4Kg_ZQmS7", "cdate": 1601308184857, "mdate": null, "content": {"title": "Learning Deep Features in Instrumental Variable Regression", "abstract": "Instrumental variable (IV) regression is a standard strategy for learning causal relationships between confounded treatment and outcome variables from observational data by using an instrumental variable, which affects the outcome only through the treatment. In classical IV regression, learning proceeds in two stages: stage 1 performs linear regression from the instrument to the treatment; and stage 2 performs linear regression from the treatment to the outcome, conditioned on the instrument. We propose a novel method, deep feature instrumental variable regression (DFIV), to address the case where relations between instruments, treatments, and outcomes may be nonlinear. In this case, deep neural nets are trained to define informative nonlinear features on the instruments and treatments. We propose an alternating training regime for these features to ensure good end-to-end performance when composing stages 1 and 2, thus obtaining highly flexible feature maps in a computationally efficient manner.\nDFIV outperforms recent state-of-the-art methods on challenging IV benchmarks, including settings involving high dimensional image data. DFIV also exhibits competitive performance in off-policy policy evaluation for reinforcement learning, which can be understood as an IV regression task."}}
{"id": "rJlEdESlIH", "cdate": 1567802476187, "mdate": null, "content": {"title": "Uncoupled Regression from Pairwise Comparison Data", "abstract": "Uncoupled regression is the problem to learn a model from unlabeled data and the set of target values while the correspondence between them is unknown. Such a situation arises in predicting anonymized targets that involve sensitive information, e.g., one's annual income. Since existing methods for uncoupled regression often require strong assumptions on the true target function, and thus, their range of applications is limited, we introduce a novel framework that does not require such assumptions in this paper. Our key idea is to utilize \\emph{pairwise comparison data, which consists of pairs of unlabeled data that we know which one has a larger target value. Such pairwise comparison data is easy to collect, as typically discussed in the learning-to-rank scenario, and does not break the anonymity of data. We propose two practical methods for uncoupled regression from pairwise comparison data and show that the learned regression model converges to the optimal model with the optimal parametric convergence rate when the target variable distributes uniformly. Moreover, we empirically show that for linear models the proposed methods are comparable to ordinary supervised regression with labeled data."}}
{"id": "BsLWpGGeOpS", "cdate": 1546300800000, "mdate": null, "content": {"title": "Dueling Bandits with Qualitative Feedback.", "abstract": "We formulate and study a novel multi-armed bandit problem called the qualitative dueling bandit (QDB) problem, where an agent observes not numeric but qualitative feedback by pulling each arm. We employ the same regret as the dueling bandit (DB) problem where the duel is carried out by comparing the qualitative feedback. Although we can naively use classic DB algorithms for solving the QDB problem, this reduction significantly worsens the performance\u2014actually, in the QDB problem, the probability that one arm wins the duel over another arm can be directly estimated without carrying out actual duels. In this paper1, we propose such direct algorithms for the QDB problem. Our theoretical analysis shows that the proposed algorithms significantly outperform DB algorithms by incorporating the qualitative feedback, and experimental results also demonstrate vast improvement over the existing DB algorithms."}}
