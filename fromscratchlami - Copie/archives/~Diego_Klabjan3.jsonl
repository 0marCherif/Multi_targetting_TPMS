{"id": "fIfbngGDeKu", "cdate": 1670982751190, "mdate": 1670982751190, "content": {"title": "Listwise learning to rank by exploring unique ratings", "abstract": "In this paper, we propose new listwise learning-to-rank models\nthat mitigate the shortcomings of existing ones. Existing listwise\nlearning-to-rank models are generally derived from the classical\nPlackett-Luce model, which has three major limitations. (1) Its permutation probabilities overlook ties, i.e., a situation when more than\none document has the same rating with respect to a query. This can\nlead to imprecise permutation probabilities and inefficient training\nbecause of selecting documents one by one. (2) It does not favor\ndocuments having high relevance. (3) It has a loose assumption that\nsampling documents at different steps is independent. To overcome\nthe first two limitations, we model ranking as selecting documents\nfrom a candidate set based on unique rating levels in decreasing\norder. The number of steps in training is determined by the number\nof unique rating levels. More specifically, in each step, we apply\nmultiple multi-class classification tasks to a document candidate\nset and choose all documents that have the highest rating from the\ndocument set. This is in contrast to taking one document step by\nstep in the classical Plackett-Luce model. Afterward, we remove all\nof the selected documents from the document set and repeat until\nthe remaining documents all have the lowest rating. We propose\na new loss function and associated four models for the entire sequence of weighted classification tasks by assigning high weights\nto the selected documents with high ratings for optimizing Normalized Discounted Cumulative Gain (NDCG). To overcome the final\nlimitation, we further propose a novel and efficient way of refining\nprediction scores by combining an adapted Vanilla Recurrent Neural Network (RNN) model with pooling given selected documents\nat previous steps. We encode all of the documents already selected\nby an RNN model. In a single step, we rank all of the documents\nwith the same ratings using the last cell of the RNN multiple times.\nWe have implemented our models using three settings: neural networks, neural networks with gradient boosting, and regression\ntrees with gradient boosting. We have conducted experiments on\nfour public datasets. The experiments demonstrate that the models\nnotably outperform state-of-the-art learning-to-rank models."}}
