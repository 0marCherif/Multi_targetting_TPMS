{"id": "dBhCawpMbCO", "cdate": 1696288554571, "mdate": null, "content": {"title": "Rich-Item Recommendations for Rich-Users: Exploiting Dynamic and Static Side Information", "abstract": "In this paper, we study the problem of recommendation system where the users/items to be\nrecommended are \u201drich\u201d data structures with multiple entity types and with multiple sources\nof side-information in the form of graphs. We provide a general formulation for the problem\nthat captures the complexities of modern real-world recommendations and generalizes many\nexisting formulations. In our formulation, each user/document that requires a recommendation\nand each item/tag that is to be recommended, both are modeled by a set of static entities and\na dynamic component. The relationships between entities are captured by several weighted\nbipartite graphs. To effectively exploit these complex interactions and learn the recommendation model, we propose MEDRES \u2013 a multiple graph-CNN based novel deep-learning architecture. MEDRES uses AL-GCN, a novel graph convolution network block, that harnesses\nstrong representative features from the underlying graphs. Moreover, in order to capture highly\nheterogeneous engagement of different users with the system and constraints on the number of\nitems to be recommended, we propose a novel ranking metric pAp@k along with a method to\noptimize the metric directly. We demonstrate effectiveness of our method on two benchmarks: a) citation data, b) Flickr data. In addition, we present two real-world case studies of our formulation and the MEDRES architecture. We show how our technique can be used to naturally model the message recommendation problem and the teams recommendation problem in the\nMicrosoft Teams (MSTeams) product and demonstrate that it is 5-6% points more accurate\nthan the production-grade models."}}
{"id": "HcUdtvUoqx5", "cdate": 1646077537270, "mdate": null, "content": {"title": "Quadratic Metric Elicitation for Fairness and Beyond", "abstract": "Metric elicitation is a recent framework for eliciting classification performance metrics that best reflect implicit user preferences based on the task and context. However, available elicitation strategies have been limited to linear (or quasi-linear) functions of predictive rates, which can be practically restrictive for many applications including fairness. This paper develops a strategy for eliciting more flexible multiclass metrics defined by quadratic functions of rates, designed to reflect human preferences better. We show its application in eliciting quadratic violation-based group-fair metrics. Our strategy requires only relative preference feedback, is robust to noise, and achieves near-optimal query complexity. We further extend this strategy to eliciting polynomial metrics -- thus broadening the use cases for metric elicitation."}}
{"id": "9jeuXoAXyNi", "cdate": 1620758426316, "mdate": null, "content": {"title": "Optimization and Analysis of the pAp@k Metric for Recommender Systems ", "abstract": "Modern recommendation and notifcation systems must be robust to data imbalance, limitations on the number of recommendations/notifcations, and heterogeneous engagement profles across users. The pAp@k metric, which combines the partial-AUC and the precision@k metrics, was recently proposed to evaluate such recommendation systems and has been used in real-world deployments. Conceptually, pAp@k measures the probability of correctly ranking a top-ranked positive instance over top-ranked negative instances. Due to the combinatorial aspect surfaced by topranked points, little is known about the characteristics and optimization methods of pAp@k. In this paper, we analyze the learning-theoretic properties of pAp@k, particularly its benefts in evaluating modern recommender systems, and propose novel surrogates that are consistent under certain data regularity conditions. We then provide gradient descent based algorithms to optimize the surrogates directly. Our analysis and experimental evaluation suggest that pAp@k indeed exhibits a certain dual behavior with respect to partialAUC and precision@k. Moreover, the proposed methods outperform all the baselines in various applications. Taken together, our results motivate the use of pAp@k for large-scale recommender systems with heterogeneous user-engagement."}}
{"id": "UCs7ZXjI0jl", "cdate": 1620758255303, "mdate": null, "content": {"title": "Performance Metric Elicitation from Pairwise Classifier Comparisons", "abstract": "Given a binary prediction problem, which performance metric should the classifier optimize? We address this question by formalizing the problem of Metric Elicitation. The goal of metric elicitation is to discover the performance metric of a practitioner, which reflects her innate rewards (costs) for correct (incorrect) classification. In particular, we focus on eliciting binary classification performance metrics from pairwise feedback, where a practitioner is queried to provide relative preference between two classifiers. By exploiting key geometric properties of the space of confusion matrices, we obtain provably query efficient algorithms for eliciting linear and linear-fractional performance metrics. We further show that our method is robust to feedback and finite sample noise."}}
{"id": "IhPJUyKiw9w", "cdate": 1618414151550, "mdate": null, "content": {"title": "Quadratic Metric Elicitation with Application to Fairness", "abstract": "Metric elicitation is a recent framework for eliciting performance metrics that best reflect implicit user preferences. This framework enables a practitioner to adjust the performance metrics based on the application, context, and population at hand. However, available elicitation strategies have been limited to linear (or fractional-linear) functions of predictive rates. In this paper, we develop an approach to elicit from a wider range of complex multiclass metrics defined by quadratic functions of rates by exploiting their local linear structure. We apply this strategy to elicit quadratic metrics for group-based fairness, and also discuss how it can be generalized to higher-order polynomials. Our elicitation strategies require only relative preference feedback and are robust to both feedback and finite sample noise.\n"}}
{"id": "6foahqUfKgY", "cdate": 1618413883967, "mdate": null, "content": {"title": "Fair Performance Metric Elicitation", "abstract": "What is a fair performance metric? We consider the choice of fairness metrics through the lens of metric elicitation -- a principled framework for selecting performance metrics that best reflect implicit preferences. The use of metric elicitation enables a practitioner to tune the performance and fairness metrics to the task, context, and population at hand. Specifically, we propose a novel strategy to elicit group-fair performance metrics for multiclass classification problems with multiple sensitive groups that also includes selecting the trade-off between predictive performance and fairness violation. The proposed elicitation strategy requires only relative preference feedback and is robust to both finite sample and feedback noise.\n"}}
{"id": "9OHI8a0yimN", "cdate": 1618413639357, "mdate": null, "content": {"title": "Optimizing Black-box Metrics with Iterative Example Weighting", "abstract": "We consider learning to optimize a classification metric defined by a black-box function of\nthe confusion matrix. Such black-box learning settings are ubiquitous, for example, when the\nlearner only has query access to the metric of interest, or in noisy-label and domain adaptation\napplications where the learner must evaluate the metric via performance evaluation using a\nsmall validation sample. Our approach is to adaptively learn example weights on the training\ndataset such that the resulting weighted objective best approximates the metric on the validation\nsample. We show how to model and estimate the example weights and use them to iteratively\npost-shift a pre-trained class probability estimator to construct a classifier. We also analyze the\nresulting procedure\u2019s statistical properties. Experiments on various label noise, domain shift, and\nfair classification setups confirm that our proposal is better than the individual state-of-the-art\nbaselines for each application."}}
{"id": "Al7aZ7oqmS6", "cdate": 1618413516720, "mdate": null, "content": {"title": "Optimizing Black-box Metrics with Iterative Example Weighting", "abstract": "We consider learning to optimize a classification metric defined by a black-box function of\nthe confusion matrix. Such black-box learning settings are ubiquitous, for example, when the\nlearner only has query access to the metric of interest, or in noisy-label and domain adaptation\napplications where the learner must evaluate the metric via performance evaluation using a\nsmall validation sample. Our approach is to adaptively learn example weights on the training\ndataset such that the resulting weighted objective best approximates the metric on the validation\nsample. We show how to model and estimate the example weights and use them to iteratively\npost-shift a pre-trained class probability estimator to construct a classifier. We also analyze the\nresulting procedure\u2019s statistical properties. Experiments on various label noise, domain shift, and\nfair classification setups confirm that our proposal is better than the individual state-of-the-art\nbaselines for each application."}}
{"id": "zxcA5RYxdWl", "cdate": 1618413451656, "mdate": null, "content": {"title": "Optimizing Black-box Metrics with Iterative Example Weighting", "abstract": "Optimizing Black-box Metrics with\nIterative Example Weighting"}}
{"id": "Syf5CNHxUH", "cdate": 1567802578425, "mdate": null, "content": {"title": "Multiclass Performance Metric Elicitation", "abstract": "Metric Elicitation is a principled framework for selecting the performance metric that best reflects implicit user preferences. However, available strategies have so far been limited to binary classification. In this paper, we propose novel strategies for eliciting multiclass classification performance metrics using only relative preference feedback. We also show that the strategies are robust to both finite sample and feedback noise."}}
