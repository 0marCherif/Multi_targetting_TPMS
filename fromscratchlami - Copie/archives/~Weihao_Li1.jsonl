{"id": "f36H_jCdUK", "cdate": 1672531200000, "mdate": 1682659854176, "content": {"title": "Weakly-supervised Point Cloud Instance Segmentation with Geometric Priors", "abstract": "This paper investigates how to leverage more readily acquired annotations, i.e., 3D bounding boxes instead of dense point-wise labels, for instance segmentation. We propose a Weakly-supervised point cloud Instance Segmentation framework with Geometric Priors (WISGP) that allows segmentation models to be trained with 3D bounding boxes of instances. Considering intersections among bounding boxes in a scene would result in ambiguous la- bels, we first group points into two sets, i.e., univocal and equivocal sets, indicating the certainty of a 3D point belonging to an instance, respectively. Specifically, 3D points with clear labels belong to the univocal set while the rest are grouped into the equivocal set. To assign reliable labels to points in the equivocal set, we design a Geometry-guided Label Propagation (GLP) scheme that progressively propagates labels to linked points based on geometric structure, e.g., polygon meshes and superpoints. Afterwards, we train an instance segmentation model with the univocal points and equivocal points labeled by GLP, and then employ it to assign pseudo labels for the remainder of the unlabeled points. Lastly, we retrain the model with all the labeled points to achieve better instance segmentation performance. Experiments on large-scale datasets ScanNet-v2 and S3DIS demonstrate that WISGP is superior to competing weakly-supervised algorithms and even on par with a few fully-supervised ones."}}
{"id": "F6Ax80zrp2", "cdate": 1672531200000, "mdate": 1682659854193, "content": {"title": "Image co-segmentation based on pyramid features cross-correlation network", "abstract": "In this study, we propose an end-to-end deep learning method to accomplish image co-segmentation pair-wise. The Siamese encoder network is used to extract the high-level features. The core cross-correlation module is based on depth-wise convolution, which models the common semantic information between images from the perspective of feature similarity matching on each channel. And this module can highlight the center position of the high-level features of common objects. A multi-scale feature pyramid is constructed to improve the model\u2019s adaptability for objects of different sizes. We conducted the experiments on several public datasets. The experimental results show that our approach achieves state-of-the-art performance and can well accomplish the image co-segmentation task. Additionally, several groups of ablation experiments are designed to show the segmentation effect under different hyperparameters. The results show a good effect based on the cross-correlation operation of the pyramid features. Please see Appendixes A\u2013C for details."}}
{"id": "69O7jqKqGZf", "cdate": 1648683567270, "mdate": 1648683567270, "content": {"title": "Deep Object Co-Segmentation", "abstract": "This work presents a deep object co-segmentation (DOCS) approach for segmenting common objects of the same class within a pair of images. This means that the method learns to ignore common, or uncommon, background stuff and focuses on common objects. If multiple object classes are presented in the image pair, they are jointly extracted as foreground. To address this task, we propose a CNN-based Siamese encoder-decoder architecture. The encoder extracts high-level semantic features of the foreground objects, a mutual correlation layer detects the common objects, and finally, the decoder generates the output foreground masks for each image. To train our model, we compile a large object co-segmentation dataset consisting of image pairs from the PASCAL dataset with common objects masks. We evaluate our approach on commonly used datasets for co-segmentation tasks and observe that our approach consistently outperforms competing methods, for both seen and unseen object classes."}}
{"id": "meMsqCgLKHd", "cdate": 1640995200000, "mdate": 1682659854181, "content": {"title": "A Hyperspectral and RGB Dataset for Building Fa\u00e7ade Segmentation", "abstract": "Hyperspectral Imaging (HSI) provides detailed spectral information and has been utilised in many real-world applications. This work introduces an HSI dataset of building facades in a light industry environment with the aim of classifying different building materials in a scene. The dataset is called the Light Industrial Building HSI (LIB-HSI) dataset. This dataset consists of nine categories and 44 classes. In this study, we investigated deep learning based semantic segmentation algorithms on RGB and hyperspectral images to classify various building materials, such as timber, brick and concrete. Our dataset is publicly available at CSIRO data access portal ."}}
{"id": "h3pvzMkrQX", "cdate": 1640995200000, "mdate": 1668597539664, "content": {"title": "Towards Open-Set Object Detection and Discovery", "abstract": "With the human pursuit of knowledge, open-set object detection (OSOD) has been designed to identify unknown objects in a dynamic world. However, an issue with the current setting is that all the predicted unknown objects share the same category as \"unknown\", which require incremental learning via a human-in-the-loop approach to label novel classes. In order to address this problem, we present a new task, namely Open-Set Object Detection and Discovery (OSODD). This new task aims to extend the ability of open-set object detectors to further discover the categories of unknown objects based on their visual appearance without human effort. We propose a two-stage method that first uses an open-set object detector to predict both known and unknown objects. Then, we study the representation of predicted objects in an unsupervised manner and discover new categories from the set of unknown objects. With this method, a detector is able to detect objects belonging to known classes and define novel categories for objects of unknown classes with minimal supervision. We show the performance of our model on the MS-COCO dataset under a thorough evaluation protocol. We hope that our work will promote further research towards a more robust real-world detection system."}}
{"id": "VNM9MHgYdC", "cdate": 1640995200000, "mdate": 1668597539686, "content": {"title": "Blind Image Decomposition", "abstract": "We propose and study a novel task named Blind Image Decomposition (BID), which requires separating a superimposed image into constituent underlying images in a blind setting, that is, both the source components involved in mixing as well as the mixing mechanism are unknown. For example, rain may consist of multiple components, such as rain streaks, raindrops, snow, and haze. Rainy images can be treated as an arbitrary combination of these components, some of them or all of them. How to decompose superimposed images, like rainy images, into distinct source components is a crucial step toward real-world vision systems. To facilitate research on this new task, we construct multiple benchmark datasets, including mixed image decomposition across multiple domains, real-scenario deraining, and joint shadow/reflection/watermark removal. Moreover, we propose a simple yet general Blind Image Decomposition Network (BIDeN) to serve as a strong baseline for future work. Experimental results demonstrate the tenability of our benchmarks and the effectiveness of BIDeN. Codes and datasets are available at GitHub ."}}
{"id": "V8SqPVXFexL", "cdate": 1640995200000, "mdate": 1668023522515, "content": {"title": "You Only Cut Once: Boosting Data Augmentation with a Single Cut", "abstract": "We present You Only Cut Once (YOCO) for performing data augmentations. YOCO cuts one image into two pieces and performs data augmentations individually within each piece. Applying YOCO improves the diversity of the augmentation per sample and encourages neural networks to recognize objects from partial information. YOCO enjoys the properties of parameter-free, easy usage, and boosting almost all augmentations for free. Thorough experiments are conducted to evaluate its effectiveness. We first demonstrate that YOCO can be seamlessly applied to varying data augmentations, neural network architectures, and brings performance gains on CIFAR and ImageNet classification tasks, sometimes surpassing conventional image-level augmentation by large margins. Moreover, we show YOCO benefits contrastive pre-training toward a more powerful representation that can be better transferred to multiple downstream tasks. Finally, we study a number of variants of YOCO and empirically analyze the performance for respective settings. Code is available at GitHub."}}
{"id": "TkPMGi_z6v", "cdate": 1640995200000, "mdate": 1682319107682, "content": {"title": "PointCaM: Cut-and-Mix for Open-Set Point Cloud Analysis", "abstract": "Point cloud analysis is receiving increasing attention, however, most existing point cloud models lack the practical ability to deal with the unavoidable presence of unknown objects. This paper mainly discusses point cloud analysis under open-set settings, where we train the model without data from unknown classes and identify them in the inference stage. Basically, we propose to solve open-set point cloud analysis using a novel Point Cut-and-Mix mechanism consisting of Unknown-Point Simulator and Unknown-Point Estimator modules. Specifically, we use the Unknown-Point Simulator to simulate unknown data in the training stage by manipulating the geometric context of partial known data. Based on this, the Unknown-Point Estimator module learns to exploit the point cloud's feature context for discriminating the known and unknown data. Extensive experiments show the plausibility of open-set point cloud analysis and the effectiveness of our proposed solutions. Our code is available at \\url{https://github.com/ShiQiu0419/pointcam}."}}
{"id": "M__dT9YIsvk", "cdate": 1640995200000, "mdate": 1668023522508, "content": {"title": "GOSS: Towards Generalized Open-set Semantic Segmentation", "abstract": "In this paper, we present and study a new image segmentation task, called Generalized Open-set Semantic Segmentation (GOSS). Previously, with the well-known open-set semantic segmentation (OSS), the intelligent agent only detects the unknown regions without further processing, limiting their perception of the environment. It stands to reason that a further analysis of the detected unknown pixels would be beneficial. Therefore, we propose GOSS, which unifies the abilities of two well-defined segmentation tasks, OSS and generic segmentation (GS), in a holistic way. Specifically, GOSS classifies pixels as belonging to known classes, and clusters (or groups) of pixels of unknown class are labelled as such. To evaluate this new expanded task, we further propose a metric which balances the pixel classification and clustering aspects. Moreover, we build benchmark tests on top of existing datasets and propose a simple neural architecture as a baseline, which jointly predicts pixel classification and clustering under open-set settings. Our experiments on multiple benchmarks demonstrate the effectiveness of our baseline. We believe our new GOSS task can produce an expressive image understanding for future research. Code will be made available."}}
{"id": "5Kb_OcYjky", "cdate": 1640995200000, "mdate": 1668023514232, "content": {"title": "You Only Cut Once: Boosting Data Augmentation with a Single Cut", "abstract": "We present You Only Cut Once (YOCO) for performing data augmentations. YOCO cuts one image into two pieces and performs data augmentations individually within each piece. Applying YOCO improves the..."}}
