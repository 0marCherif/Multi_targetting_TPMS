{"id": "8s2OeW8DLm9", "cdate": 1707453585177, "mdate": 1707453585177, "content": {"title": "Annotating and Detecting Fine-grained Factual Errors for Dialogue Summarization", "abstract": "A series of datasets and models have been proposed for summaries generated for well-formatted documents such as news articles. Dialogue summaries, however, have been under explored. In this paper, we present the first dataset with fine-grained factual error annotations named DIASUMFACT. We define fine-grained factual error detection as a sentence-level multi-label classification problem, and we evaluate two state-of-the-art (SOTA) models on our dataset. Both models yield sub-optimal results, with a macro-averaged F1 score of around 0.25 over 6 error classes. We further propose an unsupervised model ENDERANKER via candidate ranking using pretrained encoder-decoder models. Our model performs on par with the SOTA models while requiring fewer resources. These observations confirm the challenges in detecting factual errors from dialogue summaries, which call for further studies, for which our dataset and results offer a solid foundation."}}
{"id": "rEC8fcD2uLg", "cdate": 1684342598469, "mdate": 1684342598469, "content": {"title": "FedGS: Federate Graph-based Sampling with Arbitrary Client Availability", "abstract": "While federated learning has shown strong results in opti-\nmizing a machine learning model without direct access to\nthe original data, its performance may be hindered by in-\ntermittent client availability which slows down the conver-\ngence and biases the final learned model. There are significant\nchallenges to achieve both stable and bias-free training un-\nder arbitrary client availability. To address these challenges,\nwe propose a framework named Federated Graph-based Sam-\npling (FEDGS), to stabilize the global model update and\nmitigate the long-term bias given arbitrary client availabil-\nity simultaneously. First, we model the data correlations of\nclients with a Data-Distribution-Dependency Graph (3DG)\nthat helps keep the sampled clients data apart from each other,\nwhich is theoretically shown to improve the approximation\nto the optimal model update. Second, constrained by the far-\ndistance in data distribution of the sampled clients, we fur-\nther minimize the variance of the numbers of times that the\nclients are sampled, to mitigate long-term bias. To validate\nthe effectiveness of FEDGS, we conduct experiments on three\ndatasets under a comprehensive set of seven client availability\nmodes. Our experimental results confirm FEDGS\u2019s advantage\nin both enabling a fair client-sampling scheme and improving\nthe model performance under arbitrary client availability. Our\ncode is available at https://github.com/WwZzz/FedGS."}}
{"id": "olZrW0wMF7o", "cdate": 1684342371609, "mdate": 1684342371609, "content": {"title": "Federated Learning with Fair Averaging", "abstract": "Fairness has emerged as a critical problem in feder-\nated learning (FL). In this work, we identify a cause\nof unfairness in FL \u2013 conflicting gradients with\nlarge differences in the magnitudes.\nTo address\nthis issue, we propose the federated fair averaging\n(FedFV) algorithm to mitigate potential conflicts\namong clients before averaging their gradients. We\nfirst use the cosine similarity to detect gradient con-\nflicts, and then iteratively eliminate such conflicts\nby modifying both the direction and the magnitude\nof the gradients. We further show the theoretical\nfoundation of FedFV to mitigate the issue conflict-\ning gradients and converge to Pareto stationary so-\nlutions. Extensive experiments on a suite of fed-\nerated datasets confirm that FedFV compares fa-\nvorably against state-of-the-art methods in terms of\nfairness, accuracy and efficiency. The source code\nis available at https://github.com/WwZzz/easyFL."}}
{"id": "QQhNSe0eDw", "cdate": 1684315756713, "mdate": 1684315756713, "content": {"title": "Generative Image Inpainting with Submanifold Alignment", "abstract": "Image inpainting aims at restoring missing regions of corrupted images, which has many applications such as image restoration and object removal. However, current GAN-based generative inpainting models do not explicitly exploit the structural or textural consistency between restored contents and their surrounding contexts. To address this limitation, we propose to enforce the alignment (or closeness) between the local data submanifolds (or subspaces) around restored images and those around the original (uncorrupted) images during\nthe learning process of GAN-based inpainting models. We exploit Local Intrinsic Dimensionality (LID) to measure, in deep feature space, the alignment between data submanifolds learned by a GAN model and those of the original data, from a perspective of both images (denoted as iLID) and local patches (denoted as pLID) of images. We then apply iLID and pLID as regularizations for GAN-based inpainting models to encourage two levels of submanifold alignment: 1) an image-level alignment for improving structural consistency, and 2) a patch-level alignment for improving textural details. Experimental results on four benchmark datasets show that our proposed model can generate more accurate results than state-of-the-art models."}}
{"id": "xdlKKKDdHA", "cdate": 1684315623188, "mdate": 1684315623188, "content": {"title": "Short-Term and Long-Term Context Aggregation Network for Video Inpainting", "abstract": "Video inpainting aims to restore missing regions of a video and has many applications such as video editing and object removal. However, existing methods either suffer from inaccurate short-term context aggregation or rarely explore long-term frame information. In this work, we present a novel context aggregation network to effectively exploit both short-term and long-term frame information for video inpainting. In the encoding stage, we propose boundary-aware short-term context aggregation, which aligns and aggregates, from neighbor frames, local regions that are closely related to the boundary context of missing regions into the target frame5. Furthermore, we propose dynamic long-term context aggregation to globally re\fne the feature map generated in the encoding stage using long-term frame features, which are dynamically updated throughout the inpainting process. Experiments show that it outperforms state-of-the-art methods with better inpainting results and fast inpainting speed."}}
{"id": "JNPfckRvKF9", "cdate": 1624295982214, "mdate": 1624295982214, "content": {"title": "Combating Selection Biases in Recommender Systems with A Few Unbiased Ratings", "abstract": "Recommendation datasets are prone to selection biases due to self-selection behavior of users and item selection process of systems. This makes explicitly combating selection biases an essential problem in training recommender systems. Most previous studies assume no unbiased data available for training.\nWe relax this assumption and assume that a small subset of training data is unbiased. Then, we propose a novel objective that utilizes the unbiased data to adaptively assign propensity weights to biased training ratings. This objective, combined with unbiased performance estimators, alleviates the effects of selection biases on the training of recommender systems. To optimize the objective, we propose an efficient algorithm that minimizes the variance of propensity estimates for better generalized recommender systems. Extensive experiments on two real-world datasets confirm the advantages of our approach in significantly reducing both the error of rating prediction and the variance of propensity estimation."}}
{"id": "wqZn00azRi0", "cdate": 1609459200000, "mdate": 1642035731574, "content": {"title": "WGCN: Graph Convolutional Networks with Weighted Structural Features", "abstract": "Graph structural information such as topologies or connectivities provides valuable guidance for graph convolutional networks (GCNs) to learn nodes' representations. Existing GCN models that capture nodes' structural information weight in- and out-neighbors equally or differentiate in- and out-neighbors globally without considering nodes' local topologies. We observe that in- and out-neighbors contribute differently for nodes with different local topologies. To explore the directional structural information for different nodes, we propose a GCN model with weighted structural features, named WGCN. WGCN first captures nodes' structural fingerprints via a direction and degree aware Random Walk with Restart algorithm, where the walk is guided by both edge direction and nodes' in- and out-degrees. Then, the interactions between nodes' structural fingerprints are used as the weighted node structural features. To further capture nodes' high-order dependencies and graph geometry, WGCN embeds graphs into a latent space to obtain nodes' latent neighbors and geometrical relationships. Based on nodes' geometrical relationships in the latent space, WGCN differentiates latent, in-, and out-neighbors with an attention-based geometrical aggregation. Experiments on transductive node classification tasks show that WGCN outperforms the baseline models consistently by up to 17.07% in terms of accuracy on five benchmark datasets."}}
{"id": "sbHSc-TCu25", "cdate": 1609459200000, "mdate": 1642035731741, "content": {"title": "Fast, Accurate and Interpretable Time Series Classification Through Randomization", "abstract": "Time series classification (TSC) aims to predict the class label of a given time series, which is critical to a rich set of application areas such as economics and medicine. State-of-the-art TSC methods have mostly focused on classification accuracy and efficiency, without considering the interpretability of their classifications, which is an important property required by modern applications such as appliance modeling and legislation such as the European General Data Protection Regulation. To address this gap, we propose a novel TSC method - the Randomized-Supervised Time Series Forest (r-STSF). r-STSF is highly efficient, achieves state-of-the-art classification accuracy and enables interpretability. r-STSF takes an efficient interval-based approach to classify time series according to aggregate values of discriminatory sub-series (intervals). To achieve state-of-the-art accuracy, r-STSF builds an ensemble of randomized trees using the discriminatory sub-series. It uses four time series representations, nine aggregation functions and a supervised binary-inspired search combined with a feature ranking metric to identify highly discriminatory sub-series. The discriminatory sub-series enable interpretable classifications. Experiments on extensive datasets show that r-STSF achieves state-of-the-art accuracy while being orders of magnitude faster than most existing TSC methods. It is the only classifier from the state-of-the-art group that enables interpretability. Our findings also highlight that r-STSF is the best TSC method when classifying complex time series datasets."}}
{"id": "qlVC6JDch8h", "cdate": 1609459200000, "mdate": 1642035731688, "content": {"title": "Sub-trajectory Similarity Join with Obfuscation", "abstract": "User trajectory data is becoming increasingly accessible due to the prevalence of GPS-equipped devices such as smartphones. Many existing studies focus on querying trajectories that are similar to each other in their entirety. We observe that trajectories partially similar to each other contain useful information about users' travel patterns which should not be ignored. Such partially similar trajectories are critical in applications such as epidemic contact tracing. We thus propose to query trajectories that are within a given distance range from each other for a given period of time. We formulate this problem as a sub-trajectory similarity join query named as the STS-Join. We further propose a distributed index structure and a query algorithm for STS-Join, where users retain their raw location data and only send obfuscated trajectories to a server for query processing. This helps preserve user location privacy which is vital when dealing with such data. Theoretical analysis and experiments on real data confirm the effectiveness and the efficiency of our proposed index structure and query algorithm."}}
{"id": "nCXrTP9z_o", "cdate": 1609459200000, "mdate": 1639484047977, "content": {"title": "Evaluating Document Coherence Modelling", "abstract": "While pretrained language models (\u201cLMs\u201d) have driven impressive gains over morpho-syntactic and semantic tasks, their ability to model discourse and pragmatic phenomena is less clear. As a step towards a better understanding of their discourse modelling capabilities, we propose a sentence intrusion detection task. We examine the performance of a broad range of pretrained LMs on this detection task for English. Lacking a dataset for the task, we introduce INSteD, a novel intruder sentence detection dataset, containing 170,000+ documents constructed from English Wikipedia and CNN news articles. Our experiments show that pretrained LMs perform impressively in in-domain evaluation, but experience a substantial drop in the cross-domain setting, indicating limited generalisation capacity. Further results over a novel linguistic probe dataset show that there is substantial room for improvement, especially in the cross-domain setting."}}
