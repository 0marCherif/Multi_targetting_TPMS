{"id": "wZx49i7PueH", "cdate": 1686323389440, "mdate": null, "content": {"title": "Richer Event Description: Integrating event coreference with temporal, causal and bridging annotation", "abstract": "There have been a wide range of recent annotated corpora concerning events, either regarding event coreference, the temporal order\nof events, hierarchical \u201csubevent\u201d structure of\nevents, or causal relationships between events.\nHowever, although some believe that these\ndifferent phenomena will display rich interactions, relatively few corpora annotate all of\nthose layers of annotation in a unified fashion.\nThis paper describes the annotation methodology for the Richer Event Descriptions corpus, which annotates entities, events, times,\ntheir coreference and partial coreference relations, and the temporal, causal and subevent\nrelationships between the events. It suggests\nthat such rich annotations of within-document\nevent phenomena can be built with high quality through a multi-stage annotation pipeline,\nand that the resultant corpus could be useful\nfor systems hoping to transition from the detection of isolated mentions of events toward\na richer understanding of events grounded in\nthe temporal, causal, referential and bridging\nrelations that define them"}}
{"id": "3C-FA8GC-Ro", "cdate": 1632339743203, "mdate": 1632339743203, "content": {"title": "Improved Latent Tree Induction with Distant Supervision via Span Constraints", "abstract": "For over thirty years, researchers have developed and analyzed methods for latent tree induction as an approach for unsupervised syntactic parsing. Nonetheless, modern systems still do not perform well enough compared to their supervised counterparts to have any practical use as structural annotation of text. In this work, we present a technique that uses distant supervision in the form of span constraints (i.e. phrase bracketing) to improve performance in unsupervised constituency parsing. Using a relatively small number of span constraints we can substantially improve the output from DIORA, an already competitive unsupervised parsing system. Compared with full parse tree annotation, span constraints can be acquired with minimal effort, such as with a lexicon derived from Wikipedia, to find exact text matches. Our experiments show span constraints based on entities improves constituency parsing on English WSJ Penn Treebank by more than 5 F1. Furthermore, our method extends to any domain where span constraints are easily attainable, and as a case study we demonstrate its effectiveness by parsing biomedical text from the CRAFT dataset."}}
{"id": "8Y50dBbmGU", "cdate": 1629521342491, "mdate": null, "content": {"title": "CSFCube - A Test Collection of Computer Science Research Articles for Faceted Query by Example", "abstract": "Query by Example is a well-known information retrieval task in which a document is chosen by the user as the search query and the goal is to retrieve relevant documents from a large collection. However, a document often covers multiple aspects of a topic. To address this scenario we introduce the task of faceted Query by Example in which users can also specify a finer grained aspect in addition to the input query document. We focus on the application of this task in scientific literature search. We envision models which are able to retrieve scientific papers analogous to a query scientific paper along specifically chosen rhetorical structure elements as one solution to this problem. In this work, the rhetorical structure elements, which we refer to as facets,  indicate objectives, methods, or results of a scientific paper. We introduce and describe an expert annotated test collection to evaluate models trained to perform this task. Our test collection consists of a diverse set of 50 query documents in English, drawn from computational linguistics and machine learning venues. We carefully follow the annotation guideline used by TREC for depth-k pooling (k = 100 or 250) and the resulting data collection consists of graded relevance scores with high annotation agreement. State of the art models evaluated on our dataset show a significant gap to be closed in further work. Our dataset may be accessed here: https://github.com/iesl/CSFCube"}}
{"id": "jehdgnoLPgx", "cdate": 1609459200000, "mdate": null, "content": {"title": "CSFCube - A Test Collection of Computer Science Research Articles for Faceted Query by Example", "abstract": "Query by Example is a well-known information retrieval task in which a document is chosen by the user as the search query and the goal is to retrieve relevant documents from a large collection. However, a document often covers multiple aspects of a topic. To address this scenario we introduce the task of faceted Query by Example in which users can also specify a finer grained aspect in addition to the input query document. We focus on the application of this task in scientific literature search. We envision models which are able to retrieve scientific papers analogous to a query scientific paper along specifically chosen rhetorical structure elements as one solution to this problem. In this work, the rhetorical structure elements, which we refer to as facets, indicate objectives, methods, or results of a scientific paper. We introduce and describe an expert annotated test collection to evaluate models trained to perform this task. Our test collection consists of a diverse set of 50 query documents in English, drawn from computational linguistics and machine learning venues. We carefully follow the annotation guideline used by TREC for depth-k pooling (k = 100 or 250) and the resulting data collection consists of graded relevance scores with high annotation agreement. State of the art models evaluated on our dataset show a significant gap to be closed in further work. Our dataset may be accessed here: https://github.com/iesl/CSFCube"}}
{"id": "PJCFFYFdKbo", "cdate": 1609459200000, "mdate": 1634313951612, "content": {"title": "Improved Latent Tree Induction with Distant Supervision via Span Constraints", "abstract": "For over thirty years, researchers have developed and analyzed methods for latent tree induction as an approach for unsupervised syntactic parsing. Nonetheless, modern systems still do not perform well enough compared to their supervised counterparts to have any practical use as structural annotation of text. In this work, we present a technique that uses distant supervision in the form of span constraints (i.e. phrase bracketing) to improve performance in unsupervised constituency parsing. Using a relatively small number of span constraints we can substantially improve the output from DIORA, an already competitive unsupervised parsing system. Compared with full parse tree annotation, span constraints can be acquired with minimal effort, such as with a lexicon derived from Wikipedia, to find exact text matches. Our experiments show span constraints based on entities improves constituency parsing on English WSJ Penn Treebank by more than 5 F1. Furthermore, our method extends to any domain where span constraints are easily attainable, and as a case study we demonstrate its effectiveness by parsing biomedical text from the CRAFT dataset."}}
{"id": "A9nDBMSTc1u", "cdate": 1609459200000, "mdate": 1637113700460, "content": {"title": "A Dataset for Discourse Structure in Peer Review Discussions", "abstract": "At the foundation of scientific evaluation is the labor-intensive process of peer review. This critical task requires participants to consume and interpret vast amounts of highly technical text. We show that discourse cues from rebuttals can shed light on the quality and interpretation of reviews. Further, an understanding of the argumentative strategies employed by the reviewers and authors provides useful signal for area chairs and other decision makers. This paper presents a new labeled dataset of 20k sentences contained in 506 review-rebuttal pairs in English, annotated by experts. While existing datasets annotate a subset of review sentences using various schemes, ours synthesizes existing label sets and extends them to include fine-grained annotation of the rebuttal sentences, characterizing the authors' stance towards the reviewers' criticisms and their commitment to addressing them. Further, we annotate \\textit{every} sentence in both the review and the rebuttal, including a description of the context for each rebuttal sentence."}}
{"id": "67H3WwRfbRt", "cdate": 1609459200000, "mdate": 1637086756908, "content": {"title": "Improved Latent Tree Induction with Distant Supervision via Span Constraints", "abstract": "Zhiyang Xu, Andrew Drozdov, Jay Yoon Lee, Tim O\u2019Gorman, Subendhu Rongali, Dylan Finkbeiner, Shilpa Suresh, Mohit Iyyer, Andrew McCallum. Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing. 2021."}}
{"id": "2hHBuMMG3uL", "cdate": 1609459200000, "mdate": 1637113700160, "content": {"title": "MS-Mentions: Consistently Annotating Entity Mentions in Materials Science Procedural Text", "abstract": "Tim O\u2019Gorman, Zach Jensen, Sheshera Mysore, Kevin Huang, Rubayyat Mahbub, Elsa Olivetti, Andrew McCallum. Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing. 2021."}}
{"id": "s-imWFAZFDE", "cdate": 1577836800000, "mdate": 1637113700496, "content": {"title": "ProtoQA: A Question Answering Dataset for Prototypical Common-Sense Reasoning", "abstract": "Michael Boratko, Xiang Li, Tim O\u2019Gorman, Rajarshi Das, Dan Le, Andrew McCallum. Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP). 2020."}}
{"id": "q5VZ94c5UUE", "cdate": 1577836800000, "mdate": null, "content": {"title": "MRP 2020: The Second Shared Task on Cross-Framework and Cross-Lingual Meaning Representation Parsing", "abstract": "Stephan Oepen, Omri Abend, Lasha Abzianidze, Johan Bos, Jan Hajic, Daniel Hershcovich, Bin Li, Tim O\u2019Gorman, Nianwen Xue, Daniel Zeman. Proceedings of the CoNLL 2020 Shared Task: Cross-Framework Meaning Representation Parsing. 2020."}}
