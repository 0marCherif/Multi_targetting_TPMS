{"id": "eahoFTt_7BK", "cdate": 1672531200000, "mdate": 1681809085715, "content": {"title": "Dive into the Resolution Augmentations and Metrics in Low Resolution Face Recognition: A Plain yet Effective New Baseline", "abstract": "Although deep learning has significantly improved Face Recognition (FR), dramatic performance deterioration may occur when processing Low Resolution (LR) faces. To alleviate this, approaches based on unified feature space are proposed with the sacrifice under High Resolution (HR) circumstances. To deal with the huge domain gap between HR and LR domains and achieve the best on both domains, we first took a closer look at the impacts of several resolution augmentations and then analyzed the difficulty of LR samples from the perspective of the model gradient produced by different resolution samples. Besides, we also find that the introduction of some resolutions could help the learning of lower resolutions. Based on these, we divide the LR samples into three difficulties according to the resolution and propose a more effective Multi-Resolution Augmentation. Then, due to the rapidly increasing domain gap as the resolution decreases, we carefully design a novel and effective metric loss based on a LogExp distance function that provides decent gradients to prevent oscillation near the convergence point or tolerance to small distance errors; it could also dynamically adjust the penalty for errors in different dimensions, allowing for more optimization of dimensions with large errors. Combining these two insights, our model could learn more general knowledge in a wide resolution range of images and balanced results can be achieved by our extremely simple framework. Moreover, the augmentations and metrics are the cornerstones of LRFR, so our method could be considered a new baseline for the LRFR task. Experiments on the LRFR datasets: SCface, XQLFW, and large-scale LRFR dataset: TinyFace demonstrate the effectiveness of our methods, while the degradation on HRFR datasets is significantly reduced."}}
{"id": "5LE8H1pPRRK", "cdate": 1672531200000, "mdate": 1695953802802, "content": {"title": "Gradient Attention Balance Network: Mitigating Face Recognition Racial Bias via Gradient Attention", "abstract": "Although face recognition has made impressive progress in recent years, we ignore the racial bias of the recognition system when we pursue a high level of accuracy. Previous work found that for different races, face recognition networks focus on different facial regions, and the sensitive regions of darker-skinned people are much smaller. Based on this discovery, we propose a new de-bias method based on gradient attention, called Gradient Attention Balance Network (GABN). Specifically, we use the gradient attention map (GAM) of the face recognition network to track the sensitive facial regions and make the GAMs of different races tend to be consistent through adversarial learning. This method mitigates the bias by making the network focus on similar facial regions. In addition, we also use masks to erase the Top-N sensitive facial regions, forcing the network to allocate its attention to a larger facial region. This method expands the sensitive region of darker-skinned people and further reduces the gap between GAM of darker-skinned people and GAM of Caucasians. Extensive experiments show that GABN successfully mitigates racial bias in face recognition and learns more balanced performance for people of different races."}}
{"id": "QGhdsoxyAvU", "cdate": 1640995200000, "mdate": 1681809085717, "content": {"title": "Improving Autism Spectrum Disorder Prediction by Fusion of Multiple Measures of Resting-State Functional MRI Data", "abstract": "Autism spectrum disorder (ASD) is a lifelong neurodevelopmental condition characterized by social communication, language and behavior impairments. Leveraging deep learning to automatically predict ASD has attracted more and more attention in the medical and machine learning communities. However, how to select effective measure signals for deep learning prediction is still a challenging problem. In this paper, we studied two kinds of measure signals, i.e., regional homogeneity (ReHo) and Craddock 200 (CC200), which both represents homogeneous functional activity, in the framework of deep learning, and designed a new mechanism to effectively joint them for deep learning based ASD prediction. Extensive experiments on the ABIDE dataset provide empirical evidence in support of effectiveness of our method. In particular, we obtained 79% in terms of accuracy by effectively fusing these two kinds of signals, much better than any single-measure model (ReHo SM-model: \u223c69% and CC200 SM-model: \u223c70%). These results suggest that leveraging multi-measure signals together are effective for ASD prediction."}}
{"id": "DNopBDt_X6R", "cdate": 1640995200000, "mdate": 1651828190147, "content": {"title": "Dynamic Training Data Dropout for Robust Deep Face Recognition", "abstract": "Learning with noise is a practically challenging problem in deep face recognition. Despite the success of large margin softmax loss functions, these methods are designed for clean face databases. Considering the inevitable noise in the large scale databases, we first analyze the performance of noise in the training databases. For noise-robust deep face recognition, we propose a dynamic training data dropout (DTDD) method to dynamically filter the noise in the training database and gradually form a stable refined database for model learning. Specifically, we leverage the information provided by the model predictions of accumulated training epochs, which can distinguish regular samples and noise effectively and accurately. The proposed DTDD method is easy and stable for implementation, and can be combined with existing state-of-the-art loss functions and network architectures. Extensive experiments on CASIA-WebFace, VGGFace2, and MS-Celeb-1 M databases empirically demonstrate that our proposed method can robustly train deep face recognition models in the presence of label noise and low quality images."}}
{"id": "7V_dz4-bnx", "cdate": 1640995200000, "mdate": 1681809085713, "content": {"title": "Model and Data Agreement for Learning with Noisy Labels", "abstract": "Learning with noisy labels is a vital topic for practical deep learning as models should be robust to noisy open-world datasets in the wild. The state-of-the-art noisy label learning approach JoCoR fails when faced with a large ratio of noisy labels. Moreover, selecting small-loss samples can also cause error accumulation as once the noisy samples are mistakenly selected as small-loss samples, they are more likely to be selected again. In this paper, we try to deal with error accumulation in noisy label learning from both model and data perspectives. We introduce mean point ensemble to utilize a more robust loss function and more information from unselected samples to reduce error accumulation from the model perspective. Furthermore, as the flip images have the same semantic meaning as the original images, we select small-loss samples according to the loss values of flip images instead of the original ones to reduce error accumulation from the data perspective. Extensive experiments on CIFAR-10, CIFAR-100, and large-scale Clothing1M show that our method outperforms state-of-the-art noisy label learning methods with different levels of label noise. Our method can also be seamlessly combined with other noisy label learning methods to further improve their performance and generalize well to other tasks. The code is available in https://github.com/zyh-uaiaaaa/MDA-noisy-label-learning."}}
{"id": "3qDj611MAje", "cdate": 1640995200000, "mdate": 1681809085725, "content": {"title": "Face Clustering via Adaptive Aggregation of Clean Neighbors", "abstract": "Face clustering has been widely studied to solve the problem of data annotation in large-scale unlabeled face images. In recent years, state-of-the-art performance has been updated every year based on the application of Graph Convolutional Networks(GCN) in face clustering tasks. The existing GCN-based methods make each node accept the feature information from its neighbors, and then aggregate the neighbors' information with equal weights to learn enhanced feature embedding. However, rare attention has been paid to improving the quality of aggregated information. In this paper, we aim to make each node aggregate the feature information that is more conducive to clustering. The proposed novel method named Adaptive Aggregation of Clean Neighbors(AACN) has two stages of preparation before inputting the graph into GCN. Specifically, we first design a noise edge cleaner to remove the wrong neighbors of each node to ensure that they receive more accurate neighbor information. Then, we carefully allocate adaptive weights to the clean neighbors of each node, and make all nodes aggregate the received information via adaptive aggregation instead of mean aggregation. The two-stage preparation enables nodes to learn more robust features through the GCN module. Experiments on standard face clustering benchmark MS1M show that AACN has achieved state-of-the-art performance, significantly boosting the pairwise F-score from 92.79% to 93.72% on 584K unlabeled face images and from 83.99% to 86.41% on 5.21M unlabeled face images."}}
{"id": "rxKTU7-FXa9", "cdate": 1609459200000, "mdate": 1651828190149, "content": {"title": "Augmented Face Representation Learning via Transitive Distillation", "abstract": "The wild face of large variations is hard to recognize in unconstrained scenarios. To tackle this issue, existing works synthesize and augment the variation-specific faces for recognition. However, directly feeding generated samples results in negative transfer, because the feature spaces are shifted compared with normal samples. Instead, we propose a transitive distillation network (TDNet) that introduces a transitive domain to transfer cross-variation representations, which alleviates the negative influence of synthesized data. Specifically, data of diverse variations are firstly synthesized. Then we construct distributions from different variations as teachers to distill student. The negative transfer is mitigated by adopting adaptor as a bridge to break large domain distance. To handle faces of different quality, we propose a novel strategy to define easy and hard samples, which are utilized to select specific transitive status. Meanwhile, bilateral classification with curriculum learning is proposed to improve confidence of synthesized data gradually, enhancing the robustness of representation learning. Experiments show that our method achieves superiority on unconstrained face benchmarks such as IJB-C and SCface, while maintaining competence on general test sets."}}
{"id": "rvXJF8CcWK", "cdate": 1609459200000, "mdate": 1651828190148, "content": {"title": "CASSOD-Net: Cascaded and Separable Structures of Dilated Convolution for Embedded Vision Systems and Applications", "abstract": "The field of view (FOV) of convolutional neural networks is highly related to the accuracy of inference. Dilated convolutions are known as an effective solution to the problems which require large FOVs. However, for general-purpose hardware or dedicated hardware, it usually takes extra time to handle dilated convolutions compared with standard convolutions. In this paper, we propose a network module, Cascaded and Separable Structure of Dilated (CASSOD) Convolution, and a special hardware system to handle the CASSOD networks efficiently. A CASSOD-Net includes multiple cascaded 2 x 2 dilated filters, which can be used to replace the traditional 3 x 3 dilated filters without decreasing the accuracy of inference. Two example applications, face detection and image segmentation, are tested with dilated convolutions and the proposed CASSOD modules. The new network for face detection achieves higher accuracy than the previous work with only 47% of filter weights in the dilated convolution layers of the context module. Moreover, the proposed hardware system can accelerate the computations of dilated convolutions, and it is 2.78 times faster than traditional hardware systems when the filter size is 3 x 3."}}
{"id": "eIJMIVqOWb", "cdate": 1609459200000, "mdate": 1651828190083, "content": {"title": "SFace: Sigmoid-Constrained Hypersphere Loss for Robust Face Recognition", "abstract": "Deep face recognition has achieved great success due to large-scale training databases and rapidly developing loss functions. The existing algorithms devote to realizing an ideal idea: minimizing the intra-class distance and maximizing the inter-class distance. However, they may neglect that there are also low quality training images which should not be optimized in this strict way. Considering the imperfection of training databases, we propose that intra-class and inter-class objectives can be optimized in a moderate way to mitigate overfitting problem, and further propose a novel loss function, named sigmoid-constrained hypersphere loss (SFace). Specifically, SFace imposes intra-class and inter-class constraints on a hypersphere manifold, which are controlled by two sigmoid gradient re-scale functions respectively. The sigmoid curves precisely re-scale the intra-class and inter-class gradients so that training samples can be optimized to some degree. Therefore, SFace can make a better balance between decreasing the intra-class distances for clean examples and preventing overfitting to the label noise, and contributes more robust deep face recognition models. Extensive experiments of models trained on CASIA-WebFace, VGGFace2, and MS-Celeb-1M databases, and evaluated on several face recognition benchmarks, such as LFW, MegaFace and IJB-C databases, have demonstrated the superiority of SFace."}}
{"id": "ZdEdzNRe8F3", "cdate": 1609459200000, "mdate": 1651828190145, "content": {"title": "Adaptive Label Noise Cleaning with Meta-Supervision for Deep Face Recognition", "abstract": "The training of a deep face recognition system usually faces the interference of label noise in the training data. However, it is difficult to obtain a high-precision cleaning model to remove these noises. In this paper, we propose an adaptive label noise cleaning algorithm based on meta-learning for face recognition datasets, which can learn the distribution of the data to be cleaned and make automatic adjustments based on class differences. It first learns re-liable cleaning knowledge from well-labeled noisy data, then gradually transfers it to the target data with meta-supervision to improve performance. A threshold adapter module is also proposed to address the drift problem in transfer learning methods. Extensive experiments clean two noisy in-the-wild face recognition datasets and show the effectiveness of the proposed method to reach state-of-the-art performance on the IJB-C face recognition benchmark."}}
