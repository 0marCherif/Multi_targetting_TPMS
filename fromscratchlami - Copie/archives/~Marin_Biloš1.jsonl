{"id": "VmJKUypQ8wR", "cdate": 1664310942685, "mdate": null, "content": {"title": "Modeling Temporal Data as Continuous Functions with Process Diffusion", "abstract": "Temporal data like time series are often observed at irregular intervals which is a challenging setting for  the existing machine learning methods. To tackle this problem, we view such data as samples from some underlying continuous function. We then define a diffusion-based generative model that adds  noise from a predefined stochastic process while  preserving the  continuity of the resulting underlying function.\nA neural network is trained to reverse this process which allows us to sample new realizations from the learned distribution. We define suitable stochastic processes as noise sources and introduce novel denoising and score-matching models on processes. Further, we show how to apply this approach to the  multivariate probabilistic forecasting and imputation tasks. Through our extensive experiments, we demonstrate that our method outperforms previous models on synthetic and real-world datasets."}}
{"id": "1TxMUE7cF6_", "cdate": 1663850299862, "mdate": null, "content": {"title": "Modeling Temporal Data as Continuous Functions with Process Diffusion", "abstract": "Temporal data like time series are often observed at irregular intervals which is a challenging setting for  the existing machine learning methods. To tackle this problem, we view such data as samples from some underlying continuous function. We then define a diffusion-based generative model that adds  noise from a predefined stochastic process while  preserving the  continuity of the resulting underlying function. A neural network is trained to reverse this process which allows us to sample new realizations from the learned distribution. We define suitable stochastic processes as noise sources and introduce novel denoising and score-matching models on processes. Further, we show how to apply this approach to the  multivariate probabilistic forecasting and imputation tasks. Through our extensive experiments, we demonstrate that our method outperforms previous models on synthetic and real-world datasets."}}
{"id": "cPpdBVB8uO", "cdate": 1640995200000, "mdate": 1681740739859, "content": {"title": "Modeling Temporal Data as Continuous Functions with Process Diffusion", "abstract": "Temporal data such as time series can be viewed as discretized measurements of the underlying function. To build a generative model for such data we have to model the stochastic process that governs it. We propose a solution by defining the denoising diffusion model in the function space which also allows us to naturally handle irregularly-sampled observations. The forward process gradually adds noise to functions, preserving their continuity, while the learned reverse process removes the noise and returns functions as new samples. To this end, we define suitable noise sources and introduce novel denoising and score-matching models. We show how our method can be used for multivariate probabilistic forecasting and imputation, and how our model can be interpreted as a neural process."}}
{"id": "4PnGULt37-", "cdate": 1640995200000, "mdate": 1681740739865, "content": {"title": "Irregularly-Sampled Time Series Modeling with Spline Networks", "abstract": "Observations made in continuous time are often irregular and contain the missing values across different channels. One approach to handle the missing data is imputing it using splines, by fitting the piecewise polynomials to the observed values. We propose using the splines as an input to a neural network, in particular, applying the transformations on the interpolating function directly, instead of sampling the points on a grid. To do that, we design the layers that can operate on splines and which are analogous to their discrete counterparts. This allows us to represent the irregular sequence compactly and use this representation in the downstream tasks such as classification and forecasting. Our model offers competitive performance compared to the existing methods both in terms of the accuracy and computation efficiency."}}
{"id": "XCs9rM255KZ", "cdate": 1621629806581, "mdate": null, "content": {"title": "Neural Flows: Efficient Alternative to Neural ODEs", "abstract": "Neural ordinary differential equations describe how values change in time. This is the reason why they gained importance in modeling sequential data, especially when the observations are made at irregular intervals. In this paper we propose an alternative by directly modeling the solution curves - the flow of an ODE - with a neural network. This immediately eliminates the need for expensive numerical solvers while still maintaining the modeling capability of neural ODEs. We propose several flow architectures suitable for different applications by establishing precise conditions on when a function defines a valid flow. Apart from computational efficiency, we also provide empirical evidence of favorable generalization performance via applications in time series modeling, forecasting, and density estimation."}}
{"id": "eydAgK_n_g", "cdate": 1609459200000, "mdate": 1681740739941, "content": {"title": "Neural Flows: Efficient Alternative to Neural ODEs", "abstract": "Neural ordinary differential equations describe how values change in time. This is the reason why they gained importance in modeling sequential data, especially when the observations are made at irregular intervals. In this paper we propose an alternative by directly modeling the solution curves - the flow of an ODE - with a neural network. This immediately eliminates the need for expensive numerical solvers while still maintaining the modeling capability of neural ODEs. We propose several flow architectures suitable for different applications by establishing precise conditions on when a function defines a valid flow. Apart from computational efficiency, we also provide empirical evidence of favorable generalization performance via applications in time series modeling, forecasting, and density estimation."}}
{"id": "_vR9tq485H", "cdate": 1609459200000, "mdate": 1681740739874, "content": {"title": "Scalable Normalizing Flows for Permutation Invariant Densities", "abstract": "Modeling sets is an important problem in machine learning since this type of data can be found in many domains. A promising approach defines a family of permutation invariant densities with continu..."}}
{"id": "LIR3aVGIlln", "cdate": 1601308131793, "mdate": null, "content": {"title": "Equivariant Normalizing Flows for Point Processes and Sets", "abstract": "A point process describes how random sets of exchangeable points are generated. The points usually influence the positions of each other via attractive and repulsive forces. To model this behavior, it is enough to transform the samples from the uniform process with a sufficiently complex equivariant function. However, learning the parameters of the resulting process is challenging since the likelihood is hard to estimate and often intractable. This leads us to our proposed model - CONFET. Based on continuous normalizing flows, it allows arbitrary interactions between points while having tractable likelihood. Experiments on various real and synthetic datasets show the improved performance of our new scalable approach."}}
{"id": "ynOEvNtv8AL", "cdate": 1577836800000, "mdate": 1681740739975, "content": {"title": "Towards linking social media profiles with user's WiFi preferred network list", "abstract": ""}}
{"id": "TK2q5g_0OAG", "cdate": 1577836800000, "mdate": 1681740740027, "content": {"title": "Deep Representation Learning and Clustering of Traffic Scenarios", "abstract": "Determining the traffic scenario space is a major challenge for the homologation and coverage assessment of automated driving functions. In contrast to current approaches that are mainly scenario-based and rely on expert knowledge, we introduce two data driven autoencoding models that learn a latent representation of traffic scenes. First is a CNN based spatio-temporal model that autoencodes a grid of traffic participants' positions. Secondly, we develop a pure temporal RNN based model that auto-encodes a sequence of sets. To handle the unordered set data, we had to incorporate the permutation invariance property. Finally, we show how the latent scenario embeddings can be used for clustering traffic scenarios and similarity retrieval."}}
