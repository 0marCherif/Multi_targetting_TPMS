{"id": "w-VPGvQFUk", "cdate": 1640995200000, "mdate": 1681785578948, "content": {"title": "Gaussian Process Bandits with Aggregated Feedback", "abstract": "We consider the continuum-armed bandits problem, under a novel setting of recommending the best arms within a fixed budget under aggregated feedback. This is motivated by applications where the precise rewards are impossible or expensive to obtain, while an aggregated reward or feedback, such as the average over a subset, is available. We constrain the set of reward functions by assuming that they are from a Gaussian Process and propose the Gaussian Process Optimistic Optimisation (GPOO) algorithm. We adaptively construct a tree with nodes as subsets of the arm space, where the feedback is the aggregated reward of representatives of a node. We propose a new simple regret notion with respect to aggregated feedback on the recommended arms. We provide theoretical analysis for the proposed algorithm, and recover single point feedback as a special case. We illustrate GPOO and compare it with related algorithms on simulated data."}}
{"id": "KG8NaPYVA3", "cdate": 1640995200000, "mdate": 1681553193489, "content": {"title": "Two-Stage Neural Contextual Bandits for Personalised News Recommendation", "abstract": ""}}
{"id": "jb-aLPC8n64", "cdate": 1609459200000, "mdate": 1681785578949, "content": {"title": "Quantile Bandits for Best Arms Identification", "abstract": "We consider a variant of the best arm identification task in stochastic multi-armed bandits. Motivated by risk-averse decision-making problems, our goal is to identify a set of $m$ arms with the hi..."}}
{"id": "SxZbRZANT-q", "cdate": 1609459200000, "mdate": 1647296005726, "content": {"title": "Gaussian Process Bandits with Aggregated Feedback", "abstract": "We consider the continuum-armed bandits problem, under a novel setting of recommending the best arms within a fixed budget under aggregated feedback. This is motivated by applications where the precise rewards are impossible or expensive to obtain, while an aggregated reward or feedback, such as the average over a subset, is available. We constrain the set of reward functions by assuming that they are from a Gaussian Process and propose the Gaussian Process Optimistic Optimisation (GPOO) algorithm. We adaptively construct a tree with nodes as subsets of the arm space, where the feedback is the aggregated reward of representatives of a node. We propose a new simple regret notion with respect to aggregated feedback on the recommended arms. We provide theoretical analysis for the proposed algorithm, and recover single point feedback as a special case. We illustrate GPOO and compare it with related algorithms on simulated data."}}
{"id": "q3hQIfl5DS", "cdate": 1577836800000, "mdate": 1681785578980, "content": {"title": "Quantile Bandits for Best Arms Identification with Concentration Inequalities", "abstract": "We consider a variant of the best arm identification task in stochastic multi-armed bandits. Motivated by risk-averse decision-making problems, our goal is to identify a set of $m$ arms with the highest $\\tau$-quantile values within a fixed budget. We prove asymmetric two-sided concentration inequalities for order statistics and quantiles of random variables that have non-decreasing hazard rate, which may be of independent interest. With these inequalities, we analyse a quantile version of Successive Accepts and Rejects (Q-SAR). We derive an upper bound for the probability of arm misidentification, the first justification of a quantile based algorithm for fixed budget multiple best arms identification. We show illustrative experiments for best arm identification."}}
