{"id": "dcShsUSTJu", "cdate": 1696318108563, "mdate": 1696318108563, "content": {"title": "NEF: Neural Edge Fields for 3D Parametric Curve Reconstruction from Multi-view Images", "abstract": "We study the problem of reconstructing 3D feature curves of an object from a set of calibrated multi-view images. To do so, we learn a neural implicit field representing the density distribution of 3D edges which we refer to as Neural Edge Field (NEF). Inspired by NeRF, NEF is optimized with a view-based rendering loss where a 2D edge map is rendered at a given view and is compared to the ground-truth edge map extracted from the image of that view. The rendering-based differentiable optimization of NEF fully exploits 2D edge detection, without needing a supervision of 3D edges, a 3D geometric operator or cross-view edge correspondence. Several technical designs are devised to ensure learning a range-limited and view-independent NEF for robust edge extraction. The final parametric 3D curves are extracted from NEF with an iterative optimization method. On our benchmark with synthetic data, we demonstrate that NEF outperforms existing state-of-the-art methods on all metrics. Project page: https://yunfan1202. github. io/NEF/."}}
{"id": "cEbj2EYYDE5", "cdate": 1696317994253, "mdate": 1696317994253, "content": {"title": "Weakly-supervised Single-view Image Relighting", "abstract": "We present a learning-based approach to relight a single image of Lambertian and low-frequency specular objects. Our method enables inserting objects from photographs into new scenes and relighting them under the new environment lighting, which is essential for AR applications. To relight the object, we solve both inverse rendering and re-rendering. To resolve the ill-posed inverse rendering, we propose a weakly-supervised method by a low-rank constraint. To facilitate the weakly-supervised training, we contribute Relit, a large-scale (750K images) dataset of videos with aligned objects under changing illuminations. For re-rendering, we propose a differentiable specular rendering layer to render low-frequency non-Lambertian materials under various illuminations of spherical harmonics. The whole pipeline is end-to-end and efficient, allowing for a mobile app implementation of AR object insertion. Extensive evaluations demonstrate that our method achieves state-of-the-art performance. Project page: https://renjiaoyi. github. io/relighting/."}}
{"id": "W6t8U1eGvSj", "cdate": 1663850109183, "mdate": null, "content": {"title": "Leveraging Online Semantic Point Fusion for 3D-Aware Object Goal Navigation", "abstract": "Object goal navigation in unseen environments is a fundamental task for building intelligent embodied agents. Existing works tackle this problem with modular or end-to-end learning-based methods, which implicitly learn from 2D maps, sparse scene graphs or video sequences, ignoring the established fact that objects lie in 3D. Hence, in this work, we propose a dedicated 3D-aware online semantic point fusion algorithm that online aggregates 3D points along with their semantic predictions from RGB-D observations to form a high-efficient 3D point-based sparse map, which further enables us to check spatial semantic consistency. To leverage the 3D information for navigation while remaining sample efficient, we then propose a two-stage reinforcement learning framework that decomposes the object goal navigation into two complementary sub-tasks, namely exploration and verification, each learning in a different discrete action space. Thanks to the highly accurate semantic understanding and robust goal verification, our framework achieves the best performance among all modular-based methods on the Matterport3D and Gibson datasets. Furthermore, compared to mainstream RL-based works, our method requires (5-28x) less computational cost for training. We will release the source code upon acceptance."}}
{"id": "bfuGjlCwAq", "cdate": 1632875450852, "mdate": null, "content": {"title": "Learning Efficient Online 3D Bin Packing on Packing Configuration Trees", "abstract": "Online 3D Bin Packing Problem (3D-BPP) has widespread applications in industrial automation and has aroused enthusiastic research interest recently. Existing methods usually solve the problem with limited resolution of spatial discretization, and/or cannot deal with complex practical constraints well. We propose to enhance the practical applicability of online 3D-BPP via learning on a novel hierarchical representation \u2013 packing configuration tree (PCT). PCT is a full-fledged description of the state and action space of bin packing which can support packing policy learning based on deep reinforcement learning (DRL). The size of the packing action space is proportional to the number of leaf nodes, making the DRL model easy to train and well-performing even with continuous solution space. During training, PCT expands based on heuristic rules, however, the DRL model learns a much more effective and robust packing policy than heuristic methods. Through extensive evaluation, we demonstrate that our method outperforms all existing online BPP methods and is versatile in terms of incorporating various practical constraints."}}
{"id": "ng0IIc1mbTu", "cdate": 1601308374194, "mdate": null, "content": {"title": "ARELU: ATTENTION-BASED RECTIFIED LINEAR UNIT", "abstract": "Element-wise activation functions play a critical role in deep neural networks via affecting the expressivity power and the learning dynamics. Learning-based activation functions have recently gained increasing attention and success. We propose a new perspective of learnable activation function through formulating them with element-wise attention mechanism. In each network layer, we devise an attention module which learns an element-wise, sign-based attention map for the pre-activation feature map. The attention map scales an element based on its sign. Adding the attention module with a rectified linear unit (ReLU) results in an amplification of positive elements and a suppression of negative ones, both with learned, data-adaptive parameters. We coin the resulting activation function Attention-based Rectified Linear Unit (AReLU). The attention module essentially learns an element-wise residue of the activated part of the input, as ReLU can be viewed as an identity transformation. This makes the network training more resis- tant to gradient vanishing. The learned attentive activation leads to well-focused activation of relevant regions of a feature map. Through extensive evaluations, we show that AReLU significantly boosts the performance of most mainstream network architectures with only two extra learnable parameters per layer introduced. Notably, AReLU facilitates fast network training under small learning rates, which makes it especially suited in the case of transfer learning and meta learning."}}
