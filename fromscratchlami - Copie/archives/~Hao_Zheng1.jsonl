{"id": "yWM1BaTTw0", "cdate": 1640995200000, "mdate": 1667412742096, "content": {"title": "CMC-Net: 3D calf muscle compartment segmentation with sparse annotation", "abstract": ""}}
{"id": "BL3YMoGHIIe", "cdate": 1640995200000, "mdate": 1667412742136, "content": {"title": "STNet: An End-to-End Generative Framework for Synthesizing Spatiotemporal Super-Resolution Volumes", "abstract": "We present STNet, an end-to-end generative framework that synthesizes spatiotemporal super-resolution volumes with high fidelity for time-varying data. STNet includes two modules: a generator and a spatiotemporal discriminator. The input to the generator is two low-resolution volumes at both ends, and the output is the intermediate and the two-ending spatiotemporal super-resolution volumes. The spatiotemporal discriminator, leveraging convolutional long short-term memory, accepts a spatiotemporal super-resolution sequence as input and predicts a conditional score for each volume based on its spatial (the volume itself) and temporal (the previous volumes) information. We propose an unsupervised pre-training stage using cycle loss to improve the generalization of STNet. Once trained, STNet can generate spatiotemporal super-resolution volumes from low-resolution ones, offering scientists an option to save data storage (i.e., sparsely sampling the simulation output in both spatial and temporal dimensions). We compare STNet with the baseline bicubic+linear interpolation, two deep learning solutions ( <inline-formula><tex-math notation=\"LaTeX\">$\\mathsf{SSR}+\\mathsf{TSF}$</tex-math></inline-formula> , STD), and a state-of-the-art tensor compression solution (TTHRESH) to show the effectiveness of STNet."}}
{"id": "3wHjzYL7-GZ", "cdate": 1640995200000, "mdate": 1667412742127, "content": {"title": "Usable Region Estimate for Assessing Practical Usability of Medical Image Segmentation Models", "abstract": "We aim to quantitatively measure the practical usability of medical image segmentation models: to what extent, how often, and on which samples a model\u2019s predictions can be used/trusted. We first propose a measure, Correctness-Confidence Rank Correlation (CCRC), to capture how predictions\u2019 confidence estimates correlate with their correctness scores in rank. A model with a high value of CCRC means its prediction confidences reliably suggest which samples\u2019 predictions are more likely to be correct. Since CCRC does not capture the actual prediction correctness, it alone is insufficient to indicate whether a prediction model is both accurate and reliable to use in practice. Therefore, we further propose another method, Usable Region Estimate (URE), which simultaneously quantifies predictions\u2019 correctness and reliability of confidence assessments in one estimate. URE provides concrete information on to what extent a model\u2019s predictions are usable. In addition, the sizes of usable regions (UR) can be utilized to compare models: A model with a larger UR can be taken as a more usable and hence better model. Experiments on six datasets validate that the proposed evaluation methods perform well, providing a concrete and concise measure for the practical usability of medical image segmentation models. Code is made available at https://github.com/yizhezhang2000/ure ."}}
{"id": "rF8Jj0EiyZf", "cdate": 1609459200000, "mdate": 1639071509776, "content": {"title": "Hierarchical Self-supervised Learning for Medical Image Segmentation Based on Multi-domain Data Aggregation", "abstract": "A large labeled dataset is a key to the success of supervised deep learning, but for medical image segmentation, it is highly challenging to obtain sufficient annotated images for model training. In many scenarios, unannotated images are abundant and easy to acquire. Self-supervised learning (SSL) has shown great potentials in exploiting raw data information and representation learning. In this paper, we propose Hierarchical Self-Supervised Learning (HSSL), a new self-supervised framework that boosts medical image segmentation by making good use of unannotated data. Unlike the current literature on task-specific self-supervised pretraining followed by supervised fine-tuning, we utilize SSL to learn task-agnostic knowledge from heterogeneous data for various medical image segmentation tasks. Specifically, we first aggregate a dataset from several medical challenges, then pre-train the network in a self-supervised manner, and finally fine-tune on labeled data. We develop a new loss function by combining contrastive loss and classification loss, and pre-train an encoder-decoder architecture for segmentation tasks. Our extensive experiments show that multi-domain joint pre-training benefits downstream segmentation tasks and outperforms single-domain pre-training significantly. Compared to learning from scratch, our method yields better performance on various tasks (e.g., $$+0.69\\%$$ to $$+18.60\\%$$ in Dice with $$5\\%$$ of annotated data). With limited amounts of training data, our method can substantially bridge the performance gap with respect to denser annotations (e.g., $$10\\%$$ vs.\u00a0 $$100\\%$$ annotations)."}}
{"id": "SgZJ_LJzFA", "cdate": 1609459200000, "mdate": 1667412742101, "content": {"title": "V2V: A Deep Learning Approach to Variable-to-Variable Selection and Translation for Multivariate Time-Varying Data", "abstract": "We present V2V, a novel deep learning framework, as a general-purpose solution to the variable-to-variable (V2V) selection and translation problem for multivariate time-varying data (MTVD) analysis and visualization. V2V leverages a representation learning algorithm to identify transferable variables and utilizes Kullback-Leibler divergence to determine the source and target variables. It then uses a generative adversarial network (GAN) to learn the mapping from the source variable to the target variable via the adversarial, volumetric, and feature losses. V2V takes the pairs of time steps of the source and target variable as input for training, Once trained, it can infer unseen time steps of the target variable given the corresponding time steps of the source variable. Several multivariate time-varying data sets of different characteristics are used to demonstrate the effectiveness of V2V, both quantitatively and qualitatively. We compare V2V against histogram matching and two other deep learning solutions (Pix2Pix and CycleGAN)."}}
{"id": "9AJYqcLto9g", "cdate": 1609459200000, "mdate": 1639071509617, "content": {"title": "kCBAC-Net: Deeply Supervised Complete Bipartite Networks with Asymmetric Convolutions for Medical Image Segmentation", "abstract": "Accurate and automatic medical image segmentation is challenging due to significant size and shape variations of objects (e.g., in multi-scales) and missing/blurring object borders. In this paper, we propose a new deeply supervised k-complete-bipartite network with asymmetric convolutions (kCBAC-Net) to exploit multi-scale features and improve the capability of standard convolutions for segmentation. (1) We leverage a generalized complete bipartite network to reuse multi-scale features, consolidate feature hierarchies at different scales, and preserve maximum information flow between encoder and decoder layers. (2) To further capture multi-scale information, we sequentially connect k complete bipartite network modules together to facilitate their processing in different image scales. (3) We replace the standard convolution by asymmetric convolution block to strengthen the central skeleton parts of standard convolution, enhancing the model\u2019s robustness on exploiting more discriminative features. (4) We employ auxiliary deep supervisions to boost information flow in the network and extract highly discriminative features. We evaluate our kCBAC-Net on three datasets (ultrasound lymph node segmentation (2D), 2017 ISIC Skin Lesion segmentation (2D), and MM-WHS CT (3D)), achieving state-of-the-art performance."}}
{"id": "itxaEySWawr", "cdate": 1577836800000, "mdate": 1639071510125, "content": {"title": "Cartilage Segmentation in High-Resolution 3D Micro-CT Images via Uncertainty-Guided Self-training with Very Sparse Annotation", "abstract": "Craniofacial syndromes often involve skeletal defects of the head. Studying the development of the chondrocranium (the part of the endoskeleton that protects the brain and other sense organs) is crucial to understanding genotype-phenotype relationships and early detection of skeletal malformation. Our goal is to segment craniofacial cartilages in 3D micro-CT images of embryonic mice stained with phosphotungstic acid. However, due to high image resolution, complex object structures, and low contrast, delineating fine-grained structures in these images is very challenging, even manually. Specifically, only experts can differentiate cartilages, and it is unrealistic to manually label whole volumes for deep learning model training. We propose a new framework to progressively segment cartilages in high-resolution 3D micro-CT images using extremely sparse annotation (e.g., annotating only a few selected slices in a volume). Our model consists of a lightweight fully convolutional network (FCN) to accelerate the training speed and generate pseudo labels (PLs) for unlabeled slices. Meanwhile, we take into account the reliability of PLs using a bootstrap ensemble based uncertainty quantification method. Further, our framework gradually learns from the PLs with the guidance of the uncertainty estimation via self-training. Experiments show that our method achieves high segmentation accuracy compared to prior arts and obtains performance gains by iterative self-training."}}
{"id": "_AFG-4h6vUT", "cdate": 1577836800000, "mdate": 1639071509195, "content": {"title": "InTracker: An Integrated Detector-Tracker Framework for Cell Detection and Tracking", "abstract": "Automatic tracking of moving cells in time-lapse image sequences plays an important role in studying many biological processes in development and diseases. Large variations in cell appearances, limited image resolution, and various cell behaviors (e.g., division, apoptosis, deformation, clustering, and migration in or out of the imaging window) make cell tracking a challenging task. However, known cell tracking methods were designed for and tailored to specific cell image sequences and behaviors, thus having limited applicability to various cell image sequences. Aiming toward more robust cell tracking, we propose a new detector-tracker approach for detection and association based cell tracking. First, we propose a new deep learning based detector to detect cells in each image frame and assign division/non-division labels to them. Second, we carefully design an Earth Mover's Distance (EMD) based hierarchical tracker to associate detected cells through the image sequence and form moving cell trajectories. The tracker is able to correct possible detection errors made by the detector. Evaluated on several open challenge datasets, our approach outperforms state-of-the-art cell tracking methods for determining cell trajectories."}}
{"id": "NMTM297hWJo", "cdate": 1577836800000, "mdate": 1639071509776, "content": {"title": "A Coarse-to-Fine Data Generation Method for 2D and 3D Cell Nucleus Segmentation", "abstract": "Cell nucleus segmentation is a fundamental task in biomedical image analysis. Generating realistic cell nucleus data with ground truth masks can help tackle difficulties such as insufficient training data for deep learning models and the need to deal with \"hard\" cases (e.g., tightly clumped nuclei). Known nucleus generation methods generated individual nucleus masks from parametric models or based on direct transformations of real masks. It is difficult for these methods to capture and simulate the distributions of real nuclei and interactions among hard nuclei. In this paper, we propose a new three-stage coarse-to-fine nucleus generation method for 2D and 3D nucleus segmentation. The first stage simulates the positions and sizes of nuclei; the second stage simulates the shapes of nuclei and interactions among clumped nuclei; the third stage simulates the textures of nuclei. We evaluate our method on 2D and 3D cell nucleus image datasets. Experimental results show that our new nucleus generation method considerably helps improve cell nucleus segmentation performance and outperforms known nucleus generation methods for nucleus segmentation with a small amount of training data."}}
{"id": "GP2GCVqjNPi", "cdate": 1577836800000, "mdate": 1667412742108, "content": {"title": "AntVis: A web-based visual analytics tool for exploring ant movement data", "abstract": ""}}
