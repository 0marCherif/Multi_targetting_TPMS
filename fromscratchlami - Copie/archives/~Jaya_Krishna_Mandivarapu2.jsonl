{"id": "B94Nrz1Tbq", "cdate": 1647272507964, "mdate": null, "content": {"title": "Continual Learning with Deep Artificial Neurons", "abstract": "Neurons in real brains are complex computational units, capable of input-specific damping, inter-trial memory, and context-dependent signal processing.  Artificial neurons, on the other hand, are usually implemented as simple weighted sums. Here we explore if increasing the computational power of individual neurons can yield more powerful neural networks.  Specifically, we introduce Deep Artificial Neurons (DANs)\u2014small neural networks with shared, learnable parameters embedded within a larger network.  DANs act as filters between nodes in the net-work;  namely, they receive vectorized inputs from multiple neurons in the previous layer, condense these signals into a single output, then send this processed signal to the neurons in the subsequent layer.  We demonstrate that it is possible to meta-learn shared parameters for the various DANS in the network in order to facilitate continual and transfer learning during deployment.  Specifically, we present experimental results on (1) incremental non-linear regression tasks and (2)unsupervised class-incremental image reconstruction that show that DANs allow a single network to update its synapses (i.e., regular weights) over time with minimal forgetting.  Notably, our approach uses standard backpropagation, does not require experience replay, and does need separate wake/sleep phases."}}
{"id": "nhZgzaxMk6", "cdate": 1640995200000, "mdate": 1681652377502, "content": {"title": "Real-time Interface Control with Motion Gesture Recognition based on Non-contact Capacitive Sensing", "abstract": ""}}
{"id": "gcVcwuE9vu", "cdate": 1640995200000, "mdate": 1681652377502, "content": {"title": "Deep Active Learning via Open-Set Recognition", "abstract": ""}}
{"id": "_bezNCIUdN", "cdate": 1640995200000, "mdate": 1681652377536, "content": {"title": "Deep Active Learning Using Barlow Twins", "abstract": ""}}
{"id": "Nzs5KDvcehJ", "cdate": 1633106855517, "mdate": 1633106855517, "content": {"title": "A new cross-platform architecture for epi-info software suite", "abstract": "The Epi-Info software suite, built and maintained by the Centers for Disease Control and Prevention (CDC), is widely used by epidemiologists and public health researchers to collect and analyze public health data, especially in the event of outbreaks such as Ebola and Zika. As it exists today, Epi-Info Desktop runs only on the Windows platform, and the larger Epi-Info Suite of products consists of separate codebases for several different devices and use-cases. Software portability has become increasingly important over the past few years as it offers a number of obvious benefits. These include reduced development time, reduced cost, and simplified system architecture. Thus, there is a blatant need for continued research. Specifically, it is critical to fully understand any underlying negative performance issues which arise from platform-agnostic systems. Such understanding should allow for improved design, and thus result in substantial mitigation of reduced performance. In this paper, we present a viable cross-platform architecture for Epi-Info which solves many of these problems."}}
{"id": "MhQYksD5eTB", "cdate": 1633106812267, "mdate": 1633106812267, "content": {"title": "A Cross-Platform System Architecture for Form Design and Data Analytics for Public Health", "abstract": "The CDC's Epi-Info is widely-used by epidemiologists and public health researchers to collect and analyze public health data, especially in the event of outbreaks. As it exists today, Epi-Info runs only on the Windows platform and is made of separate code-bases for several different devices and use-cases. Software portability has become increasingly important over the past few years. In this poster, we present a cross-platform architecture for Epi-Info. To simplify and expedite future development, the cross-platform system architecture uses Electron, AngularJS, and Python with the capability of running on virtually any desktop or laptop computer. Additionally, the code can be easily deployed to the Web, and has the potential to be a viable solution for several mobile use-cases."}}
{"id": "xUSQSklQyo7", "cdate": 1633106740537, "mdate": 1633106740537, "content": {"title": "Deep Active Learning via Open Set Recognition", "abstract": "In many applications, data is easy to acquire but expensive and time-consuming to label prominent examples include medical imaging and NLP. This disparity has only grown in recent years as our ability to collect data improves. Under these constraints, it makes sense to select only the most informative instances from the unlabeled pool and request an oracle (e.g., a human expert) to provide labels for those samples. The goal of active learning is to infer the informativeness of unlabeled samples so as to minimize the number of requests to the oracle. Here, we formulate active learning as an open-set recognition problem. In this paradigm, only some of the inputs belong to known classes; the classifier must identify the rest as unknown. More specifically, we leverage variational neural networks (VNNs), which produce high-confidence (i.e., low-entropy) predictions only for inputs that closely resemble the training data. We use the inverse of this confidence measure to select the samples that the oracle should label. Intuitively, unlabeled samples that the VNN is uncertain about are more informative for future training. We carried out an extensive evaluation of our novel, probabilistic formulation of active learning, achieving state-of-the-art results on MNIST, CIFAR-10, and CIFAR-100. Additionally, unlike current active learning methods, our algorithm can learn tasks without the need for task labels. As our experiments show, when the unlabeled pool consists of a mixture of samples from multiple datasets, our approach can automatically distinguish between samples from seen vs. unseen tasks."}}
{"id": "V_Cw7pZxNPK", "cdate": 1633106675109, "mdate": 1633106675109, "content": {"title": "Efficient Document Image Classification Using Region-Based Graph Neural Network", "abstract": "Document image classification remains a popular research area because it can be commercialized in many enterprise applications across different industries. Recent advancements in large pre-trained computer vision and language models and graph neural networks has lent document image classification many tools. However using large pre-trained models usually requires substantial computing resources which could defeat the cost-saving advantages of automatic document image classification. In the paper we propose an efficient document image classification framework that uses graph convolution neural networks and incorporates textual, visual and layout information of the document. We have rigorously benchmarked our proposed algorithm against several state-of-art vision and language models on both publicly available dataset and a real-life insurance document classification dataset. Empirical results on both publicly available and real-world data show that our methods achieve near SOTA performance yet require much less computing resources and time for model training and inference. This results in solutions than offer better cost advantages, especially in scalable deployment for enterprise applications. The results showed that our algorithm can achieve classification performance quite close to SOTA. We also provide comprehensive comparisons of computing resources, model sizes, train and inference time between our proposed methods and baselines. In addition we delineate the cost per image using our method and other baselines."}}
{"id": "29-RpbKq3H", "cdate": 1633106632145, "mdate": 1633106632145, "content": {"title": "Continual learning with deep artificial neurons", "abstract": "Neurons in real brains are enormously complex computational units. Among\nother things, they\u2019re responsible for transforming inbound electro-chemical vectors\ninto outbound action potentials, updating the strengths of intermediate synapses,\nregulating their own internal states, and modulating the behavior of other nearby\nneurons. One could argue that these cells are the only things exhibiting any\nsemblance of real intelligence. It is odd, therefore, that the machine learning\ncommunity has, for so long, relied upon the assumption that this complexity can be\nreduced to a simple sum and fire operation. We ask, might there be some benefit to\nsubstantially increasing the computational power of individual neurons in artificial\nsystems? To answer this question, we introduce Deep Artificial Neurons (DANs),\nwhich are themselves realized as deep neural networks. Conceptually, we embed\nDANs inside each node of a traditional neural network, and we connect these\nneurons at multiple synaptic sites, thereby vectorizing the connections between\npairs of cells. We demonstrate that it is possible to meta-learn a single parameter\nvector, which we dub a neuronal phenotype, shared by all DANs in the network,\nwhich facilitates a meta-objective during deployment. Here, we isolate continual\nlearning as our meta-objective, and we show that a suitable neuronal phenotype can\nendow a single network with an innate ability to update its synapses with minimal\nforgetting, using standard backpropagation, without experience replay, nor separate\nwake/sleep phases. We demonstrate this ability on sequential non-linear regression\ntasks."}}
{"id": "sVgkHcH1-mT", "cdate": 1633106585644, "mdate": 1633106585644, "content": {"title": "Self-net: Lifelong learning via continual self-modeling", "abstract": "Learning a set of tasks over time, also known as continual learning (CL), is one of the most challenging problems in artificial intelligence. While recent approaches achieve some degree of CL in deep neural networks, they either (1) store a new network (or an equivalent number of parameters) for each new task, (2) store training data from previous tasks, or (3) restrict the network's ability to learn new tasks. To address these issues, we propose a novel framework, Self-Net, that uses an autoencoder to learn a set of low-dimensional representations of the weights learned for different tasks. We demonstrate that these low-dimensional vectors can then be used to generate high-fidelity recollections of the original weights. Self-Net can incorporate new tasks over time with little retraining, minimal loss in performance for older tasks, and without storing prior training data. We show that our technique achieves over 10X storage compression in a continual fashion, and that it outperforms state-of-the-art approaches on numerous datasets, including continual versions of MNIST, CIFAR10, CIFAR100, Atari, and task-incremental CORe50. To the best of our knowledge, we are the first to use autoencoders to sequentially encode sets of network weights to enable continual learning."}}
