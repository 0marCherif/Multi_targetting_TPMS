{"id": "-fORBF5k2ZB", "cdate": 1632875558109, "mdate": null, "content": {"title": "Gating Mechanisms Underlying Sequence-to-Sequence Working Memory", "abstract": "Working memory is the process by which a system temporarily stores information across a necessary duration. Memory retention and manipulation of discrete sequences are fundamental building blocks for the underlying computation required to perform working memory tasks. Recurrent neural networks (RNNs) have proven themselves to be powerful tools for such problems, as they, through training, bring rise to the dynamical behavior necessary to enact these computations over many time-steps. As of yet, the means by which these learned internal structures of the network result in a desired set of outputs remains broadly elusive. Furthermore, what is known is often difficult to extrapolate from due to a task specific formalism. In this work, we analyze an RNN, trained perfectly on a discrete sequence working memory task, in fine detail. We explain the learned mechanisms by which this network holds memory and extracts information from memory, and how gating is a natural architectural component to achieve these structures. A synthetic solution to a simplified variant of the working memory task is realized. We then explore how these results can be extrapolated to alternative tasks. "}}
{"id": "qfMj2AXh50G", "cdate": 1617898237484, "mdate": null, "content": {"title": "On 1/n neural representation and robustness", "abstract": "Understanding the nature of representation in neural networks is a goal shared by\nneuroscience and machine learning. It is therefore exciting that both fields converge\nnot only on shared questions but also on similar approaches. A pressing question\nin these areas is understanding how the structure of the representation used by\nneural networks affects both their generalization, and robustness to perturbations.\nIn this work, we investigate the latter by juxtaposing experimental results regarding\nthe covariance spectrum of neural representations in the mouse V1 (Stringer et al)\nwith artificial neural networks. We use adversarial robustness to probe Stringer\net al\u2019s theory regarding the causal role of a 1/n covariance spectrum. We empirically investigate the benefits such a neural code confers in neural networks, and\nilluminate its role in multi-layer architectures. Our results show that imposing\nthe experimentally observed structure on artificial neural networks makes them\nmore robust to adversarial attacks. Moreover, our findings complement the existing\ntheory relating wide neural networks to kernel methods, by showing the role of\nintermediate representations."}}
{"id": "ZxTnTqI4OT", "cdate": 1609459200000, "mdate": 1684273073734, "content": {"title": "Gated Recurrent Units Viewed Through the Lens of Continuous Time Dynamical Systems", "abstract": "Gated recurrent units (GRUs) are specialized memory elements for building recurrent neural networks. Despite their incredible success on various tasks, including extracting dynamics underlying neural data, little is understood about the specific dynamics representable in a GRU network. As a result, it is both difficult to know a priori how successful a GRU network will perform on a given task, and also their capacity to mimic the underlying behavior of their biological counterparts. Using a continuous time analysis, we gain intuition on the inner workings of GRU networks. We restrict our presentation to low dimensions, allowing for a comprehensive visualization. We found a surprisingly rich repertoire of dynamical features that includes stable limit cycles (nonlinear oscillations), multi-stable dynamics with various topologies, and homoclinic bifurcations. At the same time we were unable to train GRU networks to produce continuous attractors, which are hypothesized to exist in biological neural networks. We contextualize the usefulness of different kinds of observed dynamics and support our claims experimentally."}}
{"id": "WbbjfpwrTn", "cdate": 1609459200000, "mdate": 1684273073735, "content": {"title": "Gated Recurrent Units Viewed Through the Lens of Continuous Time Dynamical Systems", "abstract": "Gated recurrent units (GRUs) are specialized memory elements for building recurrent neural networks. Despite their incredible success on various tasks, including extracting dynamics underlying neural data, little is understood about the specific dynamics representable in a GRU network. As a result, it is both difficult to know a priori how successful a GRU network will perform on a given task, and also their capacity to mimic the underlying behavior of their biological counterparts. Using a continuous time analysis, we gain intuition on the inner workings of GRU networks. We restrict our presentation to low dimensions, allowing for a comprehensive visualization. We found a surprisingly rich repertoire of dynamical features that includes stable limit cycles (nonlinear oscillations), multi-stable dynamics with various topologies, and homoclinic bifurcations. At the same time we were unable to train GRU networks to produce continuous attractors, which are hypothesized to exist in biological neural networks. We contextualize the usefulness of different kinds of observed dynamics and support our claims experimentally."}}
{"id": "2lDEinDm7rF", "cdate": 1609459200000, "mdate": 1684273073564, "content": {"title": "Hida-Mat\u00e9rn Kernel", "abstract": "We present the class of Hida-Mat\\'ern kernels, which is the canonical family of covariance functions over the entire space of stationary Gauss-Markov Processes. It extends upon Mat\\'ern kernels, by allowing for flexible construction of priors over processes with oscillatory components. Any stationary kernel, including the widely used squared-exponential and spectral mixture kernels, are either directly within this class or are appropriate asymptotic limits, demonstrating the generality of this class. Taking advantage of its Markovian nature we show how to represent such processes as state space models using only the kernel and its derivatives. In turn this allows us to perform Gaussian Process inference more efficiently and side step the usual computational burdens. We also show how exploiting special properties of the state space representation enables improved numerical stability in addition to further reductions of computational complexity."}}
{"id": "MMsxQ5QXVg0", "cdate": 1577836800000, "mdate": 1684273073838, "content": {"title": "On 1/n neural representation and robustness", "abstract": "Understanding the nature of representation in neural networks is a goal shared by neuroscience and machine learning. It is therefore exciting that both fields converge not only on shared questions but also on similar approaches. A pressing question in these areas is understanding how the structure of the representation used by neural networks affects both their generalization, and robustness to perturbations. In this work, we investigate the latter by juxtaposing experimental results regarding the covariance spectrum of neural representations in the mouse V1 (Stringer et al) with artificial neural networks. We use adversarial robustness to probe Stringer et al\u2019s theory regarding the causal role of a 1/n covariance spectrum. We empirically investigate the benefits such a neural code confers in neural networks, and illuminate its role in multi-layer architectures. Our results show that imposing the experimentally observed structure on artificial neural networks makes them more robust to adversarial attacks. Moreover, our findings complement the existing theory relating wide neural networks to kernel methods, by showing the role of intermediate representations."}}
{"id": "C7yUNgdCicX", "cdate": 1577836800000, "mdate": 1684273073836, "content": {"title": "On 1/n neural representation and robustness", "abstract": "Understanding the nature of representation in neural networks is a goal shared by neuroscience and machine learning. It is therefore exciting that both fields converge not only on shared questions but also on similar approaches. A pressing question in these areas is understanding how the structure of the representation used by neural networks affects both their generalization, and robustness to perturbations. In this work, we investigate the latter by juxtaposing experimental results regarding the covariance spectrum of neural representations in the mouse V1 (Stringer et al) with artificial neural networks. We use adversarial robustness to probe Stringer et al's theory regarding the causal role of a 1/n covariance spectrum. We empirically investigate the benefits such a neural code confers in neural networks, and illuminate its role in multi-layer architectures. Our results show that imposing the experimentally observed structure on artificial neural networks makes them more robust to adversarial attacks. Moreover, our findings complement the existing theory relating wide neural networks to kernel methods, by showing the role of intermediate representations."}}
{"id": "ApudXGKwIer", "cdate": 1577836800000, "mdate": 1684273073837, "content": {"title": "Information Geometry of Orthogonal Initializations and Training", "abstract": "Recently mean field theory has been successfully used to analyze properties of wide, random neural networks. It gave rise to a prescriptive theory for initializing feed-forward neural networks with orthogonal weights, which ensures that both the forward propagated activations and the backpropagated gradients are near \\(\\ell_2\\) isometries and as a consequence training is orders of magnitude faster. Despite strong empirical performance, the mechanisms by which critical initializations confer an advantage in the optimization of deep neural networks are poorly understood. Here we show a novel connection between the maximum curvature of the optimization landscape (gradient smoothness) as measured by the Fisher information matrix (FIM) and the spectral radius of the input-output Jacobian, which partially explains why more isometric networks can train much faster. Furthermore, given that orthogonal weights are necessary to ensure that gradient norms are approximately preserved at initialization, we experimentally investigate the benefits of maintaining orthogonality throughout training, and we conclude that manifold optimization of weights performs well regardless of the smoothness of the gradients. Moreover, we observe a surprising yet robust behavior of highly isometric initializations --- even though such networks have a lower FIM condition number \\emph{at initialization}, and therefore by analogy to convex functions should be easier to optimize, experimentally they prove to be much harder to train with stochastic gradient descent. We conjecture the FIM condition number plays a non-trivial role in the optimization."}}
{"id": "rkg1ngrFPr", "cdate": 1569439910842, "mdate": null, "content": {"title": "Information Geometry of Orthogonal Initializations and Training", "abstract": "    Recently mean field theory has been successfully used to analyze properties\n    of wide, random neural networks. It gave rise to a prescriptive theory for\n    initializing feed-forward neural networks with orthogonal weights, which\n    ensures that both the forward propagated activations and the backpropagated\n    gradients are near \\(\\ell_2\\) isometries and as a consequence training is\n    orders of magnitude faster. Despite strong empirical performance, the\n    mechanisms by which critical initializations confer an advantage in the\n    optimization of deep neural networks are poorly understood. Here we show a\n    novel connection between the maximum curvature of the optimization landscape\n    (gradient smoothness) as measured by the Fisher information matrix (FIM) and\n    the spectral radius of the input-output Jacobian, which partially explains\n    why more isometric networks can train much faster. Furthermore, given that\n    orthogonal weights are necessary to ensure that gradient norms are\n    approximately preserved at initialization, we experimentally investigate the\n    benefits of maintaining orthogonality throughout training, and we conclude\n    that manifold optimization of weights performs well regardless of the\n    smoothness of the gradients. Moreover, we observe a surprising yet robust\n    behavior of highly isometric initializations --- even though such networks\n    have a lower FIM condition number \\emph{at initialization}, and therefore by\n    analogy to convex functions should be easier to optimize, experimentally\n    they prove to be much harder to train with stochastic gradient descent. We\n    conjecture the FIM condition number plays a non-trivial role in the optimization."}}
{"id": "7V6OAfaMqsk", "cdate": 1546300800000, "mdate": 1684273073550, "content": {"title": "Gated recurrent units viewed through the lens of continuous time dynamical systems", "abstract": "Gated recurrent units (GRUs) are specialized memory elements for building recurrent neural networks. Despite their incredible success on various tasks, including extracting dynamics underlying neural data, little is understood about the specific dynamics representable in a GRU network. As a result, it is both difficult to know a priori how successful a GRU network will perform on a given task, and also their capacity to mimic the underlying behavior of their biological counterparts. Using a continuous time analysis, we gain intuition on the inner workings of GRU networks. We restrict our presentation to low dimensions, allowing for a comprehensive visualization. We found a surprisingly rich repertoire of dynamical features that includes stable limit cycles (nonlinear oscillations), multi-stable dynamics with various topologies, and homoclinic bifurcations. At the same time we were unable to train GRU networks to produce continuous attractors, which are hypothesized to exist in biological neural networks. We contextualize the usefulness of different kinds of observed dynamics and support our claims experimentally."}}
