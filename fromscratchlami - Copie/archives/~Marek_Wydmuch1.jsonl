{"id": "uZh-J7qTA5c", "cdate": 1640995200000, "mdate": 1669846278361, "content": {"title": "On Missing Labels, Long-tails and Propensities in Extreme Multi-label Classification", "abstract": "The propensity model introduced by Jain et al has become a standard approach for dealing with missing and long-tail labels in extreme multi-label classification (XMLC). In this paper, we critically revise this approach showing that despite its theoretical soundness, its application in contemporary XMLC works is debatable. We exhaustively discuss the flaws of the propensity-based approach, and present several recipes, some of them related to solutions used in search engines and recommender systems, that we believe constitute promising alternatives to be followed in XMLC."}}
{"id": "CQRIKT6-wf8", "cdate": 1640995200000, "mdate": 1669846278369, "content": {"title": "On Missing Labels, Long-tails and Propensities in Extreme Multi-label Classification", "abstract": "The propensity model introduced by Jain et al. 2016 has become a standard approach for dealing with missing and long-tail labels in extreme multi-label classification (XMLC). In this paper, we critically revise this approach showing that despite its theoretical soundness, its application in contemporary XMLC works is debatable. We exhaustively discuss the flaws of the propensity-based approach, and present several recipes, some of them related to solutions used in search engines and recommender systems, that we believe constitute promising alternatives to be followed in XMLC."}}
{"id": "ekEpfAXX1pl", "cdate": 1609459200000, "mdate": 1648735094214, "content": {"title": "Propensity-scored Probabilistic Label Trees", "abstract": "Extreme multi-label classification (XMLC) refers to the task of tagging instances with small subsets of relevant labels coming from an extremely large set of all possible labels. Recently, XMLC has been widely applied to diverse web applications such as automatic content labeling, online advertising, or recommendation systems. In such environments, label distribution is often highly imbalanced, consisting mostly of very rare tail labels, and relevant labels can be missing. As a remedy to these problems, the propensity model has been introduced and applied within several XMLC algorithms. In this work, we focus on the problem of optimal predictions under this model for probabilistic label trees, a popular approach for XMLC problems. We introduce an inference procedure, based on the A*-search algorithm, that efficiently finds the optimal solution, assuming that all probabilities and propensities are known. We demonstrate the attractiveness of this approach in a wide empirical study on popular XMLC benchmark datasets."}}
{"id": "cAZFE0EcZ1", "cdate": 1609459200000, "mdate": 1648735094215, "content": {"title": "Online probabilistic label trees", "abstract": ""}}
{"id": "YBCXZxmhtoU", "cdate": 1609459200000, "mdate": 1648735094215, "content": {"title": "Efficient set-valued prediction in multi-class classification", "abstract": "In cases of uncertainty, a multi-class classifier preferably returns a set of candidate classes instead of predicting a single class label with little guarantee. More precisely, the classifier should strive for an optimal balance between the correctness (the true class is among the candidates) and the precision (the candidates are not too many) of its prediction. We formalize this problem within a general decision-theoretic framework that unifies most of the existing work in this area. In this framework, uncertainty is quantified in terms of conditional class probabilities, and the quality of a predicted set is measured in terms of a utility function. We then address the problem of finding the Bayes-optimal prediction, i.e., the subset of class labels with the highest expected utility. For this problem, which is computationally challenging as there are exponentially (in the number of classes) many predictions to choose from, we propose efficient algorithms that can be applied to a broad family of utility functions. Our theoretical results are complemented by experimental studies, in which we analyze the proposed algorithms in terms of predictive accuracy and runtime efficiency."}}
{"id": "5dktGfuCie", "cdate": 1609459200000, "mdate": 1648735140927, "content": {"title": "Propensity-scored Probabilistic Label Trees", "abstract": "Extreme multi-label classification (XMLC) refers to the task of tagging instances with small subsets of relevant labels coming from an extremely large set of all possible labels. Recently, XMLC has been widely applied to diverse web applications such as automatic content labeling, online advertising, or recommendation systems. In such environments, label distribution is often highly imbalanced, consisting mostly of very rare tail labels, and relevant labels can be missing. As a remedy to these problems, the propensity model has been introduced and applied within several XMLC algorithms. In this work, we focus on the problem of optimal predictions under this model for probabilistic label trees, a popular approach for XMLC problems. We introduce an inference procedure, based on the $A^*$-search algorithm, that efficiently finds the optimal solution, assuming that all probabilities and propensities are known. We demonstrate the attractiveness of this approach in a wide empirical study on popular XMLC benchmark datasets."}}
{"id": "vsKa33HYgN", "cdate": 1577836800000, "mdate": null, "content": {"title": "Online probabilistic label trees", "abstract": "We introduce online probabilistic label trees (OPLTs), an algorithm that trains a label tree classifier in a fully online manner without any prior knowledge about the number of training instances, their features and labels. OPLTs are characterized by low time and space complexity as well as strong theoretical guarantees. They can be used for online multi-label and multi-class classification, including the very challenging scenarios of one- or few-shot learning. We demonstrate the attractiveness of OPLTs in a wide empirical study on several instances of the tasks mentioned above."}}
{"id": "E770-UDNJ0s", "cdate": 1577836800000, "mdate": null, "content": {"title": "Probabilistic Label Trees for Extreme Multi-label Classification", "abstract": "Extreme multi-label classification (XMLC) is a learning task of tagging instances with a small subset of relevant labels chosen from an extremely large pool of possible labels. Problems of this scale can be efficiently handled by organizing labels as a tree, like in hierarchical softmax used for multi-class problems. In this paper, we thoroughly investigate probabilistic label trees (PLTs) which can be treated as a generalization of hierarchical softmax for multi-label problems. We first introduce the PLT model and discuss training and inference procedures and their computational costs. Next, we prove the consistency of PLTs for a wide spectrum of performance metrics. To this end, we upperbound their regret by a function of surrogate-loss regrets of node classifiers. Furthermore, we consider a problem of training PLTs in a fully online setting, without any prior knowledge of training instances, their features, or labels. In this case, both node classifiers and the tree structure are trained online. We prove a specific equivalence between the fully online algorithm and an algorithm with a tree structure given in advance. Finally, we discuss several implementations of PLTs and introduce a new one, napkinXC, which we empirically evaluate and compare with state-of-the-art algorithms."}}
{"id": "s1CeJVn0UR", "cdate": 1546300800000, "mdate": null, "content": {"title": "ViZDoom Competitions: Playing Doom From Pixels", "abstract": "This paper presents the first two editions of Visual Doom AI Competition, held in 2016 and 2017. The challenge was to create bots that compete in a multiplayer deathmatch in a first-person shooter game Doom. The bots had to make their decisions solely based on visual information, i.e., a raw screen buffer. To play well, the bots needed to understand their surroundings, navigate, explore, and handle the opponents at the same time. These aspects, together with the competitive multiagent aspect of the game, make the competition a unique platform for evaluating the state-of-the-art reinforcement learning algorithms. This paper discusses the rules, solutions, results, and statistics that give insight into the agents' behaviors. Best performing agents are described in more detail. The results of the competition lead to the conclusion that, although reinforcement learning can produce capable Doom bots, they still are not yet able to successfully compete against humans in this game. This paper also revisits the ViZDoom environment, which is a flexible, easy to use, and efficient three-dimensional platform for research for vision-based reinforcement learning, based on a well-recognized first-person perspective game Doom."}}
{"id": "fVpE00iARUI", "cdate": 1546300800000, "mdate": null, "content": {"title": "Set-Valued Prediction in Multi-Class Classification", "abstract": ""}}
