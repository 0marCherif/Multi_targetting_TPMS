{"id": "UT-_SVOyD1H", "cdate": 1663849994731, "mdate": null, "content": {"title": "Contextual bandits with concave rewards, and an application to fair ranking", "abstract": "We consider Contextual Bandits with Concave Rewards (CBCR), a multi-objective bandit problem where the desired trade-off between the rewards is defined by a known concave objective function, and the reward vector depends on an observed stochastic context. We present the first algorithm with provably vanishing regret for CBCR without restrictions on the policy space, whereas prior works were restricted to finite policy spaces or tabular representations. Our solution is based on a geometric interpretation of CBCR algorithms as optimization algorithms over the convex set of expected rewards spanned by all stochastic policies. Building on Frank-Wolfe analyses in constrained convex optimization, we derive a novel reduction from the CBCR regret to the regret of a \\emph{scalar-reward} bandit problem. We illustrate how to apply the reduction off-the-shelf to obtain algorithms for CBCR with both linear and general reward functions, in the case of non-combinatorial actions. Motivated by fairness in recommendation, we describe a special case of CBCR with rankings and fairness-aware objectives, leading to the first algorithm with regret guarantees for contextual combinatorial bandits with fairness of exposure."}}
{"id": "rOymJEqZJas", "cdate": 1634237112547, "mdate": null, "content": {"title": "e-ViL: A Dataset and Benchmark for Natural Language Explanations in Vision-Language Tasks", "abstract": "ecently, there has been an increasing number of efforts\nto introduce models capable of generating natural language\nexplanations (NLEs) for their predictions on vision-language\n(VL) tasks. Such models are appealing, because they can pro-\nvide human-friendly and comprehensive explanations. How-\never, there is a lack of comparison between existing methods,\nwhich is due to a lack of re-usable evaluation frameworks\nand a scarcity of datasets. In this work, we introduce e-\nViL and e-SNLI-VE. e-ViL is a benchmark for explainable\nvision-language tasks that establishes a unified evaluation\nframework and provides the first comprehensive comparison\nof existing approaches that generate NLEs for VL tasks. It\nspans four models and three datasets and both automatic\nmetrics and human evaluation are used to assess model-\ngenerated explanations. e-SNLI-VE is currently the largest\nexisting VL dataset with NLEs (over 430k instances). We also\npropose a new model that combines UNITER [15], which\nlearns joint embeddings of images and text, and GPT-2 [38],\na pre-trained language model that is well-suited for text gen-\neration. It surpasses the previous state of the art by a large\nmargin across all datasets. Code and data are available\nhere: https://github.com/maximek3/e-ViL"}}
{"id": "uPWdkoZHgba", "cdate": 1621630238594, "mdate": null, "content": {"title": "Two-sided fairness in rankings via Lorenz dominance", "abstract": "We consider the problem of generating rankings that are fair towards both users and item producers in recommender systems. We address both usual recommendation (e.g., of music or movies) and reciprocal recommendation (e.g., dating). Following concepts of distributive justice in welfare economics, our notion of fairness aims at increasing the utility of the worse-off individuals, which we formalize using the criterion of Lorenz efficiency. It guarantees that rankings are Pareto efficient, and that they maximally redistribute utility from better-off to worse-off, at a given level of overall utility. We propose to generate rankings by maximizing concave welfare functions, and develop an efficient inference procedure based on the Frank-Wolfe algorithm. We prove that unlike existing approaches based on fairness constraints, our approach always produces fair rankings. Our experiments also show that it increases the utility of the worse-off at lower costs in terms of overall utility."}}
