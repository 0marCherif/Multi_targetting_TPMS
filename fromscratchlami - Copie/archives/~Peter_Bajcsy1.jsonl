{"id": "ua3ME-JmkFk", "cdate": 1672531200000, "mdate": 1682343131378, "content": {"title": "LipoPose: Adapting Cellpose to Lipid Nanoparticle Segmentation", "abstract": ""}}
{"id": "47-v-yTl0Z", "cdate": 1649192180504, "mdate": 1649192180504, "content": {"title": "Designing Trojan Detectors in Neural Networks Using Interactive Simulations", "abstract": "This paper addresses the problem of designing trojan detectors in neural networks\n(NNs) using interactive simulations. Trojans in NNs are defined as triggers in inputs that cause\nmisclassification of such inputs into a class (or classes) unintended by the design of a NN-based\nmodel. The goal of our work is to understand encodings of a variety of trojan types in fully connected\nlayers of neural networks. Our approach is (1) to simulate nine types of trojan embeddings into dot\npatterns, (2) to devise measurements of NN states, and (3) to design trojan detectors in NN-based\nclassification models. The interactive simulations are built on top of TensorFlow Playground with\nin-memory storage of data and NN coefficients. The simulations provide analytical, visualization,\nand output operations performed on training datasets and NN architectures. The measurements of a\nNN include (a) model inefficiency using modified Kullback-Liebler (KL) divergence from uniformly\ndistributed states and (b) model sensitivity to variables related to data and NNs. Using the KL\ndivergence measurements at each NN layer and per each predicted class label, a trojan detector is\ndevised to discriminate NN models with or without trojans. To document robustness of such a trojan\ndetector with respect to NN architectures, dataset perturbations, and trojan types, several properties\nof the KL divergence measurement are presented. For the general use, the web-based simulations is\ndeployed via GitHub pages at https://github.com/usnistgov/nn-calculator."}}
{"id": "s_iuR5FIH-", "cdate": 1640995200000, "mdate": 1682343132069, "content": {"title": "Assessment of Dose Reduction Strategies in Wavelength-selective Neutron Tomography", "abstract": ""}}
{"id": "eZ8Rs-vYYNW", "cdate": 1640995200000, "mdate": 1682343132411, "content": {"title": "AI Model Utilization Measurements For Finding Class Encoding Patterns", "abstract": "This work addresses the problems of (a) designing utilization measurements of trained artificial intelligence (AI) models and (b) explaining how training data are encoded in AI models based on those measurements. The problems are motivated by the lack of explainability of AI models in security and safety critical applications, such as the use of AI models for classification of traffic signs in self-driving cars. We approach the problems by introducing theoretical underpinnings of AI model utilization measurement and understanding patterns in utilization-based class encodings of traffic signs at the level of computation graphs (AI models), subgraphs, and graph nodes. Conceptually, utilization is defined at each graph node (computation unit) of an AI model based on the number and distribution of unique outputs in the space of all possible outputs (tensor-states). In this work, utilization measurements are extracted from AI models, which include poisoned and clean AI models. In contrast to clean AI models, the poisoned AI models were trained with traffic sign images containing systematic, physically realizable, traffic sign modifications (i.e., triggers) to change a correct class label to another label in a presence of such a trigger. We analyze class encodings of such clean and poisoned AI models, and conclude with implications for trojan injection and detection."}}
{"id": "NcjST0qVXPk", "cdate": 1640995200000, "mdate": 1682343132412, "content": {"title": "Characterization of AI Model Configurations for Model Reuse", "abstract": "With the widespread creation of artificial intelligence (AI) models in biosciences, bio-medical researchers are reusing trained AI models from other applications. This work is motivated by the need to characterize trained AI models for reuse based on metrics derived from optimization curves captured during model training. Such AI model characterizations can aid future model accuracy refinement, inform users about model hyper-parameter sensitivity, and assist in model reuse according to multi-purpose objectives. The challenges lie in understanding relationships between trained AI models and optimization curves, defining and validating quantitative AI model metrics, and disseminating metrics with trained AI models. We approach these challenges by analyzing optimization curves generated for image segmentation and classification tasks to assist in a multi-objective reuse of AI models."}}
{"id": "sFcdKMGRSk", "cdate": 1609459200000, "mdate": 1682343132231, "content": {"title": "Quantifying Variability in Microscopy Image Analyses for COVID-19 Drug Discovery", "abstract": "Microscopy image-based measurement variability in high-throughput imaging experiments for biological drug discoveries, such as COVID-19 therapies was addressed in this study. Variability of measurements came from (1) computational approaches (methods), (2) implementations of methods, (3) parameter settings, (4) chaining methods into workflows, and (5) stabilities of floating-point arithmetic on diverse hardware. Measurement variability was addressed by (a) introducing interoperability between algorithms, (b) enforcing automated capture of computational provenance and parameter settings, and (c) quantifying multiple sources of variabilities for 10 nucleus measurements, from 8 workflow streams, executed in 2 workflow graph configurations, on 2 computational hardware platforms at 2 locations. Using modified Mean Absolute Error (mMAE [%]) to compare measurements, We concluded that for the task of image-based nucleus measurements the variability sources were (1) implementations (0.10 % - 5.72 % per measurement), (2) methods (3.08 % - 3.11 % between Otsu thresholding and CellPose segmentation), (3) parameters (1.16 %-1.17 % between 4- and 8-neighbor connectivity), (4) workflow graph construction and computer hardware (negligible)."}}
{"id": "TYJUfPGt0W5", "cdate": 1609459200000, "mdate": 1682343132004, "content": {"title": "Baseline Pruning-Based Approach to Trojan Detection in Neural Networks", "abstract": "This paper addresses the problem of detecting trojans in neural networks (NNs) by analyzing systematically pruned NN models. Our pruning-based approach consists of three main steps. First, detect any deviations from the reference look-up tables of model file sizes and model graphs. Next, measure the accuracy of a set of systematically pruned NN models following multiple pruning schemas. Finally, classify a NN model as clean or poisoned by applying a mapping between accuracy measurements and NN model labels. This work outlines a theoretical and experimental framework for finding the optimal mapping over a large search space of pruning parameters. Based on our experiments using Round 1 and Round 2 TrojAI Challenge datasets, the approach achieves average classification accuracy of 69.73 % and 82.41% respectively with an average processing time of less than 60 s per model. For both datasets random guessing would produce 50% classification accuracy. Reference model graphs and source code are available from GitHub."}}
{"id": "LwTqWW6lGYr", "cdate": 1577836800000, "mdate": 1682343132468, "content": {"title": "Neural Network Calculator for Designing Trojan Detectors", "abstract": "This work presents a web-based interactive neural network (NN) calculator and a NN inefficiency measurement that has been investigated for the purpose of detecting trojans embedded in NN models. This NN Calculator is designed on top of TensorFlow Playground with in-memory storage of data and NN graphs plus coefficients. It is \"like a scientific calculator\" with analytical, visualization, and output operations performed on training datasets and NN architectures. The prototype is aaccessible at https://pages.nist.gov/nn-calculator. The analytical capabilities include a novel measurement of NN inefficiency using modified Kullback-Liebler (KL) divergence applied to histograms of NN model states, as well as a quantification of the sensitivity to variables related to data and NNs. Both NN Calculator and KL divergence are used to devise a trojan detector approach for a variety of trojan embeddings. Experimental results document desirable properties of the KL divergence measurement with respect to NN architectures and dataset perturbations, as well as inferences about embedded trojans."}}
{"id": "rjexVT2GgOpH", "cdate": 1546300800000, "mdate": null, "content": {"title": "Cell Image Segmentation Using Generative Adversarial Networks, Transfer Learning, and Augmentations.", "abstract": "We address the problem of segmenting cell contours from microscopy images of human induced pluripotent Retinal Pigment Epithelial stem cells (iRPE) using Convolutional Neural Networks (CNN). Our goal is to compare the accuracy gains of CNN-based segmentation by using (1) un-annotated images via Generative Adversarial Networks (GAN), (2) annotated out-of-bio-domain images via transfer learning, and (3) a priori knowledge about microscope imaging mapped into geometric augmentations of a small collection of annotated images. First, the GAN learns an abstract representation of cell objects. Next, this unsupervised learned representation is transferred to the CNN segmentation models which are further fine-tuned on a small number of manually segmented iRPE cell images. Second, transfer learning is applied by pre-training a part of the CNN segmentation model with the COCO dataset containing semantic segmentation labels. The CNN model is then adapted to the iRPE cell domain using a small set of annotated iRPE cell images. Third, augmentations based on geometrical transformations are applied to a small collection of annotated images. All these approaches to training CNN-based segmentation model are compared to a baseline CNN model trained on a small collection of annotated images. For very small annotation counts, the results show accuracy improvements up to 20 % by the best approach in comparison to the accuracy achieved using a baseline U-Net model. For larger annotation counts these approaches asymptotically approach the same accuracy."}}
{"id": "-_nHLXotxda", "cdate": 1546300800000, "mdate": 1649438417292, "content": {"title": "Cell Image Segmentation Using Generative Adversarial Networks, Transfer Learning, and Augmentations", "abstract": "We address the problem of segmenting cell contours from microscopy images of human induced pluripotent Retinal Pigment Epithelial stem cells (iRPE) using Convolutional Neural Networks (CNN). Our goal is to compare the accuracy gains of CNN-based segmentation by using (1) un-annotated images via Generative Adversarial Networks (GAN), (2) annotated out-of-bio-domain images via transfer learning, and (3) a priori knowledge about microscope imaging mapped into geometric augmentations of a small collection of annotated images. First, the GAN learns an abstract representation of cell objects. Next, this unsupervised learned representation is transferred to the CNN segmentation models which are further fine-tuned on a small number of manually segmented iRPE cell images. Second, transfer learning is applied by pre-training a part of the CNN segmentation model with the COCO dataset containing semantic segmentation labels. The CNN model is then adapted to the iRPE cell domain using a small set of annotated iRPE cell images. Third, augmentations based on geometrical transformations are applied to a small collection of annotated images. All these approaches to training CNN-based segmentation model are compared to a baseline CNN model trained on a small collection of annotated images. For very small annotation counts, the results show accuracy improvements up to 20 % by the best approach in comparison to the accuracy achieved using a baseline U-Net model. For larger annotation counts these approaches asymptotically approach the same accuracy."}}
