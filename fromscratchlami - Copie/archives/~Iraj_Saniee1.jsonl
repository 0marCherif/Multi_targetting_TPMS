{"id": "4ik97aBNNZ", "cdate": 1640995200000, "mdate": 1682340419974, "content": {"title": "Truncated Lottery Ticket for Deep Pruning", "abstract": ""}}
{"id": "-J33HTHwVb", "cdate": 1623130118060, "mdate": null, "content": {"title": "Convolutional neural networks for figure extraction in historical technical documents", "abstract": "We present a method of extracting figures and images from the pages of scanned documents, especially from technical research articles. Our approach is novel in two key ways. First, we treat this as a computer vision problem, and train convolutional neural networks to recognize figures in scanned pages. Second, we generate our training data from 'born-digital' structured documents, allowing us to automatically produce labels for our training set using PDF figure extractors. This avoids the otherwise tedious task of hand-labelling thousands of document pages. Our convolutional neural networks achieve precision and recall of close to 85% in identifying figures from a test set consisting of modern journal papers and conference proceedings, and obtain precision and recall above 80% on an application data set comprised of historical technical documents scanned from the Bell Labs Records. Our results show that models trained on digital documents transfer very well to historical scans. Finally, it is easy to extend our models to identify other document elements such as tables and captions.\n"}}
{"id": "rFQQjivbjB", "cdate": 1609459200000, "mdate": 1682340420094, "content": {"title": "Hybrid Pruning And Sparsification", "abstract": ""}}
{"id": "KeBRH1mbF84", "cdate": 1609459200000, "mdate": 1682340419974, "content": {"title": "An analytical solution to the multicommodity network flow problem with weighted random routing", "abstract": ""}}
{"id": "XJTgY1ZPkGd", "cdate": 1577836800000, "mdate": null, "content": {"title": "Congestion Due to Random Walk Routing", "abstract": "In this paper we derive an analytical expression for the mean load at each node of an arbitrary undirected graph for the uniform multicommodity flow problem under random walk routing. We show the mean load is linearly dependent on the nodal degree with a common multiplier equal to the sum of the inverses of the non-zero eigenvalues of the graph Laplacian. Even though some aspects of the mean load value, such as linear dependence on the nodal degree, are intuitive and may be derived from the equilibrium distribution of the random walk on the undirected graph, the exact expression for the mean load in terms of the full spectrum of the graph has not been known before. Using the explicit expression for the mean load, we give asymptotic estimates for the load on a variety of graphs whose spectral density are well known. We conclude with numerical computation of the mean load for other well-known graphs without known spectral densities."}}
{"id": "o7Urx9iWLwh", "cdate": 1546300800000, "mdate": null, "content": {"title": "Efficient Deep Approximation of GMMs", "abstract": "The universal approximation theorem states that any regular function can be approximated closely using a single hidden layer neural network. Some recent work has shown that, for some special functions, the number of nodes in such an approximation could be exponentially reduced with multi-layer neural networks. In this work, we extend this idea to a rich class of functions, namely the discriminant functions that arise in optimal Bayesian classification of Gaussian mixture models (GMMs) in $\\mathds{R}^n$. We show that such functions can be approximated with arbitrary precision using $O(n)$ nodes in a neural network with two hidden layers (deep neural network), while in contrast, a neural network with a single hidden layer (shallow neural network) would require at least $O(\\exp(n))$ nodes or exponentially large coefficients. Given the universality of the Gaussian distribution in the feature spaces of data, e.g., in speech, image and text, our results shed light on the observed efficiency of deep neural networks in practical classification problems."}}
{"id": "ez8o9tl5Y5", "cdate": 1546300800000, "mdate": 1682340420094, "content": {"title": "Efficient Deep Learning of GMMs", "abstract": ""}}
{"id": "WA8QsD0mJW8", "cdate": 1546300800000, "mdate": null, "content": {"title": "Towards Clustering High-dimensional Gaussian Mixture Clouds in Linear Running Time", "abstract": "Clustering mixtures of Gaussian distributions is a fundamental and challenging problem. State-of-the-art theoretical work on learning Gaussian mixture models has mostly focused on estimating the mi..."}}
{"id": "oM3T99UvyYl", "cdate": 1514764800000, "mdate": null, "content": {"title": "Scaling of Random Walk Betweenness in Networks", "abstract": "We study the betweenness centrality (BC) of vertices of a graph using random walk paths. Random walk BC (RWBC) provides an alternative measure to the shortest path centrality of each vertex in a graph as it aggregates contributions from possibly all vertex-pairs in the graph and not just from those vertex-pairs on whose geodesic path the vertex lies. As such, RWBC is more relevant in the context of information diffusion in virtual networks, such as spread of news or rumors in online social media. We derive a closed-form analytical expression for RWBC using eigenfunctions of the graph Laplacian. We then show the distribution of RWBC scores of the vertices of a graph exhibits a scaling collapse with no adjustable parameters as the graph size N is varied. This means that the distribution of RWBC over all the nodes in a large graph can be obtained in terms of the distribution of RWBC for a prototypical or small graph that is generated using the same model. The exact distribution itself depends on the graph model. A normalized random walk betweenness (NRWBC), that counts each walk passing through a vertex only once, is also defined. This measure is argued to be more useful and robust and is seen to have simpler scaling behavior."}}
{"id": "8MR7Noa2Qyz", "cdate": 1514764800000, "mdate": null, "content": {"title": "Fast Approximation Algorithms for p-Centers in Large $$\\delta $$ \u03b4 -Hyperbolic Graphs", "abstract": "We provide a quasilinear time algorithm for the p-center problem with an additive error less than or equal to 3 times the input graph\u2019s hyperbolic constant. Specifically, for the graph $$G=(V,E)$$ G = ( V , E ) with n vertices, m edges and hyperbolic constant $$\\delta $$ \u03b4 , we construct an algorithm for p-centers in time $$O(p(\\delta +1)(n+m)\\log (n))$$ O ( p ( \u03b4 + 1 ) ( n + m ) log ( n ) ) with radius not exceeding $$r_p + \\delta $$ r p + \u03b4 when $$p \\le 2$$ p \u2264 2 and $$r_p + 3\\delta $$ r p + 3 \u03b4 when $$p \\ge 3$$ p \u2265 3 , where $$r_p$$ r p are the optimal radii. Prior work identified p-centers with accuracy $$r_p+\\delta $$ r p + \u03b4 but with time complexity $$O((n^3\\log n + n^2m)\\log ({{\\mathrm{diam}}}(G)))$$ O ( ( n 3 log n + n 2 m ) log ( diam ( G ) ) ) which is impractical for large graphs."}}
