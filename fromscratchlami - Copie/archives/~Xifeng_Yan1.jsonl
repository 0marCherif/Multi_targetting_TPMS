{"id": "Nv0tzncECS", "cdate": 1675849634254, "mdate": null, "content": {"title": "Time Series as Images: Vision Transformer for Irregularly Sampled Time Series", "abstract": "Irregularly sampled time series are becoming increasingly prevalent in various domains, especially medical applications. Although different highly-customized methods have been proposed to tackle irregularity, how to effectively model their complicated dynamics and high sparsity is still an open problem. This paper studies the problem from a whole new perspective: transforming irregularly sampled time series into line graph images and adapting powerful vision transformers to perform time series classification in the same way as image classification. Our approach largely simplifies algorithm designs without assuming prior knowledge and can be potentially extended as a general-purpose framework. Despite its simplicity, we show that it substantially outperforms state-of-the-art specialized algorithms on several popular healthcare and human activity datasets.  Our code and data are available at \\url{https://github.com/Leezekun/ViTST}."}}
{"id": "YbmHRyXDWv7", "cdate": 1667353609907, "mdate": 1667353609907, "content": {"title": "Context-guided entropy minimization for semi-supervised domain adaptation", "abstract": "Semi-Supervised Domain Adaptation has been widely studied with various approaches to address domain shift with labeled source-domain data combined with scarcely labeled target-domain data. Model adaptation is becoming promising with a paradigm of source pre-training and target fine-tuning, which eliminates the simultaneous availability of data from both domains and makes for data privacy. Among the model adaptation methods, Entropy Minimization (EM) is popularly incorporated to encourage a low-density separation on target samples. However, EM tends to brutally force models to make over-confident predictions, which could make the models collapse with deteriorated performance. In this paper, we first study the over-confidence of EM with a quantitative analysis, which shows the importance of capturing the dependency among labels. To address this issue, we propose to guide EM via longitudinal self-distillation. Specifically, we produce a dynamic \u201cteacher\u201d label distribution during training by constructing a graph on target data and perform pseudo-label propagation to encourage the \u201cteacher\u201d distribution to capture context category dependency based on a global data structure. Then EM is guided longitudinally by distilling the learned label distribution to combat the brute-force over-confidence. Extensive experiments demonstrate the effectiveness of our methods."}}
{"id": "8IN-qLkl215", "cdate": 1663850252782, "mdate": null, "content": {"title": "Visually-Augmented Language Modeling", "abstract": "Human language is grounded on multimodal knowledge including visual knowledge like colors, sizes, and shapes. However, current large-scale pre-trained language models rely on the text-only self-supervised training with massive text data, which precludes them from utilizing relevant visual information when necessary. To address this, we propose a novel pre-training framework, named VaLM, to Visually-augment text tokens with retrieved relevant images for Language Modeling. Specifically, VaLM builds on a novel latent text-image alignment method via an image retrieval module to fetch corresponding images given a textual context. With the visually-augmented context, VaLM uses a visual knowledge fusion layer to enable multimodal grounded language modeling by attending on both text context and visual knowledge in images. We evaluate VaLM on various visual knowledge intensive commonsense reasoning tasks, which require visual information to excel. The experimental results illustrate that VaLM outperforms all strong language-only and vision-language baselines with substantial gains on reasoning object commonsense including color, size, and shape."}}
{"id": "lRgEbHxowq", "cdate": 1663849850626, "mdate": null, "content": {"title": "Time Series are Images: Vision Transformer for Irregularly Sampled Time Series", "abstract": "Irregularly sampled time series are often observed in medical applications. Highly customized models have been developed to tackle the irregularity. In this work, we propose a simple yet effective approach that transforms irregularly sampled time series into line graph images and adapts vision transformers to perform time series classification in a way similar to image classification. Our approach simplifies the model design without assuming prior knowledge. Despite its simplicity, we show that it is able to outperform state-of-the-art specialized algorithms on several popular healthcare and human activity datasets, especially in the challenging leave-sensors-out setting where a subset of variables are masked during testing. We hope this work could provide beneficial insight into leveraging fast-evolving computer vision techniques in the time series analysis domain."}}
{"id": "WULCS1meNmT", "cdate": 1631751817597, "mdate": 1631751817597, "content": {"title": "Adaptive-Step Graph Meta-Learner for Few-Shot Graph Classification", "abstract": "Graph classification aims to extract accurate information from graph-structured data for classification and is becoming more and more important in the graph learning community. Although Graph Neural Networks (GNNs) have been successfully applied to graph classification tasks, most of them overlook the scarcity of labeled graph data in many applications. For example, in bioinformatics, obtaining protein graph labels usually needs laborious experiments. Recently, few-shot learning has been explored to alleviate this problem with only a few labeled graph samples of test classes. The shared sub-structures between training classes and test classes are essential in the few-shot graph classification. Existing methods assume that the test classes belong to the same set of super-classes clustered from training classes. However, according to our observations, the label spaces of training classes and test classes usually do not overlap in a real-world scenario. As a result, the existing methods don't well capture the local structures of unseen test classes. To overcome the limitation, in this paper, we propose a direct method to capture the sub-structures with a well initialized meta-learner within a few adaptation steps. More specifically, (1) we propose a novel framework consisting of a graph meta-learner, which uses GNNs based modules for fast adaptation on graph data, and a step controller for the robustness and generalization of meta-learner; (2) we provide quantitative analysis for the framework and give a graph-dependent upper bound of the generalization error based on our framework; (3) the extensive experiments on real-world datasets demonstrate that our framework gets state-of-the-art results on several few-shot graph classification tasks compared to baselines."}}
{"id": "eom0IUrF__F", "cdate": 1601308157796, "mdate": null, "content": {"title": "CoCo: Controllable Counterfactuals for Evaluating Dialogue State Trackers", "abstract": "Dialogue state trackers have made significant progress on benchmark datasets, but their generalization capability to novel and realistic scenarios beyond the held- out conversations is less understood. We propose controllable counterfactuals (COCO) to bridge this gap and evaluate dialogue state tracking (DST) models on novel scenarios, i.e., would the system successfully tackle the request if the user responded differently but still consistently with the dialogue flow? COCO leverages turn-level belief states as counterfactual conditionals to produce novel conversation scenarios in two steps: (i) counterfactual goal generation at turn- level by dropping and adding slots followed by replacing slot values, (ii) counterfactual conversation generation that is conditioned on (i) and consistent with the dialogue flow. Evaluating state-of-the-art DST models on MultiWOZ dataset with COCO-generated counterfactuals results in a significant performance drop of up to 30.8% (from 49.4% to 18.6%) in absolute joint goal accuracy. In comparison, widely used techniques like paraphrasing only affect the accuracy by at most 2%. Human evaluations show that COCO-generated conversations perfectly reflect the underlying user goal with more than 95% accuracy and are as human-like as the original conversations, further strengthening its reliability and promise to be adopted as part of the robustness evaluation of DST models."}}
{"id": "S1by3mWd-S", "cdate": 1546300800000, "mdate": null, "content": {"title": "How Large a Vocabulary Does Text Classification Need? A Variational Approach to Vocabulary Selection", "abstract": "Wenhu Chen, Yu Su, Yilin Shen, Zhiyu Chen, Xifeng Yan, William Yang Wang. Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers). 2019."}}
{"id": "rkbRL3xuWH", "cdate": 1514764800000, "mdate": null, "content": {"title": "DialSQL: Dialogue Based Structured Query Generation", "abstract": "L'apprentissage de mod\u00e8les temporels constitue l'une des grandes probl\u00e9matiques de l'Exploration de Donn\u00e9es (Data Mining). Dans cette th\u00e8se, nous avons d\u00e9velopp\u00e9 un nouveau mod\u00e8le temporel appel\u00e9 TITA Rules (R\u00e8gle associative temporelle bas\u00e9 sur des arbres d'intervalles). Ce mod\u00e8le permet de d\u00e9crire des ph\u00e9nom\u00e8nes ayant un certain degr\u00e9 d'incertitude et/ou d'impr\u00e9cision. Ce mod\u00e8le permet entre autres d'exprimer la synchronicit\u00e9 entre \u00e9v\u00e8nements, les contraintes temporelles disjonctives et la n\u00e9gation temporelle. De par leur nature, les TITA Rules peuvent \u00eates utilis\u00e9es pour effectuer des pr\u00e9dictions avec une grande pr\u00e9cision temporel. Nous avons aussi d\u00e9velopp\u00e9 un algorithme capable de d\u00e9couvrir et d'extraire de mani\u00e8re efficace des TITA Rules dans de grandes bases de donn\u00e9es temporelles. Le c\u0153ur de l'algorithme est bas\u00e9 sur des techniques de minimisation d'entropie, de filtrage par Apriori et par des analyses de co-d\u00e9pendance. Note mod\u00e8le temporelle et notre algorithme ont \u00e9t\u00e9 appliqu\u00e9s et \u00e9valu\u00e9s sur plusieurs jeux de donn\u00e9es issues de ph\u00e9nom\u00e8nes r\u00e9els et de ph\u00e9nom\u00e8nes simul\u00e9s. La seconde partie de cette th\u00e8se \u00e0 consist\u00e9 \u00e0 \u00e9tudier l'utilisation de notre mod\u00e8le temporel sur la probl\u00e9matique de la Planification Automatique. Ces travaux ont men\u00e9 au d\u00e9veloppement d'un algorithme de planification automatique. L'algorithme prend en entr\u00e9e un ensemble de TITA Rules d\u00e9crivant le fonctionnement d'un syst\u00e8me quelconque, une description de l'\u00e9tat initial du syst\u00e8me, et un but \u00e0 atteindre. En retour, l'algorithme calcule un plan d\u00e9crivant la meilleure fa\u00e7on d'atteindre le but donn\u00e9. Par la nature m\u00eame des TITA Rules, cet algorithme est capable de g\u00e9rer l'incertain (probabilit\u00e9s), l'impr\u00e9cision temporelle, les contraintes temporelles disjonctives, ainsi que les \u00e9v\u00e9nements exog\u00e8nes pr\u00e9dictibles mais impr\u00e9cis."}}
{"id": "rkELwm-uZS", "cdate": 1514764800000, "mdate": null, "content": {"title": "Variational Knowledge Graph Reasoning", "abstract": "Inferring missing links in knowledge graphs (KG) has attracted a lot of attention from the research community. In this paper, we tackle a practical query answering task involving predicting the relation of a given entity pair. We frame this prediction problem as an inference problem in a probabilistic graphical model and aim at resolving it from a variational inference perspective. In order to model the relation between the query entity pair, we assume that there exists an underlying latent variable (paths connecting two nodes) in the KG, which carries the equivalent semantics of their relations. However, due to the intractability of connections in large KGs, we propose to use variation inference to maximize the evidence lower bound. More specifically, our framework (\\textsc{Diva}) is composed of three modules, i.e. a posterior approximator, a prior (path finder), and a likelihood (path reasoner). By using variational inference, we are able to incorporate them closely into a unified architecture and jointly optimize them to perform KG reasoning. With active interactions among these sub-modules, \\textsc{Diva} is better at handling noise and coping with more complex reasoning scenarios. In order to evaluate our method, we conduct the experiment of the link prediction task on multiple datasets and achieve state-of-the-art performances on both datasets."}}
{"id": "rJWwWzG_-H", "cdate": 1514764800000, "mdate": null, "content": {"title": "What It Takes to Achieve 100 Percent Condition Accuracy on WikiSQL", "abstract": ""}}
