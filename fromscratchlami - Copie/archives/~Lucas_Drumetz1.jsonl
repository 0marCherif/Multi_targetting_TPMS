{"id": "xqErI1Ds8k", "cdate": 1672531200000, "mdate": 1695986115357, "content": {"title": "Sliced-Wasserstein on Symmetric Positive Definite Matrices for M/EEG Signals", "abstract": "When dealing with electro or magnetoencephalography records, many supervised prediction tasks are solved by working with covariance matrices to summarize the signals. Learning with these matrices r..."}}
{"id": "t1Q-bfAoqx", "cdate": 1672531200000, "mdate": 1681732813918, "content": {"title": "Disambiguation of One-Shot Visual Classification Tasks: A Simplex-Based Approach", "abstract": "The field of visual few-shot classification aims at transferring the state-of-the-art performance of deep learning visual systems onto tasks where only a very limited number of training samples are available. The main solution consists in training a feature extractor using a large and diverse dataset to be applied to the considered few-shot task. Thanks to the encoded priors in the feature extractors, classification tasks with as little as one example (or \"shot'') for each class can be solved with high accuracy, even when the shots display individual features not representative of their classes. Yet, the problem becomes more complicated when some of the given shots display multiple objects. In this paper, we present a strategy which aims at detecting the presence of multiple and previously unseen objects in a given shot. This methodology is based on identifying the corners of a simplex in a high dimensional space. We introduce an optimization routine and showcase its ability to successfully detect multiple (previously unseen) objects in raw images. Then, we introduce a downstream classifier meant to exploit the presence of multiple objects to improve the performance of few-shot classification, in the case of extreme settings where only one shot is given for its class. Using standard benchmarks of the field, we show the ability of the proposed method to slightly, yet statistically significantly, improve accuracy in these settings."}}
{"id": "rERhiZ1hrJ", "cdate": 1672531200000, "mdate": 1699613069828, "content": {"title": "Active Learning for Efficient Few-Shot Classification", "abstract": "We introduce the problem of Active Few-Shot Classification (AFSC) where the objective is to classify a small, initially unlabeled, dataset given a very restrained labeling budget. This problem can be seen as a rival paradigm to classical Transductive Few-Shot Classification (TFSC), as both these approaches are applicable in similar conditions. We first propose a methodology that combines statistical inference, and an original two-tier active learning strategy that fits well into this framework. We then adapt several standard vision benchmarks from the field of TFSC. Our experiments show the potential benefits of AFSC can be substantial, with gains in average weighted accuracy of up to 10% compared to state-of-the-art TFSC methods for the same labeling budget. We believe this new paradigm could lead to new developments and standards in data-scarce learning settings."}}
{"id": "qpQvgLXaV_", "cdate": 1672531200000, "mdate": 1679155144517, "content": {"title": "Sliced-Wasserstein on Symmetric Positive Definite Matrices for M/EEG Signals", "abstract": ""}}
{"id": "htqE9-Ka4c_", "cdate": 1672531200000, "mdate": 1699613069956, "content": {"title": "Spatial Graph Signal Interpolation with an Application for Merging BCI Datasets with Various Dimensionalities", "abstract": "BCI Motor Imagery datasets usually are small and have different electrodes setups. When training a Deep Neural Network, one may want to capitalize on all these datasets to increase the amount of data available and hence obtain good generalization results. To this end, we introduce a spatial graph signal interpolation technique, that allows to interpolate efficiently multiple electrodes. We conduct a set of experiments with five BCI Motor Imagery datasets comparing the proposed interpolation with spherical splines interpolation. We believe that this work provides novel ideas on how to leverage graphs to interpolate electrodes and on how to homogenize multiple datasets."}}
{"id": "aLYvhHB6gh-", "cdate": 1672531200000, "mdate": 1681732813909, "content": {"title": "Leveraging Neural Koopman Operators to Learn Continuous Representations of Dynamical Systems from Scarce Data", "abstract": "Over the last few years, several works have proposed deep learning architectures to learn dynamical systems from observation data with no or little knowledge of the underlying physics. A line of work relies on learning representations where the dynamics of the underlying phenomenon can be described by a linear operator, based on the Koopman operator theory. However, despite being able to provide reliable long-term predictions for some dynamical systems in ideal situations, the methods proposed so far have limitations, such as requiring to discretize intrinsically continuous dynamical systems, leading to data loss, especially when handling incomplete or sparsely sampled data. Here, we propose a new deep Koopman framework that represents dynamics in an intrinsically continuous way, leading to better performance on limited training data, as exemplified on several datasets arising from dynamical systems."}}
{"id": "a1BtTBL-bl", "cdate": 1672531200000, "mdate": 1699613069958, "content": {"title": "Consistency and Ambiguities of Quality No Reference Metric for Pansharpening", "abstract": "Ideally, evaluation of panchromatic and multispectral image fusion requires the use of a reference image, which is only available in a reduced scale protocol. Thus, no reference metrics such as the now standard Quality No Reference (QNR) were introduced. However, the QNR contains implicit implementation parameters which have not been studied yet. Using a statistical analysis based on rank correlation, we show that those parameters have a significant effect on the QNR values. Moreover, we extend previous results indicating that the QNR has low correlation with reference metrics at reduced scale. These results raise questions about the QNR\u2019s relevance. They call for a standardization of implicit parameters so as to compare values across works, and for the QNR to only be seen as a complementary measure to reference metrics but not as a proxy. The developed protocol is also used to find the best set of implicit parameters, but could be generalized for the assessment of other no reference metrics. Finding such well behaved no reference metric is of critical interest for the development of unsupervised machine learning methods of pansharpening."}}
{"id": "_Jrqzjvh_g", "cdate": 1672531200000, "mdate": 1699613069956, "content": {"title": "Learning Sentinel-2 reflectance dynamics for data-driven assimilation and forecasting", "abstract": "Over the last few years, massive amounts of satellite multispectral and hyperspectral images covering the Earth's surface have been made publicly available for scientific purpose, for example through the European Copernicus project. Simultaneously, the development of self-supervised learning (SSL) methods has sparked great interest in the remote sensing community, enabling to learn latent representations from unlabeled data to help treating downstream tasks for which there is few annotated examples, such as interpolation, forecasting or unmixing. Following this line, we train a deep learning model inspired from the Koopman operator theory to model long-term reflectance dynamics in an unsupervised way. We show that this trained model, being differentiable, can be used as a prior for data assimilation in a straightforward way. Our datasets, which are composed of Sentinel-2 multispectral image time series, are publicly released with several levels of treatment."}}
{"id": "ThqVRa9EDx", "cdate": 1672531200000, "mdate": 1695986115362, "content": {"title": "Spherical Sliced-Wasserstein", "abstract": ""}}
{"id": "TPPI7KuRNeL", "cdate": 1672531200000, "mdate": 1699613069957, "content": {"title": "Entropy Based Feature Regularization to Improve Transferability of Deep Learning Models", "abstract": "When dealing with signals, labeling a classification dataset implies to define classes that may approximate a smoother and more complicated ground truth. For example, natural images may contain multiple objects, only one of which is labeled in many vision datasets, or classes may result from the discretization of a regression problem where targets are continuous. Using cross-entropy to train deep models on such coarse labels is likely to roughly cut through the feature space, potentially disregarding the most meaningful such features, in particular losing information on the underlying fine-grain task. In this paper we are interested in the problem of solving fine-grain classification or regression, using a model trained on coarse-grain labels only. We show that standard cross-entropy can lead to overfitting to coarse-related features. We introduce an entropy-based regularization to promote more diversity in the feature space of trained models, and empirically demonstrate the efficacy of this methodology to reach better performance on the fine-grain problems. Our results are supported by theoretical developments and empirical validation."}}
