{"id": "yspdNwPaiM", "cdate": 1640995200000, "mdate": 1682378344238, "content": {"title": "Super-NaturalInstructions: Generalization via Declarative Instructions on 1600+ NLP Tasks", "abstract": "Yizhong Wang, Swaroop Mishra, Pegah Alipoormolabashi, Yeganeh Kordi, Amirreza Mirzaei, Atharva Naik, Arjun Ashok, Arut Selvan Dhanasekaran, Anjana Arunkumar, David Stap, Eshaan Pathak, Giannis Karamanolakis, Haizhi Lai, Ishan Purohit, Ishani Mondal, Jacob Anderson, Kirby Kuznia, Krima Doshi, Kuntal Kumar Pal, Maitreya Patel, Mehrad Moradshahi, Mihir Parmar, Mirali Purohit, Neeraj Varshney, Phani Rohitha Kaza, Pulkit Verma, Ravsehaj Singh Puri, Rushang Karia, Savan Doshi, Shailaja Keyur Sampat, Siddhartha Mishra, Sujan Reddy A, Sumanta Patro, Tanay Dixit, Xudong Shen. Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing. 2022."}}
{"id": "pQMvodccGW-", "cdate": 1640995200000, "mdate": 1666979439354, "content": {"title": "An Evaluative Measure of Clustering Methods Incorporating Hyperparameter Sensitivity", "abstract": "Clustering algorithms are often evaluated using metrics which compare with ground-truth cluster assignments, such as Rand index and NMI. Algorithm performance may vary widely for different hyperparameters, however, and thus model selection based on optimal performance for these metrics is discordant with how these algorithms are applied in practice, where labels are unavailable and tuning is often more art than science. It is therefore desirable to compare clustering algorithms not only on their optimally tuned performance, but also some notion of how realistic it would be to obtain this performance in practice. We propose an evaluation of clustering methods capturing this ease-of-tuning by modeling the expected best clustering score under a given computation budget. To encourage the adoption of the proposed metric alongside classic clustering evaluations, we provide an extensible benchmarking framework. We perform an extensive empirical evaluation of our proposed metric on popular clustering algorithms over a large collection of datasets from different domains, and observe that our new metric leads to several noteworthy observations."}}
{"id": "OE4kTmxv9_", "cdate": 1640995200000, "mdate": 1666979439359, "content": {"title": "Word2Box: Capturing Set-Theoretic Semantics of Words using Box Embeddings", "abstract": "Shib Dasgupta, Michael Boratko, Siddhartha Mishra, Shriya Atmakuri, Dhruvesh Patel, Xiang Li, Andrew McCallum. Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 2022."}}
{"id": "AOcApHvnkNX", "cdate": 1546300800000, "mdate": 1688544472147, "content": {"title": "Automatic Identification of Mixed Retinal Cells in Time-Lapse Fluorescent Microscopy Images using High-Dimensional DBSCAN", "abstract": "Despite providing high spatial resolution, functional imaging remains largely unsuitable for high-throughput experiments because current practices require cells to be manually identified in a time-consuming procedure. Against this backdrop, we seek to integrate such high-resolution technique in high-throughput workflow by automating the process of cell identification. As a step forward, we attempt to identify mixed retinal cells in time-lapse fluorescent microscopy images. Unfortunately, usual 2D image segmentation as well as other existing methods do not adequately distinguish between time courses of different spatial locations. Here, the task gets further complicated due to the inherent heterogeneity of cell morphology. To overcome such challenge, we propose to use a high-dimensional (HiD) version of DBSCAN (density based spatial clustering of applications with noise) algorithm, where difference in such time courses are appropriately accounted. Significantly, outcome of the proposed method matches manually identified cells with over 80% accuracy, marking more than 50% improvement compared to a reference 2D method."}}
