{"id": "FRTXdodwsoA", "cdate": 1665069635558, "mdate": null, "content": {"title": "REGLO: Provable Neural Network Repair for Global Robustness Properties", "abstract": "We present REGLO, a novel methodology for repairing neural networks to satisfy global robustness properties. In contrast to existing works that focus on local robustness, i.e., robustness of individual inputs, REGLO tackles global robustness, a strictly stronger notion that requires robustness for all inputs within a region. Leveraging an observation that any counterexample to a global robustness property must exhibit a corresponding large gradient, REGLO first identifies violating regions where the counterexamples reside, then uses verified robustness bounds on these regions to formulate a robust optimization problem to compute a minimal weight change in the network that will provably repair the violations. Experimental results demonstrate the effectiveness of REGLO across a set of benchmarks."}}
{"id": "0lGKTI1tho", "cdate": 1632875720096, "mdate": null, "content": {"title": "POLAR: A Polynomial Arithmetic Framework for Verifying Neural-Network Controlled Systems", "abstract": "We propose POLAR, a \\textbf{pol}ynomial \\textbf{ar}ithmetic framework that leverages polynomial overapproximations with interval remainders for bounded-time reachability analysis of neural network-controlled systems (NNCSs).\nCompared with existing arithmetic approaches that use standard Taylor models, our framework uses a novel approach to iteratively overapproximate the neuron output ranges layer-by-layer via a combination of Bernstein polynomial interpolation for continuous activation functions and Taylor model arithmetic for the other operations. This approach overcomes the main drawback in the standard Taylor model arithmetic, i.e. its inability to handle functions that cannot be well approximated by Taylor polynomials, and significantly improve the accuracy and efficiency of reachable states computation for NNCSs. To further tighten the overapproximation, our method keeps the Taylor model remainders symbolic under the linear mappings when propagating Taylor models across the neural-network controller. \nWe show that POLAR can be seamlessly integrated with existing Taylor model flowpipe construction techniques, and POLAR significantly outperforms the current state-of-the-art techniques on a suite of benchmarks."}}
{"id": "Py8WbvKH_wv", "cdate": 1632875504128, "mdate": null, "content": {"title": "DRIBO: Robust Deep Reinforcement Learning via Multi-View Information Bottleneck", "abstract": "Deep reinforcement learning (DRL) agents are often sensitive to visual changes that were unseen in their training environments. To address this problem, we leverage the sequential nature of RL to learn robust representations that encode only task-relevant information from observations based on the unsupervised multi-view setting. Specifically, we introduce a novel contrastive version of Multi-View Information Bottleneck (MIB) objective for temporal data. We train RL agents from pixels with this auxiliary objective to learn robust representations that can compress away task-irrelevant information and are predictive of task-relevant dynamics. This approach enables us to train high-performance policies that are robust to visual distractions and can generalize well to unseen environments. We demonstrate that our approach can achieve SOTA performance on diverse visual control tasks on the DeepMind Control Suite when the background is replaced with natural videos. In addition, we show that our approach outperforms well-established baselines for generalization to unseen environments on the Procgen benchmark."}}
