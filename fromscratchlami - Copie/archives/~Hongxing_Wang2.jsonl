{"id": "Kh0p6hFSbb", "cdate": 1640995200000, "mdate": 1667347740579, "content": {"title": "Multiple cross-attention for video-subtitle moment retrieval", "abstract": ""}}
{"id": "-UKMXENBE_j", "cdate": 1609459200000, "mdate": 1667347740528, "content": {"title": "Self-attention binary neural tree for video summarization", "abstract": ""}}
{"id": "ZLHwaks9d3", "cdate": 1577836800000, "mdate": 1667347740528, "content": {"title": "Deep Adversarial Active Learning With Model Uncertainty For Image Classification", "abstract": "Active learning aims at selecting and labeling as few samples as possible to train a good task model. Most existing methods rely on various heuristics to iteratively select a single sample in each active learning loop, thus cannot tackle large datasets efficiently. In this paper, we propose a new batch-mode active learning method, which can plug model prediction uncertainty into adversarial batch selection to ensure the selected samples are representative in unlabeled data, complementary to labeled data, and beneficial for model training. Experiments on four benchmark image datasets validate the effectiveness and efficiency of the proposed method for active image classification in comparison with the state-of-the-art methods."}}
{"id": "Fblv-7fVyhR", "cdate": 1577836800000, "mdate": 1667347740583, "content": {"title": "Video Summarization with a Dual Attention Capsule Network", "abstract": "In this paper, we address the problem of video summarization, which aims at selecting a subset of video frames as a summary to represent the original video contents compactly and completely. We propose a simple but effective supervised approach with a dual attention capsule network towards this end. Unlike existing LSTM based methods, it pays attention to short- and long-term dependencies among video frames through an elaborate dual self-attention architecture, which can handle longer-term dependencies and admit parallel computing. To reconcile the outputs of dual self-attention, we rely on a two-stream capsule network to learn the underlying frame selection criteria. Experiments on real-world datasets show the advantages of the proposed approach compared with state-of-the-art methods."}}
{"id": "n8AfjnAc9F", "cdate": 1514764800000, "mdate": 1667347740594, "content": {"title": "Representative Selection on a Hypersphere", "abstract": "Finding representative examples is important for pattern discovery and data analytics. In this letter, we propose a novel formulation for representative selection via center reconstruction on a hypersphere, which makes the selection not affect the center information of given data, thus, the overall data distribution can also be easily maintained by those selected representatives. We adopt the proximal gradient strategy and the fast iterative shrinkage-thresholding algorithm to solve the problem. Compared with most existing methods with cubic time complexity in the number of samples, our method is considerably more efficient, with time complexity reduced to being quadratic. Our formulation has only one parameter. We analyze the behavior of this parameter and analyze its bound theoretically. Experiments on synthesis and real-world datasets validate the effectiveness and efficiency of our method and demonstrate its robustness to noise compared with the state-of-the-art methods."}}
{"id": "3-nx9fwawpE", "cdate": 1514764800000, "mdate": 1667347740519, "content": {"title": "Video Summarization Via Multiview Representative Selection", "abstract": "Video contents are inherently heterogeneous. To exploit different feature modalities in a diverse video collection for video summarization, we propose to formulate the task as a multiview representative selection problem. The goal is to select visual elements that are representative of a video consistently across different views (i.e., feature modalities). We present in this paper the multiview sparse dictionary selection with centroid co-regularization method, which optimizes the representative selection in each view, and enforces that the view-specific selections to be similar by regularizing them towards a consensus selection. We also introduce a diversity regularizer to favor a selection of diverse representatives. The problem can be efficiently solved by an alternating minimizing optimization with the fast iterative shrinkage thresholding algorithm. Experiments on synthetic data and benchmark video datasets validate the effectiveness of the proposed approach for video summarization, in comparison with other video summarization methods and representative selection methods such as K-medoids, sparse dictionary selection, and multiview clustering."}}
{"id": "oUxMN6oy9vW", "cdate": 1483228800000, "mdate": 1667347740554, "content": {"title": "Representative Selection with Structured Sparsity", "abstract": ""}}
{"id": "JJPRssKTPI1", "cdate": 1483228800000, "mdate": 1667348208660, "content": {"title": "Video Summarization via Multi-view Representative Selection", "abstract": "Video contents are inherently heterogeneous. To exploit different feature modalities in a diverse video collection for video summarization, we propose to formulate the task as a multi-view representative selection problem. The goal is to select visual elements that are representative of a video consistently across different views (i.e., feature modalities). We present in this paper the multi-view sparse dictionary selection with centroid co-regularization (MSDS-CC) method, which optimizes the representative selection in each view, and enforces that the view-specific selections to be similar by regularizing them towards a consensus selection. The problem can be efficiently solved by an alternating minimizing optimization with the fast iterative shrinkage thresholding algorithm (FISTA). We also show how the formulation can be applied to category-specific video summarization by incorporating visual co-occurrence priors. Experiments on benchmark video datasets validate the effectiveness of the proposed approach in comparison with other video summarization methods and representative selection methods."}}
{"id": "HbmlpBApOAu", "cdate": 1483228800000, "mdate": 1667347740515, "content": {"title": "Discovering Class-Specific Spatial Layouts for Scene Recognition", "abstract": "Scene image is a spatial composition of objects and background contexts and finding discriminative spatial layouts is critical for scene recognition. In this letter, we propose an \u2113 <sub xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">1</sub> -regularized max-margin formulation to discover class-specific spatial layouts by jointly learning the image classifier and the class-specific spatial layouts for scene recognition. Unlike previous methods that classify images into different categories either without considering the spatial layouts explicitly or only using class generic spatial layout, our proposed method can discover a sparse combination of class-specific spatial layouts for different scenes and boost the recognition performance. Experiments on scene-15, landuse-21, and MIT indoor-67 datasets validate the advantages of our proposed algorithm."}}
{"id": "B14zMaZuZr", "cdate": 1451606400000, "mdate": null, "content": {"title": "From Keyframes to Key Objects: Video Summarization by Representative Object Proposal Selection", "abstract": "We propose to summarize a video into a few key objects by selecting representative object proposals generated from video frames. This representative selection problem is formulated as a sparse dictionary selection problem, i.e., choosing a few representatives object proposals to reconstruct the whole proposal pool. Compared with existing sparse dictionary selection based representative selection methods, our new formulation can incorporate object proposal priors and locality prior in the feature space when selecting representatives. Consequently it can better locate key objects and suppress outlier proposals. We convert the optimization problem into a proximal gradient problem and solve it by the fast iterative shrinkage thresholding algorithm (FISTA). Experiments on synthetic data and real benchmark datasets show promising results of our key object summarization approach in video content mining and search. Comparisons with existing representative selection approaches such as K-mediod, sparse dictionary selection and density based selection validate that our formulation can better capture the key video objects despite appearance variations, cluttered backgrounds and camera motions."}}
