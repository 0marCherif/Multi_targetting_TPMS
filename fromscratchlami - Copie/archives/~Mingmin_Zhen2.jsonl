{"id": "kEneZt8_cJ1", "cdate": 1577836800000, "mdate": null, "content": {"title": "KFNet: Learning Temporal Camera Relocalization using Kalman Filtering", "abstract": "Temporal camera relocalization estimates the pose with respect to each video frame in sequence, as opposed to one-shot relocalization which focuses on a still image. Even though the time dependency has been taken into account, current temporal relocalization methods still generally underperform the state-of-the-art one-shot approaches in terms of accuracy. In this work, we improve the temporal relocalization method by using a network architecture that incorporates Kalman filtering (KFNet) for online camera relocalization. In particular, KFNet extends the scene coordinate regression problem to the time domain in order to recursively establish 2D and 3D correspondences for the pose determination. The network architecture design and the loss formulation are based on Kalman filtering in the context of Bayesian learning. Extensive experiments on multiple relocalization benchmarks demonstrate the high accuracy of KFNet at the top of both one-shot and temporal relocalization approaches. Our codes are released at https://github.com/zlthinker/KFNet."}}
{"id": "ik7hSo7m3DJ", "cdate": 1577836800000, "mdate": null, "content": {"title": "Joint Semantic Segmentation and Boundary Detection Using Iterative Pyramid Contexts", "abstract": "In this paper, we present a joint multi-task learning framework for semantic segmentation and boundary detection. The critical component in the framework is the iterative pyramid context module (PCM), which couples two tasks and stores the shared latent semantics to interact between the two tasks. For semantic boundary detection, we propose the novel spatial gradient fusion to suppress non-semantic edges. As semantic boundary detection is the dual task of semantic segmentation, we introduce a loss function with boundary consistency constraint to improve the boundary pixel accuracy for semantic segmentation. Our extensive experiments demonstrate superior performance over state-of-the-art works, not only in semantic segmentation but also in semantic boundary detection. In particular, a mean IoU score of 81.8% on Cityscapes test set is achieved without using coarse data or any external data for semantic segmentation. For semantic boundary detection, we improve over previous state-of-the-art works by 9.9% in terms of AP and 6.8% in terms of MF(ODS)."}}
{"id": "PAc3k1Lxy2w", "cdate": 1577836800000, "mdate": null, "content": {"title": "KFNet: Learning Temporal Camera Relocalization Using Kalman Filtering", "abstract": "Temporal camera relocalization estimates the pose with respect to each video frame in sequence, as opposed to one-shot relocalization which focuses on a still image. Even though the time dependency has been taken into account, current temporal relocalization methods still generally underperform the state-of-the-art one-shot approaches in terms of accuracy. In this work, we improve the temporal relocalization method by using a network architecture that incorporates Kalman filtering (KFNet) for online camera relocalization. In particular, KFNet extends the scene coordinate regression problem to the time domain in order to recursively establish 2D and 3D correspondences for the pose determination. The network architecture design and the loss formulation are based on Kalman filtering in the context of Bayesian learning. Extensive experiments on multiple relocalization benchmarks demonstrate the high accuracy of KFNet at the top of both one-shot and temporal relocalization approaches."}}
{"id": "EDWMgUxLABx", "cdate": 1577836800000, "mdate": null, "content": {"title": "Joint Semantic Segmentation and Boundary Detection using Iterative Pyramid Contexts", "abstract": "In this paper, we present a joint multi-task learning framework for semantic segmentation and boundary detection. The critical component in the framework is the iterative pyramid context module (PCM), which couples two tasks and stores the shared latent semantics to interact between the two tasks. For semantic boundary detection, we propose the novel spatial gradient fusion to suppress nonsemantic edges. As semantic boundary detection is the dual task of semantic segmentation, we introduce a loss function with boundary consistency constraint to improve the boundary pixel accuracy for semantic segmentation. Our extensive experiments demonstrate superior performance over state-of-the-art works, not only in semantic segmentation but also in semantic boundary detection. In particular, a mean IoU score of 81:8% on Cityscapes test set is achieved without using coarse data or any external data for semantic segmentation. For semantic boundary detection, we improve over previous state-of-the-art works by 9.9% in terms of AP and 6:8% in terms of MF(ODS)."}}
{"id": "nAr-fHUzk7", "cdate": 1546300800000, "mdate": null, "content": {"title": "Multi-view based neural network for semantic segmentation on 3D scenes", "abstract": ""}}
{"id": "ysY6bgkwvGf", "cdate": 1451606400000, "mdate": null, "content": {"title": "Regional Subspace Projection Coding for Image Retrieval", "abstract": "For image retrieval task, hamming embedding, being proved to be one of the state-of-the-art methods, has been prevalently utilised. The basic idea is to project local features into orthogonal space randomly, in which the binary signature is generated based on a single partition of feature space. However, the binary signature generation process is coarse and heuristic. On the one hand, the same projection is carried out for all visual word space without consideration of difference among subspaces. On the other hand, the projection matrix is generated randomly regardless of the distribution of feature data. Therefore, the performance of hamming embedding is limited and far from the optimal. In this paper, we firstly analyse the limitation of hamming em- bedding and compare different orthogonal projection methods. Then we propose a regional subspace projection coding method that is based on the distribution of local features assigned to each visual word. Finally, our experiments on two benchmark datasets demonstrate that our proposed method outperforms current state-of-the-art methods."}}
{"id": "fcz_ib9bYD2", "cdate": 1420070400000, "mdate": null, "content": {"title": "Signature of unique angles Histograms for 3D data description", "abstract": "In recent years, the local feature descriptor called SHOT (Signature of Histograms of OrienTations) has achieved excellent performance in 3D vision. However, there still exists room for improvement: on the one hand, the convexity and concavity information is still ambiguous; on the other hand, it is not consistent and unique enough for constructing histograms with just angle information between normals. In this paper, we propose a new robust descriptor called Signature of Unique Angles Histograms (SUAH) with consideration of the unique angles, which are used to construct histograms, between local reference frames. And the convexity sign is embedded to disambiguate the convexity and concavity. In addition, power normalization is used to address the point density problem. A series of experiments are conducted to show that the performance of our method is better than state-of-the-art methods on synthesized dataset and real scenes dataset."}}
{"id": "UsRR7QBzWjB", "cdate": 1420070400000, "mdate": null, "content": {"title": "Improved cluster center adaption for image classification", "abstract": "The feature coding algorithm, \u201cVector of Locally Aggregated Descriptors (VLAD)\u201d, can be used effectively for large scale object instance retrieval. Despite its effectiveness and excellent performance, the existence of ambiguous cluster centers can reduce the performance. Though an idea to this problem has been proposed, it is not practical in fact. In this paper, we analyze possible situations that cause effect on the results and propose a novel approach to improve the VLAD method. The proposed method mainly focuses on the similarity measure between each two images. For each two images, we adapt the original cluster center to VLAD vectors. As we illustrate, our method has promising results with small vocabulary size on both datasets of 15 Scenes and VOC2007."}}
{"id": "0MehbwY5sZN", "cdate": 1420070400000, "mdate": null, "content": {"title": "Improving VLAD with regional PCA whitening", "abstract": "In recent yeas, VLAD has been used to represent an image effectively and efficiently by just a few bytes in large-scale image retrieval. In spite of its remarkable performance, a series of modification methods have been presented. In addition, the redundancy between the features corresponding to the same cluster center could be improved. In this paper, a regional PCA Whitening method is proposed to decorrelate the features and reduce the dimensionality for each cluster with the consideration of mapping the descriptor into high dimensionality explicitly. Our method can also be embedded into original VLAD pipeline with global PCA very well. The experimental results on both Holidays and UKbench dataset show that our approach improves VLAD significantly."}}
