{"id": "UB_azDStFOJ", "cdate": 1640995200000, "mdate": 1667902278393, "content": {"title": "Learn Fast, Segment Well: Fast Object Segmentation Learning on the iCub Robot", "abstract": "The visual system of a robot has different requirements depending on the application: it may require high accuracy or reliability, be constrained by limited resources, or need fast adaptation to dynamically changing environments. In this article, we focus on the instance segmentation task and provide a comprehensive study of different techniques that allow adapting an object segmentation model in the presence of novel objects or different domains. We propose a pipeline for fast instance segmentation learning designed for robotic applications where data come in stream. It is based on an hybrid method leveraging on a pre-trained convolutional neural network for feature extraction and fast-to-train Kernel-based classifiers. We also propose a training protocol that allows to shorten the training time by performing feature extraction during the data acquisition. We benchmark the proposed pipeline on two robotics datasets and we deploy it on a real robot, i.e., the iCub humanoid. To this aim, we adapt our method to an incremental setting in which novel objects are learned online by the robot. The code to reproduce the experiments is publicly available on GitHub. <xref ref-type=\"fn\" rid=\"fn1\" xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><sup>1</sup></xref> <fn id=\"fn1\" xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><label><sup>1</sup></label><p>[Online]. Available: <uri>https://github.com/hsp-iit/online-detection</uri></p></fn>"}}
{"id": "QnpVa7b0E_", "cdate": 1640995200000, "mdate": 1667902278426, "content": {"title": "Physics Informed Shallow Machine Learning for Wind Speed Prediction", "abstract": "The ability to predict wind is crucial for both energy production and weather forecasting. Mechanistic models that form the basis of traditional forecasting perform poorly near the ground. In this paper, we take an alternative data-driven approach based on supervised learning. We analyze a massive dataset of wind measured from anemometers located at 10 m height in 32 locations in two central and north west regions of Italy (Abruzzo and Liguria). We train supervised learning algorithms using the past history of wind to predict its value at a future time (horizon). Using data from a single location and time horizon we compare systematically several algorithms where we vary the input/output variables, the memory of the input and the linear vs non-linear learning model. We then compare performance of the best algorithms across all locations and forecasting horizons. We find that the optimal design as well as its performance vary with the location. We demonstrate that the presence of a reproducible diurnal cycle provides a rationale to understand this variation. We conclude with a systematic comparison with state of the art algorithms and show that, when the model is accurately designed, shallow algorithms are competitive with more complex deep architectures."}}
{"id": "KwbfLBHGY3S", "cdate": 1640995200000, "mdate": 1667902278425, "content": {"title": "Multiclass learning with margin: exponential rates with no bias-variance trade-off", "abstract": "We study the behavior of error bounds for multiclass classification under suitable margin conditions. For a wide variety of methods we prove that the classification error under a hard-margin condit..."}}
{"id": "HdhqlGj9_qX", "cdate": 1640995200000, "mdate": 1667902278424, "content": {"title": "Efficient Hyperparameter Tuning for Large Scale Kernel Ridge Regression", "abstract": "Kernel methods provide a principled approach to nonparametric learning. While their basic implementations scale poorly to large problems, recent advances showed that approximate solvers can efficiently handle massive datasets. A shortcoming of these solutions is that hyperparameter tuning is not taken care of, and left for the user to perform. Hyperparameters are crucial in practice and the lack of automated tuning greatly hinders efficiency and usability. In this paper, we work to fill in this gap focusing on kernel ridge regression based on the Nystr\u00f6m approximation. After reviewing and contrasting a number of hyperparameter tuning strategies, we propose a complexity regularization criterion based on a data dependent penalty, and discuss its efficient optimization. Then, we proceed to a careful and extensive empirical evaluation highlighting strengths and weaknesses of the different tuning strategies. Our analysis shows the benefit of the proposed approach, that we hence incorporate in a library for large scale kernel methods to derive adaptively tuned solutions."}}
{"id": "yHzHbZS73_", "cdate": 1577836800000, "mdate": 1667902278516, "content": {"title": "Kernel Methods Through the Roof: Handling Billions of Points Efficiently", "abstract": "Kernel methods provide an elegant and principled approach to nonparametric learning, but so far could hardly be used in large scale problems, since na\u00efve implementations scale poorly with data size. Recent advances have shown the benefits of a number of algorithmic ideas, for example combining optimization, numerical linear algebra and random projections. Here, we push these efforts further to develop and test a solver that takes full advantage of GPU hardware. Towards this end, we designed a preconditioned gradient solver for kernel methods exploiting both GPU acceleration and parallelization with multiple GPUs, implementing out-of-core variants of common linear algebra operations to guarantee optimal hardware utilization. Further, we optimize the numerical precision of different operations and maximize efficiency of matrix-vector multiplications. As a result we can experimentally show dramatic speedups on datasets with billions of points, while still guaranteeing state of the art performance. Additionally, we make our software available as an easy to use library."}}
