{"id": "OUDszKiaJQh", "cdate": 1690848000000, "mdate": 1696035723205, "content": {"title": "Credible Dual-Expert Learning for Weakly Supervised Semantic Segmentation", "abstract": "Great progress has been witnessed for weakly supervised semantic segmentation, which aims to segment objects without dense pixel annotations. Most approaches concentrate on generating high quality pseudo labels, which are then fed into a standard segmentation model as supervision. However, such a solution has one major limitation: noise of pseudo labels is inevitable, which is unsolvable for the standard segmentation model. In this paper, we propose a credible dual-expert learning (CDL) framework to mitigate the noise of pseudo labels. Specifically, we first observe that the model predictions with different optimization loss functions will have different credible regions; thus, it is possible to make self-corrections with multiple predictions. Based on this observation, we design a dual-expert structure to mine credible predictions, which are then processed by our noise correction module to update pseudo labels in an online way. Meanwhile, to handle the case that the dual-expert produces incredible predictions for the same region, we design a relationship transfer module to provide feature relationships, enabling our noise correction module to transfer predictions from the credible regions to such incredible regions. Considering the above designs, we propose a base CDL network and an extended CDL network to satisfy different requirements. Extensive experiments show that directly replacing our model with a conventional fully supervised segmentation model, the performances of various weakly supervised semantic segmentation pipelines were boosted, achieving new state-of-the-art performances on both PASCAL VOC 2012 and MS COCO with a clear margin. Code will be available at: https://github.com/zbf1991/CDL ."}}
{"id": "9pOooSzz9R", "cdate": 1688169600000, "mdate": 1696035723220, "content": {"title": "Plausible Proxy Mining With Credibility for Unsupervised Person Re-Identification", "abstract": "One effective way to address unsupervised person re-identification is to use a clustering-based contrastive learning approach. Existing state-of-the-art methods adopt clustering algorithms ( <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">e.g.</i> , DBSCAN) and camera ID information to divide all person images into several camera-aware proxies. Then, for each person image, the extracted feature representation is pulled closer to the centroids of its pseudo-positive proxies (the proxies that share the same pseudo-identity label with this image) and pushed away from the centroids of other pseudo-negative proxies (the proxies that share the different pseudo-identity label with this image). However, the quality of the proxy centroid is significantly affected by the proxy impurity issue and thus deteriorates the learned feature representations. On the premise that we cannot introduce superior supervision signals by thoroughly solving the proxy impurity issue, for a person image, identifying its plausible proxies: the pseudo-negative proxies which potentially include its wrongly-clustered instances (the instances with the same ground-truth identity with this image), and further fixing the resulted incorrect supervision signals become an urgent and challenging problem. This paper proposes a simple yet effective approach to address this problem. With a given image, our method can effectively locate its plausible proxies. Then we introduce credibility to measure how much we should treat the centroid of each mined plausible proxy as a positive supervision signal rather than entirely negative. Extensive experiments on three widely-used person re-ID datasets validate the effectiveness of our proposed approach. Codes will be available at: <uri xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">https://github.com/Dingyuan-Zheng/PPCL</uri> ."}}
{"id": "z-T0reHd7Bh", "cdate": 1685577600000, "mdate": 1682317750301, "content": {"title": "Aggregated pyramid gating network for human pose estimation without pre-training", "abstract": ""}}
{"id": "dhtE697vKb", "cdate": 1685577600000, "mdate": 1682317750337, "content": {"title": "Weight-guided class complementing for long-tailed image recognition", "abstract": ""}}
{"id": "S5txpa11m3", "cdate": 1685577600000, "mdate": 1696035723191, "content": {"title": "Real-Time Prediction of Simulator Sickness in Virtual Reality Games", "abstract": "Virtual reality (VR) technology has progressed rapidly and is used in various domains, particularly games. Simulator sickness (SS) still represents a significant problem for its wider adoption. The most common way to detect SS is using the simulator sickness questionnaire (SSQ). SSQ is a subjective measurement and is inadequate for real-time applications such as VR games. This research aims to develop a model to predict SS in real time using in-game characters\u2019 movement and users\u2019 eye motion data during gameplay in VR games. To achieve this, we designed an experiment to collect such data with three types of games. We trained a long short-term memory neural network with the eye-tracking and character movement data to predict SS. Our model can predict SS in real time with an accuracy of 83.4% for players who suffer from severe sensitivity to SS. Our results indicate that, in VR games, our model is an accurate and efficient method to predict SS in real time."}}
{"id": "Ml2Te3PNR3x", "cdate": 1685577600000, "mdate": 1696035723191, "content": {"title": "Towards Simple and Accurate Human Pose Estimation With Stair Network", "abstract": "In this paper, we focus on tackling the precise keypoint coordinates regression task. Most existing approaches adopt complicated networks with a large number of parameters, leading to a heavy model with poor cost-effectiveness in practice. To overcome this limitation, we develop a small yet discrimicative model called STair Network, which can be simply stacked towards an accurate multi-stage pose estimation system. Specifically, to reduce computational cost, STair Network is composed of novel basic feature extraction blocks which focus on promoting feature diversity and obtaining rich local representations with fewer parameters, enabling a satisfactory balance on efficiency and performance. To further improve the performance, we introduce two mechanisms with negligible computational cost, focusing on feature fusion and replenish. We demonstrate the effectiveness of the STair Network on two standard datasets, e.g., 1-stage STair Network achieves a higher accuracy than HRNet by 5.5% on COCO test dataset with 80% fewer parameters and 68% fewer GFLOPs."}}
{"id": "yZHVZeOaeJy", "cdate": 1672531200000, "mdate": 1682317750225, "content": {"title": "PointGS: Bridging and fusing geometric and semantic space for 3D point cloud analysis", "abstract": ""}}
{"id": "Q12Y4Pj55YO", "cdate": 1672531200000, "mdate": 1696035723206, "content": {"title": "Cycle-Free Weakly Referring Expression Grounding With Self-Paced Learning", "abstract": "In this paper, we are tackling the weakly referring expression grounding task to localize the target object in an image according to a given query sentence, where the mapping between the query sentence and image regions is blind during the training period. Previous methods all follow a cyclic forward-backward pipeline to handle this task, where the query sentence is firstly converted to the result region through the forward module, and then the result region is converted back to a sentence through the backward module, with the difference between the reconstructed sentence and original query used as the loss to optimize the entire network. These existing methods, however, suffer from the deviation issue when the result region, generated through the forward module, totally deviates from the target area, but the backward module still reconstructs a similar sentence. The aforementioned loss function cannot penalize this kind of deviation because of the consistent prediction of the sentence. To overcome this limitation, we propose a cycle-free pipeline, where a region describer network is designed to predict the textual description for each candidate region, and a result region is selected according to the similarity between the predicted description and the query sentence. Furthermore, a self-paced learning mechanism is designed to avoid the drift issue during the warm-up period of the optimization process. The proposed method achieves a higher average accuracy on RefCOCO and RefCOCO+ datasets, compared with all previous state-of-the-art methods."}}
{"id": "Ld1iKKOOhO", "cdate": 1672531200000, "mdate": 1696035723198, "content": {"title": "Starting Point Selection and Multiple-Standard Matching for Video Object Segmentation With Language Annotation", "abstract": "In this study, we investigate language-level video object segmentation, where first-frame language annotation is used to describe the target object. Because a language label is typically compatible with all frames in a video, the proposed method can choose the most suitable starting frame to mitigate initialization failure. Apart from extracting the visual feature from a static video frame, a motion-language score based on optical flow is also proposed to describe moving objects more accurately. Scores of multiple standards are then aggregated using an attention-based mechanism to predict the final result. The proposed method is evaluated on four widely-used video object segmentation datasets, including the DAVIS 2017, DAVIS 2016, SegTrack V2 and YouTubeObject datasets, and a novel accuracy measured as mean region similarity is obtained on both the DAVIS 2017 (67.2%) and DAVIS 2016 (83.5%) datasets. The code will be published."}}
{"id": "Eai6Trqk7e", "cdate": 1672531200000, "mdate": 1682317750351, "content": {"title": "Weight-guided loss for long-tailed object detection and instance segmentation", "abstract": ""}}
