{"id": "bKcEM2EM-qY", "cdate": 1672531200000, "mdate": 1682376111834, "content": {"title": "Multi-Task and Few-Shot Learning-Based Fully Automatic Deep Learning Platform for Mobile Diagnosis of Skin Diseases", "abstract": "Fluorescence imaging-based diagnostic systems have been widely used to diagnose skin diseases due to their ability to provide detailed information related to the molecular composition of the skin compared to conventional RGB imaging. In addition, recent advances in smartphones have made them suitable for application in biomedical imaging, and therefore various smartphone-based optical imaging systems have been developed for mobile healthcare. However, an advanced analysis algorithm is required to improve the diagnosis of skin diseases. Various deep learning-based algorithms have recently been developed for this purpose. However, deep learning-based algorithms using only white-light reflectance RGB images have exhibited limited diagnostic performance. In this study, we developed an auxiliary deep learning network called fluorescence-aided amplifying network (FAA-Net) to diagnose skin diseases using a developed multi-modal smartphone imaging system that offers RGB and fluorescence images. FAA-Net is equipped with a meta-learning-based algorithm to solve problems that may occur due to the insufficient number of images acquired by the developed system. In addition, we devised a new attention-based module that can learn the location of skin diseases by itself and emphasize potential disease regions, and incorporated it into FAA-Net. We conducted a clinical trial in a hospital to evaluate the performance of FAA-Net and to compare various evaluation metrics of our developed model and other state-of-the-art models for the diagnosis of skin diseases using our multi-modal system. Experimental results demonstrated that our developed model exhibited an 8.61% and 9.83% improvement in mean accuracy and area under the curve in classifying skin diseases, respectively, compared with other advanced models."}}
{"id": "AKOvXw5G-k8", "cdate": 1668669000128, "mdate": 1668669000128, "content": {"title": "Fully-Automatic Deep Learning-Based Analysis for Determination of Invasiveness of Breast Cancer Cells in an Acoustic Trap", "abstract": "A single-beam acoustic trapping technique has been shown to be very useful for determining the invasiveness of suspended breast cancer cells in an acoustic trap with a manual calcium analysis method. However, for the rapid translation of the technology into the clinic, the development of an efficient/accurate analytical method is needed. We, therefore, develop a fully-automatic deep learning-based calcium image analysis algorithm for determining the invasiveness of suspended breast cancer cells using a single-beam acoustic trapping system. The algorithm allows to segment cells, find trapped cells, and quantify their calcium changes over time. For better segmentation of calcium fluorescent cells even with vague boundaries, a novel deep learning architecture with multi-scale/multi-channel convolution operations (MM-Net) is devised and constructed by a target inversion training method. The MM-Net outperforms other deep learning models in the cell segmentation. Also, a detection/quantification algorithm is developed and implemented to automatically determine the invasiveness of a trapped cell. For the evaluation of the algorithm, it is applied to quantify the invasiveness of breast cancer cells. The results show that the algorithm offers similar performance to the manual calcium analysis method for determining the invasiveness of cancer cells, suggesting that it may serve as a novel tool to automatically determine the invasiveness of cancer cells with high-efficiency."}}
{"id": "ZGfi_1AD7tR", "cdate": 1668668888208, "mdate": 1668668888208, "content": {"title": "Smartphone-based spectral imaging otoscope: system development and preliminary study for evaluation of its potential as a mobile diagnostic tool", "abstract": "We develop a novel smartphone-based spectral imaging otoscope for telemedicine and examine its capability for the mobile diagnosis of middle ear diseases. The device was applied to perform spectral imaging and analysis of an ear-mimicking phantom and a normal and abnormal tympanic membrane for evaluation of its potential for the mobile diagnosis. Spectral classified images were obtained via online spectral analysis in a remote server. The phantom experimental results showed that it allowed us to distinguish four different fluids located behind a semitransparent membrane. Also, in the spectral classified images of normal ears (n = 3) and an ear with chronic otitis media (n = 1), the normal and abnormal regions in each ear could be quantitatively distinguished with high contrast. These preliminary results thus suggested that it might have the potentials for providing quantitative information for the mobile diagnosis of various middle ear diseases."}}
{"id": "I3ZYCsghEH", "cdate": 1668668766096, "mdate": 1668668766096, "content": {"title": "Wide-field 3D Ultrasound Imaging Platform With a Semi-automatic 3D Segmentation Algorithm for Quantitative Analysis of Rotator Cuff Tears", "abstract": "Rotator cuff tear (RCT) is a common injury that causes pain and disability in adults. The quantitative diagnosis of the RCT can be crucial in determining a treatment plan or monitoring treatment efficacy. Currently, only a few diagnosis tools, such as magnetic resonance imaging (MRI) and ultrasound imaging (US), are utilized for the diagnosis. Specifically, US exhibited comparable performance with MRI while offering a readily available diagnosis of RCTs at a lower cost. However, three-dimensional(3D) US and analysis of the regions are necessary to enable a better diagnosis of RCTs. Therefore, we developed a wide-field 3D US platform with a semi-automatic 3D image segmentation algorithm for 3D quantitative diagnosis of RCTs. The 3D US platform is built based on a conventional 2D US system and obtains 3D US images via linear scanning. With respect to 3D segmentation algorithm based on active contour model, frequency compounding and anisotropic diffusion methods were applied, and their effects on segmentation were discussed. The platform was used for clinical examination after evaluating the platform via the RCT-mimicking phantoms. As verified by the Dice coefficient(average DC: 0.663, volume DC: 0.723), which was approximately up to 50% higher than that obtained with conventional algorithms, the RCT regions segmented by the developed algorithm significantly matched the ground truth. The results indicated that the wide-field 3D US platform with the 3D segmentation algorithm can constitute a useful tool for improving the accuracy in the diagnosis of RCTs, and can eventually lead to better determination of treatment plans and surgical planning."}}
{"id": "NWxRYNYUjb7", "cdate": 1668668647162, "mdate": 1668668647162, "content": {"title": "Domain Adaptive Transfer Attack (DATA)-based Segmentation Networks for Building Extraction from Aerial Images", "abstract": "Semantic segmentation models based on convolutional neural networks (CNNs) have gained much attention in relation to remote sensing and have achieved remarkable performance for the extraction of buildings from high-resolution aerial images. However, the issue of limited generalization for unseen images remains. When there is a domain gap between the training and test data sets, the CNN-based segmentation models trained by a training data set fail to segment buildings for the test data set. In this article, we propose segmentation networks based on a domain adaptive transfer attack (DATA) scheme for building extraction from aerial images. The proposed system combines the domain transfer and the adversarial attack concepts. Based on the DATA scheme, the distribution of the input images can be shifted to that of the target images while turning images into adversarial examples against a target network. Defending adversarial examples adapted to the target domain can overcome the performance degradation due to the domain gap and increase the robustness of the segmentation model. Cross-data set experiments and ablation study are conducted for three different data sets: the Inria aerial image labeling data set, the Massachusetts building data set, and the WHU East Asia data set. Compared with the performance of the segmentation network without the DATA scheme, the proposed method shows improvements in the overall intersection over union (IoU). Moreover, it is verified that the proposed method outperforms even when compared with feature adaptation (FA) and output space adaptation (OSA)."}}
{"id": "w0h7wiY9j9", "cdate": 1668668488368, "mdate": null, "content": {"title": "Local Similarity Siamese Network for Urban Use Change Detection on Aerial Images", "abstract": "Change detection is an important task in the field of remote sensing. Various change detection methods based on convolutional neural networks (CNNs) have recently been proposed for remote sensing using satellite or aerial images. However, existing methods allow only the partial use of content information in images during change detection because they adopt simple feature similarity measurements or pixel-level loss functions to construct their network architectures. Therefore, when these methods are applied to complex urban areas, their performance in terms of change detection tends to be limited. In this article, a novel CNN-based change detection approach, referred to as a local similarity Siamese network (LSS-Net), with a cosine similarity measurement, was proposed for better urban land change detection in remote sensing images. To use content information on two sequential images, a new change attention map-based content loss function was developed in this study. In addition, to enhance the performance of the LSS-Net in terms of change detection, a suitable feature similarity measurement method, incorporated into a local similarity attention module, was determined through systemic experiments. To verify the change detection performance of the LSS-Net, it was compared with other state-of-the-art methods. The experimental results show that the proposed method outperforms the state-of-the-art methods in terms of the F1 score (0.9630, 0.9377, and 0.7751) and kappa (0.9581, 0.9351, and 0.7646) on the three test datasets, thus suggesting its potential for various remote sensing applications."}}
{"id": "2OY4Oeifij", "cdate": 1668668447338, "mdate": 1668668447338, "content": {"title": "Imbalanced Loss-Integrated Deep-Learning-Based Ultrasound Image Analysis for Diagnosis of Rotator-Cuff Tear", "abstract": "A rotator cuff tear (RCT) is an injury in adults that causes difficulty in moving, weakness, and pain. Only limited diagnostic tools such as magnetic resonance imaging (MRI) and ultrasound Imaging (UI) systems can be utilized for an RCT diagnosis. Although UI offers comparable performance at a lower cost to other diagnostic instruments such as MRI, speckle noise can occur the degradation of the image resolution. Conventional vision-based algorithms exhibit inferior performance for the segmentation of diseased regions in UI. In order to achieve a better segmentation for diseased regions in UI, deep-learning-based diagnostic algorithms have been developed. However, it has not yet reached an acceptable level of performance for application in orthopedic surgeries. In this study, we developed a novel end-to-end fully convolutional neural network, denoted as Segmentation Model Adopting a pRe-trained Classification Architecture (SMART-CA), with a novel integrated on positive loss function (IPLF) to accurately diagnose the locations of RCT during an orthopedic examination using UI. Using the pre-trained network, SMART-CA can extract remarkably distinct features that cannot be extracted with a normal encoder. Therefore, it can improve the accuracy of segmentation. In addition, unlike other conventional loss functions, which are not suited for the optimization of deep learning models with an imbalanced dataset such as the RCT dataset, IPLF can efficiently optimize the SMART-CA. Experimental results have shown that SMART-CA offers an improved precision, recall, and dice coefficient of 0.604% (+38.4%), 0.942% (+14.0%) and 0.736% (+38.6%) respectively. The RCT segmentation from a normal ultrasound image offers the improved precision, recall, and dice coefficient of 0.337% (+22.5%), 0.860% (+15.8%) and 0.484% (+28.5%), respectively, in the RCT segmentation from an ultrasound image with severe speckle noise. The experimental results demonstrated the IPLF outperforms other conventional loss functions, and the proposed SMART-CA optimized with the IPLF showed better performance than other state-of-the-art networks for the RCT segmentation with high robustness to speckle noise."}}
{"id": "reZe-3engRP", "cdate": 1668668336947, "mdate": 1668668336947, "content": {"title": "Federated Learning for Thyroid Ultrasound Image Analysis to Protect Personal Information: Validation Study in Real Healthcare Environment", "abstract": "Background: Federated learning is a decentralized approach to machine learning; it is a training strategy that overcomes medical data privacy regulations and generalizes deep learning algorithms. Federated learning mitigates many systemic privacy risks by sharing only the model and parameters for training, without the need to export existing medical data sets. In this study, we performed ultrasound image analysis using federated learning to predict whether thyroid nodules were benign or malignant.\n\nObjective: The goal of this study was to evaluate whether the performance of federated learning was comparable with that of conventional deep learning.\n\nMethods: A total of 8457 (5375 malignant, 3082 benign) ultrasound images were collected from 6 institutions and used for federated learning and conventional deep learning. Five deep learning networks (VGG19, ResNet50, ResNext50, SE-ResNet50, and SE-ResNext50) were used. Using stratified random sampling, we selected 20% (1075 malignant, 616 benign) of the total images for internal validation. For external validation, we used 100 ultrasound images (50 malignant, 50 benign) from another institution.\n\nResults: For internal validation, the area under the receiver operating characteristic (AUROC) curve for federated learning was between 78.88% and 87.56%, and the AUROC for conventional deep learning was between 82.61% and 91.57%. For external validation, the AUROC for federated learning was between 75.20% and 86.72%, and the AUROC curve for conventional deep learning was between 73.04% and 91.04%.\n\nConclusions: We demonstrated that the performance of federated learning using decentralized data was comparable to that of conventional deep learning using pooled data. Federated learning might be potentially useful for analyzing medical images while protecting patients' personal information.\n\nKeywords: deep learning; federated learning; thyroid nodules; ultrasound image."}}
{"id": "blA0itqD1hj", "cdate": 1668668264471, "mdate": 1668668264471, "content": {"title": "Intelligent smartphone-based multimode imaging otoscope for the mobile diagnosis of otitis media", "abstract": "Otitis media (OM) is one of the most common ear diseases in children and a common reason for outpatient visits to medical doctors in primary care practices. Adhesive OM (AdOM) is recognized as a sequela of OM with effusion (OME) and often requires surgical intervention. OME and AdOM exhibit similar symptoms, and it is difficult to distinguish between them using a conventional otoscope in a primary care unit. The accuracy of the diagnosis is highly dependent on the experience of the examiner. The development of an advanced otoscope with less variation in diagnostic accuracy by the examiner is crucial for a more accurate diagnosis. Thus, we developed an intelligent smartphone-based multimode imaging otoscope for better diagnosis of OM, even in mobile environments. The system offers spectral and autofluorescence imaging of the tympanic membrane using a smartphone attached to the developed multimode imaging module. Moreover, it is capable of intelligent analysis for distinguishing between normal, OME, and AdOM ears using a machine learning algorithm. Using the developed system, we examined the ears of 69 patients to assess their performance for distinguishing between normal, OME, and AdOM ears. In the classification of ear diseases, the multimode system based on machine learning analysis performed better in terms of accuracy and F1 scores than single RGB image analysis, RGB/fluorescence image analysis, and the analysis of spectral image cubes only, respectively. These results demonstrate that the intelligent multimode diagnostic capability of an otoscope would be beneficial for better diagnosis and management of OM."}}
{"id": "E_EEq56ytM", "cdate": 1668668066276, "mdate": 1668668066276, "content": {"title": "USG-Net: Deep Learning-based Ultrasound Scanning-Guide for an Orthopedic Sonographer", "abstract": "Ultrasound (US) imaging is widely used in the field of medicine. US images containing pathological information are essential for better diagnosis. However, it is challenging to obtain informative US images because of their anatomical complexity, which is significantly dependent on the expertise of the sonographer. Therefore, in this study, we propose a fully automatic scanning-guide algorithm that assists unskilled sonographers in acquiring informative US images by providing accurate directions of probe movement to search for target disease regions. The main contributions of this study are: (1) proposing a new scanning-guide task that searches for a rotator cuff tear (RCT) region using a deep learning-based algorithm, i.e., ultrasound scanning-guide network (USG-Net); (2) constructing a dataset to optimize the corresponding deep learning algorithm. Multidimensional US images collected from 80 patients with RCT were processed to optimize the scanning-guide algorithm which classified the existence of RCT. Furthermore, the algorithm provides accurate directions for the RCT, if it is not in the current frame. The experimental results demonstrate that the fully optimized scanning-guide algorithm offers accurate directions to localize a probe within target regions and helps to acquire informative US images."}}
