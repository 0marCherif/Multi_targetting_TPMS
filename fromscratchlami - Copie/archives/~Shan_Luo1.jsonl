{"id": "D_P10z7nqGC", "cdate": 1640995200000, "mdate": 1677541310828, "content": {"title": "Long-tailed Instance Segmentation using Gumbel Optimized Loss", "abstract": ""}}
{"id": "Bs4XPWNRnVK", "cdate": 1640995200000, "mdate": 1667817512864, "content": {"title": "Inverse Image Frequency for Long-tailed Image Recognition", "abstract": "The long-tailed distribution is a common phenomenon in the real world. Extracted large scale image datasets inevitably demonstrate the long-tailed property and models trained with imbalanced data can obtain high performance for the over-represented categories, but struggle for the under-represented categories, leading to biased predictions and performance degradation. To address this challenge, we propose a novel de-biasing method named Inverse Image Frequency (IIF). IIF is a multiplicative margin adjustment transformation of the logits in the classification layer of a convolutional neural network. Our method achieves stronger performance than similar works and it is especially useful for downstream tasks such as long-tailed instance segmentation as it produces fewer false positive detections. Our extensive experiments show that IIF surpasses the state of the art on many long-tailed benchmarks such as ImageNet-LT, CIFAR-LT, Places-LT and LVIS, reaching 55.8% top-1 accuracy with ResNet50 on ImageNet-LT and 26.2% segmentation AP with MaskRCNN on LVIS. Code available at https://github.com/kostas1515/iif"}}
{"id": "cPLho5HxQNt", "cdate": 1546300800000, "mdate": 1681855054521, "content": {"title": "Fully Convolutional One-Shot Object Segmentation for Industrial Robotics", "abstract": "The ability to identify and localize new objects robustly and effectively is vital for robotic grasping and manipulation in warehouses or smart factories. Deep convolutional neural networks (DCNNs) have achieved the state-of-the-art performance on established image datasets for object detection and segmentation. However, applying DCNNs in dynamic industrial scenarios, e.g., warehouses and autonomous production, remains a challenging problem. DCNNs quickly become ineffective when tasked with detecting objects that they have not been trained on. Given that re-training using the latest data is time consuming, DCNNs cannot meet the requirement of the Factory of the Future (FoF) regarding rapid development and production cycles. To address this problem, we propose a novel one-shot object segmentation framework, using a fully convolutional Siamese network architecture, to detect previously unknown objects based on a single prototype image. We turn to multi-task learning to reduce training time and improve classification accuracy. Furthermore, we introduce a novel approach to automatically cluster the learnt feature space representation in a weakly supervised manner. We test the proposed framework on the RoboCup@Work dataset, simulating requirements for the FoF. Results show that the trained network on average identifies 73% of previously unseen objects correctly from a single example image. Correctly identified objects are estimated to have a 87.53% successful pick-up rate. Finally, multi-task learning lowers the convergence time by up to 33%, and increases accuracy by 2.99%."}}
{"id": "SJVmbjZOWr", "cdate": 1546300800000, "mdate": null, "content": {"title": "Neural Logic Reinforcement Learning", "abstract": "Deep reinforcement learning (DRL) has achieved significant breakthroughs in various tasks. However, most DRL algorithms suffer a problem of generalising the learned policy, which makes the policy p..."}}
{"id": "SB1BpfM3UWg", "cdate": 1546300800000, "mdate": 1681855054522, "content": {"title": "Surface Following using Deep Reinforcement Learning and a GelSightTactile Sensor", "abstract": "Tactile sensors can provide detailed contact in-formation that can facilitate robots to perform dexterous, in-hand manipulation tasks. One of the primitive but important tasks is surface following that is a key feature for robots while exploring unknown environments or workspace of inaccurate modeling. In this paper, we propose a novel end-to-end learning strategy, by directly mapping the raw tactile data acquired from a GelSight tactile sensor to the motion of the robot end-effector.Experiments on a KUKA youBot platform equipped with theGelSight sensor show that 80% of the actions generated by a fully trained SFDQN model are proper surface following actions; the autonomous surface following test also indicates that the proposed solution works well on a test surface."}}
