{"id": "WBVbl8POq8v", "cdate": 1621629963718, "mdate": null, "content": {"title": "Doubly Robust Thompson Sampling with Linear Payoffs", "abstract": "A challenging aspect of the bandit problem is that a stochastic reward is observed only for the chosen arm and the rewards of other arms remain missing.    \nThe dependence of the arm choice on the past context and reward pairs compounds the complexity of regret analysis.\nWe propose a novel multi-armed contextual bandit algorithm called Doubly Robust Thompson Sampling (DRTS) employing the doubly-robust estimator used in missing data literature to Thompson Sampling with contexts (\\texttt{LinTS}).\nDifferent from previous works relying on missing data techniques (Dimakopoulou et al. [2019], Kim and Paik [2019]), the proposed algorithm is designed to allow a novel additive regret decomposition leading to an improved regret bound with the order of $\\tilde{O}(\\phi^{-2}\\sqrt{T})$, where $\\phi^2$ is the minimum eigenvalue of the covariance matrix of contexts.\nThis is the first regret bound of \\texttt{LinTS} using $\\phi^2$ without $d$,  where $d$ is the dimension of the context.\nApplying the relationship between $\\phi^2$ and $d$, the regret bound of the proposed algorithm is $\\tilde{O}(d\\sqrt{T})$ in many practical scenarios, improving the bound of \\texttt{LinTS} by a factor of $\\sqrt{d}$.\nA benefit of the proposed method is that it uses all the context data, chosen or not chosen, thus allowing to circumvent the technical definition of unsaturated arms used in theoretical analysis of \\texttt{LinTS}.\nEmpirical studies show the advantage of the proposed algorithm over \\texttt{LinTS}."}}
{"id": "3CZz3cgUqrq3", "cdate": 1598668492606, "mdate": null, "content": {"title": "Cluster-specific nonignorably missing, endogenous, and continuous regressors in multilevel model for binary outcome", "abstract": "In multilevel regression models for observational clustered data, regressors can be correlated with cluster-level error components, namely endogenous, due to omitted cluster-level covariates, measurement error, and simultaneity. When endogeneity is ignored, regression coefficient estimators can be severely biased. To deal with endogeneity, instrument variable methods have been widely used. However, the instrument variable method often requires external instrument variables with certain conditions that cannot be verified empirically. Methods that use the within-cluster variations of the endogenous variable work under the restriction that either the outcome or the endogenous variable has a linear relationship with the cluster-level random effect. We propose a new method for binary outcome when it follows a logistic mixed-effects model and the endogenous variable is normally distributed but not linear in the random effect. The proposed estimator capitalizes on the nested data structure without requiring external instrument variables. We show that the proposed estimator is consistent and asymptotically normal. Furthermore, our method can be applied when the endogenous variable is missing in a cluster-specific nonignorable mechanism, without requiring that the missing mechanism be correctly specified. We evaluate the finite sample performance of the proposed approach via simulation and apply the method to a health care study using a San Diego inpatient dataset. Our study demonstrates that the clustered structure can be exploited to draw valid analysis of multilevel data with correlated effects."}}
{"id": "rJlOc4Bl8r", "cdate": 1567802512389, "mdate": null, "content": {"title": "Doubly-Robust Lasso Bandit", "abstract": "Contextual multi-armed bandit algorithms are widely used in sequential decision tasks such as news article recommendation systems, web page ad placement algorithms, and mobile health. Most of the existing algorithms have regret proportional to a polynomial function of the context dimension, $d$. In many applications however, it is often the case that contexts are high-dimensional with only a sparse subset of size $s_0 (\\ll d)$ being correlated with the reward. We propose a novel algorithm, namely the Doubly-Robust Lasso Bandit algorithm, which exploits the sparse structure as in Lasso, while blending the doubly-robust technique used in missing data literature. The high-probability upper bound of the regret incurred by the proposed algorithm does not depend on the number of arms, has better dependency on $s_0$ than previous works, and scales with $\\mathrm{log}(d)$ instead of a polynomial function of $d$. The proposed algorithm shows good performance when contexts of different arms are correlated and requires less tuning parameters than existing methods. "}}
{"id": "Bk-rOn-dZB", "cdate": 1546300800000, "mdate": null, "content": {"title": "Contextual Multi-armed Bandit Algorithm for Semiparametric Reward Model", "abstract": "Contextual multi-armed bandit (MAB) algorithms have been shown promising for maximizing cumulative rewards in sequential decision tasks such as news article recommendation systems, web page ad plac..."}}
{"id": "Sk_P2Q9sG", "cdate": 1523362911895, "mdate": null, "content": {"title": "Uncertainty quantification using Bayesian neural networks in classification: Application to ischemic stroke lesion segmentation", "abstract": "Most recent research of neural networks in the field of computer vision has focused on improving accuracy of point predictions by developing various network architectures or learning algorithms. Uncertainty quantification accompanied by point estimation can lead to a more informed decision, and the quality of prediction can be improved. In medical imaging applications, assessment of uncertainty could potentially reduce untoward outcomes due to suboptimal decisions. In this paper, we invoke a Bayesian neural network and propose a natural way to quantify uncertainty in classification problems by decomposing predictive uncertainty into two parts, aleatoric and epistemic uncertainty. The proposed method takes into account discrete nature of the outcome, yielding correct interpretation of each uncertainty. We demonstrate that the proposed uncertainty quantification method provides additional insight to the point prediction using images from the Ischemic Stroke Lesion Segmentation Challenge."}}
