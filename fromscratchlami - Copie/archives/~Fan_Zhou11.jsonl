{"id": "PIVcKX4BN6", "cdate": 1682899200000, "mdate": 1684201729840, "content": {"title": "CCGL: Contrastive Cascade Graph Learning", "abstract": "Supervised learning, while prevalent for information cascade modeling, often requires abundant labeled data in training, and the trained model is not easy to generalize across tasks and datasets. It often learns task-specific representations, which can easily result in overfitting for downstream tasks. Recently, self-supervised learning is designed to alleviate these two fundamental issues in linguistic and visual tasks. However, its direct applicability for information cascade modeling, especially graph cascade related tasks, remains underexplored. In this work, we present Contrastive Cascade Graph Learning ( <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">CCGL</i> ), a novel framework for information cascade graph learning in a <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">contrastive</i> , <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">self-supervised</i> , and <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">task-agnostic</i> way. In particular, CCGL first designs an effective data augmentation strategy to capture variation and uncertainty by simulating the information diffusion in graphs. Second, it learns a generic model for graph cascade tasks via self-supervised contrastive pre-training using both unlabeled and labeled data. Third, CCGL learns a task-specific cascade model via <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">fine-tuning</i> using labeled data. Finally, to make the model transferable across datasets and cascade applications, CCGL further enhances the model via <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">distillation</i> using a teacher-student architecture. We demonstrate that CCGL significantly outperforms its supervised and semi-supervised counterparts for several downstream tasks."}}
{"id": "VtLH_iTBsLq", "cdate": 1680307200000, "mdate": 1680078393381, "content": {"title": "CasFlow: Exploring Hierarchical Structures and Propagation Uncertainty for Cascade Prediction", "abstract": ""}}
{"id": "QCIGTlIC9a", "cdate": 1680307200000, "mdate": 1684201729941, "content": {"title": "Adversarial Human Trajectory Learning for Trip Recommendation", "abstract": "The problem of trip recommendation has been extensively studied in recent years, by both researchers and practitioners. However, one of its key aspects\u2014understanding human mobility\u2014remains under-explored. Many of the proposed methods for trip modeling rely on empirical analysis of attributes associated with historical points-of-interest (POIs) and routes generated by tourists while attempting to also intertwine personal preferences\u2014such as contextual topics, geospatial, and temporal aspects. However, the implicit transitional preferences and semantic sequential relationships among various POIs, along with the constraints implied by the starting point and destination of a particular trip, have not been fully exploited. Inspired by the recent advances in generative neural networks, in this work we propose DeepTrip\u2014an end-to-end method for better understanding of the underlying human mobility and improved modeling of the POIs\u2019 transitional distribution in human moving patterns. DeepTrip consists of: a trip encoder (TE) to embed the contextual route into a latent variable with a recurrent neural network (RNN); and a trip decoder to reconstruct this route conditioned on an optimized latent space. Simultaneously, we define an Adversarial Net composed of a generator and critic, which generates a representation for a given query and uses a critic to distinguish the trip representation generated from TE and query representation obtained from Adversarial Net. DeepTrip enables regularizing the latent space and generalizing users\u2019 complex check-in preferences. We demonstrate, both theoretically and empirically, the effectiveness and efficiency of the proposed model, and the experimental evaluations show that DeepTrip outperforms the state-of-the-art baselines on various evaluation metrics"}}
{"id": "uQnLPNj1YX", "cdate": 1677628800000, "mdate": 1684201729891, "content": {"title": "Improving session-based recommendation with contrastive learning", "abstract": "Session-based recommendation, which aims to predict the next item given anonymous behavior sequences of users, is critical in modern recommender systems. While prior works have made efforts to improve recommendation performance, two challenges remain unsolved. First, existing learning methodologies rely on mining sequential patterns within the individual session and use the next item as the supervised signal, which may not effectively capture the correlations among interactions. Second, previous solutions are also limited in learning the mixed dependencies inside flexibly ordered sessions, i.e., sequential dependencies among ordered interactions and non-sequential dependencies among unordered ones. This work presents a novel session recommender algorithm by distilling knowledge and supervision signals from sessions in a contrastive manner. We propose position-aware importance extraction module with contrastive learning, which utilizes the intrinsic dependencies to discover extra knowledge and augment the ability of information distillation. Besides, we introduce a bi-directional matching algorithm with contrastive loss to capture potential patterns through maximizing the mutual information between current interaction and historical behaviors. Moreover, we introduce a simple yet effective learnable position-coding mechanism with self-attention-based importance extraction to flexibly learn user browsing patterns. Extensive experiments conducted on two real-world datasets demonstrate that our proposed algorithm enhances the recommendation performance over existing state-of-the-art approaches."}}
{"id": "rXjFISOzvJ", "cdate": 1672531200000, "mdate": 1684201729866, "content": {"title": "Exploring indirect entity relations for knowledge graph enhanced recommender system", "abstract": ""}}
{"id": "lQlXxnSKUsc", "cdate": 1672531200000, "mdate": 1683757408075, "content": {"title": "When Friendship Meets Sequential Human Check-ins: Inferring Social Circles with Variational Mobility", "abstract": ""}}
{"id": "Uq1rL1D-KTg", "cdate": 1672531200000, "mdate": 1684201730026, "content": {"title": "Reservoir Inflow Forecasting in Hydropower Industry: A Generative Flow-Based Approach", "abstract": "Forecasting the inflow of reservoirs plays an essential role in the hydropower industry. Existing studies are either limited to point estimates or inefficient in capturing higher-order dynamic correlations across data. It is nevertheless necessary to estimate data uncertainty in actual dam operation. This article presents a novel inflow prediction method that exploits generative flows to model complex multivariate hydrological time series. Our flow-to-flow method (F2F) augments the deterministic models with the normalizing flow-based generative networks to explicitly capture the multivariate correlations and approximate the predictive inflow distribution. Besides, F2F can quantify the prediction uncertainty to help interpret model behavior and predicted results while facilitating safety-critical decision-making on real-time reservoir operation. We conduct extensive experiments on real-world datasets collected from large-scale hydropower stations. The experimental results show that our method consistently outperforms existing methods while accounting for uncertain observations and providing tractable multistep ahead inflow forecasts."}}
{"id": "b-3cQ_h4kqz", "cdate": 1671476183567, "mdate": null, "content": {"title": "AO-Net: Efficient Neural Network for Ambient Occlusion", "abstract": "Screen space based ambient occlusion is widely applied in real-time 3D applications due to its high efficiency, however, it frequently exhibits artifacts including banding and blurring. In this paper, we propose AO-Net, a learning-based method for fast and high-quality ambient occlusion generation. Our neural network is built upon kernel prediction-based architecture with careful input screen space feature selection, leading to a light-weight and compact solution. Experiment results indicate that our approach can achieve visual quality to a level in comparable with ray-traced solutions, meanwhile maintaining real-time performance. In addition, our method can be easily integrated into existing rendering pipelines and shows robustness for unseen scenes."}}
{"id": "HiuupcGa-0g", "cdate": 1663850088274, "mdate": null, "content": {"title": "Continual Learning via Adaptive Neuron Selection", "abstract": "Continual learning (CL) aims at learning a sequence of tasks without losing previously acquired knowledge. Early efforts have achieved promising results in overcoming the catastrophic forgetting problem. As a consequence, contemporary studies turn to investigate whether learning a sequence of tasks can be facilitated from the perspective of knowledge consolidation. However, existing solutions either still confront severe forgetting issues or share narrow knowledge between the new and previous tasks. This paper presents a novel Continual Learning solution with Adaptive Neuron Selection (CLANS), which treats the used neurons in earlier tasks as a knowledge pool and makes it scalable via reinforcement learning with a small margin. Subsequently, the adaptive neuron selection enables knowledge consolidation for both old and new tasks in addition to overcoming the CF problem. The experimental results conducted on four datasets widely used in CL evaluations demonstrate that CLANS outperforms the state-of-the-art baselines. "}}
{"id": "C9yUwd72yy", "cdate": 1652737327868, "mdate": null, "content": {"title": "Learning Latent Seasonal-Trend Representations for Time Series Forecasting", "abstract": "Forecasting complex time series is ubiquitous and vital in a range of applications but challenging. Recent advances endeavor to achieve progress by incorporating various deep learning techniques (e.g., RNN and Transformer) into sequential models. However, clear patterns are still hard to extract since time series are often composed of several intricately entangled components. Motivated by the success of disentangled variational autoencoder in computer vision and classical time series decomposition, we plan to infer a couple of representations that depict seasonal and trend components of time series. To achieve this goal, we propose LaST, which, based on variational inference, aims to disentangle the seasonal-trend representations in the latent space. Furthermore, LaST supervises and disassociates representations from the perspectives of themselves and input reconstruction, and introduces a series of auxiliary objectives. Extensive experiments prove that LaST achieves state-of-the-art performance on time series forecasting task against the most advanced representation learning and end-to-end forecasting models. For reproducibility, our implementation is publicly available on Github."}}
