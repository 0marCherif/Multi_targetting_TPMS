{"id": "EEZ9LFjf0h", "cdate": 1683880633425, "mdate": 1683880633425, "content": {"title": "IMPROVED DYNAMIC SPATIAL-TEMPORAL ATTENTION NETWORK FOR EARLY ANTICIPATION OF TRAFFIC ACCIDENTS", "abstract": "\nThe proliferation of dashcams has significantly increased the volume of recorded data on road traffic, offering a unique opportunity to develop sophisticated algorithms that can analyze this data and predict potential accidents. In this paper, we introduces a new approach for predicting car accidents in videos by leveraging the Dynamic Spatial-temporal Attention Network (DSTA). We incorporate a frame-level loss and a bag-level loss into our method to aid in the model\u2019s learning process. Moreover, given that car crashes often involve continuous processes, we introduce soft labels to smoothen the label transitions in each video frame, thereby helping the model to more accurately identify the accident frame number and minimizing the impact of labeling noise. Additionally, we employ the output of the temporal self-attention aggregation (TSAA) module to enhance the prediction\u2019s robustness, which extracts information from all frames of the current video and to avoid interference from individual difficult frames. Our experimental results indicate that our Improved-DSTA (IDSTA) method outperforms the original DSTA method and performs exceptionally well in the AVA dataset. Overall, our proposed approach demonstrates significant potential in predicting car accidents from dashcam videos.\n"}}
{"id": "k3w_FMfVAi", "cdate": 1683880386908, "mdate": 1683880386908, "content": {"title": "IMPROVED DYNAMIC SPATIAL-TEMPORAL ATTENTION NETWORK FOR EARLY ANTICIPATION OF TRAFFIC ACCIDENTS", "abstract": "The proliferation of dashcams has significantly increased the volume of recorded data on road traffic, offering a unique opportunity to develop sophisticated algorithms that can analyze this data and predict potential accidents. In this paper, we introduces a new approach for predicting car accidents in videos by leveraging the Dynamic Spatial-temporal Attention Network (DSTA). We incorporate a frame-level loss and a bag-level loss into our method to aid in the model\u2019s learning process. Moreover, given that car crashes often involve continuous processes, we introduce soft labels to smoothen the label transitions in each video frame, thereby helping the model to more accurately identify the accident frame number and minimizing the impact of labeling noise. Additionally, we employ the output of the temporal self-attention aggregation (TSAA) module to enhance the prediction\u2019s robustness, which extracts information from all frames of the current video and to avoid interference from individual difficult frames. Our experimental results indicate that our Improved-DSTA (IDSTA) method outperforms the original DSTA method and performs exceptionally well in the AVA dataset. Overall, our proposed approach demonstrates significant potential in predicting car accidents from dashcam videos."}}
{"id": "qq-bA-VLUN", "cdate": 1677713833080, "mdate": null, "content": {"title": "One Important Thing To Do Before Federated Training", "abstract": "Previous research in Federated learning (FL) have emphasized privacy protection, model optimization, and so on, meanwhile, they overlooked how to choose the appropriate FL algorithm for a new federation with preserving data privacy. In our study, we provide a formal problem formulation for algorithm selection in FL and present a novel approach that involves leveraging trained federations to aid with algorithm selection. Empirical results prove the effectiveness of our method."}}
{"id": "j8vBn5hvV59", "cdate": 1676882545516, "mdate": null, "content": {"title": "Capturing Delayed Feedback in Conversion Rate Prediction via Elapsed-Time Sampling", "abstract": "Conversion rate (CVR) prediction is one of the most critical tasks for digital display advertising. Commercial systems often require to update models in an online learning manner to catch up with the evolving data distribution. However, conversions usually do not happen immediately after user clicks. This may result in inaccurate labeling, which is called delayed feedback problem. In previous studies, delayed feedback problem is handled either by waiting positive label for a long period of time, or by consuming the negative sample on its arrival and then insert a positive duplicate when conversion happens later. Indeed, there is a trade-off between waiting for more accurate labels and utilizing fresh data, which is not considered in existing works. To strike a balance in this trade-off, we propose Elapsed-Time Sampling Delayed Feedback Model (ES-DFM), which models the relationship between the observed conversion distribution and the true conversion distribution. Then we optimize the expectation of true conversion distribution via importance sampling under the elapsed-time sampling distribution. We further estimate the importance weight for each instance, which is used as the weight of loss function in CVR prediction. To demonstrate the effectiveness of ES-DFM, we conduct extensive experiments on a public data and a private industrial dataset. Experimental results confirm that our method consistently outperforms the previous state-of-the-art results."}}
{"id": "HBP9oXwT127", "cdate": 1668749729996, "mdate": 1668749729996, "content": {"title": "Federated Learning with Position-Aware Neurons", "abstract": "Federated Learning (FL) fuses collaborative models from local nodes without centralizing users' data. The permutation invariance property of neural networks and the non-i.i.d. data across clients make the locally updated parameters imprecisely aligned, disabling the coordinate-based parameter averaging. Traditional neurons do not explicitly consider position information. Hence, we propose Position-Aware Neurons (PANs) as an alternative, fusing position-related values (i.e., position encodings) into neuron outputs. PANs couple themselves to their positions and minimize the possibility of dislocation, even updating on heterogeneous data. We turn on/off PANs to disable/enable the permutation invariance property of neural networks. PANs are tightly coupled with positions when applied to FL, making parameters across clients pre-aligned and facilitating coordinate-based parameter averaging. PANs are algorithm-agnostic and could universally improve existing FL algorithms. Furthermore, \"FL with PANs\" is simple to implement and computationally friendly."}}
{"id": "dhBq3GL1Ox", "cdate": 1668601645012, "mdate": 1668601645012, "content": {"title": "Identifying Ambiguous Similarity Conditions via Semantic Matching", "abstract": "Rich semantics inside an image result in its ambiguous relationship with others, i.e., two images could be similar in one condition but dissimilar in another. Given triplets like \"aircraft\" is similar to \"bird\" than \"train\", Weakly Supervised Conditional Similarity Learning (WS-CSL) learns multiple embeddings to match semantic conditions without explicit condition labels such as \"can fly\". However, similarity relationships in a triplet are uncertain except providing a condition. For example, the previous comparison becomes invalid once the conditional label changes to \"is vehicle\". To this end, we introduce a novel evaluation criterion by predicting the comparison's correctness after assigning the learned embeddings to their optimal conditions, which measures how much WS-CSL could cover latent semantics as the supervised model. Furthermore, we propose the Distance Induced Semantic COndition VERification Network (DiscoverNet), which characterizes the instance-instance and triplets-condition relations in a \"decompose-and-fuse\" manner. To make the learned embeddings cover all semantics, DiscoverNet utilizes a set module or an additional regularizer over the correspondence between a triplet and a condition. DiscoverNet achieves state-of-the-art performance on benchmarks like UT-Zappos-50k and Celeb-A w.r.t. different criteria."}}
{"id": "5vM51iamNeL", "cdate": 1663850490328, "mdate": null, "content": {"title": "Augmentation Component Analysis: Modeling Similarity via the Augmentation Overlaps", "abstract": "Self-supervised learning aims to learn a embedding space where semantically similar samples are close. Contrastive learning methods pull views of samples together and push different samples away, which utilizes semantic invariance of augmentation but ignores the relationship between samples. To better exploit the power of augmentation, we observe that semantically similar samples are more likely to have similar augmented views. Therefore, we can take the augmented views as a special description of a sample. In this paper, we model such a description as the augmentation distribution, and we call it augmentation feature. The similarity in augmentation feature reflects how much the views of two samples overlap and is related to their semantical similarity. Without computational burdens to explicitly estimate values of the augmentation feature, we propose Augmentation Component Analysis (ACA) with a contrastive-like loss to learn principal components and an on-the-fly projection loss to embed data. ACA equals an efficient dimension reduction by PCA and extracts low-dimensional embeddings, theoretically preserving the similarity of augmentation distribution between samples. Empirical results show that our method can achieve competitive results against various traditional contrastive learning methods on different benchmarks."}}
{"id": "16BDzjpOwe", "cdate": 1663850334139, "mdate": null, "content": {"title": "Learning Debiased Representations via Conditional Attribute Interpolation", "abstract": "An image is usually associated with more than one attribute, e.g., annotated based on both \"shape\" and \"color\". If most samples have attributes spuriously correlated with the target label, a Deep Neural Network (DNN) is prone to neglect those samples with attributes intrinsically consistent with the targets and leads to representations with large intra-class covariance. To improve the generalization ability of such a biased model, we propose a $\\chi^2$-model to fill in the intra-class blanks and learn debiased representations. First, we use a $\\chi$-shape pattern to match the training dynamics of a DNN and find Intermediate Attribute Samples (IASs) --- samples near decision boundaries when discerning various attributes, which indicate how attribute values change from one extreme to another. Then we rectify the decision boundary with a $\\chi$-branch metric learning objective. Conditional interpolation among IASs eliminates the negative effect of peripheral attributes and facilitates making intra-class samples compact. Experiments show that $\\chi^2$-model learns debiased representation effectively and achieves remarkable improvements on various datasets."}}
{"id": "iP77_axu0h3", "cdate": 1663850053481, "mdate": null, "content": {"title": " BEEF: Bi-Compatible Class-Incremental Learning via Energy-Based Expansion and Fusion", "abstract": "Neural networks suffer from catastrophic forgetting when sequentially learning tasks phase-by-phase, making them inapplicable in dynamically updated systems. Class-incremental learning (CIL) aims to enable neural networks to learn different categories at multi-stages. Recently, dynamic-structure-based CIL methods achieve remarkable performance. However, these methods train all modules in a coupled manner and do not consider possible conflicts among modules, resulting in spoilage of eventual predictions. In this work, we propose a unifying energy-based theory and framework called Bi-Compatible Energy-Based Expansion and Fusion (BEEF) to analyze and achieve the goal of CIL. We demonstrate the possibility of training independent modules in a decoupled manner while achieving bi-directional compatibility among modules through two additionally allocated prototypes, and then integrating them into a unifying classifier with minimal cost. Furthermore, BEEF extends the exemplar-set to a more challenging setting, where exemplars are randomly selected and imbalanced, and maintains its performance when prior methods fail dramatically.\nExtensive experiments on three widely used benchmarks: CIFAR-100, ImageNet-100, and ImageNet-1000 demonstrate that BEEF achieves state-of-the-art performance in both the ordinary and challenging  CIL settings. The Code is available at https://github.com/G-U-N/ICLR23-BEEF."}}
{"id": "S07feAlQHgM", "cdate": 1663850000929, "mdate": null, "content": {"title": "A Model or 603 Exemplars: Towards Memory-Efficient Class-Incremental Learning", "abstract": "Real-world applications require the classification model to adapt to new classes without forgetting old ones. Correspondingly, Class-Incremental Learning (CIL) aims to train a model with limited memory size to meet this requirement. Typical CIL methods tend to save representative exemplars from former classes to resist forgetting, while recent works find that storing models from history can substantially boost the performance. However, the stored models are not counted into the memory budget, which implicitly results in unfair comparisons. We find that when counting the model size into the total budget and comparing methods with aligned memory size, saving models do not consistently work, especially for the case with limited memory budgets. As a result, we need to holistically evaluate different CIL methods at different memory scales and simultaneously consider accuracy and memory size for measurement. On the other hand, we dive deeply into the construction of the memory buffer for memory efficiency. By analyzing the effect of different layers in the network, we find that shallow and deep layers have different characteristics in CIL. Motivated by this, we propose a simple yet effective baseline, denoted as MEMO for Memory-efficient Expandable MOdel. MEMO extends specialized layers based on the shared generalized representations, efficiently extracting diverse representations with modest cost and maintaining representative exemplars. Extensive experiments on benchmark datasets validate MEMO's competitive performance. Code is available at: https://github.com/wangkiw/ICLR23-MEMO"}}
