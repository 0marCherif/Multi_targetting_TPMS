{"id": "lq5txZRuf1M", "cdate": 1623601933977, "mdate": 1623601933977, "content": {"title": "Structured World Belief for Reinforcement Learning in POMDP", "abstract": "Object-centric world models provide structured representation  of  the  scene  and  can  be  an  important backbone in reinforcement learning and planning.  However, existing approaches suffer in partially-observable environments due to the lack of belief states.  In this paper, we propose Structured  World  Belief,  a  model  for  learning and inference of object-centric belief states.  Inferred  by  Sequential  Monte  Carlo  (SMC),  our belief states provide multiple object-centric scene hypotheses.  To synergize the benefits of SMC particles with object representations, we also pro-pose a new object-centric dynamics model that considers the inductive bias of object permanence.This enables tracking of object states even when they are invisible for a long time. To further facilitate object tracking in this regime, we allow our model to attend flexibly to any spatial location in the image which was restricted in previous models. In experiments, we show that object-centric belief provides a more accurate and robust performance for filtering and generation. Furthermore,we show the efficacy of structured world belief in improving the performance of reinforcement learning, planning and supervised reasoning."}}
{"id": "jgjhr2JyA3s", "cdate": 1577836800000, "mdate": null, "content": {"title": "Improving Generative Imagination in Object-Centric World Models", "abstract": "The remarkable recent advances in object-centric generative world models raise a few questions. First, while many of the recent achievements are indispensable for making a general and versatile wor..."}}
{"id": "7dpYEyt80qA", "cdate": 1577836800000, "mdate": null, "content": {"title": "Improving Generative Imagination in Object-Centric World Models", "abstract": "The remarkable recent advances in object-centric generative world models raise a few questions. First, while many of the recent achievements are indispensable for making a general and versatile world model, it is quite unclear how these ingredients can be integrated into a unified framework. Second, despite using generative objectives, abilities for object detection and tracking are mainly investigated, leaving the crucial ability of temporal imagination largely under question. Third, a few key abilities for more faithful temporal imagination such as multimodal uncertainty and situation-awareness are missing. In this paper, we introduce Generative Structured World Models (G-SWM). The G-SWM achieves the versatile world modeling not only by unifying the key properties of previous models in a principled framework but also by achieving two crucial new abilities, multimodal uncertainty and situation-awareness. Our thorough investigation on the temporal generation ability in comparison to the previous models demonstrates that G-SWM achieves the versatility with the best or comparable performance for all experiment settings including a few complex settings that have not been tested before."}}
{"id": "rkl03ySYDH", "cdate": 1569439670329, "mdate": null, "content": {"title": "SPACE: Unsupervised Object-Oriented Scene Representation via Spatial Attention and Decomposition", "abstract": "The ability to decompose complex multi-object scenes into meaningful abstractions like objects is fundamental to achieve higher-level cognition. Previous approaches for unsupervised object-oriented scene representation learning are either based on spatial-attention or scene-mixture approaches and limited in scalability which is a main obstacle towards modeling real-world scenes. In this paper, we propose a generative latent variable model, called SPACE, that provides a uni\ufb01ed probabilistic modeling framework that combines the best of spatial-attention and scene-mixture approaches. SPACE can explicitly provide factorized object representations for foreground objects while also decomposing background segments of complex morphology. Previous models are good at either of these, but not both. SPACE also resolves the scalability problems of previous methods by incorporating parallel spatial-attention and thus is applicable to scenes with a large number of objects without performance degradations. We show through experiments on Atari and 3D-Rooms that SPACE achieves the above properties consistently in comparison to SPAIR, IODINE, and GENESIS. Results of our experiments can be found on our project website: https://sites.google.com/view/space-project-page"}}
