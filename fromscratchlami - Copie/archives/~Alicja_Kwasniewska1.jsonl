{"id": "yD_Tkb9Ux4", "cdate": 1640995200000, "mdate": 1682383741510, "content": {"title": "Comparison of image pre-processing methods in liver segmentation task", "abstract": "Automatic liver segmentation of Computed Tomography (CT) images is becoming increasingly important. Although there are many publications in this field there is little explanation why certain pre-processing methods were utilised. This paper presents a comparison of the commonly used approach of Hounsfield Units (HU) windowing, histogram equalisation, and a combination of these methods to try to ascertain what are the differences between them and how big the differences are. All experiments were conducted on the LiTS dataset. To achieve comparable and reliable results only one architecture of neural network is used which is U-Net with ResNet34 blocks."}}
{"id": "rAmSsH8R-Te", "cdate": 1640995200000, "mdate": 1682383741533, "content": {"title": "Preferred Benchmarking Criteria for Systematic Taxonomy of Embedded Platforms (STEP) in Human System Interaction Systems", "abstract": "The rate of progress in the field of Artificial Intelligence (AI) and Machine Learning (ML) has significantly increased over the past ten years and continues to accelerate. Since then, AI has made the leap from research case studies to real production ready applications. The significance of this growth cannot be undermined as it catalyzed the very nature of computing. Conventional platforms struggle to achieve greater performance and efficiency, what causes a surging demand for innovative AI accelerators, specialized platforms and purpose-built computes. At the same time, it is required to provide solutions for assessment of ML platform performance in a reproducible and unbiased manner to be able to provide a fair comparison of different products. This is especially valid for Human System Interaction (HSI) systems that require specific data handling for low latency responses in emergency situations or to improve user experience, as well as for preserving data privacy and security by processing it locally. Taking it into account, this work presents a comprehensive guideline on preferred benchmarking criteria for evaluation of ML platforms that include both lower level analysis of ML models and system-level evaluation of the entire pipeline. In addition, we propose a Systematic Taxonomy of Embedded Platforms (STEP) that can be used by the community and customers for better selection of specific ML hardware consistent with their needs for better design of ML-based HSI solutions."}}
{"id": "r_8Z_iFdLoK", "cdate": 1609459200000, "mdate": 1682383741551, "content": {"title": "Improving Accuracy of Respiratory Rate Estimation by Restoring High Resolution Features With Transformers and Recursive Convolutional Models", "abstract": "Non-contact evaluation of vital signs has been becoming increasingly important, especially in light of the COVID-19 pandemic, which is causing the whole world to examine people's interactions in public places at a scale never seen before. However, evaluating one's vital signs can be a relatively complex procedure, which requires both time and physical contact between examiner and examinee. These requirements limit the number of people who can be efficiently checked, either due to the medical station throughput, patients' remote locations or the need for social distancing. This study is a first step to increasing the accuracy of computer vision-based respiratory rate estimation by transferring texture information from images acquired in different domains. Experiments conducted with two deep neural network topologies, a recursive convolutional model and transformers, proved their robustness in the analyzed scenario by reducing estimation error by 50% compared to low resolution sequences. All resources used in this research, including links to the dataset and code, have been made publicly available."}}
{"id": "NJ7px_oUNF", "cdate": 1609459200000, "mdate": 1682383741509, "content": {"title": "Fully Automated AI-powered Contactless Cough Detection based on Pixel Value Dynamics Occurring within Facial Regions", "abstract": "Increased interest in non-contact evaluation of the health state has led to higher expectations for delivering automated and reliable solutions that can be conveniently used during daily activities. Although some solutions for cough detection exist, they suffer from a series of limitations. Some of them rely on gesture or body pose recognition, which might not be possible in cases of occlusions, closer camera distances or impediments that prevent users from performing such movements at all. Others focus on analyzing breath using audio recordings, which cannot be easily applied in crowded or loud spaces. Many of them utilize visible light data which is prone to changing lighting conditions and can lead to various privacy concerns. Taking these into account, we propose to make use of the temporal pixel value changes occurring within specific facial areas. Due to the use of a combination of object detection and signal classification models, our system allows for fully automated classification of breathing anomalies. The benchmark evaluation performed on the newly created thermal cough data set proved the reliability of the introduced solution (precision of cough detection equals 94%). Due to the use of a lightweight deep learning model, the proposed system also has huge practical value, as it can potentially be deployed on edge devices frequently sought out in markets such as autonomous vehicles, drones, smart home or military applications."}}
{"id": "TxjWTx0bcgQ", "cdate": 1577836800000, "mdate": null, "content": {"title": "Super-resolved thermal imagery for high-accuracy facial areas detection and analysis", "abstract": "In this study, we evaluate various Convolutional Neural Networks based Super-Resolution (SR) models to improve facial areas detection in thermal images. In particular, we analyze the influence of selected spatiotemporal properties of thermal image sequences on detection accuracy. For this purpose, a thermal face database was acquired for 40 volunteers. Contrary to most of existing thermal databases of faces, we publish our dataset in a raw, original format (14-bit depth) to preserve all important details. In our experiments, we utilize two metrics usually used for image enhancement evaluation: Peak-Signal-to-Noise Ratio (PSNR) and Structural Similarity Index Metric (SSIM). In addition, we present how to design a SR network with a widened receptive field to mitigate the problem of contextual information being spread over larger image regions due to the heat flow in thermal images. Finally, we determine whether there is a relation between achieved PSNR and accuracy of facial areas detection that can be analyzed for vital signs extraction (e.g. nostril region). The performed evaluation showed that PSNR can be improved even by 60% if full bit depth resolution data is used instead of 8 bits. Also, we showed that the application of image enhancement solution is necessary for low resolution images to achieve a satisfactory accuracy of object detection."}}
{"id": "qO33Lbdx47R", "cdate": 1546300800000, "mdate": null, "content": {"title": "Evaluation of Facial Pulse Signals using Deep Neural Net Models", "abstract": "The reliable measurement of the pulse rate using remote photoplethysmography (PPG) is very important for many medical applications. In this paper we present how deep neural networks (DNNs) models can be used in the problem of PPG signal classification and pulse rate estimation. In particular, we show that the DNN-based classification results correspond to parameters describing the PPG signals (e.g. peak energy in the frequency domain, SNR, etc.). The results show that it is possible to identify regions of a face, for which reliable PPG signals can be extracted. The accuracy obtained for the classification task and the mean absolute error achieved for the regression task proved the usefulness of the DNN models."}}
{"id": "mvPrvwtPAwu", "cdate": 1546300800000, "mdate": null, "content": {"title": "Evaluating Accuracy of Respiratory Rate Estimation from Super Resolved Thermal Imagery", "abstract": "Non-contact estimation of Respiratory Rate (RR) has revolutionized the process of establishing the measurement by surpassing some issues related to attaching sensors to a body, e.g. epidermal stripping, skin disruption and pain. In this study, we perform further experiments with image processing-based RR estimation by using various image enhancement algorithms. Specifically, we employ Super Resolution (SR) Deep Learning (DL) network to generate hallucinated thermal image sequences that are then analyzed to extract breathing signals. DL-based SR networks have been proved to increase image quality in terms of Peak Signal-to-Noise ratio. However, it hasn't been evaluated yet whether it leads to better RR estimation accuracy, what we address in this study. Our research confirms that for estimator based on the dominated peak in the frequency spectrum Root Mean Squared Error improves by 0.15bpm for 8-bit and by 0.84bpm for 16-bit data comparing to original sequences if hallucinated frames are used. Mean Absolute Error is reduced by 0.63bpm for average aggregator and by 2.06bpm for skewness. This finding can enable various remote monitoring solutions that may suffer from poorer accuracy due to low spatial resolution of utilized thermal cameras."}}
{"id": "k22CC1RsNZ", "cdate": 1546300800000, "mdate": null, "content": {"title": "Influence of Thermal Imagery Resolution on Accuracy of Deep Learning based Face Recognition", "abstract": "Human-system interactions frequently require a retrieval of the key context information about the user and the environment. Image processing techniques have been widely applied in this area, providing details about recognized objects, people and actions. Considering remote diagnostics solutions, e.g. non-contact vital signs estimation and smart home monitoring systems that utilize person's identity, security is a very important factor. Thus, thermal imaging has become more and more popular, as it does not reveal features that are often used for person recognition, i.e. sharp edges, clear changes of pixel values between areas, etc. On the other hand, there are much more visible light data available for deep model training. Taking it into account, person recognition from thermography is much more challenging due to specific characteristics (blurring and smooth representation of features) and small amount of training data. Moreover, when low resolution data is used, features become even less visible, so this problem may become more difficult. This study focuses on verifying whether model trained to extract important facial embedding from RGB images can perform equally well if applied to thermal domain, without additional re-training. We also perform a set of experiments aim at evaluating the influence of resolution degradation by down-scaling images on the recognition accuracy. In addition, we present deep super-resolution (SR) model that by enhancing donw-scaled images can improve results for data acquired in scenarios that simulate real-life environment, i.e. mimicking facial expressions and performing head motions. Preliminary results proved that in such cases SR helps to increase accuracy by 6.5% for data 8 times smaller than original images. It has also been shown that it is possible to accurately recognize even 40 volunteers using only 4 images per person as a reference embedding. Thus, the initial profiles can be easily created in a real time, what is an additional advantage considering a solution setup in a new environment."}}
{"id": "X6X34Mhxjh0", "cdate": 1546300800000, "mdate": null, "content": {"title": "Deep Learning Optimization for Edge Devices: Analysis of Training Quantization Parameters", "abstract": "This paper focuses on convolution neural network quantization problem. The quantization has a distinct stage of data conversion from floating-point into integer-point numbers. In general, the process of quantization is associated with the reduction of the matrix dimension via limited precision of the numbers. However, the training and inference stages of deep learning neural network are limited by the space of the memory and a variety of factors including programming complexity and even reliability of the system. On the whole the process of quantization becomes more and more popular due to significant impact on performance and minimal accuracy loss. Various techniques for networks quantization have been already proposed, including quantization aware training and integer arithmetic-only inference. Yet, a detailed comparison of various quantization configurations, combining all proposed methods haven't been presented yet. This comparison is important to understand selection of quantization hyperparameters during training to optimize networks for inference while preserving their robustness. In this work, we perform in-depth analysis of parameters in the quantization aware training, the process of simulating precision loss in the forward pass by quantizing and dequantizing tensors. Specifically, we modify rounding modes, input preprocessing, output data signedness, bitwidth of the quantization and locations of precision loss simulation to evaluate how they affect accuracy of deep neural network aimed at performing efficient calculations on resource-constrained devices."}}
{"id": "rmSiFUGjL0V", "cdate": 1514764800000, "mdate": null, "content": {"title": "Long Distance Vital Signs Monitoring with Person Identification for Smart Home Solutions", "abstract": "Imaging photoplethysmography has already been proved to be successful in short distance (below 1m). However, most of the real-life use cases of measuring vital signs require the system to work at longer distances, to be both more reliable and convenient for the user. The possible scenarios that system designers must have in mind include monitoring of the vital signs of residents in nursing homes, disabled people, who can't move, constant support for people regardless of the performed activity (e.g. during sleeping), infants, etc. In this work we verified the possibility of remote pulse estimation at a distance above 5m. Additionally, we integrated the deep learning algorithm for person tracking and identification, even when facial features are not visible. In this way, we enabled the collection of user specific measurements to create personalized vital signs patterns and we provided the support for monitoring of multiple people using one video stream. The preliminary results showed that it is possible to accurately (RMSE <; 2.8 beats per minute) extract pulse from visible light sequences acquired with a webcam at a distance of 6m after applying a proper image pre-processing algorithm."}}
