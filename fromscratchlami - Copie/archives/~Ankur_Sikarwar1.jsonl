{"id": "zX1ZLGtRMVC", "cdate": 1640995200000, "mdate": 1682317709332, "content": {"title": "When Can Transformers Ground and Compose: Insights from Compositional Generalization Benchmarks", "abstract": "Humans can reason compositionally whilst grounding language utterances to the real world. Recent benchmarks like ReaSCAN use navigation tasks grounded in a grid world to assess whether neural models exhibit similar capabilities. In this work, we present a simple transformer-based model that outperforms specialized architectures on ReaSCAN and a modified version of gSCAN. On analyzing the task, we find that identifying the target location in the grid world is the main challenge for the models. Furthermore, we show that a particular split in ReaSCAN, which tests depth generalization, is unfair. On an amended version of this split, we show that transformers can generalize to deeper input structures. Finally, we design a simpler grounded compositional generalization task, RefEx, to investigate how transformers reason compositionally. We show that a single self-attention layer with a single head generalizes to novel combinations of object attributes. Moreover, we derive a precise mathematical construction of the transformer's computations from the learned network. Overall, we provide valuable insights about the grounded compositional generalization task and the behaviour of transformers on it, which would be useful for researchers working in this area."}}
{"id": "kajAXnwaLY", "cdate": 1640995200000, "mdate": 1666307331888, "content": {"title": "On the Efficacy of Co-Attention Transformer Layers in Visual Question Answering", "abstract": "In recent years, multi-modal transformers have shown significant progress in Vision-Language tasks, such as Visual Question Answering (VQA), outperforming previous architectures by a considerable margin. This improvement in VQA is often attributed to the rich interactions between vision and language streams. In this work, we investigate the efficacy of co-attention transformer layers in helping the network focus on relevant regions while answering the question. We generate visual attention maps using the question-conditioned image attention scores in these co-attention layers. We evaluate the effect of the following critical components on visual attention of a state-of-the-art VQA model: (i) number of object region proposals, (ii) question part of speech (POS) tags, (iii) question semantics, (iv) number of co-attention layers, and (v) answer accuracy. We compare the neural network attention maps against human attention maps both qualitatively and quantitatively. Our findings indicate that co-attention transformer modules are crucial in attending to relevant regions of the image given a question. Importantly, we observe that the semantic meaning of the question is not what drives visual attention, but specific keywords in the question do. Our work sheds light on the function and interpretation of co-attention transformer layers, highlights gaps in current networks, and can guide the development of future VQA models and networks that simultaneously process visual and language streams."}}
{"id": "hh5zVj2jJqj", "cdate": 1640995200000, "mdate": 1678800144998, "content": {"title": "Human or Machine? Turing Tests for Vision and Language", "abstract": ""}}
{"id": "HDbd4Z6rPlX", "cdate": 1640995200000, "mdate": 1678800144999, "content": {"title": "Reason from Context with Self-supervised Learning", "abstract": ""}}
{"id": "6zLw2fog6m", "cdate": 1640995200000, "mdate": 1678800144999, "content": {"title": "Learning to Learn: How to Continuously Teach Humans and Machines", "abstract": ""}}
{"id": "2pRp19SM8t1", "cdate": 1640995200000, "mdate": 1678646678672, "content": {"title": "When Can Transformers Ground and Compose: Insights from Compositional Generalization Benchmarks", "abstract": ""}}
