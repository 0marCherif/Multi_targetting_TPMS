{"id": "walno7E1F8w", "cdate": 1663850252433, "mdate": null, "content": {"title": "A HIERARCHICAL FRAGMENT-BASED MODEL FOR 3D DRUG-LIKE MOLECULE GENERATION", "abstract": "De novo design of hit molecules is an important task in drug discovery. With the help of deep generative models, 3D molecular point set generation for smaller molecules (QM9) has been proposed by a few researchers. However, it is a non-trivial task to generate drug-like molecules which have relatively large atom numbers in the 3D space. Inspired by the human prior from domain experts, we propose a hierarchical fragment-based model. In order to avoid fragment collisions and maintain chemical validity, we solve the problem by generating high-level features and then sampling specific fragments and edges conditioned on the former. This hierarchical framework can capture basic chemical rules while generating 3D molecules of high quality. To evaluate our model's ability to sample molecules from the drug-like chemical space, we tested our method on multiple metrics. Among all evaluated metrics, our model outperforms the baseline model by a large margin. "}}
{"id": "KUmMSZ_r28W", "cdate": 1632875617261, "mdate": null, "content": {"title": "Particle Based Stochastic Policy Optimization", "abstract": "Stochastic polic have been widely applied for their good property in exploration and uncertainty quantification.  Modeling policy distribution by joint state-action distribution within the exponential family has enabled flexibility in exploration and learning multi-modal policies and also involved the probabilistic perspective of deep reinforcement learning (RL). The connection between probabilistic inference and RL makes it possible to leverage the advancements of probabilistic optimization tools.  However, recent efforts are limited to the minimization of reverse KLdivergence which is confidence-seeking and may fade the merit of a stochastic policy.  To leverage the full potential of stochastic policy and provide more flexible property, there is a strong motivation to consider different update rules during policy optimization.  In this paper, we propose a particle-based probabilistic pol-icy optimization framework, ParPI, which enables the usage of a broad family of divergence or distances,  such asf-divergences, and the Wasserstein distance which could serve better probabilistic behavior of the learned stochastic policy. Experiments in both online and offline settings demonstrate the effectiveness of the proposed algorithm as well as the characteristics of different discrepancy measures for policy optimization."}}
{"id": "5slGDu_bVc6", "cdate": 1601308349840, "mdate": null, "content": {"title": "Learning from deep model via exploring local targets", "abstract": "Deep neural networks often have huge number of parameters, which posts challenges in deployment in application scenarios with limited memory and computation capacity. Knowledge distillation is one approach to derive compact models from bigger ones. \nHowever, it has been observed that a converged heavy teacher model is strongly constrained for learning a compact student network and could make the optimization subject to poor local optima.  In this paper, we propose proKT, a new model-agnostic method by projecting the supervision signals of a teacher model into the student's parameter space. Such projection is implemented by decomposing the training objective  into  local intermediate targets with approximate mirror descent technique. The proposed method could be less sensitive with the quirks during optimization which could result in a better local optima. Experiments on both image and text datasets show that our proposed proKT consistently achieves the state-of-the-art performance comparing to all existing knowledge distillation methods.  "}}
{"id": "rJ-66s-_ZS", "cdate": 1546300800000, "mdate": null, "content": {"title": "Lipschitz Generative Adversarial Nets", "abstract": "In this paper we show that generative adversarial networks (GANs) without restriction on the discriminative function space commonly suffer from the problem that the gradient produced by the discrim..."}}
{"id": "SXtWyGzx_pS", "cdate": 1546300800000, "mdate": null, "content": {"title": "Guiding the One-to-One Mapping in CycleGAN via Optimal Transport.", "abstract": "CycleGAN is capable of learning a one-to-one mapping between two data distributions without paired examples, achieving the task of unsupervised data translation. However, there is no theoretical guarantee on the property of the learned one-to-one mapping in CycleGAN. In this paper, we experimentally find that, under some circumstances, the one-to-one mapping learned by CycleGAN is just a random one within the large feasible solution space. Based on this observation, we explore to add extra constraints such that the one-to-one mapping is controllable and satisfies more properties related to specific tasks. We propose to solve an optimal transport mapping restrained by a task-specific cost function that reflects the desired properties, and use the barycenters of optimal transport mapping to serve as references for CycleGAN. Our experiments indicate that the proposed algorithm is capable of learning a one-to-one mapping with the desired properties."}}
{"id": "r1zOg309tX", "cdate": 1538087920167, "mdate": null, "content": {"title": "Understanding the Effectiveness of Lipschitz-Continuity in Generative Adversarial Nets", "abstract": "In this paper, we investigate the underlying factor that leads to the failure and success in training of GANs. Specifically, we study the property of the optimal discriminative function $f^*(x)$ and show that $f^*(x)$ in most GANs can only reflect the local densities at $x$, which means the value of $f^*(x)$ for points in the fake distribution ($P_g$) does not contain any information useful about the location of other points in the real distribution ($P_r$). Given that the supports of the real and fake distributions are usually disjoint, we argue that such a $f^*(x)$ and its gradient tell nothing about \"how to pull $P_g$ to $P_r$\", which turns out to be the fundamental cause of failure in training of GANs. We further demonstrate that a well-defined distance metric (including the dual form of Wasserstein distance with a compacted constraint) does not necessarily ensure the convergence of GANs. Finally, we propose Lipschitz-continuity condition as a general solution and show that in a large family of GAN objectives, Lipschitz condition is capable of connecting $P_g$ and $P_r$ through $f^*(x)$ such that the gradient $\\nabla_{\\!x}f^*(x)$ at each sample $x \\sim P_g$ points towards some real sample $y \\sim P_r$."}}
{"id": "HyyP33gAZ", "cdate": 1518730178914, "mdate": null, "content": {"title": "Activation Maximization Generative Adversarial Nets", "abstract": "Class labels have been empirically shown useful in improving the sample quality of generative adversarial nets (GANs). In this paper, we mathematically study the properties of the current variants of GANs that make use of class label information. With class aware gradient and cross-entropy decomposition, we reveal how class labels and associated losses influence GAN's training. Based on that, we propose Activation Maximization Generative Adversarial Networks (AM-GAN) as an advanced solution. Comprehensive experiments have been conducted to validate our analysis and evaluate the effectiveness of our solution, where AM-GAN outperforms other strong baselines and achieves state-of-the-art Inception Score (8.91) on CIFAR-10. In addition, we demonstrate that, with the Inception ImageNet classifier, Inception Score mainly tracks the diversity of the generator, and there is, however, no reliable evidence that it can reflect the true sample quality. We thus propose a new metric, called AM Score, to provide more accurate estimation on the sample quality. Our proposed model also outperforms the baseline methods in the new metric."}}
