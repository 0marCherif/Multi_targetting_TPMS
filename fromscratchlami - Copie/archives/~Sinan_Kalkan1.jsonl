{"id": "u0eIs1KGk5l", "cdate": 1690848000000, "mdate": 1695966188952, "content": {"title": "TMO-Det: Deep tone-mapping optimized with and for object detection", "abstract": ""}}
{"id": "sMLaQUUiUzG", "cdate": 1672531200000, "mdate": 1707050747115, "content": {"title": "Generalized Mask-aware IoU for Anchor Assignment for Real-time Instance Segmentation", "abstract": "This paper introduces Generalized Mask-aware Intersection-over-Union (GmaIoU) as a new measure for positive-negative assignment of anchor boxes during training of instance segmentation methods. Unlike conventional IoU measure or its variants, which only consider the proximity of anchor and ground-truth boxes; GmaIoU additionally takes into account the segmentation mask. This enables GmaIoU to provide more accurate supervision during training. We demonstrate the effectiveness of GmaIoU by replacing IoU with our GmaIoU in ATSS, a state-of-the-art (SOTA) assigner. Then, we train YOLACT, a real-time instance segmentation method, using our GmaIoU-based ATSS assigner. The resulting YOLACT based on the GmaIoU assigner outperforms (i) ATSS with IoU by $\\sim 1.0-1.5$ mask AP, (ii) YOLACT with a fixed IoU threshold assigner by $\\sim 1.5-2$ mask AP over different image sizes and (iii) decreases the inference time by $25 \\%$ owing to using less anchors. Taking advantage of this efficiency, we further devise GmaYOLACT, a faster and $+7$ mask AP points more accurate detector than YOLACT. Our best model achieves $38.7$ mask AP at $26$ fps on COCO test-dev establishing a new state-of-the-art for real-time instance segmentation."}}
{"id": "s-mzopMGWB", "cdate": 1672531200000, "mdate": 1675689320964, "content": {"title": "Correlation Loss: Enforcing Correlation between Classification and Localization", "abstract": "Object detectors are conventionally trained by a weighted sum of classification and localization losses. Recent studies (e.g., predicting IoU with an auxiliary head, Generalized Focal Loss, Rank & Sort Loss) have shown that forcing these two loss terms to interact with each other in non-conventional ways creates a useful inductive bias and improves performance. Inspired by these works, we focus on the correlation between classification and localization and make two main contributions: (i) We provide an analysis about the effects of correlation between classification and localization tasks in object detectors. We identify why correlation affects the performance of various NMS-based and NMS-free detectors, and we devise measures to evaluate the effect of correlation and use them to analyze common detectors. (ii) Motivated by our observations, e.g., that NMS-free detectors can also benefit from correlation, we propose Correlation Loss, a novel plug-in loss function that improves the performance of various object detectors by directly optimizing correlation coefficients: E.g., Correlation Loss on Sparse R-CNN, an NMS-free method, yields 1.6 AP gain on COCO and 1.8 AP gain on Cityscapes dataset. Our best model on Sparse R-CNN reaches 51.0 AP without test-time augmentation on COCO test-dev, reaching state-of-the-art. Code is available at https://github.com/fehmikahraman/CorrLoss"}}
{"id": "ilAtiQ6xOe", "cdate": 1672531200000, "mdate": 1703442463278, "content": {"title": "A Novel Graph Neural Network for Zone-Level Urban-Scale Building Energy Use Estimation", "abstract": "Buildings are highly responsible for total energy consumption in cities; therefore, accurate estimation of building energy consumption is essential for developing energy-efficient strategies on an urban scale. Data-driven urban building energy models can predict energy use with high precision and low computational cost. In recent years, machine learning, especially neural networks, emerged as the prominent method for predicting energy load for buildings. These models typically use different input features on building form, occupancy and operation. However, they remain inadequate in capturing the complex inter-dependencies (i.e., heat transfer) between units in multi-zone buildings, as they do not have an explicit representation of the neighborhood relations between zones. The precision of data-driven models can be improved using Graph neural networks (GNN) that can capture the underlying relationships and dependencies between different building elements. In this paper we propose a novel GNN model that surpasses the current state-of-art methods for the prediction of zone-level heating energy use. We applied the methodology in a residential neighborhood consisting of 5866 buildings and 64462 zones. We use zone-level features regarding their geometry, material thermal characteristics, internal loads as node features, inter-zone parameters as edge features (total area and U value of the adjacent surfaces) and weather parameters. The results showed that our proposed model provides improvements over alternative approaches for precise prediction of urban building energy consumption."}}
{"id": "gbengGT0fPO", "cdate": 1672531200000, "mdate": 1707050747124, "content": {"title": "Uncertainty-based Fairness Measures", "abstract": "Unfair predictions of machine learning (ML) models impede their broad acceptance in real-world settings. Tackling this arduous challenge first necessitates defining what it means for an ML model to be fair. This has been addressed by the ML community with various measures of fairness that depend on the prediction outcomes of the ML models, either at the group level or the individual level. These fairness measures are limited in that they utilize point predictions, neglecting their variances, or uncertainties, making them susceptible to noise, missingness and shifts in data. In this paper, we first show that an ML model may appear to be fair with existing point-based fairness measures but biased against a demographic group in terms of prediction uncertainties. Then, we introduce new fairness measures based on different types of uncertainties, namely, aleatoric uncertainty and epistemic uncertainty. We demonstrate on many datasets that (i) our uncertainty-based measures are complementary to existing measures of fairness, and (ii) they provide more insights about the underlying issues leading to bias."}}
{"id": "eBEylMgO3G", "cdate": 1672531200000, "mdate": 1695966188953, "content": {"title": "Correlation Loss: Enforcing Correlation between Classification and Localization", "abstract": "Object detectors are conventionally trained by a weighted sum of classification and localization losses. Recent studies (e.g., predicting IoU with an auxiliary head, Generalized Focal Loss, Rank & Sort Loss) have shown that forcing these two loss terms to interact with each other in non-conventional ways creates a useful inductive bias and improves performance. Inspired by these works, we focus on the correlation between classification and localization and make two main contributions: (i) We provide an analysis about the effects of correlation between classification and localization tasks in object detectors. We identify why correlation affects the performance of various NMS-based and NMS-free detectors, and we devise measures to evaluate the effect of correlation and use them to analyze common detectors. (ii) Motivated by our observations, e.g., that NMS-free detectors can also benefit from correlation, we propose Correlation Loss, a novel plug-in loss function that improves the performance of various object detectors by directly optimizing correlation coefficients: E.g., Correlation Loss on Sparse R-CNN, an NMS-free method, yields 1.6 AP gain on COCO and 1.8 AP gain on Cityscapes dataset. Our best model on Sparse R-CNN reaches 51.0 AP without test-time augmentation on COCO test-dev, reaching state-of-the-art. Code is available at: https://github.com/fehmikahraman/CorrLoss."}}
{"id": "dE4qsIkvwI", "cdate": 1672531200000, "mdate": 1703442463271, "content": {"title": "Class Uncertainty: A Measure to Mitigate Class Imbalance", "abstract": "Class-wise characteristics of training examples affect the performance of deep classifiers. A well-studied example is when the number of training examples of classes follows a long-tailed distribution, a situation that is likely to yield sub-optimal performance for under-represented classes. This class imbalance problem is conventionally addressed by approaches relying on the class-wise cardinality of training examples, such as data resampling. In this paper, we demonstrate that considering solely the cardinality of classes does not cover all issues causing class imbalance. To measure class imbalance, we propose \"Class Uncertainty\" as the average predictive uncertainty of the training examples, and we show that this novel measure captures the differences across classes better than cardinality. We also curate SVCI-20 as a novel dataset in which the classes have equal number of training examples but they differ in terms of their hardness; thereby causing a type of class imbalance which cannot be addressed by the approaches relying on cardinality. We incorporate our \"Class Uncertainty\" measure into a diverse set of ten class imbalance mitigation methods to demonstrate its effectiveness on long-tailed datasets as well as on our SVCI-20. Code and datasets will be made available."}}
{"id": "Opzmgvz__Oe", "cdate": 1672531200000, "mdate": 1695966188951, "content": {"title": "Towards Gender Fairness for Mental Health Prediction", "abstract": "Mental health is becoming an increasingly prominent health challenge. Despite a plethora of studies analysing and mitigating bias for a variety of tasks such as face recognition and credit scoring, research on machine learning (ML) fairness for mental health has been sparse to date. In this work, we focus on gender bias in mental health and make the following contributions. First, we examine whether bias exists in existing mental health datasets and algorithms. Our experiments were conducted using Depresjon, Psykose and D-Vlog. We identify that both data and algorithmic bias exist. Second, we analyse strategies that can be deployed at the pre-processing, in-processing and post-processing stages to mitigate for bias and evaluate their effectiveness. Third, we investigate factors that impact the efficacy of existing bias mitigation strategies and outline recommendations to achieve greater gender fairness for mental health. Upon obtaining counter-intuitive results on D-Vlog dataset, we undertake further experiments and analyses, and provide practical suggestions to avoid hampering bias mitigation efforts in ML for mental health."}}
{"id": "FX2bNuTn3J", "cdate": 1672531200000, "mdate": 1677838989982, "content": {"title": "Causal Structure Learning of Bias for Fair Affect Recognition", "abstract": ""}}
{"id": "0wIU8B33dF", "cdate": 1672531200000, "mdate": 1695966188951, "content": {"title": "Towards Causal Replay for Knowledge Rehearsal in Continual Learning", "abstract": "Given the challenges associated with the real-world deployment of Machine Learning (ML) models, especially towards efficiently integrating novel information on-the-go, both Continual Learning (CL) ..."}}
