{"id": "neXqIGpO-tn", "cdate": 1673287844751, "mdate": null, "content": {"title": "Memory-Efficient 3D Denoising Diffusion Models for Medical Image Processing", "abstract": "Denoising diffusion models have recently achieved state-of-the-art performance in many image-generation tasks. They do, however, require\na large amount of computational resources. This limits their application to medical tasks, where we often deal with large 3D volumes, like high-resolution three-dimensional data. In this work, we present a number of different ways to reduce the resource consumption for 3D diffusion models and apply them to a dataset of 3D images. The main contribution of this paper is the memory-efficient patch-based diffusion model PatchDDM, which can be applied to the total volume during inference while the training is performed only on patches. While the proposed diffusion model can be applied to any image generation task, we evaluate the method on the tumor segmentation task of the BraTS2020 dataset and demonstrate that we can generate meaningful three-dimensional segmentations."}}
{"id": "Xs_Hd23_PP", "cdate": 1673287844682, "mdate": null, "content": {"title": "Diffusion Models for Contrast Harmonization of Magnetic Resonance Images", "abstract": "Magnetic resonance (MR) images from multiple sources often show differences in image contrast related to acquisition settings or the used scanner type. For long-term studies, longitudinal comparability is essential but can be impaired by these contrast differences, leading to biased results when using automated evaluation tools. This study presents a diffusion model-based approach for contrast harmonization. We use a data set consisting of scans of 18 Multiple Sclerosis patients and 22 healthy controls. Each subject was scanned in two MR scanners of different magnetic field strengths (1.5 T and 3 T), resulting in a paired data set that shows scanner-inherent differences. We map images from the source contrast to the target contrast for both directions, from 3 T to 1.5 T and from 1.5 T to 3 T. As we only want to change the contrast, not the anatomical information, our method uses the original image to guide the image-to-image translation process by adding structural information. The aim is that the mapped scans display increased comparability with scans of the target contrast for downstream tasks. We evaluate this method for the task of segmentation of cerebrospinal fluid, grey matter and white matter. Our method achieves good and consistent results for both directions of the mapping."}}
{"id": "myJkK4u93g", "cdate": 1639123696322, "mdate": null, "content": {"title": "Position Regression for Unsupervised Anomaly Detection", "abstract": "In recent years, anomaly detection has become an essential field in medical image analysis. \nMost current anomaly detection methods for medical images are based on image reconstruction. \nIn this work, we propose a novel anomaly detection approach based on coordinate regression. \nOur method estimates the position of patches within a volume, and is trained only on data of healthy subjects. \nDuring inference, we can detect and localize anomalies by considering the error of the position estimate of a given patch. \nWe apply our method to 3D CT volumes and evaluate it on patients with intracranial haemorrhages and cranial fractures.\nThe results show that our method performs well in detecting these anomalies. \nFurthermore, we show that our method requires less memory than comparable approaches that involve image reconstruction. \nThis is highly relevant for processing large 3D volumes, for instance, CT or MRI scans.\nThe code will be publicly available."}}
{"id": "QNLR05X6uW", "cdate": 1638979680649, "mdate": null, "content": {"title": "Diffusion Models for Implicit Image Segmentation Ensembles", "abstract": "Diffusion models have shown impressive performance for generative modelling of images. In this paper, we present a novel semantic segmentation method based on diffusion models. By modifying the training and sampling scheme, we show that diffusion models can perform lesion segmentation of medical images. To generate an image-specific segmentation, we train the model on the ground truth segmentation, and use the image as a prior during training and in every step during the sampling process. With the given stochastic sampling process, we can generate a distribution of segmentation masks. This property allows us to compute pixel-wise uncertainty maps of the segmentation, and allows an implicit ensemble of segmentations that increases the segmentation performance. We evaluate our method on the BRATS2020 dataset for brain tumor segmentation. Compared to state-of-the-art segmentation models, our approach yields good segmentation results and, additionally, detailed uncertainty maps."}}
{"id": "aZxnZjbVQHp", "cdate": 1577836800000, "mdate": null, "content": {"title": "DeScarGAN: Disease-Specific Anomaly Detection with Weak Supervision", "abstract": "Anomaly detection and localization in medical images is a challenging task, especially when the anomaly exhibits a change of existing structures, e.g., brain atrophy or changes in the pleural space due to pleural effusions. In this work, we present a weakly supervised and detail-preserving method that is able to detect structural changes of existing anatomical structures. In contrast to standard anomaly detection methods, our method extracts information about the disease characteristics from two groups: a group of patients affected by the same disease and a healthy control group. Together with identity-preserving mechanisms, this enables our method to extract highly disease-specific characteristics for a more detailed detection of structural changes. We designed a specific synthetic data set to evaluate and compare our method against state-of-the-art anomaly detection methods. Finally, we show the performance of our method on chest X-ray images. Our method called DeScarGAN outperforms other anomaly detection methods on the synthetic data set and by visual inspection on the chest X-ray image data set."}}
{"id": "H1ee0VHe8S", "cdate": 1567802567532, "mdate": null, "content": {"title": "Recurrent Registration Neural Networks for Deformable Image Registration", "abstract": "Parametric spatial transformation models have been successfully applied to image registration tasks. In such models, the transformation of interest is parameterized by a fixed set of basis functions as for example B-splines. Each basis function is located on a fixed regular grid position among the image domain, because the transformation of interest is not known in advance. As a consequence, not all basis functions will necessarily contribute to the final transformation which results in a non-compact representation of the transformation. We reformulate the pairwise registration problem as a recursive sequence of successive alignments. For each element in the sequence, a local deformation defined by its position, shape, and weight is computed by our recurrent registration neural network. The sum of all lo- cal deformations yield the final spatial alignment of both images. Formulating the registration problem in this way allows the network to detect non-aligned regions in the images and to learn how to locally refine the registration properly. In contrast to current non-sequence-based registration methods, our approach iteratively applies local spatial deformations to the images until the desired registration accuracy is achieved. We trained our network on 2D magnetic resonance images of the lung and compared our method to a standard parametric B-spline registration. The experiments show, that our method performs on par for the accuracy but yields a more compact representation of the transformation. Furthermore, we achieve a speedup of around 15 compared to the B-spline registration."}}
{"id": "cQ6p-OYfL599", "cdate": 1546300800000, "mdate": null, "content": {"title": "Gated Recurrent Neural Networks for Accelerated Ventilation MRI", "abstract": "Thanks to recent advancements of specific acquisition methods and post-processing, proton Magnetic Resonance Imaging became an alternative imaging modality for detecting and monitoring chronic pulmonary disorders. Currently, ventilation maps of the lung are calculated from time-resolved image series which are acquired under free breathing. Each series consists of 140 coronal 2D images containing several breathing cycles. To cover the majority of the lung, such a series is acquired at several coronal slice-positions. A reduction of the number of images per slice enable an increase in the number of slice-positions per patient and therefore a more detailed analysis of the lung function without adding more stress to the patient. In this paper, we present a new method in order to reduce the number of images for one coronal slice while preserving the quality of the ventilation maps. As the input is a time-dependent signal, we designed our model based on Gated Recurrent Units. The results show that our method is able to compute ventilation maps with a high quality using only 40 images. Furthermore, our method shows strong robustness regarding changes in the breathing cycles during the acquisition."}}
{"id": "VRDS71-y4w35", "cdate": 1546300800000, "mdate": null, "content": {"title": "Weakly Supervised Learning Strategy for Lung Defect Segmentation", "abstract": "Through the development of specific magnetic resonance sequences, it is possible to measure the physiological properties of the lung parenchyma, e.g., ventilation. Automatic segmentation of pathologies in such ventilation maps is essential for the clinical application. The generation of labeled ground truth data is costly, time-consuming and requires much experience in the field of lung anatomy and physiology. In this paper, we present a weakly supervised learning strategy for the segmentation of defected lung areas in those ventilation maps. As a weak label, we use the Lung Clearance Index (LCI) which is measured by a Multiple Breath Washout test. The LCI is a single global measure for the ventilation inhomogeneities of the whole lung. We designed a network and a training procedure in order to infer a pixel-wise segmentation from the global LCI value. Our network is composed of two autoencoder sub-networks for the extraction of global and local features respectively. Furthermore, we use self-supervised regularization to prevent the network from learning non-meaningful segmentations. The performance of our method is evaluated by a rating of the created defect segmentations by 5 human experts, where over $$60\\%$$ of the segmentation results are rated with very good or perfect."}}
{"id": "SLln9UK8Q7X", "cdate": 1546300800000, "mdate": null, "content": {"title": "Accelerated Motion-Aware MR Imaging via Motion Prediction from K-Space Center", "abstract": "Motion has been a challenge for magnetic resonance (MR) imaging ever since the MR has been invented. Especially in volumetric imaging of thoracic and abdominal organs, motion-awareness is essential for reducing motion artifacts in the final image. A recently proposed MR imaging approach copes with motion by observing the motion patterns during the acquisition. Repetitive scanning of the k-space center region enables the extraction of the patient motion while acquiring the remaining part of the k-space. Due to highly redundant measurements of the center, the required scanning time of over 11 min and the reconstruction time of 2 h exceed clinical applicability though. We propose an accelerated motion-aware MR imaging method where the motion is inferred from small-sized k-space center patches and an initial training phase during which the characteristic movements are modeled. Thereby, acquisition times are reduced by a factor of almost 2 and reconstruction times by two orders of magnitude. Moreover, we improve the existing motion-aware approach with a systematic temporal shift correction to achieve a sharper image reconstruction. We tested our method on 12 volunteers and scanned their lungs and abdomen under free breathing. We achieved equivalent to higher reconstruction quality using the motion-prediction compared to the slower existing approach."}}
{"id": "cK4mqYr3bGt", "cdate": 1514764800000, "mdate": null, "content": {"title": "Motion Aware MR Imaging via Spatial Core Correspondence", "abstract": "Motion awareness in MR imaging is essential when it comes to long acquisition times. For volumetric high-resolution or temporal resolved images, sporadic subject movements or respiration induced organ motion has to be considered in order to reduce motion artifacts. We present a novel MR imaging sequence and an associated retrospective reconstruction method incorporating motion via spatial correspondence of the k-space center. The sequence alternatingly samples k-space patches located in the center and in peripheral higher frequency regions. Each patch is transformed into the spatial domain in order to normalize for spatial transformations rigidly as well as non-rigidly. The k-space is reconstructed from the spatially aligned patches where the alignment is derived using image registration of the center patches. Our proposed method assumes neither periodic motion nor requires any binning of motion states to properly compensate for movements during acquisition. As we directly acquire volumes, 2D slice stacking is avoided. We tested our method for brain imaging with sporadic head motion and for chest imaging where a volunteer has been scanned under free breathing. In both cases, we demonstrate high-quality 3D reconstructions."}}
