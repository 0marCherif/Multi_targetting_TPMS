{"id": "xmvFJ5DETOC", "cdate": 1698019309802, "mdate": 1698019309802, "content": {"title": "Local Temperature Beam Search: Avoid Neural Text DeGeneration via Enhanced Calibration", "abstract": "Previous studies have constantly observed that a language model repeats itself, creating repetitions in an output sequence. To cope with the issue, stochastic decoding schemes have been the de facto approaches; the strategies add randomness in inference, hence avoiding the \u201cself-loop\u201d. However, the remedy comes at the cost of sacrificing output quality due to the randomness involved. In this work, we introduce a deterministic decoding scheme, local temperature beam search. This inference algorithm is an embarrassingly simple variant of beam search, yet it reduces repetition, whose level is superior to that of a sampling-based decoding algorithm, while maintaining the level of coherence as in beam search. Our idea is rooted in the concept of model calibration; we view a repetition as a casualty from overconfidence in a model. Therefore, our work mitigates the miscalibration present in the course of inference with a post-calibration approach applied in beam-specific manner. Our inference scheme is validated on text completion tasks, in which the repetition problem is seen most clearly, and is exhaustively compared with existing inference schemes."}}
{"id": "x7PuR4_7da", "cdate": 1698019060708, "mdate": 1698019060708, "content": {"title": "CECADA: Cause-Effect Conjunctive Adverb-based Data Augmentation Method in Low-Resource Knowledge-Grounded Dialogue", "abstract": "A large body of research has investigated in drawing an interesting and engaging conversation with a user, and one of the effort is incorporating a knowledge in generation. Accordingly, a growing need for knowledge-incorporated dialogue dataset has gained attention. However, coupling a response and a knowledge in a context-specific manner is laborious and challenging, and hence the amount of data collected is often insufficient. In this light, this study proposes a simple but effective data augmentation method by leveraging the linguistic features of cause-effect conjunctive adverbs in a natural language; we reformulate a plain document with a cause-effect conjunctive adverb as a knowledge-grounded dialogue data instance. With the proposed data augmentation technique, we observe a marked gain in generalization of a model in both knowledge selection and knowledge-grounded dialogue generation. In particular, the proposed method demonstrates its effectiveness in a low-resource setting in which dialogue systems generally suffer from."}}
{"id": "awlDN5CFfU", "cdate": 1672531200000, "mdate": 1696558686206, "content": {"title": "Local Temperature Beam Search: Avoid Neural Text DeGeneration via Enhanced Calibration", "abstract": ""}}
{"id": "k2xC9JO347H", "cdate": 1640995200000, "mdate": 1696558686205, "content": {"title": "Adaptive Label Smoothing with Self-Knowledge in Natural Language Generation", "abstract": "Overconfidence has been shown to impair generalization and calibration of a neural network. Previous studies remedy this issue by adding a regularization term to a loss function, preventing a model from making a peaked distribution. Label smoothing smoothes target labels with a pre-defined prior label distribution; as a result, a model is learned to maximize the likelihood of predicting the soft label. Nonetheless, the amount of smoothing is the same in all samples and remains fixed in training. In other words, label smoothing does not reflect the change in probability distribution mapped by a model over the course of training. To address this issue, we propose a regularization scheme that brings dynamic nature into the smoothing parameter by taking model probability distribution into account, thereby varying the parameter per instance. A model in training self-regulates the extent of smoothing on the fly during forward propagation. Furthermore, inspired by recent work in bridging label smoothing and knowledge distillation, our work utilizes self-knowledge as a prior label distribution in softening target labels, and presents theoretical support for the regularization effect by knowledge distillation and the dynamic smoothing parameter. Our regularizer is validated comprehensively, and the result illustrates marked improvements in model generalization and calibration, enhancing robustness and trustworthiness of a model."}}
{"id": "VyKVrp0umeA", "cdate": 1640995200000, "mdate": 1696558686226, "content": {"title": "Hard Gate Knowledge Distillation - Leverage Calibration for Robust and Reliable Language Model", "abstract": ""}}
{"id": "TTR7xIl5MFV", "cdate": 1640995200000, "mdate": 1696489099386, "content": {"title": "Semi-Supervised Lifelong Language Learning", "abstract": "Lifelong learning aims to accumulate knowledge and alleviate catastrophic forgetting when learning tasks sequentially. However, existing lifelong language learning methods only focus on the supervised learning setting. Unlabeled data, which can be easily accessed in real-world scenarios, are underexplored. In this paper, we explore a novel setting, semi-supervised lifelong language learning (SSLL), where a model learns sequentially arriving language tasks with both labeled and unlabeled data. We propose an unlabeled data enhanced lifelong learner to explore SSLL. Specially, we dedicate task-specific modules to alleviate catastrophic forgetting and design two modules to exploit unlabeled data: (1) a virtual supervision enhanced task solver is constructed on a teacher-student framework to mine the underlying knowledge from unlabeled data; and (2) a backward augmented learner is built to encourage knowledge transfer from newly arrived unlabeled data to previous tasks. Experimental results on various language tasks demonstrate our model's effectiveness and superiority over competitive baselines under the new setting SSLL."}}
{"id": "KAEsM4cSeU", "cdate": 1640995200000, "mdate": 1696558686225, "content": {"title": "Adaptive Label Smoothing with Self-Knowledge in Natural Language Generation", "abstract": ""}}
{"id": "JFsDJoXOwXG", "cdate": 1640995200000, "mdate": 1696558686217, "content": {"title": "Hard Gate Knowledge Distillation - Leverage Calibration for Robust and Reliable Language Model", "abstract": "In knowledge distillation, a student model is trained with supervisions from both knowledge from a teacher and observations drawn from a training data distribution. Knowledge of a teacher is considered a subject that holds inter-class relations which send a meaningful supervision to a student; hence, much effort has been put to find such knowledge to be distilled. In this paper, we explore a question that has been given little attention: \"when to distill such knowledge.\" The question is answered in our work with the concept of model calibration; we view a teacher model not only as a source of knowledge but also as a gauge to detect miscalibration of a student. This simple and yet novel view leads to a hard gate knowledge distillation scheme that switches between learning from a teacher model and training data. We verify the gating mechanism in the context of natural language generation at both the token-level and the sentence-level. Empirical comparisons with strong baselines show that hard gate knowledge distillation not only improves model generalization, but also significantly lowers model calibration error."}}
{"id": "7DSOPgeeJ8n", "cdate": 1640995200000, "mdate": 1696558686205, "content": {"title": "Improving Meta-learning for Low-resource Text Classification and Generation via Memory Imitation", "abstract": "Building models of natural language processing (NLP) is challenging in low-resource scenarios where only limited data are available. Optimization-based meta-learning algorithms achieve promising results in low-resource scenarios by adapting a well-generalized model initialization to handle new tasks. Nonetheless, these approaches suffer from the memorization overfitting issue, where the model tends to memorize the meta-training tasks while ignoring support sets when adapting to new tasks. To address this issue, we propose a memory imitation meta-learning (MemIML) method that enhances the model's reliance on support sets for task adaptation. Specifically, we introduce a task-specific memory module to store support set information and construct an imitation module to force query sets to imitate the behaviors of some representative support-set samples stored in the memory. A theoretical analysis is provided to prove the effectiveness of our method, and empirical results also demonstrate that our method outperforms competitive baselines on both text classification and generation tasks."}}
{"id": "4r47KHXUTD", "cdate": 1640995200000, "mdate": 1696558686184, "content": {"title": "Improving Meta-learning for Low-resource Text Classification and Generation via Memory Imitation", "abstract": "Yingxiu Zhao, Zhiliang Tian, Huaxiu Yao, Yinhe Zheng, Dongkyu Lee, Yiping Song, Jian Sun, Nevin Zhang. Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 2022."}}
