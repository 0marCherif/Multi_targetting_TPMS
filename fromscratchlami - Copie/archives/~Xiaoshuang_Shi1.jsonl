{"id": "WF46IHAFTFD", "cdate": 1640995200000, "mdate": 1668044386501, "content": {"title": "Dual-Graph Learning Convolutional Networks for Interpretable Alzheimer's Disease Diagnosis", "abstract": "In this paper, we propose a dual-graph learning convolutional network (dGLCN) to achieve interpretable Alzheimer\u2019s disease (AD) diagnosis, by jointly investigating subject graph learning and feature graph learning in the graph convolution network (GCN) framework. Specifically, we first construct two initial graphs to consider both the subject diversity and the feature diversity. We further fuse these two initial graphs into the GCN framework so that they can be iteratively updated (i.e.,\u00a0dual-graph learning) while conducting representation learning. As a result, the dGLCN achieves interpretability in both subjects and brain regions through the subject importance and the feature importance, and the generalizability by overcoming the issues, such as limited subjects and noisy subjects. Experimental results on the Alzheimer\u2019s disease neuroimaging initiative (ADNI) datasets show that our dGLCN outperforms all comparison methods for binary classification. The codes of dGLCN are available on https://github.com/xiaotingsong/dGLCN ."}}
{"id": "F4rn8UGo4Z", "cdate": 1640995200000, "mdate": 1668044386494, "content": {"title": "Robust convolutional neural networks against adversarial attacks on medical images", "abstract": ""}}
{"id": "qk_BiVK0CL", "cdate": 1609459200000, "mdate": 1668044386522, "content": {"title": "A Scalable Optimization Mechanism for Pairwise Based Discrete Hashing", "abstract": ""}}
{"id": "YZx_dmH6j_M", "cdate": 1609459200000, "mdate": 1668044386508, "content": {"title": "Loss-Based Attention for Interpreting Image-Level Prediction of Convolutional Neural Networks", "abstract": ""}}
{"id": "EhUKjfLt_w", "cdate": 1609459200000, "mdate": 1668044386518, "content": {"title": "Self-paced Resistance Learning against Overfitting on Noisy Labels", "abstract": "Noisy labels composed of correct and corrupted ones are pervasive in practice. They might significantly deteriorate the performance of convolutional neural networks (CNNs), because CNNs are easily overfitted on corrupted labels. To address this issue, inspired by an observation, deep neural networks might first memorize the probably correct-label data and then corrupt-label samples, we propose a novel yet simple self-paced resistance framework to resist corrupted labels, without using any clean validation data. The proposed framework first utilizes the memorization effect of CNNs to learn a curriculum, which contains confident samples and provides meaningful supervision for other training samples. Then it adopts selected confident samples and a proposed resistance loss to update model parameters; the resistance loss tends to smooth model parameters' update or attain equivalent prediction over each class, thereby resisting model overfitting on corrupted labels. Finally, we unify these two modules into a single loss function and optimize it in an alternative learning. Extensive experiments demonstrate the significantly superior performance of the proposed framework over recent state-of-the-art methods on noisy-label data. Source codes of the proposed method are available on https://github.com/xsshi2015/Self-paced-Resistance-Learning."}}
