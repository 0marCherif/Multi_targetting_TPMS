{"id": "iIPzi_WcMX", "cdate": 1672531200000, "mdate": 1681717445625, "content": {"title": "Make Every Example Count: On Stability and Utility of Self-Influence for Learning from Noisy NLP Datasets", "abstract": "Increasingly larger datasets have become a standard ingredient to advancing the state of the art in NLP. However, data quality might have already become the bottleneck to unlock further gains. Given the diversity and the sizes of modern datasets, standard data filtering is not straight-forward to apply, because of the multifacetedness of the harmful data and elusiveness of filtering rules that would generalize across multiple tasks. We study the fitness of task-agnostic self-influence scores of training examples for data cleaning, analyze their efficacy in capturing naturally occurring outliers, and investigate to what extent self-influence based data cleaning can improve downstream performance in machine translation, question answering and text classification, building up on recent approaches to self-influence calculation and automated curriculum learning."}}
{"id": "vWNIB67vXc", "cdate": 1640995200000, "mdate": 1681717445211, "content": {"title": "Scaling Up Influence Functions", "abstract": "We address efficient calculation of influence functions for tracking predictions back to the training data. We propose and analyze a new approach to speeding up the inverse Hessian calculation based on Arnoldi iteration. With this improvement, we achieve, to the best of our knowledge, the first successful implementation of influence functions that scales to full-size (language and vision) Transformer models with several hundreds of millions of parameters. We evaluate our approach in image classification and sequence-to-sequence tasks with tens to a hundred of millions of training examples. Our code is available at https://github.com/google-research/jax-influence."}}
{"id": "kpFordw_YP", "cdate": 1640995200000, "mdate": 1667535273534, "content": {"title": "Quality at a Glance: An Audit of Web-Crawled Multilingual Datasets", "abstract": "With the success of large-scale pre-training and multilingual modeling in Natural Language Processing (NLP), recent years have seen a proliferation of large, Web-mined text datasets covering hundreds of languages. We manually audit the quality of 205 language-specific corpora released with five major public datasets (CCAligned, ParaCrawl, WikiMatrix, OSCAR, mC4). Lower-resource corpora have systematic issues: At least 15 corpora have no usable text, and a significant fraction contains less than 50% sentences of acceptable quality. In addition, many are mislabeled or use nonstandard/ambiguous language codes. We demonstrate that these issues are easy to detect even for non-proficient speakers, and supplement the human audit with automatic analyses. Finally, we recommend techniques to evaluate and improve multilingual corpora and discuss potential risks that come with low-quality data releases."}}
{"id": "Qa2lOGCeMLd", "cdate": 1632930162484, "mdate": 1632930162484, "content": {"title": "Don't Search for a Search Method - Simple Heuristics Suffice for Adversarial Text Attacks", "abstract": "Recently more attention has been given to adversarial attacks on neural networks for natural language processing (NLP). A central research topic  has  been  the  investigation  of  search  algorithms and search constraints, accompanied by benchmark algorithms and tasks.   We implement an algorithm inspired by zeroth order optimization-based attacks and compare with the benchmark results in the TextAttack frame-work.  Surprisingly, we find that optimization-based methods do not yield any improvement in a constrained setup and slightly benefit from approximate gradient information only in unconstrained  setups  where  search  spaces  are larger.   In  contrast,  simple  heuristics  exploiting nearest neighbors without querying the tar-get function yield substantial success rates in constrained setups, and nearly full success rate in unconstrained setups, at an order of magnitude fewer queries. We conclude from these results that current TextAttack benchmark tasks are too easy and constraints are too strict, preventing meaningful research on black-box adversarial text attacks"}}
{"id": "B7fvsSNCiz", "cdate": 1632930040027, "mdate": 1632930040027, "content": {"title": "Fixing exposure bias with imitation learning needs powerful oracles", "abstract": "We  apply  imitation  learning  (IL)  to  tackle the  NMT  exposure  bias  problem  with  error-correcting   oracles,   and   evaluate   an   SMT lattice-based  oracle  which,  despite  its  excel-lent  performance  in  an  unconstrained  oracle translation  task,  turned  out  to  be  too  pruned and idiosyncratic to serve as the oracle for IL."}}
{"id": "won8aywH3j", "cdate": 1632929956127, "mdate": 1632929956127, "content": {"title": "Controlling Machine Translation for Multiple Attributes with Additive Interventions", "abstract": "Fine-grained   control   of   machine   translation (MT) outputs along multiple attributes is critical for many modern MT applications and is  a  requirement  for  gaining  users\u2019  trust.   A standard approach for exerting control in MT is  to  prepend  the  input  with  a  special  tag  to signal the desired output attribute.  Despite its simplicity, attribute tagging has several draw-backs:  continuous values must be binned into discrete categories, which is unnatural for certain applications;  interference between multiple  tags  is  poorly  understood.    We  address these  problems  by  introducing  vector-valued interventions which allow for fine-grained control over multiple attributes simultaneously via a  weighted  linear  combination  of  the  corresponding  vectors.    For  some  attributes,  our approach even allows for fine-tuning a model trained  without  annotations  to  support  such interventions.    In  experiments  with  three  attributes (length, politeness and monotonicity) and  two  language  pairs  (English  to  German and Japanese) our models achieve better control over a wider range of tasks compared to tagging,  and  translation  quality  does  not  de-grade  when  no  control  is  requested.   Finally,we  demonstrate  how  to  enable  control  in  an already trained model after a relatively cheap fine-tuning stage"}}
{"id": "XVRLgRgMSKU", "cdate": 1632929783180, "mdate": 1632929783180, "content": {"title": "Bandits Don't Follow Rules: Balancing Multi-Facet Machine Translation with Multi-Armed Bandits", "abstract": "Training data for machine translation (MT) is often  sourced  from  a  multitude of  large  corpora that are multi-faceted in nature, e.g.  containing contents from multiple domains or different  levels  of  quality  or  complexity.   Naturally, these facets do not occur with equal frequency, nor are they equally important for the test  scenario  at  hand.   In  this  work,  we  pro-pose to optimize this balance jointly with MT model parameters to relieve system developers from manual schedule design.  A multi-armed bandit  is  trained  to  dynamically  choose  be-tween facets in a way that is most beneficial for the MT system. We evaluate it on three different multi-facet applications: balancing translationese and natural training data, or data from multiple  domains  or  multiple  language  pairs.We find that bandit learning leads to competitive MT systems across tasks, and our analysis provides insights into its learned strategies and the underlying data sets"}}
{"id": "Sd6PANMOf6k", "cdate": 1609459200000, "mdate": null, "content": {"title": "Quality at a Glance: An Audit of Web-Crawled Multilingual Datasets", "abstract": "With the success of large-scale pre-training and multilingual modeling in Natural Language Processing (NLP), recent years have seen a proliferation of large, web-mined text datasets covering hundreds of languages. We manually audit the quality of 205 language-specific corpora released with five major public datasets (CCAligned, ParaCrawl, WikiMatrix, OSCAR, mC4). Lower-resource corpora have systematic issues: At least 15 corpora have no usable text, and a significant fraction contains less than 50% sentences of acceptable quality. In addition, many are mislabeled or use nonstandard/ambiguous language codes. We demonstrate that these issues are easy to detect even for non-proficient speakers, and supplement the human audit with automatic analyses. Finally, we recommend techniques to evaluate and improve multilingual corpora and discuss potential risks that come with low-quality data releases."}}
{"id": "HbWR_U4f7c", "cdate": 1609459200000, "mdate": 1648670326168, "content": {"title": "Bandits Don't Follow Rules: Balancing Multi-Facet Machine Translation with Multi-Armed Bandits", "abstract": "Julia Kreutzer, David Vilar, Artem Sokolov. Findings of the Association for Computational Linguistics: EMNLP 2021. 2021."}}
{"id": "HN2ZCOUNGXc", "cdate": 1609459200000, "mdate": 1648670326223, "content": {"title": "Bandits Don't Follow Rules: Balancing Multi-Facet Machine Translation with Multi-Armed Bandits", "abstract": "Training data for machine translation (MT) is often sourced from a multitude of large corpora that are multi-faceted in nature, e.g. containing contents from multiple domains or different levels of quality or complexity. Naturally, these facets do not occur with equal frequency, nor are they equally important for the test scenario at hand. In this work, we propose to optimize this balance jointly with MT model parameters to relieve system developers from manual schedule design. A multi-armed bandit is trained to dynamically choose between facets in a way that is most beneficial for the MT system. We evaluate it on three different multi-facet applications: balancing translationese and natural training data, or data from multiple domains or multiple language pairs. We find that bandit learning leads to competitive MT systems across tasks, and our analysis provides insights into its learned strategies and the underlying data sets."}}
