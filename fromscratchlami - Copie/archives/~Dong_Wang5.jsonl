{"id": "uvrUmfoIgk", "cdate": 1668164933168, "mdate": 1668164933168, "content": {"title": "Deep mutual learning for visual object tracking", "abstract": "Existing deep trackers use deep convolutional neural networks to extract powerful features or directlypredict the position of the target. For most deep trackers, it is hard to improve their performance byreplacing the original backbone with a more powerfully heavyweight network directly. In this paper, wepropose a novel mutual-learning-based training methodology for visual object tracking. By re-trainingthe backbone network with this novel methodology, we can improve the tracking performance sim-ply and effectively. We demonstrate this novel training methodology with two mainstream tracking ap-proaches: correlation-filter-based approach and tracking-by-detection-based approach. First, we reformu-late a correlation-filter-based tracker as a fully convolutional network and design an end-to-end trackingframework. With this framework, we can enhance the backbone network in a mutual learning way. Sec-ond, we integrate our training methodology into a typical tracking-by-detection-based tracker, and thenwe improve the tracking performance with a simple offline training process. Extensive experiments onthe OTB2013, OTB2015, VOT2017 and LaSOT benchmarks demonstrate that the tracking performance canbe improved effectively by using the proposed mutual-learning-based training methodology."}}
{"id": "HsxgZKM7euTr", "cdate": 1546300800000, "mdate": null, "content": {"title": "Visual Tracking via Adaptive Spatially-Regularized Correlation Filters.", "abstract": "In this work, we propose a novel adaptive spatially-regularized correlation filters (ASRCF) model to simultaneously optimize the filter coefficients and the spatial regularization weight. First, this adaptive spatial regularization scheme could learn an effective spatial weight for a specific object and its appearance variations, and therefore result in more reliable filter coefficients during the tracking process. Second, our ASRCF model can be effectively optimized based on the alternating direction method of multipliers, where each subproblem has the closed-from solution. Third, our tracker applies two kinds of CF models to estimate the location and scale respectively. The location CF model exploits ensembles of shallow and deep features to determine the optimal position accurately. The scale CF model works on multi-scale shallow features to estimate the optimal scale efficiently. Extensive experiments on five recent benchmarks show that our tracker performs favorably against many state-of-the-art algorithms, with real-time performance of 28fps."}}
{"id": "HoZZGTGgupS", "cdate": 1546300800000, "mdate": null, "content": {"title": "ROI Pooled Correlation Filters for Visual Tracking.", "abstract": "The ROI (region-of-interest) based pooling method performs pooling operations on the cropped ROI regions for various samples and has shown great success in the object detection methods. It compresses the model size while preserving the localization accuracy, thus it is useful in the visual tracking field. Though being effective, the ROI-based pooling operation is not yet considered in the correlation filter formula. In this paper, we propose a novel ROI pooled correlation filter (RPCF) algorithm for robust visual tracking. Through mathematical derivations, we show that the ROI-based pooling can be equivalently achieved by enforcing additional constraints on the learned filter weights, which makes the ROI-based pooling feasible on the virtual circular samples. Besides, we develop an efficient joint training formula for the proposed correlation filter algorithm, and derive the Fourier solvers for efficient model training. Finally, we evaluate our RPCF tracker on OTB-2013, OTB-2015 and VOT-2017 benchmark datasets. Experimental results show that our tracker performs favourably against other state-of-the-art trackers."}}
{"id": "rkVNd5WuWH", "cdate": 1514764800000, "mdate": null, "content": {"title": "Structured Siamese Network for Real-Time Visual Tracking", "abstract": "Local structures of target objects are essential for robust tracking. However, existing methods based on deep neural networks mostly describe the target appearance from the global view, leading to high sensitivity to non-rigid appearance change and partial occlusion. In this paper, we circumvent this issue by proposing a local structure learning method, which simultaneously considers the local patterns of the target and their structural relationships for more accurate target tracking. To this end, a local pattern detection module is designed to automatically identify discriminative regions of the target objects. The detection results are further refined by a message passing module, which enforces the structural context among local patterns to construct local structures. We show that the message passing module can be formulated as the inference process of a conditional random field (CRF) and implemented by differentiable operations, allowing the entire model to be trained in an end-to-end manner. By considering various combinations of the local structures, our tracker is able to form various types of structure patterns. Target tracking is finally achieved by a matching procedure of the structure patterns between target template and candidates. Extensive evaluations on three benchmark data sets demonstrate that the proposed tracking algorithm performs favorably against state-of-the-art methods while running at a highly efficient speed of 45\u00a0fps."}}
{"id": "rJW9EFZO-r", "cdate": 1514764800000, "mdate": null, "content": {"title": "Real-Time 'Actor-Critic' Tracking", "abstract": "In this work, we propose a novel tracking algorithm with real-time performance based on the \u2018Actor-Critic\u2019 framework. This framework consists of two major components: \u2018Actor\u2019 and \u2018Critic\u2019. The \u2018Actor\u2019 model aims to infer the optimal choice in a continuous action space, which directly makes the tracker move the bounding box to the object\u2019s location in the current frame. For offline training, the \u2018Critic\u2019 model is introduced to form a \u2018Actor-Critic\u2019 framework with reinforcement learning and outputs a Q-value to guide the learning process of both \u2018Actor\u2019 and \u2018Critic\u2019 deep networks. Then, we modify the original deep deterministic policy gradient algorithm to effectively train our \u2018Actor-Critic\u2019 model for the tracking task. For online tracking, the \u2018Actor\u2019 model provides a dynamic search strategy to locate the tracked object efficiently and the \u2018Critic\u2019 model acts as a verification module to make our tracker more robust. To the best of our knowledge, this work is the first attempt to exploit the continuous action and \u2018Actor-Critic\u2019 framework for visual tracking. Extensive experimental results on popular benchmarks demonstrate that the proposed tracker performs favorably against many state-of-the-art methods, with real-time performance."}}
{"id": "SJNRf0Z_ZB", "cdate": 1514764800000, "mdate": null, "content": {"title": "Defocus Blur Detection via Multi-Stream Bottom-Top-Bottom Fully Convolutional Network", "abstract": "Defocus blur detection (DBD) is the separation of infocus and out-of-focus regions in an image. This process has been paid considerable attention because of its remarkable potential applications. Accurate differentiation of homogeneous regions and detection of low-contrast focal regions, as well as suppression of background clutter, are challenges associated with DBD. To address these issues, we propose a multi-stream bottom-top-bottom fully convolutional network (BTBNet), which is the first attempt to develop an end-to-end deep network for DBD. First, we develop a fully convolutional BTBNet to integrate low-level cues and high-level semantic information. Then, considering that the degree of defocus blur is sensitive to scales, we propose multi-stream BTBNets that handle input images with different scales to improve the performance of DBD. Finally, we design a fusion and recursive reconstruction network to recursively refine the preceding blur detection maps. To promote further study and evaluation of the DBD models, we construct a new database of 500 challenging images and their pixel-wise defocus blur annotations. Experimental results on the existing and our new datasets demonstrate that the proposed method achieves significantly better performance than other state-of-the-art algorithms."}}
{"id": "HkEoHp-_ZH", "cdate": 1514764800000, "mdate": null, "content": {"title": "Learning Spatial-Aware Regressions for Visual Tracking", "abstract": "In this paper, we analyze the spatial information of deep features, and propose two complementary regressions for robust visual tracking. First, we propose a kernelized ridge regression model wherein the kernel value is defined as the weighted sum of similarity scores of all pairs of patches between two samples. We show that this model can be formulated as a neural network and thus can be efficiently solved. Second, we propose a fully convolutional neural network with spatially regularized kernels, through which the filter kernel corresponding to each output channel is forced to focus on a specific region of the target. Distance transform pooling is further exploited to determine the effectiveness of each output channel of the convolution layer. The outputs from the kernelized ridge regression model and the fully convolutional neural network are combined to obtain the ultimate response. Experimental results on two benchmark datasets validate the effectiveness of the proposed method."}}
{"id": "HJ-jVtZdWH", "cdate": 1514764800000, "mdate": null, "content": {"title": "The Sixth Visual Object Tracking VOT2018 Challenge Results", "abstract": "The Visual Object Tracking challenge VOT2018 is the sixth annual tracker benchmarking activity organized by the VOT initiative. Results of over eighty trackers are presented; many are state-of-the-art trackers published at major computer vision conferences or in journals in the recent years. The evaluation included the standard VOT and other popular methodologies for short-term tracking analysis and a \u201creal-time\u201d experiment simulating a situation where a tracker processes images as if provided by a continuously running sensor. A long-term tracking subchallenge has been introduced to the set of standard VOT sub-challenges. The new subchallenge focuses on long-term tracking properties, namely coping with target disappearance and reappearance. A new dataset has been compiled and a performance evaluation methodology that focuses on long-term tracking capabilities has been adopted. The VOT toolkit has been updated to support both standard short-term and the new long-term tracking subchallenges. Performance of the tested trackers typically by far exceeds standard baselines. The source code for most of the trackers is publicly available from the VOT page. The dataset, the evaluation kit and the results are publicly available at the challenge website ( http://votchallenge.net )."}}
{"id": "ByZ1Slz_ZH", "cdate": 1514764800000, "mdate": null, "content": {"title": "Correlation Tracking via Joint Discrimination and Reliability Learning", "abstract": "For visual tracking, an ideal filter learned by the correlation filter (CF) method should take both discrimination and reliability information. However, existing attempts usually focus on the former one while pay less attention to reliability learning. This may make the learned filter be dominated by the unexpected salient regions on the feature map, thereby resulting in model degradation. To address this issue, we propose a novel CF-based optimization problem to jointly model the discrimination and reliability information. First, we treat the filter as the element-wise product of a base filter and a reliability term. The base filter is aimed to learn the discrimination information between the target and backgrounds, and the reliability term encourages the final filter to focus on more reliable regions. Second, we introduce a local response consistency regular term to emphasize equal contributions of different regions and avoid the tracker being dominated by unreliable regions. The proposed optimization problem can be solved using the alternating direction method and speeded up in the Fourier domain. We conduct extensive experiments on the OTB-2013, OTB-2015 and VOT-2016 datasets to evaluate the proposed tracker. Experimental results show that our tracker performs favorably against other state-of-the-art trackers."}}
{"id": "rkZpUA-O-S", "cdate": 1483228800000, "mdate": null, "content": {"title": "Learning to Detect Salient Objects with Image-Level Supervision", "abstract": "Deep Neural Networks (DNNs) have substantially improved the state-of-the-art in salient object detection. However, training DNNs requires costly pixel-level annotations. In this paper, we leverage the observation that image-level tags provide important cues of foreground salient objects, and develop a weakly supervised learning method for saliency detection using image-level tags only. The Foreground Inference Network (FIN) is introduced for this challenging task. In the first stage of our training method, FIN is jointly trained with a fully convolutional network (FCN) for image-level tag prediction. A global smooth pooling layer is proposed, enabling FCN to assign object category tags to corresponding object regions, while FIN is capable of capturing all potential foreground regions with the predicted saliency maps. In the second stage, FIN is fine-tuned with its predicted saliency maps as ground truth. For refinement of ground truth, an iterative Conditional Random Field is developed to enforce spatial label consistency and further boost performance. Our method alleviates annotation efforts and allows the usage of existing large scale training sets with image-level tags. Our model runs at 60 FPS, outperforms unsupervised ones with a large margin, and achieves comparable or even superior performance than fully supervised counterparts."}}
