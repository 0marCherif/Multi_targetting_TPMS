{"id": "mHC2K_6akV", "cdate": 1676827081954, "mdate": null, "content": {"title": "Fixed-Budget Best-Arm Identification with Heterogeneous Reward Variances", "abstract": "We study the problem of best-arm identification (BAI) in the fixed-budget setting with heterogeneous reward variances. We propose two variance-adaptive BAI algorithms for this setting: SHVar for known reward variances and SHAdaVar for unknown reward variances. The key idea in our algorithms is to adaptively allocate more budget to arms with higher reward variances. The main algorithmic novelty is in the design of SHAdaVar, which allocates budget greedily based on overestimating unknown reward variances. We bound the probabilities of misidentifying best arms in both SHVar and SHAdaVar. Our analyses rely on novel lower bounds on the number of arm pulls in BAI that do not require closed-form solutions to the budget allocation problem. One of our budget allocation problems is equivalent to the optimal experiment design with unknown variances and thus of a broad interest. We also evaluate our algorithms on synthetic and real-world problems. In most settings, SHVar and SHAdaVar outperform all prior algorithms."}}
{"id": "TZeArecH2Nf", "cdate": 1632875533349, "mdate": null, "content": {"title": "Bridging Recommendation and Marketing via Recurrent Intensity Modeling", "abstract": "This paper studies some under-explored connections between personalized recommendation and marketing systems. Obviously, these two systems are different, in two main ways. Firstly, personalized item-recommendation (ItemRec) is user-centric, whereas marketing recommends the best user-state segments (UserRec) on behalf of its item providers. (We treat different temporal states of the same user as separate marketing opportunities.) To overcome this difference, we realize a novel connection to Marked-Temporal Point Processes (MTPPs), where we view both problems as different projections from a unified temporal intensity model for all user-item pairs. Correspondingly, we derive Recurrent Intensity Models (RIMs) to extend from recurrent ItemRec models with minimal changes. The second difference between recommendation and marketing is in the temporal domains where they operate. While recommendation demands immediate responses in real-time, marketing campaigns are often long-term, setting goals to cover a given percentage of all opportunities for a given item in a given period of time. We formulate both considerations into a constrained optimization problem we call online match (OnlnMtch) and derive a solution we call Dual algorithm. Simply put, Dual modifies the real-time ItemRec scores such that the marketing constraints can be met with least compromises in user-centric utilities. Finally, our connections between recommendation and marketing may lead to novel applications. We run experiments where we use marketing as an alternative to cold-start item exploration, by setting a minimal-exposure constraint for every item in the audience base. Our experiments are available at \\url{https://github.com/awslabs/recurrent-intensity-model-experiments}"}}
{"id": "y7tKDxxTo8T", "cdate": 1632875532528, "mdate": null, "content": {"title": "Zero-Shot Recommender Systems", "abstract": "Performance of recommender systems (RecSys) relies heavily on the amount of training data available. This poses a chicken-and-egg problem for early-stage products, whose amount of data, in turn, relies on the performance of their RecSys. In this paper, we explore the possibility of zero-shot learning in RecSys, to enable generalization from an old dataset to an entirely new dataset. We develop an algorithm, dubbed ZEro-Shot Recommenders (ZESRec), that is trained on an old dataset and generalize to a new one where there are neither overlapping users nor overlapping items, a setting that contrasts typical cross-domain RecSys that has either overlapping users or items. Different from previous methods that use categorical item indices (i.e., item ID), ZESRec uses items' generic features, such as natural-language descriptions, product images, and videos, as their continuous indices, and therefore naturally generalizes to any unseen items. In terms of users, ZESRec builds upon recent advances on sequential RecSys to represent users using their interactions with items, thereby generalizing to unseen users as well. We study three pairs of real-world RecSys datasets and demonstrate that ZESRec can successfully enable recommendations in such a zero-shot setting, opening up new opportunities for resolving the chicken-and-egg problem for data-scarce startups or early-stage products."}}
{"id": "hFx3fY7-m9b", "cdate": 1632328762249, "mdate": null, "content": {"title": "Language Models as Recommender Systems: Evaluations and Limitations", "abstract": "Pre-trained language models (PLMs) such as BERT and GPT learn general text representations and encode extensive world knowledge; thus, they can efficiently and accurately adapt to various downstream tasks. In this work, we propose to leverage these powerful PLMs as recommender systems and use prompts to reformulate the session-based recommendation task to a multi-token cloze task. We evaluate the proposed method on a movie recommendation dataset in zero-shot and fine-tuned settings where no or limited training data are available. In the zero-shot setting: we find that PLMs outperform the random recommendation baseline by a large margin; in the meantime, we observe strong linguistic bias when using PLMs as recommenders. In the fine-tuned setting: such bias is reduced with available training data; however, PLMs tend to under-perform traditional recommender system baselines such as GRU4Rec. Our observations demonstrate potential opportunities as well as current challenges in this novel direction."}}
{"id": "WN_6sThEI_-", "cdate": 1601308041753, "mdate": null, "content": {"title": "Recurrent Exploration Networks for Recommender Systems", "abstract": "Recurrent neural networks have proven effective in modeling sequential user feedbacks for recommender systems. However, they usually focus solely on item relevance and fail to effectively explore diverse items for users, therefore harming the system performance in the long run. To address this problem, we propose a new type of recurrent neural networks, dubbed recurrent exploration networks (REN), to jointly perform representation learning and effective exploration in the latent space. REN tries to balance relevance and exploration while taking into account the uncertainty in the representations. Our theoretical analysis shows that REN can preserve the rate-optimal sublinear regret (Chu et al., 2011) even when there exists uncertainty in the learned representations. Our empirical study demonstrates that REN can achieve satisfactory long-term rewards on both synthetic and real-world recommendation datasets, outperforming state-of-the-art models. "}}
{"id": "Ll_GvBm-7f", "cdate": 1600245368747, "mdate": null, "content": {"title": "Towards optimal off-policy evaluation for reinforcement learning with marginalized importance sampling.", "abstract": "Motivated by the many real-world applications of reinforcement learning (RL) that require safe-policy iterations, we consider the problem of off-policy evaluation (OPE) \u2014 the problem of evaluating a new policy using the historical data obtained by different behavior policies \u2014 under the model of nonstationary episodic Markov Decision Processes (MDP) with a long horizon and a large action space. Existing importance sampling (IS) methods often suffer from large variance that depends exponentially on the RL horizon H. To solve this problem, we consider a marginalized importance sampling (MIS) estimator that recursively estimates the state marginal distribution for the target policy at every step. MIS achieves a mean-squared error of ... The result matches the Cramer-Rao lower bound in Jiang and Li [2016] up to a multiplicative factor of H. To the best of our knowledge, this is the first OPE estimation error bound with a polynomial dependence on H. Besides theory, we show empirical superiority of our method in time-varying, partially observable, and long-horizon RL environments."}}
{"id": "RUNOwdjiUE", "cdate": 1600245198867, "mdate": null, "content": {"title": "Imitation-Regularized Offline Learning", "abstract": "We study the problem of offline learning in automated decision systems under the contextual bandits model. We are given logged historical data consisting of contexts, (randomized) actions, and (nonnegative) rewards. A common goal is to evaluate what would happen if different actions were taken in the same contexts, so as to optimize the action policies accordingly. The typical approach to this problem, inverse probability weighted estimation (IPWE) [5], requires logged action probabilities, which may be missing in practice due to engineering complications. Even when available, small action probabilities cause large uncertainty in IPWE, rendering the corresponding results insignificant. To solve both problems, we show how one can use policy improvement (PIL) objectives, regularized by policy imitation (IML). We motivate and analyze PIL as an extension to Clipped-IPWE, by showing that both are lower-bound surrogates to the vanilla IPWE. We also formally connect IML to IPWE variance estimation [31] and natural policy gradients. Without probability logging, our PIL-IML interpretations justify and improve, by reward-weighting, the stateof-art cross-entropy (CE) loss that predicts the action items among all action candidates available in the same contexts. With probability logging, our main theoretical contribution connects IML-underfitting to the existence of either confounding variables or model misspecification. We show the value and accuracy of our insights by simulations based on Simpson\u2019s paradox, standard UCI multiclassto-bandit conversions and on the Criteo counterfactual analysis challenge dataset."}}
{"id": "8QFKbygVy4r", "cdate": 1600245104271, "mdate": null, "content": {"title": "Temporal-Contextual Recommendation in Real-Time", "abstract": "Personalized real-time recommendation has had a profound impact on retail, media, entertainment and other industries. However, developing recommender systems for every use case is costly, time consuming and resource-intensive. To fill this gap, we present a black-box recommender system that can adapt to a diverse set of scenarios without the need for manual tuning. We build on techniques that go beyond simple matrix factorization to incorporate important new sources of information: the temporal order of events [Hidasi et al., 2016], contextual information to bootstrap cold-start users, metadata information about items [Rendle 2012] and the additional information surrounding each event. Additionally, we address two fundamental challenges when putting recommender systems in the real-world: how to efficiently train them with even millions of unique items and how to cope with changing item popularity trends [Wu et al., 2017]. We introduce a compact model, which we call hierarchical recurrent network with meta data (HRNN-meta) to address the real-time and diverse metadata needs; we further provide efficient training techniques via importance sampling that can scale to millions of items with little loss in performance. We report significant improvements on a wide range of real-world datasets and provide intuition into model capabilities with synthetic experiments. Parts of HRNN-meta have been deployed in production at scale for customers to use at Amazon Web Services and serves as the underlying recommender engine for thousands of websites."}}
{"id": "ByzxsrrkJ4", "cdate": 1543619992132, "mdate": null, "content": {"title": "Hierarchical Temporal-Contextual Recommenders", "abstract": "Recommendation systems have developed beyond simple matrix factorization to focus on two important sources of information: the temporal order of events [Hidasi 2015] and side (e.g., spatial) information encoded in user and item features [Rendle 2012]. However, state-of-art temporal modeling is often limited by model capacity for long user histories. In addition, meta data are rarely used in generic sequence models, perhaps due to a lack of improvement guarantees in end-to-end training. Important kinds of meta-data, like interaction feedback (e.g. click vs. add to cart, view duration) are not modeled. In this paper we propose a hierarchical recurrent network with meta data (HRNN-meta) model to solve both problems. To compactly store long histories, and propagate gradients through them, we use HRNN to group user interactions into hierarchical sessions of activity intervals, within which a user tends to maintain related interests. Different from previous hierarchical models [Quadrana 2017], which manipulate model hidden states, HRNN encodes session information in the embedded inputs. We show that this change not only yields up to 10x better computational efficiency due to better ability to align batches, but also allows us to extend from GRUs [Cho 2014] to the entire family of RNN models, and further increases model capacities when combined with temporal convolutional networks. To use meta data in sequential models, we extend the HRNN decoder with a factorization machine inspired network, between the HRNN output embedding and item meta data, which improves over the vanilla HRNN which is a special case of the model. We also extend HRNN-meta model to handle user features and interaction feedback to learn different objectives such as click or rating predictions. We report significant improvements both in simulation studies and in real-world datasets."}}
{"id": "SkWKL6xd-S", "cdate": 1483228800000, "mdate": null, "content": {"title": "Active Search for Sparse Signals with Region Sensing", "abstract": "Autonomous systems can be used to search for sparse signals in a large space; e.g., aerial robots can be deployed to localize threats, detect gas leaks, or respond to distress calls. Intuitively, search algorithms may increase efficiency by collecting aggregate measurements summarizing large contiguous regions. However, most existing search methods either ignore the possibility of such region observations (e.g., Bayesian optimization and multi-armed bandits) or make strong assumptions about the sensing mechanism that allow each measurement to arbitrarily encode all signals in the entire environment (e.g., compressive sensing). We propose an algorithm that actively collects data to search for sparse signals using only noisy measurements of the average values on rectangular regions (including single points), based on the greedy maximization of information gain. We analyze our algorithm in 1d and show that it requires \\tilde{O}(\\frac{n}{\\mu^2}+k^2)$ measurements to recover all of k$ signal locations with small Bayes error, where \\mu$ and n$ are the signal strength and the size of the search space, respectively. We also show that active designs can be fundamentally more efficient than passive designs with region sensing, contrasting with the results of Arias-Castro, Candes, and Davenport (2013). We demonstrate the empirical performance of our algorithm on a search problem using satellite image data and in high dimensions."}}
