{"id": "jTnRVU4K-F", "cdate": 1577836800000, "mdate": 1696338342880, "content": {"title": "Korean Part-of-speech Tagging Based on Morpheme Generation", "abstract": "Two major problems of Korean part-of-speech (POS) tagging are that the word-spacing unit is not mapped one-to-one to a POS tag and that morphemes should be recovered during POS tagging. Therefore, this article proposes a novel two-step Korean POS tagger that solves the problems. This tagger first generates a sequence of lemmatized and recovered morphemes that can be mapped one-to-one to a POS tag using an encoder-decoder architecture derived from a POS-tagged corpus. Then, the POS tag of each morpheme in the generated sequence is finally determined by a standard sequence labeling method. Since the knowledge for segmenting and recovering morphemes is extracted automatically from a POS-tagged corpus by an encoder-decoder architecture, the POS tagger is constructed without a dictionary nor handcrafted linguistic rules. The experimental results on a standard dataset show that the proposed method outperforms existing POS taggers with its state-of-the-art performance."}}
{"id": "XMYkvZgYLS8V", "cdate": 1577836800000, "mdate": null, "content": {"title": "WIRE: An Automated Report Generation System using Topical and Temporal Summarization", "abstract": "The demand for a tool for summarizing emerging topics is increasing in modern life since the tool can deliver well-organized information to its users. Even though there are already a number of successful search systems, the system which automatically summarizes and organizes the content of emerging topics is still in its infancy. To fulfill such demand, we introduce an automated report generation system that generates a well-summarized human-readable report for emerging topics. In this report generation system, emerging topics are automatically discovered by a topic model and news articles are indexed by the discovered topics. Then, a topical summary and a timeline summary for each topic is generated by a topical multi-document summarizer and a timeline summarizer respectively. In order to enhance the apprehensibility of the users, the proposed report system provides two report modes. One is Today's Briefing which summarizes five discovered topics of every day, and the other is Full Report which shows a long-term view of each topic with a detailed topical summary and an important event timeline."}}
{"id": "5BEyN6JmEWs", "cdate": 1546300800000, "mdate": null, "content": {"title": "Korean Morphological Analysis with Tied Sequence-to-Sequence Multi-Task Model", "abstract": "Hyun-Je Song, Seong-Bae Park. Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP). 2019."}}
{"id": "lWIJuKXnoLD", "cdate": 1514764800000, "mdate": 1696338342885, "content": {"title": "An adapted surrogate kernel for classification under covariate shift", "abstract": ""}}
{"id": "D3iyQer4L0F", "cdate": 1514764800000, "mdate": 1696338342881, "content": {"title": "Enriching Translation-Based Knowledge Graph Embeddings Through Continual Learning", "abstract": "This paper addresses an enrichment of translation-based knowledge graph embeddings. When new knowledge triples become available after a knowledge graph is embedded onto a vector space, the embedding should be enriched with the new triples, but without the triples used in training the embedding. The main challenge is that the enrichment of new triples should be accomplished without forgetting the knowledge of current embedding. This paper achieves the goal by minimizing a risk over the new triples penalized by rapid parameter change between old and new embedding models. The effectiveness of the proposed method is shown by learning a translation-based knowledge graph embedding trained incrementally using a series of knowledge triples. The experimental results from two tasks of knowledge graph embedding prove that the proposed method not only incorporates new knowledge of new triples into the existing embedding successfully but also preserves the knowledge of the current embedding."}}
{"id": "HkVKIBbdZB", "cdate": 1483228800000, "mdate": null, "content": {"title": "Translation of Natural Language Query Into Keyword Query Using a RNN Encoder-Decoder", "abstract": "The number of natural language queries submitted to search engines is increasing as search environments get diversified. However, legacy search engines are still optimized for short keyword queries. Thus, the use of natural language queries at legacy search engines degrades the retrieval performance of the engines. This paper proposes a novel method to translate a natural language query into a keyword query relevant to the natural language query for retrieving better search results without change of the engines. The proposed method formulates the translation as a generation task. That is, the method generates a keyword query from a natural language query by preserving the semantics of the natural language query. A recurrent neural network encoder-decoder architecture is adopted as a generator of keyword queries from natural language queries. In addition, an attention mechanism is also used to cope with long natural language queries."}}
{"id": "SJNq7QWObB", "cdate": 1451606400000, "mdate": null, "content": {"title": "A Translation-Based Knowledge Graph Embedding Preserving Logical Property of Relations", "abstract": "This paper proposes a novel translation-based knowledge graph embedding that preserves the logical properties of relations such as transitivity and symmetricity. The embedding space generated by existing translation-based embeddings do not represent transitive and symmetric relations precisely, because they ignore the role of entities in triples. Thus, we introduce a role-specific projection which maps an entity to distinct vectors according to its role in a triple. That is, a head entity is projected onto an embedding space by a head projection operator, and a tail entity is projected by a tail projection operator. This idea is applied to TransE, TransR, and TransD to produce lppTransE, lppTransR, and lppTransD, respectively. According to the experimental results on link prediction and triple classification, the proposed logical property preserving embeddings show the state-of-the-art performance at both tasks. These results prove that it is critical to preserve logical properties of relations while embedding knowledge graphs, and the proposed method does it effectively."}}
{"id": "rkZkFMMubS", "cdate": 1388534400000, "mdate": null, "content": {"title": "Device-Dependent Readability for Improved Text Understanding", "abstract": "Readability is used to provide users with highquality service in text recommendation or text visualization. With the increasing use of handheld devices, reading device is regarded as an important factor for readability. Therefore, this paper investigates the relationship between readability and reading devices such as a smart phone, a tablet, and paper. We suggest readability factors that are strongly related with the readability of a specific device by showing the correlations between various factors in each device and human-rated readability. Our experimental results show that each device has its own readability characteristics, and thus different weights should be imposed on readability factors according to the device type. In order to prove the usefulness of the results, we apply the device-dependent readability to news article recommendation."}}
{"id": "HybJw7Wd-B", "cdate": 1356998400000, "mdate": null, "content": {"title": "A Just-In-Time Keyword Extraction from Meeting Transcripts", "abstract": "In a meeting, it is often desirable to extract keywords from each utterance as soon as it is spoken. Thus, this paper proposes a just-in- time keyword extraction from meeting tran- scripts. The proposed method considers two major factors that make it different from key- word extraction from normal texts. The first factor is the temporal history of preceding ut- terances that grants higher importance to re- cent utterances than old ones, and the sec- ond is topic relevance that forces only the pre- ceding utterances relevant to the current utter- ance to be considered in keyword extraction. Our experiments on two data sets in English and Korean show that the consideration of the factors results in performance improvement in keyword extraction from meeting transcripts."}}
{"id": "BkWICnx_bH", "cdate": 1325376000000, "mdate": null, "content": {"title": "A Cost Sensitive Part-of-Speech Tagging: Differentiating Serious Errors from Minor Errors", "abstract": "All types of part-of-speech (POS) tagging errors have been equally treated by existing taggers. However, the errors are not equally important, since some errors affect the performance of subsequent natural language processing seriously while others do not. This paper aims to minimize these serious errors while retaining the overall performance of POS tagging. Two gradient loss functions are proposed to reflect the different types of errors. They are designed to assign a larger cost for serious errors and a smaller cost for minor errors. Through a series of experiments, it is shown that the classifier trained with the proposed loss functions not only reduces serious errors but also achieves slightly higher accuracy than ordinary classifiers."}}
