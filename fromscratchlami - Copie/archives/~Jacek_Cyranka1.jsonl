{"id": "qmluHHTvW7m", "cdate": 1672531200000, "mdate": 1707896861488, "content": {"title": "Unified Long-Term Time-Series Forecasting Benchmark", "abstract": "In order to support the advancement of machine learning methods for predicting time-series data, we present a comprehensive dataset designed explicitly for long-term time-series forecasting. We incorporate a collection of datasets obtained from diverse, dynamic systems and real-life records. Each dataset is standardized by dividing it into training and test trajectories with predetermined lookback lengths. We include trajectories of length up to $2000$ to ensure a reliable evaluation of long-term forecasting capabilities. To determine the most effective model in diverse scenarios, we conduct an extensive benchmarking analysis using classical and state-of-the-art models, namely LSTM, DeepAR, NLinear, N-Hits, PatchTST, and LatentODE. Our findings reveal intriguing performance comparisons among these models, highlighting the dataset-dependent nature of model effectiveness. Notably, we introduce a custom latent NLinear model and enhance DeepAR with a curriculum learning phase. Both consistently outperform their vanilla counterparts."}}
{"id": "mCcvuZTaFBZ", "cdate": 1672531200000, "mdate": 1686634168013, "content": {"title": "Improved Overparametrization Bounds for Global Convergence of SGD for Shallow Neural Networks", "abstract": "We study the overparametrization bounds required for the global convergence of stochastic gradient descent algorithm for a class of one hidden layer feed-forward neural networks equipped with ReLU activation function. We improve the existing state-of-the-art results in terms of the required hidden layer width. We introduce a new proof technique combining nonlinear analysis with properties of random initializations of the network."}}
{"id": "fsQpJbgLX12", "cdate": 1672531200000, "mdate": 1707896861487, "content": {"title": "A Polarization Opinion Model Inspired by Bounded Confidence Communications", "abstract": "We present an opinion model founded upon the principles of the bounded confidence interaction among agents. Our objective is to explain the polarization effects inherent to vector-valued opinions. The evolutionary process adheres to the rule where each agent aspires to increase polarization through communication with a single friend during each discrete time step. The dynamics ensure that agents' ultimate (temporal) configuration will encompass a finite number of outlier states. We introduce deterministic and stochastic models, accompanied by a comprehensive mathematical analysis of their inherent properties. Additionally, we provide compelling illustrative examples and introduce a stochastic solver tailored for scenarios featuring an extensive set of agents. Furthermore, in the context of smaller agent populations, we scrutinize the suitability of neural networks for the rapid inference of limit configurations."}}
{"id": "SNAFj3m8IiL", "cdate": 1672531200000, "mdate": 1695990676017, "content": {"title": "Worrisome Properties of Neural Network Controllers and Their Symbolic Representations", "abstract": "We raise concerns about controllers' robustness in simple reinforcement learning benchmark problems. We focus on neural network controllers and their low neuron and symbolic abstractions. A typical controller reaching high mean return values still generates an abundance of persistent low-return solutions, which is a highly undesirable property, easily exploitable by an adversary. We find that the simpler controllers admit more persistent bad solutions. We provide an algorithm for a systematic robustness study and prove existence of persistent solutions and, in some cases, periodic orbits, using a computer-assisted proof methodology."}}
{"id": "7Z9CJ09_i", "cdate": 1640995200000, "mdate": 1686634168037, "content": {"title": "Validated forward integration scheme for parabolic PDEs via Chebyshev series", "abstract": ""}}
{"id": "rvost-n5X4G", "cdate": 1632875453290, "mdate": null, "content": {"title": "SPP-RL: State Planning Policy Reinforcement Learning", "abstract": "We introduce an algorithm for reinforcement learning, in which the actor plans for the next state provided the current state. To communicate the actor output to the environment we incorporate an inverse dynamics control model and train it using supervised learning. \nWe train the RL agent using off-policy state-of-the-art reinforcement learning algorithms: DDPG, TD3, and SAC. To guarantee that the target states are physically relevant, the overall learning procedure is formulated as a constrained optimization problem, solved via the classical Lagrangian optimization method. We benchmark the state planning RL approach using a varied set of continuous environments, including standard MuJoCo tasks,  safety-gym level 0 environments, and AntPush. In SPP approach the optimal policy is being searched for in the space of state-state mappings, a considerably larger space than the traditional space of state-action mappings. We report that quite surprisingly SPP implementations attain superior performance to vanilla state-of-the-art off-policy RL algorithms in the tested environments."}}
{"id": "334EyC79V", "cdate": 1609459200000, "mdate": 1686634168052, "content": {"title": "On the Verification of Neural ODEs with Stochastic Guarantees", "abstract": "We show that Neural ODEs, an emerging class of time-continuous neural networks, can be verified by solving a set of global-optimization problems. For this purpose, we introduce Stochastic Lagrangian Reachability (SLR), an abstraction-based technique for constructing a tight Reachtube (an over-approximation of the set of reachable states over a given time-horizon), and provide stochastic guarantees in the form of confidence intervals for the Reachtube bounds. SLR inherently avoids the infamous wrapping effect (accumulation of over-approximation errors) by performing local optimization steps to expand safe regions instead of repeatedly forward-propagating them as is done by deterministic reachability methods. To enable fast local optimizations, we introduce a novel forward-mode adjoint sensitivity method to compute gradients without the need for backpropagation. Finally, we establish asymptotic and non-asymptotic convergence rates for SLR."}}
{"id": "oilIpMB3o3E", "cdate": 1577836800000, "mdate": 1626448086837, "content": {"title": "Contractibility of a persistence map preimage", "abstract": "This work is motivated by the following question in data-driven study of dynamical systems: given a dynamical system that is observed via time series of persistence diagrams that encode topological features of snapshots of solutions, what conclusions can be drawn about solutions of the original dynamical system? We address this challenge in the context of an N dimensional system of ordinary differential equation defined in $${\\mathbb {R}}^N$$ R N . To each point in $${\\mathbb {R}}^N$$ R N (e.g. an initial condition) we associate a persistence diagram. The main result of this paper is that under this association the preimage of every persistence diagram is contractible. As an application we provide conditions under which multiple time series of persistence diagrams can be used to conclude the existence of a fixed point of the differential equation that generates the time series."}}
{"id": "gkiip5xzpF", "cdate": 1577836800000, "mdate": null, "content": {"title": "Lagrangian Reachtubes: The Next Generation", "abstract": "We introduce LRT-NG, a set of techniques and an associated toolset that computes a reachtube (an over-approximation of the set of reachable states over a given time horizon) of a nonlinear dynamical system. LRT-NG significantly advances the state-of-the-art Langrangian Reachability and its associated tool LRT. From a theoretical perspective, LRT-NG is superior to LRT in three ways. First, it uses for the first time an analytically computed metric for the propagated ball which is proven to minimize the ball's volume. We emphasize that the metric computation is the centerpiece of all bloating-based techniques. Secondly, it computes the next reachset as the intersection of two balls: one based on the Cartesian metric and the other on the new metric. While the two metrics were previously considered opposing approaches, their joint use considerably tightens the reachtubes. Thirdly, it avoids the \"wrapping effect\" associated with the validated integration of the center of the reachset, by optimally absorbing the interval approximation in the radius of the next ball. From a tool-development perspective, LRT-NG is superior to LRT in two ways. First, it is a standalone tool that no longer relies on CAPD. This required the implementation of the Lohner method and a Runge-Kutta time-propagation method. Secondly, it has an improved interface, allowing the input model and initial conditions to be provided as external input files. Our experiments on a comprehensive set of benchmarks, including two Neural ODEs, demonstrates LRT-NG's superior performance compared to LRT, CAPD, and Flow*."}}
{"id": "bEcXb2dQHir", "cdate": 1577836800000, "mdate": null, "content": {"title": "On The Verification of Neural ODEs with Stochastic Guarantees", "abstract": "We show that Neural ODEs, an emerging class of time-continuous neural networks, can be verified by solving a set of global-optimization problems. For this purpose, we introduce Stochastic Lagrangian Reachability (SLR), an abstraction-based technique for constructing a tight Reachtube (an over-approximation of the set of reachable states over a given time-horizon), and provide stochastic guarantees in the form of confidence intervals for the Reachtube bounds. SLR inherently avoids the infamous wrapping effect (accumulation of over-approximation errors) by performing local optimization steps to expand safe regions instead of repeatedly forward-propagating them as is done by deterministic reachability methods. To enable fast local optimizations, we introduce a novel forward-mode adjoint sensitivity method to compute gradients without the need for backpropagation. Finally, we establish asymptotic and non-asymptotic convergence rates for SLR."}}
