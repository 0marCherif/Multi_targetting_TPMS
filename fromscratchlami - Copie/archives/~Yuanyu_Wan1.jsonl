{"id": "l_VwezlddSJ", "cdate": 1672531200000, "mdate": 1695648380862, "content": {"title": "Non-stationary Projection-free Online Learning with Dynamic and Adaptive Regret Guarantees", "abstract": "Projection-free online learning has drawn increasing interest due to its efficiency in solving high-dimensional problems with complicated constraints. However, most existing projection-free online methods focus on minimizing the static regret, which unfortunately fails to capture the challenge of changing environments. In this paper, we investigate non-stationary projection-free online learning, and choose dynamic regret and adaptive regret to measure the performance. Specifically, we first provide a novel dynamic regret analysis for an existing projection-free method named $\\text{BOGD}_\\text{IP}$, and establish an $\\mathcal{O}(T^{3/4}(1+P_T))$ dynamic regret bound, where $P_T$ denotes the path-length of the comparator sequence. Then, we improve the upper bound to $\\mathcal{O}(T^{3/4}(1+P_T)^{1/4})$ by running multiple $\\text{BOGD}_\\text{IP}$ algorithms with different step sizes in parallel, and tracking the best one on the fly. Our results are the first general-case dynamic regret bounds for projection-free online learning, and can recover the existing $\\mathcal{O}(T^{3/4})$ static regret by setting $P_T = 0$. Furthermore, we propose a projection-free method to attain an $\\tilde{\\mathcal{O}}(\\tau^{3/4})$ adaptive regret bound for any interval with length $\\tau$, which nearly matches the static regret over that interval. The essential idea is to maintain a set of $\\text{BOGD}_\\text{IP}$ algorithms dynamically, and combine them by a meta algorithm. Moreover, we demonstrate that it is also equipped with an $\\mathcal{O}(T^{3/4}(1+P_T)^{1/4})$ dynamic regret bound. Finally, empirical studies verify our theoretical findings."}}
{"id": "_rQLwKgFqmB", "cdate": 1672531200000, "mdate": 1695648380854, "content": {"title": "Non-stationary Online Convex Optimization with Arbitrary Delays", "abstract": "Online convex optimization (OCO) with arbitrary delays, in which gradients or other information of functions could be arbitrarily delayed, has received increasing attention recently. Different from previous studies that focus on stationary environments, this paper investigates the delayed OCO in non-stationary environments, and aims to minimize the dynamic regret with respect to any sequence of comparators. To this end, we first propose a simple algorithm, namely DOGD, which performs a gradient descent step for each delayed gradient according to their arrival order. Despite its simplicity, our novel analysis shows that DOGD can attain an $O(\\sqrt{dT}(P_T+1)$ dynamic regret bound in the worst case, where $d$ is the maximum delay, $T$ is the time horizon, and $P_T$ is the path length of comparators. More importantly, in case delays do not change the arrival order of gradients, it can automatically reduce the dynamic regret to $O(\\sqrt{S}(1+P_T))$, where $S$ is the sum of delays. Furthermore, we develop an improved algorithm, which can reduce those dynamic regret bounds achieved by DOGD to $O(\\sqrt{dT(P_T+1)})$ and $O(\\sqrt{S(1+P_T)})$, respectively. The essential idea is to run multiple DOGD with different learning rates, and utilize a meta-algorithm to track the best one based on their delayed performance. Finally, we demonstrate that our improved algorithm is optimal in both cases by deriving a matching lower bound."}}
{"id": "Wel27JCjTz", "cdate": 1672531200000, "mdate": 1695648380081, "content": {"title": "Improved Dynamic Regret for Online Frank-Wolfe", "abstract": "To deal with non-stationary online problems with complex constraints, we investigate the dynamic regret of online Frank-Wolfe (OFW), which is an efficient projection-free algorithm for online conve..."}}
{"id": "SHcfvVyvE4", "cdate": 1672531200000, "mdate": 1681727798039, "content": {"title": "Improved Dynamic Regret for Online Frank-Wolfe", "abstract": "To deal with non-stationary online problems with complex constraints, we investigate the dynamic regret of online Frank-Wolfe (OFW), which is an efficient projection-free algorithm for online convex optimization. It is well-known that in the setting of offline optimization, the smoothness of functions and the strong convexity of functions accompanying specific properties of constraint sets can be utilized to achieve fast convergence rates for the Frank-Wolfe (FW) algorithm. However, for OFW, previous studies only establish a dynamic regret bound of $O(\\sqrt{T}(1+V_T+\\sqrt{D_T}))$ by utilizing the convexity of problems, where $T$ is the number of rounds, $V_T$ is the function variation, and $D_T$ is the gradient variation. In this paper, we derive improved dynamic regret bounds for OFW by extending the fast convergence rates of FW from offline optimization to online optimization. The key technique for this extension is to set the step size of OFW with a line search rule. In this way, we first show that the dynamic regret bound of OFW can be improved to $O(\\sqrt{T(1+V_T)})$ for smooth functions. Second, we achieve a better dynamic regret bound of $O((1+V_T)^{2/3}T^{1/3})$ when functions are smooth and strongly convex, and the constraint set is strongly convex. Finally, for smooth and strongly convex functions with minimizers in the interior of the constraint set, we demonstrate that the dynamic regret of OFW reduces to $O(1+V_T)$, and can be further strengthened to $O(\\min\\{P_T^\\ast,S_T^\\ast,V_T\\}+1)$ by performing a constant number of FW iterations per round, where $P_T^\\ast$ and $S_T^\\ast$ denote the path length and squared path length of minimizers, respectively."}}
{"id": "H7cyY2tHEPN", "cdate": 1672531200000, "mdate": 1693727460325, "content": {"title": "Distributed Projection-Free Online Learning for Smooth and Convex Losses", "abstract": "We investigate the problem of distributed online convex optimization with complicated constraints, in which the projection operation could be the computational bottleneck. To avoid projections, distributed online projection-free methods have been proposed and attain an O(T^{3/4}) regret bound for general convex losses. However, they cannot utilize the smoothness condition, which has been exploited in the centralized setting to improve the regret. In this paper, we propose a new distributed online projection-free method with a tighter regret bound of O(T^{2/3}) for smooth and convex losses. Specifically, we first provide a distributed extension of Follow-the-Perturbed-Leader so that the smoothness can be utilized in the distributed setting. Then, we reduce the computational cost via sampling and blocking techniques. In this way, our method only needs to solve one linear optimization per round on average. Finally, we conduct experiments on benchmark datasets to verify the effectiveness of our proposed method."}}
{"id": "3FgnyWZvG0", "cdate": 1672531200000, "mdate": 1695952536872, "content": {"title": "Improved Projection-free Online Continuous Submodular Maximization", "abstract": "We investigate the problem of online learning with monotone and continuous DR-submodular reward functions, which has received great attention recently. To efficiently handle this problem, especially in the case with complicated decision sets, previous studies have proposed an efficient projection-free algorithm called Mono-Frank-Wolfe (Mono-FW) using $O(T)$ gradient evaluations and linear optimization steps in total. However, it only attains a $(1-1/e)$-regret bound of $O(T^{4/5})$. In this paper, we propose an improved projection-free algorithm, namely POBGA, which reduces the regret bound to $O(T^{3/4})$ while keeping the same computational complexity as Mono-FW. Instead of modifying Mono-FW, our key idea is to make a novel combination of a projection-based algorithm called online boosting gradient ascent, an infeasible projection technique, and a blocking technique. Furthermore, we consider the decentralized setting and develop a variant of POBGA, which not only reduces the current best regret bound of efficient projection-free algorithms for this setting from $O(T^{4/5})$ to $O(T^{3/4})$, but also reduces the total communication complexity from $O(T)$ to $O(\\sqrt{T})$."}}
{"id": "swIARHfCaUB", "cdate": 1652737503650, "mdate": null, "content": {"title": "Online Frank-Wolfe with Arbitrary Delays", "abstract": "The online Frank-Wolfe (OFW) method has gained much popularity for online convex optimization due to its projection-free property. Previous studies show that OFW can attain an $O(T^{3/4})$ regret bound for convex losses and an $O(T^{2/3})$ regret bound for strongly convex losses. However, they assume that each gradient queried by OFW is revealed immediately, which may not hold in practice and limits the application of OFW. To address this limitation, we propose a delayed variant of OFW, which allows gradients to be delayed by arbitrary rounds. The main idea is to perform an update similar to OFW after receiving any delayed gradient, and play the latest decision for each round. Despite its simplicity, we prove that our delayed variant of OFW is able to achieve an $O(T^{3/4}+dT^{1/4})$ regret bound for convex losses and an $O(T^{2/3}+d\\log T)$ regret bound for strongly convex losses, where $d$ is the maximum delay. This is quite surprising since under a relatively large amount of delay (e.g., $d=O(\\sqrt{T})$ for convex losses and $d=O(T^{2/3}/\\log T)$ for strongly convex losses), the delayed variant of OFW enjoys the same regret bound as that of the original OFW."}}
{"id": "wtqI7Tmshlc", "cdate": 1640995200000, "mdate": 1681727798039, "content": {"title": "Online strongly convex optimization with unknown delays", "abstract": "We investigate the problem of online convex optimization with unknown delays, in which the feedback of a decision arrives with an arbitrary delay. Previous studies have presented delayed online gradient descent (DOGD), and achieved the regret bound of $$O(\\sqrt{D})$$ O ( D ) by only utilizing the convexity condition, where $$D\\ge T$$ D \u2265 T is the sum of delays over T rounds. In this paper, we further exploit the strong convexity to improve the regret bound. Specifically, we first propose a variant of DOGD for strongly convex functions, and establish a better regret bound of $$O(d\\log T)$$ O ( d log T ) , where d is the maximum delay. The essential idea is to let the learning rate decay with the total number of received feedback linearly. Furthermore, we extend the strongly convex variant of DOGD and its theoretical guarantee to the more challenging bandit setting by combining with the classical $$(n+1)$$ ( n + 1 ) -point and two-point gradient estimators, where n is the dimensionality. To the best of our knowledge, this is the first work that solves online strongly convex optimization under the general delayed setting."}}
{"id": "mojzNa0rgb", "cdate": 1640995200000, "mdate": 1695648380868, "content": {"title": "Projection-free Distributed Online Learning with Sublinear Communication Complexity", "abstract": "To deal with complicated constraints via locally light computations in distributed online learning, a recent study has presented a projection-free algorithm called distributed online conditional gradient (D-OCG), and achieved an $O(T^{3/4})$ regret bound for convex losses, where $T$ is the number of total rounds. However, it requires $T$ communication rounds, and cannot utilize the strong convexity of losses. In this paper, we propose an improved variant of D-OCG, namely D-BOCG, which can attain the same $O(T^{3/4})$ regret bound with only $O(\\sqrt{T})$ communication rounds for convex losses, and a better regret bound of $O(T^{2/3}(\\log T)^{1/3})$ with fewer $O(T^{1/3}(\\log T)^{2/3})$ communication rounds for strongly convex losses. The key idea is to adopt a delayed update mechanism that reduces the communication complexity, and redefine the surrogate loss function in D-OCG for exploiting the strong convexity. Furthermore, we provide lower bounds to demonstrate that the $O(\\sqrt{T})$ communication rounds required by D-BOCG are optimal (in terms of $T$) for achieving the $O(T^{3/4})$ regret with convex losses, and the $O(T^{1/3}(\\log T)^{2/3})$ communication rounds required by D-BOCG are near-optimal (in terms of $T$) for achieving the $O(T^{2/3}(\\log T)^{1/3})$ regret with strongly convex losses up to polylogarithmic factors. Finally, to handle the more challenging bandit setting, in which only the loss value is available, we incorporate the classical one-point gradient estimator into D-BOCG, and obtain similar theoretical guarantees."}}
{"id": "Iitiv9UDDn5", "cdate": 1640995200000, "mdate": 1681727798047, "content": {"title": "Strongly adaptive online learning over partial intervals", "abstract": "To cope with changing environments, strongly adaptive algorithms that almost enjoy the optimal performance on every time interval have been proposed for online learning. However, the best regret bound of existing algorithms on each time interval with length \u03c4 is $$O\\left( {\\sqrt {\\tau \\log \\,T} } \\right)$$ O ( \u03c4 log T ) , and their complexities are increasing with a factor of O(log T), where T is the time horizon. In real-world applications, T could go to infinity, which means that even these logarithmic factors are unacceptable. In this paper, we propose to remove the logarithmic factors of existing algorithms by utilizing prior information of environments. Specifically, we assume a lower bound \u03c41 and an upper bound \u03c42 on how long the environment changes are given, and only focus on the performance over time intervals with length in [\u03c41, \u03c42]. Then, we propose a new algorithm with a refined set of intervals that can reduce the complexity and a simple weighting method that can cooperate with our interval set. Theoretical analysis reveals that the regret bound of our algorithm on any focused interval is optimal up to a constant factor. Both the regret bound and the computational cost per iteration are independent of T. Experimental results show that our algorithm outperforms the state-of-the-art algorithm."}}
