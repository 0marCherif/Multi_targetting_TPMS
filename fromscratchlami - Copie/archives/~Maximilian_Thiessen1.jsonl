{"id": "BNhhZwAlVNC", "cdate": 1664194167102, "mdate": null, "content": {"title": "Generalized Laplacian Positional Encoding for Graph Representation Learning", "abstract": "Graph neural networks (GNNs) are the primary tool for processing graph-structured data. Unfortunately, the most commonly used GNNs, called Message Passing Neural Networks (MPNNs) suffer from several fundamental limitations. To overcome these limitations, recent works have adapted the idea of positional encodings to graph data. This paper draws inspiration from the recent success of Laplacian-based positional encoding and defines a novel family of positional encoding schemes for graphs. We accomplish this by generalizing the optimization problem that defines the Laplace embedding to more general dissimilarity functions rather than the 2-norm used in the original formulation. This family of positional encodings is then instantiated by considering p-norms. We discuss a method for calculating these  positional encoding schemes, implement it in PyTorch and demonstrate how the resulting positional encoding captures different properties of the graph. Furthermore, we demonstrate that this novel family of positional encodings can improve the expressive power of MPNNs. Lastly, we present preliminary experimental results. "}}
{"id": "Zf-Mn6xzD2B", "cdate": 1664046166825, "mdate": null, "content": {"title": "Expectation Complete Graph Representations using Graph Homomorphisms", "abstract": "We propose and study a practical graph embedding that *in expectation* is able to distinguish all non-isomorphic graphs and can be computed in polynomial time. The embedding is based on Lov\u00e1sz' characterization of graph isomorphism through an infinite dimensional vector of homomorphism counts. Recent work has studied the expressiveness of graph embeddings by comparing their ability to distinguish graphs to that of the Weisfeiler-Leman hierarchy. While previous methods have either limited expressiveness or are computationally impractical, we devise efficient sampling-based alternatives that are maximally expressive in expectation. We empirically evaluate our proposed embeddings and show competitive results on several benchmark graph learning tasks."}}
{"id": "8GJyW4i2oST", "cdate": 1662812635484, "mdate": null, "content": {"title": "Expectation Complete Graph Representations using Graph Homomorphisms", "abstract": "We propose and study a practical graph embedding that *in expectation* is able to distinguish all non-isomorphic graphs and can be computed in polynomial time. The embedding is based on Lov\u00e1sz' characterisation of graph isomorphism through an infinite dimensional vector of homomorphism counts. Recent work has studied the expressiveness of graph embeddings by comparing their ability to distinguish graphs to that of the Weisfeiler-Leman hierarchy. While previous methods have either limited expressiveness or are computationally impractical, we devise efficient sampling-based alternatives that are maximally expressive in expectation. We empirically evaluate our proposed embeddings and show competitive results on several benchmark graph learning tasks."}}
{"id": "Oq5mzL-3SUV", "cdate": 1655802924303, "mdate": null, "content": {"title": "Weisfeiler and Leman Return with Graph Transformations", "abstract": "We propose novel graph transformations that allow standard message passing to achieve state-of-the-art expressiveness and predictive performance. Message passing graph neural networks are known to have limited expressiveness in distinguishing graphs. To mitigate this, one can either change message passing or modify the graphs. Changing message passing is powerful but requires significant changes to existing implementations and cannot easily be combined with other approaches. Modifying the graph requires no changes to the learning algorithm and works directly with off-the-shelf implementations. In this paper, we propose novel graph transformations and compare them to the state-of-the-art. We prove that they are at least as expressive as corresponding message passing algorithms when combined with the Weisfeiler-Leman test or a sufficiently powerful graph neural network. Furthermore, we empirically demonstrate that these transformations lead to competitive results on molecular graph datasets."}}
{"id": "dNXg-h6YX9h", "cdate": 1652737509283, "mdate": null, "content": {"title": "Active Learning of Classifiers with Label and Seed Queries", "abstract": "We study exact active learning of binary and multiclass classifiers with margin. Given an $n$-point set $X \\subset \\mathbb{R}^m$, we want to learn an unknown classifier on $X$ whose classes have finite strong convex hull margin, a new notion extending the SVM margin. In the standard active learning setting, where only label queries are allowed, learning a classifier with strong convex hull margin $\\gamma$ requires in the worst case $\\Omega\\big(1+\\frac{1}{\\gamma}\\big)^{\\frac{m-1}{2}}$ queries.  On the other hand, using the more powerful \\emph{seed} queries (a variant of equivalence queries), the target classifier could be learned in $O(m \\log n)$ queries via Littlestone's Halving algorithm; however, Halving is computationally inefficient. In this work we show that, by carefully combining the two types of queries, a binary classifier can be learned in time $\\operatorname{poly}(n+m)$ using only $O(m^2 \\log n)$ label queries and $O\\big(m \\log \\frac{m}{\\gamma}\\big)$ seed queries; the result extends to $k$-class classifiers at the price of a $k!k^2$ multiplicative overhead. Similar results hold when the input points have bounded bit complexity, or when only one class has strong convex hull margin against the rest. We complement the upper bounds by showing that in the worst case any algorithm needs $\\Omega\\big(k m \\log \\frac{1}{\\gamma}\\big)$ seed and label queries to learn a $k$-class classifier with strong convex hull margin $\\gamma$."}}
{"id": "HKUxAE-J6lq", "cdate": 1646223669541, "mdate": null, "content": {"title": "Reducing Learning on Cell Complexes to Graphs", "abstract": "Message passing graph neural networks (GNNs) are known to have a limited expressiveness in distinguishing graphs. A recent approach tackles this problem by transforming graphs to regular cell complexes. This makes it possible to model higher-order structures and yields algorithms that are more powerful than the Weisfeiler Leman test (WL) or GNNs. However, this approach cannot easily be combined with previous graph algorithms and implementations due to their fundamental differences. We develop Cell Encoding, a novel approach of transforming regular cell complexes to graphs. We show that cell encoding combined with WL or a suitably expressive GNN is at least as expressive as Cellular Weisfeiler Leman (CWL) in distinguishing cell complexes. This means that with a simple preprocessing one can use any GNN for learning tasks on cell complexes. Additionally, we show that this approach can make GNNs more expressive and give better results on graph classification datasets."}}
{"id": "QRs2Mz6UCi", "cdate": 1640995200000, "mdate": 1682317865306, "content": {"title": "Online Learning of Convex Sets on Graphs", "abstract": "We study online learning of general convex sets and halfspaces on graphs. While online learning of halfspaces in Euclidean space is a classical learning problem, the corresponding problem on graphs is understudied. In this context, a set of vertices is convex if it contains all connecting shortest paths and a halfspace is a convex set whose complement is also convex. We discuss mistake bounds based on the Halving algorithm and shortest path covers. Halving achieves near-optimal bounds but is inefficient in general. The shortest path cover based algorithm is efficient but provides optimal bounds only for restricted graph families such as trees. To mitigate the weaknesses of both approaches, we propose a novel polynomial time algorithm which achieves near-optimal bounds on graphs that are $$K_{2,k}$$ minor-free for some constant $$k\\in \\mathbb {N}$$ . In contrast to previous mistake bounds on graphs, which typically depend on the induced cut of the labelling, our bounds only depend on the graph itself. Finally, we discuss the agnostic version of this problem and introduce an adaptive variant of Halving for k-intersections of halfspaces."}}
{"id": "O-fOgeI_D-B", "cdate": 1621630340383, "mdate": null, "content": {"title": "Active Learning of Convex Halfspaces on Graphs", "abstract": "We systematically study the query complexity of learning geodesically convex halfspaces on graphs. Geodesic convexity is a natural generalisation of Euclidean convexity and allows the definition of convex sets and halfspaces on graphs. We prove an upper bound on the query complexity linear in the treewidth and the minimum hull set size but only logarithmic in the diameter. We show tight lower bounds along well-established separation axioms and identify the Radon number as a central parameter of the query complexity and the VC dimension. While previous bounds typically depend on the cut size of the labelling, all parameters in our bounds can be computed from the unlabelled graph. We provide evidence that ground-truth communities in real-world graphs are often convex and empirically compare our proposed approach with other active learning algorithms."}}
{"id": "-__S9T8QrDD", "cdate": 1621630340383, "mdate": null, "content": {"title": "Active Learning of Convex Halfspaces on Graphs", "abstract": "We systematically study the query complexity of learning geodesically convex halfspaces on graphs. Geodesic convexity is a natural generalisation of Euclidean convexity and allows the definition of convex sets and halfspaces on graphs. We prove an upper bound on the query complexity linear in the treewidth and the minimum hull set size but only logarithmic in the diameter. We show tight lower bounds along well-established separation axioms and identify the Radon number as a central parameter of the query complexity and the VC dimension. While previous bounds typically depend on the cut size of the labelling, all parameters in our bounds can be computed from the unlabelled graph. We provide evidence that ground-truth communities in real-world graphs are often convex and empirically compare our proposed approach with other active learning algorithms."}}
{"id": "7i5MlVtomt", "cdate": 1577836800000, "mdate": 1682317864503, "content": {"title": "Improving a Branch-and-Bound Approach for the Degree-Constrained Minimum Spanning Tree Problem with LKH", "abstract": ""}}
