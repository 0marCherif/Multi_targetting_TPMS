{"id": "DmzF_IuR_Gv", "cdate": 1668734801400, "mdate": null, "content": {"title": "Netflix and Forget: Fast Severance From Memorizing Training Data in Recommendations", "abstract": "Suppose a person, who has streamed rom-coms exclusively with their significant\nother, suddenly breaks up.\nConsider an expecting mom, who has shopped for baby clothes, miscarries.\nTheir streaming and shopping recommendations, however, do not necessarily update, serving as unhappy reminders of their loss.\nOne approach is to implement the Right To Be Forgotten for recommendation systems built from user data, with the goal of updating downstream recommendations to reflect the removal without incurring the cost of re-training.\nInspired by solutions to the original Netflix challenge~\\citep{koren2009bellkor}, we develop Unlearn-ALS, which is more aggressively forgetful of select data than fine-tuning. In theory, it is consistent with retraining without model degradation. Empirically, it shows fast convergence, and can be applied directly to any bi-linear models regardless of the training procedure."}}
{"id": "G-uNfHKrj46", "cdate": 1663850216501, "mdate": null, "content": {"title": "Efficient Attention via Control Variates", "abstract": "Random-feature-based attention (RFA) is an efficient approximation of softmax attention with linear runtime and space complexity. However, the approximation gap between RFA and conventional softmax attention is not well studied. Built upon previous progress of RFA, we characterize this gap through the lens of control variates and show that RFA can be decomposed into a sum of multiple control variate estimators for each element in the sequence. This new framework reveals that exact softmax attention can be recovered from RFA by manipulating each control variate. Besides, it allows us to develop a more flexible form of control variates, resulting in a novel attention mechanism that significantly reduces the approximation gap while maintaining linear complexity. Extensive experiments demonstrate that our model outperforms state-of-the-art efficient attention mechanisms on both vision and language tasks."}}
{"id": "bl7sj8GAmDT", "cdate": 1650307123896, "mdate": 1650307123896, "content": {"title": "Thoracic Disease Identification and Localization with Limited Supervision", "abstract": "Accurate identification and localization of abnormalities from radiology images play an integral part in clinical diagnosis and treatment planning. Building a highly accurate prediction model for these tasks usually requires a large number of images manually annotated with labels and finding sites of abnormalities. In reality, however, such annotated data are expensive to acquire, especially the ones with location annotations. We need methods that can work well with only a small amount of location annotations. To address this challenge, we present a unified approach that simultaneously performs disease identification and localization through the same underlying model for all images. We demonstrate that our approach can effectively leverage both class information as well as limited location annotation, and significantly outperforms the comparative reference baseline in both classification and localization tasks."}}
{"id": "NeeuFJC8kqW", "cdate": 1650306753375, "mdate": null, "content": {"title": "Prior-aware Neural Network for Partially-Supervised Multi-Organ Segmentation", "abstract": "Accurate multi-organ abdominal CT segmentation is essential to many clinical applications such as computeraided intervention. As data annotation requires massive\nhuman labor from experienced radiologists, it is common that training data are partially labeled, e.g., pancreas\ndatasets only have the pancreas labeled while leaving the\nrest marked as background. However, these background labels can be misleading in multi-organ segmentation since\nthe \u201cbackground\u201d usually contains some other organs of\ninterest. To address the background ambiguity in these\npartially-labeled datasets, we propose Prior-aware Neural Network (PaNN) via explicitly incorporating anatomical priors on abdominal organ sizes, guiding the training process with domain-specific knowledge. More specifically, PaNN assumes that the average organ size distributions in the abdomen should approximate their empirical\ndistributions, prior statistics obtained from the fully-labeled\ndataset. As our training objective is difficult to be directly\noptimized using stochastic gradient descent, we propose to\nreformulate it in a min-max form and optimize it via the\nstochastic primal-dual gradient algorithm. PaNN achieves\nstate-of-the-art performance on the MICCAI2015 challenge\n\u201cMulti-Atlas Labeling Beyond the Cranial Vault\u201d, a competition on organ segmentation in the abdomen. We report an\naverage Dice score of 84.97%, surpassing the prior art by\na large margin of 3.27%."}}
{"id": "SAlemvIoql9", "cdate": 1646077530528, "mdate": null, "content": {"title": "Differentially Private Multi-Party Data Release for Linear Regression", "abstract": "Differentially Private (DP) data release is a promising technique to disseminate data without compromising the privacy of data subjects. However the majority of prior work has focused on scenarios where a single party owns all the data. In this paper we focus on the multi-party setting, where different stakeholders own disjoint sets of attributes belonging to the same group of data subjects. Within the context of linear regression that allow all parties to train models on the complete data without the ability to infer private attributes or identities of individuals, we start with directly applying Gaussian mechanism and show it has the small eigenvalue problem. We further propose our novel method and prove it asymptotically converges to the optimal (non-private) solutions with increasing dataset size. We substantiate the theoretical results through experiments on both artificial and real-world datasets.  "}}
{"id": "Hh4VpIUiqeq", "cdate": 1646077525259, "mdate": null, "content": {"title": "PathFlow: A Normalizing Flow Generator that Finds Transition Paths", "abstract": "Sampling from a Boltzmann distribution to calculate important macro statistics is one of the central tasks in the study of large atomic and molecular systems.  Recently, a one-shot configuration sampler, the Boltzmann generator (Noe et al., 2019), is introduced. Though a Boltzmann generator can directly generate independent metastable states, it lacks the ability to find transition pathways and describe the whole transition process. In this paper, we propose PathFlow that can function as a one-shot generator as well as a transition pathfinder. More specifically, a normalizing flow model is constructed to map the base distribution and linear interpolated path in the latent space to the Boltzmann distribution and a minimum (free) energy path in the configuration space simultaneously. PathFlow can be trained by standard gradient-based optimizers using the proposed gradient estimator with a theoretical guarantee. PathFlow, validated with the extensively studied examples including a synthetic M\\\"{u}ller potential and Alanine dipeptide, shows a remarkable performance. "}}
{"id": "mAsPhtKTpEQ", "cdate": 1640995200000, "mdate": 1668085265696, "content": {"title": "Collaborative Anomaly Detection", "abstract": "In recommendation systems, items are likely to be exposed to various users and we would like to learn about the familiarity of a new user with an existing item. This can be formulated as an anomaly detection (AD) problem distinguishing between \"common users\" (nominal) and \"fresh users\" (anomalous). Considering the sheer volume of items and the sparsity of user-item paired data, independently applying conventional single-task detection methods on each item quickly becomes difficult, while correlations between items are ignored. To address this multi-task anomaly detection problem, we propose collaborative anomaly detection (CAD) to jointly learn all tasks with an embedding encoding correlations among tasks. We explore CAD with conditional density estimation and conditional likelihood ratio estimation. We found that: $i$) estimating a likelihood ratio enjoys more efficient learning and yields better results than density estimation. $ii$) It is beneficial to select a small number of tasks in advance to learn a task embedding model, and then use it to warm-start all task embeddings. Consequently, these embeddings can capture correlations between tasks and generalize to new correlated tasks."}}
{"id": "BXmjMpBVvu", "cdate": 1640995200000, "mdate": 1649649772389, "content": {"title": "Learning to Simulate Unseen Physical Systems with Graph Neural Networks", "abstract": "Simulation of the dynamics of physical systems is essential to the development of both science and engineering. Recently there is an increasing interest in learning to simulate the dynamics of physical systems using neural networks. However, existing approaches fail to generalize to physical substances not in the training set, such as liquids with different viscosities or elastomers with different elasticities. Here we present a machine learning method embedded with physical priors and material parameters, which we term as \"Graph-based Physics Engine\" (GPE), to efficiently model the physical dynamics of different substances in a wide variety of scenarios. We demonstrate that GPE can generalize to materials with different properties not seen in the training set and perform well from single-step predictions to multi-step roll-out simulations. In addition, introducing the law of momentum conservation in the model significantly improves the efficiency and stability of learning, allowing convergence to better models with fewer training steps."}}
{"id": "cOtBRgsf2fO", "cdate": 1632875533771, "mdate": null, "content": {"title": "Label Leakage and Protection in Two-party Split Learning", "abstract": "Two-party split learning is a popular technique for learning a model across feature-partitioned data. In this work, we explore whether it is possible for one party to steal the private label information from the other party during split training, and whether there are methods that can protect against such attacks. Specifically, we first formulate a realistic threat model and propose a privacy loss metric to quantify label leakage in split learning. We then show that there exist two simple yet effective methods within the threat model that can allow one party to accurately recover private ground-truth labels owned by the other party. To combat these attacks, we propose several random perturbation techniques, including $\\texttt{Marvell}$, an approach that strategically finds the structure of the noise perturbation by minimizing the amount of label leakage (measured through our quantification metric) of a worst-case adversary. We empirically demonstrate the effectiveness of our protection techniques against the identified attacks, and show that $\\texttt{Marvell}$ in particular has improved privacy-utility tradeoffs relative to baseline approaches."}}
{"id": "9Xh1v7Y9MAj", "cdate": 1632499905161, "mdate": null, "content": {"title": "Learning to Simulate Unseen Physical Systems with Graph Neural Networks", "abstract": "Recently there is an increasing interest in learning to simulate the dynamics of physic systems via machine learning. However, existing approaches fail to generalize to physical substances not in the training set, such as liquids with different viscosities or elastomers with different elasticities. Here we present a machine learning method embedded with physical priors and material parameters, which we term as \u201cGraph-based Physics Engine\u201d (GPE), to efficiently model the physical dynamics of different substances in a wide variety of challenging scenarios. We demonstrate that GPE can generalize to different material properties not seen in the training set by simply modifying the physical parameters, and also performs well from single-step predictions to multi-step roll-out simulations. GPE provides new insights into the construction of learnable simulators and is a key step toward predicting unknown physics problems in the real world.\n"}}
