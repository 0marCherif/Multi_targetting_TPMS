{"id": "7WkBLLPZhhd", "cdate": 1620742982426, "mdate": null, "content": {"title": "From fair decision making to social equality", "abstract": "The study of fairness in intelligent decision systems has mostly ignored long-term influence\non the underlying population. Yet fairness considerations (e.g. affirmative action) have often\nthe implicit goal of achieving balance among groups within the population. The most basic\nnotion of balance is eventual equality between the qualifications of the groups. How can we\nincorporate influence dynamics in decision making? How well do dynamics-oblivious fairness\npolicies fare in terms of reaching equality? In this paper, we propose a simple yet revealing model\nthat encompasses (1) a selection process where an institution chooses from multiple groups\naccording to their qualifications so as to maximize an institutional utility and (2) dynamics that\ngovern the evolution of the groups\u2019 qualifications according to the imposed policies. We focus\non demographic parity as the formalism of affirmative action.\nWe then give conditions under which an unconstrained policy reaches equality on its own. In\nthis case, surprisingly, imposing demographic parity may break equality. When it doesn\u2019t, one\nwould expect the additional constraint to reduce utility, however, we show that utility may in\nfact increase. In more realistic scenarios, unconstrained policies do not lead to equality. In such\ncases, we show that although imposing demographic parity may remedy it, there is a danger\nthat groups settle at a worse set of qualifications. As a silver lining, we also identify when\nthe constraint not only leads to equality, but also improves all groups. This gives quantifiable\ninsight into both sides of the mismatch hypothesis. These cases and trade-offs are instrumental in\ndetermining when and how imposing demographic parity can be beneficial in selection processes,\nboth for the institution and for society on the long run."}}
{"id": "dj_onxZg4bw", "cdate": 1577836800000, "mdate": 1631481846212, "content": {"title": "Towards Competitive N-gram Smoothing", "abstract": "N-gram models remain a fundamental component of language modeling. In data-scarce regimes, they are a strong alternative to neural models. Even when not used as-is, recent work shows they can regul..."}}
{"id": "78X-ZoGTP5a", "cdate": 1577836800000, "mdate": null, "content": {"title": "Fair Learning with Private Demographic Data", "abstract": "Sensitive attributes such as race are rarely available to learners in real world settings as their collection is often restricted by laws and regulations. We give a scheme that allows individuals t..."}}
{"id": "rPj7vUOzZp", "cdate": 1546300800000, "mdate": 1707375588291, "content": {"title": "On the Impossibility of Learning the Missing Mass", "abstract": "This paper shows that one cannot learn the probability of rare events without imposing further structural assumptions. The event of interest is that of obtaining an outcome outside the coverage of an i.i.d. sample from a discrete distribution. The probability of this event is referred to as the \u201cmissing mass\u201d. The impossibility result can then be stated as: the missing mass is not distribution-free learnable in relative error. The proof is semi-constructive and relies on a coupling argument using a dithered geometric distribution. Via a reduction, this impossibility also extends to both discrete and continuous tail estimation. These results formalize the folklore that in order to predict rare events without restrictive modeling, one necessarily needs distributions with \u201cheavy tails\u201d."}}
{"id": "G43DlcNQc4", "cdate": 1546300800000, "mdate": 1707375588282, "content": {"title": "From Fair Decision Making To Social Equality", "abstract": "The study of fairness in intelligent decision systems has mostly ignored long-term influence on the underlying population. Yet fairness considerations (e.g. affirmative action) have often the implicit goal of achieving balance among groups within the population. The most basic notion of balance is eventual equality between the qualifications of the groups. How can we incorporate influence dynamics in decision making? How well do dynamics-oblivious fairness policies fare in terms of reaching equality? In this paper, we propose a simple yet revealing model that encompasses (1) a selection process where an institution chooses from multiple groups according to their qualifications so as to maximize an institutional utility and (2) dynamics that govern the evolution of the groups' qualifications according to the imposed policies. We focus on demographic parity as the formalism of affirmative action. We first give conditions under which an unconstrained policy reaches equality on its own. In this case, surprisingly, imposing demographic parity may break equality. When it doesn't, one would expect the additional constraint to reduce utility, however, we show that utility may in fact increase. In real world scenarios, unconstrained policies do not lead to equality. In such cases, we show that although imposing demographic parity may remedy it, there is a danger that groups settle at a worse set of qualifications. As a silver lining, we also identify when the constraint not only leads to equality, but also improves all groups. These cases and trade-offs are instrumental in determining when and how imposing demographic parity can be beneficial in selection processes, both for the institution and for society on the long run."}}
{"id": "q1QgS-69WW", "cdate": 1483228800000, "mdate": 1707375588303, "content": {"title": "Learning Non-Discriminatory Predictors", "abstract": "We consider learning a predictor which is non-discriminatory with respect to a \u201cprotected attribute\u201d according to the notion of \u201cequalized odds\u201d proposed by Hardt et al. (2016). We study the problem of learning such a non-discriminatory predictor from a finite training set, both statistically and computationally. We show that a post-hoc correction approach, as suggested by Hardt et al, can be highly suboptimal, present a nearly-optimal statistical procedure, argue that the associated computational problem is intractable, and suggest a second moment relaxation of the non-discrimination definition for which learning is tractable."}}
{"id": "Syb7h_W_WH", "cdate": 1483228800000, "mdate": null, "content": {"title": "The power of absolute discounting: all-dimensional distribution estimation", "abstract": "Categorical models are a natural fit for many problems. When learning the distribution of categories from samples, high-dimensionality may dilute the data. Minimax optimality is too pessimistic to remedy this issue. A serendipitously discovered estimator, absolute discounting, corrects empirical frequencies by subtracting a constant from observed categories, which it then redistributes among the unobserved. It outperforms classical estimators empirically, and has been used extensively in natural language modeling. In this paper, we rigorously explain the prowess of this estimator using less pessimistic notions. We show that (1) absolute discounting recovers classical minimax KL-risk rates, (2) it is \\emph{adaptive} to an effective dimension rather than the true dimension, (3) it is strongly related to the Good-Turing estimator and inherits its \\emph{competitive} properties. We use power-law distributions as the cornerstone of these results. We validate the theory via synthetic data and an application to the Global Terrorism Database."}}
{"id": "AEa-kmF0ljj", "cdate": 1483228800000, "mdate": 1707375588342, "content": {"title": "Learning Non-Discriminatory Predictors", "abstract": "We consider learning a predictor which is non-discriminatory with respect to a \"protected attribute\" according to the notion of \"equalized odds\" proposed by Hardt et al. [2016]. We study the problem of learning such a non-discriminatory predictor from a finite training set, both statistically and computationally. We show that a post-hoc correction approach, as suggested by Hardt et al, can be highly suboptimal, present a nearly-optimal statistical procedure, argue that the associated computational problem is intractable, and suggest a second moment relaxation of the non-discrimination definition for which learning is tractable."}}
{"id": "QBLdmKn-oBrm", "cdate": 1451606400000, "mdate": 1663921825577, "content": {"title": "Tradeoffs for Space, Time, Data and Risk in Unsupervised Learning", "abstract": "Faced with massive data, is it possible to trade off (statistical) risk, and (computational) space and time? This challenge lies at the heart of large-scale machine learning. Using k-means clustering as a prototypical unsupervised learning problem, we show how we can strategically summarize the data (control space) in order to trade off risk and time when data is generated by a probabilistic model. Our summarization is based on coreset constructions from computational geometry. We also develop an algorithm, TRAM, to navigate the space/time/data/risk tradeoff in practice. In particular, we show that for a fixed risk (or data size), as the data size increases (resp. risk increases) the running time of TRAM decreases. Our extensive experiments on real data sets demonstrate the existence and practical utility of such tradeoffs, not only for k-means but also for Gaussian Mixture Models."}}
{"id": "BJEByF-ObH", "cdate": 1451606400000, "mdate": null, "content": {"title": "Near-Optimal Smoothing of Structured Conditional Probability Matrices", "abstract": "Utilizing the structure of a probabilistic model can significantly increase its learning speed. Motivated by several recent applications, in particular bigram models in language processing, we consider learning low-rank conditional probability matrices under expected KL-risk. This choice makes smoothing, that is the careful handling of low-probability elements, paramount. We derive an iterative algorithm that extends classical non-negative matrix factorization to naturally incorporate additive smoothing and prove that it converges to the stationary points of a penalized empirical risk. We then derive sample-complexity bounds for the global minimizer of the penalized risk and show that it is within a small factor of the optimal sample complexity. This framework generalizes to more sophisticated smoothing techniques, including absolute-discounting."}}
