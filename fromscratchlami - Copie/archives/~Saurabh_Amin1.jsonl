{"id": "zm23Nw46MZ", "cdate": 1684350843321, "mdate": 1684350843321, "content": {"title": "Integer Programming-based Error-Correcting Output Code Design for Robust Classification", "abstract": "Error-Correcting Output Codes (ECOCs) offer aprincipled approach for combining binary classi-fiers into multiclass classifiers. In this paper, westudy the problem of designing optimal ECOCsto achieve both nominal and adversarial accuracyusing Support Vector Machines (SVMs) and bi-nary deep neural networks. We develop a scalableInteger Programming (IP) formulation to designminimal codebooks with desirable error correct-ing properties. Our work leverages the advancesin IP solution techniques to generate codebookswith optimality guarantees. To achieve tractability,we exploit the underlying graph-theoretic struc-ture of the constraint set. Particularly, the size ofthe constraint set can be significantly reduced us-ing edge clique covers. Using this reduction tech-nique along with Plotkin\u2019s bound in coding theory,we demonstrate that our approach is scalable to alarge number of classes. The resulting codebooksachieve a high nominal accuracy relative to stan-dard codebooks (e.g., one-vs-all, one-vs-one, anddense/sparse codes). Interestingly, our codebooksprovide non-trivial robustness to white-box attackswithout any adversarial training."}}
{"id": "4nGK_WtWqE", "cdate": 1684350711164, "mdate": 1684350711164, "content": {"title": "Scalable design of Error-Correcting Output Codesusing Discrete Optimization with Graph Coloring", "abstract": "We study the problem of scalable design of Error-Correcting Output Codes (ECOC)for multi-class classification. Prior works on ECOC-based classifiers are limited tocodebooks with small number of rows (classes) or columns, and do not provide op-timality guarantees for the codebook design problem. We address these limitationsby developing a codebook design approach based on a Mixed-Integer QuadraticallyConstrained Program (MIQCP). This discrete formulation is naturally suited formaximizing the error-correction capability of ECOC-based classifiers and incorpo-rates various design criteria in a flexible manner. Our solution approach is tractablein that it incrementally increases the codebook size by adding columns to maximizethe gain in error-correcting capability.  In particular, we show that the maximalgain in error-correction can be upper bounded by solving a graph-coloring problem.As a result, we can efficiently generate near-optimal codebooks for very largeproblem instances. These codebooks provide competitive multi-class classificationperformance on small class datasets such as MNIST and CIFAR10.  Moreover,by leveraging transfer-learned binary classifiers, we achieve better classificationperformance over transfer-learned multi-class CNNs on large class datasets such asCIFAR100, Caltech-101/256. Our results highlight the advantages of simple andmodular ECOC-based classifiers in improving classification accuracy without therisk of overfitting."}}
{"id": "0xdH-09oGD7", "cdate": 1652737751636, "mdate": null, "content": {"title": "Effective Dimension in Bandit Problems under Censorship", "abstract": "In this paper, we study both multi-armed and contextual bandit problems in censored environments. Our goal is to estimate the performance loss due to censorship in the context of classical algorithms designed for uncensored environments. Our main contributions include the introduction of a broad class of censorship models and their analysis in terms of the effective dimension of the problem -- a natural measure of its underlying statistical complexity and main driver of the regret bound. In particular, the effective dimension allows us to maintain the structure of the original problem at first order, while embedding it in a bigger space, and thus naturally leads to results analogous to uncensored settings. Our analysis involves a continuous generalization of the Elliptical Potential Inequality, which we believe is of independent interest. We also discover an interesting property of decision-making under censorship: a transient phase during which initial misspecification of censorship is self-corrected at an extra cost; followed by a stationary phase that reflects the inherent slowdown of learning governed by the effective dimension. Our results are useful for applications of sequential decision-making models where the feedback received depends on strategic uncertainty (e.g., agents\u2019 willingness to follow a recommendation) and/or random uncertainty (e.g., loss or delay in arrival of information)."}}
{"id": "WaKGmSI2-8g", "cdate": 1652737608662, "mdate": null, "content": {"title": "Scalable design of Error-Correcting Output Codes using Discrete Optimization with Graph Coloring", "abstract": "We study the problem of scalable design of Error-Correcting Output Codes (ECOC) for multi-class classification. Prior works on ECOC-based classifiers are limited to codebooks with small number of rows (classes) or columns, and do not provide optimality guarantees for the codebook design problem. We address these limitations by developing a codebook design approach based on a Mixed-Integer Quadratically Constrained Program (MIQCP). This discrete formulation is naturally suited for maximizing the error-correction capability of ECOC-based classifiers and incorporates various design criteria in a flexible manner. Our solution approach is tractable in that it incrementally increases the codebook size by adding columns to maximize the gain in error-correcting capability. In particular, we show that the maximal gain in error-correction can be upper bounded by solving a graph-coloring problem.  As a result, we can efficiently generate near-optimal codebooks for very large problem instances. These codebooks provide competitive multi-class classification performance on small class datasets such as MNIST and CIFAR10. Moreover, by leveraging transfer-learned binary classifiers, we achieve better classification performance over transfer-learned multi-class CNNs on large class datasets such as CIFAR100, Caltech-101/256. Our results highlight the advantages of simple and modular ECOC-based classifiers in improving classification accuracy without the risk of overfitting."}}
{"id": "DNDG44KxxJF", "cdate": 1591623827454, "mdate": null, "content": {"title": "Bayesian Learning with Adaptive Load Allocation Strategies", "abstract": "We study a Bayesian learning dynamics induced by agents who repeatedly allocate loads on a set of resources based on their belief of an unknown parameter that affects the cost distributions of resources. In each step, belief update is performed according to Bayes' rule using the agents' current load and a realization of costs on resources that they utilized. Then, agents choose a new load using an adaptive strategy update rule that accounts for their preferred allocation based on the updated belief. We prove that beliefs and loads generated by this learning dynamics converge almost surely. The convergent belief accurately estimates cost distributions of resources that are utilized by the convergent load. We establish conditions on the initial load and strategy updates under which the cost estimation is accurate on all resources. These results apply to Bayesian learning in congestion games with unknown latency functions. Particularly, we provide conditions under which the load converges to an equilibrium or socially optimal load with complete information of cost parameter. We also design an adaptive tolling mechanism that eventually induces the socially optimal outcome. "}}
