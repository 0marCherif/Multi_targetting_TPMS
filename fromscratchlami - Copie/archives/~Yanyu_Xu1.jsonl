{"id": "db7DX8COFZz", "cdate": 1683708642880, "mdate": 1683708642880, "content": {"title": "Prior Based Human Completion", "abstract": "We study a very challenging task, human image completion, which tries to recover the human body part with a reasonable human shape from the corrupted region. Since each human body part is unique, it is infeasible to restore the missing part by borrowing textures from other visible regions. Thus, we propose two types of learned priors to compensate for the damaged region. One is a structure prior, it uses a human parsing map to represent the human body structure. The other is a structure-texture correlation prior. It learns a structure and a texture memory bank, which encodes the common body structures and texture patterns, respectively. With the aid of these memory banks, the model could utilize the visible pattern to query and fetch a similar structure and texture pattern to introduce additional reasonable structures and textures for the corrupted region. Besides, since multiple potential human shapes are underlying the corrupted region, we propose multi-scale structure discriminators to further restore a plausible topological structure. Experiments on various large-scale benchmarks demonstrate the effectiveness of our proposed method."}}
{"id": "aBHTGMkisy-", "cdate": 1663850002806, "mdate": null, "content": {"title": "Gradient Inversion via Over-parameterized Convolutional Network in Federated Learning", "abstract": "The main premise of federated learning is local clients could upload gradients instead of data during collaborative learning, hence preserving data privacy. But the development of gradient inversion method renders this premise under severe challenges: a third-party could still reconstruct the original training images through the uploaded gradients. While previous works are majorly conducted under relatively low-resolution images and small batch sizes, in this paper, we show that image reconstruction from complex datasets like ImageNet is still possible, even nested with large batch sizes and high resolutions. Success of the proposed method is built upon three key factors: a convolutional network to implicitly create an image prior, an over-parameterized network to guarantee the non-empty of the image generation and gradient matching, and a properly-designed architecture to create pixel intimacy. We conduct a series of practical experiments to demonstrate that the proposed algorithm can outperform SOTA algorithms and reconstruct the underlying original training images more effectively. Source code is available at: (to be released upon publication)."}}
{"id": "uoozaUJE3-r", "cdate": 1640995200000, "mdate": 1668776970503, "content": {"title": "An Efficient Defending Mechanism Against Image Attacking on Medical Image Segmentation Models", "abstract": "Image attacking has been studied for a long time. However, in reality, the number of research on defending against the attacks on segmentation models is still limited especially for medical imaging. To fill this research gap, we propose a novel defending mechanism against adversarial attacks for the segmentation models. We focus on segmentation as robustness improvement on segmentation is much more challenging due to its dense nature, and segmentation is at the center of medical imaging tasks. In this paper, we are the first time to employ Transformer as a technique to protect the segmentation models from attacks. Our result on several medical well-known benchmark datasets shows that the proposed defending mechanism to enhance the segmentation models is effective with high scores and better compared to other strong methods."}}
{"id": "sfyYupuese", "cdate": 1640995200000, "mdate": 1668776970677, "content": {"title": "Localizing Anatomical Landmarks in Ocular Images using Zoom-In Attentive Networks", "abstract": "Localizing anatomical landmarks are important tasks in medical image analysis. However, the landmarks to be localized often lack prominent visual features. Their locations are elusive and easily confused with the background, and thus precise localization highly depends on the context formed by their surrounding areas. In addition, the required precision is usually higher than segmentation and object detection tasks. Therefore, localization has its unique challenges different from segmentation or detection. In this paper, we propose a zoom-in attentive network (ZIAN) for anatomical landmark localization in ocular images. First, a coarse-to-fine, or \"zoom-in\" strategy is utilized to learn the contextualized features in different scales. Then, an attentive fusion module is adopted to aggregate multi-scale features, which consists of 1) a co-attention network with a multiple regions-of-interest (ROIs) scheme that learns complementary features from the multiple ROIs, 2) an attention-based fusion module which integrates the multi-ROIs features and non-ROI features. We evaluated ZIAN on two open challenge tasks, i.e., the fovea localization in fundus images and scleral spur localization in AS-OCT images. Experiments show that ZIAN achieves promising performances and outperforms state-of-the-art localization methods. The source code and trained models of ZIAN are available at https://github.com/leixiaofeng-astar/OMIA9-ZIAN."}}
{"id": "rjhyTFfqVYD", "cdate": 1640995200000, "mdate": 1681649710023, "content": {"title": "ResNeRF: Geometry-Guided Residual Neural Radiance Field for Indoor Scene Novel View Synthesis", "abstract": ""}}
{"id": "ebAOMmk6TjT", "cdate": 1640995200000, "mdate": 1668090739984, "content": {"title": "GAMMA Challenge: Glaucoma grAding from Multi-Modality imAges", "abstract": "Color fundus photography and Optical Coherence Tomography (OCT) are the two most cost-effective tools for glaucoma screening. Both two modalities of images have prominent biomarkers to indicate glaucoma suspected. Clinically, it is often recommended to take both of the screenings for a more accurate and reliable diagnosis. However, although numerous algorithms are proposed based on fundus images or OCT volumes in computer-aided diagnosis, there are still few methods leveraging both of the modalities for the glaucoma assessment. Inspired by the success of Retinal Fundus Glaucoma Challenge (REFUGE) we held previously, we set up the Glaucoma grAding from Multi-Modality imAges (GAMMA) Challenge to encourage the development of fundus \\& OCT-based glaucoma grading. The primary task of the challenge is to grade glaucoma from both the 2D fundus images and 3D OCT scanning volumes. As part of GAMMA, we have publicly released a glaucoma annotated dataset with both 2D fundus color photography and 3D OCT volumes, which is the first multi-modality dataset for glaucoma grading. In addition, an evaluation framework is also established to evaluate the performance of the submitted methods. During the challenge, 1272 results were submitted, and finally, top-10 teams were selected to the final stage. We analysis their results and summarize their methods in the paper. Since all these teams submitted their source code in the challenge, a detailed ablation study is also conducted to verify the effectiveness of the particular modules proposed. We find many of the proposed techniques are practical for the clinical diagnosis of glaucoma. As the first in-depth study of fundus \\& OCT multi-modality glaucoma grading, we believe the GAMMA Challenge will be an essential starting point for future research."}}
{"id": "asUsCHiF5rf", "cdate": 1640995200000, "mdate": 1668776970712, "content": {"title": "Localizing Anatomical Landmarks in Ocular Images Using Zoom-In Attentive Networks", "abstract": "Localizing anatomical landmarks are important tasks in medical image analysis. However, the landmarks to be localized often lack prominent visual features. Their locations are elusive and easily confused with the background, and thus precise localization highly depends on the context formed by their surrounding areas. In addition, the required precision is usually higher than segmentation and object detection tasks. Therefore, localization has its unique challenges different from segmentation or detection. In this paper, we propose a zoom-in attentive network (ZIAN) for anatomical landmark localization in ocular images. First, a coarse-to-fine, or \u201czoom-in\u201d strategy is utilized to learn the contextualized features in different scales. Then, an attentive fusion module is adopted to aggregate multi-scale features, which consists of 1) a co-attention network with a multiple regions-of-interest (ROIs) scheme that learns complementary features from the multiple ROIs, 2) an attention-based fusion module which integrates the multi-ROIs features and non-ROI features. We evaluated ZIAN on two open challenge tasks, i.e., the fovea localization in fundus images and scleral spur localization in AS-OCT images. Experiments show that ZIAN achieves promising performances and outperforms state-of-the-art localization methods. The source code and trained models of ZIAN are available at https://github.com/leixiaofeng-astar/OMIA9-ZIAN ."}}
{"id": "Vv0qzmEjgq", "cdate": 1640995200000, "mdate": 1681649709933, "content": {"title": "Reliable Joint Segmentation of Retinal Edema Lesions in OCT Images", "abstract": ""}}
{"id": "OLj-2OJkR2", "cdate": 1640995200000, "mdate": 1668776970496, "content": {"title": "Tiny-Lesion Segmentation in OCT via Multi-scale Wavelet Enhanced Transformer", "abstract": "The accurate segmentation of retinal lesions from OCT images can greatly aid ophthalmologists in evaluating retinal diseases. However, it remains a challenge to accurately segment retinal lesions in OCT images. This is due to the complicated pathological features of retinal diseases, resulting in severe regional scale imbalance between different lesions, and leading to the problem of target tendency of the network during training, subsequently resulting in the segmentation performance reduction for tiny-lesion. Aiming to solve these challenges, we propose a novel multi-scale wavelet enhanced transformer network for tiny-lesion segmentation in retinal OCT images. In the proposed model, we first design a novel adaptive wavelet down-sampling module combined with the pre-trained ResNet blocks as the feature extractor network, which can generate a wavelet representation to improve the model\u2019s interpretability while avoiding feature loss, and further enhancing the ability of the network to represent local detailed features. Meanwhile, we also develop a novel multi-scale transformer module to further improve the model\u2019s capacity of extracting the multi-scale long-dependent global features of the retinal lesions in OCT images. Finally, the proposed method is evaluated on the public database of AI-Challenge 2018 for retinal edema lesions joint segmentation, and the results indicate that the proposed method achieves better segmentation performance than other state-of-the-art networks, especially for tiny PED lesions with very small regional proportions."}}
{"id": "DMufULLLBDN", "cdate": 1640995200000, "mdate": 1681649709607, "content": {"title": "Spherical DNNs and Their Applications in 360$^\\circ$\u2218 Images and Videos", "abstract": ""}}
