{"id": "s653vra3bHt", "cdate": 1702139254811, "mdate": 1702139254811, "content": {"title": "Physics-informed neural ODE (PINODE): embedding physics into models using collocation points", "abstract": "Building reduced-order models (ROMs) is essential for efficient forecasting and control of complex dynamical systems. Recently, autoencoder-based methods for building such models have gained significant traction, but their demand for data limits their use when the data is scarce and expensive. We propose aiding a model\u2019s training with the knowledge of physics using a collocation-based physics-informed loss term. Our innovation builds on ideas from classical collocation methods of numerical analysis to embed knowledge from a known equation into the latent-space dynamics of a ROM. We show that the addition of our physics-informed loss allows for exceptional data supply strategies that improves the performance of ROMs in data-scarce settings, where training high-quality data-driven models is impossible. Namely, for a problem of modeling a high-dimensional nonlinear PDE, our experiments show  5 performance gains, measured by prediction error, in a low-data regime,  10 performance gains in tasks of high-noise learning,  100 gains in the efficiency of utilizing the latent-space dimension, and  200 gains in tasks of far-out out-of-distribution forecasting relative to purely data-driven models. These improvements pave the way for broader adoption of network-based physics-informed ROMs in compressive sensing and control applications."}}
{"id": "E8Pr7qudV8", "cdate": 1702139121975, "mdate": 1702139121975, "content": {"title": "Data-driven control of COVID-19 in buildings: a reinforcement-learning approach", "abstract": "In addition to its public health crisis, COVID- 19 pandemic has led to the shutdown and closure of workplaces with an estimated total cost of more than $16 trillion. Given the long hours an average person spends in buildings and indoor environments, this re- search article proposes data-driven control strategies to design optimal indoor airflow to minimize the exposure of occupants to viral pathogens in built environments. A general control framework is put forward for designing an optimal velocity field and proximal policy optimization, a reinforcement learning algorithm is employed to solve the control problem in a data-driven fashion. The same framework is used for optimal placement of disinfectants to neutralize the viral pathogens as an alternative to the airflow design when the latter is practically infea- sible or hard to implement. We show, via simulation experiments, that the control agent learns the optimal policy in both scenarios within a reasonable time. The proposed data-driven control framework in this study will have significant societal and economic benefits by setting the foundation for an improved methodology in designing case-specific infection control guidelines that can be realized by affordable ventilation devices and disinfectants."}}
{"id": "FqJEHNSR4e", "cdate": 1673366098862, "mdate": 1673366098862, "content": {"title": "Sparse sensing and DMD-based identification of flow regimes and bifurcations in complex flows", "abstract": "We present a sparse sensing framework based on Dynamic Mode Decomposition (DMD) to identify flow regimes and bifurcations in large-scale thermo-fluid systems. Motivated by real-time sensing and control of thermal-fluid flows in buildings and equipment, we apply this method to a Direct Numerical Simulation (DNS) data set of a 2D laterally heated cavity. The resulting flow solutions can be divided into several regimes, ranging from steady to chaotic flow. The DMD modes and eigenvalues capture the main temporal and spatial scales in the dynamics belonging to different regimes. Our proposed classification method is data-driven, robust w.r.t measurement noise, and exploits the dynamics extracted from the DMD method. Namely, we construct an augmented DMD basis, with \u201cbuilt-in\u201d dynamics, given by the DMD eigenvalues. This allows us to employ a short time-series of data from sensors, to more robustly classify flow regimes, particularly in the presence of measurement noise. We also exploit the incoherence exhibited among the data generated by different regimes, which persists even if the number of measurements is small compared to the dimension of the DNS data. The data-driven regime identification algorithm can enable robust low-order modeling of flows for state estimation and control."}}
{"id": "2vk4EOitswv", "cdate": 1673365731326, "mdate": 1673365731326, "content": {"title": "Robust preconditioned one-shot methods and direct-adjoint-looping for optimizing Reynolds-averaged turbulent flows", "abstract": "We compare the performance of direct-adjoint-looping (DAL) and one-shot algorithms in a design optimization task involving turbulent flow modeled using the Reynolds-Averaged-Navier-Stokes equations. Two preconditioned variants of the one-shot algorithm are proposed and tested. The role of an approximate Hessian as a preconditioner for the one-shot method iterations is highlighted. We find that  preconditioned one-shot algorithms can solve the PDE-constrained optimization problem with a cost of computation comparable (i.e. typically a single digit multiple greater) to that of the simulation run alone. This cost is substantially less than that of DAL, which requires $\\mathcal{O}(10)$ direct-adjoint loops to converge. The optimization results arising from the one-shot method can be used for optimal sensor/actuator placement tasks, or to provide a reference trajectory to be used for online feedback control applications."}}
{"id": "a3Rhl617hW", "cdate": 1665013555519, "mdate": null, "content": {"title": "Optimal Control of PDEs Using Physics-Informed Neural Networks", "abstract": "Physics-informed neural networks (PINNs) have recently become a popular method for solving forward and inverse problems governed by partial differential equations (PDEs). By incorporating the residual of the PDE into the loss function of a neural network-based surrogate model for the unknown state, PINNs can seamlessly blend measurement data with physical constraints. Here, we extend this framework to PDE-constrained optimal control problems, for which the governing PDE is fully known and the goal is to find a control variable that minimizes a desired cost objective. Importantly, we validate the performance of the PINN framework by comparing it to state-of-the-art adjoint-based optimization, which performs gradient descent on the discretized control variable while satisfying the discretized PDE. This comparison, carried out on challenging problems based on the nonlinear Kuramoto-Sivashinsky and Navier-Stokes equations, sheds light on the pros and cons of the PINN and adjoint-based approaches for solving PDE-constrained optimal control problems."}}
{"id": "ZADNbI_3sbS", "cdate": 1663850508725, "mdate": null, "content": {"title": "Reinforcement Learning-Based Estimation for Partial Differential Equations", "abstract": "In systems governed by nonlinear partial differential equations such as fluid flows, the design of state estimators such as Kalman filters relies on a reduced-order model (ROM) that projects the original high-dimensional dynamics onto a computationally tractable low-dimensional space. However, ROMs are prone to large errors, which negatively affects the performance of the estimator. Here, we introduce the reinforcement learning reduced-order estimator (RL-ROE), a ROM-based estimator in which the correction term that takes in the measurements is given by a nonlinear policy trained through reinforcement learning. The nonlinearity of the policy enables the RL-ROE to compensate efficiently for errors of the ROM, while still taking advantage of the imperfect knowledge of the dynamics. Using examples involving the Burgers and Navier-Stokes equations, we show that in the limit of very few sensors, the trained RL-ROE outperforms a Kalman filter designed using the same ROM. Moreover, it yields accurate high-dimensional state estimates for reference trajectories corresponding to various physical parameter values, without direct knowledge of the latter."}}
{"id": "UxTR9Z2DW8R", "cdate": 1632875760458, "mdate": null, "content": {"title": "Reinforcement Learning State Estimation for High-Dimensional Nonlinear Systems", "abstract": "In high-dimensional nonlinear systems such as fluid flows, the design of state estimators such as Kalman filters relies on a reduced-order model (ROM) of the dynamics. However, ROMs are prone to large errors, which negatively affects the performance of the estimator. Here, we introduce the reinforcement learning reduced-order estimator (RL-ROE), a ROM-based estimator in which the data assimilation feedback term is given by a nonlinear stochastic policy trained through reinforcement learning. The flexibility of the nonlinear policy enables the RL-ROE to compensate for errors of the ROM, while still taking advantage of the imperfect knowledge of the dynamics. We show that the trained RL-ROE is able to outperform a Kalman filter designed using the same ROM, and displays robust estimation performance with respect to different reference trajectories and initial state estimates."}}
{"id": "YnBlTtKpI9g", "cdate": 1601061551823, "mdate": null, "content": {"title": "Dynamic Mode Decomposition and Robust Estimation: Case Study of a 2D Turbulent Boussinesq Flow", "abstract": "This paper focuses on an application of dynamic mode decomposition (DMD) identification methods and robust estimation theory to thermo-fluid systems modelled by the Boussinesq equations. First, we use Dynamic Mode Decomposition with control (DMDc) to construct a reduced order linear model for the Boussinesq equations. Due to inherent model uncertainties in real applications, we propose robust estimators that minimize an H infinity norm from disturbance to estimation error. The disturbances we consider here stem from uncertainty in boundary conditions and unknown inputs acting on walls. Numerical simulations on a challenging turbulent flow, of the 2D Boussinesq equations, is used to demonstrate the potential of our approach."}}
{"id": "ByWZ_oWd-r", "cdate": 1514764800000, "mdate": null, "content": {"title": "Reinforcement Learning with Function-Valued Action Spaces for Partial Differential Equation Control", "abstract": "Recent work has shown that reinforcement learning (RL) is a promising approach to control dynamical systems described by partial differential equations (PDE). This paper shows how to use RL to tack..."}}
