{"id": "zvIEMSVBbT", "cdate": 1686250300222, "mdate": null, "content": {"title": "Online Learning under Adversarial Nonlinear Constraints", "abstract": "In many applications, learning systems are required to process continuous non-stationary data streams.\nWe study this problem in an online learning framework and propose an algorithm that can deal with adversarial time-varying and nonlinear constraints.\nAs we show in our work, the algorithm called Constraint Violation Velocity Projection (CVV-Pro) achieves $\\sqrt{T}$ regret and converges to the feasible set at a rate of $1/\\sqrt{T}$, despite the fact that the feasible set is slowly time-varying and a priori unknown to the learner.\nCVV-Pro only relies on local sparse linear approximations of the feasible set and therefore avoids optimizing over the entire set at each iteration, which is in sharp contrast to projected gradients or Frank-Wolfe methods.\nWe also empirically evaluate our algorithm on two-player games, where the players are subjected to a shared constraint."}}
{"id": "F5VLmQJHgd", "cdate": 1676827083132, "mdate": null, "content": {"title": "Causal Effect Estimation from Observational and Interventional Data Through Matrix Weighted Linear Estimators", "abstract": "We study causal effect estimation from a mixture of observational and interventional data in a confounded linear regression model with multivariate treatments. We show that the statistical efficiency in terms of expected squared error can be improved by combining estimators arising from both the observational and interventional setting. To this end, we derive methods based on matrix weighted linear estimators and prove that our methods are asymptotically unbiased in the infinite sample limit. This is an important improvement compared to the pooled estimator using the union of interventional and observational data, for which the bias only vanishes if the ratio of observational to interventional data tends to zero. Studies on synthetic data confirm our theoretical findings. In settings where confounding is substantial and the ratio of observational to interventional data is large, our estimators outperform a Stein-type estimator and various other baselines."}}
{"id": "u_byIR-I42_", "cdate": 1672313135706, "mdate": 1672313135706, "content": {"title": "Optimization with Adaptive Step Size Selection from a Dynamical Systems Perspective", "abstract": "We investigate how adaptive step size methods from numerical analysis can be used to speed up optimization routines. In contrast to line search strategies, the proposed methods recycle available gradient evaluations. Thus, neither evaluations of the objective function nor additional gradient evaluations are required, and the computational complexity per iteration remains at O(d), where d is the problem dimension. On strongly convex functions, our results show a consistent improvement in the number of iterations by up to a factor of 2 with the gradient method and of 1.4 with the heavy ball method across a range of condition numbers."}}
{"id": "OHv-vlgXQOv", "cdate": 1669838472988, "mdate": null, "content": {"title": "Black-Box vs. Gray-Box: A Case Study on Learning Table Tennis Ball Trajectory Prediction with Spin and Impacts", "abstract": "In this paper, we present a method for table tennis ball trajectory filtering and prediction. Our gray-box approach builds on a physical model. At the same time, we use data to learn parameters of the dynamics model, of an extended Kalman filter, and of a neural model that infers the ball's initial condition. We demonstrate superior prediction performance of our approach over two black-box approaches, which are not supplied with physical prior knowledge. We demonstrate that initializing the spin from parameters of the ball launcher using a neural network drastically improves long-time prediction performance over estimating the spin purely from measured ball positions. An accurate prediction of the ball trajectory is crucial for successful returns. We therefore evaluate the return performance with a pneumatic artificial muscular robot and achieve a return rate of 29/30 (97.7%)."}}
{"id": "CTqjKUAyRBt", "cdate": 1652737386370, "mdate": null, "content": {"title": "Sampling without Replacement Leads to Faster Rates in Finite-Sum Minimax Optimization", "abstract": "We analyze the convergence rates of stochastic gradient algorithms for smooth finite-sum minimax optimization and show that, for many such algorithms, sampling the data points \\emph{without replacement} leads to faster convergence compared to sampling with replacement. For the smooth and strongly convex-strongly concave setting, we consider gradient descent ascent and the proximal point method, and present a unified analysis of two popular without-replacement sampling strategies, namely \\emph{Random Reshuffling} (RR), which shuffles the data every epoch, and \\emph{Single Shuffling} or \\emph{Shuffle Once} (SO), which shuffles only at the beginning. We obtain tight convergence rates for RR and SO and demonstrate that these strategies lead to faster convergence than uniform sampling. Moving beyond convexity, we obtain similar results for smooth nonconvex-nonconcave objectives satisfying a two-sided Polyak-\\L{}ojasiewicz inequality. Finally, we demonstrate that our techniques are general enough to analyze the effect of \\emph{data-ordering attacks}, where an adversary manipulates the order in which data points are supplied to the optimizer. Our analysis also recovers tight rates for the \\emph{incremental gradient} method, where the data points are not shuffled at all."}}
{"id": "rJEaU3WubS", "cdate": 1546300800000, "mdate": null, "content": {"title": "A Dynamical Systems Perspective on Nesterov Acceleration", "abstract": "We present a dynamical system framework for understanding Nesterov\u2019s accelerated gradient method. In contrast to earlier work, our derivation does not rely on a vanishing step size argument. We sho..."}}
