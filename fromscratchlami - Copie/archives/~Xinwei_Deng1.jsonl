{"id": "ie-s9xwnWH", "cdate": 1675209600000, "mdate": 1682435098650, "content": {"title": "Challenges of modeling and analysis in cybermanufacturing: a review from a machine learning and computation perspective", "abstract": "In Industry 4.0, smart manufacturing is facing its next stage, cybermanufacturing, founded upon advanced communication, computation, and control infrastructure. Cybermanufacturing will unleash the potential of multi-modal manufacturing data, and provide a new perspective called computation service, as a part of service-oriented architecture (SOA), where on-demand computation requests throughout manufacturing operations are seamlessly satisfied by data analytics and machine learning. However, the complexity of information technology infrastructure leads to fundamental challenges in modeling and analysis under cybermanufacturing, ranging from information-poor datasets to a lack of reproducibility of analytical studies. Nevertheless, existing reviews have focused on the overall architecture of cybermanufacturing/SOA or its technical components (e.g., communication protocol), rather than the potential bottleneck of computation service with respect to modeling and analysis. In this paper, we review the fundamental challenges with respect to modeling and analysis in cybermanufacturing. Then, we introduce the existing efforts in computation pipeline recommendation, which aims at identifying an optimal sequence of method options for data analytics/machine learning without time-consuming trial-and-error. We envision computation pipeline recommendation as a promising research field to address the fundamental challenges in cybermanufacturing. We also expect that computation pipeline recommendation can be a driving force to flexible and resilient manufacturing operations in the post-COVID-19 industry."}}
{"id": "Yc3nDXMbMXe", "cdate": 1672531200000, "mdate": 1682435098283, "content": {"title": "JST-RR Model: Joint Modeling of Ratings and Reviews in Sentiment-Topic Prediction", "abstract": "Analysis of online reviews has attracted great attention with broad applications. Often times, the textual reviews are coupled with the numerical ratings in the data. In this work, we propose a pro..."}}
{"id": "M-seILmeISn", "cdate": 1652737627009, "mdate": null, "content": {"title": "Tight Mutual Information Estimation With Contrastive Fenchel-Legendre Optimization", "abstract": "Successful applications of InfoNCE (Information Noise-Contrastive Estimation) and its variants have popularized the use of contrastive variational mutual information (MI) estimators in machine learning . While featuring superior stability, these estimators crucially depend on costly large-batch training, and they sacrifice bound tightness for variance reduction. To overcome these limitations, we revisit the mathematics of popular variational MI bounds from the lens of unnormalized statistical modeling and convex optimization. Our investigation yields a new unified theoretical framework encompassing popular variational MI bounds, and leads to a novel, simple, and powerful contrastive MI estimator we name FLO. Theoretically, we show that the FLO estimator is tight, and it converges under stochastic gradient descent. Empirically, the proposed FLO estimator overcomes the limitations of its predecessors and learns more efficiently. The utility of FLO is verified using extensive benchmarks, and we further inspire the community with novel applications in meta-learning. Our presentation underscores the foundational importance of variational MI estimation in data-efficient learning."}}
{"id": "w6cT3ZQOWDU", "cdate": 1640995200000, "mdate": 1682435098310, "content": {"title": "Building degradation index with variable selection for multivariate sensory data", "abstract": ""}}
{"id": "btdtU8XtoB6", "cdate": 1640995200000, "mdate": 1682435098281, "content": {"title": "A generative approach to modeling data with quantitative and qualitative responses", "abstract": ""}}
{"id": "YTLpc_KjTZK", "cdate": 1640995200000, "mdate": 1682435099024, "content": {"title": "Boosting Sensitivity of Large-scale Online Experimentation via Dropout Buyer Imputation", "abstract": "In online experimentation, appropriate metrics (e.g., purchase) provide strong evidence to support hypotheses and enhance the decision-making process. However, incomplete metrics are frequently occurred in the online experimentation, making the available data to be much fewer than the planned online experiments (e.g., A/B testing). In this work, we introduce the concept of dropout buyers and categorize users with incomplete metric values into two groups: visitors and dropout buyers. For the analysis of incomplete metrics, we propose a clustering-based imputation method using $k$-nearest neighbors. Our proposed imputation method considers both the experiment-specific features and users' activities along their shopping paths, allowing different imputation values for different users. To facilitate efficient imputation of large-scale data sets in online experimentation, the proposed method uses a combination of stratification and clustering. The performance of the proposed method is compared to several conventional methods in both simulation studies and a real online experiment at eBay."}}
{"id": "YDq8MvDW3L", "cdate": 1640995200000, "mdate": 1682435098161, "content": {"title": "A Bayesian Uncertainty Quantification Approach for Agent-Based Modeling of Networked Anagram Games", "abstract": "In group anagram games, players cooperate to form words by sharing letters that they are initially given. The aim is to form as many words as possible as a group, within five minutes. Players take several different actions: requesting letters from their neighbors, replying to letter requests, and forming words. Agent-based models (ABMs) for the game compute likelihoods of each player's next action, which contain uncertainty, as they are estimated from experimental data. We adopt a Bayesian approach as a natural means of quantifying uncertainty, to enhance the ABM for the group anagram game. Specifically, a Bayesian nonparametric clustering method is used to group player behaviors into different clusters without pre-specifying the number of clusters. Bayesian multi-nominal regression is adopted to model the transition probabilities among different actions of the players in the ABM. We describe the methodology and the benefits of it, and perform agent-based simulations of the game."}}
{"id": "AOOB3Rp1tF", "cdate": 1640995200000, "mdate": 1682435098399, "content": {"title": "A Parallel Tempering Approach for Efficient Exploration of the Verification Tradespace in Engineered Systems", "abstract": "Verification is a critical process in the development of engineered systems. Through verification, engineers gain confidence in the correct functionality of the system before it is deployed into operation. Traditionally, verification strategies are fixed at the beginning of the system\u2019s development and verification activities (VAs) are executed as the development progresses. Such an approach appears to give inferior results as the selection of the VAs does not leverage information gained through the system\u2019s development process. In contrast, a set-based design (SBD) approach to verification, where VAs are dynamically selected as the system\u2019s development progresses, has been shown to provide superior results. However, its application under realistic engineering scenarios remains unproven due to the large size of the verification tradespace. In this work, we propose a parallel tempering approach (PTA) to efficiently explore the verification tradespace. First, we formulate an exploration of the verification tradespace as a tree search problem. Second, we design a parallel tempering (PT) algorithm by simulating several replicas of the verification process at different temperatures to obtain a near-optimal result. Third, We apply the PT algorithm to all possible verification states to dynamically identify near-optimal results. The effectiveness of the proposed PTA is evaluated on a partial model of a notional satellite optical instrument."}}
{"id": "7P0ay5j5xtT", "cdate": 1640995200000, "mdate": 1682435098108, "content": {"title": "A UCB-based Tree Search Approach to Joint Verification-Correction Strategy for Large Scale Systems", "abstract": "Verification planning is a sequential decision-making problem that specifies a set of verification activities (VA) and correction activities (CA) at different phases of system development. While VAs are used to identify errors and defects, CAs also play important roles in system verification as they correct the identified errors and defects. However, current planning methods only consider VAs as decision choices. Because VAs and CAs have different activity spaces, planning a joint verification-correction strategy (JVCS) is still challenging, especially for large-size systems. Here we introduce a UCB-based tree search approach to search for near-optimal JVCSs. First, verification planning is simplified as repeatable bandit problems and an upper confidence bound rule for repeatable bandits (UCBRB) is presented with the optimal regret bound. Next, a tree search algorithm is proposed to search for feasible JVCSs. A tree-based ensemble learning model is also used to extend the tree search algorithm to handle local optimality issues. The proposed approach is evaluated on the notional case of a communication system."}}
{"id": "rIZYyikAOOz", "cdate": 1609459200000, "mdate": 1682435098310, "content": {"title": "A Parallel Tempering Approach for Efficient Exploration of the Verification Tradespace in Engineered Systems", "abstract": "Verification is a critical process in the development of engineered systems. Through verification, engineers gain confidence in the correct functionality of the system before it is deployed into operation. Traditionally, verification strategies are fixed at the beginning of the system's development and verification activities are executed as the development progresses. Such an approach appears to give inferior results as the selection of the verification activities does not leverage information gained through the system's development process. In contrast, a set-based design approach to verification, where verification activities are dynamically selected as the system's development progresses, has been shown to provide superior results. However, its application under realistic engineering scenarios remains unproven due to the large size of the verification tradespace. In this work, we propose a parallel tempering approach (PTA) to efficiently explore the verification tradespace. First, we formulate exploration of the verification tradespace as a tree search problem. Second, we design a parallel tempering (PT) algorithm by simulating several replicas of the verification process at different temperatures to obtain a near-optimal result. Third, We apply the PT algorithm to all possible verification states to dynamically identify near-optimal results. The effectiveness of the proposed PTA is evaluated on a partial model of a notional satellite optical instrument."}}
