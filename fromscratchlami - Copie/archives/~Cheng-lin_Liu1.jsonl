{"id": "9_Vk_vu2-yb", "cdate": 1683883362965, "mdate": 1683883362965, "content": {"title": "An Algorithm for Maximum Common Subgraph of Planar Triangulation Graphs", "abstract": "We propose a new fast algorithm for solving the Maximum Common Subgraph (MCS) problem. MCS is an NP-complete problem. In this paper, we focus on a special class of graphs, i.e. Planar Triangulation Graphs, which are commonly used in computer vision, pattern recognition and graphics. By exploiting the properties of Planar Triangulation Graphs and restricting the problem to connected MCS, for two such graphs of size n and m and their maximum common subgraph of size k, our algorithm solves the MCS problem approximately with time complexity O(nmk)."}}
{"id": "DDlFN5ULsI", "cdate": 1683883257718, "mdate": 1683883257718, "content": {"title": "A Fast Projected Fixed-Point Algorithm for Large Graph Matching", "abstract": "We propose a fast approximate algorithm for large graph matching. A new projected fixed-point method is defined and a new doubly stochastic projection is adopted to derive the algorithm. Previous graph matching algorithms suffer from high computational complexity and therefore do not have good scalability with respect to graph size. For matching two weighted graphs of n nodes, our algorithm has time complexity only O(n3) per iteration and space complexity O(n2). In addition to its scalability, our algorithm is easy to implement, robust, and able to match undirected weighted attributed graphs of different sizes. While the convergence rate of previous iterative graph matching algorithms is unknown, our algorithm is theoretically guaranteed to converge at a linear rate. Extensive experiments on large synthetic and real graphs (more than 1,000 nodes) were conducted to evaluate the performance of various algorithms. Results show that in most cases our proposed algorithm achieves better performance than previous state-of-the-art algorithms in terms of both speed and accuracy in large graph matching. In particular, with high accuracy, our algorithm takes only a few seconds (in a PC) to match two graphs of 1,000 nodes."}}
{"id": "J_kUIC1DNHJ", "cdate": 1663849995914, "mdate": null, "content": {"title": "Dynamic Loss for Learning with Label Noise", "abstract": "Label noise is verified seriously harmful to deep neural networks (DNNs). A simple and scalable strategy to handle this problem is to design robust loss functions, which improve generalization in the presence of label noise by reconciling fitting ability with robustness. However, the widely-used static trade-off between the two contradicts the dynamics of DNNs learning with label noise, leading to an inferior performance. Therefore, in this paper, we propose a dynamic loss function to solve this problem. Specifically, DNNs tend to first learn generalized patterns, then gradually overfit label noise. In light of this, we make fitting ability stronger initially, then gradually increase the weight of robustness. Moreover, we let DNNs put more emphasis on easy examples than hard ones at the later stage since the former are correctly labeled with a higher probability, further reducing the negative impact of label noise. Extensive experimental results on various benchmark datasets demonstrate the state-of-the-art performance of our method. We will open-source our code very soon."}}
{"id": "qWhajfmKEUt", "cdate": 1632875653220, "mdate": null, "content": {"title": "Delving into Feature Space: Improving Adversarial Robustness by Feature Spectral Regularization", "abstract": "The study of adversarial examples in deep neural networks has attracted great attention. Numerous methods are proposed to eliminate the gap of features between natural examples and adversarial examples. Nevertheless, every feature may play a different role in adversarial robustness. It is worth exploring which feature is more beneficial for robustness. In this paper, we delve into this problem from the perspective of spectral analysis in feature space. We define a new metric to measure the change of features along eigenvectors under adversarial attacks. One key finding is that eigenvectors with smaller eigenvalues are more non-robust, i.e., adversary adds more components along such directions. We attribute this phenomenon to the dominance of the top eigenvalues. To alleviate this problem, we propose a method called \\textit{Feature Spectral Regularization (FSR)} to penalize the largest eigenvalue, and as a result, the other smaller eigenvalues get increased relatively. Comprehensive experiments demonstrate that FSR is effective to alleviate the dominance of larger eigenvalues and improve adversarial robustness on different datasets. Our codes will be publicly available soon."}}
{"id": "8dqEeFuhgMG", "cdate": 1621629841054, "mdate": null, "content": {"title": "Class-Incremental Learning via Dual Augmentation", "abstract": "Deep learning systems typically suffer from catastrophic forgetting of past knowledge when acquiring new skills continually. In this paper, we emphasize two dilemmas, representation bias and classifier bias in class-incremental learning, and present a simple and novel approach that employs explicit class augmentation (classAug) and implicit semantic augmentation (semanAug) to address the two biases, respectively. On the one hand, we propose to address the representation bias by learning transferable and diverse representations. Specifically, we investigate the feature representations in incremental learning based on spectral analysis and present a simple technique called classAug, to let the model see more classes during training for learning representations transferable across classes. On the other hand, to overcome the classifier bias, semanAug implicitly involves the simultaneous generating of an infinite number of instances of old classes in the deep feature space, which poses tighter constraints to maintain the decision boundary of previously learned classes. Without storing any old samples, our method can perform comparably with representative data replay based approaches."}}
{"id": "sWMF2rf9nQt", "cdate": 1601308127948, "mdate": null, "content": {"title": "Misclassification Detection via Class Augmentation", "abstract": "Despite the impressive performance in various pattern recognition tasks, deep neural networks (DNNs) are typically overconfident in their predictions, making it difficult to determine whether a test example is misclassified. In this paper, we propose a simple yet effective method of class augmentation (classAug) to address the challenge of misclassification detection in DNNs. Specifically, we increase the number of classes during training by assigning new classes to the samples generated using between-class interpolation. In spite of the simplicity, extensive experiments demonstrate that the misclassification detection performance of DNNs can be significantly improved by seeing more generated pseudo-classes during training. Additionally, we observe that DNNs trained with classAug are more robust on out-of-distribution examples and better calibrated. Finally, as a general regularization strategy, classAug can also enhance the original classification accuracy and few-shot learning performance."}}
{"id": "BjlxD_g7lO6H", "cdate": 1546300800000, "mdate": null, "content": {"title": "Arbitrary Shape Scene Text Detection With Adaptive Text Region Representation.", "abstract": "Scene text detection attracts much attention in computer vision, because it can be widely used in many applications such as real-time text translation, automatic information entry, blind person assistance, robot sensing and so on. Though many methods have been proposed for horizontal and oriented texts, detecting irregular shape texts such as curved texts is still a challenging problem. To solve the problem, we propose a robust scene text detection method with adaptive text region representation. Given an input image, a text region proposal network is first used for extracting text proposals. Then, these proposals are verified and refined with a refinement network. Here, recurrent neural network based adaptive text region representation is proposed for text region refinement, where a pair of boundary points are predicted each time step until no new points are found. In this way, text regions of arbitrary shapes are detected and represented with adaptive number of boundary points. This gives more accurate description of text regions. Experimental results on five benchmarks, namely, CTW1500, TotalText, ICDAR2013, ICDAR2015 and MSRA-TD500, show that the proposed method achieves state-of-the-art in scene text detection."}}
{"id": "BiWbHXMxO6H", "cdate": 1546300800000, "mdate": null, "content": {"title": "Data-Distortion Guided Self-Distillation for Deep Neural Networks.", "abstract": "Knowledge distillation is an effective technique that has been widely used for transferring knowledge from a network to another network. Despite its effective improvement of network performance, the dependence of accompanying assistive models complicates the training process of single network in the need of large memory and time cost. In this paper, we design a more elegant self-distillation mechanism to transfer knowledge between different distorted versions of same training data without the reliance on accompanying models. Specifically, the potential capacity of single network is excavated by learning consistent global feature distributions and posterior distributions (class probabilities) across these distorted versions of data. Extensive experiments on multiple datasets (i.e., CIFAR-10/100 and ImageNet) demonstrate that the proposed method can effectively improve the generalization performance of various network architectures (such as AlexNet, ResNet, Wide ResNet, and DenseNet), outperform existing distillation methods with little extra training efforts."}}
{"id": "ryEyGAbdbB", "cdate": 1514764800000, "mdate": null, "content": {"title": "Robust Classification With Convolutional Prototype Learning", "abstract": "Convolutional neural networks (CNNs) have been widely used for image classification. Despite its high accuracies, CNN has been shown to be easily fooled by some adversarial examples, indicating that CNN is not robust enough for pattern classification. In this paper, we argue that the lack of robustness for CNN is caused by the softmax layer, which is a totally discriminative model and based on the assumption of closed world (i.e., with a fixed number of categories). To improve the robustness, we propose a novel learning framework called convolutional prototype learning (CPL). The advantage of using prototypes is that it can well handle the open world recognition problem and therefore improve the robustness. Under the framework of CPL, we design multiple classification criteria to train the network. Moreover, a prototype loss (PL) is proposed as a regularization to improve the intra-class compactness of the feature representation, which can be viewed as a generative model based on the Gaussian assumption of different classes. Experiments on several datasets demonstrate that CPL can achieve comparable or even better results than traditional CNN, and from the robustness perspective, CPL shows great advantages for both the rejection and incremental category learning tasks."}}
{"id": "S1N3pNz_WS", "cdate": 1514764800000, "mdate": null, "content": {"title": "Multi-task Layout Analysis for Historical Handwritten Documents Using Fully Convolutional Networks", "abstract": "Layout analysis is a fundamental process in document image analysis and understanding.\u00a0It consists of several sub-processes such as page segmentation, text line segmentation, baseline detection and so on.\u00a0In this work, we propose a multi-task layout analysis method that use a single FCN model to solve the above three problems simultaneously.\u00a0The FCN is trained to segment the document image into different regions and detect the center line of each text line by classifying pixels into different categories.\u00a0By supervised learning on document images with pixel-wise labels, the FCN can extract discriminative features and perform pixel-wise classification accurately.\u00a0After pixel-wise classification, post-processing steps are taken to reduce noises, correct wrong segmentations and find out overlapping regions.\u00a0Experimental results on the public dataset DIVA-HisDB containing challenging medieval manuscripts demonstrate the effectiveness and superiority of the proposed method."}}
