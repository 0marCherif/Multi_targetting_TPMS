{"id": "twxJX_jqmh", "cdate": 1640995200000, "mdate": 1682777621238, "content": {"title": "Reliable Offline Model-based Optimization for Industrial Process Control", "abstract": "In the research area of offline model-based optimization, novel and promising methods are frequently developed. However, implementing such methods in real-world industrial systems such as production lines for process control is oftentimes a frustrating process. In this work, we address two important problems to extend the current success of offline model-based optimization to industrial process control problems: 1) how to learn a reliable dynamics model from offline data for industrial processes? 2) how to learn a reliable but not over-conservative control policy from offline data by utilizing existing model-based optimization algorithms? Specifically, we propose a dynamics model based on ensemble of conditional generative adversarial networks to achieve accurate reward calculation in industrial scenarios. Furthermore, we propose an epistemic-uncertainty-penalized reward evaluation function which can effectively avoid giving over-estimated rewards to out-of-distribution inputs during the learning/searching of the optimal control policy. We provide extensive experiments with the proposed method on two representative cases (a discrete control case and a continuous control case), showing that our method compares favorably to several baselines in offline policy learning for industrial process control."}}
{"id": "9Yvj3ZuPHk1", "cdate": 1546300800000, "mdate": null, "content": {"title": "A Model-Based Investigating of the Biological Origin of Human Social Perception of Faces", "abstract": "Humans readily form social impressions of faces at a glance, whether assessing trustworthiness, attractiveness, or dominance. However, little is understood about how such computations are carried out neurally. Here, we leverage a computational model of human face perception to quantify and characterize the extent to which macaque monkey face patch neurons encode information relevant for social trait perception. Specifically, we use a social trait prediction model to estimate the social trait ratings for face stimuli viewed by monkeys during a neural recording experiment. We find that, while the monkey face patch neurons are linearly tuned to facial features different from those used by humans to make social judgments, the subspace spanned by the face patch neurons and the subspace spanned by the facial features supporting human social perception are highly overlapping. This result implies that the information present in the monkey face patch neurons are largely sufficient, after linear decoding, to support human social perception, thus shedding light on the biological origin of human social processing of faces."}}
{"id": "BJ-g79Zu-B", "cdate": 1514764800000, "mdate": null, "content": {"title": "Multiple-Gaze Geometry: Inferring Novel 3D Locations from Gazes Observed in Monocular Video", "abstract": "We develop using person gaze direction for scene understanding. In particular, we use intersecting gazes to learn 3D locations that people tend to look at, which is analogous to having multiple camera views. The 3D locations that we discover need not be visible to the camera. Conversely, knowing 3D locations of scene elements that draw visual attention, such as other people in the scene, can help infer gaze direction. We provide a Bayesian generative model for the temporal scene that captures the joint probability of camera parameters, locations of people, their gaze, what they are looking at, and locations of visual attention. Both the number of people in the scene and the number of extra objects that draw attention are unknown and need to be inferred. To execute this joint inference we use a probabilistic data association approach that enables principled comparison of model hypotheses. We use MCMC for inference over the discrete correspondence variables, and approximate the marginalization over continuous parameters using the Metropolis-Laplace approximation, using Hamiltonian (Hybrid) Monte Carlo for maximization. As existing data sets do not provide the 3D locations of what people are looking at, we contribute a small data set that does. On this data set, we infer what people are looking at with 59% precision compared with 13% for a baseline approach, and where those objects are within about 0.58\u00a0m."}}
{"id": "HkbHbhbd-B", "cdate": 1420070400000, "mdate": null, "content": {"title": "Moderated and Drifting Linear Dynamical Systems", "abstract": "We consider linear dynamical systems, particularly coupled linear oscillators, where the parameters represent meaningful values in a domain theory and thus learning what affects them contributes to..."}}
{"id": "DB-rfEIrpXE", "cdate": 1388534400000, "mdate": 1682777621145, "content": {"title": "Action Recognition in the Frequency Domain", "abstract": "In this paper, we describe a simple strategy for mitigating variability in temporal data series by shifting focus onto long-term, frequency domain features that are less susceptible to variability. We apply this method to the human action recognition task and demonstrate how working in the frequency domain can yield good recognition features for commonly used optical flow and articulated pose features, which are highly sensitive to small differences in motion, viewpoint, dynamic backgrounds, occlusion and other sources of variability. We show how these frequency-based features can be used in combination with a simple forest classifier to achieve good and robust results on the popular KTH Actions dataset."}}
{"id": "B1WrjWf_WH", "cdate": 1356998400000, "mdate": null, "content": {"title": "Bayesian 3D Tracking from Monocular Video", "abstract": "We develop a Bayesian modeling approach for tracking people in 3D from monocular video with unknown cameras. Modeling in 3D provides natural explanations for occlusions and smoothness discontinuities that result from projection, and allows priors on velocity and smoothness to be grounded in physical quantities: meters and seconds vs. pixels and frames. We pose the problem in the context of data association, in which observations are assigned to tracks. A correct application of Bayesian inference to multi-target tracking must address the fact that the model's dimension changes as tracks are added or removed, and thus, posterior densities of different hypotheses are not comparable. We address this by marginalizing out the trajectory parameters so the resulting posterior over data associations has constant dimension. This is made tractable by using (a) Gaussian process priors for smooth trajectories and (b) approximately Gaussian likelihood functions. Our approach provides a principled method for incorporating multiple sources of evidence, we present results using both optical flow and object detector outputs. Results are comparable to recent work on 3D tracking and, unlike others, our method requires no pre-calibrated cameras."}}
{"id": "BJ4AakGubS", "cdate": 1293840000000, "mdate": null, "content": {"title": "Sampling bedrooms", "abstract": "We propose a top down approach for understanding indoor scenes such as bedrooms and living rooms. These environments typically have the Manhattan world property that many surfaces are parallel to three principle ones. Further, the 3D geometry of the room and objects within it can largely be approximated by non overlapping simple structures such as single blocks (e.g. the room boundary), thin blocks (e.g. picture frames), and objects that are well modeled by single blocks (e.g. simple beds). We separately model the 3D geometry, the imaging process (camera parameters), and edge likelihood, to provide a generative statistical model for image data. We fit this model using data driven MCMC sampling. We combine reversible jump Metropolis Hastings samples for discrete changes in the model such as the number of blocks, and stochastic dynamics to estimate continuous parameter values in a particular parameter space that includes block positions, block sizes, and camera parameters. We tested our approach on two datasets using room box pixel orientation. Despite using only bounding box geometry and, in particular, not training on appearance, our method achieves results approaching those of others. We also introduce a new evaluation method for this domain based on ground truth camera parameters, which we found to be more sensitive to the task of understanding scene geometry."}}
