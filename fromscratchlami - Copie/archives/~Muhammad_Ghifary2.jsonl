{"id": "tVbgqcuicG", "cdate": 1640995200000, "mdate": 1682340930854, "content": {"title": "FDLS: A Deep Learning Approach to Production Quality, Controllable, and Retargetable Facial Performances", "abstract": ""}}
{"id": "bosE0zNunhz", "cdate": 1483228800000, "mdate": 1682340930705, "content": {"title": "Scatter Component Analysis: A Unified Framework for Domain Adaptation and Domain Generalization", "abstract": ""}}
{"id": "SjjZYbSxupB", "cdate": 1483228800000, "mdate": null, "content": {"title": "Scatter Component Analysis: A Unified Framework for Domain Adaptation and Domain Generalization.", "abstract": "This paper addresses classification tasks on a particular target domain in which labeled training data are only available from source domains different from (but related to) the target. Two closely related frameworks, domain adaptation and domain generalization, are concerned with such tasks, where the only difference between those frameworks is the availability of the unlabeled target data: domain adaptation can leverage unlabeled target information, while domain generalization cannot. We propose Scatter Component Analyis (SCA), a fast representation learning algorithm that can be applied to both domain adaptation and domain generalization. SCA is based on a simple geometrical measure, i.e., scatter, which operates on reproducing kernel Hilbert space. SCA finds a representation that trades between maximizing the separability of classes, minimizing the mismatch between domains, and maximizing the separability of data; each of which is quantified through scatter. The optimization problem of SCA can be reduced to a generalized eigenvalue problem, which results in a fast and exact solution. Comprehensive experiments on benchmark cross-domain object recognition datasets verify that SCA performs much faster than several state-of-the-art algorithms and also provides state-of-the-art classification accuracy in both domain adaptation and domain generalization. We also show that scatter can be used to establish a theoretical generalization bound in the case of domain adaptation."}}
{"id": "xqsKc5uT9z", "cdate": 1451606400000, "mdate": 1682340930737, "content": {"title": "Deep Reconstruction-Classification Networks for Unsupervised Domain Adaptation", "abstract": ""}}
{"id": "Zr8CxwAHhU", "cdate": 1451606400000, "mdate": 1682340930704, "content": {"title": "Strongly-Typed Recurrent Neural Networks", "abstract": ""}}
{"id": "Bybk8qWuZB", "cdate": 1451606400000, "mdate": null, "content": {"title": "Deep Reconstruction-Classification Networks for Unsupervised Domain Adaptation", "abstract": "In this paper, we propose a novel unsupervised domain adaptation algorithm based on deep learning for visual object recognition. Specifically, we design a new model called Deep Reconstruction-Classification Network (DRCN), which jointly learns a shared encoding representation for two tasks: (i) supervised classification of labeled source data, and (ii) unsupervised reconstruction of unlabeled target data. In this way, the learnt representation not only preserves discriminability, but also encodes useful information from the target domain. Our new DRCN model can be optimized by using backpropagation similarly as the standard neural networks. We evaluate the performance of $$ DRCN $$ on a series of cross-domain object recognition tasks, where $$ DRCN $$ provides a considerable improvement (up\u00a0to $$\\sim $$ 8 $$\\%$$ in accuracy) over the prior state-of-the-art algorithms. Interestingly, we also observe that the reconstruction pipeline of $$ DRCN $$ transforms images from the source domain into images whose appearance resembles the target dataset. This suggests that $$ DRCN $$ \u2019s performance is due to constructing a single composite representation that encodes information about both the structure of target images and the classification of source images. Finally, we provide a formal analysis to justify the algorithm\u2019s objective in domain adaptation context."}}
{"id": "BkNsp9Z_br", "cdate": 1451606400000, "mdate": null, "content": {"title": "Strongly-Typed Recurrent Neural Networks", "abstract": "Recurrent neural networks are increasing popular models for sequential learning. Unfortunately, although the most effective RNN architectures are perhaps excessively complicated, extensive searches..."}}
{"id": "4JlXi3nC8Zu", "cdate": 1451606400000, "mdate": 1682340930697, "content": {"title": "Domain Adaptation and Domain Generalization with Representation Learning", "abstract": ""}}
{"id": "kgIDmYTbDZ", "cdate": 1420070400000, "mdate": 1682340930706, "content": {"title": "Scatter Component Analysis: A Unified Framework for Domain Adaptation and Domain Generalization", "abstract": ""}}
{"id": "HyV3AxfdbH", "cdate": 1420070400000, "mdate": null, "content": {"title": "Domain Generalization for Object Recognition with Multi-task Autoencoders", "abstract": "The problem of domain generalization is to take knowledge acquired from a number of related domains, where training data is available, and to then successfully apply it to previously unseen domains. We propose a new feature learning algorithm, Multi-Task Autoencoder (MTAE), that provides good generalization performance for cross-domain object recognition. The algorithm extends the standard denoising autoencoder framework by substituting artificially induced corruption with naturally occurring inter-domain variability in the appearance of objects. Instead of reconstructing images from noisy versions, MTAE learns to transform the original image into analogs in multiple related domains. It thereby learns features that are robust to variations across domains. The learnt features are then used as inputs to a classifier. We evaluated the performance of the algorithm on benchmark image recognition datasets, where the task is to learn features from multiple datasets and to then predict the image label from unseen datasets. We found that (denoising) MTAE outperforms alternative autoencoder-based models as well as the current state-of-the-art algorithms for domain generalization."}}
