{"id": "Gs3Wc7d_GnJ", "cdate": 1680013206679, "mdate": 1680013206679, "content": {"title": "Teaching Ethics by Teaching Ethics Pedagogy", "abstract": "We report on a reformulated general Ethics and Robotics course, in which we aim to address the twin curricular challenges of exposing computer science students to ethics discourse and establishing a pathway for ethics-oriented modules to be designed into numerous computer science courses across an institution. Given computer science instructors' lack of time and expertise to build ethics modules themselves, we tasked our students with creating ethics modules for instructors of 11 computer science courses at our university. Our course participants represented a diverse range of backgrounds and perspectives that catalyzed lively discussions and creative ideas for ethics pedagogy innovation. We report on course details, including in-class activities, assignments, and the project. We discuss our findings, including reception from students and computer science instructors and planned updates for the next course iteration. Given the course's overall success, we share with the hope that others may learn from or adopt our course approach. Materials are available on our website: https://vdean.github.io/16-735-ethics-robotics.html."}}
{"id": "xsV08dSxLl7", "cdate": 1667893314802, "mdate": null, "content": {"title": "Train Offline, Test Online: A Real Robot Learning Benchmark", "abstract": "Three challenges limit the progress of robot learning research: robots are expensive (few labs can participate), everyone uses different robots (findings do not generalize across labs), and we lack internet-scale robotics data. We take on these challenges via a new benchmark: Train Offline, Test Online (TOTO). TOTO provides remote users with access to shared robots for evaluating methods on common tasks and an open-source dataset of these tasks for offline training. Its manipulation task suite requires challenging generalization to unseen objects, positions, and lighting. We present initial results on TOTO comparing five pretrained visual representations and four offline policy learning baselines, remotely contributed by five institutions. The real promise of TOTO, however, lies in the future: we release the benchmark for additional submissions from any user, enabling easy, direct comparison to several methods without the need to obtain hardware or collect data."}}
{"id": "mw8pn4OPmd6", "cdate": 1665866745450, "mdate": null, "content": {"title": "Train Offline, Test Online: A Real Robot Learning Benchmark", "abstract": "Three challenges limit the progress of robot learning research: robots are expensive (few labs can participate), everyone uses different robots (findings do not generalize across labs), and we lack internet-scale robotics data. We take on these challenges via a new benchmark: Train Offline, Test Online (TOTO). TOTO provides remote users with access to shared robots for evaluating methods on common tasks and an open-source dataset of these tasks for offline training. Its manipulation task suite requires challenging generalization to unseen objects, positions, and lighting. We present initial results on TOTO comparing five pretrained visual representations and four offline policy learning baselines, remotely contributed by five institutions. The real promise of TOTO, however, lies in the future: we release the benchmark for additional submissions from any user, enabling easy, direct comparison to several methods without the need to obtain hardware or collect data."}}
{"id": "eqrVnNgkYWZ", "cdate": 1665251236112, "mdate": null, "content": {"title": "Train Offline, Test Online: A Real Robot Learning Benchmark", "abstract": "Three challenges limit the progress of robot learning research: robots are expensive (few labs can participate), everyone uses different robots (findings do not generalize across labs), and we lack internet-scale robotics data. We take on these challenges via a new benchmark: Train Offline, Test Online (TOTO). TOTO provides remote users with access to shared robots for evaluating methods on common tasks and an open-source dataset of these tasks for offline training. Its manipulation task suite requires challenging generalization to unseen objects, positions, and lighting. We present initial results on TOTO comparing five pretrained visual representations and four offline policy learning baselines, remotely contributed by five institutions. The real promise of TOTO, however, lies in the future: we release the benchmark for additional submissions from any user, enabling easy, direct comparison to several methods without the need to obtain hardware or collect data."}}
{"id": "1knXvMHFU_U", "cdate": 1664994276231, "mdate": null, "content": {"title": "Train Offline, Test Online: A Real Robot Learning Benchmark", "abstract": "Three challenges limit the progress of robot learning research: robots are expensive (few labs can participate), everyone uses different robots (findings do not generalize across labs), and we lack internet-scale robotics data. We take on these challenges via a new benchmark: Train Offline, Test Online (TOTO). TOTO provides remote users with access to shared robots for evaluating methods on common tasks and an open-source dataset of these tasks for offline training. Its manipulation task suite requires challenging generalization to unseen objects, positions, and lighting. We present initial results on TOTO comparing five pretrained visual representations and four offline policy learning baselines, remotely contributed by five institutions. The real promise of TOTO, however, lies in the future: we release the benchmark for additional submissions from any user, enabling easy, direct comparison to several methods without the need to obtain hardware or collect data."}}
{"id": "VMspd1RnI_0", "cdate": 1664928791728, "mdate": null, "content": {"title": "Train Offline, Test Online: A Real Robot Learning Benchmark ", "abstract": "Three challenges limit the progress of robot learning research: robots are expensive (few labs can participate), everyone uses different robots (findings do not generalize across labs), and we lack internet-scale robotics data. We take on these challenges via a new benchmark: Train Offline, Test Online (TOTO). TOTO provides remote users with access to shared robots for evaluating methods on common tasks and an open-source dataset of these tasks for offline training. Its manipulation task suite requires challenging generalization to unseen objects, positions, and lighting. We present initial results on TOTO comparing five pretrained visual representations and four offline policy learning baselines, remotely contributed by five institutions. The real promise of TOTO, however, lies in the future: we release the benchmark for additional submissions from any user, enabling easy, direct comparison to several methods without the need to obtain hardware or collect data."}}
{"id": "HBHMrQD-LZc", "cdate": 1646823196751, "mdate": null, "content": {"title": "Don't Freeze Your Embedding: Lessons from Policy Finetuning in Environment Transfer", "abstract": "A common occurrence in reinforcement learning (RL) research is making use of a pretrained vision stack that converts image observations to latent vectors. Using a visual embedding in this way leaves open questions, though: should the vision stack be updated with the policy? In this work, we evaluate the effectiveness of such decisions in RL transfer settings. We introduce policy update formulations for use after pretraining in a different environment and analyze the performance of such formulations. Through this evaluation, we also detail emergent metrics of benchmark suites and present results on Atari and AndroidEnv."}}
{"id": "HtbfC4pNJbc", "cdate": 1646378293748, "mdate": null, "content": {"title": "Don't Freeze Your Embedding: Lessons from Policy Finetuning in Environment Transfer", "abstract": "A common occurrence in reinforcement learning (RL) research is making use of a pretrained vision stack that converts image observations to latent vectors. Using a visual embedding in this way leaves open questions, though: should the vision stack be updated with the policy? In this work, we evaluate the effectiveness of such decisions in RL transfer settings. We introduce policy update formulations for use after pretraining in a different environment and analyze the performance of such formulations. Through this evaluation, we also detail emergent metrics of benchmark suites and present results on Atari and AndroidEnv."}}
{"id": "DdglKo8hBq0", "cdate": 1633790968773, "mdate": null, "content": {"title": "KitchenShift: Evaluating Zero-Shot Generalization of Imitation-Based Policy Learning Under Domain Shifts", "abstract": "Humans are remarkably capable of zero-shot generalizing while performing tasks in new settings, even when the task is learned entirely from observing others. In this work, we show that current imitation-based policy learning methods do not share this capability, lacking robustness to minor shifts in the training environment. To demonstrate these limitations of current methods, we propose a testing protocol that new methods may use as a benchmark. We implement and evaluate KitchenShift, an instance of our testing protocol that applies domain shifts to a realistic kitchen environment. We train policies from RGB image observations using a set of demonstrations for a multi-stage robotic manipulation task in the kitchen environment. Using KitchenShift, we evaluate imitation and representation learning methods used in current policy learning approaches and find that they are not robust to visual changes in the scene (e.g., lighting, camera view) or changes in the environment state (e.g., orientation of an object). With our benchmark, we hope to encourage the development of algorithms that can generalize under such domain shifts and overcome the challenges preventing robots from completing tasks in diverse everyday settings.\n"}}
{"id": "W_TkB-1eNbs", "cdate": 1626186665845, "mdate": null, "content": {"title": "Robots on Demand: A Democratized Robotics Research Cloud", "abstract": "Robotics research is slowed by three challenges: building a robotics lab is expensive (few participants), everyone uses different robots (participants\u2019 findings often don\u2019t generalize outside their lab), and there is no internet-scale robotics dataset (no lab has the resources to make many robots do many different tasks to generate data and there is no data in the wild). The solution is to build a \u201cRobotics Research Cloud\u201d consisting of centers filled with remotely operable robots in standardized environments. This would be a valuable resource in pushing forward robot learning as a field by making cutting-edge robotics research broadly accessible, helping the field identify promising new approaches that succeed on agreed benchmarks, and creating a massive real-world robotics dataset similar to those that have revolutionized machine learning for vision and language."}}
