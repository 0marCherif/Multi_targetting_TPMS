{"id": "aofq4EIibka", "cdate": 1675952729413, "mdate": 1675952729413, "content": {"title": "The Shape of Learning Curves: a Review", "abstract": "Learning curves provide insight into the dependence of a learner's generalization performance on the training set size. This important tool can be used for model selection, to predict the effect of more training data, and to reduce the computational complexity of model training and hyperparameter tuning. This review recounts the origins of the term, provides a formal definition of the learning curve, and briefly covers basics such as its estimation. Our main contribution is a comprehensive overview of the literature regarding the shape of learning curves. We discuss empirical and theoretical evidence that supports well-behaved curves that often have the shape of a power law or an exponential. We consider the learning curves of Gaussian processes, the complex shapes they can display, and the factors influencing them. We draw specific attention to examples of learning curves that are ill-behaved, showing worse learning performance with more training data. To wrap up, we point out various open problems that warrant deeper empirical and theoretical investigation. All in all, our review underscores that learning curves are surprisingly diverse and no universal model can be identified."}}
{"id": "IJaDnBblIhG", "cdate": 1675952374590, "mdate": 1675952374590, "content": {"title": "A Survey of Learning Curves with Bad Behavior: or How More Data Need Not Lead to Better Performance", "abstract": "Plotting a learner\u2019s generalization performance against the training set size results in a\nso-called learning curve. This tool, providing insight in the behavior of the learner, is also\npractically valuable for model selection, predicting the effect of more training data, and\nreducing the computational complexity of training. We set out to make the (ideal) learning\ncurve concept precise and briefly discuss the aforementioned usages of such curves. The\nlarger part of this survey\u2019s focus, however, is on learning curves that show that more data does\nnot necessarily leads to better generalization performance. A result that seems surprising to\nmany researchers in the field of artificial intelligence. We point out the significance of these\nfindings and conclude our survey with an overview and discussion of open problems in this\narea that warrant further theoretical and empirical investigation."}}
{"id": "Cm7SOkSo59", "cdate": 1675952148017, "mdate": null, "content": {"title": "A Brief Prehistory of Double Descent", "abstract": "n/a"}}
{"id": "zvS0Mxffax8", "cdate": 1640995200000, "mdate": 1681657816057, "content": {"title": "LCDB 1.0: An Extensive Learning Curves Database for Classification Tasks", "abstract": "The use of learning curves for decision making in supervised machine learning is standard practice, yet understanding of their behavior is rather limited. To facilitate a deepening of our knowledge, we introduce the Learning Curve Database (LCDB), which contains empirical learning curves of 20 classification algorithms on 246 datasets. One of the LCDB\u2019s unique strength is that it contains all (probabilistic) predictions, which allows for building learning curves of arbitrary metrics. Moreover, it unifies the properties of similar high quality databases in that it (i) defines clean splits between training, validation, and test data, (ii) provides training times, and (iii) provides an API for convenient access (pip install lcdb). We demonstrate the utility of LCDB by analyzing some learning curve phenomena, such as convexity, monotonicity, peaking, and curve shapes. Improving our understanding of these matters is essential for efficient use of learning curves for model selection, speeding up model training, and to determine the value of more training data."}}
{"id": "LYZDVGXCm1", "cdate": 1640995200000, "mdate": 1681657815877, "content": {"title": "A Survey of Learning Curves with Bad Behavior: or How More Data Need Not Lead to Better Performance", "abstract": "Plotting a learner's generalization performance against the training set size results in a so-called learning curve. This tool, providing insight in the behavior of the learner, is also practically valuable for model selection, predicting the effect of more training data, and reducing the computational complexity of training. We set out to make the (ideal) learning curve concept precise and briefly discuss the aforementioned usages of such curves. The larger part of this survey's focus, however, is on learning curves that show that more data does not necessarily leads to better generalization performance. A result that seems surprising to many researchers in the field of artificial intelligence. We point out the significance of these findings and conclude our survey with an overview and discussion of open problems in this area that warrant further theoretical and empirical investigation."}}
{"id": "4svYnPzfQWg", "cdate": 1609459200000, "mdate": null, "content": {"title": "The Shape of Learning Curves: a Review", "abstract": "Learning curves provide insight into the dependence of a learner's generalization performance on the training set size. This important tool can be used for model selection, to predict the effect of more training data, and to reduce the computational complexity of model training and hyperparameter tuning. This review recounts the origins of the term, provides a formal definition of the learning curve, and briefly covers basics such as its estimation. Our main contribution is a comprehensive overview of the literature regarding the shape of learning curves. We discuss empirical and theoretical evidence that supports well-behaved curves that often have the shape of a power law or an exponential. We consider the learning curves of Gaussian processes, the complex shapes they can display, and the factors influencing them. We draw specific attention to examples of learning curves that are ill-behaved, showing worse learning performance with more training data. To wrap up, we point out various open problems that warrant deeper empirical and theoretical investigation. All in all, our review underscores that learning curves are surprisingly diverse and no universal model can be identified."}}
{"id": "xhc9TcK8qEG", "cdate": 1577836800000, "mdate": 1681657816058, "content": {"title": "Making Learners (More) Monotone", "abstract": ""}}
{"id": "lb6MsYrvNs8", "cdate": 1577836800000, "mdate": null, "content": {"title": "Making Learners (More) Monotone.", "abstract": "Learning performance can show non-monotonic behavior. That is, more data does not necessarily lead to better models, even on average. We propose three algorithms that take a supervised learning model and make it perform more monotone. We prove consistency and monotonicity with high probability, and evaluate the algorithms on scenarios where non-monotone behaviour occurs. Our proposed algorithm $$\\text {MT}_{\\text {HT}}$$ makes less than $$1\\%$$ non-monotone decisions on MNIST while staying competitive in terms of error rate compared to several baselines. Our code is available at https://github.com/tomviering/monotone ."}}
{"id": "RjbJWnuugI", "cdate": 1577836800000, "mdate": null, "content": {"title": "A Distribution Dependent and Independent Complexity Analysis of Manifold Regularization", "abstract": "Manifold regularization is a commonly used technique in semi-supervised learning. It enforces the classification rule to be smooth with respect to the data-manifold. Here, we derive sample complexity bounds based on pseudo-dimension for models that add a convex data dependent regularization term to a supervised learning process, as is in particular done in Manifold regularization. We then compare the bound for those semi-supervised methods to purely supervised methods, and discuss a setting in which the semi-supervised method can only have a constant improvement, ignoring logarithmic terms. By viewing Manifold regularization as a kernel method we then derive Rademacher bounds which allow for a distribution dependent analysis. Finally we illustrate that these bounds may be useful for choosing an appropriate manifold regularization parameter in situations with very sparsely labeled data."}}
{"id": "MnHfSuU23yC", "cdate": 1577836800000, "mdate": null, "content": {"title": "A Brief Prehistory of Double Descent", "abstract": "In their thought-provoking paper [1], Belkin et al. illustrate and discuss the shape of risk curves in the context of modern high-complexity learners. Given a fixed training sample size $n$, such curves show the risk of a learner as a function of some (approximate) measure of its complexity $N$. With $N$ the number of features, these curves are also referred to as feature curves. A salient observation in [1] is that these curves can display, what they call, double descent: with increasing $N$, the risk initially decreases, attains a minimum, and then increases until $N$ equals $n$, where the training data is fitted perfectly. Increasing $N$ even further, the risk decreases a second and final time, creating a peak at $N=n$. This twofold descent may come as a surprise, but as opposed to what [1] reports, it has not been overlooked historically. Our letter draws attention to some original, earlier findings, of interest to contemporary machine learning."}}
