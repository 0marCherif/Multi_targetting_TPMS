{"id": "pHALSh6fQ8", "cdate": 1672531200000, "mdate": 1681661366029, "content": {"title": "Material-agnostic Shaping of Granular Materials with Optimal Transport", "abstract": "From construction materials, such as sand or asphalt, to kitchen ingredients, like rice, sugar, or salt; the world is full of granular materials. Despite impressive progress in robotic manipulation, manipulating and interacting with granular material remains a challenge due to difficulties in perceiving, representing, modelling, and planning for these variable materials that have complex internal dynamics. While some prior work has looked into estimating or learning accurate dynamics models for granular materials, the literature is still missing a more abstract planning method that can be used for planning manipulation actions for granular materials with unknown material properties. In this work, we leverage tools from optimal transport and connect them to robot motion planning. We propose a heuristics-based sweep planner that does not require knowledge of the material's properties and directly uses a height map representation to generate promising sweeps. These sweeps transform granular material from arbitrary start shapes into arbitrary target shapes. We apply the sweep planner in a fast and reactive feedback loop and avoid the need for model-based planning over multiple time steps. We validate our approach with a large set of simulation and hardware experiments where we show that our method is capable of efficiently solving several complex tasks, including gathering, separating, and shaping of several types of granular materials into different target shapes."}}
{"id": "_h2KbrCuUN", "cdate": 1672531200000, "mdate": 1681661365862, "content": {"title": "Obstacle avoidance using raycasting and Riemannian Motion Policies at kHz rates for MAVs", "abstract": "In this paper, we present a novel method for using Riemannian Motion Policies on volumetric maps, shown in the example of obstacle avoidance for Micro Aerial Vehicles (MAVs). While sampling or optimization-based planners are widely used for obstacle avoidance with volumetric maps, they are computationally expensive and often have inflexible monolithic architectures. Riemannian Motion Policies are a modular, parallelizable, and efficient navigation paradigm but are challenging to use with the widely used voxel-based environment representations. We propose using GPU raycasting and a large number of concurrent policies to provide direct obstacle avoidance using Riemannian Motion Policies in voxelized maps without the need for smoothing or pre-processing of the map. Additionally, we present how the same method can directly plan on LiDAR scans without the need for an intermediate map. We show how this reactive approach compares favorably to traditional planning methods and is able to plan using thousands of rays at kilohertz rates. We demonstrate the planner successfully on a real MAV for static and dynamic obstacles. The presented planner is made available as an open-source software package."}}
{"id": "ugZs1PQQtH", "cdate": 1640995200000, "mdate": 1655296783859, "content": {"title": "NavDreams: Towards Camera-Only RL Navigation Among Humans", "abstract": "Autonomously navigating a robot in everyday crowded spaces requires solving complex perception and planning challenges. When using only monocular image sensor data as input, classical two-dimensional planning approaches cannot be used. While images present a significant challenge when it comes to perception and planning, they also allow capturing potentially important details, such as complex geometry, body movement, and other visual cues. In order to successfully solve the navigation task from only images, algorithms must be able to model the scene and its dynamics using only this channel of information. We investigate whether the world model concept, which has shown state-of-the-art results for modeling and learning policies in Atari games as well as promising results in 2D LiDAR-based crowd navigation, can also be applied to the camera-based navigation problem. To this end, we create simulated environments where a robot must navigate past static and moving humans without colliding in order to reach its goal. We find that state-of-the-art methods are able to achieve success in solving the navigation problem, and can generate dream-like predictions of future image-sequences which show consistent geometry and moving persons. We are also able to show that policy performance in our high-fidelity sim2real simulation scenario transfers to the real world by testing the policy on a real robot. We make our simulator, models and experiments available at https://github.com/danieldugas/NavDreams."}}
{"id": "sn9dOHLgV1", "cdate": 1640995200000, "mdate": 1681661366199, "content": {"title": "Reactive Motion Planning for Rope Manipulation and Collision Avoidance using Aerial Robots", "abstract": "In this work we address the challenging problem of manipulating a flexible link, like a rope, with an aerial robot. Inspired by spraying tasks in construction and maintenance scenarios, we consider the case in which an autonomous end-effector (e.g., a spray nozzle moved by a robot or a human operator) is connected to a fixed point by a rope (e.g., a hose). To avoid collisions between the rope and the environment while the end-effector moves, we propose the use of an aerial robot as a flying companion to properly manipulate the rope away from collisions. The aerial robot is attached to the rope between the end-effector and the fixed point. Assuming no direct control of the end-effector (e.g., when operated by a human), we design a reactive and fast motion planner for the aerial robot. Grounding on the theory of Forced Geometric Fabrics, we design a motion planner that generates trajectories to drive the aerial robot to follow the end-effector, while manipulating the rope to avoid collisions in cluttered environments. To include the complex behavior of the flexible link, we propose a rope model that estimates its real-time state under forces and position-based interactions, as well as collisions with obstacle surfaces. Finally, we evaluate the system behavior and the motion planner performance in simulations, as well as in real-world experiments on an original spray painting application."}}
{"id": "o9_n6I1ZXc", "cdate": 1640995200000, "mdate": 1681661366200, "content": {"title": "Fast and Compute-efficient Sampling-based Local Exploration Planning via Distribution Learning", "abstract": "Exploration is a fundamental problem in robotics. While sampling-based planners have shown high performance, they are oftentimes compute intensive and can exhibit high variance. To this end, we propose to directly learn the underlying distribution of informative views based on the spatial context in the robot's map. We further explore a variety of methods to also learn the information gain. We show in thorough experimental evaluation that our proposed system improves exploration performance by up to 28% over classical methods, and find that learning the gains in addition to the sampling distribution can provide favorable performance vs. compute trade-offs for compute-constrained systems. We demonstrate in simulation and on a low-cost mobile robot that our system generalizes well to varying environments."}}
{"id": "haMwPE_41Uw", "cdate": 1640995200000, "mdate": 1681661366031, "content": {"title": "NavDreams: Towards Camera-Only RL Navigation Among Humans", "abstract": "Autonomously navigating a robot in everyday crowded spaces requires solving complex perception and planning challenges. When using only monocular image sensor data as input, classical two-dimensional planning approaches cannot be used. While images present a significant challenge when it comes to perception and planning, they also allow capturing potentially important details, such as complex geometry, body movement, and other visual cues. In order to successfully solve the navigation task from only images, algorithms must be able to model the scene and its dynamics using only this channel of information. We investigate whether the world model concept, which has shown state-of-the-art results for modeling and learning policies in Atari games as well as promising results in 2D LiDAR-based crowd navigation, can also be applied to the camera-based navigation problem. To this end, we create simulated environments where a robot must navigate past static and moving humans without colliding in order to reach its goal. We find that state-of-the-art methods are able to achieve success in solving the navigation problem, and can generate dream-like predictions of future image-sequences which show consistent geometry and moving persons. We are also able to show that policy performance in our high-fidelity sim2real simulation scenario transfers to the real world by testing the policy on a real robot. We make our simulator, models and experiments available at https://github.com/danieldugas/NavDreams."}}
{"id": "giSlkSjLeW", "cdate": 1640995200000, "mdate": 1681661366030, "content": {"title": "CERBERUS in the DARPA Subterranean Challenge", "abstract": "This article presents the core technologies and deployment strategies of Team CERBERUS that enabled our winning run in the DARPA Subterranean Challenge finals. CERBERUS is a robotic system-of-syste..."}}
{"id": "c2U03Ge3wby", "cdate": 1640995200000, "mdate": 1667225806410, "content": {"title": "Fast and Compute-Efficient Sampling-Based Local Exploration Planning via Distribution Learning", "abstract": "Exploration is a fundamental problem in robotics. While sampling-based planners have shown high performance and robustness, they are oftentimes compute intensive and can exhibit high variance. To this end, we propose to learn both components of sampling-based exploration. We present a method to directly learn an underlying informed distribution of views based on the spatial context in the robot\u2019s map, and further explore a variety of methods to also learn the information gain of each sample. We show in thorough experimental evaluation that our proposed system improves exploration performance by up to 28% over classical methods, and find that learning the gains in addition to the sampling distribution can provide favorable performance vs. compute trade-offs for compute-constrained systems. We demonstrate in simulation and on a low-cost mobile robot that our system generalizes well to varying environments."}}
{"id": "IQNuVftCsL", "cdate": 1640995200000, "mdate": 1681661366043, "content": {"title": "FlowBot: Flow-based Modeling for Robot Navigation", "abstract": "Autonomous navigation among people is a com-plex problem that also exhibits considerable variation depending on the type of environment and people involved. Here we consider navigation among crowds that exhibit flow-like behavior like people moving through a train station. We propose a novel pseudo-fluid model of crowd flow for such problems. These have an intuitive physical interpretation and do not require much tuning. We further formalize an observation model to infer flow properties from discrete sensor observations, including support for partial observability, and pair it with a flow-aware planner. We demonstrate the potential of the approach in simulated navigation scenarios. We achieve state of the art results on the CrowdBot navigation benchmark, and also compare favorably against a standard ROS planner on a partially observable environment, demonstrating that the flow-aware planner successfully estimates and plans around counter-flows in the crowd in real time. We conclude that flow-based planning shows great promise for crowded environments that may exhibit such flow-like behavior."}}
{"id": "32D9_UejaV", "cdate": 1640995200000, "mdate": 1681504275366, "content": {"title": "Team CERBERUS Wins the DARPA Subterranean Challenge: Technical Overview and Lessons Learned", "abstract": ""}}
