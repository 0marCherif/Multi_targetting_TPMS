{"id": "D5YtDU5urAN", "cdate": 1420070400000, "mdate": 1632904967797, "content": {"title": "Large-scale Classification and Retrieval of 3D Shapes; Opzoeking en classificatie van 3D objecten op grote schaal", "abstract": ""}}
{"id": "BJ-7Qp-_ZH", "cdate": 1420070400000, "mdate": null, "content": {"title": "3D all the way: Semantic segmentation of urban scenes from start to end in 3D", "abstract": "We propose a new approach for semantic segmentation of 3D city models. Starting from an SfM reconstruction of a street-side scene, we perform classification and facade splitting purely in 3D, obviating the need for slow image-based semantic segmentation methods. We show that a properly trained pure-3D approach produces high quality labelings, with significant speed benefits (20x faster) allowing us to analyze entire streets in a matter of minutes. Additionally, if speed is not of the essence, the 3D labeling can be combined with the results of a state-of-the-art 2D classifier, further boosting the performance. Further, we propose a novel facade separation based on semantic nuances between facades. Finally, inspired by the use of architectural principles for 2D facade labeling, we propose new 3D-specific principles and an efficient optimization scheme based on an integer quadratic programming formulation."}}
{"id": "bxXq-0zBN7", "cdate": 1356998400000, "mdate": 1632904967798, "content": {"title": "Automatic Shape Expansion with Verification to Improve 3D Retrieval, Classification and Matching", "abstract": "The goal of this paper is to retrieve 3D object models from a database, that are similar to a single 3D object model, given as a query. The system has no prior models of any object class and is class-generic. The approach is fully automated and unsupervised. The main contribution of the paper is to improve the quality of such 3D shape retrieval, through query verification and query expansion. These are part of a cascaded, two-stage system: (i) Verification: after a first inexpensive and coarse retrieval step that uses a standard Bag-of-Words (BoW) over quantized local features, a fast but effective spatial layout verification of those words is used to prune the initial search results. (ii) Expansion: a new BoW query is issued on the basis of an expanded set of query shapes that, next to the original query, also includes the positively verified results of (i). We perform comprehensive evaluation and show improved performance. As an additional novelty, we show the usefulness of the query expansion on shape classification with limited training data and shape matching, domains in which it has not been used before. The experiments were performed on a variety of state-of-the-art datasets."}}
{"id": "JHuM_iCZdM9", "cdate": 1293840000000, "mdate": 1632904967797, "content": {"title": "Class-specific 3D localization using constellations of object parts", "abstract": ""}}
{"id": "EwwmjBOU89p", "cdate": 1293840000000, "mdate": 1632904967599, "content": {"title": "Scene Cut: Class-Specific Object Detection and Segmentation in 3D Scenes", "abstract": "In this paper we present a method to combine the detection and segmentation of object categories from 3D scenes. In the process, we combine the top-down cues available from object detection technique of Implicit Shape Models and the bottom-up power of Markov Random Fields for the purpose of segmentation. While such approaches have been tried for the 2D image problem domain before, this is the first application of such a method in 3D. 3D scene understanding is prone to many problems different from 2D owing to problems from noise, lack of distinctive high-frequency feature information, mesh parametrization problems etc. Our method enables us to localize objects of interest for more purposeful meshing and subsequent scene understanding."}}
{"id": "r1V5QF-dbB", "cdate": 1262304000000, "mdate": null, "content": {"title": "Hough Transform and 3D SURF for Robust Three Dimensional Classification", "abstract": "Most methods for the recognition of shape classes from 3D datasets focus on classifying clean, often manually generated models. However, 3D shapes obtained through acquisition techniques such as Structure-from-Motion or LIDAR scanning are noisy, clutter and holes. In that case global shape features\u2014still dominating the 3D shape class recognition literature\u2014are less appropriate. Inspired by 2D methods, recently researchers have started to work with local features. In keeping with this strand, we propose a new robust 3D shape classification method. It contains two main contributions. First, we extend a robust 2D feature descriptor, SURF, to be used in the context of 3D shapes. Second, we show how 3D shape class recognition can be improved by probabilistic Hough transform based methods, already popular in 2D. Through our experiments on partial shape retrieval, we show the power of the proposed 3D features. Their combination with the Hough transform yields superior results for class recognition on standard datasets. The potential for the applicability of such a method in classifying 3D obtained from Structure-from-Motion methods is promising, as we show in some initial experiments."}}
{"id": "ULrbNw90Xc6", "cdate": 1262304000000, "mdate": 1632904967800, "content": {"title": "Orientation invariant 3D object classification using hough transform based methods", "abstract": "In comparison to the 2D case, object class recognition in 3D is a much less researched area. However, with the advent of affordable 3D acquisition technology and the growing popularity of 3D content, its relevance is steadily increasing. Just as in the 2D case, 3D data is often partial, noisy and without prior segmentation. Moreover, the object is rarely observed in a canonical frame of reference with respect to orientation (or scale). We propose a method, using Hough-voting for local 3D features, which is orientation (and scale) invariant."}}
{"id": "HyW4k9Z_br", "cdate": 1262304000000, "mdate": null, "content": {"title": "Avoiding Confusing Features in Place Recognition", "abstract": "We seek to recognize the place depicted in a query image using a database of \u201cstreet side\u201d images annotated with geolocation information. This is a challenging task due to changes in scale, viewpoint and lighting between the query and the images in the database. One of the key problems in place recognition is the presence of objects such as trees or road markings, which frequently occur in the database and hence cause significant confusion between different places. As the main contribution, we show how to avoid features leading to confusion of particular places by using geotags attached to database images as a form of supervision. We develop a method for automatic detection of image-specific and spatially-localized groups of confusing features, and demonstrate that suppressing them significantly improves place recognition performance while reducing the database size. We show the method combines well with the state of the art bag-of-features model including query expansion, and demonstrate place recognition that generalizes over wide range of viewpoints and lighting conditions. Results are shown on a geotagged database of over 17K images of Paris downloaded from Google Street View."}}
{"id": "rJWfSTZObr", "cdate": 1230768000000, "mdate": null, "content": {"title": "Randomized structure from motion based on atomic 3D models from camera triplets", "abstract": "This paper presents a new efficient technique for large-scale structure from motion from unordered data sets. We avoid costly computation of all pairwise matches and geometries by sampling pairs of images using the pairwise similarity scores based on the detected occurrences of visual words leading to a significant speedup. Furthermore, atomic 3D models reconstructed from camera triplets are used as the seeds which form the final large-scale 3D model when merged together. Using three views instead of two allows us to reveal most of the outliers of pairwise geometries at an early stage of the process hindering them from derogating the quality of the resulting 3D structure at later stages. The accuracy of the proposed technique is shown on a set of 64 images where the result of the exhaustive technique is known. Scalability is demonstrated on a landmark reconstruction from hundreds of images."}}
