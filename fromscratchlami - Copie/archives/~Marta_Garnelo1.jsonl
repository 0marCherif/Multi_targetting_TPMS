{"id": "Sql8oqJTe9", "cdate": 1646226078330, "mdate": null, "content": {"title": "Learning Truthful, Efficient, and Welfare Maximizing Auction Rules", "abstract": "From social networks to supply chains, more and more aspects of how humans, firms and organizations interact is mediated by artificial learning agents. As the influence of machine learning systems grows, it is paramount that we study how to imbue our modern institutions with our own values and principles.\nHere we consider the problem of allocating goods to buyers who have preferences over them in settings where the seller's aim is not to maximize their monetary gains, but rather to advance some notion of social welfare (e.g. the government trying to award construction licenses for hospitals or schools).\nThis problem has a long history in economics, and solutions take the form of auction rules. Researchers have proposed reliable auction rules that work in extremely general settings, and in the presence of information asymmetry and strategic buyers. However, these protocols require significant payments from participants resulting in low aggregate welfare. Here we address this shortcoming by casting auction rule design as a statistical learning problem, and trade generality for participant welfare effectively and automatically with a novel deep learning network architecture and auction representation. Our analysis shows that our auction rules outperform state-of-the art approaches in terms of participants welfare, applicability, robustness."}}
{"id": "Gm2NT9DPX5u", "cdate": 1621872314726, "mdate": null, "content": {"title": "A Limited-Capacity Minimax Theorem for Non-Convex Games or: How I Learned to Stop Worrying about Mixed-Nash and Love Neural Nets", "abstract": "Adversarial training, a special case of multi-objective optimization, is an increasingly prevalent machine learning technique: some of its most notable applications include GAN-based generative modeling and self-play techniques in reinforcement learning which have been applied to complex games such as Go or Poker. In practice, a \\emph{single} pair of networks is typically trained in order to find an approximate equilibrium of a highly nonconcave-nonconvex adversarial problem. However, while a classic result in game theory states such an equilibrium exists in concave-convex games, there is no analogous guarantee if the payoff is nonconcave-nonconvex. Our main contribution is to provide an approximate minimax theorem for a large class of games where the players pick neural networks including WGAN, StarCraft II, and Blotto Game. Our findings rely on the fact that despite being nonconcave-nonconvex with respect to the neural networks parameters, these games are concave-convex with respect to the actual models (e.g., functions or distributions) represented by these neural networks."}}
{"id": "yJiNE8DMpg", "cdate": 1599674225345, "mdate": null, "content": {"title": "A Neural Architecture for Designing Truthful and Efficient Auctions", "abstract": "Auctions are protocols to allocate goods to buyers who have preferences over them,\nand collect payments in return. Economists have invested significant effort in designing auction rules that result in allocations of the goods that are desirable for the\ngroup as a whole. However, for settings where participants\u2019 valuations of the items\non sale are their private information, the rules of the auction must deter buyers\nfrom misreporting their preferences, so as to maximize their own utility, since misreported preferences hinder the ability for the auctioneer to allocate goods to those\nwho want them most. Manual auction design has yielded excellent mechanisms for\nspecific settings, but requires significant effort when tackling new domains. We\npropose a deep learning based approach to automatically design auctions in a wide\nvariety of domains, shifting the design work from human to machine. We assume\nthat participants\u2019 valuations for the items for sale are independently sampled from\nan unknown but fixed distribution. Our system receives a data-set consisting of\nsuch valuation samples, and outputs an auction rule encoding the desired incentive\nstructure. We focus on producing truthful and efficient auctions that minimize\nthe economic burden on participants. We evaluate the auctions designed by our\nframework on well-studied domains, such as multi-unit and combinatorial auctions,\nshowing that they outperform known auction designs in terms of the economic\nburden placed on participants."}}
{"id": "H1gcw1HYPr", "cdate": 1569439585638, "mdate": null, "content": {"title": "AlignNet: Self-supervised Alignment Module", "abstract": "The natural world consists of objects that we perceive as persistent in space and time, even though these objects appear, disappear and reappear in our field of view as we move. This can be attributed to our notion of object persistence -- our knowledge that objects typically continue to exist, even if we can no longer see them -- and our ability to track objects. Drawing inspiration from the psychology literature on `sticky indices', we propose the AlignNet, a model that learns to assign unique indices to new objects when they first appear and reassign the index to subsequent instances of that object. By introducing a persistent object-based memory, the AlignNet may be used to keep track of objects across time, even if they disappear and reappear later. We implement the AlignNet as a graph network applied to a bipartite graph, in which the input nodes are objects from two sets that we wish to align. The network is trained to predict the edges which connect two instances of the same object across sets. The model is also capable of identifying when there are no matches and dealing with these cases. We perform experiments to show the model's ability to deal with the appearance, disappearance and reappearance of objects. Additionally, we demonstrate how a persistent object-based memory can help solve question-answering problems in a partially observable environment."}}
{"id": "ryl1r1BYDS", "cdate": 1569439542578, "mdate": null, "content": {"title": "Multiagent Reinforcement Learning in Games with an Iterated Dominance Solution", "abstract": "Multiagent reinforcement learning (MARL) attempts to optimize policies of intelligent agents interacting in the same environment. However, it may fail to converge to a Nash equilibrium in some games.  We study independent MARL under the more demanding solution concept of iterated elimination of strictly dominated strategies.  In dominance solvable games, if players iteratively eliminate strictly dominated strategies until no further strategies can be eliminated, we obtain a single strategy profile. We show that convergence to the iterated dominance solution is guaranteed for several reinforcement learning algorithms (for multiple independent learners). We illustrate an application of our results by studying mechanism design for principal-agent problems, where a principal wishes to incentivize agents to exert costly effort in a joint project when it can only observe whether the project succeeded, but not whether agents actually exerted effort. We show that MARL converges to the desired outcome if the rewards are designed so that exerting effort is the iterated dominance solution, but fails if it is merely a Nash equilibrium."}}
{"id": "S1l6ITVKPS", "cdate": 1569439060720, "mdate": null, "content": {"title": "An Explicitly Relational Neural Network Architecture", "abstract": "With a view to bridging the gap between deep learning and symbolic AI, we present a novel end-to-end neural network architecture that learns to form propositional representations with an explicitly relational structure from raw pixel data. In order to evaluate and analyse the architecture, we introduce a family of simple visual relational reasoning tasks of varying complexity. We show that the proposed architecture, when pre-trained on a curriculum of such tasks, learns to generate reusable representations that better facilitate subsequent learning on previously unseen tasks when compared to a number of baseline architectures. The workings of a successfully trained model are visualised to shed some light on how the architecture functions."}}
{"id": "B1Z-C9-dbH", "cdate": 1546300800000, "mdate": null, "content": {"title": "Open-ended learning in symmetric zero-sum games", "abstract": "Zero-sum games such as chess and poker are, abstractly, functions that evaluate pairs of agents, for example labeling them \u2018winner\u2019 and \u2018loser\u2019. If the game is approximately transitive, then self-p..."}}
{"id": "S1gQ5sRcFm", "cdate": 1538087818556, "mdate": null, "content": {"title": "Consistent Jumpy Predictions for Videos and Scenes", "abstract": "Stochastic video prediction models take in a sequence of image frames, and generate a sequence of consecutive future image frames. These models typically generate future frames in an autoregressive fashion, which is slow and requires the input and output frames to be consecutive. We introduce a model that overcomes these drawbacks by generating a latent representation from an arbitrary set of frames that can then be used to simultaneously and efficiently sample temporally consistent frames at arbitrary time-points. For example, our model can \"jump\" and directly sample frames at the end of the video, without sampling intermediate frames. Synthetic video evaluations confirm substantial gains in speed and functionality without loss in fidelity. We also apply our framework to a 3D scene reconstruction dataset. Here, our model is conditioned on camera location and can sample consistent sets of images for what an occluded region of a 3D scene might look like, even if there are multiple possibilities for what that region might contain. Reconstructions and videos are available at https://bit.ly/2O4Pc4R.\n"}}
{"id": "ByeSdsC9Km", "cdate": 1538087788771, "mdate": null, "content": {"title": "Adaptive Posterior Learning: few-shot learning with a surprise-based memory module", "abstract": "The ability to generalize quickly from few observations is crucial for intelligent systems. In this paper we introduce APL, an algorithm that approximates probability distributions by remembering the most surprising observations it has encountered. These past observations are recalled from an external memory module and processed by a decoder network that can combine information from different memory slots to generalize beyond direct recall. We show this algorithm can perform as well as state of the art baselines on few-shot classification benchmarks with a smaller memory footprint.  In addition, its memory compression allows it to scale to thousands of unknown labels.  Finally, we introduce a meta-learning reasoning task which is more challenging than direct classification. In this setting, APL is able to generalize with fewer than one example per class via deductive reasoning."}}
{"id": "SkE6PjC9KX", "cdate": 1538087781445, "mdate": null, "content": {"title": "Attentive Neural Processes", "abstract": "Neural Processes (NPs) (Garnelo et al., 2018) approach regression by learning to map a context set of observed input-output pairs to a distribution over regression functions. Each function models the distribution of the output given an input, conditioned on the context. NPs have the benefit of fitting observed data efficiently with linear complexity in the number of context input-output pairs, and can learn a wide family of conditional distributions; they learn predictive distributions conditioned on context sets of arbitrary size. Nonetheless, we show that NPs suffer a fundamental drawback of underfitting, giving inaccurate predictions at the inputs of the observed data they condition on. We address this issue by incorporating attention into NPs, allowing each input location to attend to the relevant context points for the prediction. We show that this greatly improves the accuracy of predictions, results in noticeably faster training, and expands the range of functions that can be modelled. "}}
