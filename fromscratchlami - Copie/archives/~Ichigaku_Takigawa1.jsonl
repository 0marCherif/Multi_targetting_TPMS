{"id": "8vPwzosaN2", "cdate": 1649033135433, "mdate": 1649033135433, "content": {"title": "Edit-Aware Generative Molecular Graph Autocompletion for Scaffold Input", "abstract": "We present a novel molecular graph generation method by auto-completing a privileged scaffold which represents a core graph substructure step-by-step. We propose a generative GNN model thus providing the ability to generate unseen molecular graphs outside the given training set. An edit-aware graph autocomplete- tion paradigm that follows the \u201csubstructure-by-substructure\u201d process is designed to complete the scaffold queries in multiple substructure adopt operations and allow meaningful edit operation to show the user\u2019s intention. Such operations enable the involvement of user decisions when interacting with a generative user-centered AI system, which differentiates our work from existing single-run generation paradigms. We also propose a scaf- fold trie for fast training pair augmentation or changing training models in real-time. Moreover, we design a top-k ranking func- tion which considers the preferences on popularity and diversity for different applications, such as query compositions for graph database and drug discovery respectively. Such techniques en- able human experts to synergistically interact with the generative models grounded on large data."}}
{"id": "7bikJEbFB2Y", "cdate": 1640995200000, "mdate": 1696052053881, "content": {"title": "Interval-Memoized Backtracking on ZDDs for Fast Enumeration of All Lower Cost Solutions", "abstract": "In this paper, we propose a fast method for exactly enumerating a very large number of all lower cost solutions for various combinatorial problems. Our method is based on backtracking for a given decision diagram which represents all the feasible solutions. The main idea is to memoize the intervals of cost bounds to avoid duplicate search in the backtracking process. In contrast to usual pseudo-polynomial-time dynamic programming approaches, the computation time of our method does not directly depend on the total cost values, but is bounded by the input and output size of the decision diagrams. Therefore, it can be much faster if the cost values are large but the input/output decision diagrams are well-compressed. We demonstrate its practical efficiency by comparing our method to current available enumeration methods: for nontrivial size instances of the Hamiltonian path problem, our method succeeded in exactly enumerating billions of all lower cost solutions in a few seconds, which was hundred or much more times faster. Our method can be regarded as a novel search algorithm which integrates the two classical techniques, branch-and-bound and dynamic programming. This method would have many applications in various fields, including operations research, data mining, statistical testing, hardware/software system design, etc."}}
{"id": "Lg2J9OG2djv", "cdate": 1609459200000, "mdate": 1696052053884, "content": {"title": "Fast improvement of TEM image with low-dose electrons by deep learning", "abstract": "Low-electron-dose observation is indispensable for observing various samples using a transmission electron microscope; consequently, image processing has been used to improve transmission electron microscopy (TEM) images. To apply such image processing to in situ observations, we here apply a convolutional neural network to TEM imaging. Using a dataset that includes short-exposure images and long-exposure images, we develop a pipeline for processed short-exposure images, based on end-to-end training. The quality of images acquired with a total dose of approximately 5 e- per pixel becomes comparable to that of images acquired with a total dose of approximately 1000 e- per pixel. Because the conversion time is approximately 8 ms, in situ observation at 125 fps is possible. This imaging technique enables in situ observation of electron-beam-sensitive specimens."}}
{"id": "FnXYk48oz0", "cdate": 1609459200000, "mdate": 1667627174739, "content": {"title": "Minor-embedding heuristics for large-scale annealing processors with sparse hardware graphs of up to 102, 400 nodes", "abstract": "Minor-embedding heuristics have become an indispensable tool for compiling problems in quadratically unconstrained binary optimization (QUBO) into the hardware graphs of quantum and CMOS annealing processors. While recent embedding heuristics have been developed for annealers of moderate size (about 2000 nodes), the size of the latest CMOS annealing processor (with 102,400 nodes) poses entirely new demands on the embedding heuristic. This raises the question, if recent embedding heuristics can maintain meaningful embedding performance on hardware graphs of increasing size. Here, we develop an improved version of the probabilistic-swap-shift-annealing (PSSA) embedding heuristic [which has recently been demonstrated to outperform the standard embedding heuristic by D-Wave Systems (Cai et al. in http://arxiv.org/abs/1406.2741 , 2014)] and evaluate its embedding performance on hardware graphs of increasing size. For random cubic and Bar\u00e1basi\u2013Albert graphs we find the embedding performance of improved PSSA to consistently exceed the threshold of the best known complete graph embedding by a factor of 3.2 and 2.8, respectively, up to hardware graphs with 102,400 nodes. On the other hand, for random graphs with constant edge density not even improved PSSA can overcome the deterministic threshold guaranteed by the existence of the best known complete graph embedding. Finally, we prove a new upper bound on the maximal embeddable size of complete graphs into hardware graphs of CMOS annealers and show that the embedding performance of its currently best known complete graph embedding has optimal order for hardware graphs with fixed coordination number."}}
{"id": "sOvinsM7jShd", "cdate": 1598844485794, "mdate": null, "content": {"title": "Generalized Sparse Learning of Linear Models Over the Complete Subgraph Feature Set", "abstract": "Supervised learning over graphs is an intrinsically difficult problem: simultaneous learning of relevant features from the complete subgraph feature set, in which enumerating all subgraph features occurring in given graphs is practically intractable due to combinatorial explosion. We show that 1) existing graph supervised learning studies, such as Adaboost, LPBoost, and LARS/LASSO, can be viewed as variations of a branch-and-bound algorithm with simple bounds, which we call Morishita-Kudo bounds; 2) We present a direct sparse optimization algorithm for generalized problems with arbitrary twice-differentiable loss functions, to which Morishita-Kudo bounds cannot be directly applied; 3) We experimentally showed that i) our direct optimization method improves the convergence rate and stability, and ii) L1-penalized logistic regression (L1LogReg) by our method identifies a smaller subgraph set, keeping the competitive performance, iii) the learned subgraphs by L1-LogReg are more size-balanced than competing methods, which are biased to small-sized subgraphs."}}
{"id": "4KEnjxRVxg", "cdate": 1585699200000, "mdate": 1696052053900, "content": {"title": "Dual graph convolutional neural network for predicting chemical networks", "abstract": "Background Predicting of chemical compounds is one of the fundamental tasks in bioinformatics and chemoinformatics, because it contributes to various applications in metabolic engineering and drug discovery. The recent rapid growth of the amount of available data has enabled applications of computational approaches such as statistical modeling and machine learning method. Both a set of chemical interactions and chemical compound structures are represented as graphs, and various graph-based approaches including graph convolutional neural networks have been successfully applied to chemical network prediction. However, there was no efficient method that can consider the two different types of graphs in an end-to-end manner. Results We give a new formulation of the chemical network prediction problem as a link prediction problem in a graph of graphs (GoG) which can represent the hierarchical structure consisting of compound graphs and an inter-compound graph. We propose a new graph convolutional neural network architecture called dual graph convolutional network that learns compound representations from both the compound graphs and the inter-compound network in an end-to-end manner. Conclusions Experiments using four chemical networks with different sparsity levels and degree distributions shows that our dual graph convolution approach achieves high prediction performance in relatively dense networks, while the performance becomes inferior on extremely-sparse networks."}}
{"id": "1npdZrbuQeC", "cdate": 1577836800000, "mdate": null, "content": {"title": "Efficiently Enumerating Substrings with Statistically Significant Frequencies of Locally Optimal Occurrences in Gigantic String", "abstract": "We propose new frequent substring pattern mining which can enumerate all substrings with statistically significant frequencies of their locally optimal occurrences from a given single sequence. Our target application is genome sequences, around a half being said to be covered by interspersed and consecutive (tandem) repeats, and detecting these repeats is an important task in molecular life sciences. We evaluate the statistical significance of frequent substrings by using a string generation model with a memoryless stationary information source. We combine this idea with an existing algorithm, ESFLOO-0G.C (Nakamura et al. 2016), to enumerate all statistically significant substrings with locally optimal occurrences. We further develop a parallelized version of our algorithm. Experimental results using synthetic datasets showed the proposed algorithm achieved far higher F-measure in extracting substrings (with various lengths and frequencies) embedded in a randomly generated string with noise, than conventional algorithms. The large-scale experiment using the whole human genome sequence with 3,095,677,412 bases (letters) showed that our parallel algorithm covers 75% of the whole positions analyzed, around 4% and 24% higher than the recent report and the current cutting-edge knowledge, implying a biologically unique finding."}}
{"id": "-EjkZDNhmo1", "cdate": 1577836800000, "mdate": null, "content": {"title": "Minor-embedding heuristics for large-scale annealing processors with sparse hardware graphs of up to 102, 400 nodes", "abstract": "Minor embedding heuristics have become an indispensable tool for compiling problems in quadratically unconstrained binary optimization (QUBO) into the hardware graphs of quantum and CMOS annealing processors. While recent embedding heuristics have been developed for annealers of moderate size (about 2000 nodes) the size of the latest CMOS annealing processor (with 102,400 nodes) poses entirely new demands on the embedding heuristic. This raises the question, if recent embedding heuristics can maintain meaningful embedding performance on hardware graphs of increasing size. Here, we develop an improved version of the probabilistic-swap-shift-annealing (PSSA) embedding heuristic [which has recently been demonstrated to outperform the standard embedding heuristic by D-Wave Systems (Cai et al., 2014)] and evaluate its embedding performance on hardware graphs of increasing size. For random-cubic and Barabasi-Albert graphs we find the embedding performance of improved PSSA to consistently exceed the threshold of the best known complete graph embedding by a factor of 3.2 and 2.8, respectively, up to hardware graphs with 102,400 nodes. On the other hand, for random graphs with constant edge density not even improved PSSA can overcome the deterministic threshold guaranteed by the existence of the best known complete graph embedding. Finally, we prove a new upper bound on the maximal embeddable size of complete graphs into hardware graphs of CMOS annealers and show that the embedding performance of its currently best known complete graph embedding has optimal order for hardware graphs with fixed coordination number."}}
{"id": "KawhBCEVZgF", "cdate": 1546300800000, "mdate": null, "content": {"title": "Learning Relevant Molecular Representations via Self-Attentive Graph Neural Networks", "abstract": "Molecular graphs are one of the established representations for small molecules, and even steric or electronic information can be encoded as node and edge features. Naturally, graph neural networks have been intensively investigated to solve various chemical problems at molecular levels. However, it remains unclear how to encode relevant chemical information into graphs. We investigate this problem by proposing three models of graph neural networks with self-attention mechanisms at different levels to adaptively select relevant chemical information for each input. Using neural graph fingerprint (NFP) as a baseline, we introduce three types of attention mechanisms on the top of NFPs. Our experimental evaluations suggest that introducing these self-attention mechanisms contributes to not only improving the prediction accuracy but also providing quantitative interpretation using obtained attention coefficients."}}
{"id": "A6CEagnq80x", "cdate": 1546300800000, "mdate": 1684040211970, "content": {"title": "Learning Relevant Molecular Representations via Self-Attentive Graph Neural Networks", "abstract": "Molecular graphs are one of the established representations for small molecules, and even steric or electronic information can be encoded as node and edge features. Naturally, graph neural networks have been intensively investigated to solve various chemical problems at molecular levels. However, it remains unclear how to encode relevant chemical information into graphs. We investigate this problem by proposing three models of graph neural networks with self-attention mechanisms at different levels to adaptively select relevant chemical information for each input. Using neural graph fingerprint (NFP) as a baseline, we introduce three types of attention mechanisms on the top of NFPs. Our experimental evaluations suggest that introducing these self-attention mechanisms contributes to not only improving the prediction accuracy but also providing quantitative interpretation using obtained attention coefficients."}}
