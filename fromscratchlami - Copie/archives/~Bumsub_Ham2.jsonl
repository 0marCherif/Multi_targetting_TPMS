{"id": "WBIcl1_POo", "cdate": 1698218164310, "mdate": 1698218164310, "content": {"title": "ACLS: Adaptive and Conditional Label Smoothing for Network Calibration", "abstract": "We address the problem of network calibration adjusting\nmiscalibrated confidences of deep neural networks. Many\napproaches to network calibration adopt a regularizationbased method that exploits a regularization term to smooth\nthe miscalibrated confidences. Although these approaches\nhave shown the effectiveness on calibrating the networks,\nthere is still a lack of understanding on the underlying\nprinciples of regularization in terms of network calibration. We present in this paper an in-depth analysis of existing regularization-based methods, providing a better understanding on how they affect to network calibration. Specifically, we have observed that 1) the regularization-based\nmethods can be interpreted as variants of label smoothing,\nand 2) they do not always behave desirably. Based on the\nanalysis, we introduce a novel loss function, dubbed ACLS,\nthat unifies the merits of existing regularization methods,\nwhile avoiding the limitations. We show extensive experimental results for image classification and semantic segmentation on standard benchmarks, including CIFAR10,\nTiny-ImageNet, ImageNet, and PASCAL VOC, demonstrating the effectiveness of our loss function."}}
{"id": "d7wIO8VI6B", "cdate": 1698218111805, "mdate": 1698218111805, "content": {"title": "RankMixup: Ranking-Based Mixup Training for Network Calibration", "abstract": "Network calibration aims to accurately estimate the level\nof confidences, which is particularly important for employing deep neural networks in real-world systems. Recent approaches leverage mixup to calibrate the network\u2019s predictions during training. However, they do not consider the\nproblem that mixtures of labels in mixup may not accurately\nrepresent the actual distribution of augmented samples. In\nthis paper, we present RankMixup, a novel mixup-based\nframework alleviating the problem of the mixture of labels\nfor network calibration. To this end, we propose to use\nan ordinal ranking relationship between raw and mixupaugmented samples as an alternative supervisory signal to\nthe label mixtures for network calibration. We hypothesize\nthat the network should estimate a higher level of confidence for the raw samples than the augmented ones (Fig.1).\nTo implement this idea, we introduce a mixup-based ranking loss (MRL) that encourages lower confidences for augmented samples compared to raw ones, maintaining the\nranking relationship. We also propose to leverage the ranking relationship among multiple mixup-augmented samples\nto further improve the calibration capability. Augmented\nsamples with larger mixing coefficients are expected to have\nhigher confidences and vice versa (Fig.1). That is, the order\nof confidences should be aligned with that of mixing coefficients. To this end, we introduce a novel loss, M-NDCG, in\norder to reduce the number of misaligned pairs of the coefficients and confidences. Extensive experimental results on\nstandard benchmarks for network calibration demonstrate\nthe effectiveness of RankMixup."}}
{"id": "CnC-WHeT7f", "cdate": 1698218050755, "mdate": 1698218050755, "content": {"title": "Camera-Driven Representation Learning for Unsupervised Domain Adaptive Person Re-identification", "abstract": "We present a novel unsupervised domain adaption\nmethod for person re-identification (reID) that generalizes a\nmodel trained on a labeled source domain to an unlabeled\ntarget domain. We introduce a camera-driven curriculum\nlearning (CaCL) framework that leverages camera labels\nof person images to transfer knowledge from source to target domains progressively. To this end, we divide target domain dataset into multiple subsets based on the camera labels, and initially train our model with a single subset (i.e.,\nimages captured by a single camera). We then gradually\nexploit more subsets for training, according to a curriculum sequence obtained with a camera-driven scheduling\nrule. The scheduler considers maximum mean discrepancies (MMD) between each subset and the source domain\ndataset, such that the subset closer to the source domain is\nexploited earlier within the curriculum. For each curriculum sequence, we generate pseudo labels of person images\nin a target domain to train a reID model in a supervised\nway. We have observed that the pseudo labels are highly\nbiased toward cameras, suggesting that person images obtained from the same camera are likely to have the same\npseudo labels, even for different IDs. To address the camera\nbias problem, we also introduce a camera-diversity (CD)\nloss encouraging person images of the same pseudo label,\nbut captured across various cameras, to involve more for\ndiscriminative feature learning, providing person representations robust to inter-camera variations. Experimental results on standard benchmarks, including real-to-real and\nsynthetic-to-real scenarios, demonstrate the effectiveness of\nour framework."}}
{"id": "0SgKq4ZC9r", "cdate": 1652737611967, "mdate": null, "content": {"title": "Decomposed Knowledge Distillation for Class-Incremental Semantic Segmentation", "abstract": "Class-incremental semantic segmentation (CISS) labels each pixel of an image with a corresponding object/stuff class continually. To this end, it is crucial to learn novel classes incrementally without forgetting previously learned knowledge. Current CISS methods typically use a knowledge distillation (KD) technique for preserving classifier logits, or freeze a feature extractor, to avoid the forgetting problem. The strong constraints, however, prevent learning discriminative features for novel classes. We introduce a CISS framework that alleviates the forgetting problem and facilitates learning novel classes effectively. We have found that a logit can be decomposed into two terms. They quantify how likely an input belongs to a particular class or not, providing a clue for a reasoning process of a model. The KD technique, in this context, preserves the sum of two terms ($\\textit{i.e.}$, a class logit), suggesting that each could be changed and thus the KD does not imitate the reasoning process. To impose constraints on each term explicitly, we propose a new decomposed knowledge distillation (DKD) technique, improving the rigidity of a model and addressing the forgetting problem more effectively. We also introduce a novel initialization method to train new classifiers for novel classes. In CISS, the number of negative training samples for novel classes is not sufficient to discriminate old classes. To mitigate this, we propose to transfer knowledge of negatives to the classifiers successively using an auxiliary classifier, boosting the performance significantly. Experimental results on standard CISS benchmarks demonstrate the effectiveness of our framework."}}
{"id": "_2-r5UurHp", "cdate": 1652737414186, "mdate": null, "content": {"title": "ALIFE: Adaptive Logit Regularizer and Feature Replay for Incremental Semantic Segmentation", "abstract": "We address the problem of incremental semantic segmentation (ISS) recognizing novel object/stuff categories continually without forgetting previous ones that have been learned. The catastrophic forgetting problem is particularly severe in ISS, since pixel-level ground-truth labels are available only for the novel categories at training time. To address the problem, regularization-based methods exploit probability calibration techniques to learn semantic information from unlabeled pixels. While such techniques are effective, there is still a lack of theoretical understanding of them. Replay-based methods propose to memorize a small set of images for previous categories. They achieve state-of-the-art performance at the cost of large memory footprint. We propose in this paper a novel ISS method, dubbed ALIFE, that provides a better compromise between accuracy and efficiency. To this end, we first show an in-depth analysis on the calibration techniques to better understand the effects on ISS. Based on this, we then introduce an adaptive logit regularizer (ALI) that enables our model to better learn new categories, while retaining knowledge for previous ones. We also present a feature replay scheme that memorizes features, instead of images directly, in order to reduce memory requirements significantly. Since a feature extractor is changed continually, memorized features should also be updated at every incremental stage. To handle this, we introduce category-specific rotation matrices updating the features for each category separately. We demonstrate the effectiveness of our approach with extensive experiments on standard ISS benchmarks, and show that our method achieves a better trade-off in terms of accuracy and efficiency."}}
{"id": "dp9gy4Vh6Y", "cdate": 1640995200000, "mdate": 1668181716526, "content": {"title": "Bi-directional Contrastive Learning for Domain Adaptive Semantic Segmentation", "abstract": ""}}
{"id": "ZsgzDEwdTc", "cdate": 1640995200000, "mdate": 1668181716518, "content": {"title": "OIMNet++: Prototypical Normalization and Localization-Aware Learning for Person Search", "abstract": ""}}
{"id": "Axhps5QHqRU", "cdate": 1640995200000, "mdate": 1668181716406, "content": {"title": "Decomposed Knowledge Distillation for Class-Incremental Semantic Segmentation", "abstract": ""}}
{"id": "0SMLNKPFeF", "cdate": 1640995200000, "mdate": 1668181716418, "content": {"title": "ALIFE: Adaptive Logit Regularizer and Feature Replay for Incremental Semantic Segmentation", "abstract": ""}}
{"id": "vQ1bjIgnjJ", "cdate": 1609459200000, "mdate": 1649293108865, "content": {"title": "Exploiting a Joint Embedding Space for Generalized Zero-Shot Semantic Segmentation", "abstract": "We address the problem of generalized zero-shot semantic segmentation (GZS3) predicting pixel-wise semantic labels for seen and unseen classes. Most GZS3 methods adopt a generative approach that synthesizes visual features of unseen classes from corresponding semantic ones (e.g., word2vec) to train novel classifiers for both seen and unseen classes. Although generative methods show decent performance, they have two limitations: (1) the visual features are biased towards seen classes; (2) the classifier should be retrained whenever novel unseen classes appear. We propose a discriminative approach to address these limitations in a unified framework. To this end, we leverage visual and semantic encoders to learn a joint embedding space, where the semantic encoder transforms semantic features to semantic prototypes that act as centers for visual features of corresponding classes. Specifically, we introduce boundary-aware regression (BAR) and semantic consistency (SC) losses to learn discriminative features. Our approach to exploiting the joint embedding space, together with BAR and SC terms, alleviates the seen bias problem. At test time, we avoid the retraining process by exploiting semantic prototypes as a nearest-neighbor (NN) classifier. To further alleviate the bias problem, we also propose an inference technique, dubbed Apollonius calibration (AC), that modulates the decision boundary of the NN classifier to the Apollonius circle adaptively. Experimental results demonstrate the effectiveness of our framework, achieving a new state of the art on standard benchmarks."}}
