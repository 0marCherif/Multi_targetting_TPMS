{"id": "grRmv990tP", "cdate": 1672531200000, "mdate": 1683617933693, "content": {"title": "Quantum Channel Certification with Incoherent Strategies", "abstract": "In the problem of quantum channel certification, we have black box access to a quantum process and would like to decide if this process matches some predefined specification or is $\\varepsilon$-far from this specification. The objective is to achieve this task while minimizing the number of times the black box is used. Here, we focus on optimal incoherent strategies for two relevant extreme cases of channel certification. The first one is when the predefined specification is a unitary channel, e.g., a gate in a quantum circuit. In this case, we show that testing whether the black box is described by a fixed unitary operator in dimension $d$ or $\\varepsilon$-far from it in the trace norm requires $\\Theta(d/\\varepsilon^2)$ uses of the black box. The second setting we consider is when the predefined specification is a completely depolarizing channel with input dimension $d_{\\text{in}}$ and output dimension $d_{\\text{out}}$. In this case, we prove that, in the non-adaptive setting, $\\tilde{\\Theta}(d_{\\text{in}}^2d_{\\text{out}}^{1.5}/\\varepsilon^2)$ uses of the channel are necessary and sufficient to verify whether it is equal to the depolarizing channel or $\\varepsilon$-far from it in the diamond norm. Finally, we prove a lower bound of $\\Omega(d_{\\text{in}}^2d_{\\text{out}}/\\varepsilon^2)$ for this problem in the adaptive setting. Note that the special case $d_{\\text{in}} = 1$ corresponds to the well-studied quantum state certification problem."}}
{"id": "5V9-oioLqv", "cdate": 1672531200000, "mdate": 1683617933690, "content": {"title": "Lower Bounds on Learning Pauli Channels", "abstract": "Understanding the noise affecting a quantum device is of fundamental importance for scaling quantum technologies. A particularly important class of noise models is that of Pauli channels, as randomized compiling techniques can effectively bring any quantum channel to this form and are significantly more structured than general quantum channels. In this paper, we show fundamental lower bounds on the sample complexity for learning Pauli channels in diamond norm with unentangled measurements. We consider both adaptive and non-adaptive strategies. In the non-adaptive setting, we show a lower bound of $\\Omega(2^{3n}\\epsilon^{-2})$ to learn an $n$-qubit Pauli channel. In particular, this shows that the recently introduced learning procedure by Flammia and Wallman is essentially optimal. In the adaptive setting, we show a lower bound of $\\Omega(2^{2.5n}\\epsilon^{-2})$ for $\\epsilon=\\mathcal{O}(2^{-n})$, and a lower bound of $\\Omega(2^{2n}\\epsilon^{-2} )$ for any $\\epsilon > 0$. This last lower bound even applies for arbitrarily many sequential uses of the channel, as long as they are only interspersed with other unital operations."}}
{"id": "-15EjcVHv6o", "cdate": 1640995200000, "mdate": 1683617933696, "content": {"title": "Sequential algorithms for testing identity and closeness of distributions", "abstract": "What advantage do \\emph{sequential} procedures provide over batch algorithms for testing properties of unknown distributions? Focusing on the problem of testing whether two distributions $\\mathcal{D}_1$ and $\\mathcal{D}_2$ on $\\{1,\\dots, n\\}$ are equal or $\\epsilon$-far, we give several answers to this question. We show that for a small alphabet size $n$, there is a sequential algorithm that outperforms any batch algorithm by a factor of at least $4$ in terms sample complexity. For a general alphabet size $n$, we give a sequential algorithm that uses no more samples than its batch counterpart, and possibly fewer if the actual distance $TV(\\mathcal{D}_1, \\mathcal{D}_2)$ between $\\mathcal{D}_1$ and $\\mathcal{D}_2$ is larger than $\\epsilon$. As a corollary, letting $\\epsilon$ go to $0$, we obtain a sequential algorithm for testing closeness when no a priori bound on $TV(\\mathcal{D}_1, \\mathcal{D}_2)$ is given that has a sample complexity $\\tilde{\\mathcal{O}}(\\frac{n^{2/3}}{TV(\\mathcal{D}_1, \\mathcal{D}_2)^{4/3}})$: this improves over the $\\tilde{\\mathcal{O}}(\\frac{n/\\log n}{TV(\\mathcal{D}_1, \\mathcal{D}_2)^{2} })$ tester of \\cite{daskalakis2017optimal} and is optimal up to multiplicative constants. We also establish limitations of sequential algorithms for the problem of testing identity and closeness: they can improve the worst case number of samples by at most a constant factor."}}
{"id": "UDe_F-4EeHd", "cdate": 1621629977603, "mdate": null, "content": {"title": "Sequential Algorithms for Testing Closeness of Distributions", "abstract": "  What advantage do sequential procedures provide over batch algorithms for testing properties of unknown distributions? Focusing on the problem of testing whether two distributions $\\mathcal{D}_1$ and $\\mathcal{D}_2$ on $\\{1,\\dots, n\\}$ are equal or $\\epsilon$-far, we give several answers to this question. We show that for a small alphabet size $n$, there is a sequential algorithm that outperforms any batch algorithm by a factor of at least $4$ in terms sample complexity. For a general alphabet size $n$, we give a sequential algorithm that uses no more samples than its batch counterpart, and possibly fewer if the actual distance between $\\mathcal{D}_1$ and $\\mathcal{D}_2$ is larger than $\\epsilon$. As a corollary, letting $\\epsilon$ go to $0$, we obtain a sequential algorithm for testing closeness (with no a priori bound on the distance between $\\mathcal{D}_1$ and $\\mathcal{D}_2$) with a sample complexity $\\tilde{\\mathcal{O}}(\\frac{n^{2/3}}{TV(\\mathcal{D}_1, \\mathcal{D}_2)^{4/3}})$: this improves over the $\\tilde{\\mathcal{O}}(\\frac{n/\\log n}{TV(\\mathcal{D}_1, \\mathcal{D}_2)^{2} })$ tester of [Daskalakis and Kawase 2017]  and is optimal up to multiplicative constants. We also establish limitations of sequential algorithms for the problem of testing closeness: they can improve the worst case number of samples by at most a constant factor. "}}
{"id": "XD3sPK82W5z", "cdate": 1609459200000, "mdate": 1652268060901, "content": {"title": "Sequential Algorithms for Testing Closeness of Distributions", "abstract": "What advantage do sequential procedures provide over batch algorithms for testing properties of unknown distributions? Focusing on the problem of testing whether two distributions $\\mathcal{D}_1$ and $\\mathcal{D}_2$ on $\\{1,\\dots, n\\}$ are equal or $\\epsilon$-far, we give several answers to this question. We show that for a small alphabet size $n$, there is a sequential algorithm that outperforms any batch algorithm by a factor of at least $4$ in terms sample complexity. For a general alphabet size $n$, we give a sequential algorithm that uses no more samples than its batch counterpart, and possibly fewer if the actual distance between $\\mathcal{D}_1$ and $\\mathcal{D}_2$ is larger than $\\epsilon$. As a corollary, letting $\\epsilon$ go to $0$, we obtain a sequential algorithm for testing closeness (with no a priori bound on the distance between $\\mathcal{D}_1$ and $\\mathcal{D}_2$) with a sample complexity $\\tilde{\\mathcal{O}}(\\frac{n^{2/3}}{TV(\\mathcal{D}_1, \\mathcal{D}_2)^{4/3}})$: this improves over the $\\tilde{\\mathcal{O}}(\\frac{n/\\log n}{TV(\\mathcal{D}_1, \\mathcal{D}_2)^{2} })$ tester of [Daskalakis and Kawase 2017] and is optimal up to multiplicative constants. We also establish limitations of sequential algorithms for the problem of testing closeness: they can improve the worst case number of samples by at most a constant factor."}}
