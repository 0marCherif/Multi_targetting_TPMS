{"id": "ahgY6mHfod", "cdate": 1672531200000, "mdate": 1695949483419, "content": {"title": "Attribute-Efficient PAC Learning of Low-Degree Polynomial Threshold Functions with Nasty Noise", "abstract": "The concept class of low-degree polynomial threshold functions (PTFs) plays a fundamental role in machine learning. In this paper, we study PAC learning of $K$-sparse degree-$d$ PTFs on $\\mathbb{R}..."}}
{"id": "7l0fK2_gXG", "cdate": 1672531200000, "mdate": 1695949483414, "content": {"title": "Semi-Verified PAC Learning from the Crowd", "abstract": "We study the problem of crowdsourced PAC learning of threshold functions. This is a challenging problem and only recently have query-efficient algorithms been established under the assumption that ..."}}
{"id": "PZtIiZ43E2R", "cdate": 1652737346926, "mdate": null, "content": {"title": "List-Decodable Sparse Mean Estimation", "abstract": "Robust mean estimation is one of the most important problems in statistics: given a set of samples in $\\mathbb{R}^d$ where an $\\alpha$ fraction are drawn from some distribution $D$ and the rest are adversarially corrupted, we aim to estimate the mean of $D$. A surge of recent research interest has been focusing on the list-decodable setting where $\\alpha \\in (0, \\frac12]$, and the goal is to output a finite number of estimates among which at least one approximates the target mean. In this paper, we consider that the underlying distribution $D$ is Gaussian with $k$-sparse mean. Our main contribution is the first polynomial-time algorithm that enjoys sample complexity $O\\big(\\mathrm{poly}(k, \\log d)\\big)$, i.e. poly-logarithmic in the dimension. One of our core algorithmic ingredients is using low-degree {\\em sparse polynomials} to filter outliers, which may find more applications."}}
{"id": "osKeXmqyPo5", "cdate": 1640995200000, "mdate": 1681755881642, "content": {"title": "Efficient PAC Learning from the Crowd with Pairwise Comparisons", "abstract": "We study crowdsourced PAC learning of threshold function, where the labels are gathered from a pool of annotators some of whom may behave adversarially. This is yet a challenging problem and until ..."}}
{"id": "AvQSmZNJKJv", "cdate": 1640995200000, "mdate": 1681755881642, "content": {"title": "List-Decodable Sparse Mean Estimation", "abstract": "Robust mean estimation is one of the most important problems in statistics: given a set of samples in $\\mathbb{R}^d$ where an $\\alpha$ fraction are drawn from some distribution $D$ and the rest are adversarially corrupted, we aim to estimate the mean of $D$. A surge of recent research interest has been focusing on the list-decodable setting where $\\alpha \\in (0, \\frac12]$, and the goal is to output a finite number of estimates among which at least one approximates the target mean. In this paper, we consider that the underlying distribution $D$ is Gaussian with $k$-sparse mean. Our main contribution is the first polynomial-time algorithm that enjoys sample complexity $O\\big(\\mathrm{poly}(k, \\log d)\\big)$, i.e. poly-logarithmic in the dimension. One of our core algorithmic ingredients is using low-degree sparse polynomials to filter outliers, which may find more applications."}}
