{"id": "_J1uezt3PYI", "cdate": 1664642336870, "mdate": 1664642336870, "content": {"title": "Training Set Camouflage", "abstract": "We introduce a form of steganography in the domain of machine learning which we call training set camouflage. Imagine Alice has a\ntraining set on an illicit machine learning classification task. Alice wants\nBob (a machine learning system) to learn the task. However, sending\neither the training set or the trained model to Bob can raise suspicion if\nthe communication is monitored. Training set camouflage allows Alice to\ncompute a second training set on a completely different \u2013 and seemingly\nbenign \u2013 classification task. By construction, sending the second training set will not raise suspicion. When Bob applies his standard (public)\nlearning algorithm to the second training set, he approximately recovers\nthe classifier on the original task. Training set camouflage is a novel form\nof steganography in machine learning. We formulate training set camouflage as a combinatorial bilevel optimization problem and propose solvers\nbased on nonlinear programming and local search. Experiments on real\nclassification tasks demonstrate the feasibility of such camouflage."}}
{"id": "tK0luh4jGj", "cdate": 1546300800000, "mdate": null, "content": {"title": "Using Machine Learning to Overcome the Expert Blind Spot for Perceptual Fluency Trainings.", "abstract": "Most STEM domains use multiple visual representations to illustrate complex concepts. While much research has focused on helping students make sense of visuals, students also have to become perceptually fluent at translating among visuals fast and effortlessly. Because perceptual fluency is acquired via implicit, nonverbal processes, perceptual fluency trainings provide simple classification tasks that vary visual features across numerous examples. Prior research shows that learning from such trainings is strongly affected by the sequence of the examples. Further, prior research shows that perceptual fluency trainings are most effective for high-performing students but may confuse low-performing students. We propose that a lack of benefits for low-performing students may result from a perceptual expert blind spot of instructors who typically develop perceptual fluency trainings: expert instructors may be unable to anticipate the needs of students who do not see meaningful information in the visuals. In prior work, we used a machine-learning approach to develop a sequence of example visuals of chemical molecules for low-performing students. This study tested the effectiveness of this sequence in comparison to an expert-generated sequence in a randomized experiment as part of an undergraduate chemistry course. We determined students\u2019 performance based on log data from an educational technology they used in the course. Results show that the machine-learned sequence was more effective for low-performing students. The expert sequence was more effective for high-performing students. Our results can inform the development of perceptual-fluency trainings for adaptive educational technologies."}}
{"id": "L5UBSTraXa8", "cdate": 1546300800000, "mdate": null, "content": {"title": "Should Adversarial Attacks Use Pixel p-Norm?", "abstract": "Adversarial attacks aim to confound machine learning systems, while remaining virtually imperceptible to humans. Attacks on image classification systems are typically gauged in terms of $p$-norm distortions in the pixel feature space. We perform a behavioral study, demonstrating that the pixel $p$-norm for any $0\\le p \\le \\infty$, and several alternative measures including earth mover's distance, structural similarity index, and deep net embedding, do not fit human perception. Our result has the potential to improve the understanding of adversarial attack and defense strategies."}}
{"id": "zGLrmJCfPbt", "cdate": 1514764800000, "mdate": null, "content": {"title": "Training Set Camouflage.", "abstract": "We introduce a form of steganography in the domain of machine learning which we call training set camouflage. Imagine Alice has a training set on an illicit machine learning classification task. Alice wants Bob (a machine learning system) to learn the task. However, sending either the training set or the trained model to Bob can raise suspicion if the communication is monitored. Training set camouflage allows Alice to compute a second training set on a completely different -- and seemingly benign -- classification task. By construction, sending the second training set will not raise suspicion. When Bob applies his standard (public) learning algorithm to the second training set, he approximately recovers the classifier on the original task. Training set camouflage is a novel form of steganography in machine learning. We formulate training set camouflage as a combinatorial bilevel optimization problem and propose solvers based on nonlinear programming and local search. Experiments on real classification tasks demonstrate the feasibility of such camouflage."}}
{"id": "huyqi1iV-d2", "cdate": 1514764800000, "mdate": null, "content": {"title": "Machine Beats Human at Sequencing Visuals for Perceptual-Fluency Practice.", "abstract": ""}}
{"id": "BoO_yYLFZa8", "cdate": 1514764800000, "mdate": null, "content": {"title": "For Teaching Perceptual Fluency, Machines Beat Human Experts.", "abstract": "In STEM domains, students are expected to acquire domain knowledge from visual representations that they may not yet be able to interpret. Such learning requires perceptual fluency, or the ability to intuitively and rapidly see the underlying concepts in visuals and to translate between them. Perceptual fluency is acquired via nonverbal, implicit learning processes. Thus far, we have lacked a principled approach for identifying a sequence of perceptual fluency problems that promote robust learning. Here, we describe how a novel machine learning technique can generate an optimal sequence of perceptual fluency problems. In a human experiment, we show that a machine-generated sequence outperforms both a random sequence and a sequence generated by a human domain expert. Interestingly, the machine-generated sequence resulted in significantly lower accuracy during training, but higher posttest accuracy. This suggests that the machine-generated sequence induced desirable difficulties. To our knowledge, our study is the first to show that machine learning can yield desirable difficulties for perceptual learning."}}
{"id": "43pipedvNhP", "cdate": 1514764800000, "mdate": null, "content": {"title": "Training Set Camouflage.", "abstract": "We introduce a form of steganography in the domain of machine learning which we call training set camouflage. Imagine Alice has a training set on an illicit machine learning classification task. Alice wants Bob (a machine learning system) to learn the task. However, sending either the training set or the trained model to Bob can raise suspicion if the communication is monitored. Training set camouflage allows Alice to compute a second training set on a completely different \u2013 and seemingly benign \u2013 classification task. By construction, sending the second training set will not raise suspicion. When Bob applies his standard (public) learning algorithm to the second training set, he approximately recovers the classifier on the original task. Training set camouflage is a novel form of steganography in machine learning. We formulate training set camouflage as a combinatorial bilevel optimization problem and propose solvers based on nonlinear programming and local search. Experiments on real classification tasks demonstrate the feasibility of such camouflage."}}
{"id": "RkILRjvnURb", "cdate": 1483228800000, "mdate": null, "content": {"title": "Palindromic Subsequence Automata and Longest Common Palindromic Subsequence.", "abstract": "In this paper, we present a novel weighted finite automaton called palindromic subsequence automaton (PSA) that is a compact representation of all the palindromic subsequences of a string. Then we use PSA to solve the longest common palindromic subsequence problem. Our automata based algorithms are efficient both in theory and in practice."}}
{"id": "mG4_v4Cpgh", "cdate": 1451606400000, "mdate": null, "content": {"title": "Binarization With Boosting and Oversampling for Multiclass Classification.", "abstract": "Using a set of binary classifiers to solve multiclass classification problems has been a popular approach over the years. The decision boundaries learnt by binary classifiers (also called base classifiers) are much simpler than those learnt by multiclass classifiers. This paper proposes a new classification framework, termed binarization with boosting and oversampling (BBO), for efficiently solving multiclass classification problems. The new framework is devised based on the one-versus-all (OVA) binarization technique. Unlike most previous work, BBO employs boosting for solving the hard-to-learn instances and oversampling for handling the class-imbalance problem arising due to OVA binarization. These two features make BBO different from other existing works. Our new framework has been tested extensively on several multiclass supervised and semi-supervised classification problems using five different base classifiers, including neural networks, C4.5, k-nearest neighbor, repeated incremental pruning to produce error reduction, support vector machine, random forest, and learning with local and global consistency. Experimental results show that BBO can exhibit better performance compared to its counterparts on supervised and semi-supervised classification problems."}}
{"id": "dQTcUin5xo7", "cdate": 1420070400000, "mdate": null, "content": {"title": "MARQUES: Distributed multi-attribute range query solution using space filling curve on DTHs.", "abstract": "This paper proposes a distributed peer-to-peer data lookup technique on DHTs in order to serve range queries over multiple attributes. The scheme, MARQUES, uses space filling curves to map multi-attribute data points to a one-dimensional key space and thus effectively converts multi-attribute range queries into a consecutive series of one-dimensional keys. These keys are then used to place or lookup data objects over a DHT. Space filling curves preserve locality of attribute values and thus helps greatly in facilitating range queries in terms of the number of nodes to be searched to serve a given range query. MARQUES, although can be instrumented with any space filling curve, has been implemented with two curves, namely Z-order curve and Hilbert curve, and uses a multi-level variant of Chord, a popular DHT, as its underlying overlay. Simulation results on OMNET++ show that MARQUES successfully answers range queries with significant efficiency in terms of message overhead and query latency."}}
