{"id": "ZkIVgVxUwau", "cdate": 1577836800000, "mdate": 1682928781973, "content": {"title": "Answer Generation through Unified Memories over Multiple Passages", "abstract": "Machine reading comprehension methods that gen- erate answers by referring to multiple passages for a question have gained much attention in AI and NLP communities. The current methods, however, do not investigate the relationships among multi- ple passages in the answer generation process, even though topics correlated among the passages may be answer candidates. Our method, called neural answer Generation through Unified Memories over Multiple Passages (GUM-MP), solves this problem as follows. First, it determines which tokens in the passages are matched to the question. In particular, it investigates matches between tokens in positive passages, which are assigned to the question, and those in negative passages, which are not related to the question. Next, it determines which tokens in the passage are matched to other passages assigned to the same question and at the same time it investi- gates the topics in which they are matched. Finally, it encodes the token sequences with the above two matching results into unified memories in the pas- sage encoders and learns the answer sequence by using an encoder-decoder with a multiple-pointer- generator mechanism. As a result, GUM-MP can generate answers by pointing to important tokens present across passages. Evaluations indicate that GUM-MP generates much more accurate results than the current models do."}}
{"id": "FemNi2waiGw", "cdate": 1577836800000, "mdate": 1682928781978, "content": {"title": "Answer Generation through Unified Memories over Multiple Passages", "abstract": "Machine reading comprehension methods that generate answers by referring to multiple passages for a question have gained much attention in AI and NLP communities. The current methods, however, do not investigate the relationships among multiple passages in the answer generation process, even though topics correlated among the passages may be answer candidates. Our method, called neural answer Generation through Unified Memories over Multiple Passages (GUM-MP), solves this problem as follows. First, it determines which tokens in the passages are matched to the question. In particular, it investigates matches between tokens in positive passages, which are assigned to the question, and those in negative passages, which are not related to the question. Next, it determines which tokens in the passage are matched to other passages assigned to the same question and at the same time it investigates the topics in which they are matched. Finally, it encodes the token sequences with the above two matching results into unified memories in the passage encoders and learns the answer sequence by using an encoder-decoder with a multiple-pointer-generator mechanism. As a result, GUM-MP can generate answers by pointing to important tokens present across passages. Evaluations indicate that GUM-MP generates much more accurate results than the current models do."}}
{"id": "26nfmKuqwy", "cdate": 1577836800000, "mdate": 1682928781791, "content": {"title": "Conclusion-Supplement Answer Generation for Non-Factoid Questions", "abstract": "This paper tackles the goal of conclusion-supplement answer generation for non-factoid questions, which is a critical issue in the field of Natural Language Processing (NLP) and Artificial Intelligence (AI), as users often require supplementary information before accepting a conclusion. The current encoder-decoder framework, however, has difficulty generating such answers, since it may become confused when it tries to learn several different long answers to the same non-factoid question. Our solution, called an ensemble network, goes beyond single short sentences and fuses logically connected conclusion statements and supplementary statements. It extracts the context from the conclusion decoder's output sequence and uses it to create supplementary decoder states on the basis of an attention mechanism. It also assesses the closeness of the question encoder's output sequence and the separate outputs of the conclusion and supplement decoders as well as their combination. As a result, it generates answers that match the questions and have natural-sounding supplementary sequences in line with the context expressed by the conclusion sequence. Evaluations conducted on datasets including \u201cLove Advice\u201d and \u201cArts & Humanities\u201d categories indicate that our model outputs much more accurate results than the tested baseline models do."}}
{"id": "bb8PVfkQLF", "cdate": 1546300800000, "mdate": 1682928781967, "content": {"title": "Can AI Generate Love Advice?: Toward Neural Answer Generation for Non-Factoid Questions", "abstract": "Deep learning methods that extract answers for non-factoid questions from QA sites are seen as critical since they can assist users in reaching their next decisions through conversations with AI systems. The current methods, however, have the following two problems: (1) They can not understand the ambiguous use of words in the questions as word usage can strongly depend on the context. As a result, the accuracies of their answer selections are not good enough. (2) The current methods can only select from among the answers held by QA sites and can not generate new ones. Thus, they can not answer the questions that are somewhat different with those stored in QA sites. Our solution, Neural Answer Construction Model, tackles these problems as it: (1) Incorporates the biases of semantics behind questions into word embeddings while also computing them regardless of the semantics. As a result, it can extract answers that suit the contexts of words used in the question as well as following the common usage of words across semantics. This improves the accuracy of answer selection. (2) Uses biLSTM to compute the embeddings of questions as well as those of the sentences often used to form answers. It then simultaneously learns the optimum combination of those sentences as well as the closeness between the question and those sentences. As a result, our model can construct an answer that corresponds to the situation that underlies the question; it fills the gap between answer selection and generation and is the first model to move beyond the current simple answer selection model for non-factoid QAs. Evaluations using datasets created for love advice stored in the Japanese QA site, Oshiete goo, indicate that our model achieves 20% higher accuracy in answer creation than the strong baselines. Our model is practical and has already been applied to the love advice service in Oshiete goo."}}
{"id": "AuzyUNyih6", "cdate": 1546300800000, "mdate": 1682928781808, "content": {"title": "Conclusion-Supplement Answer Generation for Non-Factoid Questions", "abstract": "This paper tackles the goal of conclusion-supplement answer generation for non-factoid questions, which is a critical issue in the field of Natural Language Processing (NLP) and Artificial Intelligence (AI), as users often require supplementary information before accepting a conclusion. The current encoder-decoder framework, however, has difficulty generating such answers, since it may become confused when it tries to learn several different long answers to the same non-factoid question. Our solution, called an ensemble network, goes beyond single short sentences and fuses logically connected conclusion statements and supplementary statements. It extracts the context from the conclusion decoder's output sequence and uses it to create supplementary decoder states on the basis of an attention mechanism. It also assesses the closeness of the question encoder's output sequence and the separate outputs of the conclusion and supplement decoders as well as their combination. As a result, it generates answers that match the questions and have natural-sounding supplementary sequences in line with the context expressed by the conclusion sequence. Evaluations conducted on datasets including \"Love Advice\" and \"Arts & Humanities\" categories indicate that our model outputs much more accurate results than the tested baseline models do."}}
{"id": "NqX-mvcPtjR", "cdate": 1483228800000, "mdate": 1682317808693, "content": {"title": "Fast Ad-Hoc Search Algorithm for Personalized PageRank", "abstract": ""}}
{"id": "1ep-AjndMR", "cdate": 1483228800000, "mdate": 1682928781998, "content": {"title": "Semantic Social Network Analysis by Cross-Domain Tensor Factorization", "abstract": "Analyzing \u201cwhat topics\u201d a user discusses with others is important in social network analysis. Since social relationships can be represented as multiobject relationships (e.g., those composed of a user, another user, and the topic of communication), they can be naturally represented as a tensor. By factorizing the tensor, we can perform communication prediction that predicts links among users and the topics discussed among them. The prediction accuracy, however, is often inadequate for applications because: 1) users usually discuss a variety of topics, and thus the prediction results tend to be biased toward popular domains and 2) topics that are rarely discussed among users trigger the sparsity problem in tensor factorization. Our solution, cross-domain tensor factorization (CrTF), first determines the topic domain by analyzing communication logs among users using the DBpedia knowledge base and creates a tensor composed of users, other users, and the topics of communication for each domain; it avoids strong bias toward particular domains. It then simultaneously factorizes tensors across domains while integrating semantics from DBpedia into factorizations; this solves the sparsity problem. Experiments using Twitter data sets show that CrTF achieves higher accuracy than the state-ofthe-art tensor-based methods and extracts key topics and social influencers for each domain."}}
{"id": "Uhlu1Jrjn-", "cdate": 1451606400000, "mdate": 1682928781796, "content": {"title": "Semantic Sensitive Simultaneous Tensor Factorization", "abstract": "The semantics distributed over large-scale knowledge bases can be used to intermediate heterogeneous users\u2019 activity logs created in services; such information can be used to improve applications that can help users to decide the next activities/services. Since user activities can be represented in terms of relationships involving three or more things (e.g. a user tags movie items on a webpage), tensors are an attractive approach to represent them. The recently introduced Semantic Sensitive Tensor Factorization (SSTF) is promising as it achieves high accuracy in predicting users\u2019 activities by basing tensor factorization on the semantics behind objects (e.g. item categories). However, SSTF currently focuses on the factorization of a tensor for a single service and thus has two problems: (1) the balance problem occurs when handling heterogeneous datasets simultaneously, and (2) the sparsity problem triggered by insufficient observations within a single service. Our solution, Semantic Sensitive Simultaneous Tensor Factorization (S $$^3$$ TF), tackles the problems by: (1) Creating tensors for individual services and factorizing them simultaneously; it does not force the creation of a tensor from multiple services and factorize the single tensor. This avoids the low prediction accuracy caused by the balance problem. (2) Utilizing shared semantics behind distributed activity logs and assigning semantic bias to each tensor factorization. This avoids the sparsity problem by sharing semantics among services. Experiments using real-world datasets show that S $$^3$$ TF achieves higher accuracy in rating prediction than the current best tensor method. It also extracts implicit relationships across services in the feature spaces by simultaneous factorization with shared semantics."}}
{"id": "GxIDN4snhX", "cdate": 1451606400000, "mdate": 1682513193487, "content": {"title": "Semantic sensitive tensor factorization", "abstract": ""}}
{"id": "aQz7EY8TlSu", "cdate": 1420070400000, "mdate": 1682513193468, "content": {"title": "Assigning Tasks to Workers by Referring to Their Schedules in Mobile Crowdsourcing", "abstract": ""}}
