{"id": "WVpAeZd6ooY", "cdate": 1664046171088, "mdate": null, "content": {"title": "Condensing Graphs via One-Step Gradient Matching", "abstract": "As training deep learning models on large dataset takes a lot of time and resources, it is desired to construct a small synthetic dataset with which we can train deep learning models sufficiently. There are recent works that have explored solutions on condensing image datasets through complex bi-level optimization. For instance, dataset condensation (DC) matches network gradients w.r.t. large-real data and small-synthetic data, where the network weights are optimized for multiple steps at each outer iteration. However, existing approaches have their inherent limitations: (1) they are not directly applicable to graphs where the data is discrete; and (2) the condensation process is computationally expensive due to the involved nested optimization. To bridge the gap, we investigate efficient dataset condensation tailored for graph datasets where we model the discrete graph structure as a probabilistic model. We further propose a one-step gradient matching scheme, which performs gradient matching for only one single step without training the network weights. Our theoretical analysis shows this strategy can generate synthetic graphs that lead to lower classification loss on real graphs.  Extensive experiments on various graph datasets demonstrate the effectiveness and efficiency of the proposed method. In particular, we are able to reduce the dataset size by $90$\\% while approximating up to $98$\\% of the original performance and our method is significantly faster than multi-step gradient matching (e.g. $15$\u00d7 in CIFAR10 for synthesizing $500$ graphs)."}}
{"id": "RqN8W3R76J", "cdate": 1662812632102, "mdate": null, "content": {"title": "AutoGDA: Automated Graph Data Augmentation for Node Classification", "abstract": "Graph data augmentation has been used to improve generalizability of graph machine learning. However, by only applying fixed augmentation operations on entire graphs, existing methods overlook the unique characteristics of communities which naturally exist in the graphs. For example, different communities can have various degree distributions and homophily ratios. Ignoring such discrepancy with unified augmentation strategies on the entire graph could lead to sub-optimal performance for graph data augmentation methods. In this paper, we study a novel problem of automated graph data augmentation for node classification from the localized perspective of communities. We formulate it as a bilevel optimization problem: finding a set of augmentation strategies for each community, which maximizes the performance of graph neural networks on node classification. As the bilevel optimization is hard to solve directly and the search space for community-customized augmentations strategy is huge, we propose a reinforcement learning framework AutoGDA that learns the local-optimal augmentation strategy for each community sequentially. Our proposed approach outperforms established and popular baselines on public node classification benchmarks as well as real industry e-commerce networks by up to +12.5% accuracy."}}
{"id": "5iuTROX9k0Q", "cdate": 1631764425279, "mdate": 1631764425279, "content": {"title": "Improving Pretrained Models for Zero-shot Multi-label Text Classification through Reinforced Label Hierarchy Reasoning", "abstract": "Exploiting label hierarchies has become a promising approach to tackling the zero-shot multi-label text classification (ZS-MTC) problem. Conventional methods aim to learn a matching model between text and labels, using a graph encoder to incorporate label hierarchies to obtain effective label representations (Rios and Kavuluru, 2018). More recently, pretrained models like BERT (Devlin et al., 2018) have been used to convert classification tasks into a textual entailment task (Yin et al., 2019). This approach is naturally suitable for the ZS-MTC task. However, pretrained models are underexplored in the existing work because they do not generate individual vector representations for text or labels, making it unintuitive to combine them with conventional graph encoding methods. In this paper, we explore to improve pretrained models with label hierarchies on the ZS-MTC task. We propose a Reinforced Label Hierarchy Reasoning (RLHR) approach to encourage interdependence among labels in the hierarchies during training. Meanwhile, to overcome the weakness of flat predictions, we design a rollback algorithm that can remove logical errors from predictions during inference. Experimental results on three real-life datasets show that our approach achieves better performance and outperforms previous non-pretrained methods on the ZS-MTC task."}}
{"id": "sJbOhYLyYat", "cdate": 1609459200000, "mdate": 1631662425051, "content": {"title": "QUEACO: Borrowing Treasures from Weakly-labeled Behavior Data for Query Attribute Value Extraction", "abstract": "We study the problem of query attribute value extraction, which aims to identify named entities from user queries as diverse surface form attribute values and afterward transform them into formally canonical forms. Such a problem consists of two phases: {named entity recognition (NER)} and {attribute value normalization (AVN)}. However, existing works only focus on the NER phase but neglect equally important AVN. To bridge this gap, this paper proposes a unified query attribute value extraction system in e-commerce search named QUEACO, which involves both two phases. Moreover, by leveraging large-scale weakly-labeled behavior data, we further improve the extraction performance with less supervision cost. Specifically, for the NER phase, QUEACO adopts a novel teacher-student network, where a teacher network that is trained on the strongly-labeled data generates pseudo-labels to refine the weakly-labeled data for training a student network. Meanwhile, the teacher network can be dynamically adapted by the feedback of the student's performance on strongly-labeled data to maximally denoise the noisy supervisions from the weak labels. For the AVN phase, we also leverage the weakly-labeled query-to-attribute behavior data to normalize surface form attribute values from queries into canonical forms from products. Extensive experiments on a real-world large-scale E-commerce dataset demonstrate the effectiveness of QUEACO."}}
{"id": "cn0cbqn7Jz", "cdate": 1609459200000, "mdate": 1631662425049, "content": {"title": "Named Entity Recognition with Small Strongly Labeled and Large Weakly Labeled Data", "abstract": "Haoming Jiang, Danqing Zhang, Tianyu Cao, Bing Yin, Tuo Zhao. Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers). 2021."}}
{"id": "9rE_d8uRtms", "cdate": 1609459200000, "mdate": null, "content": {"title": "Improving Pretrained Models for Zero-shot Multi-label Text Classification through Reinforced Label Hierarchy Reasoning", "abstract": "Exploiting label hierarchies has become a promising approach to tackling the zero-shot multi-label text classification (ZS-MTC) problem. Conventional methods aim to learn a matching model between text and labels, using a graph encoder to incorporate label hierarchies to obtain effective label representations \\cite{rios2018few}. More recently, pretrained models like BERT \\cite{devlin2018bert} have been used to convert classification tasks into a textual entailment task \\cite{yin-etal-2019-benchmarking}. This approach is naturally suitable for the ZS-MTC task. However, pretrained models are underexplored in the existing work because they do not generate individual vector representations for text or labels, making it unintuitive to combine them with conventional graph encoding methods. In this paper, we explore to improve pretrained models with label hierarchies on the ZS-MTC task. We propose a Reinforced Label Hierarchy Reasoning (RLHR) approach to encourage interdependence among labels in the hierarchies during training. Meanwhile, to overcome the weakness of flat predictions, we design a rollback algorithm that can remove logical errors from predictions during inference. Experimental results on three real-life datasets show that our approach achieves better performance and outperforms previous non-pretrained methods on the ZS-MTC task."}}
{"id": "_DOqqmJZ7eM", "cdate": 1577836800000, "mdate": null, "content": {"title": "On Data Augmentation for Extreme Multi-label Classification", "abstract": "In this paper, we focus on data augmentation for the extreme multi-label classification (XMC) problem. One of the most challenging issues of XMC is the long tail label distribution where even strong models suffer from insufficient supervision. To mitigate such label bias, we propose a simple and effective augmentation framework and a new state-of-the-art classifier. Our augmentation framework takes advantage of the pre-trained GPT-2 model to generate label-invariant perturbations of the input texts to augment the existing training data. As a result, it present substantial improvements over baseline models. Our contributions are two-factored: (1) we introduce a new state-of-the-art classifier that uses label attention with RoBERTa and combine it with our augmentation framework for further improvement; (2) we present a broad study on how effective are different augmentation methods in the XMC task."}}
{"id": "sY-3W1zia4Z", "cdate": 1514764800000, "mdate": null, "content": {"title": "Predicting Driver Attention in Critical Situations", "abstract": "Robust driver attention prediction for critical situations is a challenging computer vision problem, yet essential for autonomous driving. Because critical driving moments are so rare, collecting enough data for these situations is difficult with the conventional in-car data collection protocol\u2014tracking eye movements during driving. Here, we first propose a new in-lab driver attention collection protocol and introduce a new driver attention dataset, Berkeley DeepDrive Attention (BDD-A) dataset, which is built upon braking event videos selected from a large-scale, crowd-sourced driving video dataset. We further propose Human Weighted Sampling (HWS) method, which uses human gaze behavior to identify crucial frames of a driving dataset and weights them heavily during model training. With our dataset and HWS, we built a driver attention prediction model that outperforms the state-of-the-art and demonstrates sophisticated behaviors, like attending to crossing pedestrians but not giving false alarms to pedestrians safely walking on the sidewalk. Its prediction results are nearly indistinguishable from ground-truth to humans. Although only being trained with our in-lab attention data, the model also predicts in-car driver attention data of routine driving with state-of-the-art accuracy. This result not only demonstrates the performance of our model but also proves the validity and usefulness of our dataset and data collection protocol."}}
{"id": "3ccGaAhYJG", "cdate": 1514764800000, "mdate": null, "content": {"title": "Social-enabled Urban Data Analytics", "abstract": "Author(s): Zhang, Danqing | Advisor(s): Pozdnukhov, Alexei | Abstract: Increasing traffic congestion, vehicle emissions and commuters delay have been major challenges for urban transportation systems for years. The economic cost of traffic congestion in the US is Increasing from 200 billion in 2013 to 293 billion in 2030. There is an increasing need for a better solution to long-term transportation demand forecasting for urban infrastructure planning, and solution to short-term traffic prediction for managing existing urban infrastructure. Accordingly, understanding how urban systems operate and evolve through modeling individuals' daily urban activities has been a major focus of transportation planners, urban planners, and geographers. Traffic data (loop sensors, surveillance cameras, and GPS in taxis, buses), survey data (ACS, CHTS), mobile phone signals (CDR and GPS) and Location Based Social Network (LBSN) data (Facebook, Twitter, Yelp, and Foursquare) have enabled data-driven research on transportation behavior research. The data-driven research, urban data analytics, is an interdisciplinary field where machine learning/ deep learning methods from computer science and optimization/ simulation methods from operation research are applied in conventional city-related fields using spatial-temporal data. In this dissertation, we aim to add the third dimension, social, to urban data analytics research using social-spatial-temporal data, whose key topic is understanding how friendship influences human behavior over time and space. In this era of transformative mobility, this can help better design policies and investment strategies for managing existing urban infrastructure and forecasting future urban infrastructure planning. In this dissertation, we explored two research directions on social-enabled urban data analytics. First, we developed new machine learning models for social discrete choice model, bridging the gap between discrete choice modeling research and computer science research. Second, we developed a methodology framework for synthetic population synthesis using both small data and big data.The first part of the dissertation focus on modeling social influence on human behavior from a graph modeling perspective, while conforming to the discrete choice modeling framework. The proposed models can be used to model how friends influence individual's travel mode choice and other transportation related choices, which is important to transportation demand forecasting. We propose two novel models with scalable training algorithms: local logistics graph regularization (LLGR) and latent class graph regularization (LCGR) models. We add social regularization to represent similarity between friends, and we introduce latent classes to account for possible preference discrepancies between different social groups. Training of the LLGR model is performed using alternating direction method of multipliers (ADMM), and training of the LCGR model is performed using a specialized Monte Carlo expectation maximization (MCEM) algorithm. Scalability to large graphs is achieved by parallelizing computation in both the expectation and the maximization steps. The LCGR model is the first latent class classification model that incorporates social relationships among individuals represented by a given graph. To evaluate our two models, we consider three classes of data: small synthetic data to illustrate the knobs of the method, small real data to illustrate one social science use case, and large real data to illustrate a typical large-scale use case in the internet and social media applications. We experiment on synthetic datasets to empirically explain when the proposed model is better than vanilla classification models that do not exploit graph structure. We illustrate how the graph structure and labels, assigned to each node of the graph, need to satisfy certain reasonable properties. We also experiment on real-world data, including both small scale and large scale real-world datasets, to demonstrate on which types of datasets our model can be expected to outperform state-of-the-art models.This dissertation also develops an algorithmic procedure to incorporate social information into population synthesizer, which is an essential step to incorporate social information into the transportation simulation framework. Agent-based modeling in transportation problems requires detailed information on each of the agents that represent the population in the region of a study. To extend the agent-based transportation modeling with social influence, a connected synthetic population with both synthetic features and its social networks need to be simulated. However, either the traditional manually-collected household survey data (ACS) or the recent large-scale passively-collected Call Detail Records (CDR) alone lacks features. This work proposes an algorithmic procedure that makes use of both traditional survey data as well as digital records of networking and human behaviors to generate connected synthetic populations. This proposed framework for connected population synthesis is applicable to cities or metropolitan regions where data availability allows for the estimation of the component models. The generated populations coupled with recent advances in graph (social networks) algorithms can be used for testing transportation simulation scenarios with different social factors."}}
{"id": "ipQGDuh6sS", "cdate": 1483228800000, "mdate": null, "content": {"title": "Social Discrete Choice Models", "abstract": "Human decision making underlies data generating process in multiple application areas, and models explaining and predicting choices made by individuals are in high demand. Discrete choice models are widely studied in economics and computational social sciences. As digital social networking facilitates information flow and spread of influence between individuals, new advances in modeling are needed to incorporate social information into these models in addition to characteristic features affecting individual choices. In this paper, we propose two novel models with scalable training algorithms: local logistics graph regularization (LLGR) and latent class graph regularization (LCGR) models. We add social regularization to represent similarity between friends, and we introduce latent classes to account for possible preference discrepancies between different social groups. Training of the LLGR model is performed using alternating direction method of multipliers (ADMM), and training of the LCGR model is performed using a specialized Monte Carlo expectation maximization (MCEM) algorithm. Scalability to large graphs is achieved by parallelizing computation in both the expectation and the maximization steps. The LCGR model is the first latent class classification model that incorporates social relationships among individuals represented by a given graph. To evaluate our two models, we consider three classes of data to illustrate a typical large-scale use case in internet and social media applications. We experiment on synthetic datasets to empirically explain when the proposed model is better than vanilla classification models that do not exploit graph structure. We also experiment on real-world data, including both small scale and large scale real-world datasets, to demonstrate on which types of datasets our model can be expected to outperform state-of-the-art models."}}
