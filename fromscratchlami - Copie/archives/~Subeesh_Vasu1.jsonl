{"id": "uABSDzrRAR", "cdate": 1668007633900, "mdate": 1668007633900, "content": {"title": "Topoal: An adversarial learning approach for topology-aware road segmentation", "abstract": "Most state-of-the-art approaches to road extraction from aerial images rely on a CNN trained to label road pixels as foreground and remainder of the image as background. The CNN is usually trained by minimizing pixel-wise losses, which is less than ideal to produce binary masks that preserve the road network's global connectivity. To address this issue, we introduce an Adversarial Learning (AL) strategy tailored for our purposes. A naive one would treat the segmentation network as a generator and would feed its output along with ground-truth segmentations to a discriminator. It would then train the generator and discriminator jointly. We will show that this is not enough because it does not capture the fact that most errors are local and need to be treated as such. Instead, we use a more sophisticated discriminator that returns a label pyramid describing what portions of the road network are correct at several different scales. This discriminator and the structured labels it returns are what gives our approach its edge and we will show that it outperforms state-of-the-art ones on the challenging RoadTracer dataset."}}
{"id": "0BZwMWNr_tT", "cdate": 1640995200000, "mdate": 1668007736307, "content": {"title": "Multi-planar geometry and latent image recovery from a single motion-blurred image", "abstract": "Existing works for depth estimation and image deblurring in the presence of depth-dependent blur work with the assumption of a multi-layered scene wherein each layer is modeled in the form of a fronto-parallel plane. In this work, we attempt to relax these constraints by considering more generalized settings of a 3D scene with piecewise planar structure, i.e., a scene that can be modeled as a combination of multiple planes with arbitrary orientations. To this end, we first propose a novel approach to estimate the normal of a planar surface from a single motion-blurred image. We then extend this idea and develop an algorithm for automatic recovery of the number of planes, the parameters corresponding to each plane, and camera motion from a single motion-blurred image of a multi-planar 3D scene. Finally, we propose a first-of-its-kind approach to recover the planar geometry and latent image of the scene by adopting an alternating minimization framework built on our findings. Experiments on synthetic and real data reveal that our proposed method achieves state-of-the-art results on the dual problem of depth recovery and image deblurring."}}
{"id": "z_l9XpuSCbN", "cdate": 1609459200000, "mdate": 1668007736319, "content": {"title": "HybridSDF: Combining Free Form Shapes and Geometric Primitives for effective Shape Manipulation", "abstract": "Deep implicit surfaces excel at modeling generic shapes but do not always capture the regularities present in manufactured objects, which is something simple geometric primitives are particularly good at. In this paper, we propose a representation combining latent and explicit parameters that can be decoded into a set of deep implicit and geometric shapes that are consistent with each other. As a result, we can effectively model both complex and highly regular shapes that coexist in manufactured objects. This enables our approach to manipulate 3D shapes in an efficient and precise manner."}}
{"id": "IAcTgRUNbT8", "cdate": 1577836800000, "mdate": 1668007736174, "content": {"title": "TopoAL: An Adversarial Learning Approach for Topology-Aware Road Segmentation", "abstract": "Most state-of-the-art approaches to road extraction from aerial images rely on a CNN trained to label road pixels as foreground and remainder of the image as background. The CNN is usually trained by minimizing pixel-wise losses, which is less than ideal to produce binary masks that preserve the road network\u2019s global connectivity. To address this issue, we introduce an Adversarial Learning (AL) strategy tailored for our purposes. A naive one would treat the segmentation network as a generator and would feed its output along with ground-truth segmentations to a discriminator. It would then train the generator and discriminator jointly. We will show that this is not enough because it does not capture the fact that most errors are local and need to be treated as such. Instead, we use a more sophisticated discriminator that returns a label pyramid describing what portions of the road network are correct at several different scales. This discriminator and the structured labels it returns are what gives our approach its edge and we will show that it outperforms state-of-the-art ones on the challenging RoadTracer dataset."}}
{"id": "s1xRj2ce0CO", "cdate": 1514764800000, "mdate": 1668007736188, "content": {"title": "Camera Shutter-Independent Registration and Rectification", "abstract": "Inevitable camera motion during exposure does not augur well for free-hand photography. Distortions introduced in images can be of different types and mainly depend on the structure of the scene, the nature of camera motion, and the shutter mechanism of the camera. In this paper, we address the problem of registering images taken from global shutter and rolling shutter cameras and reveal the constraints on camera motion that admit registration, change detection, and rectification. Our analysis encompasses degradations arising from camera motion during exposure and differences in shutter mechanisms. We also investigate conditions under which camera motions causing distortions in reference and target image can be decoupled to yield the underlying latent image through RS rectification. We validate our approach using several synthetic and real examples."}}
{"id": "ZDwL3Ofenk", "cdate": 1514764800000, "mdate": 1668007736128, "content": {"title": "Joint HDR and Super-Resolution Imaging in Motion Blur", "abstract": "Images captured from consumer cameras are often prone to camera shake resulting in motion blur. Effect of motion blur is more common in high dynamic range imaging applications where multiple images are captured over a wide range of exposure settings. In this paper, we propose a unified approach to perform high dynamic range super-resolution (HDR-SR) imaging from a sequence of low dynamic range and low-resolution motion-blurred images. While existing works on HDR-SR assume the availability of blur-free input images, we propose an approach which is designed to handle blurring effects caused by the camera motion. Our approach attempts to harness the complementarity present in terms of the sensor exposure and blur to yield a high-quality image which has both higher spatial resolution as well as dynamic range. Experiments on synthetic and real examples demonstrate that the proposed method delivers state-of-the-art results."}}
{"id": "SyZHX0-ObS", "cdate": 1514764800000, "mdate": null, "content": {"title": "Non-Blind Deblurring: Handling Kernel Uncertainty With CNNs", "abstract": "Blind motion deblurring methods are primarily responsible for recovering an accurate estimate of the blur kernel. Non-blind deblurring (NBD) methods, on the other hand, attempt to faithfully restore the original image, given the blur estimate. However, NBD is quite susceptible to errors in blur kernel. In this work, we present a convolutional neural network-based approach to handle kernel uncertainty in non-blind motion deblurring. We provide multiple latent image estimates corresponding to different prior strengths obtained from a given blurry observation in order to exploit the complementarity of these inputs for improved learning. To generalize the performance to tackle arbitrary kernel noise, we train our network with a large number of real and synthetic noisy blur kernels. Our network mitigates the effects of kernel noise so as to yield detail-preserving and artifact-free restoration. Our quantitative and qualitative evaluations on benchmark datasets demonstrate that the proposed method delivers state-of-the-art results. To further underscore the benefits that can be achieved from our network, we propose two adaptations of our method to improve kernel estimates, and image deblurring quality, respectively."}}
{"id": "SyNQ9q-ObB", "cdate": 1514764800000, "mdate": null, "content": {"title": "PIRM Challenge on Perceptual Image Enhancement on Smartphones: Report", "abstract": "This paper reviews the first challenge on efficient perceptual image enhancement with the focus on deploying deep learning models on smartphones. The challenge consisted of two tracks. In the first one, participants were solving the classical image super-resolution problem with a bicubic downscaling factor of 4. The second track was aimed at real-world photo enhancement, and the goal was to map low-quality photos from the iPhone 3GS device to the same photos captured with a DSLR camera. The target metric used in this challenge combined the runtime, PSNR scores and solutions\u2019 perceptual results measured in the user study. To ensure the efficiency of the submitted models, we additionally measured their runtime and memory requirements on Android smartphones. The proposed solutions significantly improved baseline results defining the state-of-the-art for image enhancement on smartphones."}}
{"id": "B1Zybp-uZS", "cdate": 1514764800000, "mdate": null, "content": {"title": "Occlusion-Aware Rolling Shutter Rectification of 3D Scenes", "abstract": "A vast majority of contemporary cameras employ rolling shutter (RS) mechanism to capture images. Due to the sequential mechanism, images acquired with a moving camera are subjected to rolling shutter effect which manifests as geometric distortions. In this work, we consider the specific scenario of a fast moving camera wherein the rolling shutter distortions not only are predominant but also become depth-dependent which in turn results in intra-frame occlusions. To this end, we develop a first-of-its-kind pipeline to recover the latent image of a 3D scene from a set of such RS distorted images. The proposed approach sequentially recovers both the camera motion and scene structure while accounting for RS and occlusion effects. Subsequently, we perform depth and occlusion-aware rectification of RS images to yield the desired latent image. Our experiments on synthetic and real image sequences reveal that the proposed approach achieves state-of-the-art results."}}
{"id": "B1468KZdbS", "cdate": 1514764800000, "mdate": null, "content": {"title": "Analyzing Perception-Distortion Tradeoff Using Enhanced Perceptual Super-Resolution Network", "abstract": "Convolutional neural network (CNN) based methods have recently achieved great success for image super-resolution (SR). However, most deep CNN based SR models attempt to improve distortion measures (e.g. PSNR, SSIM, IFC, VIF) while resulting in poor quantified perceptual quality (e.g. human opinion score, no-reference quality measures such as NIQE). Few works have attempted to improve the perceptual quality at the cost of performance reduction in distortion measures. A very recent study has revealed that distortion and perceptual quality are at odds with each other and there is always a trade-off between the two. Often the restoration algorithms that are superior in terms of perceptual quality, are inferior in terms of distortion measures. Our work attempts to analyze the trade-off between distortion and perceptual quality for the problem of single image SR. To this end, we use the well-known SR architecture- enhanced deep super-resolution (EDSR) network and show that it can be adapted to achieve better perceptual quality for a specific range of the distortion measure. While the original network of EDSR was trained to minimize the error defined based on per-pixel accuracy alone, we train our network using a generative adversarial network framework with EDSR as the generator module. Our proposed network, called enhanced perceptual super-resolution network (EPSR), is trained with a combination of mean squared error loss, perceptual loss, and adversarial loss. Our experiments reveal that EPSR achieves the state-of-the-art trade-off between distortion and perceptual quality while the existing methods perform well in either of these measures alone."}}
