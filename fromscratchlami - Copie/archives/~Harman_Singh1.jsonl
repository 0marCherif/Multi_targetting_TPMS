{"id": "UQB2KPRd5Tp", "cdate": 1672531200000, "mdate": 1695991929437, "content": {"title": "Coarse-to-Fine Contrastive Learning in Image-Text-Graph Space for Improved Vision-Language Compositionality", "abstract": "Contrastively trained vision-language models have achieved remarkable progress in vision and language representation learning, leading to state-of-the-art models for various downstream multimodal tasks. However, recent research has highlighted severe limitations of these models in their ability to perform compositional reasoning over objects, attributes, and relations. Scene graphs have emerged as an effective way to understand images compositionally. These are graph-structured semantic representations of images that contain objects, their attributes, and relations with other objects in a scene. In this work, we consider the scene graph parsed from text as a proxy for the image scene graph and propose a graph decomposition and augmentation framework along with a coarse-to-fine contrastive learning objective between images and text that aligns sentences of various complexities to the same image. Along with this, we propose novel negative mining techniques in the scene graph space for improving attribute binding and relation understanding. Through extensive experiments, we demonstrate the effectiveness of our approach that significantly improves attribute binding, relation understanding, systematic generalization, and productivity on multiple recently proposed benchmarks (For example, improvements upto $18\\%$ for systematic generalization, $16.5\\%$ for relation understanding over a strong baseline), while achieving similar or better performance than CLIP on various general multimodal tasks."}}
{"id": "UT75yKgc-j", "cdate": 1664884605660, "mdate": null, "content": {"title": "Image Manipulation via Neuro-Symbolic Networks", "abstract": "Image manipulation via natural language text -- an extremely useful task for multiple AI applications but requires complex reasoning over multi-modal spaces. Neuro-symbolic approaches has been quite effective in solving such tasks as they offer better modularity, interpretability, and generalizability. A noteworthy such approach is NSCL [10] developed for the task of Visual Question Answering (VQA). We extend NSCL for the image manipulation task and propose a solution referred to as NEUROSIM. Unlike previous works, which either require supervised data training or can only deal with simple reasoning instructions over single object scenes; NEUROSIM can perform complex multi-hop reasoning over multi-object scenes and requires only weak supervision in the form of annotated data for the VQA task. On the language side, NEUROSIM contains neural modules that parse an instruction into a symbolic program over a Domain Specific Language (DSL) comprising manipulation operations that guide the manipulation. On the perceptual side, NEUROSIM contains neural modules which first generate a scene graph of the input image and then change the scene graph representation following the parsed instruction. To train these modules, we design novel loss functions capable of testing the correctness of manipulated object and scene graph representations via query networks. An image decoder is trained to render the final image from the manipulated scene graph representation. Extensive experiments demonstrate that NEUROSIM is highly competitive with state-of-the-art supervised baselines."}}
{"id": "RqJZTlQMph", "cdate": 1663850244797, "mdate": null, "content": {"title": "Weakly Supervised Neuro-Symbolic Image Manipulation via Multi-Hop Complex Instructions", "abstract": "We are interested in image manipulation via natural language text \u2013 a task that is extremely useful for multiple AI applications but requires complex reasoning over multi-modal spaces. Recent work on neuro-symbolic approaches (Mao et al., 2019) (NSCL) has been quite effective for solving VQA as they offer better modularity, interpretability, and generalizability. We extend NSCL for the image manipulation task and propose a solution referred to as NeuroSIM. Previous work either requires supervised training data in the form of manipulated images or can only deal with very simple reasoning instructions over single object scenes. In contrast, NeuroSIM can perform complex multi-hop reasoning over multi-object scenes and only requires weak supervision in the form of annotated data for VQA. NeuroSIM parses an instruction into a symbolic program, based on a Domain Specific Language (DSL) comprising of object attributes and manipulation operations, that guides the manipulation. We design neural modules for manipulation, as well as novel loss functions that are capable of testing the correctness of manipulated object and scene graph representations via query networks trained merely on VQA data. An image decoder is trained to render the final image from the manipulated scene graph. Extensive experiments demonstrate that NeuroSIM, without using target images as supervision, is highly competitive with SOTA baselines that make use of supervised data for manipulation."}}
{"id": "X2_Zk7byMmv", "cdate": 1640995200000, "mdate": 1673936097606, "content": {"title": "FaiRR: Faithful and Robust Deductive Reasoning over Natural Language", "abstract": ""}}
{"id": "7-EWd0RI3Pm", "cdate": 1640995200000, "mdate": 1673936097610, "content": {"title": "FaiRR: Faithful and Robust Deductive Reasoning over Natural Language", "abstract": ""}}
{"id": "9DGMd1XwSt", "cdate": 1609459200000, "mdate": 1673936097604, "content": {"title": "A Novel Network Representation of SARS-CoV-2 Sequencing Data", "abstract": ""}}
