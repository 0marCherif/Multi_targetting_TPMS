{"id": "Klg3LvTHENB", "cdate": 1672531200000, "mdate": 1681143714577, "content": {"title": "On the Role of Emergent Communication for Social Learning in Multi-Agent Reinforcement Learning", "abstract": ""}}
{"id": "SQO4StcQKdN", "cdate": 1665251227290, "mdate": null, "content": {"title": "Towards True Lossless Sparse Communication in Multi-Agent Systems", "abstract": "Communication enables agents to cooperate to achieve their goals. Learning when to communicate, i.e., sparse (in time) communication, and whom to message is particularly important when bandwidth is limited. Recent work in learning sparse individualized communication, however, suffers from high variance during training, where decreasing communication comes at the cost of decreased reward, particularly in cooperative tasks. We use the information bottleneck to reframe sparsity as a representation learning problem, which we show naturally enables lossless sparse communication at lower budgets than prior art. In this paper, we propose a method for true lossless sparsity in communication via Information Maximizing Gated Sparse Multi-Agent Communication (IMGS-MAC). Our model uses two individualized regularization objectives, an information maximization autoencoder and sparse communication loss, to create informative and sparse communication. We evaluate the learned communication `language' through direct causal analysis of messages in non-sparse runs to determine the range of lossless sparse budgets, which allow zero-shot sparsity, and the range of sparse budgets that will inquire a reward loss, which is minimized by our learned gating function with few-shot sparsity. To demonstrate the efficacy of our results, we experiment in cooperative multi-agent tasks where communication is essential for success. We evaluate our model with both continuous and discrete messages. We focus our analysis on a variety of ablations to show the effect of message representations, including their properties, and lossless performance of our model."}}
{"id": "GC7EGXBbX_", "cdate": 1640995200000, "mdate": 1681143714580, "content": {"title": "The Enforcers: Consistent Sparse-Discrete Methods for Constraining Informative Emergent Communication", "abstract": ""}}
{"id": "qz7WI4eBA82", "cdate": 1609459200000, "mdate": 1655324136110, "content": {"title": "Improving Kinodynamic Planners for Vehicular Navigation with Learned Goal-Reaching Controllers", "abstract": "This paper aims to improve the path quality and computational efficiency of sampling-based kinodynamic planners for vehicular navigation. It proposes a learning framework for identifying promising controls during the expansion process of sampling-based planners. Given a dynamics model, a reinforcement learning process is trained offline to return a low-cost control that reaches a local goal state (i.e., a waypoint) in the absence of obstacles. By focusing on the system\u2019s dynamics and not knowing the environment, this process is data-efficient and takes place once for a robotic system. In this way, it can be reused in different environments. The planner generates online local goal states for the learned controller in an informed manner to bias towards the goal and consecutively in an exploratory, random manner. For the informed expansion, local goal states are generated either via (a) medial axis information in environments with obstacles, or (b) wavefront information for setups with traversability costs. The learning process and the resulting planning framework are evaluated for a first and second-order differential drive system, as well as a physically simulated Segway robot. The results show that the proposed integration of learning and planning can produce higher quality paths than sampling-based kinodynamic planning with random controls in fewer iterations and computation time."}}
