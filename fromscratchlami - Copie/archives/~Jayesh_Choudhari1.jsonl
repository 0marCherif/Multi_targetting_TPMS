{"id": "_ZWURLc900", "cdate": 1640995200000, "mdate": 1672034161102, "content": {"title": "On Coresets for Fair Regression and Individually Fair Clustering", "abstract": "In this paper we present coresets for Fair Regression with Statistical Parity (SP) constraints and for Individually Fair Clustering. Due to the fairness constraints, the classical coreset definition is not enough for these problems. We first define coresets for both the problems. We show that to obtain such coresets, it is sufficient to sample points based on the probabilities dependent on combination of sensitivity score and a carefully chosen term according to the fairness constraints. We give provable guarantees with relative error in preserving the cost and a small additive error in preserving fairness constraints for both problems. Since our coresets are much smaller in size as compared to $n$, the number of points, they can give huge benefits in computational costs (from polynomial to polylogarithmic in $n$), especially when $n \\gg d$, where $d$ is the input dimension. We support our theoretical claims with experimental evaluations."}}
{"id": "Jcfmb-k9A1u", "cdate": 1640995200000, "mdate": 1674123555722, "content": {"title": "DeMEtRIS: Counting (near)-Cliques by Crawling", "abstract": "We study the problem of approximately counting cliques and near cliques in a graph, where the access to the graph is only available through crawling its vertices; thus typically seeing only a small portion of it. This model, known as the random walk model or the neighborhood query model has been introduced recently and captures real-life scenarios in which the entire graph is too massive to be stored as a whole or be scanned entirely and sampling vertices independently is non-trivial in it. We introduce DeMEtRIS: Dense Motif Estimation through Random Incident Sampling. This method provides a scalable algorithm for clique and near clique counting in the random walk model. We prove the correctness of our algorithm through rigorous mathematical analysis and extensive experiments. Both our theoretical results and our experiments show that DeMEtRIS obtains a high precision estimation by only crawling a sub-linear portion on vertices, thus we demonstrate a significant improvement over previously known results."}}
{"id": "AJL7RCZSYV", "cdate": 1640995200000, "mdate": 1674123555722, "content": {"title": "A New Dynamic Algorithm for Densest Subhypergraphs", "abstract": "Computing a dense subgraph is a fundamental problem in graph mining, with a diverse set of applications ranging from electronic commerce to community detection in social networks. In many of these applications, the underlying context is better modelled as a weighted hypergraph that keeps evolving with time. This motivates the problem of maintaining the densest subhypergraph of a weighted hypergraph in a dynamic setting, where the input keeps changing via a sequence of updates (hyperedge insertions/deletions). Previously, the only known algorithm for this problem was due to Hu et al.\u00a0[19]. This algorithm worked only on unweighted hypergraphs, and had an approximation ratio of (1 +\u03f5)r2 and an update time of O(poly(r, log\u2009n)), where r denotes the maximum rank of the input across all the updates. We obtain a new algorithm for this problem, which works even when the input hypergraph is weighted. Our algorithm has a significantly improved (near-optimal) approximation ratio of (1 +\u03f5) that is independent of r, and a similar update time of O(poly(r, log\u2009n)). It is the first (1 +\u03f5)-approximation algorithm even for the special case of weighted simple graphs. To complement our theoretical analysis, we perform experiments with our dynamic algorithm on large-scale, real-world data-sets. Our algorithm significantly outperforms the state of the art [19] both in terms of accuracy and efficiency."}}
{"id": "410zJ8e7Jc6", "cdate": 1609459200000, "mdate": null, "content": {"title": "Analyzing Topic Transitions in Text-Based Social Cascades Using Dual-Network Hawkes Process", "abstract": "We address the problem of modeling bursty diffusion of text-based events over a social network of user nodes. The purpose is to recover, disentangle and analyze overlapping social conversations from the perspective of user-topic preferences, user-user connection strengths and, importantly, topic transitions. For this, we propose a Dual-Network Hawkes Process (DNHP), which executes over a graph whose nodes are user-topic pairs, and closeness of nodes is captured using topic-topic, a user-user, and user-topic interactions. No existing Hawkes Process model captures such multiple interactions simultaneously. Additionally, unlike existing Hawkes Process based models, where event times are generated first, and event topics are conditioned on the event times, the DNHP is more faithful to the underlying social process by making the event times depend on interacting (user, topic) pairs. We develop a Gibbs sampling algorithm for estimating the three network parameters that allows evidence to flow between the parameter spaces. Using experiments over large real collection of tweets by US politicians, we show that the DNHP generalizes better than state of the art models, and also provides interesting insights about user and topic transitions."}}
{"id": "aUy24riCgiM", "cdate": 1577836800000, "mdate": null, "content": {"title": "Streaming Coresets for Symmetric Tensor Factorization", "abstract": "Factorizing tensors has recently become an important optimization module in a number of machine learning pipelines, especially in latent variable models. We show how to do this efficiently in the streaming setting. Given a set of $n$ vectors, each in $\\mathbb{R}^d$, we present algorithms to select a sublinear number of these vectors as coreset, while guaranteeing that the CP decomposition of the $p$-moment tensor of the coreset approximates the corresponding decomposition of the $p$-moment tensor computed from the full data. We introduce two novel algorithmic techniques: online filtering and kernelization. Using these two, we present six algorithms that achieve different tradeoffs of coreset size, update time and working space, beating or matching various state of the art algorithms. In the case of matrices ($2$-ordered tensor), our online row sampling algorithm guarantees $(1 \\pm \\epsilon)$ relative error spectral approximation. We show applications of our algorithms in learning single topic modeling."}}
{"id": "FzWNh5SQLxD", "cdate": 1577836800000, "mdate": null, "content": {"title": "Online Coresets for Clustering with Bregman Divergences", "abstract": "We present algorithms that create coresets in an online setting for clustering problems according to a wide subset of Bregman divergences. Notably, our coresets have a small additive error, similar in magnitude to the lightweight coresets Bachem et. al. 2018, and take update time $O(d)$ for every incoming point where $d$ is dimension of the point. Our first algorithm gives online coresets of size $\\tilde{O}(\\mbox{poly}(k,d,\\epsilon,\\mu))$ for $k$-clusterings according to any $\\mu$-similar Bregman divergence. We further extend this algorithm to show existence of a non-parametric coresets, where the coreset size is independent of $k$, the number of clusters, for the same subclass of Bregman divergences. Our non-parametric coresets are larger by a factor of $O(\\log n)$ ($n$ is number of points) and have similar (small) additive guarantee. At the same time our coresets also function as lightweight coresets for non-parametric versions of the Bregman clustering like DP-Means. While these coresets provide additive error guarantees, they are also significantly smaller (scaling with $O(\\log n)$ as opposed to $O(d^d)$ for points in $\\~R^d$) than the (relative-error) coresets obtained in Bachem et. al. 2015 for DP-Means. While our non-parametric coresets are existential, we give an algorithmic version under certain assumptions."}}
{"id": "AJ5TMaQRroF", "cdate": 1577836800000, "mdate": null, "content": {"title": "Efficient Hierarchical Clustering for Classification and Anomaly Detection", "abstract": "We address the problem of large scale real-time classification of content posted on social networks, along with the need to rapidly identify novel spam types. Obtaining manual labels for user-generated content using editorial labeling and taxonomy development lags compared to the rate at which new content type needs to be classified. We propose a class of hierarchical clustering algorithms that can be used both for efficient and scalable real-time multiclass classification as well as in detecting new anomalies in user-generated content. Our methods have low query time, linear space usage, and come with theoretical guarantees with respect to a specific hierarchical clustering cost function (Dasgupta, 2016). We compare our solutions against a range of classification techniques and demonstrate excellent empirical performance."}}
{"id": "fF1RWXwELyp", "cdate": 1514764800000, "mdate": null, "content": {"title": "Discovering Topical Interactions in Text-based Cascades using Hidden Markov Hawkes Processes.", "abstract": "Social media conversations unfold based on complex interactions between users, topics and time. While recent models have been proposed to capture network strengths between users, users' topical preferences and temporal patterns between posting and response times, interaction patterns between topics has not been studied. We propose the Hidden Markov Hawkes Process (HMHP) that incorporates topical Markov Chains within Hawkes processes to jointly model topical interactions along with user-user and user-topic patterns. We propose a Gibbs sampling algorithm for HMHP that jointly infers the network strengths, diffusion paths, the topics of the posts as well as the topic-topic interactions. We show using experiments on real and semi-synthetic data that HMHP is able to generalize better and recover the network strengths, topics and diffusion paths more accurately than state-of-the-art baselines. More interestingly, HMHP finds insightful interactions between topics in real tweets which no existing model is able to do."}}
{"id": "c9pgSt6c-zZ", "cdate": 1514764800000, "mdate": 1652685369572, "content": {"title": "Discovering Topical Interactions in Text-Based Cascades Using Hidden Markov Hawkes Processes", "abstract": "Social media conversations unfold based on complex interactions between users, topics and time. While recent models have been proposed to capture network strengths between users, users' topical preferences and temporal patterns between posting and response times, interaction patterns between topics has not been studied. We propose the Hidden Markov Hawkes Process (HMHP) that incorporates topical Markov Chains within Hawkes processes to jointly model topical interactions along with user-user and user-topic patterns. We propose a Gibbs sampling algorithm for HMHP that jointly infers the network strengths, diffusion paths, the topics of the posts as well as the topic-topic interactions. We show using experiments on real and semi-synthetic data that HMHP is able to generalize better and recover the network strengths, topics and diffusion paths more accurately than state-of-the-art baselines. More interestingly, HMHP finds insightful interactions between topics in real tweets which no existing model is able to do."}}
{"id": "RiGq-lD7W0O", "cdate": 1514764800000, "mdate": null, "content": {"title": "Nearly Optimal Space Efficient Algorithm for Depth First Search", "abstract": "We design a space-efficient algorithm for performing depth-first search traversal(DFS) of a graph in $O(m+n\\log^* n)$ time using $O(n)$ bits of space. While a normal DFS algorithm results in a DFS-tree (in case the graph is connected), our space bounds do not permit us even to store such a tree. However, our algorithm correctly outputs all edges of the DFS-tree. The previous best algorithm (which used $O(n)$ working space) took $O(m \\log n)$ time (Asano, Izumi, Kiyomi, Konagaya, Ono, Otachi, Schweitzer, Tarui, Uehara (ISAAC 2014) and Elmasry, Hagerup, Krammer (STACS 2015)). The main open question left behind in this area was to design faster algorithm for DFS using $O(n)$ bits of space. Our algorithm answers this open question as it has a nearly optimal running time (as the DFS takes $O(m+n)$ time even if there is no space restriction)."}}
