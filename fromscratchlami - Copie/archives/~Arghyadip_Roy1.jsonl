{"id": "T4auogThZQG", "cdate": 1672531200000, "mdate": 1681709319461, "content": {"title": "Online Radio Access Technology Selection Algorithms in a 5G Multi-RAT Network", "abstract": "In today's wireless networks, a variety of Radio Access Technologies (RATs) are present. However, each RAT being controlled individually leads to suboptimal utilization of network resources. Due to the remarkable growth of data traffic, interworking among different RATs is becoming necessary to overcome the problem of suboptimal resource utilization. Users can be offloaded from one RAT to another based on loads of different networks, channel conditions and priority of users. We consider the optimal RAT selection problem in a Fifth Generation (5G) New Radio (NR)-Wireless Fidelity (WiFi) network where we aim to maximize the total system throughput subject to constraints on the blocking probability of high priority users and the offloading probability of low priority users. The problem is formulated as a Constrained Markov Decision Process (CMDP). We reduce the effective dimensionality of the action space by eliminating the provably suboptimal actions. We propose low-complexity online heuristics for RAT selection which can operate without the knowledge regarding the statistics of system dynamics. Network Simulator-3 (ns-3) simulations reveal that the proposed algorithms outperform traditional RAT selection algorithms under realistic network scenarios including user mobility."}}
{"id": "aX9q_0KxSSj", "cdate": 1640995200000, "mdate": 1681709319468, "content": {"title": "Online Reinforcement Learning of Optimal Threshold Policies for Markov Decision Processes", "abstract": "To overcome the <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">curses of dimensionality and modeling</i> of dynamic programming methods to solve Markov decision process problems, reinforcement learning (RL) methods are adopted in practice. Contrary to traditional RL algorithms, which do not consider the structural properties of the optimal policy, we propose a structure-aware learning algorithm to exploit the ordered multithreshold structure of the optimal policy, if any. We prove the asymptotic convergence of the proposed algorithm to the optimal policy. Due to the reduction in the policy space, the proposed algorithm provides remarkable improvements in storage and computational complexities over classical RL algorithms. Simulation results establish that the proposed algorithm converges faster than other RL algorithms."}}
{"id": "ELCrAbBII0Q", "cdate": 1640995200000, "mdate": 1681709319482, "content": {"title": "A Policy Gradient Algorithm for the Risk-Sensitive Exponential Cost MDP", "abstract": "We study the risk-sensitive exponential cost MDP formulation and develop a trajectory-based gradient algorithm to find the stationary point of the cost associated with a set of parameterized policies. We derive a formula that can be used to compute the policy gradient from (state, action, cost) information collected from sample paths of the MDP for each fixed parameterized policy. Unlike the traditional average-cost problem, standard stochastic approximation theory cannot be used to exploit this formula. To address the issue, we introduce a truncated and smooth version of the risk-sensitive cost and show that this new cost criterion can be used to approximate the risk-sensitive cost and its gradient uniformly under some mild assumptions. We then develop a trajectory-based gradient algorithm to minimize the smooth truncated estimation of the risk-sensitive cost and derive conditions under which a sequence of truncations can be used to solve the original, untruncated cost problem."}}
{"id": "3hLO35hVbuo", "cdate": 1640995200000, "mdate": 1681709319469, "content": {"title": "GoPro: a Low Complexity Task Allocation Algorithm for a Mobile Edge Computing System", "abstract": "In an Internet of Things (IoT) based network, tasks arriving at individual nodes can be processed in-device or at a local Mobile Edge Computing (MEC) server. In this paper, we focus on the optimal resource allocation problem for tasks arriving in an MEC based IoT network. To address the inherent trade-off between the computation time and the power consumption, we aim to minimize the average power consumption subject to a constraint on the deadline violation probability. The problem is formulated as a Constrained Markov Decision Process (CMDP) problem. To address the high complexities of achieving optimality, we propose a low-complexity heuristic task scheduling scheme. Efficacy of our approach is demonstrated using simulations."}}
{"id": "NtDy3p2qv7", "cdate": 1577836800000, "mdate": 1681709319470, "content": {"title": "Low Complexity Online Radio Access Technology Selection Algorithm in LTE-WiFi HetNet", "abstract": "In an offload-capable Long Term Evolution (LTE)Wireless Fidelity (WiFi) Heterogeneous Network (HetNet), we consider the problem of maximization of the total system throughput under voice user blocking probability constraint. The optimal policy is threshold in nature. However, computation of optimal policy requires the knowledge of the statistics of system dynamics, viz., arrival processes of voice and data users, which may be difficult to obtain in reality. Motivated by the Post-Decision State (PDS) framework to learn the optimal policy under unknown statistics of system dynamics, we propose, in this paper, an online Radio Access Technology (RAT) selection algorithm using Relative Value Iteration Algorithm (RVIA). However, the convergence speed of this algorithm can be further improved if the underlying threshold structure of the optimal policy can be exploited. To this end, we propose a novel structureaware online RAT selection algorithm which reduces the feasible policy space, thereby offering lesser storage and computational complexity and faster convergence. This algorithm provides a novel framework for designing online learning algorithms for other problems and hence is of independent interest. We prove that both the algorithms converge to the optimal policy. Simulation results demonstrate that the proposed algorithms converge faster than a traditional scheme. Also, the proposed schemes perform better than other benchmark algorithms under realistic network scenarios."}}
{"id": "0SCvHpWP3E", "cdate": 1577836800000, "mdate": 1681709319484, "content": {"title": "Hellinger KL-UCB based Bandit Algorithms for Markovian and i.i.d. Settings", "abstract": "In the regret-based formulation of Multi-armed Bandit (MAB) problems, except in rare instances, much of the literature focuses on arms with i.i.d. rewards. In this paper, we consider the problem of obtaining regret guarantees for MAB problems in which the rewards of each arm form a Markov chain which may not belong to a single parameter exponential family. To achieve a logarithmic regret in such problems is not difficult: a variation of standard Kullback-Leibler Upper Confidence Bound (KL-UCB) does the job. However, the constants obtained from such an analysis are poor for the following reason: i.i.d. rewards are a special case of Markov rewards and it is difficult to design an algorithm that works well independent of whether the underlying model is truly Markovian or i.i.d. To overcome this issue, we introduce a novel algorithm that identifies whether the rewards from each arm are truly Markovian or i.i.d. using a total variation distance-based test. Our algorithm then switches from using a standard KL-UCB to a specialized version of KL-UCB when it determines that the arm reward is Markovian, thus resulting in low regrets for both i.i.d. and Markovian settings."}}
{"id": "k1YZOegNKx", "cdate": 1546300800000, "mdate": 1681709319486, "content": {"title": "A Structure-aware Online Learning Algorithm for Markov Decision Processes", "abstract": "To overcome the curse of dimensionality and curse of modeling in Dynamic Programming (DP) methods for solving classical Markov Decision Process (MDP) problems, Reinforcement Learning (RL) algorithms are popular. In this paper, we consider an infinite-horizon average reward MDP problem and prove the optimality of the threshold policy under certain conditions. Traditional RL techniques do not exploit the threshold nature of optimal policy while learning. We propose a new RL algorithm which utilizes the known threshold structure of the optimal policy while learning by reducing the feasible policy space. We establish that the proposed algorithm converges to the optimal policy. It provides a significant improvement in convergence speed and computational and storage complexity over traditional RL algorithms. The proposed technique can be applied to a wide variety of optimization problems that include energy efficient data transmission and management of queues. We exhibit the improvement in convergence speed of the proposed algorithm over other RL algorithms through simulations."}}
{"id": "dGLRY_vBC1", "cdate": 1546300800000, "mdate": 1681709319754, "content": {"title": "Optimal Radio Access Technology Selection in an SDN based LTE-WiFi Network", "abstract": ""}}
{"id": "RHOachm1JWA", "cdate": 1546300800000, "mdate": 1681709319474, "content": {"title": "Control and Management of Multiple RATs in Wireless Networks: An SDN Approach", "abstract": "Multiple Radio Access Technologies (RATs) co-exist within today's mobile broadband networks, and each of these RATs is controlled by a different set of entities, leading to fragmented network control. This may lead to sub-optimal utilization of the overall network resources. In this paper, we propose a novel Software Defined Networking (SDN) based network architecture for unified control of multiple RATs and provide a framework for improved network performance over those of the present-day architectures. The proposed architecture enables end-to-end network control while preserving scalability with the help of network slicing. We develop an evaluation platform based on network simulator-3 (ns-3) in accordance with the proposed architecture. We also demonstrate the performance improvements provided by the proposed architecture through simulations."}}
{"id": "4whvkE0LOI", "cdate": 1546300800000, "mdate": 1681709319483, "content": {"title": "Online Reinforcement Learning of Optimal Threshold Policies for Markov Decision Processes", "abstract": "To overcome the curses of dimensionality and modeling of Dynamic Programming (DP) methods to solve Markov Decision Process (MDP) problems, Reinforcement Learning (RL) methods are adopted in practice. Contrary to traditional RL algorithms which do not consider the structural properties of the optimal policy, we propose a structure-aware learning algorithm to exploit the ordered multi-threshold structure of the optimal policy, if any. We prove the asymptotic convergence of the proposed algorithm to the optimal policy. Due to the reduction in the policy space, the proposed algorithm provides remarkable improvements in storage and computational complexities over classical RL algorithms. Simulation results establish that the proposed algorithm converges faster than other RL algorithms."}}
