{"id": "TvKKqWn_-6", "cdate": 1668480873353, "mdate": null, "content": {"title": "Plant Geometry Reconstruction From Field Data Using Neural Radiance Fields", "abstract": "Real-time simulations of large-scale farming operations would provide farmers with data-driven and physics-consistent decision support. These real-time farming simulations could be accomplished using predictive digital twins. Predictive digital twins of biological entities allow for a virtual simulation of real-life processes for various environmental conditions, thus paving the way for a comprehensive understanding of various biological responses. One of the first steps in constructing a predictive digital twin is the 3D reconstruction of plant geometry. While traditional approaches for the reconstruction of plant geometry exist, they require a very expensive setup using a LIDAR or destructive imaging of the plant in a controlled environment. Neural approaches for 3D scene reconstruction have alleviated the data collection burden associated with traditional 3D reconstruction methods. In this work, we demonstrate the ability to generate a 3D reconstruction (mesh) of a maize plant by leveraging a recent work in 3D computer vision, Neural Radiance Fields (NeRFs), which uses data collected from a mobile phone camera. Our approach aims to generate high-resolution geometric models for several downstream tasks, such as developing a predictive digital twin.\n"}}
{"id": "kPM87uCwFq", "cdate": 1668480873287, "mdate": null, "content": {"title": "Optimized Class-specific Data Augmentation for Plant Stress Classification", "abstract": "Data augmentation has the potential to significantly improve the performance of deep learning-based image classifiers. However, a key challenge in applying data augmentation is choosing an effective set of augmentations from a large pool of candidates. Recently, automated augmentation strategies have produced state-of-the-art results for image classification. Most results have focused on improving the total accuracy of the classifier, often at the cost of reduced performance of a finite number of classes. We explore a Genetic Algorithm-based optimization to identify the ideal class-specific augmentations that maximize the mean-per-class accuracy, starting from a well-trained classifier (which serves as our baseline). We illustrate the utility of this strategy on a well-studied problem (and\nassociated dataset) of classifying soybean leaf stresses. Our (preliminary) work indicated improvements over our baseline model and showed improvement in the mean-per-class accuracy from 90.68% to 93.11% across generations. Identifying class-specific augmentations can provide contextual information to end users. This approach is computationally less expensive than traditional Network-Architecture-Search (NAS), as we only seek to fine-tune the baseline classifier."}}
{"id": "39Eh1ifhsj", "cdate": 1668480873089, "mdate": null, "content": {"title": "Out-of-distribution algorithms for robust insect classification", "abstract": "Plants are exposed to various useful and harmful insect pests during their growth cycle. Accurate identification of these pests is critical for deciding on a timely and appropriate mitigation strategy with significant economic and environmental implications. Recent progress in deep learning-based approaches has resulted in insects exhibiting good accuracy. However, deploying them in the wild is still problematic since input images that are wildly out of the distribution (e.g., non-insect images like vehicles, animals, or a blurred image of an insect or insect class that is not yet trained on) can still produce insect classification. To counter this, methods that ensure that a model abstains from making predictions are needed. To address this issue, we leverage the out-of-distribution detection concept that showed promising results in detecting out-of-distribution data in dermatology tasks (Roy et al., 2022).\nIn our work, we evaluate the performance of state-of-the-art out-of-distribution (OOD) \nalgorithms on insect detection classifiers. These algorithms represent a diversity of methods of approaching an OOD problem. Additionally, we focus on extrusive algorithms -- i.e., algorithms that wrap around a pre-trained classifier without the need for additional co-training. We choose three OOD detection algorithms: (i) Maximum Softmax Probability (MSP), commonly referred to as the baseline algorithms, (ii) Mahalanobis distance-based algorithm, which solves the problem using a generative classification approach; and (iii) Energy-Based Model OOD detection algorithm, which exhibits SOTA for OOD detection. We perform an extensive series of evaluations of these OOD algorithms across two performance axes: (a) how the accuracy of the classifier impacts OOD performance and (b) how the degree of out-of-domain impacts OOD performance. Our analysis shows OOD detection algorithms can significantly improve from abstaining classification across different settings of models\u2019 structures and datasets. Thus, our OOD-robust classifier improves user trust in using the application for insect-pests classification."}}
{"id": "vrXKC3eYMU", "cdate": 1668480872946, "mdate": null, "content": {"title": "Data driven ensemble learning for soybean yield prediction", "abstract": "Soybean yield prediction is a challenging problem in agronomy that is often affected by many different factors simultaneously. Hyperspectral reflectance data from plants provide agronomist's with useful data about the health of soybean plants and using this data for yield prediction is an active area of research. Often breeding programs suffer from issues such as data imbalance and several external factors such as genotype variablility in different environment which can pose a serious challenge for developing yield prediction models for large scale breeding programs. In this work we demonstrate a cluster based ensemble approach for yield prediction that can perform well for large scale breeding programs by efficiently harnessing useful information from data through an unsupervised approach.\n"}}
{"id": "VPDKe672pv", "cdate": 1668480872564, "mdate": null, "content": {"title": "Zero-Shot Insect Detection via Weak Language Supervision", "abstract": "Open source image datasets collected via citizen science platforms (such as iNaturalist) can pave the way for the development of powerful AI models for insect detection and classification. However, traditional supervised learning methods require labeled data, and manual annotation of these raw datasets with useful labels (such as bounding boxes) can be extremely laborious, expensive, and error-prone. In this paper, we show that recent advances in vision-language models enable highly accurate zero-shot detection of insects in a variety of challenging environs. Our contributions are twofold: a) We curate the Insecta rank class of iNaturalist to form a new benchmark dataset of approximately 6M images consisting of 2526 agriculturally important species (both pests and beneficial insects). b) Using a vision-language object detection method coupled with weak language supervision, we are able to automatically annotate images in this dataset with bounding box information localizing the insect within each image. Our method succeeds in detection of diverse insect species present in a wide variety of backgrounds, producing high-quality bounding boxes in a zero-shot manner with no additional training cost. "}}
{"id": "62_fMHuggF", "cdate": 1665251229389, "mdate": null, "content": {"title": "A study of natural robustness of deep reinforcement learning algorithms towards adversarial perturbations", "abstract": "Deep reinforcement learning (DRL) has been shown to have numerous potential applications in the real world. However, DRL algorithms are still extremely sensitive to noise and adversarial perturbations, hence inhibiting the deployment of RL in many real-life applications. Analyzing the robustness of DRL algorithms to adversarial attacks is an important prerequisite to enabling the widespread adoption of DRL algorithms. Common perturbations on DRL frameworks during test time include perturbations to the observation and the action channel. Compared with observation channel attacks, action channel attacks are less studied; hence, few comparisons exist that compare the effectiveness of these attacks in DRL literature. In this work, we examined the effectiveness of these two paradigms of attacks on common DRL algorithms and studied the natural robustness of DRL algorithms towards various adversarial attacks in hopes of gaining insights into the individual response of each type of algorithm under different attack conditions. "}}
{"id": "f9Lk1G9q-G-", "cdate": 1664314537199, "mdate": null, "content": {"title": "Generative Design of Material Microstructures for Organic Solar Cells using Diffusion Models", "abstract": "Score-based methods, particularly denoising diffusion probabilistic models (DDPMs), have demonstrated impressive improvements to state-of-the-art generative modeling. Due to their impressive ability to sample from complex distributions, DDPM models and related variants, all broadly categorized under diffusion models, apply to various applications. In this work, we compare the performance of a diffusion model with a Wasserstein Generative Adversarial Network in generating two-phase microstructures of photovoltaic cells. We demonstrate the diffusion model's performance improvements in generating realistic-looking microstructures and its ability to cover several modes of the target distribution."}}
{"id": "3ndIvP2491e", "cdate": 1637384114739, "mdate": null, "content": {"title": "Self-Supervised Learning Improves Agricultural Pest Classification", "abstract": "Globally, crop insect pests lead to 10 \u2013 40% yield loss. However, crop insect pest detection and mitigation remain an extremely challenging task for the farmers, due to several factors. While supervised learning has achieved a remarkable feat in insect detection, it requires significant human intervention in labeling the input data, thereby making the downstream tasks tedious and sometimes infeasible. This is particularly the case for identifying insects in the field, where labeling is tedious. Here, we present a self-supervised learning (SSL) approach \u2013 Bootstrap your own latent (BYOL) to classify 12 types of agricultural insect pests using minimal labeling. Both raw and segmented images were separately fed to the BYOL SSL method, and the linear classification ac-curacies from the representations learned were examined. The results indicate that using segmented images as input to BYOL could lead up to 94% classification accuracy."}}
{"id": "F4eTwol9qne", "cdate": 1637383722199, "mdate": null, "content": {"title": "Deep implicit surface reconstruction of 3D plant geometry from point cloud", "abstract": "Reconstructing the geometry of crops from 3D point cloud data is useful for a variety of plant phenotyping applications. Due to very thin and slender segments, obtaining accurate surface geometry representations from the 3D point cloud data is challenging. Further, defects (noise) and holes (sparsity or occlusion) in the point cloud data might be errors in the reconstructed plant structures. While the reconstruction of a surface from an input point cloud has been studied for decades, recent work on deep learning frameworks that learn neural implicit representations have shown significant promise in accurately reconstructing 3D data, especially under noisy and sparse sampling conditions. However, these approaches have not yet been deployed for slender members. In this work, we explore neural implicit representations to reconstruct the surfaces of fully developed maize plants using data acquired from Terrestrial Laser Scanners (TLS). We compare several neural implicit approaches with more traditional methods of surface reconstruction. We also analyze the robustness of these neural implicit methods for 3D plant data reconstruction. We finally utilize the predicted surface to infer structural features from the data. This approach paves the way for detailed flow/transport simulations of agricultural domains from 3D point cloud data."}}
{"id": "kTHfZzeIoH4", "cdate": 1637383708122, "mdate": null, "content": {"title": "Exploring the use of 3D point cloud data for improved plant stress rating", "abstract": "Currently, automated canopy stress classification for field crops relies on single-perspective, two-dimensional (2D) photographs, typically top view imaging via UAV. However, plant stress symptoms may appear throughout the canopy, and a single viewpoint photograph may not capture the entire region affected by the stress. Recent developments in efficient, large-scale, 3D point cloud capture of agricultural fields open up the possibility of more comprehensive stress identification and rating. We hypothesized that utilizing the 3D point cloud will allow multi-perspective construction of plant canopy, and subsequent training of more accurate plant stress identification and its rating in the field. We utilize an RGB 3D point cloud of a field where a diversity panel of soybean under Iron Deficiency chlorosis (IDC) stress was grown. We explore both multiview projection as well as area-preserving map projection methods to obtain parameterized 2D images depicting the complete 3D canopy surface. This approach allowed us to create models agnostic to canopy size/shape while allowing us to leverage pre-trained deep learning models -- trained on 2D image data. Our preliminary results are promising, and we continue to fine-tune these machine learning pipelines for classifying plant stress expression."}}
