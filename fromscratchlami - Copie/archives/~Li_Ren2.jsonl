{"id": "uQTnrTRpZCb", "cdate": 1546300800000, "mdate": null, "content": {"title": "Improving Diversity of Image Captioning Through Variational Autoencoders and Adversarial Learning", "abstract": "Learning translation from images to human-readable natural language has become a great challenge in computer vision research in recent years. Existing works explore the semantic correlation between the visual and language domains via encoder-to-decoder learning frameworks based on classifying visual features in the language domain. This approach, however, is criticized for its lacking of naturalness and diversity. In this paper, we demonstrate a novel way to learn a semantic connection between visual information and natural language directly based on a Variational Autoencoder (VAE) that is trained in an adversarial routine. Instead of using the classification based discriminator, our method directly learns to estimate the diversity between a hidden vector embedded from a text encoder and an informative feature that is sampled from a learned distribution of the autoencoders. We show that the sentences learned from this matching contains accurate semantic meaning with high diversity in the image captioning task. Our experiments on the popular MSCOCO dataset indicates that our method learns to generate high-quality natural language with competitive scores on both correctness and diversity."}}
{"id": "TPgs-CHBngO", "cdate": 1514764800000, "mdate": null, "content": {"title": "Improved Image Description Via Embedded Object Structure Graph and Semantic Feature Matching", "abstract": "Image description has become a popular topic in multimedia computing and computer vision areas. Recent works have demonstrated that learning the local semantic concepts, in addition to the image features, as the contextual information can help to understand the image scene better. However, current image description methods treating the local features as the bag-of-visual-words that do not capture the interaction and structure of the objects embedded in the image. In this paper, we propose a novel captioning framework that learns to integrate local concepts with their geometry structure as the side information. We design an Object Structure Graph to encode the positions and the distribution of the objects in the image. In order to embed the graph into an efficient representation, we introduce a semantic matching schema that matches our embedded graph with their corresponding sentence. Our experiments based on the public image captioning data sets, the MS-COCO and the Flickr30k, show that our improved solution is significantly better than current state-of-the-art techniques that leverage local semantic concepts; and our best model on the same splitting has competitive results compared to other recent approaches."}}
{"id": "vq808xX1lr6", "cdate": 1451606400000, "mdate": null, "content": {"title": "Representing 3D shapes based on implicit surface functions learned from RBF neural networks", "abstract": "Highlights \u2022 We propose a 3D shape representation method based on neural network classifier. \u2022 The combination of radial base functions can implicitly represent complex shapes. \u2022 The use of neural network can represent the shape with 3 classes of points. \u2022 We conduct extensive experiments on medical and non-medical data. \u2022 Our method can accurately and memory-efficiently represent shapes. \u2022 We introduced a new prostate dataset. Abstract We propose to represent the shape of 3D objects using a neural network classifier. The 3D shape is learned from a neural network, where Radial Basis Function (RBF) is applied as the activation function for each perceptron. The implicit functions derived from the neural network is a combination of radial basis functions, which can represent complex shapes. The use of RBF provides a rotation, translation and scaling invariant feature to represent the shape. We conduct experiments on a new prostate dataset and public datasets. Our testing results show that our neural network-based method can accurately represent various shapes."}}
{"id": "Cjr35oWzv2B", "cdate": 1451606400000, "mdate": null, "content": {"title": "Neural network shape: Organ shape representation with radial basis function neural networks", "abstract": "We propose to represent the shape of an organ using a neural network classifier. The shape is represented by a function learned by a neural network. Radial Basis Function (RBF) is used as the activation function for each perceptron. The learned implicit function is a combination of radial basis functions, which can represent complex shapes. The organ shape representation is learned using classification methods. Our testing results show that the neural network shape provides the best representation accuracy. The use of RBF provides a rotation, translation and scaling invariant feature to represent the shape. Experiments show that our method can accurately represent the organ shape."}}
{"id": "7i96qEbmvm", "cdate": 1451606400000, "mdate": null, "content": {"title": "Where am I in the dark: Exploring active transfer learning on the use of indoor localization based on thermal imaging", "abstract": "Indoor localization is one of the key problems in robotics research. Most current localization systems use cellular base stations and Wifi signals, whose localization accuracy is largely dependent on the signal strength and is sensitive to environmental changes. With the development of camera-based technologies, image-based localization may be employed in an indoor environment where the GPS signal is weak. Most of the existing image-based localization systems are based on color images captured by cameras, but this is only feasible in environments with adequate lighting conditions. In this paper, we introduce an image-based localization system based on thermal imaging to make the system independent of light sources, which are especially useful during emergencies such as a sudden power outage in a building. As thermal images are not obtained as easily as color images, we apply active transfer learning to enrich the thermal image classification learning, where normal RGB images are treated as the source domain, and thermal images are the target domain. The application of active transfer learning avoids random target training sample selection and chooses the most informative samples in the learning process. Through the proposed active transfer learning, the query thermal images can be accurately used to indicate the location. Experiments show that our system can be efficiently deployed to perform indoor localization in a dark environment."}}
{"id": "BkZTVWz_bB", "cdate": 1420070400000, "mdate": null, "content": {"title": "Localize Me Anywhere, Anytime: A Multi-task Point-Retrieval Approach", "abstract": "Image-based localization is an essential complement to GPS localization. Current image-based localization methods are based on either 2D-to-3D or 3D-to-2D to find the correspondences, which ignore the real scene geometric attributes. The main contribution of our paper is that we use a 3D model reconstructed by a short video as the query to realize 3D-to-3D localization under a multi-task point retrieval framework. Firstly, the use of a 3D model as the query enables us to efficiently select location candidates. Furthermore, the reconstruction of 3D model exploits the correlations among different images, based on the fact that images captured from different views for SfM share information through matching features. By exploring shared information (matching features) across multiple related tasks (images of the same scene captured from different views), the visual feature's view-invariance property can be improved in order to get to a higher point retrieval accuracy. More specifically, we use multi-task point retrieval framework to explore the relationship between descriptors and the 3D points, which extracts the discriminant points for more accurate 3D-to-3D correspondences retrieval. We further apply multi-task learning (MTL) retrieval approach on thermal images to prove that our MTL retrieval framework also provides superior performance for the thermal domain. This application is exceptionally helpful to cope with the localization problem in an environment with limited light sources."}}
