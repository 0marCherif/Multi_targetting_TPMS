{"id": "j99cFDoVxCP", "cdate": 1733011200000, "mdate": 1706347981645, "content": {"title": "Cardiac murmur grading and risk analysis of cardiac diseases based on adaptable heterogeneous-modality multi-task learning", "abstract": "Cardiovascular disease (CVDs) has become one of the leading causes of death, posing a significant threat to human life. The development of reliable Artificial Intelligence (AI) assisted diagnosis algorithms for cardiac sounds is of great significance for early detection and treatment of CVDs. However, there is scarce research in this field. Existing research mainly faces three major challenges: (1) They mainly limited to murmur classification and cannot achieve murmur grading, but attempting both classification and grading may lead to negative effects between different multi-tasks. (2) They mostly pay attention to unstructured cardiac sound modality and do not consider the structured demographic modality, as it is difficult to balance the influence of heterogeneous modalities. (3) Deep learning methods lack interpretability, which makes it challenging to apply them clinically. To tackle these challenges, we propose a method for cardiac murmur grading and cardiac risk analysis based on heterogeneous modality adaptive multi-task learning. Specifically, a Hierarchical Multi-Task learning-based cardiac murmur detection and grading method (HMT) is proposed to prevent negative interference between different tasks. In addition, a cardiac risk analysis method based on Heterogeneous Multi-modal feature impact Adaptation (HMA) is also proposed, which transforms unstructured modality into structured modality representation, and utilizes an adaptive mode weight learning mechanism to balance the impact between unstructured modality and structured modality, thus enhancing the performance of cardiac risk prediction. Finally, we propose a multi-task interpretability learning module that incorporates an important evaluation using random masks. This module utilizes SHAP graphs to visualize crucial murmur segments in cardiac sound and employs a multi-factor risk decoupling model based on nomograms. And then we gain insights into the cardiac disease risk in both pre-decoupled multi-modality and post-decoupled single-modality scenarios, thus providing a solid foundation for AI assisted cardiac murmur grading and risk analysis. Experimental results on a large real-world CirCor DigiScope PCG dataset demonstrate that the proposed method outperforms the state-of-the-art (SOTA) method in murmur detection, grading, and cardiac risk analysis, while also providing valuable diagnostic evidence."}}
{"id": "ZFPnS2JW3IW", "cdate": 1709251200000, "mdate": 1706347981694, "content": {"title": "Time pattern reconstruction for classification of irregularly sampled time series", "abstract": ""}}
{"id": "V2XU80v8rd25", "cdate": 1706745600000, "mdate": 1706347981898, "content": {"title": "Individual and Structural Graph Information Bottlenecks for Out-of-Distribution Generalization", "abstract": "Out-of-distribution (OOD) graph generalization are critical for many real-world applications. Existing methods neglect to discard spurious or noisy features of inputs, which are irrelevant to the label. Besides, they mainly conduct instance-level class-invariant graph learning and fail to utilize the structural class relationships between graph instances. In this work, we endeavor to address these issues in a unified framework, dubbed <bold xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">I</b> ndividual and <bold xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">S</b> tructural <bold xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">G</b> raph <bold xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">I</b> nformation <bold xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">B</b> ottlenecks ( <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">IS-GIB</i> ). To remove class spurious feature caused by distribution shifts, we propose Individual Graph Information Bottleneck (I-GIB) which discards irrelevant information by minimizing the mutual information between the input graph and its embeddings. To leverage the structural intra- and inter-domain correlations, we propose Structural Graph Information Bottleneck (S-GIB). Specifically for a batch of graphs with multiple domains, S-GIB first computes the pair-wise input-input, embedding-embedding, and label-label correlations. Then it minimizes the mutual information between input graph and embedding pairs while maximizing the mutual information between embedding and label pairs. The critical insight of S-GIB is to simultaneously discard spurious features and learn invariant features from a high-order perspective by maintaining class relationships under multiple distributional shifts. Notably, we unify the proposed I-GIB and S-GIB to form our complementary framework IS-GIB. Extensive experiments conducted on both node- and graph-level tasks consistently demonstrate the superior generalization ability of IS-GIB."}}
{"id": "tlaXSQn4ka", "cdate": 1704067200000, "mdate": 1706347981745, "content": {"title": "A Systematic Review of Echo State Networks From Design to Application", "abstract": "A recurrent neural network (RNN) has demonstrated its outstanding ability in sequence tasks and has achieved state of the art in many applications, such as industrial and medical. An echo state network (ESN) is a simple type of RNN and has emerged in the last decade as an alternative to gradient descent training-based RNN. The ESN is practical, conceptually simple, and easy to implement with a strong theoretical ground. It can avoid nonconverging and computationally expensive issues in gradient descent RNN methods. Since the ESN was put forward in 2002, abundant existing works have promoted the progress of ESN, and the recently introduced deep ESN opened the way to uniting the merits of deep learning and reservoir computing. Besides, the combinations of ESNs with other machine learning models have also overperformed baselines in some applications. However, the apparent simplicity of ESNs can sometimes be deceptive. Successfully applying ESNs needs some experience. Thus, we reviewed over 300 related papers and provided a systematic overview for the first time. In this article, we categorize the related methods into classical ESN, DeepESN, and combination. Then, we analyze them from the perspective of network designs and specific applications. Finally, we discuss the challenges and opportunities by proposing open problems and future work."}}
{"id": "G5QYeFMGb_", "cdate": 1704067200000, "mdate": 1706347981718, "content": {"title": "Improving Diffusion-Based Image Synthesis with Context Prediction", "abstract": "Diffusion models are a new class of generative models, and have dramatically promoted image generation with unprecedented quality and diversity. Existing diffusion models mainly try to reconstruct input image from a corrupted one with a pixel-wise or feature-wise constraint along spatial axes. However, such point-based reconstruction may fail to make each predicted pixel/feature fully preserve its neighborhood context, impairing diffusion-based image synthesis. As a powerful source of automatic supervisory signal, context has been well studied for learning representations. Inspired by this, we for the first time propose ConPreDiff to improve diffusion-based image synthesis with context prediction. We explicitly reinforce each point to predict its neighborhood context (i.e., multi-stride features/tokens/pixels) with a context decoder at the end of diffusion denoising blocks in training stage, and remove the decoder for inference. In this way, each point can better reconstruct itself by preserving its semantic connections with neighborhood context. This new paradigm of ConPreDiff can generalize to arbitrary discrete and continuous diffusion backbones without introducing extra parameters in sampling procedure. Extensive experiments are conducted on unconditional image generation, text-to-image generation and image inpainting tasks. Our ConPreDiff consistently outperforms previous methods and achieves a new SOTA text-to-image generation results on MS-COCO, with a zero-shot FID score of 6.21."}}
{"id": "r5P9uFE1wl", "cdate": 1693526400000, "mdate": 1706347981773, "content": {"title": "SPL-LDP: a label distribution propagation method for semi-supervised partial label learning", "abstract": "Partial label learning learns from examples represented by a single instance while associated with multiple candidate labels, among which only one valid label resides. However, in real-world applications, collecting candidate label sets for all training examples is costly. As unlabeled data are being considered as a indispensable ingredient for low-cost computing, the semi-supervised partial label learning underlying propagating labels between partially labeled and unlabeled instances has grown progressively momentous. Nevertheless, the noisy information carried by false-positive instances hides in the candidate label sets and is propagated as well. In this work, we propose a label distribution propagation based approach, namely Spl-ldp, which can jointly learn from partially labeled and unlabeled instances. Specifically, the label distribution of partially labeled instances is mined based on the topological information. Instead of directly logic label propagation, an iterative label distribution propagation procedure between partially labeled and unlabeled instances is subsequently employed to leverage the data distribution of unlabeled instances. Unseen instances are classified with the minimum reconstruction error on the whole data sets. Extensive experiments on five real-world data sets show that the proposed Spl-ldp method performs favorably against baselines."}}
{"id": "o79BzYc29o", "cdate": 1690848000000, "mdate": 1706347981684, "content": {"title": "Adaptive model training strategy for continuous classification of time series", "abstract": "The classification of time series is essential in many real-world applications like healthcare. The class of a time series is usually labeled at the final time, but more and more time-sensitive applications require classifying time series continuously. For example, the outcome of a critical patient is only determined at the end, but he should be diagnosed at all times for timely treatment. For this demand, we propose a new concept, Continuous Classification of Time Series (CCTS). Different from the existing single-shot classification, the key of CCTS is to model multiple distributions simultaneously due to the dynamic evolution of time series. But the deep learning model will encounter intertwined problems of catastrophic forgetting and over-fitting when learning multi-distribution. In this work, we found that the well-designed distribution division and replay strategies in the model training process can help to solve the problems. We propose a novel Adaptive model training strategy for CCTS (ACCTS). Its adaptability represents two aspects: (1) Adaptive multi-distribution extraction policy. Instead of the fixed rules and the prior knowledge, ACCTS extracts data distributions adaptive to the time series evolution and the model change; (2) Adaptive importance-based replay policy. Instead of reviewing all old distributions, ACCTS only replays important samples adaptive to their contribution to the model. Experiments on four real-world datasets show that our method outperforms all baselines."}}
{"id": "VAr19J0s2J", "cdate": 1684991690811, "mdate": 1684991690811, "content": {"title": "Diffusion Models: A Comprehensive Survey of Methods and Applications", "abstract": "Diffusion models have emerged as a powerful new family of deep generative models with record-breaking performance in many\napplications, including image synthesis, video generation, and molecule design. In this survey, we provide an overview of the rapidly\nexpanding body of work on diffusion models, categorizing the research into three key areas: efficient sampling, improved likelihood\nestimation, and handling data with special structures. We also discuss the potential for combining diffusion models with other generative\nmodels for enhanced results. We further review the wide-ranging applications of diffusion models in fields spanning from computer\nvision, natural language processing, temporal data modeling, to interdisciplinary applications in other scientific disciplines. This\nsurvey aims to provide a contextualized, in-depth look at the state of diffusion models, identifying the key areas of focus and pointing\nto potential areas for further exploration."}}
{"id": "XNX_HqItXK6H", "cdate": 1682899200000, "mdate": 1706347982004, "content": {"title": "Self-sovereign identity empowered non-fungible patient tokenization for health information exchange using blockchain technology", "abstract": ""}}
{"id": "ukiUmLLjZ0", "cdate": 1675209600000, "mdate": 1706347981708, "content": {"title": "Continuous diagnosis and prognosis by controlling the update process of deep neural networks", "abstract": ""}}
