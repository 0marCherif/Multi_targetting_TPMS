{"id": "vd6Ii6q2ChZ", "cdate": 1672531200000, "mdate": 1681689373312, "content": {"title": "Dialogue Response Evaluation Model with Conversational Feature Sensitive Negative Sampling", "abstract": "Evaluating the conversational responses is a challenging task. This is because there are so many possible responses in open-domain conversation. Recent work finds that appropriate negative samples are effective in practice, but there was problem that labeled conversational negative sample was insufficient. It is important to create an appropriate negative sample automatically because it is too costly to create all possible responses by person and annotate the response\u2019s coherence score. To address this problem, we propose a method for generating and labeling feature sensitive negative responses for conversation automatically. Besides, we show that the model learned with the generated negative sample performs well with high correlation between human score and model score."}}
{"id": "fRoXSbZyJGb", "cdate": 1672531200000, "mdate": 1695970167060, "content": {"title": "A Transformer-based Function Symbol Name Inference Model from an Assembly Language for Binary Reversing", "abstract": "Reverse engineering of a stripped binary has a wide range of applications, yet it is challenging mainly due to the lack of contextually useful information within. Once debugging symbols (e.g., variable names, types, function names) are discarded, recovering such information is not technically viable with traditional approaches like static or dynamic binary analysis. We focus on a function symbol name recovery, which allows a reverse engineer to gain a quick overview of an unseen binary. The key insight is that a well-developed program labels a meaningful function name that describes its underlying semantics well. In this paper, we present AsmDepictor, the Transformer-based framework that generates a function symbol name from a set of assembly codes (i.e., machine instructions), which consists of three major components: binary code refinement, model training, and inference. To this end, we conduct systematic experiments on the effectiveness of code refinement that can enhance an overall performance. We introduce the per-layer positional embedding and Unique-softmax for AsmDepictor so that both can aid to capture a better relationship between tokens. Lastly, we devise a novel evaluation metric tailored for a short description length, the Jaccard* score. Our empirical evaluation shows that the performance of AsmDepictor by far surpasses that of the state-of-the-art models up to around 400%. The best AsmDepictor model achieves an F1 of 71.5 and Jaccard* of 75.4."}}
{"id": "ZC0HJHXSWE", "cdate": 1672531200000, "mdate": 1695970167062, "content": {"title": "A Transformer-based Function Symbol Name Inference Model from an Assembly Language for Binary Reversing", "abstract": "Reverse engineering of a stripped binary has a wide range of applications, yet it is challenging mainly due to the lack of contextually useful information within. Once debugging symbols (e.g., variable names, types, function names) are discarded, recovering such information is not technically viable with traditional approaches like static or dynamic binary analysis. We focus on a function symbol name recovery, which allows a reverse engineer to gain a quick overview of an unseen binary. The key insight is that a well-developed program labels a meaningful function name that describes its underlying semantics well. In this paper, we present AsmDepictor, the Transformer-based framework that generates a function symbol name from a set of assembly codes (i.e., machine instructions), which consists of three major components: binary code refinement, model training, and inference. To this end, we conduct systematic experiments on the effectiveness of code refinement that can enhance an overall performance. We introduce the per-layer positional embedding and Unique-softmax for AsmDepictor so that both can aid to capture a better relationship between tokens. Lastly, we devise a novel evaluation metric tailored for a short description length, the Jaccard* score. Our empirical evaluation shows that the performance of AsmDepictor by far surpasses that of the state-of-the-art models up to around 400%. The best AsmDepictor model achieves an F1 of 71.5 and Jaccard* of 75.4."}}
{"id": "G9f3PUBzUv", "cdate": 1672531200000, "mdate": 1695970167061, "content": {"title": "Conversational Emotion-Cause Pair Extraction with Guided Mixture of Experts", "abstract": ""}}
{"id": "tBD_BUdbtby", "cdate": 1640995200000, "mdate": 1680275488864, "content": {"title": "Translating Hanja Historical Documents to Contemporary Korean and English", "abstract": ""}}
{"id": "oB9gmXQ77R", "cdate": 1640995200000, "mdate": 1675481670042, "content": {"title": "Forest-Fire Response System Using Deep-Learning-Based Approaches With CCTV Images and Weather Data", "abstract": "An effective forest-fire response is critical for minimizing the losses caused by forest fires. The purpose of this study is to construct a model for early fire detection and damage area estimation for response systems based on deep learning. First, we implement neural architecture search-based object detection (DetNAS) for searching optimal backbone. Backbone networks play a crucial role in the application of deep learning-based models, as they have a significant impact on the performance of the model. A large-scale fire dataset with approximately 400,000 images is used to train and test object-detection models. Then, the searched light-weight backbone is compared with well-known backbones, such as ResNet, VoVNet, and FBNetV3. In addition, we propose damage area estimation method using Bayesian neural network (BNN), data pertaining to six years of historical forest fire events are employed to estimate the damaged area. Subsequently, a weather API is used to match the recorded events. A BNN model is used as a regression model to estimate the damaged area. Additionally, the trained model is compared with other widely used regression models, such as decision trees and neural networks. The Faster R-CNN with a searched backbone achieves a mean average precision of 27.9 on 40,000 testing images, outperforming existing backbones. Compared with other regression models, the BNN estimates the damage area with less error and increased generalization. Thus, both proposed models demonstrate their robustness and suitability for implementation in real-world systems."}}
{"id": "h0HZdDSiMb", "cdate": 1640995200000, "mdate": 1654526190536, "content": {"title": "Translating Hanja historical documents to understandable Korean and English", "abstract": "The Annals of Joseon Dynasty (AJD) contain the daily records of the Kings of Joseon, the 500-year kingdom preceding the modern nation of Korea. The Annals were originally written in an archaic Korean writing system, `Hanja', and translated into Korean from 1968 to 1993. However, this translation was literal and contained many archaic Korean words; thus, a new expert translation effort began in 2012, completing the records of only one king in a decade. Also, expert translators are working on an English translation, of which only one king's records are available because of the high cost and slow progress. Thus, we propose H2KE, the neural machine translation model that translates Hanja historical documents to understandable Korean and English. Based on the multilingual neural machine translation approach, it translates the historical document written in Hanja, using both the full dataset of outdated Korean translation and a small dataset of recently translated Korean and English. We compare our method with two baselines: one is a recent model that simultaneously learns to restore and translate Hanja historical document and the other is the transformer that trained on newly translated corpora only. The results show that our method significantly outperforms the baselines in terms of BLEU score in both modern Korean and English translations. We also conduct a human evaluation that shows that our translation is preferred over the original expert translation."}}
{"id": "Xme8N6GTzO", "cdate": 1640995200000, "mdate": 1654526190532, "content": {"title": "Genre-Controllable Story Generation via Supervised Contrastive Learning", "abstract": "While controllable text generation has received attention due to the recent advances in large-scale pre-trained language models, there is a lack of research that focuses on story-specific controllability. To address this, we present Story Control via Supervised Contrastive learning model (SCSC), to create a story conditioned on genre. For this, we design a supervised contrastive objective combined with log-likelihood objective, to capture the intrinsic differences among the stories in different genres. The results of our automated evaluation and user study demonstrate that the proposed method is effective in genre-controlled story generation."}}
{"id": "ONiK_pnVAh0", "cdate": 1640995200000, "mdate": 1680275488898, "content": {"title": "HUE: Pretrained Model and Dataset for Understanding Hanja Documents of Ancient Korea", "abstract": ""}}
{"id": "Lmdh45-1or", "cdate": 1640995200000, "mdate": 1675481670139, "content": {"title": "Advanced wildfire detection using generative adversarial network-based augmented datasets and weakly supervised object localization", "abstract": ""}}
