{"id": "qeK984DqTjB", "cdate": 1679929194009, "mdate": 1679929194009, "content": {"title": "CoVerD: Community-Based Vertex Defense Against Crawling Adversaries", "abstract": "The problem of hiding a node inside of a network in the presence of an unauthorized crawler has been shown to be NP-complete. The available heuristics tackle this problem from mainly two perspectives: (1) the local immediate neighborhood of the target node (local perturbation models) and (2) the global structure of the graph (global perturbation models). While the objective of both is similar (i.e., decreasing the centrality of the target node), they vary substantially in their performance and efficiency; the global measures are computationally inefficient in the real-world scenarios, while the local perturbation methods deal with the problem of constrained performance. In this study, we propose a community-based heuristic, CoVerD, that retains both the computational efficiency of local methods and the superior performance of global methods in minimizing the target\u2019s closeness centrality. Our experiments on five real-world networks show a significant increase in performance by using CoVerD against both BFS and DFS crawling attacks. In some instances, our algorithm successfully increased the crawler\u2019s budget by 3 and 10 times compared to the next best-performing benchmark. The results of this study show the importance of the local community structure in preserving the privacy of the nodes in a network, and pave a promising path for designing scalable and effective network protection models."}}
{"id": "5dOa7H6lmg", "cdate": 1679929034511, "mdate": 1679929034511, "content": {"title": "ComMit: Blind Community-based Early Mitigation Strategy against Viral Spread", "abstract": "In the early stages of a pandemic, epidemiological knowledge of the disease is limited and no vaccination is available. This poses the problem of determining an Early Mitigation Strategy. Previous studies have tackled this problem through finding globally influential nodes that contribute the most to the spread. These methods are often not practical due to their assumptions that (1) accessing the full contact social network is possible; (2) there is an unlimited budget for the mitigation strategy; (3) healthy individuals can be isolated for indefinite amount of time, which in practice can have serious mental health and economic consequences. In this work, we study the problem of developing an early mitigation strategy from a community perspective and propose a dynamic Community-based Mitigation strategy, ComMit. The distinguishing features of ComMit are: (1) It is agnostic to the dynamics of the spread; (2) does not require prior knowledge of contact network; (3) it works within a limited budget; and (4) it enforces bursts of short-term restriction on small communities instead of long-term isolation of healthy individuals. ComMit relies on updated data from test-trace reports and its strategy evolves over time. We have tested ComMit on several real-world social networks. The results of our experiments show that, within a small budget, ComMit can reduce the peak of infection by 73% and shorten the duration of infection by 90%, even for spreads that would reach a steady state of non-zero infections otherwise (e.g., SIS contagion model)."}}
{"id": "7WQvXisyALT", "cdate": 1620386256273, "mdate": null, "content": {"title": "NetProtect: Network Perturbations to Protect Nodes against Entry-Point Attack", "abstract": "In many network applications, it may be desirable to conceal certain target nodes from detection by a data collector, who is using a crawling algorithm to explore a network. For example, in a computer network, the network administrator may wish to protect those computers (target nodes) with sensitive information from discovery by a hacker who has exploited vulnerable machines and entered the network. These networks are often protected by hiding the machines (nodes) from external access, and allow only fixed entry points into the system (protection against external attacks). However, in this protection scheme, once one of the entry points is breached, the safety of all internal machines is jeopardized (i.e., the external attack turns into an internal attack). In this paper, we view this problem from the perspective of the data protector. We propose the Node Protection Problem: given a network with known entry points, which edges should be removed/added so as to protect as many target nodes from the data collector as possible? A trivial way to solve this problem would be to simply disconnect either the entry points or the target nodes \u2013 but that would make the network non-functional. Accordingly, we impose certain constraints: for each node, only (1 \u2212 r) fraction of its edges can be removed, and the resulting network must not be disconnected. We propose two novel scoring mechanisms - the Frequent Path Score and the Shortest Path Score. Using these scores, we propose NetProtect, an algorithm that selects edges to be removed or added so as to best impede the progress of the data collector. We show experimentally that NetProtect outperforms baseline node protection algorithms across several real-world networks. In some datasets, With 1% of the edges removed by NetProtect, we found that the data collector requires up to 6 (4) times the budget compared to the next best baseline in order to discover 5 (50) nodes."}}
{"id": "pAicmmFFCey", "cdate": 1620386043259, "mdate": null, "content": {"title": "Network-Based Analysis of Early Pandemic Mitigation Strategies, Solutions, and Future Directions", "abstract": "Despite the large amount of literature on mitigation strategies for pandemic spread, in practice, we are still limited by na\\\"ive strategies, such as lockdowns, that are not effective in controlling the spread of the disease in long term. One major reason behind adopting basic strategies in real-world settings is that, in the early stages of a pandemic, we lack knowledge of the behavior of a disease, and so cannot tailor a more sophisticated response. In this study, we design different mitigation strategies for early stages of a pandemic and perform a comprehensive analysis among them. We then propose a novel community-based isolation method and show its efficacy in reducing the speed of the spread by a large margin as compared to current methods. We also show that the test-trace-isolation strategy can outperform lockdown and random test-trace in reducing the economic impact and spread of the disease if combined with k-hop neighborhood ranking. The novelty of our work lies in using network structural properties (local and global) to design a strategy for the early stages of a pandemic. Our results encourage further investigation into community-based mitigation strategies and shed more light on the differences between current methods of choice in practical setting."}}
{"id": "64D1x_CM-Q", "cdate": 1600726580002, "mdate": null, "content": {"title": "Python Source Code De-Anonymization Using Nested Bigrams", "abstract": "An important issue in cybersecurity is the insertionor  modification  of  code  by  individuals  other  than  the  original authors   of   the   code.   This   motivates   research   on   authorship attribution  of  unknown  source  code.  We  have  addressed  the deficiencies  of  previously  used  feature  extraction  methods  and propose a novel approach:Nested Bigrams. Such features are easy to extract and carry substantial information about the interconnections  between  the  nodes  of  the  abstract  syntax  tree.  We  also show  that  for  large  number  of  authors,  a Strongly RegularizedFeed-forward Neural Networkoutperforms the  Random  ForestClassifier used in many code stylometric studies. A new ranking system for reducing the number of features is also proposed, and experiments  show  that  this  approach  can  reduce  the  feature  set to 98 nested bigrams while maintaining a classification accuracy above  90  percent."}}
{"id": "4o5leiywYkK", "cdate": 1600726254714, "mdate": null, "content": {"title": "Zero-Shot Source Code Author Identification: A Lexical and Layout Independent Approach", "abstract": "Current author identification approaches for sourcecode rely heavily on a rich set of code samples from each author for training.  In a  real-world setting, the scarcity of the  historical record of the authors\u2019 code samples makes the training impossible. Additionally, to support the identification of yet unseen authors, retraining  is needed.  We tackle the challenge of  \u201czero-shot\u201d recognition of  authors  outside  of  the  training  distribution  usinga strongly-supervised learning approach;Feedforward DuplicatedResolver (FDR)model.  A  feedforward  network  is  first  trainedusing  labeled  data,  and  a  substantial  part  of  this  network  isduplicated   and   reused   to   compare   code   samples.   The   inputfeatures to the network areVariable-Independent Nested Bigramsextracted from the Abstract Syntax Trees of code samples; theseare designed to be robust against lexical and layout obfuscationattacks frequently used in plagiarism attempts. We show that thisapproach  performs  accurately  even  on  code  samples  with  newauthors (AUC of 0.96 and 0.91 for non-obfuscated and obfuscatedcode respectively), using a crawled dataset of Google Code Jam,an  international  coding  competition  platform.  This  is  the  first work  that  successfully  implements  zero-shot  learning  of  coding style."}}
