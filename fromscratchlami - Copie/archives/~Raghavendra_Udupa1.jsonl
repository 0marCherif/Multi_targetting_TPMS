{"id": "taRmd8hF3B", "cdate": 1673850864774, "mdate": 1673850864774, "content": {"title": "ProtoNN: Compressed and accurate kNN for resource-scarce devices", "abstract": "Several real-world applications require real-time prediction on resource-scarce devices such as an Internet of Things (IoT) sensor. Such applications demand prediction models with small storage and computational complexity that do not compromise significantly on accuracy. In this work, we propose ProtoNN, a novel algorithm that addresses the problem of real-time and accurate prediction on resource-scarce devices. ProtoNN is inspired by k-Nearest Neighbor (KNN) but has several orders lower storage and prediction complexity. ProtoNN models can be deployed even on devices with puny storage and computational power (e.g. an Arduino UNO with 2kB RAM) to get excellent prediction accuracy. ProtoNN derives its strength from three key ideas: a) learning a small number of prototypes to represent the entire training set, b) sparse low dimensional projection of data, c) joint discriminative learning of the projection and prototypes with explicit model size constraint. We conduct systematic empirical evaluation of ProtoNN on a variety of supervised learning tasks (binary, multi-class, multi-label classification) and show that it gives nearly state-of-the-art prediction accuracy on resource-scarce devices while consuming several orders lower storage, and using minimal working memory."}}
{"id": "rJVXz3WdZB", "cdate": 1483228800000, "mdate": null, "content": {"title": "ProtoNN: Compressed and Accurate kNN for Resource-scarce Devices", "abstract": "Several real-world applications require real-time prediction on resource-scarce devices such as an Internet of Things (IoT) sensor. Such applications demand prediction models with small storage and..."}}
{"id": "Bk-a2S-u-S", "cdate": 1451606400000, "mdate": null, "content": {"title": "InLook: Revisiting Email Search Experience", "abstract": "Emails continue to remain the most important and widely used mode of online communication despite having its origins in the middle of last century and being threatened by a variety of online communication innovations. While several studies have predicted the continuous growth of volume of email communication, there is little innovation on improving the search in emails, an imperative part of the user experience. In this work, we present a lightweight email application codenamed InLook, that intends to provide a productive search experience."}}
{"id": "rJbEml-OWS", "cdate": 1420070400000, "mdate": null, "content": {"title": "On Correcting Misspelled Queries in Email Search", "abstract": "We consider the problem of providing spelling corrections for misspelled queries in Email Search using user's own mail data. A popular strategy for general query spelling correction is to generate corrections from query logs. However, this strategy is not effective in Email Search for two reasons: 1) query log of any single user is typically not rich enough to provide potential corrections for a new query 2) corrections generated using query logs of other users are not particularly useful since the mail data as well as search intent are highly specific to the user. We address the challenge of designing an effective spelling correction algorithm for Email Search in the absence of query logs. We propose SpEQ, a Machine Learning based approach that generates corrections for misspelled queries directly from the user's own mail data."}}
{"id": "BJZb7W-OWH", "cdate": 1325376000000, "mdate": null, "content": {"title": "Extracting advertising keywords from URL strings", "abstract": "Extracting advertising keywords from web-pages is important in keyword-based online advertising. Previous works have attempted to extract advertising keywords from the whole content of a web-page. However, in some scenarios, it is necessary to extract keywords from just the URL string itself. In this work, we propose an algorithm for extracting advertising keywords from the URL string alone. Our algorithm has applications in contextual and paid search advertising. We evaluate the effectiveness of our algorithm on publisher URLs and show that it produces very good quality keywords that are comparable with keywords produced by page based extractors."}}
{"id": "ryZTnixdbB", "cdate": 1293840000000, "mdate": null, "content": {"title": "From Bilingual Dictionaries to Interlingual Document Representations", "abstract": "Mapping documents into an interlingual representation can help bridge the language barrier of a cross-lingual corpus. Previous approaches use aligned documents as training data to learn an interlingual representation, making them sensitive to the domain of the training data. In this paper, we learn an interlingual representation in an unsupervised manner using only a bilingual dictionary. We first use the bilingual dictionary to find candidate document alignments and then use them to find an interlingual representation. Since the candidate alignments are noisy, we develop a robust learning algorithm to learn the interlingual representation. We show that bilingual dictionaries generalize to different domains better: our approach gives better performance than either a word by word translation method or Canonical Correlation Analysis (CCA) trained on a different domain."}}
{"id": "SkWWxMMO-r", "cdate": 1293840000000, "mdate": null, "content": {"title": "Improving Bilingual Projections via Sparse Covariance Matrices", "abstract": "Mapping documents into an interlingual representation can help bridge the language barrier of cross-lingual corpora. Many existing approaches are based on word co-occurrences extracted from aligned training data, represented as a covariance matrix. In theory, such a covariance matrix should represent semantic equivalence, and should be highly sparse. Unfortunately, the presence of noise leads to dense covariance matrices which in turn leads to suboptimal document representations. In this paper, we explore techniques to recover the desired sparsity in covariance matrices in two ways. First, we explore word association measures and bilingual dictionaries to weigh the word pairs. Later, we explore different selection strategies to remove the noisy pairs based on the association scores. Our experimental results on the task of aligning comparable documents shows the efficacy of sparse covariance matrices on two data sets from two different language pairs."}}
{"id": "HkbQNXfuWr", "cdate": 1293840000000, "mdate": null, "content": {"title": "Learning Hash Functions for Cross-View Similarity Search", "abstract": "Many applications in Multilingual and Multimodal Information Access involve searching large databases of high dimensional data objects with multiple (conditionally independent) views. In this work we consider the problem of learning hash functions for similarity search across the views for such applications. We propose a principled method for learning a hash function for each view given a set of multiview training data objects. The hash functions map similar objects to similar codes across the views thus enabling cross-view similarity search. We present results from an extensive empirical study of the proposed approach which demonstrate its effectiveness on Japanese language People Search and Multilingual People Search problems."}}
{"id": "SybYArWOWr", "cdate": 1262304000000, "mdate": null, "content": {"title": "Suggesting related topics in web search", "abstract": "Suggesting topics that are related to user's goal or interest is very important in web search. However, search engines today focus on suggesting mainly reformulations and lexical variants of the query mined from query logs. In this demonstration, we show a system that can suggest related topics for a query based on the top search results for the query. It can help users in exploring the topics related to their information need. The topic suggestion system can be integrated with any search engine or it can be easily installed on the client machine as a browser plugin."}}
{"id": "Skb7_kZdWS", "cdate": 1262304000000, "mdate": null, "content": {"title": "PR + RQ ALMOST EQUAL TO PQ: Transliteration Mining Using Bridge Language", "abstract": "We address the problem of mining name transliterations from comparable corpora in languages P and Q in the following resource-poor scenario: Parallel names in PQ are not available for training. Parallel names in PR and RQ are available for training. We propose a novel solution for the problem by computing a common geometric feature space for P,Q and R where name transliterations are mapped to similar vectors. We employ Canonical Correlation Analysis (CCA) to compute the common geometric feature space using only parallel names in PR and RQ and without requiring parallel names in PQ. We test our algorithm on data sets in several languages and show that it gives results comparable to the state-of-the-art transliteration mining algorithms that use parallel names in PQ for training."}}
