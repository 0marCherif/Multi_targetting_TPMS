{"id": "zo1hLtQq1f", "cdate": 1609459200000, "mdate": 1632860217429, "content": {"title": "The JHU-Microsoft Submission for WMT21 Quality Estimation Shared Task", "abstract": "This paper presents the JHU-Microsoft joint submission for WMT 2021 quality estimation shared task. We only participate in Task 2 (post-editing effort estimation) of the shared task, focusing on the target-side word-level quality estimation. The techniques we experimented with include Levenshtein Transformer training and data augmentation with a combination of forward, backward, round-trip translation, and pseudo post-editing of the MT output. We demonstrate the competitiveness of our system compared to the widely adopted OpenKiwi-XLM baseline. Our system is also the top-ranking system on the MT MCC metric for the English-German language pair."}}
{"id": "v3tnD484OXg", "cdate": 1609459200000, "mdate": 1632860217428, "content": {"title": "Levenshtein Training for Word-level Quality Estimation", "abstract": "We propose a novel scheme to use the Levenshtein Transformer to perform the task of word-level quality estimation. A Levenshtein Transformer is a natural fit for this task: trained to perform decoding in an iterative manner, a Levenshtein Transformer can learn to post-edit without explicit supervision. To further minimize the mismatch between the translation task and the word-level QE task, we propose a two-stage transfer learning procedure on both augmented data and human post-editing data. We also propose heuristics to construct reference labels that are compatible with subword-level finetuning and inference. Results on WMT 2020 QE shared task dataset show that our proposed method has superior data efficiency under the data-constrained setting and competitive performance under the unconstrained setting."}}
{"id": "8UjqqgdYq2R", "cdate": 1609459200000, "mdate": 1632860217433, "content": {"title": "Evaluating Saliency Methods for Neural Language Models", "abstract": "Shuoyang Ding, Philipp Koehn. Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. 2021."}}
{"id": "pSMea7AQNIg", "cdate": 1546300800000, "mdate": null, "content": {"title": "A Call for Prudent Choice of Subword Merge Operations in Neural Machine Translation", "abstract": "Shuoyang Ding, Adithya Renduchintala, Kevin Duh. Proceedings of Machine Translation Summit XVII: Research Track. 2019."}}
{"id": "M9sEJLH81_QV", "cdate": 1546300800000, "mdate": 1632860217467, "content": {"title": "Saliency-driven Word Alignment Interpretation for Neural Machine Translation", "abstract": "Shuoyang Ding, Hainan Xu, Philipp Koehn. Proceedings of the Fourth Conference on Machine Translation (Volume 1: Research Papers). 2019."}}
{"id": "HsSFQmVCoNA", "cdate": 1546300800000, "mdate": 1632860217517, "content": {"title": "Improving End-to-end Speech Recognition with Pronunciation-assisted Sub-word Modeling", "abstract": "Most end-to-end speech recognition systems model text directly as a sequence of characters or sub-words. Current approaches to sub-word extraction only consider character sequence frequencies, which at times produce inferior sub-word segmentation that might lead to erroneous speech recognition output. We propose pronunciation-assisted sub-word modeling (PASM), a sub-word extraction method that leverages the pronunciation information of a word. Experiments show that the proposed method can greatly improve upon the character-based baseline, and also outperform commonly used byte-pair encoding methods."}}
{"id": "9CA3VTxArCc", "cdate": 1546300800000, "mdate": 1632860217468, "content": {"title": "Espresso: A Fast End-to-End Neural Speech Recognition Toolkit", "abstract": "We present Espresso, an open-source, modular, extensible end-to-end neural automatic speech recognition (ASR) toolkit based on the deep learning library PyTorch and the popular neural machine translation toolkit FAIRSEQ. ESRESSO supports distributed training across GPUs and computing nodes, and features various decoding approaches commonly employed in ASR, including look-ahead word-based language model fusion, for which a fast, parallelized decoder is implemented. Espresso achieves state-of-the-art ASR performance on the WSJ, LibriSpeech, and Switchboard data sets among other end-to-end systems without data augmentation, and is 4-11x faster for decoding than similar systems (e.g. ESPNET)."}}
{"id": "8hM5bIpM14Me", "cdate": 1546300800000, "mdate": 1632860217428, "content": {"title": "An Exploration of Placeholding in Neural Machine Translation", "abstract": "Matt Post, Shuoyang Ding, Marianna Martindale, Winston Wu. Proceedings of Machine Translation Summit XVII: Research Track. 2019."}}
{"id": "6BUDuNO7dCE", "cdate": 1546300800000, "mdate": 1632860217398, "content": {"title": "Parallelizable Stack Long Short-Term Memory", "abstract": "Shuoyang Ding, Philipp Koehn. Proceedings of the Third Workshop on Structured Prediction for NLP. 2019."}}
{"id": "CLyP3G8w3kp", "cdate": 1514764800000, "mdate": 1632860217430, "content": {"title": "Multi-Modal Data Augmentation for End-to-end ASR", "abstract": "We present a new end-to-end architecture for automatic speech recognition (ASR) that can be trained using symbolic input in addition to the traditional acoustic input. This architecture utilizes two separate encoders: one for acoustic input and another for symbolic input, both sharing the attention and decoder parameters. We call this architecture a multi-modal data augmentation network (MMDA), as it can support multi-modal (acoustic and symbolic) input and enables seamless mixing of large text datasets with significantly smaller transcribed speech corpora during training. We study different ways of transforming large text corpora into a symbolic form suitable for training our MMDA network. Our best MMDA setup obtains small improvements on character error rate (CER) and as much as 7-10% relative word error rate (WER) improvement over a baseline both with and without an external language model."}}
