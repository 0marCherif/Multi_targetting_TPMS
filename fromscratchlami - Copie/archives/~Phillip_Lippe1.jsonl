{"id": "VS7Dn31xuB", "cdate": 1676827068655, "mdate": null, "content": {"title": "BISCUIT: Causal Representation Learning from Binary Interactions", "abstract": "Identifying the causal variables of an environment and how to intervene on them is of core value in applications such as robotics and embodied AI. While an agent can commonly interact with the environment and may implicitly perturb the behavior of some of these causal variables, often the targets it affects remain unknown. In this paper, we show that causal variables can still be identified for many common setups, e.g., additive Gaussian noise models, if the agent's interactions with a causal variable can be described by an unknown binary variable. This happens when each causal variable has two different mechanisms, e.g., an observational and an interventional one. Using this identifiability result, we propose BISCUIT, a method for simultaneously learning causal variables and their corresponding binary interaction variables. On three robotic-inspired datasets, BISCUIT accurately identifies causal variables and can even be scaled to complex, realistic environments for embodied AI."}}
{"id": "kig2SKv0bok", "cdate": 1664055782300, "mdate": null, "content": {"title": "$\\mathrm{SE}(3)$-equivariant hemodynamics estimation on arterial surface meshes using graph convolutional networks", "abstract": "Hemodynamic field estimation on the artery surface is valuable for patient-specific prognosis, diagnosis, and treatment of cardiovascular disease. Medical biomarkers like wall shear stress (WSS) can be obtained from computational fluid dynamics (CFD) simulation of the blood flow. Machine-learning methods could accelerate or replace the time-intensive CFD simulation. We propose a graph convolutional network (GCN) that predicts hemodynamic fields mapped to the vertices of a finite-element surface mesh. Our neural network is end-to-end $\\mathrm{SE}(3)$-equivariant and uses anisotropic convolution filters, as well as pooling layers, informed by the mesh structure. We generate a large dataset of CFD simulations in synthetic arteries which we use to train and evaluate our neural network. We show that our method can accurately predict WSS, up to two orders of magnitude faster than CFD."}}
{"id": "1J-ZTr7aypY", "cdate": 1663850000689, "mdate": null, "content": {"title": "Differentiable Mathematical Programming for Object-Centric Representation Learning", "abstract": "We propose topology-aware feature partitioning into $k$ disjoint partitions for given scene features as a method for object-centric representation learning. To this end, we propose to use minimum $s$-$t$ graph cuts as a partitioning method which is represented as a linear program. The method is topologically aware since it explicitly encodes neighborhood relationships in the image graph. To solve the graph cuts our solution relies on an efficient, scalable, and differentiable quadratic programming approximation. Optimizations specific to cut problems allow us to solve the quadratic programs and compute their gradients significantly more efficiently compared with the general quadratic programming approach. Our results show that our approach is scalable and outperforms existing methods on object discovery tasks with textured scenes and objects."}}
{"id": "p8hMBcPtvju", "cdate": 1663849999969, "mdate": null, "content": {"title": "Scalable Subset Sampling with Neural Conditional Poisson Networks", "abstract": "A number of problems in learning can be formulated in terms of the basic primitive of sampling $k$ elements out of a universe of $n$ elements. This subset sampling operation cannot directly be included in differentiable models and approximations are essential. Current approaches take an \\emph{order sampling} approach to sampling subsets and depend on differentiable approximations of the Top-$k$ operator for selecting the largest $k$ elements from a set. We present a simple alternative method for sampling subsets based on \\emph{conditional Poisson sampling}. Unlike order sampling approaches, the parallel complexity of the proposed method is independent of the subset size which makes the method scalable to large subset sizes. We adapt the procedure to make it efficient and amenable to discrete gradient approximations for use in differentiable models. Furthermore, the method also allows the subset size parameter $k$ to be differentiable. We demonstrate our approach on model explanation, image sub-sampling and stochastic $k$-nearest neighbor tasks outperforming existing methods in accuracy, efficiency and scalability."}}
{"id": "itZ6ggvMnzS", "cdate": 1663849916291, "mdate": null, "content": {"title": "Causal Representation Learning for Instantaneous and Temporal Effects in Interactive Systems", "abstract": "Causal representation learning is the task of identifying the underlying causal variables and their relations from high-dimensional observations, such as images. Recent work has shown that one can reconstruct the causal variables from temporal sequences of observations under the assumption that there are no instantaneous causal relations between them. In practical applications, however, our measurement or frame rate might be slower than many of the causal effects. This effectively creates ``instantaneous'' effects and invalidates previous identifiability results. To address this issue, we propose iCITRIS, a causal representation learning method that allows for instantaneous effects in intervened temporal sequences when intervention targets can be observed, e.g., as actions of an agent. iCITRIS identifies the potentially multidimensional causal variables from temporal observations, while simultaneously using a differentiable causal discovery method to learn their causal graph. In experiments on three datasets of interactive systems, iCITRIS accurately identifies the causal variables and their causal graph."}}
{"id": "oQOfMrkGVEu", "cdate": 1654886253404, "mdate": null, "content": {"title": "Weakly supervised causal representation learning", "abstract": "Learning high-level causal representations together with a causal model from unstructured low-level data such as pixels is impossible from observational data alone. We prove under mild assumptions that this representation is however identifiable in a weakly supervised setting. This requires a dataset with paired samples before and after random, unknown interventions, but no further labels. We then introduce implicit latent causal models, variational autoencoders that represent causal variables and causal structure without having to optimize an explicit discrete graph structure. On simple image data, including a novel dataset of simulated robotic manipulation, we demonstrate that such models can reliably identify the causal structure and disentangle causal variables."}}
{"id": "TpVzjh4M2hd", "cdate": 1654886253213, "mdate": null, "content": {"title": "Intervention Design for Causal Representation Learning", "abstract": "In this paper, we take a first step towards bringing two fields of causality closer together: intervention design and causal representation learning. Intervention design is a well studied task in classic causal discovery, which aims at finding the minimal sets of experiments under which the causal graph can be identified. Causal representation learning aims at recovering causal variables from high-dimensional entangled observations. In recent work in causal representation, interventions are exploited to improve identifiability, similarly to classic causal discovery. Hence, the same task becomes relevant in this setting as well: how many experiments are minimally needed to identify the latent causal variables? Based on the recent causal representation learning method CITRIS, we show that for $K$ causal variables, $\\lfloor \\log_2 (K) \\rfloor + 2$ experiments are sufficient to identify causal variables from temporal, intervened sequences, which is only one more experiment than needed for classic causal discovery in the worst case. Further, we show that this bound holds empirically in experiments on a 3D rendered video dataset."}}
{"id": "xeDKTZsZ7Z7", "cdate": 1654886253081, "mdate": null, "content": {"title": "iCITRIS: Causal Representation Learning for Instantaneous Temporal Effects", "abstract": "Causal representation learning is the task of identifying the underlying causal variables and their relations from high-dimensional observations, such as images. Recent work has shown that one can reconstruct the causal variables from temporal sequences of observations under the assumption that there are no instantaneous causal relations between them. In practical applications, however, our measurement or frame rate might be slower than many of the causal effects. This effectively creates ``instantaneous'' effects and invalidates previous identifiability results. To address this issue, we propose iCITRIS, a causal representation learning method that can handle instantaneous effects in temporal sequences when given perfect interventions with known intervention targets. iCITRIS identifies the intervention-dependent part of the causal factors from temporal observations, while simultaneously using a differentiable causal discovery method to learn their causal graph. We demonstrate this in experiments on two video datasets."}}
{"id": "dz79MhQXWvg", "cdate": 1652737402989, "mdate": null, "content": {"title": "Weakly supervised causal representation learning", "abstract": "Learning high-level causal representations together with a causal model from unstructured low-level data such as pixels is impossible from observational data alone. We prove under mild assumptions that this representation is however identifiable in a weakly supervised setting. This involves a dataset with paired samples before and after random, unknown interventions, but no further labels. We then introduce implicit latent causal models, variational autoencoders that represent causal variables and causal structure without having to optimize an explicit discrete graph structure. On simple image data, including a novel dataset of simulated robotic manipulation, we demonstrate that such models can reliably identify the causal structure and disentangle causal variables."}}
{"id": "rOBaAOQqYH", "cdate": 1651491243017, "mdate": 1651491243017, "content": {"title": "Complex-Valued Autoencoders for Object Discovery", "abstract": "Object-centric representations form the basis of human perception and enable us to reason about the world and to systematically generalize to new settings. Currently, most machine learning work on unsupervised object discovery focuses on slot-based approaches, which explicitly separate the latent representations of individual objects. While the result is easily interpretable, it usually requires the design of involved architectures. In contrast to this, we propose a distributed approach to object-centric representations: the Complex AutoEncoder. Following a coding scheme theorized to underlie object representations in biological neurons, its complex-valued activations represent two messages: their magnitudes express the presence of a feature, while the relative phase differences between neurons express which features should be bound together to create joint object representations. We show that this simple and efficient approach achieves better reconstruction performance than an equivalent real-valued autoencoder on simple multi-object datasets. Additionally, we show that it achieves competitive unsupervised object discovery performance to a SlotAttention model on two datasets, and manages to disentangle objects in a third dataset where SlotAttention fails -- all while being 7-70 times faster to train."}}
