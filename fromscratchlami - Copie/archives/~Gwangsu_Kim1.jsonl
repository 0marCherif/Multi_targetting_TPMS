{"id": "n2ZU3USR8a", "cdate": 1672531200000, "mdate": 1681650391841, "content": {"title": "ESD: Expected Squared Difference as a Tuning-Free Trainable Calibration Measure", "abstract": ""}}
{"id": "UgLKEBoE3QP", "cdate": 1663850078439, "mdate": null, "content": {"title": "Least Disagree Metric-based Active Learning", "abstract": "The most popular class of active learners today queries for the labels of the samples for which the prediction is most uncertain and uses the labeled samples to update its prediction. Unfortunately, quantifying uncertainty is an open question. This paper mathematically defines uncertainty in terms of the least disagree metric (LDM), which is the smallest perturbation required to alter the sample prediction. Based on this metric, the predictor is updated by querying the label of the most uncertain samples. Given a finite-sized training set, empirical LDM is incorporated into an active learning algorithm and used to approximate the theoretical LDM of each sample. Theoretical convergence properties between the empirical and the mathematical definition of LDM are provided. Experimental results show that our algorithm mostly outperforms other high-performing active learning algorithms and leads to state-of-the-art performance on various datasets and deep networks."}}
{"id": "bHW9njOSON", "cdate": 1663849870721, "mdate": null, "content": {"title": "ESD: Expected Squared Difference as a Tuning-Free Trainable Calibration Measure", "abstract": "Studies have shown that modern neural networks tend to be poorly calibrated due to over-confident predictions. Traditionally, post-processing methods have been used to calibrate the model after training. In recent years, various trainable calibration measures have been proposed to incorporate them directly into the training process. However, these methods all incorporate internal hyperparameters, and the performance of these calibration objectives relies on tuning these hyperparameters, incurring more computational costs as the size of neural networks and datasets become larger. As such, we present Expected Squared Difference (ESD), a tuning-free (i.e., hyperparameter-free) trainable calibration objective loss, where we view the calibration error from the perspective of the squared difference between the two expectations. With extensive experiments on several architectures (CNNs, Transformers) and datasets, we demonstrate that (1) incorporating ESD into the training improves model calibration in various batch size settings without the need for internal hyperparameter tuning, (2) ESD yields the best-calibrated results compared with previous approaches, and (3) ESD drastically improves the computational costs required for calibration during training due to the absence of internal hyperparameter. The code is publicly accessible at https://github.com/hee-suk-yoon/ESD."}}
{"id": "4Z9vNLsgmx", "cdate": 1653402618853, "mdate": 1653402618853, "content": {"title": "Fast and Efficient MMD-based Fair PCA via Optimization over Stiefel Manifold", "abstract": "This paper defines fair principal component analysis (PCA) as minimizing the maximum mean discrepancy (MMD) between dimensionality-reduced conditional distributions of different protected classes. The incorporation of MMD naturally leads to an exact and tractable mathematical formulation of fairness with good statistical properties. We formulate the problem of fair PCA subject to MMD constraints as a non-convex optimization over the Stiefel manifold and solve it using the Riemannian Exact Penalty Method with Smoothing (REPMS; Liu and Boumal, 2019). Importantly, we provide local optimality guarantees and explicitly show the theoretical effect of each hyperparameter in practical settings, extending previous results. Experimental comparisons based on synthetic and UCI datasets show that our approach outperforms prior work in explained variance, fairness, and runtime."}}
{"id": "ynM2RKmIf5", "cdate": 1640995200000, "mdate": 1669123439169, "content": {"title": "Blending Query Strategy of Active Learning for Imbalanced Data", "abstract": "When the data is imbalanced, often observed in the real-world, important minor class instances that are conducive to accurately predicting the decision boundary are less likely to be queried in the active learning for classification task. Therefore, mitigating the effect of the imbalance in learning is necessary for achieving better generalization. For the alleviation of this problem, this paper considers an active learning algorithm referred to as the blending minority preferential (BMP). The BMP systematically adapts to blend conventional query strategies with the proposed minority preferential queries on a randomly sampled pool dataset. The proposed minority preferential queries are conditioned on an unlabeled data instance predicted to belong to the minor class. A multi-armed bandit is involved in the blending of the two different types of queries for achieving high accuracy and balanced learning in obtaining each query set. The performance of the BMP is validated on datasets that include three imbalanced datasets having binary labels, eleven small structured datasets, modified Fashion-MNIST, CIFAR10 dataets, and two real datasets of the PlantSC and HAM10000. The comparison result shows that the BMP can mitigate imbalanced learning and achieves higher accuracy combined with higher G-mean, compared with conventional queries or other query-based imbalanced active learning."}}
{"id": "XAswkinvl-", "cdate": 1640995200000, "mdate": 1671297512697, "content": {"title": "Fast and Efficient MMD-Based Fair PCA via Optimization over Stiefel Manifold", "abstract": "This paper defines fair principal component analysis (PCA) as minimizing the maximum mean discrepancy (MMD) between the dimensionality-reduced conditional distributions of different protected classes. The incorporation of MMD naturally leads to an exact and tractable mathematical formulation of fairness with good statistical properties. We formulate the problem of fair PCA subject to MMD constraints as a non-convex optimization over the Stiefel manifold and solve it using the Riemannian Exact Penalty Method with Smoothing (REPMS). Importantly, we provide a local optimality guarantee and explicitly show the theoretical effect of each hyperparameter in practical settings, extending previous results. Experimental comparisons based on synthetic and UCI datasets show that our approach outperforms prior work in explained variance, fairness, and runtime."}}
{"id": "MXyzJ5aTDh", "cdate": 1640995200000, "mdate": 1669123439059, "content": {"title": "Survival Analysis of COVID-19 Patients With Symptoms Information by Machine Learning Algorithms", "abstract": "In this study, a survival analysis of the time to death caused by coronavirus disease 2019 is presented. The analysis of a dataset from the East Asian region with a focus on data from the Philippines revealed that the hazard of time to death was associated with the symptoms and background variables of patients. Machine learning algorithms, i.e., dimensionality reduction and boosting, were used along with conventional Cox regression. Machine learning algorithms solved the diverging problem observed when using traditional Cox regression and improved performance by maximizing the concordance index (C-index). Logistic principal component analysis for dimensionality reduction was significantly efficient in addressing the collinearity problem. In addition, to address the nonlinear pattern, a higher C-index was achieved using extreme gradient boosting (XGBoost). The results of the analysis showed that the symptoms were statistically significant for the hazard rate. Among the symptoms, respiratory and pneumonia symptoms resulted in the highest hazard level, which can help in the preliminary identification of high-risk patients. Among various background variables, the influence of age, chronic disease, and their interaction were identified as significant. The use of XGBoost revealed that the hazards were minimized during middle age and increased for younger and older people without any chronic diseases, with only the elderly having a higher risk of chronic disease. These results imply that patients with respiratory and pneumonia symptoms or older patients should be given medical attention."}}
{"id": "K1t-K-LWd6", "cdate": 1640995200000, "mdate": 1681650391785, "content": {"title": "Deep Neural Network Based Accelerated Failure Time Models using Rank Loss", "abstract": ""}}
{"id": "8-TYmHPGRD", "cdate": 1640995200000, "mdate": 1669123439333, "content": {"title": "Fair Facial Attribute Classification via Causal Graph-Based Attribute Translation", "abstract": "Recent studies have raised concerns regarding racial and gender disparity in facial attribute classification performance. As these attributes are directly and indirectly correlated with the sensitive attribute in a complex manner, simple disparate treatment is ineffective in reducing performance disparity. This paper focuses on achieving counterfactual fairness for facial attribute classification. Each labeled input image is used to generate two synthetic replicas: one under factual assumptions about the sensitive attribute and one under counterfactual. The proposed causal graph-based attribute translation generates realistic counterfactual images that consider the complicated causal relationship among the attributes with an encoder\u2013decoder framework. A causal graph represents complex relationships among the attributes and is used to sample factual and counterfactual facial attributes of the given face image. The encoder\u2013decoder architecture translates the given facial image to have sampled factual or counterfactual attributes while preserving its identity. The attribute classifier is trained for fair prediction with counterfactual regularization between factual and corresponding counterfactual translated images. Extensive experimental results on the CelebA dataset demonstrate the effectiveness and interpretability of the proposed learning method for classifying multiple face attributes."}}
{"id": "1qdDKqetmnU", "cdate": 1640995200000, "mdate": 1669123438972, "content": {"title": "Corrections to \"Blending Query Strategy of Active Learning for Imbalanced Data\"", "abstract": "In the above article <xref ref-type=\"bibr\" rid=\"ref1\" xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">[1]</xref> , the following corrections are necessary. <list list-type=\"ordered\" xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><list-item><label>1)</label><p>In Table 4, all notions of \u201cMC-Drop-B\u201d are corrected to \u201cMC-Drop-BMP.\u201d</p></list-item><list-item><label>2)</label><p>\u201cStatistical significannces of all experiments are examined\u201d is corrected to \u201cStatistical significance of each experiments is examined.\u201d</p></list-item><list-item><label>3)</label><p>In Appendix II-D, \u201cShapiro test\u201d is correct to \u2018Shapiro-Wilk test.\u201d</p></list-item> </list> In addition, we would like to add the following acknowledgment: <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">The authors appreciate the constructive discussions with Jaewon Lee (M.S. of KAIST), and the cooperation with researchers working on the project [Development and Study of AI Technologies to Inexpensively Conform to Evolving Policy on Ethics].</i>"}}
