{"id": "gb6VM_pTd5E", "cdate": 1682227363265, "mdate": null, "content": {"title": "ParaGAN: A Cloud Training Framework for Generative Adversarial Networks", "abstract": "Generative Adversarial Network (GAN) has shown tremendous success in synthesizing realistic photos and videos in recent years. However, training GAN to convergence is still a challenging task that requires significant computing power and is subject to training instability. To address these challenges, we propose ParaGAN, a cloud training framework for GAN optimized from both system and numerical perspectives. To achieve this, ParaGAN implements a congestion-aware pipeline for latency hiding, hardware-aware layout transformation for improved accelerator utilization, and an asynchronous update scheme to optimize system performance. Additionally, from a numerical perspective, we introduce an asymmetric optimization policy to stabilize training. Our preliminary experiments show that ParaGAN reduces the training time of BigGAN from 15 days to just 14 hours on 1024 TPUs, achieving 91\\% scaling efficiency. Moreover, we demonstrate that ParaGAN enables the generation of unprecedented high-resolution ($1024\\times1024$) images on BigGAN."}}
{"id": "6d5El_LENnf", "cdate": 1682227363155, "mdate": null, "content": {"title": "TAP: Efficient Derivation of Tensor Parallel Plans for Large Neural Networks", "abstract": "Model parallelism is essential to train large language models efficiently. However, determining the optimal model parallel schedule for a given neural network can be slow and inefficient due to the vast choice space. To address this challenge, we propose a tensor model parallelism framework called TAP, which automatically searches for the best data and tensor parallel schedules.\n\nOur approach is based on the observation that a neural network can be represented as a directed acyclic graph, within which only exists a limited set of frequent subgraphs. With that, we design a graph pruning algorithm that efficiently folds the search space. As a result, TAP runs at sub-linear complexity with respect to model size, which makes it a practical solution for large-scale networks.\n\nExperimental results demonstrate that TAP outperforms the state-of-the-art automatic parallelism frameworks by $20-160\\times$ in searching time. Moreover, the performance of TAP's discovered schedules is competitive with expert-engineered ones. In summary, TAP provides a powerful and efficient tool for model parallelism that can help alleviate the burden of manual tuning."}}
{"id": "MtQIb5VkVTV", "cdate": 1672531200000, "mdate": 1681115262418, "content": {"title": "Auto-Parallelizing Large Models with Rhino: A Systematic Approach on Production AI Platform", "abstract": ""}}
{"id": "8-A6uV38KGX", "cdate": 1672531200000, "mdate": 1681115262420, "content": {"title": "TAP: Accelerating Large-Scale DNN Training Through Tensor Automatic Parallelisation", "abstract": ""}}
{"id": "KUQkiIAKG7", "cdate": 1640995200000, "mdate": 1681115262403, "content": {"title": "Whale: Efficient Giant Model Training over Heterogeneous GPUs", "abstract": ""}}
{"id": "2wNlCV-mmcT", "cdate": 1640995200000, "mdate": 1668592973770, "content": {"title": "Go Wider Instead of Deeper", "abstract": "More transformer blocks with residual connections have recently achieved impressive results on various tasks. To achieve better performance with fewer trainable parameters, recent methods are proposed to go shallower by parameter sharing or model compressing along with the depth. However, weak modeling capacity limits their performance. Contrastively, going wider by inducing more trainable matrixes and parameters would produce a huge model requiring advanced parallelism to train and inference. In this paper, we propose a parameter-efficient framework, going wider instead of deeper. Specially, following existing works, we adapt parameter sharing to compress along depth. But, such deployment would limit the performance. To maximize modeling capacity, we scale along model width by replacing feed-forward network (FFN) with mixture-of-experts (MoE). Across transformer blocks, instead of sharing normalization layers, we propose to use individual layernorms to transform various semantic representations in a more parameter-efficient way. To evaluate our plug-and-run framework, we design WideNet and conduct comprehensive experiments on popular computer vision and natural language processing benchmarks. On ImageNet-1K, our best model outperforms Vision Transformer (ViT) by 1.5% with 0.72 times trainable parameters. Using 0.46 times and 0.13 times parameters, our WideNet can still surpass ViT and ViT-MoE by 0.8% and 2.1%, respectively. On four natural language processing datasets, WideNet outperforms ALBERT by 1.8% on average and surpass BERT using factorized embedding parameterization by 0.8% with fewer parameters."}}
{"id": "5kjkMzfGnE7", "cdate": 1577836800000, "mdate": 1652979248899, "content": {"title": "Domain Adaptation for Degraded Remote Scene Classification", "abstract": "Remote scene classification serves a vital role in many applications. However, satellite images are often blurred and degraded due to aerosol scattering under fog, haze, and other weather conditions, reducing the image contrast and color fidelity. State-of-the-art remote sensing classification models building upon convolutional neural networks (CNNs) are mostly trained on annotated datasets of clear satellite images. When applied to blurred images, they will suffer a great degradation in performance. To address this problem, we adopt the domain adaptation algorithm TADA and propose Transferable Attention enhanced Adversarial Adaptation Network (TA <sup xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">3</sup> N), which utilizes annotated data in clear images by applying knowledge transferring from clear image domain to blurred image domain. Our TA <sup xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">3</sup> N first integrates spatial attention to focus on salient areas which are discriminative and transferable. In addition, domain discriminator and adversarial training via gradient reversal layer are used to minimize the discrepancies in extracted features from clear and degraded domains. We synthesize degraded remote scene classification dataset SSI based on FoHIS model. Experiments on degraded SSI showed that TA <sup xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">3</sup> N significantly outperforms baseline and other state-of-the-art domain adaptation methods."}}
