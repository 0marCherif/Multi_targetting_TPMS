{"id": "YEMH26an2bM", "cdate": 1680924889111, "mdate": null, "content": {"title": "Transforming Radiology Workflows: Pretraining for Automated Chest X-ray Report Generation", "abstract": "Automated chest X-ray report generation using machine learning has emerged as a promising technology for improving the accuracy and efficiency of chest X-ray interpretation. In this paper, we present a novel approach for automated report generation that combines the power of vision transformers for image information encoding and PubMedBERT for text decoding. Our model extracts image features using a vision transformer and text features using PubMedBERT. The encoded features are then fed into a text decoder to generate standardized reports. We trained our model on a dataset of chest X-rays and corresponding report findings (a subset of the MIMIC-CXR dataset) and evaluated its performance on a small subset of the IU dataset."}}
{"id": "tfEylAl8vf", "cdate": 1680922059779, "mdate": null, "content": {"title": "FFCL: Forward-Forward Contrastive Learning for Improved Medical Image Classification", "abstract": "Medical image classification is one of the most important tasks for computer-aided diagnosis. Deep learning models, particularly convolutional neural networks, have been successfully used for disease classification from medical images, facilitated by automated feature learning. However, the diverse imaging modalities and clinical pathology make it challenging to construct generalized and robust classifications. Towards improving the model performance, we propose a novel pretraining approach, namely \\textbf{Forward Forward Contrastive Learning (FFCL)}, which leverages the Forward-Forward Algorithm in a contrastive learning framework--both locally and globally. Our experimental results on the chest X-ray dataset indicate that the proposed FFCL achieves superior performance (\\textbf{3.69\\%} accuracy over ImageNet pretrained ResNet-18) over existing pretraining models in the pneumonia classification task. Moreover, extensive ablation experiments support the particular local and global contrastive pretraining design in FFCL.\n"}}
{"id": "zFDnr7cQKVq", "cdate": 1609459200000, "mdate": 1631889030198, "content": {"title": "Ssiqa: Multi-Task Learning For Non-Reference Ct Image Quality Assessment With Self-Supervised Noise Level Prediction", "abstract": "Reduction of CT radiation dose is important due to the potential effects on patients. But lowering dose incurs degradation in the reconstructed image quality, furthering compromise in the diagnostic and image-based analyses performance. Considering the patient health risks, high quality reference images cannot be easily obtained, making the assessment challenging. Therefore, automatic no-reference image quality assessment is desirable. Leveraging an innovative self-supervised regularization in a convolutional neural network, we propose a novel, fully automated, no-reference CT image quantification method namely self-supervised image quality assessment (SSIQA). Extensive experimentation via in-domain (abdomen CT) and cross-domain (chest CT) evaluations demonstrates SSIQA is accurate in quantifying CT image quality, generalized across the scan types, and consistent with the established metrics and different relative dose levels."}}
{"id": "sCgdYMC7h9", "cdate": 1609459200000, "mdate": 1631889030188, "content": {"title": "Window-Level is a Strong Denoising Surrogate", "abstract": "CT image quality is heavily reliant on radiation dose, which causes a trade-off between radiation dose and image quality that affects the subsequent image-based diagnostic performance. However, high radiation can be harmful to both patients and operators. Several (deep learning-based) approaches have been attempted to denoise low dose images. However, those approaches require access to large training sets, specifically the full dose CT images for reference, which can often be difficult to obtain. Self-supervised learning is an emerging alternative for lowering the reference data requirement facilitating unsupervised learning. Currently available self-supervised CT denoising works are either dependent on foreign domain or pretexts are not very task-relevant. To tackle the aforementioned challenges, we propose a novel self-supervised learning approach, namely Self-Supervised Window-Leveling for Image DeNoising (SSWL-IDN), leveraging an innovative, task-relevant, simple, yet effective surrogate -- prediction of the window-leveled equivalent. SSWL-IDN leverages residual learning and a hybrid loss combining perceptual loss and MSE, all incorporated in a VAE framework. Our extensive (in- and cross-domain) experimentation demonstrates the effectiveness of SSWL-IDN in aggressive denoising of CT (abdomen and chest) images acquired at 5\\% dose level only."}}
{"id": "YVEOOcZGFhg", "cdate": 1609459200000, "mdate": 1642192125398, "content": {"title": "Personalized CT Organ Dose Estimation from Scout Images", "abstract": "With the rapid increase of CT usage, radiation dose across patient populations is also increasing. Therefore, it is desirable to reduce the CT radiation dose. However, the reduction in dose also incurs additional noise and with the degraded image quality, diagnostic performance can be compromised. Existing routine dosimetric quantities are usually based on absorbed dose within cylindrical phantoms and do not appropriately represent the actual patient dose. More comprehensive dose metrics such as effective dose require estimation of patient-specific dose at an organ level. Unfortunately, currently available systems are quite far from achieving this goal as well as limited by a number of manual adjustments, time-consuming and inefficient procedures. To overcome all these challenges in achieving the goal of patient safety through reduced dose without compromising image quality, we devise a fully-automated, end-to-end deep learning-based solution to perform real-time, patient-specific, organ-level dosimetric prediction of CT scans. Leveraging the 2D scout (frontal and lateral) images of the actual patients, which are routinely acquired prior to the CT scan, our proposed Scout-Net model estimates the patient-specific mean dose in real-time for six different organs. Our experimental evaluation on real patient data demonstrates the effectiveness of our Scout-Net model not only in real-time dose estimation (only 11 ms on average per scan), but also as a potential tool for optimizing CT radiation dose in specific patients."}}
{"id": "J03eBDirIr", "cdate": 1609459200000, "mdate": 1642192125422, "content": {"title": "Generalized Multi-Task Learning from Substantially Unlabeled Multi-Source Medical Image Data", "abstract": "Deep learning-based models, when trained in a fully-supervised manner, can be effective in performing complex image analysis tasks, although contingent upon the availability of large labeled datasets. Especially in the medical imaging domain, however, expert image annotation is expensive, time-consuming, and prone to variability. Semi-supervised learning from limited quantities of labeled data has shown promise as an alternative. Maximizing knowledge gains from copious unlabeled data benefits semi-supervised learning models. Moreover, learning multiple tasks within the same model further improves its generalizability. We propose MultiMix, a new multi-task learning model that jointly learns disease classification and anatomical segmentation in a semi-supervised manner, while preserving explainability through a novel saliency bridge between the two tasks. Our experiments with varying quantities of multi-source labeled data in the training sets confirm the effectiveness of MultiMix in the simultaneous classification of pneumonia and segmentation of the lungs in chest X-ray images. Moreover, both in-domain and cross-domain evaluations across these tasks further showcase the potential of our model to adapt to challenging generalization scenarios."}}
{"id": "Dpva_FkfJ_u", "cdate": 1609459200000, "mdate": 1642192125399, "content": {"title": "Window-Level Is a Strong Denoising Surrogate", "abstract": "CT image quality is heavily reliant on radiation dose, which causes a trade-off between radiation dose and image quality that affects the subsequent image-based diagnostic performance. However, high radiation can be harmful to both patients and operators. Several (deep learning-based) approaches have been attempted to denoise low dose images. However, those approaches require access to large training sets, specifically the full dose CT images for reference, which can often be difficult to obtain. Self-supervised learning is an emerging alternative for lowering the reference data requirement facilitating unsupervised learning. Currently available self-supervised CT denoising works are either dependent on foreign domains or pretexts that are not very task-relevant. To tackle the aforementioned challenges, we propose a novel self-supervised learning approach, namely Self-Supervised Window-Leveling for Image DeNoising (SSWL-IDN), leveraging an innovative, task-relevant, simple, yet effective surrogate\u2014prediction of the window-leveled equivalent. SSWL-IDN leverages residual learning and a hybrid loss combining perceptual loss and MSE, all incorporated in a VAE framework. Our extensive (in- and cross-domain) experimentation demonstrates the effectiveness of SSWL-IDN in aggressive denoising of CT (abdomen and chest) images acquired at 5% dose level only (Code available at https://github.com/ayaanzhaque/SSWL-IDN )."}}
{"id": "-LyFMJYWmSM", "cdate": 1609459200000, "mdate": 1631889030195, "content": {"title": "Multimix: Sparingly-Supervised, Extreme Multitask Learning from Medical Images", "abstract": "Semi-supervised learning from limited quantities of labeled data, an alternative to fully-supervised schemes, benefits by maximizing knowledge gains from copious unlabeled data. Furthermore, learning multiple tasks within the same model improves model generalizability. We propose MultiMix, a novel multitask learning model that jointly learns disease classification and anatomical segmentation in a sparingly supervised manner, while preserving explainability through bridge saliency between the two tasks. Extensive experimentation with varied quantities of labeled data in the training sets affirms the effectiveness of our multitasking model in classifying pneumonia and segmenting lungs from chest X-ray images. Moreover, both in-domain and cross-domain evaluations across the tasks further showcase the potential of our model to adapt to challenging generalization scenarios."}}
{"id": "rN9KgPC68qa", "cdate": 1577836800000, "mdate": 1631889030203, "content": {"title": "Self-Supervised, Semi-Supervised, Multi-Context Learning for the Combined Classification and Segmentation of Medical Images (Student Abstract)", "abstract": "To tackle the problem of limited annotated data, semi-supervised learning is attracting attention as an alternative to fully supervised models. Moreover, optimizing a multiple-task model to learn \u201cmultiple contexts\u201d can provide better generalizability compared to single-task models. We propose a novel semi-supervised multiple-task model leveraging self-supervision and adversarial training\u2014namely, self-supervised, semi-supervised, multi-context learning (S4MCL)\u2014and apply it to two crucial medical imaging tasks, classification and segmentation. Our experiments on spine X-rays reveal that the S4MCL model significantly outperforms semi-supervised single-task, semi-supervised multi-context, and fully-supervised single-task models, even with a 50% reduction of classification and segmentation labels."}}
{"id": "jSGQT_gg60", "cdate": 1577836800000, "mdate": 1631889030248, "content": {"title": "Progressive Adversarial Semantic Segmentation", "abstract": "Medical image computing has advanced rapidly with the advent of deep learning techniques such as convolutional neural networks. Deep convolutional neural networks can perform exceedingly well given full supervision. However, the success of such fully-supervised models for various image analysis tasks (e.g., anatomy or lesion segmentation from medical images) is limited to the availability of massive amounts of labeled data. Given small sample sizes, such models are prohibitively data biased with large domain shift. To tackle this problem, we propose a novel end-to-end medical image segmentation model, namely Progressive Adversarial Semantic Segmentation (PASS), which can make improved segmentation predictions without requiring any domain-specific data during training time. Our extensive experimentation with 8 public diabetic retinopathy and chest X-ray datasets, confirms the effectiveness of PASS for accurate vascular and pulmonary segmentation, both for in-domain and cross-domain evaluations."}}
