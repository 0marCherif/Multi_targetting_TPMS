{"id": "Zc7uRpPIcb", "cdate": 1640995200000, "mdate": 1683609942080, "content": {"title": "Sample-Level and Class-Level Adaptive Training for Face Recognition", "abstract": "Marginal softmax loss function has been widely used for face recognition, where a universal angular margin is added between weight prototypes. However, this method neglects the differences between classes and samples. On class-level, the imbalanced real world training dataset requires different margin for the head and tail classes to equally squeeze each class's feature space. On the sample-level, it's also necessary to assign larger importance for the hard samples during training. In this paper, we address these two issues by combining two strategies: (1) explicitly assign the adaptive margin according to the image quantity so that the margin is enlarged for the tail classes; (2) semantically identify the \u2018hard positive, samples and misclassified samples [1] to attach adaptive weights to increase the training emphasis on these samples. Extensive experiments on LFW/CFP/AGEDB and IJB-B/IJB-C show our method's effectiveness."}}
{"id": "NHYgLJAwsEB", "cdate": 1640995200000, "mdate": 1683609941458, "content": {"title": "Exploiting the Tail Data for Long-Tailed Face Recognition", "abstract": "Long-tailed distribution generally exists in large-scale face datasets, which poses challenges for learning discriminative feature in face recognition. Although a few works conduct preliminary research on this problem, the value of the tail data is still underestimated. This paper addresses the long-tailed problem from the perspective of maximally exploiting the tail data. We propose a Joint Alternating Training (JAT) framework to learn discriminative feature from both the long-tailed data and the tail data by using alternating training strategy. JAT consists of two branches: 1) the long-tailed data branch is adopted to learn the universal discrimination information from the whole long-tailed data with instance-balanced sampling. 2) the tail data branch is designed to exploit the discriminative information in the tail data with class-balanced sampling. To compensate the insufficient samples and lack of intra-class variations, we apply data augmentation (DA) to the tail data. We further propose margin-based mixup (MarginMix) for data augmentation, which can deal with the nonlinearity of margin-based softmax loss and stabilize the training process in mixup. Furthermore, we obtain the best combination of strategies (i.e., JAT+DA+ MarginMix) for long-tailed face recognition, which can maximally exploit the discriminative information in the tail data while retaining the universal discrimination learned from the long-tailed data. Extensive experiments on 8 face datasets demonstrate that our proposed methods and combination of strategies can effectively address the long-tailed problem in face recognition."}}
{"id": "b872tJpW05", "cdate": 1546300800000, "mdate": 1683609942163, "content": {"title": "Improved Knowledge Distillation for Training Fast Low Resolution Face Recognition Model", "abstract": "Low resolution (LR) face recognition (FR) is a challenging, yet common problem for FR task, especially for surveillance scenario. The issue addressed here is not just to build a LR-FR model, more importantly to make it run fast. Here, the knowledge distillation method is adopted for our task, where the teacher's knowledge can be 'distilled' into a small student model by guiding its training process. For LRFR task, the original knowledge distillation scheme would update the teacher's weights first by tuning it using LR augmented train set, and then the student model is trained using same train set under updated teacher's guidance. The problem of this method is that the weights tuning of large teacher model is time-consuming, especially for large-scale dataset. In this paper, we proposed an improved scheme to enable us to avoid the teacher retraining and still be able to train the small model for LR-FR task. Here, different from the original scheme, the train sets for teacher and student model become different, where the train set for teacher model keeps unchanged and the one student is LR augmented. Therefore, it becomes unnecessary to update teacher model any more since the train set is the unchanged. Only the small student model needs to be trained under the original teacher's guidance. This can speed up the whole training process, especially for large-scale dataset. The different train sets for teacher and student will increase the data distribution discrepancy. To solve this problem, we constrained the multikernel maximum mean discrepancy between outputs to reduce this influence. Experimental results show our method can accelerate the training process by about 5 times, while preserving the accuracy. Our student model has same level coresponding author: wangmengjiao@cn.fujitsu.com with respect to state-of-art accuracy on LFW and SCFace. It can achieve 3x acceleration comparing to teacher model and only takes 35ms to run on a CPU."}}
{"id": "oJHfUFwq0a", "cdate": 1514764800000, "mdate": 1683609941929, "content": {"title": "A Similarity Measurement Method for Diffuse Lung Disease CT Slice Image Retrieval", "abstract": "Diffuse lung disease (DLD) is difficult to diagnose due to the ambiguity of disease patterns, which motivates the development of image retrieval method to facilitate the physicians in diagnosis by retrieving the similar cases from database. In this paper, we propose a similarity measurement method for diffuse lung disease computed tomography (CT) slice image retrieval. In our method, the DLD patterns and the spatial distribution of the diseased area are both integrated to compute the similarity between query and database image. For this purpose, the powerful GoogLeNet is adopted and fine-tuned to locate the diseased area and classify it into different DLD patterns. Moreover, the spatial distribution of the diseased area is calculated based on the distance to the body center. Our method is verified on 324 CT slice images obtained from 53 subjects. The correct ratio among the top-5 retrieved images achieved 86.2%. Based on this performance, we can draw the conclusion that this method has high potential to improve the efficiency for diagnosis of diffuse lung disease in clinical use."}}
{"id": "4rpjqTJ8ziq", "cdate": 1514764800000, "mdate": 1683609942167, "content": {"title": "Discover the Effective Strategy for Face Recognition Model Compression by Improved Knowledge Distillation", "abstract": "For the sake of better accuracy, the face recognition model is becoming larger and larger, which makes them difficult to be deployed on embedded systems. This work proposes an effective model compression method using knowledge distillation, where a fast student model is trained under the guidance of a complex teacher model. Firstly, different loss combinations and network architectures are analyzed through comprehensive experiments to find the most effective approach. To augment the performance, the feature layer is further normalized to make the optimization objective consistent with cosine similarity metric. Moreover, a teacher weighting strategy is proposed to address the issue when teacher provides wrong guidance. Experimental results show that the student model built by our approach can surpass the teacher model while achieving 3\u00d7 acceleration."}}
{"id": "4biFq1thKzz", "cdate": 1514764800000, "mdate": 1683609941922, "content": {"title": "A Double Joint Bayesian Approach for J-Vector Based Text-dependent Speaker Verification", "abstract": "J-vector has been proved to be very effective in text-dependent speaker verification with short-duration speech. However, the current state-of-the-art back-end classifiers, e.g. joint Bayesian model, cannot make full use of such deep features. In this paper, we generalize the standard joint Bayesian approach to model the multi-faceted information in the j-vector explicitly and jointly. In our generalization, the j-vector was modeled as a result derived by a generative Double Joint Bayesian (DoJoBa) model, which contains several kinds of latent variables.With DoJoBa, we are able to explicitly build a model that can combine multiple heterogeneous information from the j-vectors. In verification step, we calculated the likelihood to describe whether the two j-vectors having consistent labels or not. On the public RSR2015 data corpus, the experimental results showed that our approach can achieve 0.02\\% EER and 0.02\\% EER for impostor wrong and impostor correct cases respectively."}}
{"id": "daxAcoDkfs2", "cdate": 1483228800000, "mdate": 1683609941918, "content": {"title": "Multi-view (Joint) probability linear discrimination analysis for J-vector based text dependent speaker verification", "abstract": "J-vector has been proved to be very effective in text dependent speaker verification with short-duration speech. However, the current back-end classifiers cannot make full use of such deep features. In this paper, we propose a method to model the multi-faceted information in the j-vector explicitly and jointly. Examples of the multi-faceted information include speaker identity and text content. In our approach, the j-vector was modeled as a result derived by a generative multi-view (joint <sup xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">1</sup> ) Probability Linear Discriminant Analysis (PLDA) model, which contains multiple kinds of latent variables. The usual PLDA model only considers one single label. However, in practical use, when using multi-task learned network as feature extractor, the extracted feature are always associated with several labels. This type of feature is called multi-view deep feature (e.g. j-vector). With multi-view (joint) PLDA, we are able to explicitly build a model that can combine multiple heterogeneous information from the j-vectors. In verification step, we calculated the likelihood to describe whether the two j-vectors having consistent labels or not. This likelihood is used in the following decision-making. Experiments have been conducted on large scale data corpus of different languages. On the public RSR2015 data corpus, the results showed that our approach can achieve 0.02% EER and 0.09% EER for impostor wrong and impostor correct cases respectively."}}
{"id": "bV3siPvoUpc", "cdate": 1483228800000, "mdate": 1683609942526, "content": {"title": "A Double Joint Bayesian Approach for J-Vector Based Text-dependent Speaker Verification", "abstract": "J-vector has been proved to be very effective in text-dependent speaker verification with short-duration speech. However, the current state-of-the-art back-end classifiers, e.g. joint Bayesian model, cannot make full use of such deep features. In this paper, we generalize the standard joint Bayesian approach to model the multi-faceted information in the j-vector explicitly and jointly. In our generalization, the j-vector was modeled as a result derived by a generative Double Joint Bayesian (DoJoBa) model, which contains several kinds of latent variables. With DoJoBa, we are able to explicitly build a model that can combine multiple heterogeneous information from the j-vectors. In verification step, we calculated the likelihood to describe whether the two j-vectors having consistent labels or not. On the public RSR2015 data corpus, the experimental results showed that our approach can achieve 0.02\\% EER and 0.02\\% EER for impostor wrong and impostor correct cases respectively."}}
