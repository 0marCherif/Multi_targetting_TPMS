{"id": "LM1Nt6YHRwe", "cdate": 1664943347561, "mdate": null, "content": {"title": "Planning with Large Language Models for Code Generation", "abstract": "Existing large language model-based code generation pipelines typically use beam search or sampling algorithms during the decoding process. Although the programs they generate achieve high token-matching-based scores, they often fail to compile or generate incorrect outputs. The main reason is that conventional Transformer decoding algorithms may not be the best choice for code generation. In this work, we propose a novel Transformer decoding algorithm, Planning-Guided Transformer Decoding (PG-TD), that uses a planning algorithm to do lookahead search and guide the Transformer to generate better programs. Specifically, instead of simply optimizing the likelihood of the generated sequences, the Transformer makes use of a planner that generates complete programs and tests them on public test cases. The Transformer can therefore make more informed decisions and generate tokens that will eventually lead to higher-quality programs. We also design a mechanism that shares information between the Transformer and the planner to make our algorithm computationally efficient. We empirically evaluate our framework with several large language models as backbones on public coding challenge benchmarks, showing that 1) it can generate programs that consistently achieve higher performance compared with competing baseline methods; 2) it enables controllable code generation, such as concise codes and highly-commented codes by optimizing modified objective."}}
{"id": "LDkhQkQOJ7", "cdate": 1664943344601, "mdate": null, "content": {"title": "Hyper-Decision Transformer for Efficient Online Policy Adaptation", "abstract": "Decision Transformers (DT) have demonstrated strong performances in offline reinforcement learning settings, but quickly adapting to unseen novel tasks remains challenging. To address this challenge, we propose a new framework, called Hyper-Decision Transformer (HDT), that can generalize to novel tasks from a handful of demonstrations in a data- and parameter-efficient manner. To achieve such a goal, we propose to augment the base DT with an adaptation module, whose parameters are initialized by a hyper-network. When encountering unseen tasks, the hyper-network takes a handful of demonstrations as inputs and initializes the adaptation module accordingly. This initialization enables HDT to efficiently adapt to novel tasks by only fine-tuning the adaptation module. We validate HDT's generalization capability on object manipulation tasks. We find that with a single expert demonstration and fine-tuning only 0.5% of DT parameters, HDT adapts faster to unseen tasks than fine-tuning the whole DT model. Finally, we explore a more challenging setting where expert actions are not available, and we show that HDT outperforms state-of-the-art baselines in terms of task success rates by a large margin. Demos are available on our project page: https://sites.google.com/view/hdtforiclr2023/home."}}
{"id": "AatUEvC-Wjv", "cdate": 1663850395858, "mdate": null, "content": {"title": "Hyper-Decision Transformer for Efficient Online Policy Adaptation", "abstract": "Decision Transformers (DT) have demonstrated strong performances in offline reinforcement learning settings, but quickly adapting to unseen novel tasks remains challenging. To address this challenge, we propose a new framework, called Hyper-Decision Transformer (HDT), that can generalize to novel tasks from a handful of demonstrations in a data- and parameter-efficient manner. To achieve such a goal, we propose to augment the base DT with an adaptation module, whose parameters are initialized by a hyper-network. When encountering unseen tasks, the hyper-network takes a handful of demonstrations as inputs and initializes the adaptation module accordingly. This initialization enables HDT to efficiently adapt to novel tasks by only fine-tuning the adaptation module. We validate HDT's generalization capability on object manipulation tasks. We find that with a single expert demonstration and fine-tuning only 0.5% of DT parameters, HDT adapts faster to unseen tasks than fine-tuning the whole DT model. Finally, we explore a more challenging setting where expert actions are not available, and we show that HDT outperforms state-of-the-art baselines in terms of task success rates by a large margin. Demos are available on our project page: https://sites.google.com/view/hdtforiclr2023/home."}}
{"id": "Lr8cOOtYbfL", "cdate": 1663850365239, "mdate": null, "content": {"title": "Planning with Large Language Models for Code Generation", "abstract": "Existing large language model-based code generation pipelines typically use beam search or sampling algorithms during the decoding process. Although the programs they generate achieve high token-matching-based scores, they often fail to compile or generate incorrect outputs. The main reason is that conventional Transformer decoding algorithms may not be the best choice for code generation. In this work, we propose a novel Transformer decoding algorithm, Planning-Guided Transformer Decoding (PG-TD), that uses a planning algorithm to do lookahead search and guide the Transformer to generate better programs. Specifically, instead of simply optimizing the likelihood of the generated sequences, the Transformer makes use of a planner that generates candidate programs and tests them on public test cases. The Transformer can therefore make more informed decisions and generate tokens that will eventually lead to higher-quality programs. We also design a mechanism that shares information between the Transformer and the planner to make our algorithm computationally efficient. We empirically evaluate our framework with several large language models as backbones on public coding challenge benchmarks, showing that 1) it can generate programs that consistently achieve higher performance compared with competing baseline methods; 2) it enables controllable code generation, such as concise codes and highly-commented codes by optimizing modified objective."}}
{"id": "pJLBnCfHlRo", "cdate": 1640995200000, "mdate": 1667406484420, "content": {"title": "Prompting Decision Transformer for Few-Shot Policy Generalization", "abstract": "Human can leverage prior experience and learn novel tasks from a handful of demonstrations. In contrast to offline meta-reinforcement learning, which aims to achieve quick adaptation through better..."}}
{"id": "SYoz3ZzwGT", "cdate": 1577836800000, "mdate": 1683916725016, "content": {"title": "Querying to Find a Safe Policy under Uncertain Safety Constraints in Markov Decision Processes", "abstract": "An autonomous agent acting on behalf of a human user has the potential of causing side-effects that surprise the user in unsafe ways. When the agent cannot formulate a policy with only side-effects it knows are safe, it needs to selectively query the user about whether other useful side-effects are safe. Our goal is an algorithm that queries about as few potential side-effects as possible to find a safe policy, or to prove that none exists. We extend prior work on irreducible infeasible sets to also handle our problem's complication that a constraint to avoid a side-effect cannot be relaxed without user permission. By proving that our objectives are also adaptive submodular, we devise a querying algorithm that we empirically show finds nearly-optimal queries with much less computation than a guaranteed-optimal approach, and outperforms competing approximate approaches."}}
{"id": "H6h6PGdTcTe", "cdate": 1514764800000, "mdate": 1683916725032, "content": {"title": "On Querying for Safe Optimality in Factored Markov Decision Processes", "abstract": "As it achieves a goal on behalf of its human user, an autonomous agent's actions may have side effects that change features of its environment in ways that negatively surprise its user. An agent that can be trusted to operate safely should thus only change features the user has explicitly permitted. We formalize this problem, and develop a planning algorithm that avoids potentially negative side effects given what the agent knows about (un)changeable features. Further, we formulate a provably minimax-regret querying strategy for the agent to selectively ask the user about features that it hasn't explicitly been told about. We empirically show how much faster it is than a more exhaustive approach and how much better its queries are than those found by the best known heuristic."}}
{"id": "_LqwKNZrTG", "cdate": 1483228800000, "mdate": 1683916725037, "content": {"title": "Approximately-Optimal Queries for Planning in Reward-Uncertain Markov Decision Processes", "abstract": ""}}
{"id": "k4Aiqbp4xg", "cdate": 1420070400000, "mdate": 1683916748238, "content": {"title": "Determining Placements of Influencing Agents in a Flock", "abstract": "Flocking is a fascinating collective behavior exhibited by many different animals including birds and fish. As understood by biologists, the overall flocking behavior emerges from relatively simple local control rules by which each individual adjusts its own trajectory based on those of its closest neighbors. We consider the possibility of adding a small set of influencing agents, that are under our control, into a flock. Specifically, in this paper we consider where in the flock to place the influencing agents that we add to the flock. Following ad hoc teamwork methodology, we assume that we are given knowledge of, but no direct control over, the rest of the flock. We use the influencing agents to alter the flock's trajectory, for instance to avoid an obstacle. We define several methodologies for placing the influencing agents into the flock, and compare them via detailed experimental results."}}
{"id": "EfcEIwyg_Y", "cdate": 1388534400000, "mdate": 1683916748393, "content": {"title": "Semi-autonomous intersection management", "abstract": "Autonomous Intersection Management (AIM) is a reservation-based intersection control protocol that leverages the capacities of autonomous vehicles to dramatically reduce traffic delay at intersections. AIM was designed for the time when all, or most, of the vehicles on the road are fully autonomous. However, we anticipate that there will be a long transition period during which many cars are still driven by human drivers and/or most vehicles have some but not all capabilities of fully autonomous vehicles. In order to accommodate this transition, this paper introduces a new multiagent protocol called Semi-Autonomous Intersection Management (SemiAIM), which allows vehicles with partially-autonomous features such as adaptive cruise control to make reservations in AIM. We propose a method for vehicles with limited autonomy to make reservations to enter an intersection in an AIM-like style and conduct experiments in simulation to evaluate its effectiveness. Our results show that the delay of semi-autonomous vehicles in SemiAIM can be greatly reduced compared to human-driven vehicles."}}
