{"id": "rjyG494uJM", "cdate": 1676827089456, "mdate": null, "content": {"title": "Variable Importance Matching for Causal Inference", "abstract": "Our goal is to produce methods for observational causal inference that are auditable, easy to troubleshoot, accurate for treatment effect estimation, and scalable to high-dimensional data. We describe a general framework called Model-to-Match that achieves these goals by (i) learning a distance metric via outcome modeling, (ii) creating matched groups using the distance metric, and (iii) using the matched groups to estimate treatment effects. Model-to-Match uses variable importance measurements to construct a distance metric, making it a flexible framework that can be adapted to various applications. Concentrating on the scalability of the problem in the number of potential confounders, we operationalize the Model-to-Match framework with LASSO. We derive performance guarantees for settings where LASSO outcome modeling consistently identifies all confounders (importantly without requiring the linear model to be correctly specified). We also provide experimental results demonstrating the method\u2019s auditability, accuracy, and scalability as well as extensions to more general nonparametric outcome modeling."}}
{"id": "jiQDQdnD44g", "cdate": 1674892813995, "mdate": 1674892813995, "content": {"title": "AutoBlock: A Hands-off Blocking Framework for Entity Matching", "abstract": "Entity matching seeks to identify data records over one or multiple\ndata sources that refer to the same real-world entity. Virtually every\nentity matching task on large datasets requires blocking, a step that\nreduces the number of record pairs to be matched. However, most\nof the traditional blocking methods are learning-free and key-based,\nand their successes are largely built on laborious human effort in\ncleaning data and designing blocking keys.\nIn this paper, we propose AutoBlock, a novel hands-off blocking\nframework for entity matching, based on similarity-preserving representation learning and nearest neighbor search. Our contributions\ninclude: (a) Automation: AutoBlock frees users from laborious\ndata cleaning and blocking key tuning. (b) Scalability: AutoBlock\nhas a sub-quadratic total time complexity and can be easily deployed\nfor millions of records. (c) Effectiveness: AutoBlock outperforms\na wide range of competitive baselines on multiple large-scale, realworld datasets, especially when datasets are dirty and/or unstructured."}}
{"id": "nS_Ntykf5Y9", "cdate": 1577836800000, "mdate": null, "content": {"title": "Stochastic Learning for Sparse Discrete Markov Random Fields with Controlled Gradient Approximation Error", "abstract": "We study the $L_1$-regularized maximum likelihood estimator/estimation (MLE) problem for discrete Markov random fields (MRFs), where efficient and scalable learning requires both sparse regularization and approximate inference. To address these challenges, we consider a stochastic learning framework called stochastic proximal gradient (SPG; Honorio 2012a, Atchade et al. 2014,Miasojedow and Rejchel 2016). SPG is an inexact proximal gradient algorithm [Schmidtet al., 2011], whose inexactness stems from the stochastic oracle (Gibbs sampling) for gradient approximation - exact gradient evaluation is infeasible in general due to the NP-hard inference problem for discrete MRFs [Koller and Friedman, 2009]. Theoretically, we provide novel verifiable bounds to inspect and control the quality of gradient approximation. Empirically, we propose the tighten asymptotically (TAY) learning strategy based on the verifiable bounds to boost the performance of SPG."}}
{"id": "KByDqvPVVna", "cdate": 1577836800000, "mdate": null, "content": {"title": "CAUSE: Learning Granger Causality from Event Sequences using Attribution Methods", "abstract": "We study the problem of learning Granger causality between event types from asynchronous, interdependent, multi-type event sequences. Existing work suffers from either limited model flexibility or poor model explainability and thus fails to uncover Granger causality across a wide variety of event sequences with diverse event interdependency. To address these weaknesses, we propose CAUSE (Causality from AttribUtions on Sequence of Events), a novel framework for the studied task. The key idea of CAUSE is to first implicitly capture the underlying event interdependency by fitting a neural point process, and then extract from the process a Granger causality statistic using an axiomatic attribution method. Across multiple datasets riddled with diverse event interdependency, we demonstrate that CAUSE achieves superior performance on correctly inferring the inter-type Granger causality over a range of state-of-the-art methods."}}
{"id": "5_837bodCs", "cdate": 1577836800000, "mdate": null, "content": {"title": "AutoBlock: A Hands-off Blocking Framework for Entity Matching", "abstract": "Entity matching seeks to identify data records over one or multiple data sources that refer to the same real-world entity. Virtually every entity matching task on large datasets requires blocking, a step that reduces the number of record pairs to be matched. However, most of the traditional blocking methods are learning-free and key-based, and their successes are largely built on laborious human effort in cleaning data and designing blocking keys. In this paper, we propose AutoBlock, a novel hands-off blocking framework for entity matching, based on similarity-preserving representation learning and nearest neighbor search. Our contributions include: (a) Automation: AutoBlock frees users from laborious data cleaning and blocking key tuning. (b) Scalability: AutoBlock has a sub-quadratic total time complexity and can be easily deployed for millions of records. (c) Effectiveness: AutoBlock outperforms a wide range of competitive baselines on multiple large-scale, real-world datasets, especially when datasets are dirty and/or unstructured."}}
{"id": "54J9IPhcFvX", "cdate": 1577836800000, "mdate": null, "content": {"title": "Adverse drug reaction discovery from electronic health records with deep neural networks", "abstract": "Adverse drug reactions (ADRs) are detrimental and unexpected clinical incidents caused by drug intake. The increasing availability of massive quantities of longitudinal event data such as electronic health records (EHRs) has redefined ADR discovery as a big data analytics problem, where data-hungry deep neural networks are especially suitable because of the abundance of the data. To this end, we introduce neural self-controlled case series (NSCCS), a deep learning framework for ADR discovery from EHRs. NSCCS rigorously follows a self-controlled case series design to adjust implicitly and efficiently for individual heterogeneity. In this way, NSCCS is robust to time-invariant confounding issues and thus more capable of identifying associations that reflect the underlying mechanism between various types of drugs and adverse conditions. We apply NSCCS to a large-scale real-world EHR dataset and empirically demonstrate its superior performance with comprehensive experiments on a benchmark ADR discovery task."}}
{"id": "msvGEAa42Uj", "cdate": 1546300800000, "mdate": null, "content": {"title": "Predicting Drug-Drug Interactions from Molecular Structure Images", "abstract": "Predicting and discovering drug-drug interactions (DDIs) is an important problem and has been studied extensively both from medical and machine learning point of view. Almost all of the machine learning approaches have focused on text data or textual representation of the structural data of drugs. We present the first work that uses drug structure images as the input and utilizes a Siamese convolutional network architecture to predict DDIs."}}
{"id": "li2iVW7kevw", "cdate": 1546300800000, "mdate": null, "content": {"title": "Machine Learning to Predict Developmental Neurotoxicity with High-throughput Data from 2D Bio-engineered Tissues", "abstract": "There is a growing need for fast and accurate methods for testing developmental neurotoxicity across several chemical exposure sources. Current approaches, such as in vivo animal studies, and assays of animal and human primary cell cultures, suffer from challenges related to time, cost, and applicability to human physiology. We previously demonstrated success employing machine learning to predict developmental neurotoxicity using gene expression data collected from human 3D tissue models exposed to various compounds. The 3D model is biologically similar to developing neural structures, but its complexity necessitates extensive expertise and effort to employ. By instead focusing solely on constructing an assay of developmental neurotoxicity, we propose that a simpler 2D tissue model may prove sufficient. We thus compare the accuracy of predictive models trained on data from a 2D tissue model with those trained on data from a 3D tissue model, and find the 2D model to be substantially more accurate. Furthermore, we find the 2D model to be more robust under stringent gene set selection, whereas the 3D model suffers substantial accuracy degradation. While both approaches have advantages and disadvantages, we propose that our described 2D approach could be a valuable tool for decision makers when prioritizing neurotoxicity screening."}}
{"id": "kfciX3zjgm5", "cdate": 1546300800000, "mdate": null, "content": {"title": "Machine learning for phenotyping opioid overdose events", "abstract": "Highlights \u2022 Phenotyping of opioid overdose cases stratified by severity using machine learning. \u2022 Random forests were superior to all other methods (AUC\u202f=\u202f0.893). \u2022 Features derived from the OMOP CDM and NLP boost performance. \u2022 Ordinal models were inferior to traditional classification methods. Abstract Objective To develop machine learning models for classifying the severity of opioid overdose events from clinical data. Materials and methods Opioid overdoses were identified by diagnoses codes from the Marshfield Clinic population and assigned a severity score via chart review to form a gold standard set of labels. Three primary feature sets were constructed from disparate data sources surrounding each event and used to train machine learning models for phenotyping. Results Random forest and penalized logistic regression models gave the best performance with cross-validated mean areas under the ROC curves (AUCs) for all severity classes of 0.893 and 0.882 respectively. Features derived from a common data model outperformed features collected from disparate data sources for the same cohort of patients (AUCs 0.893 versus 0.837, p value\u202f=\u202f0.002). The addition of features extracted from free text to machine learning models also increased AUCs from 0.827 to 0.893 (p value\u202f<\u202f0.0001). Key word features extracted using natural language processing (NLP) such as \u2018Narcan\u2019 and \u2018Endotracheal Tube\u2019 are important for classifying overdose event severity. Conclusion Random forest models using features derived from a common data model and free text can be effective for classifying opioid overdose events."}}
{"id": "SybMUjb_-S", "cdate": 1546300800000, "mdate": null, "content": {"title": "AUC\u03bc: A Performance Metric for Multi-Class Machine Learning Models", "abstract": "The area under the receiver operating characteristic curve (AUC) is arguably the most common metric in machine learning for assessing the quality of a two-class classification model. As the number ..."}}
