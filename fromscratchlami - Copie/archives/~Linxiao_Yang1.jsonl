{"id": "zWR96Pv27e", "cdate": 1640995200000, "mdate": 1663296099636, "content": {"title": "Robust Time Series Analysis and Applications: An Industrial Perspective", "abstract": "Time series analysis is ubiquitous and important in various areas, such as Artificial Intelligence for IT Operations (AIOps) in cloud computing, AI-powered Business Intelligence (BI) in E-commerce, Artificial Intelligence of Things (AIoT), etc. In real-world scenarios, time series data often exhibit complex patterns with trend, seasonality, outlier, and noise. In addition, as more time series data are collected and stored, how to handle the huge amount of data efficiently is crucial in many applications. We note that these significant challenges exist in various tasks like forecasting, anomaly detection, and fault cause localization. Therefore, how to design effective and efficient time series models for different tasks, which are robust to address the aforementioned challenging patterns and noise in real-world scenarios, is of great theoretical and practical interests. In this tutorial, we provide a comprehensive and organized tutorial on the state-of-the-art algorithms of robust time series analysis, ranging from traditional statistical methods to the most recent deep learning based methods. We will not only introduce the principle of time series algorithms, but also provide insights into how to apply them effectively in practical real-world industrial applications. Specifically, we organize the tutorial in a bottom-up framework. We first present preliminaries from different disciplines including robust statistics, signal processing, optimization, and deep learning. Then, we identify and discuss those most-frequently processing blocks in robust time series analysis, including periodicity detection, trend filtering, seasonal-trend decomposition, and time series similarity. Lastly, we discuss recent advances in multiple time series tasks including forecasting, anomaly detection, fault cause localization, and autoscaling, as well as practical lessons of large-scale time series applications from an industrial perspective."}}
{"id": "b4ZuMvVgaD", "cdate": 1640995200000, "mdate": 1674121417222, "content": {"title": "Learning Interpretable Decision Rule Sets: A Submodular Optimization Approach", "abstract": "Rule sets are highly interpretable logical models in which the predicates for decision are expressed in disjunctive normal form (DNF, OR-of-ANDs), or, equivalently, the overall model comprises an unordered collection of if-then decision rules. In this paper, we consider a submodular optimization based approach for learning rule sets. The learning problem is framed as a subset selection task in which a subset of all possible rules needs to be selected to form an accurate and interpretable rule set. We employ an objective function that exhibits submodularity and thus is amenable to submodular optimization techniques. To overcome the difficulty arose from dealing with the exponential-sized ground set of rules, the subproblem of searching a rule is casted as another subset selection task that asks for a subset of features. We show it is possible to write the induced objective function for the subproblem as a difference of two submodular (DS) functions to make it approximately solvable by DS optimization algorithms. Overall, the proposed approach is simple, scalable, and likely to be benefited from further research on submodular optimization. Experiments on real datasets demonstrate the effectiveness of our method."}}
{"id": "7GFNEDCfOSU", "cdate": 1640995200000, "mdate": 1674121417248, "content": {"title": "NetRCA: An Effective Network Fault Cause Localization Algorithm", "abstract": "Localizing the root cause of network faults is crucial to network operation and maintenance. However, due to the complicated network architectures and wireless environments, as well as limited labeled data, accurately localizing the true root cause is challenging. In this paper, we propose a novel algorithm named NetRCA to deal with this problem. Firstly, we extract effective derived features from the original raw data by considering temporal, directional, attribution, and interaction characteristics. Secondly, we adopt multivariate time series similarity and label propagation to generate new training data from both labeled and unlabeled data to overcome the lack of labeled samples. Thirdly, we design an ensemble model which combines XGBoost, rule set learning, attribution model, and graph algorithm, to fully utilize all data information and enhance performance. Finally, experiments and analysis are conducted on the real-world dataset from ICASSP 2022 AIOps Challenge to demonstrate the superiority and effectiveness of our approach."}}
{"id": "0EAK0nA64bW", "cdate": 1640995200000, "mdate": 1655008824206, "content": {"title": "Netrca: An Effective Network Fault Cause Localization Algorithm", "abstract": "Localizing the root cause of network faults is crucial to network operation and maintenance. However, due to the complicated network architectures and wireless environments, as well as limited labeled data, accurately localizing the true root cause is challenging. In this paper, we propose a novel algorithm named NetRCA to deal with this problem. Firstly, we extract effective derived features from the original raw data by considering temporal, directional, attribution, and interaction characteristics. Secondly, we adopt multivariate time series similarity and label propagation to generate new training data from both labeled and unlabeled data to overcome the lack of labeled samples. Thirdly, we design an ensemble model which combines XGBoost, rule set learning, attribution model, and graph algorithm, to fully utilize all data information and enhance performance. Finally, experiments and analysis are conducted on the real-world dataset from ICASSP 2022 AIOps Challenge to demonstrate the superiority and effectiveness of our approach."}}
{"id": "pZHGKM9mAp", "cdate": 1621629744284, "mdate": null, "content": {"title": "Learning Interpretable Decision Rule Sets: A Submodular Optimization Approach", "abstract": "Rule sets are highly interpretable logical models in which the predicates for decision are expressed in disjunctive normal form (DNF, OR-of-ANDs), or, equivalently, the overall model comprises an unordered collection of if-then decision rules. In this paper, we consider a submodular optimization based approach for learning rule sets. The learning problem is framed as a subset selection task in which a subset of all possible rules needs to be selected to form an accurate and interpretable rule set. We employ an objective function that exhibits submodularity and thus is amenable to submodular optimization techniques. To overcome the difficulty arose from dealing with the exponential-sized ground set of rules, the subproblem of searching a rule is casted as another subset selection task that asks for a subset of features. We show it is possible to write the induced objective function for the subproblem as a difference of two submodular (DS) functions to make it approximately solvable by DS optimization algorithms. Overall, the proposed approach is simple, scalable, and likely to be benefited from further research on submodular optimization. Experiments on real datasets demonstrate the effectiveness of our method."}}
{"id": "JoKZoqMLmww", "cdate": 1609459200000, "mdate": 1674121417231, "content": {"title": "A Robust and Efficient Multi-Scale Seasonal-Trend Decomposition", "abstract": "Many real-world time series exhibit multiple seasonality with different lengths. The removal of seasonal components is crucial in numerous applications of time series, including forecasting and anomaly detection. However, many seasonal-trend decomposition algorithms suffer from high computational cost and require a large amount of data when multiple seasonal components exist, especially when the periodic length is long. In this paper, we propose a general and efficient multi-scale seasonal-trend decomposition algorithm for time series with multiple seasonality. We first down-sample the original time series onto a lower resolution, and then convert it to a time series with single seasonality. Thus, existing seasonal-trend decomposition algorithms can be applied directly to obtain the rough estimates of trend and the seasonal component corresponding to the longer periodic length. By considering the relationship between different resolutions, we formulate the recovery of different components on the high resolution as an optimization problem, which is solved efficiently by our alternative direction multiplier method (ADMM) based algorithm. Our experimental results demonstrate the accurate decomposition results with significantly improved efficiency."}}
{"id": "JcbHPlGGadW", "cdate": 1609459200000, "mdate": 1674121417288, "content": {"title": "A Robust and Efficient Multi-Scale Seasonal-Trend Decomposition", "abstract": "Many real-world time series exhibit multiple seasonality with different lengths. The removal of seasonal components is crucial in numerous applications of time series, including forecasting and anomaly detection. However, many seasonal-trend decomposition algorithms suffer from high computational cost and require a large amount of data when multiple seasonal components exist, especially when the periodic length is long. In this paper, we propose a general and efficient multi-scale seasonal-trend decomposition algorithm for time series with multiple seasonality. We first down-sample the original time series onto a lower resolution, and then convert it to a time series with single seasonality. Thus, existing seasonal-trend decomposition algorithms can be applied directly to obtain the rough estimates of trend and the seasonal component corresponding to the longer periodic length. By considering the relationship between different resolutions, we formulate the recovery of different components on the high resolution as an optimization problem, which is solved efficiently by our alternative direction multiplier method (ADMM) based algorithm. Our experimental results demonstrate the accurate decomposition results with significantly improved efficiency."}}
{"id": "-6CO3WEjeW1", "cdate": 1609459200000, "mdate": 1674121417234, "content": {"title": "Learning Interpretable Decision Rule Sets: A Submodular Optimization Approach", "abstract": "Rule sets are highly interpretable logical models in which the predicates for decision are expressed in disjunctive normal form (DNF, OR-of-ANDs), or, equivalently, the overall model comprises an unordered collection of if-then decision rules. In this paper, we consider a submodular optimization based approach for learning rule sets. The learning problem is framed as a subset selection task in which a subset of all possible rules needs to be selected to form an accurate and interpretable rule set. We employ an objective function that exhibits submodularity and thus is amenable to submodular optimization techniques. To overcome the difficulty arose from dealing with the exponential-sized ground set of rules, the subproblem of searching a rule is casted as another subset selection task that asks for a subset of features. We show it is possible to write the induced objective function for the subproblem as a difference of two submodular (DS) functions to make it approximately solvable by DS optimization algorithms. Overall, the proposed approach is simple, scalable, and likely to be benefited from further research on submodular optimization. Experiments on real datasets demonstrate the effectiveness of our method."}}
{"id": "vkSHyoGTCb", "cdate": 1577836800000, "mdate": 1674121417491, "content": {"title": "Unsupervised Deep Spectrum Sensing: A Variational Auto-Encoder Based Approach", "abstract": "In cognitive radio (CR), the test statistics of most spectrum sensing algorithms are generated from the model-based features such as the signal energy and the eigenvalues from the sample covariance matrix (CM). Despite their low complexity, their detection performance depends very much on the accuracy of the presumed model. Also, these model-based statistics may not be able to exploit the full potential of the signal samples. To this end, the data-driven deep learning-based detectors have been proposed, with test statistics generated directly from signal samples in an automatic manner. However, existing deep learning-based detectors are all supervised learning-based and they usually require a massive amount of labeled training data to achieve decent detection performance. In practical CR scenarios, however, obtaining a large amount of labeled training data may be difficult. To address this issue, in this paper, we propose an unsupervised deep learning based spectrum sensing method named unsupervised deep spectrum sensing (UDSS). The UDSS algorithm requires no prior information such as the noise power or the signal's statistical CM. Moreover, the UDSS only requires a small amount of samples collected in absence of the primary user's (PU) signals ($H_0$ labeled data). Simulation results show that the proposed UDSS algorithm is able to approach the performance of the benchmark deep supervised learning-based spectrum sensing algorithm and outperforms the model-based benchmark algorithms under both Gaussian noise and Laplace noise."}}
{"id": "dbvZ-Y00FXq", "cdate": 1577836800000, "mdate": 1674121417493, "content": {"title": "Fast Compressed Power Spectrum Estimation: Toward a Practical Solution for Wideband Spectrum Sensing", "abstract": "There has been a growing interest in wideband spectrum sensing due to its applications in cognitive radios and electronic surveillance. To overcome the sampling rate bottleneck for wideband spectrum sensing, in this paper, we study the problem of compressed power spectrum estimation whose objective is to reconstruct the power spectrum of a wide-sense stationary signal based on sub-Nyquist samples. By exploring the sampling structure inherent in the multicoset sampling scheme, we develop a computationally efficient method for power spectrum reconstruction. An important advantage of our proposed method over existing compressed power spectrum estimation methods is that our proposed method, whose primary computational task consists of fast Fourier transform (FFT), has a very low computational complexity. Such a merit makes it possible to efficiently implement the proposed algorithm in a practical field-programmable gate array (FPGA)-based system for real-time wideband spectrum sensing. Our proposed method also provides a new perspective on the power spectrum recovery condition, which leads to a result similar to what was reported in prior works. Simulation results are presented to show the computational efficiency and the effectiveness of the proposed method."}}
