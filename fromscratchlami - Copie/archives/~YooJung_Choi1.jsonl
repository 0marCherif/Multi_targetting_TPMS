{"id": "Ym3pW4oqOUZ", "cdate": 1672531200000, "mdate": 1696011003511, "content": {"title": "Certifying Fairness of Probabilistic Circuits", "abstract": "With the increased use of machine learning systems for decision making, questions about the fairness properties of such systems start to take center stage. Most existing work on algorithmic fairness assume complete observation of features at prediction time, as is the case for popular notions like statistical parity and equal opportunity. However, this is not sufficient for models that can make predictions with partial observation as we could miss patterns of bias and incorrectly certify a model to be fair. To address this, a recently introduced notion of fairness asks whether the model exhibits any discrimination pattern, in which an individual\u2014characterized by (partial) feature observations\u2014receives vastly different decisions merely by disclosing one or more sensitive attributes such as gender and race. By explicitly accounting for partial observations, this provides a much more fine-grained notion of fairness. In this paper, we propose an algorithm to search for discrimination patterns in a general class of probabilistic models, namely probabilistic circuits. Previously, such algorithms were limited to naive Bayes classifiers which make strong independence assumptions; by contrast, probabilistic circuits provide a unifying framework for a wide range of tractable probabilistic models and can even be compiled from certain classes of Bayesian networks and probabilistic programs, making our method much more broadly applicable. Furthermore, for an unfair model, it may be useful to quickly find discrimination patterns and distill them for better interpretability. As such, we also propose a sampling-based approach to more efficiently mine discrimination patterns, and introduce new classes of patterns such as minimal, maximal, and Pareto optimal patterns that can effectively summarize exponentially many discrimination patterns."}}
{"id": "EXD5Hao_7Z", "cdate": 1672531200000, "mdate": 1696011003512, "content": {"title": "Probabilistic Reasoning and Learning for Trustworthy AI", "abstract": "As automated decision-making systems are increasingly deployed in areas with personal and societal impacts, there is a growing demand for artificial intelligence and machine learning systems that are fair, robust, interpretable, and generally trustworthy. Ideally we would wish to answer questions regarding these properties and provide guarantees about any automated system to be deployed in the real world. This raises the need for a unified language and framework under which we can reason about and develop trustworthy AI systems. This talk will discuss how tractable probabilistic reasoning and learning provides such framework. It is important to note that guarantees regarding fairness, robustness, etc., hold with respect to the distribution of the world in which the decision-making system operates. For example, to see whether automated loan decisions are biased against certain gender, one may compare the average decision for each gender; this requires knowledge of how the features used in the decision are distributed for each gender. Moreover, there are inherent uncertainties in modeling this distribution, in addition to the uncertainties when deploying a system in the real world, such as missing or noisy information. We can handle such uncertainties in a principled way through probabilistic reasoning. Taking fairness-aware learning as an example, we can deal with biased labels in the training data by explicitly modeling the observed labels as being generated from some probabilistic process that injects bias/noise to hidden, fair labels, particularly in a way that best explains the observed data. A key challenge that still needs to be addressed is that: we need models that can closely fit complex real-world distributions\u2014i.e. expressive\u2014while also being amenable to exact and efficient inference of probabilistic queries\u2014i.e. tractable. I will show that probabilistic circuits, a family of tractable probabilistic models, offer both such benefits. In order to ultimately develop a common framework to study various areas of trustworthy AI (e.g., privacy, fairness, explanations, etc.), we need models that can flexibly answer different questions, even the ones it did not foresee. This talk will thus survey the efforts to expand the horizon of complex reasoning capabilities of probabilistic circuits, especially highlighted by a modular approach that answers various queries via a pipeline of a handful of simple tractable operations."}}
{"id": "QLCzm27rM2", "cdate": 1655167733398, "mdate": null, "content": {"title": "Certifying Fairness of Probabilistic Circuits", "abstract": "With the increased use of machine learning systems for decision making, questions about their fairness properties start to take center stage. A recently introduced notion of fairness asks whether the model exhibits a \\textit{discrimination pattern}, in which an individual---characterized by (partial) feature observations---receives vastly different decisions merely by disclosing some sensitive attributes. Existing work on checking the presence of such patterns is limited to naive Bayes classifiers, which make strong independence assumptions. This paper proposes an algorithm to search for discrimination patterns in a more general class of probabilistic models---probabilistic circuits. If a model is not fair, it may be useful to quickly find discrimination patterns and distill them for better interpretability. As such, we also propose a sampling-based approach to more efficiently mine discrimination patterns, and introduce new classes of discrimination patterns: minimal, maximal, and Pareto optimal.\n"}}
{"id": "rITqy0rNAv2", "cdate": 1640995200000, "mdate": 1681510244444, "content": {"title": "Solving Marginal MAP Exactly by Probabilistic Circuit Transformations", "abstract": ""}}
{"id": "GL9W_ID4Hnn", "cdate": 1640995200000, "mdate": 1681510244649, "content": {"title": "Certifying Fairness of Probabilistic Circuits", "abstract": ""}}
{"id": "2gmnLGCwWS", "cdate": 1623413376434, "mdate": null, "content": {"title": "A Compositional Atlas of Tractable Circuit Operations for Probabilistic Inference", "abstract": "Circuit representations are becoming the lingua franca to express and reason about tractable generative and discriminative models.\nIn this paper, we show how complex inference scenarios for these models that commonly arise in machine learning---from computing the expectations of decision tree ensembles to information-theoretic divergences of sum-product networks---can be represented in terms of tractable modular operations over circuits. Specifically, we characterize the tractability of simple transformations---sums, products, powers, logarithms, and exponentials---in terms of sufficient structural constraints of the circuits they operate on. Building on these operations, we derive a unified framework for reasoning about tractable models that generalizes several results in the literature and opens up novel tractable inference scenarios."}}
{"id": "9SD2Rb3NiWu", "cdate": 1621630085128, "mdate": null, "content": {"title": "A Compositional Atlas of Tractable Circuit Operations for Probabilistic Inference", "abstract": "Circuit representations are becoming the lingua franca to express and reason about tractable generative and discriminative models. In this paper, we show how complex inference scenarios for these models that commonly arise in machine learning---from  computing the expectations of decision tree ensembles to information-theoretic divergences of sum-product networks---can be represented in terms of tractable modular operations over circuits. Specifically, we characterize the tractability of simple transformations---sums, products, quotients, powers, logarithms, and exponentials---in terms of sufficient structural constraints of the circuits they operate on, and present novel hardness results for the cases in which these properties are not satisfied. Building on these operations, we derive a unified framework for reasoning about tractable models that generalizes several results in the literature and opens up novel tractable inference scenarios."}}
{"id": "UQ95S7OctbF", "cdate": 1620880351443, "mdate": null, "content": {"title": "On Tractable Computation of Expected Predictions", "abstract": "Computing expected predictions of discriminative models is a fundamental task in machine learning that appears in many interesting applications such as fairness, handling missing values, and data analysis. Unfortunately, computing expectations of a discriminative model with respect to a probability distribution defined by an arbitrary generative model has been proven to be hard in general. In fact, the task is intractable even for simple models such as logistic regression and a naive Bayes distribution. In this paper, we identify a pair of generative and discriminative models that enables tractable computation of expectations, as well as moments of any order, of the latter with respect to the former in case of regression. Specifically, we consider expressive probabilistic circuits with certain structural constraints that support tractable probabilistic inference. Moreover, we exploit the tractable computation of high-order moments to derive an algorithm to approximate the expectations for classification scenarios in which exact computations are intractable. Our framework to compute expected predictions allows for handling of missing data during prediction time in a principled and accurate way and enables reasoning about the behavior of discriminative models. We empirically show our algorithm to consistently outperform standard imputation techniques on a variety of datasets. Finally, we illustrate how our framework can be used for exploratory data analysis."}}
{"id": "6dmUsi8nqT7", "cdate": 1620880167086, "mdate": null, "content": {"title": "A Compositional Atlas of Tractable Circuit Operations: From Simple Transformations to Complex Information-Theoretic Queries", "abstract": " Circuit representations are becoming the lingua franca to express and reason about tractable generative and discriminative models. In this paper, we show how complex inference scenarios for these models that commonly arise in machine learning -- from computing the expectations of decision tree ensembles to information-theoretic divergences of deep mixture models -- can be represented in terms of tractable modular operations over circuits. Specifically, we characterize the tractability of a vocabulary of simple transformations -- sums, products, quotients, powers, logarithms, and exponentials -- in terms of sufficient structural constraints of the circuits they operate on, and present novel hardness results for the cases in which these properties are not satisfied. Building on these operations, we derive a unified framework for reasoning about tractable models that generalizes several results in the literature and opens up novel tractable inference scenarios. "}}
{"id": "rWonrB9r_UT", "cdate": 1609459200000, "mdate": 1652729049237, "content": {"title": "A Compositional Atlas of Tractable Circuit Operations for Probabilistic Inference", "abstract": "Circuit representations are becoming the lingua franca to express and reason about tractable generative and discriminative models. In this paper, we show how complex inference scenarios for these models that commonly arise in machine learning---from computing the expectations of decision tree ensembles to information-theoretic divergences of sum-product networks---can be represented in terms of tractable modular operations over circuits. Specifically, we characterize the tractability of simple transformations---sums, products, quotients, powers, logarithms, and exponentials---in terms of sufficient structural constraints of the circuits they operate on, and present novel hardness results for the cases in which these properties are not satisfied. Building on these operations, we derive a unified framework for reasoning about tractable models that generalizes several results in the literature and opens up novel tractable inference scenarios."}}
