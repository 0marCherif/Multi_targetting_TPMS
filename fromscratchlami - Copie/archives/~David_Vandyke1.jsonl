{"id": "SVhzDaPMggF", "cdate": 1634219621083, "mdate": 1634219621083, "content": {"title": "A Generative Model for Joint Natural Language Understanding and Generation", "abstract": "Natural language understanding (NLU) and natural language generation (NLG) are two fundamental and related tasks in building task-oriented dialogue systems with opposite objectives: NLU tackles the transformation from natural language to formal representations, whereas NLG does the reverse. A key to success in either task is parallel training data which is expensive to obtain at a large scale. In this work, we propose a generative model which couples NLU and NLG through a shared latent variable. This approach allows us to explore both spaces of natural language and formal representations, and facilitates information sharing through the latent space to eventually benefit NLU and NLG. Our model achieves state-of-the-art performance on two dialogue datasets with both flat and tree-structured formal representations. We also show that the model can be trained in a semi-supervised fashion by utilising unlabelled data to boost its performance."}}
{"id": "mCZEnBd2-r2F", "cdate": 1577836800000, "mdate": null, "content": {"title": "A Generative Model for Joint Natural Language Understanding and Generation", "abstract": "Natural language understanding (NLU) and natural language generation (NLG) are two fundamental and related tasks in building task-oriented dialogue systems with opposite objectives: NLU tackles the transformation from natural language to formal representations, whereas NLG does the reverse. A key to success in either task is parallel training data which is expensive to obtain at a large scale. In this work, we propose a generative model which couples NLU and NLG through a shared latent variable. This approach allows us to explore both spaces of natural language and formal representations, and facilitates information sharing through the latent space to eventually benefit NLU and NLG. Our model achieves state-of-the-art performance on two dialogue datasets with both flat and tree-structured formal representations. We also show that the model can be trained in a semi-supervised fashion by utilising unlabelled data to boost its performance."}}
{"id": "fUfqrziMmJU", "cdate": 1577836800000, "mdate": null, "content": {"title": "A Generative Model for Joint Natural Language Understanding and Generation", "abstract": "Natural language understanding (NLU) and natural language generation (NLG) are two fundamental and related tasks in building task-oriented dialogue systems with opposite objectives: NLU tackles the transformation from natural language to formal representations, whereas NLG does the reverse. A key to success in either task is parallel training data which is expensive to obtain at a large scale. In this work, we propose a generative model which couples NLU and NLG through a shared latent variable. This approach allows us to explore both spaces of natural language and formal representations, and facilitates information sharing through the latent space to eventually benefit NLU and NLG. Our model achieves state-of-the-art performance on two dialogue datasets with both flat and tree-structured formal representations. We also show that the model can be trained in a semi-supervised fashion by utilising unlabelled data to boost its performance."}}
{"id": "xQpY5-xrcS", "cdate": 1483228800000, "mdate": null, "content": {"title": "A Network-based End-to-End Trainable Task-oriented Dialogue System", "abstract": "Tsung-Hsien Wen, David Vandyke, Nikola Mrk\u0161i\u0107, Milica Ga\u0161i\u0107, Lina M. Rojas-Barahona, Pei-Hao Su, Stefan Ultes, Steve Young. Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 1, Long Papers. 2017."}}
{"id": "_O19pzHBF_3", "cdate": 1483228800000, "mdate": null, "content": {"title": "Dialogue manager domain adaptation using Gaussian process reinforcement learning", "abstract": "Highlights \u2022 Generic-specific policy model. \u2022 Policy committee model. \u2022 Multi-agent policy model. \u2022 Human user evaluation. Abstract Spoken dialogue systems allow humans to interact with machines using natural speech. As such, they have many benefits. By using speech as the primary communication medium, a computer interface can facilitate swift, human-like acquisition of information. In recent years, speech interfaces have become ever more popular, as is evident from the rise of personal assistants such as Siri, Google Now, Cortana and Amazon Alexa. Recently, data-driven machine learning methods have been applied to dialogue modelling and the results achieved for limited-domain applications are comparable to or out-perform traditional approaches. Methods based on Gaussian processes are particularly effective as they enable good models to be estimated from limited training data. Furthermore, they provide an explicit estimate of the uncertainty which is particularly useful for reinforcement learning. This article explores the additional steps that are necessary to extend these methods to model multiple dialogue domains. We show that Gaussian process reinforcement learning is an elegant framework that naturally supports a range of methods, including prior knowledge, Bayesian committee machines and multi-agent learning, for facilitating extensible and adaptable dialogue systems."}}
{"id": "HkWWkald-H", "cdate": 1483228800000, "mdate": null, "content": {"title": "PyDial: A Multi-domain Statistical Dialogue System Toolkit", "abstract": "Stefan Ultes, Lina M. Rojas-Barahona, Pei-Hao Su, David Vandyke, Dongho Kim, I\u00f1igo Casanueva, Pawe\u0142 Budzianowski, Nikola Mrk\u0161i\u0107, Tsung-Hsien Wen, Milica Ga\u0161i\u0107, Steve Young. Proceedings of ACL 2017, System Demonstrations. 2017."}}
{"id": "usp8E7Oq3jz", "cdate": 1451606400000, "mdate": null, "content": {"title": "Continuously Learning Neural Dialogue Management", "abstract": "We describe a two-step approach for dialogue management in task-oriented spoken dialogue systems. A unified neural network framework is proposed to enable the system to first learn by supervision from a set of dialogue data and then continuously improve its behaviour via reinforcement learning, all using gradient-based algorithms on one single model. The experiments demonstrate the supervised model's effectiveness in the corpus-based evaluation, with user simulation, and with paid human subjects. The use of reinforcement learning further improves the model's performance in both interactive settings, especially under higher-noise conditions."}}
{"id": "jLf26dT2Jse", "cdate": 1451606400000, "mdate": null, "content": {"title": "A Network-based End-to-End Trainable Task-oriented Dialogue System", "abstract": "Teaching machines to accomplish tasks by conversing naturally with humans is challenging. Currently, developing task-oriented dialogue systems requires creating multiple components and typically this involves either a large amount of handcrafting, or acquiring costly labelled datasets to solve a statistical learning problem for each component. In this work we introduce a neural network-based text-in, text-out end-to-end trainable goal-oriented dialogue system along with a new way of collecting dialogue data based on a novel pipe-lined Wizard-of-Oz framework. This approach allows us to develop dialogue systems easily and without making too many assumptions about the task at hand. The results show that the model can converse with human subjects naturally whilst helping them to accomplish tasks in a restaurant search domain."}}
{"id": "Sk-TbXWOWH", "cdate": 1451606400000, "mdate": null, "content": {"title": "Multi-domain Neural Network Language Generation for Spoken Dialogue Systems", "abstract": "\u00a92016 Association for Computational Linguistics. Moving from limited-domain natural language generation (NLG) to open domain is difficult because the number of semantic input combinations grows exponentially with the number of domains. Therefore, it is important to leverage existing resources and exploit similarities between domains to facilitate domain adaptation. In this paper, we propose a procedure to train multi-domain, Recurrent Neural Network-based (RNN) language generators via multiple adaptation steps. In this procedure, a model is first trained on counterfeited data synthesised from an out-of-domain dataset, and then fine tuned on a small set of in-domain utterances with a discriminative objective function. Corpus-based evaluation results show that the proposed procedure can achieve competitive performance in terms of BLEU score and slot error rate while significantly reducing the data needed to train generators in new, unseen domains. In subjective testing, human judges confirm that the procedure greatly improves generator performance when only a small amount of data is available in the domain."}}
{"id": "SJbYy2gO-r", "cdate": 1451606400000, "mdate": null, "content": {"title": "On-line Active Reward Learning for Policy Optimisation in Spoken Dialogue Systems", "abstract": "\u00a9 2016 Association for Computational Linguistics. The ability to compute an accurate reward function is essential for optimising a dialogue policy via reinforcement learning. In real-world applications, using explicit user feedback as the reward signal is often unreliable and costly to collect. This problem can be mitigated if the user's intent is known in advance or data is available to pre-train a task success predictor off-line. In practice neither of these apply for most real world applications. Here we propose an on-line learning framework whereby the dialogue policy is jointly trained alongside the reward model via active learning with a Gaussian process model. This Gaussian process operates on a continuous space dialogue representation generated in an unsupervised fashion using a recurrent neural network encoder-decoder. The experimental results demonstrate that the proposed framework is able to significantly reduce data annotation costs and mitigate noisy user feedback in dialogue policy learning."}}
