{"id": "uHGJ-8PMImN", "cdate": 1652474400309, "mdate": 1652474400309, "content": {"title": "Estimation in Rotationally Invariant Generalized Linear Models via Approximate Message Passing", "abstract": "We consider the problem of signal estimation in generalized linear models defined via rotationally invariant design matrices. Since these matrices can have an arbitrary spectral distribution, this model is well suited to capture complex correlation structures which often arise in applications. We propose a novel family of approximate message passing (AMP) algorithms for signal estimation, and rigorously characterize their performance in the high-dimensional limit via a state evolution recursion. Assuming knowledge of the design matrix spectrum, our rotationally invariant AMP has complexity of the same order as the existing AMP for Gaussian matrices; it also recovers the existing AMP as a special case. Numerical results showcase a performance close to Vector AMP (which is conjectured to be Bayes-optimal in some settings), but obtained with a much lower complexity, as the proposed algorithm does not require a computationally expensive singular value decomposition."}}
{"id": "FEIFFzmq_V_", "cdate": 1621629805795, "mdate": null, "content": {"title": "PCA Initialization for Approximate Message Passing in Rotationally Invariant Models", "abstract": "We study the problem of estimating a rank-1 signal in the presence of rotationally invariant noise--a class of perturbations more general than Gaussian noise.  Principal Component Analysis (PCA) provides a natural estimator, and sharp results on its performance have been obtained in the high-dimensional regime. Recently, an Approximate Message Passing (AMP) algorithm has been proposed as an alternative estimator with the potential to improve the accuracy of PCA. However, the existing analysis of AMP requires an initialization that is both correlated with the signal and independent of the noise, which is often unrealistic in practice. In this work, we combine the two methods, and propose to initialize AMP with PCA. Our main result is a rigorous asymptotic characterization of the performance of this estimator. Both the AMP algorithm and its analysis differ from those previously derived in the Gaussian setting: at every iteration, our AMP algorithm requires a specific term to account for PCA initialization, while in the Gaussian case, PCA initialization affects only the first iteration of AMP. The proof is based on a two-phase artificial AMP that first approximates the PCA estimator and then mimics the true AMP. Our numerical simulations show an excellent agreement between AMP results and theoretical predictions, and suggest an interesting open direction on achieving Bayes-optimal performance."}}
{"id": "ETRum0mXQG", "cdate": 1598858954038, "mdate": null, "content": {"title": "Optimal Combination of Linear and Spectral Estimators for Generalized Linear Models", "abstract": "We study the problem of recovering an unknown signal x given measurements obtained from a generalized linear model with a Gaussian sensing matrix. Two popular solutions are based on a linear estimator x\u02c6L and a spectral estimator x\u02c6s. The former is a data-dependent linear combination of the columns of the measurement matrix, and its analysis is quite simple. The latter is the principal eigenvector of a data-dependent matrix, and a recent line of work has studied its performance. In this paper, we show how to optimally combine x\u02c6L and x\u02c6s. At the heart of our analysis is the exact characterization of the empirical joint distribution of (x, x\u02c6L, x\u02c6s) in the high-dimensional limit. This allows us to compute the Bayes-optimal combination of x\u02c6L and x\u02c6s, given the limiting distribution of the signal x. When the distribution of the signal is Gaussian, then the Bayes-optimal combination has the form \u03b8x\u02c6L + x\u02c6s and we derive the optimal combination coefficient. In order to establish the limiting distribution of (x,x\u02c6L,x\u02c6s), we design and analyze an Approximate Message Passing (AMP) algorithm whose iterates give x\u02c6L and approach x\u02c6s. Numerical simulations demonstrate the improvement of the proposed combination with respect to the two methods considered separately.\n"}}
