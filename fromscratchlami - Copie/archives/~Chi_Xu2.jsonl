{"id": "lwDzx3-T04", "cdate": 1672531200000, "mdate": 1692845197640, "content": {"title": "Gait Recognition from Fisheye Images", "abstract": "Gait recognition has been a hot topic of extensive research in video-based surveillance and forensics. Compared with traditional rectilinear cameras mainly used in existing studies, fisheye cameras have a wider field of view, and hence are more suitable for gait recognition applications in navigation robots, which enables more flexible and free surveillance scenarios. In this paper, to the best of our knowledge, we propose the first framework for gait recognition from images captured by fisheye cameras. To deal with severe image distortion and partial body occlusions induced by fisheye cameras set at lower heights, we combine a set of preprocessing procedures with a state-of-the-art model-based gait recognition method. Specifically, an input fisheye image is first expanded into a panoramic view before pedestrian detection. A person-dependent gnomonic projection is then applied to the detected human region for distortion correction. Next, background regions are attenuated to improve human model fitting accuracy in complex outdoor scenes. The resulting rectified image sequence is finally fed into the gait recognition network for human model estimation and gait feature extraction. To validate the performance, we collect a real fisheye image gait dataset with various views and capture scenarios, including simplified indoor and challenging outdoor scenes. Various experiments on the collected dataset demonstrate the effectiveness of the proposed method."}}
{"id": "FRU79ZaIXO", "cdate": 1672531200000, "mdate": 1675933602644, "content": {"title": "Occlusion-Aware Human Mesh Model-Based Gait Recognition", "abstract": "Partial occlusion of the human body caused by obstacles or a limited camera field of view often occurs in surveillance videos, which affects the performance of gait recognition in practice. Existing methods for gait recognition against occlusion require a bounding box or the height of a full human body as a prerequisite, which is unobserved in occlusion scenarios. In this paper, we propose an occlusion-aware model-based gait recognition method that works directly on gait videos under occlusion without the above-mentioned prerequisite. Specifically, given a gait sequence that only contains non-occluded body parts in the images, we directly fit a skinned multi-person linear (SMPL)-based human mesh model to the input images without any pre-normalization or registration of the human body. We further use the pose and shape features extracted from the estimated SMPL model for recognition purposes, and use the extracted camera parameters in the occlusion attenuation module to reduce intra-subject variation in human model fitting caused by occlusion pattern differences. Experiments on occlusion samples simulated from the OU-MVLP dataset demonstrated the effectiveness of the proposed method, which outperformed state-of-the-art gait recognition methods by about 15% rank-1 identification rate and 2% equal error rate in the identification and verification scenarios, respectively."}}
{"id": "DQggByyk4g", "cdate": 1672531200000, "mdate": 1705542816577, "content": {"title": "Occluded Gait Recognition via Silhouette Registration Guided by Automated Occlusion Degree Estimation", "abstract": "Gait recognition tasks often face significant difficulties caused by partial occlusions of the human body. To address this challenge, we propose a silhouette registration method based on flexible estimation of the spatial scale associated with the occluding elements. Existing appearance-based methods require prior knowledge about the spatial scale of the human body in relation to the input image, or a bounding box that includes the actual full body. In our method, the region corresponding to the silhouette of the body is estimated directly from visible body parts within the image. This estimate is then used to normalize and register the human body by adapting it to the scale of the occlusions. To reduce the occlusion difference between elements of a matching pair, which may lead to substantial intra-subject variation when the difference is large, we use a pairwise mask to extract common visible regions for subsequent feature learning and matching. Experiments on the synthetic occluded OU-MVLP dataset demonstrate the effectiveness of the proposed method, which successfully improves recognition performance when matching pairs present occlusion differences. We discuss specific characteristics of the proposed silhouette registration and pairwise masking methods with the aid of detailed quantitative and qualitative evaluations, in the hope of providing useful insights for future research on this topic."}}
{"id": "VOUWq-n3KCq", "cdate": 1640995200000, "mdate": 1668563218524, "content": {"title": "Multi-View Large Population Gait Database With Human Meshes and Its Performance Evaluation", "abstract": "Existing model-based gait databases provide the 2D poses (i.e., joint locations) extracted by general pose estimators as the human model. However, these 2D poses suffer from information loss and are of relatively low quality. In this paper, we consider a more informative 3D human mesh model with parametric pose and shape features, and propose a multi-view training framework for accurate mesh estimation. Unlike existing methods, which estimate a mesh from a single view and suffer from the ill-posed estimation problem in 3D space, the proposed framework takes asynchronous multi-view gait sequences as input and uses both multi-view and single-view streams to learn consistent and accurate mesh models for both multi-view and single-view sequences. After applying the proposed framework to the existing OU-MVLP database, we establish a large-scale gait database with human meshes (i.e., OUMVLP-Mesh), containing over 10,000 subjects and up to 14 view angles. Experimental results show that the proposed framework estimates human mesh models more accurately than similar methods, providing models of sufficient quality to improve the recognition performance of a baseline model-based gait recognition approach."}}
{"id": "XlGhjNifXmQ", "cdate": 1623603066836, "mdate": 1623603066836, "content": {"title": "DeformGait: Gait Recognition under Posture Changes using Deformation Patterns between Gait Feature Pairs", "abstract": "In this paper, we propose a unified convolutional neural network (CNN) framework for robust gait recognition against posture changes (e.g., those induced by walking speed changes). In order to mitigate the posture changes, we first register an input matching pair of gait features with different postures by a deformable registration network, which estimates a deformation field to transform the input pair both into their intermediate posture. The pair of the registered features is then fed into a recognition network. Furthermore, ways of the deformation (i.e., deformation patterns) can differ between the same subject pairs (e.g., only posture deformation) and different subject pairs (e.g., not only posture deformation but also body shape deformation), which implies the deformation pattern can be another cue to distinguish the same subject pairs from the different subject pairs. We therefore introduce another recognition network whose input is the deformation pattern. Finally, the deformable registration network, and the two recognition networks for the registered features and the deformation patterns, constitute the whole framework, named DeformGait, and they are trained in an end-to-end manner by minimizing a loss function which is appropriately designed for each of verification and identification scenario. Experiments on the publicly available dataset containing the largest speed variations demonstrate that the proposed method achieves the state-of-the-art performance in both identification and verification scenarios."}}
{"id": "5x3lfIDemHZ", "cdate": 1623602868563, "mdate": 1623602868563, "content": {"title": "Real-Time Gait-Based Age Estimation and Gender Classification From a Single Image", "abstract": "In this paper, we propose a unified real-time framework for gait-based age estimation and gender classification that uses just a single image, which reduces the latency in video capturing compared with the existing methods based on a gait cycle. To cope with the problem of lacking motion information in the input single image, we first reconstruct a gait cycle of a silhouette sequence from the input image via a gait cycle reconstruction network. The reconstructed gait cycle is then fed into a state-of-the-art gait recognition network for feature representation learning, which is further used to obtain the class of the gender and the estimated probability distribution of integer age labels. Unlike the existing methods focusing on the gait sequences captured from the side view, the proposed method is applicable to the gait images from an arbitrary view with a single trained model, which is more suitable for real-world application scenarios (e.g., automatic access control). Stand-alone and client-server online systems were implemented based on the proposed method, which validates the real-time/online property in actual scenes. The experiments on the world's largest multi-view gait dataset demonstrate the effectiveness of the proposed method, which achieves performance improvement compared with the benchmark algorithms."}}
{"id": "wmx-8-yKuoG", "cdate": 1623602640581, "mdate": 1623602640581, "content": {"title": "Uncertainty-aware Gait-based Age Estimation and Its Applications", "abstract": "Gait-based age estimation is a key technique for many applications. It is well known that age estimation uncertainty is highly dependent on age (i.e., small for children and large for adults), and it is important to know the uncertainty for the above-mentioned applications. Therefore, we propose a method for uncertainty-aware gait-based age estimation by introducing a label distribution learning framework. Specifically, we design a network that takes an appearance-based gait feature as input and outputs discrete label distributions in the integer age domain. We then train the network to minimize a loss function, which is defined as the dissimilarity between the estimated age distribution and the ground-truth age distribution, in addition to the conventional mean absolute error for the estimated age. Additionally, we demonstrate that uncertainty-aware gait-based age estimation is beneficial for two applications: person search by age query and people counting by age group. Experiments on the world\u2019s largest gait database, OULP-Age, demonstrated that the proposed method can successfully represent age estimation uncertainty, and outperforms or is comparable with state-of-the-art methods in terms of age estimation accuracy. Moreover, we demonstrated the effectiveness of the uncertainty-aware framework in applications to person search and people counting through experiments on the database."}}
{"id": "tYPu4W38TBI", "cdate": 1623602079881, "mdate": 1623602079881, "content": {"title": "Speed-invariant gait recognition using single-support gait energy image", "abstract": "Gait is one of the most popular behavioral biometrics because it can be authenticated at a distance from a camera without subject cooperation. Speed differences between matching pairs, however, cause significant performance drops in gait recognition, and gait mode difference (i.e., walking versus running) makes gait recognition further challenging. We therefore propose a speed-invariant gait representation called single-support GEI (SSGEI), which realizes a good trade-off between speed invariance and stability by aggregating multiple frames around single-support phases. In addition, to mitigate the pose differences between walking and running modes at single-support phases, we morph walking and running SSGEIs into intermediate SSGEIs between walking and running mode, where we exploit a free-form deformation field from the walking or running modes to the intermediate mode obtained by training data. We finally apply Gabor filtering and spatial metric learning as postprocessing for further accuracy improvement. Experiments on two publicly available datasets, the OU-ISIR Treadmill Dataset A and the CASIA-C Dataset demonstrate that the proposed method yields the state-of-the-art accuracies in both identification and verification scenarios with a low computational cost."}}
{"id": "FupypZyA25-", "cdate": 1623601944620, "mdate": 1623601944620, "content": {"title": "Gait recognition invariant to carried objects using alpha blending generative adversarial networks", "abstract": "Gait recognition invariant to carried objects (COs) is very difficult in a real-life scene because the COs can have various shapes and sizes, in addition to unpredictable carrying locations (e.g., front, back, and side, or multiple locations). Therefore, in this paper, we propose a robust method for gait recognition against various COs by reconstructing a gait template without COs. A straightforward approach is to directly generate a gait template without COs given a gait template with COs as the input using a conventional generative adversarial network. There is, however, a potential risk of unnecessarily altering parts that were originally unaffected by COs (e.g., leg parts for a person carrying a backpack). Because we do not want to touch such unaffected parts in the original template, we first estimate a gait template without COs, and then blend it with the original template by an estimated alpha matte that indicates the blending parameters. We then create an alpha-blended template from the original template and the generated template without COs based on the estimated alpha matte. We use two independent generators to estimate the alpha matte and the generated template without COs. Finally, we feed the alpha-blended gait template into a state-of-the-art discrimination network for gait recognition. The experimental results on three publicly available gait databases with real-life COs demonstrate the state-of-the-art performance of the proposed method."}}
{"id": "-NknXIEHR8x", "cdate": 1623601748737, "mdate": 1623601748737, "content": {"title": "Speed invariance vs. stability: cross-speed gait recognition using single-support gait energy image", "abstract": "Gait recognition has recently attracted much attention since it can identify person at a distance without subject cooperation. Walking speed changes, however, cause gait changes in appearance, which significantly drops performance of gait recognition. Considering a speed-invariant property at single-support phases where stride change due to speed changes are mitigated, and a stability against phase estimation error and segmentation noise by aggregating multiple phases inspired by gait energy image (GEI), we propose a speed-invariant gait representation called single-support GEI (SSGEI), which realizes a good trade-off between the speed invariance and the stability by combining single-support phases and GEI concept. For this purpose, we firstly find out the optimal duration around single support phases using a training set so as to well balance the speed invariance and the stability. We then extract SSGEI by aggregating multiple single-support frames. Finally, we combine the proposed SSGEI with subsequent Gabor filters and metric learning for better performance. Experiments on the publicly available OU-ISIR Treadmill Dataset A composed of the largest speed variations demonstrated that the proposed method yielded 99.33% rank-1 identification rate on average for cross-speed gait recognition, which outperforms the other state-of-the-arts, and realized a low computational cost as well."}}
