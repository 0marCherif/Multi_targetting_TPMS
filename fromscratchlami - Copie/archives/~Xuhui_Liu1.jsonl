{"id": "fMwkliZ6qL4", "cdate": 1672531200000, "mdate": 1683772578884, "content": {"title": "Implicit Diffusion Models for Continuous Super-Resolution", "abstract": "Image super-resolution (SR) has attracted increasing attention due to its wide applications. However, current SR methods generally suffer from over-smoothing and artifacts, and most work only with fixed magnifications. This paper introduces an Implicit Diffusion Model (IDM) for high-fidelity continuous image super-resolution. IDM integrates an implicit neural representation and a denoising diffusion model in a unified end-to-end framework, where the implicit neural representation is adopted in the decoding process to learn continuous-resolution representation. Furthermore, we design a scale-controllable conditioning mechanism that consists of a low-resolution (LR) conditioning network and a scaling factor. The scaling factor regulates the resolution and accordingly modulates the proportion of the LR information and generated features in the final output, which enables the model to accommodate the continuous-resolution requirement. Extensive experiments validate the effectiveness of our IDM and demonstrate its superior performance over prior arts."}}
{"id": "AataVsjoJP", "cdate": 1672531200000, "mdate": 1683772578905, "content": {"title": "Face Animation with an Attribute-Guided Diffusion Model", "abstract": "Face animation has achieved much progress in computer vision. However, prevailing GAN-based methods suffer from unnatural distortions and artifacts due to sophisticated motion deformation. In this paper, we propose a Face Animation framework with an attribute-guided Diffusion Model (FADM), which is the first work to exploit the superior modeling capacity of diffusion models for photo-realistic talking-head generation. To mitigate the uncontrollable synthesis effect of the diffusion model, we design an Attribute-Guided Conditioning Network (AGCN) to adaptively combine the coarse animation features and 3D face reconstruction results, which can incorporate appearance and motion conditions into the diffusion process. These specific designs help FADM rectify unnatural artifacts and distortions, and also enrich high-fidelity facial details through iterative diffusion refinements with accurate animation attributes. FADM can flexibly and effectively improve existing animation videos. Extensive experiments on widely used talking-head benchmarks validate the effectiveness of FADM over prior arts."}}
{"id": "7HTEHRMlxYH", "cdate": 1652737405694, "mdate": null, "content": {"title": "FNeVR: Neural Volume Rendering for Face Animation", "abstract": "Face animation, one of the hottest topics in computer vision, has achieved a promising performance with the help of generative models. However, it remains a critical challenge to generate identity preserving and photo-realistic images due to the sophisticated motion deformation and complex facial detail modeling. To address these problems, we propose a Face Neural Volume Rendering (FNeVR) network to fully explore the potential of 2D motion warping and 3D volume rendering in a unified framework. In FNeVR, we design a 3D Face Volume Rendering (FVR) module to enhance the facial details for image rendering. Specifically, we first extract 3D information with a well designed architecture, and then introduce an orthogonal adaptive ray-sampling module for efficient rendering. We also design a lightweight pose editor, enabling FNeVR to edit the facial pose in a simple yet effective way. Extensive experiments show that our FNeVR obtains the best overall quality and performance on widely used talking-head benchmarks."}}
{"id": "rqkdcTe_Hq", "cdate": 1640995200000, "mdate": 1668671342441, "content": {"title": "Attentive encoder-decoder networks for crowd counting", "abstract": ""}}
{"id": "hANUJzG2CYk", "cdate": 1640995200000, "mdate": 1668388681750, "content": {"title": "Weakly Supervised Object Detection Based on Active Learning", "abstract": "Weakly supervised object detection which reduces the need for strong supersivison during training has recently made significant achievements. However, it remains a challenging issue due to the time-consuming and labor-intensive problems in application. To further reduce the label cost, we introduce a new fusion method of weakly supervised learning and active learning in a unied framework for object detection. Weakly supervised learning based on min-entropy latent model is used to weaken the labels by image-label, while active learning is used to reduce the quantity of labeled images. The fusion method proposed can effectively reduce the dependency of object detection on manual annotation. In this paper, we introduce three strategies of active learning, including least confidence sampling, margining sampling and weighted classification sampling. To validate the effectiveness of each strategy and different sample compositions in weakly supervised learning object detection, we conducted lots of experiments. Extensive experiments show that the combination of image-level labeling and active learning can achieve comparable results with the previous state-of-the-art methods with much lower label cost."}}
{"id": "h5NpS1VTVR", "cdate": 1640995200000, "mdate": 1683772541560, "content": {"title": "FNeVR: Neural Volume Rendering for Face Animation", "abstract": "Face animation, one of the hottest topics in computer vision, has achieved a promising performance with the help of generative models. However, it remains a critical challenge to generate identity preserving and photo-realistic images due to the sophisticated motion deformation and complex facial detail modeling. To address these problems, we propose a Face Neural Volume Rendering (FNeVR) network to fully explore the potential of 2D motion warping and 3D volume rendering in a unified framework. In FNeVR, we design a 3D Face Volume Rendering (FVR) module to enhance the facial details for image rendering. Specifically, we first extract 3D information with a well designed architecture, and then introduce an orthogonal adaptive ray-sampling module for efficient rendering. We also design a lightweight pose editor, enabling FNeVR to edit the facial pose in a simple yet effective way. Extensive experiments show that our FNeVR obtains the best overall quality and performance on widely used talking-head benchmarks."}}
{"id": "520EatDekrw", "cdate": 1640995200000, "mdate": 1683772818033, "content": {"title": "MagFormer: Hybrid Video Motion Magnification Transformer from Eulerian and Lagrangian Perspectives", "abstract": ""}}
{"id": "CbNW4AV72kf", "cdate": 1609459200000, "mdate": 1683809478520, "content": {"title": "Alignment Enhancement Network for Fine-grained Visual Categorization", "abstract": "Fine-grained visual categorization (FGVC) aims to automatically recognize objects from different sub-ordinate categories. Despite attracting considerable attention from both academia and industry, it remains a challenging task due to subtle visual differences among different classes. Cross-layer feature aggregation and cross-image pairwise learning become prevailing in improving the performance of FGVC by extracting discriminative class-specific features. However, they are still inefficient to fully use the cross-layer information based on the simple aggregation strategy, while existing pairwise learning methods also fail to explore long-range interactions between different images. To address these problems, we propose a novel Alignment Enhancement Network (AENet), including two-level alignments, Cross-layer Alignment (CLA) and Cross-image Alignment (CIA). The CLA module exploits the cross-layer relationship between low-level spatial information and high-level semantic information, which contributes to cross-layer feature aggregation to improve the capacity of feature representation for input images. The new CIA module is further introduced to produce the aligned feature map, which can enhance the relevant information as well as suppress the irrelevant information across the whole spatial region. Our method is based on an underlying assumption that the aligned feature map should be closer to the inputs of CIA when they belong to the same category. Accordingly, we establish Semantic Affinity Loss to supervise the feature alignment within each CIA block. Experimental results on four challenging datasets show that the proposed AENet achieves the state-of-the-art results over prior arts."}}
{"id": "dl8pp48Dkg", "cdate": 1577836800000, "mdate": 1668229555533, "content": {"title": "NAS-Count: Counting-by-Density with Neural Architecture Search", "abstract": "Most of the recent advances in crowd counting have evolved from hand-designed density estimation networks, where multi-scale features are leveraged to address the scale variation problem, but at the expense of demanding design efforts. In this work, we automate the design of counting models with Neural Architecture Search (NAS) and introduce an end-to-end searched encoder-decoder architecture, Automatic Multi-Scale Network (AMSNet). Specifically, we utilize a counting-specific two-level search space. The encoder and decoder in AMSNet are composed of different cells discovered from micro-level search, while the multi-path architecture is explored through macro-level search. To solve the pixel-level isolation issue in MSE loss, AMSNet is optimized with an auto-searched Scale Pyramid Pooling Loss (SPPLoss) that supervises the multi-scale structural information. Extensive experiments on four datasets show AMSNet produces state-of-the-art results that outperform hand-designed models, fully demonstrating the efficacy of NAS-Count."}}
