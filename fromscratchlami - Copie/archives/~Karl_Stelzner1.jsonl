{"id": "w4rvpu4SwMh", "cdate": 1640995200000, "mdate": 1682317518958, "content": {"title": "Right for the Right Latent Factors: Debiasing Generative Models via Disentanglement", "abstract": "A key assumption of most statistical machine learning methods is that they have access to independent samples from the distribution of data they encounter at test time. As such, these methods often perform poorly in the face of biased data, which breaks this assumption. In particular, machine learning models have been shown to exhibit Clever-Hans-like behaviour, meaning that spurious correlations in the training set are inadvertently learnt. A number of works have been proposed to revise deep classifiers to learn the right correlations. However, generative models have been overlooked so far. We observe that generative models are also prone to Clever-Hans-like behaviour. To counteract this issue, we propose to debias generative models by disentangling their internal representations, which is achieved via human feedback. Our experiments show that this is effective at removing bias even when human feedback covers only a small fraction of the desired distribution. In addition, we achieve strong disentanglement results in a quantitative comparison with recent methods."}}
{"id": "r2VuvN0r5vj", "cdate": 1640995200000, "mdate": 1652732643442, "content": {"title": "Conditional sum-product networks: Modular probabilistic circuits via gate functions", "abstract": ""}}
{"id": "rS9t6WH34p", "cdate": 1632875700720, "mdate": null, "content": {"title": "Decomposing 3D Scenes into Objects via Unsupervised Volume Segmentation", "abstract": "We present ObSuRF, a method which turns a single image of a scene into a 3D model represented as a set of Neural Radiance Fields (NeRFs), with each NeRF corresponding to a different object. A single forward pass of an encoder network outputs a set of latent vectors describing the objects in the scene. These vectors are used independently to condition a NeRF decoder, defining the geometry and appearance of each object. We make learning more computationally efficient by deriving a novel loss, which allows training NeRFs on RGB-D inputs without explicit ray marching. After confirming that the model performs equal or better than state of the art on three 2D image segmentation benchmarks, we apply it to two multi-object 3D datasets: A multiview version of CLEVR, and a novel dataset in which scenes are populated by ShapeNet models. We find that after training ObSuRF on RGB-D views of training scenes, it is capable of not only recovering the 3D geometry of a scene depicted in a single input image, but also to segment it into objects, despite receiving no supervision in that regard. "}}
{"id": "LzlegUNyYQd", "cdate": 1621239994776, "mdate": null, "content": {"title": "Decomposing 3D Scenes into Objects via Unsupervised Volume Segmentation", "abstract": "We present ObSuRF, a method which turns a single image of a scene into a 3D model represented as a set of Neural Radiance Fields (NeRFs), with each NeRF corresponding to a different object. A single forward pass of an encoder network outputs a set of latent vectors describing the objects in the scene. These vectors are used independently to condition a NeRF decoder, defining the geometry and appearance of each object. We make learning more computationally efficient by deriving a novel loss, which allows training NeRFs on RGB-D inputs without explicit ray marching. After confirming that the model performs equal or better than state of the art on three 2D image segmentation benchmarks, we apply it to two multi-object 3D datasets: A multiview version of CLEVR, and a novel dataset in which scenes are populated by ShapeNet models. We find that after training ObSuRF on RGB-D views of training scenes, it is capable of not only recovering the 3D geometry of a scene depicted in a single input image, but also to segment it into objects, despite receiving no supervision in that regard. "}}
{"id": "KlktHQEQOS", "cdate": 1609459200000, "mdate": 1682317519311, "content": {"title": "Decomposing 3D Scenes into Objects via Unsupervised Volume Segmentation", "abstract": "We present ObSuRF, a method which turns a single image of a scene into a 3D model represented as a set of Neural Radiance Fields (NeRFs), with each NeRF corresponding to a different object. A single forward pass of an encoder network outputs a set of latent vectors describing the objects in the scene. These vectors are used independently to condition a NeRF decoder, defining the geometry and appearance of each object. We make learning more computationally efficient by deriving a novel loss, which allows training NeRFs on RGB-D inputs without explicit ray marching. After confirming that the model performs equal or better than state of the art on three 2D image segmentation benchmarks, we apply it to two multi-object 3D datasets: A multiview version of CLEVR, and a novel dataset in which scenes are populated by ShapeNet models. We find that after training ObSuRF on RGB-D views of training scenes, it is capable of not only recovering the 3D geometry of a scene depicted in a single input image, but also to segment it into objects, despite receiving no supervision in that regard."}}
{"id": "-rEMLaQla29", "cdate": 1600156639579, "mdate": null, "content": {"title": "Generative Adversarial Set Transformers", "abstract": "Generative Adversarial Set TransformersKarl Stelzner1Kristian Kersting1Adam R. Kosiorek2AbstractGroups of entities are naturally represented assets,  but generative models usually treat them as independent from each other or as sequences. This either over-simplifies the problem or imposes an order to the otherwise unordered col-lections, which has to be accounted for in loss computation. We, therefore, introduce generative adversarial set transformer(GAST)\u2014aGANforsets capable of generating variable-sized sets in a permutation-equivariant manner, while accounting for dependencies between set elements.   It avoids the problem of formulating a distance metric between sets by using a permutation-invariant discriminator. When evaluated on a dataset of regular polygons and on MNIST point clouds, GAST outperforms graph-convolution-based GANs in sample fidelity, while showing good generalization to novel set sizes"}}
{"id": "zBT7LSEd9H", "cdate": 1577836800000, "mdate": 1682317519319, "content": {"title": "Residual Sum-Product Networks", "abstract": "Tractable yet expressive density estimators are a key building block of probabilistic machine learning. While sum-product networks (SPNs) offer attractive inference capabilities, obtaining structures large enough to fit complex, high-dimensional data has proven challenging. In this paper, we present a residual learning approach to ease the learning of SPNs, which are deeper and wider than those used previously. The main trick is to ensemble SPNs by explicitly reformulating sum nodes as residual functions. This adds references to substructures across the SPNs at different depths, which in turn helps to improve training. Our experiments demonstrate that the resulting residual SPNs (ResSPNs) are easy to optimize, gain performance from considerably increased depth and width, and are competitive to state of-the-art SPN structure learning approaches. To combat overfitting, we introduce an iterative pruning technique that compacts models and yields better generalization."}}
{"id": "wBmvh-ICNdm", "cdate": 1577836800000, "mdate": 1652732643434, "content": {"title": "Conditional Sum-Product Networks: Imposing Structure on Deep Probabilistic Architectures", "abstract": "Probabilistic graphical models are a central tool in AI, however, they are generally not as expressive as deep neural models, and inference is notoriously hard and slow. In contrast, deep probabilistic models such as sum-product networks (SPNs) capture joint distributions in a tractable fashion, but still lack the expressive power of intractable models based on deep neural networks. Therefore, we introduce conditional SPNs (CSPNs), conditional density estimators for multivariate and potentially hybrid domains that allow harnessing the expressive power of neural networks while still maintaining tractability guarantees. One way to implement CSPNs is to use an existing SPN structure and condition its parameters on the input, e.g., via a deep neural network. Our experimental evidence demonstrates that CSPNs are competitive with other probabilistic models and yield superior performance on multilabel image classification compared to mean field and mixture density networks. Furthermore, they can successfully be employed as building blocks for structured probabilistic models, such as autoregressive image models."}}
{"id": "viI0LCY9MQK", "cdate": 1577836800000, "mdate": 1668811453606, "content": {"title": "Einsum Networks: Fast and Scalable Learning of Tractable Probabilistic Circuits", "abstract": "Probabilistic circuits (PCs) are a promising avenue for probabilistic modeling, as they permit a wide range of exact and efficient inference routines. Recent \u201cdeep-learning-style\u201d implementations o..."}}
{"id": "qFPk5eQkcAQ", "cdate": 1577836800000, "mdate": null, "content": {"title": "Einsum Networks: Fast and Scalable Learning of Tractable Probabilistic Circuits", "abstract": "Probabilistic circuits (PCs) are a promising avenue for probabilistic modeling, as they permit a wide range of exact and efficient inference routines. Recent ``deep-learning-style'' implementations of PCs strive for a better scalability, but are still difficult to train on real-world data, due to their sparsely connected computational graphs. In this paper, we propose Einsum Networks (EiNets), a novel implementation design for PCs, improving prior art in several regards. At their core, EiNets combine a large number of arithmetic operations in a single monolithic einsum-operation, leading to speedups and memory savings of up to two orders of magnitude, in comparison to previous implementations. As an algorithmic contribution, we show that the implementation of Expectation-Maximization (EM) can be simplified for PCs, by leveraging automatic differentiation. Furthermore, we demonstrate that EiNets scale well to datasets which were previously out of reach, such as SVHN and CelebA, and that they can be used as faithful generative image models."}}
